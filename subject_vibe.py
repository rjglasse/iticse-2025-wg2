"""
Subject Classification Tool

This tool uses OpenAI's API to automatically classify academic papers into computer 
science course subjects based on their titles and abstracts. It extracts text from 
BibTeX files and outputs CSV with DOIs, titles, and predicted CS courses.

Key Features:
- Extracts text from BibTeX titles and abstracts
- Uses OpenAI GPT models for intelligent classification
- Handles missing abstracts gracefully
- Exports results to CSV with DOI, title, and predicted course
- Includes error handling for API issues
- Respects API rate limits with built-in delays
- Provides progress tracking for large datasets
- Generates horizontal bar charts for visualization

Usage Examples:
    # Basic subject classification
    python subject_vibe.py -f papers.bib -o classifications.csv

    # Classify with verbose output and generate chart
    python subject_vibe.py -f bibfiles/acm_chatgpt.bib -v -o cs_subjects.csv -p

    # Use specific OpenAI model with chart generation
    python subject_vibe.py -f papers.bib -m gpt-4 -o detailed_analysis.csv -p --chart-output analysis_chart.png

Requirements:
    - Python packages: openai, bibtexparser, matplotlib, numpy
    - OpenAI API key (set as OPENAI_API_KEY environment variable)
    - BibTeX files with title and preferably abstract fields

Author: Designed by Ric Glassey. Generated by Claude Sonnet 4 for ITiCSE 2025 WG2 Systematic Literature Review
"""

import argparse
import re
import csv
import os
import time
import random
from collections import Counter
import matplotlib.pyplot as plt
import numpy as np
from openai import OpenAI
import bibtexparser

def extract_papers_from_bibtex(bibtex_path):
    """Extract paper information from BibTeX file using bibtexparser."""
    papers = []
    
    try:
        with open(bibtex_path, 'r', encoding='utf-8', errors='ignore') as f:
            # Parse the BibTeX file using bibtexparser
            bib_database = bibtexparser.load(f)
        
        print(f"Found {len(bib_database.entries)} total BibTeX entries")
        
        # Process each entry
        for entry in bib_database.entries:
            paper = {}
            
            # Extract DOI
            if 'doi' in entry:
                doi = entry['doi'].strip()
                # Clean up DOI by removing common prefixes
                if doi.startswith('https://doi.org/'):
                    doi = doi[16:]
                elif doi.startswith('http://dx.doi.org/'):
                    doi = doi[18:]
                elif doi.startswith('dx.doi.org/'):
                    doi = doi[11:]
                paper['doi'] = doi
            
            # Extract title (try title first, then booktitle as fallback)
            if 'title' in entry:
                title = clean_text(entry['title'])
                paper['title'] = title
            elif 'booktitle' in entry:
                title = clean_text(entry['booktitle'])
                paper['title'] = title
            
            # Extract abstract
            if 'abstract' in entry:
                abstract = clean_text(entry['abstract'])
                paper['abstract'] = abstract
            
            # Only include papers with at least title and DOI
            if paper.get('title') and paper.get('doi'):
                papers.append(paper)
        
        print(f"Found {len(papers)} papers with both title and DOI")
    
    except Exception as e:
        print(f"Error reading BibTeX file {bibtex_path}: {e}")
        return []
    
    return papers

def clean_text(text):
    """Clean LaTeX commands and normalize text."""
    # Remove LaTeX commands
    text = re.sub(r'\\[a-zA-Z]+\{[^}]*\}', '', text)
    text = re.sub(r'\\[a-zA-Z]+', '', text)
    
    # Remove extra whitespace
    text = ' '.join(text.split())
    
    return text

def classify_paper(client, paper, model="gpt-3.5-turbo"):
    """Classify a paper using OpenAI API."""
    title = paper.get('title', 'No title')
    abstract = paper.get('abstract', 'No abstract available')
    
    # Create prompt
    prompt = f"""Your task is to try to classify each paper based on its title and abstract. The goal is to find papers that are targetting a specific computer science course (like Databases, or Operating Systems). However, not all papers will fit this neat classification, so you can try to come up with a more appropriate label:

    Title: {title}

    Abstract: {abstract}

    Please respond with just the best prediction of course name (e.g., "Machine Learning", "Databases", "Software Engineering", "Computer Networks", "Operating Systems", "Computer Graphics", "Human-Computer Interaction", "Algorithms and Data Structures", "Introductory Programming", "Object-oriented Programming", "Distributed Systems", "Computer Security", "Theory of Computation", "Web Development", or another specific CS course subject or label if more appropriate).

Course Subject:"""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are an expert computer science educator who classifies research papers into appropriate undergraduate/graduate CS course subjects."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=50,
            temperature=0.1
        )
        
        predicted_course = response.choices[0].message.content.strip()
        return predicted_course
        
    except Exception as e:
        print(f"Error classifying paper '{title[:50]}...': {e}")
        return f"Error: {str(e)}"

def classify_papers_batch(client, papers, model="gpt-4o"):
    """
    Classify multiple papers in a single API call for improved efficiency.
    
    Args:
        client: OpenAI client instance
        papers: List of paper dictionaries with 'title' and 'abstract' keys
        model: OpenAI model to use for classification
        
    Returns:
        List of classification strings, one per input paper
        
    Note:
        This function processes multiple papers in one API call, which is more
        efficient than individual calls but may be less accurate for complex cases.
    """
    
    # Create batch prompt
    papers_text = ""
    for i, paper in enumerate(papers, 1):
        title = paper.get('title', 'No title')
        abstract = paper.get('abstract', 'No abstract available')
        papers_text += f"\nPaper {i}:\nTitle: {title}\nAbstract: {abstract}\n"
    
    prompt = f"""Classify each of these {len(papers)} computer science papers into course subjects. For each paper, respond with just the course name.

{papers_text}

Please respond in this exact format:
Paper 1: [Course Subject]
Paper 2: [Course Subject]
Paper 3: [Course Subject]
etc.

Use subjects like: Machine Learning, Databases, Software Engineering, Computer Networks, Operating Systems, Computer Graphics, Human-Computer Interaction, Algorithms and Data Structures, Introductory Programming, Distributed Systems, Computer Security, Theory of Computation, Web Development, etc."""

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": "You are an expert computer science educator who classifies research papers into appropriate undergraduate/graduate CS course subjects."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=len(papers) * 20,  # Scale tokens based on number of papers
            temperature=0.1
        )
        
        # Parse the batch response
        response_text = response.choices[0].message.content.strip()
        classifications = []
        
        for line in response_text.split('\n'):
            if line.strip() and ':' in line:
                # Extract just the classification part after the colon
                classification = line.split(':', 1)[1].strip()
                classifications.append(classification)
        
        # Ensure we have the right number of classifications
        while len(classifications) < len(papers):
            classifications.append("Classification Error")
        
        return classifications[:len(papers)]  # Return exactly the number requested
        
    except Exception as e:
        print(f"Error in batch classification: {e}")
        return [f"Error: {str(e)}"] * len(papers)

def plot_classification_results(results, output_file):
    """Generate and save a pie chart of classification results."""
    # Count papers per course subject
    course_counts = Counter(result['Predicted_Course'] for result in results)
    
    # Prepare data for plotting
    labels = list(course_counts.keys())
    sizes = list(course_counts.values())
    
    # Normalize sizes to be between 0 and 1
    total_papers = sum(sizes)
    sizes = [size / total_papers for size in sizes]
    
    # Create a color palette with fading effect
    cmap = plt.get_cmap("viridis")
    colors = [cmap(i / len(sizes)) for i in range(len(sizes))]
    
    # Plot pie chart
    fig, ax = plt.subplots()
    wedges, texts, autotexts = ax.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=colors)
    
    # Beautify the chart
    plt.setp(autotexts, size=10, weight="bold", color="white")
    plt.setp(texts, size=10)
    ax.set_title("Paper Classification Distribution", fontsize=14, weight="bold")
    
    # Save the figure
    plt.tight_layout()
    plt.savefig(output_file, dpi=300)
    plt.close(fig)
    print(f"Chart saved to: {output_file}")

def create_subject_chart(results, output_file='subject_vibes_chart.png', max_subjects=20):
    """Create a horizontal bar chart of CS subject frequencies with a fading color palette."""
    try:
        # Count subject frequencies
        subject_counts = Counter(result['Predicted_Course'] for result in results)
        
        # Sort by frequency and limit display
        sorted_subjects = subject_counts.most_common(max_subjects)
        
        if not sorted_subjects:
            print("No subjects to plot.")
            return False
        
        # Extract subjects and counts
        subjects = [item[0] for item in sorted_subjects]
        counts = [item[1] for item in sorted_subjects]
        
        # Create figure with appropriate size for readability
        plt.figure(figsize=(12, max(8, len(subjects) * 0.4)))
        
        # Create beautiful fading color palette (purple to blue gradient)
        num_bars = len(subjects)
        colors = plt.cm.viridis(np.linspace(0.8, 0.2, num_bars))  # Deep purple to teal gradient
        
        # Create horizontal bar chart
        bars = plt.barh(subjects, counts, color=colors, alpha=0.85, edgecolor='white', linewidth=0.5)
        
        # Customize the chart
        plt.title('CS Subject Vibe Count', fontsize=18, fontweight='bold', pad=25, color='#2c3e50')
        plt.xlabel('Number of Papers', fontsize=14, fontweight='bold', color='#34495e')
        plt.ylabel('Computer Science Subjects', fontsize=14, fontweight='bold', color='#34495e')
        
        # Invert y-axis so highest frequency is on top
        plt.gca().invert_yaxis()
        
        # Add value labels at the end of bars
        for bar, count in zip(bars, counts):
            plt.text(bar.get_width() + max(counts) * 0.01, bar.get_y() + bar.get_height()/2,
                    str(count), ha='left', va='center', fontweight='bold', fontsize=11, color='#2c3e50')
        
        # Add grid for better readability
        plt.grid(axis='x', alpha=0.3, linestyle='--', color='#bdc3c7')
        
        # Style the axes
        plt.gca().spines['top'].set_visible(False)
        plt.gca().spines['right'].set_visible(False)
        plt.gca().spines['left'].set_color('#bdc3c7')
        plt.gca().spines['bottom'].set_color('#bdc3c7')
        
        # Adjust layout to prevent label cutoff
        plt.tight_layout()
        
        # Save the chart with high quality
        plt.savefig(output_file, dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        plt.close()  # Close the figure to free memory
        
        print(f"Subject visualization chart saved to: {output_file}")
        return True
        
    except ImportError:
        print("Error: matplotlib and numpy are required for plotting. Install with: pip install matplotlib numpy")
        return False
    except Exception as e:
        print(f"Error creating subject chart: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='Classify CS papers into course subjects using OpenAI')
    parser.add_argument('-f', '--file', required=True, help='BibTeX file to analyze')
    parser.add_argument('-o', '--output', required=True, help='Output CSV file')
    parser.add_argument('-m', '--model', default='gpt-4o', 
                       help='OpenAI model to use (default: gpt-4o)')
    parser.add_argument('-v', '--verbose', action='store_true', help='Show detailed progress')
    parser.add_argument('--delay', type=float, default=1.0, 
                       help='Delay between API calls in seconds (default: 1.0)')
    parser.add_argument('-n', '--sample-size', type=int, 
                       help='Randomly sample n papers instead of processing all')
    parser.add_argument('--seed', type=int, default=42,
                       help='Random seed for reproducible sampling (default: 42)')
    parser.add_argument('--batch-size', type=int, 
                       help='Process multiple papers per API call (e.g., 5). Faster but experimental.')
    parser.add_argument('-p', '--plot-chart', action='store_true', 
                       help='Generate horizontal bar chart of subject frequencies')
    parser.add_argument('--chart-output', 
                       help='Output file for chart (default: subject_vibes_chart.png)', 
                       default='subject_vibes_chart.png')
    parser.add_argument('--max-subjects', type=int, default=20, 
                       help='Maximum number of subjects to display in chart (default: 20)')
    parser.add_argument('--chart', action='store_true', help='Generate a chart of classification results')
    parser.add_argument('--output-chart', help='Output file for the chart (PNG format)')
    
    args = parser.parse_args()
    
    # Check for OpenAI API key
    api_key = os.getenv('OPENAI_API_KEY')
    if not api_key:
        print("Error: OpenAI API key not found. Please set OPENAI_API_KEY environment variable.")
        print("Example: export OPENAI_API_KEY='your-api-key-here'")
        return
    
    # Initialize OpenAI client
    try:
        client = OpenAI(api_key=api_key)
    except Exception as e:
        print(f"Error initializing OpenAI client: {e}")
        return
    
    # Check if input file exists
    if not os.path.exists(args.file):
        print(f"Error: File '{args.file}' not found.")
        return
    
    print(f"Extracting papers from: {args.file}")
    
    # Extract papers from BibTeX
    papers = extract_papers_from_bibtex(args.file)
    if not papers:
        print("No papers with titles and DOIs found.")
        return
    
    print(f"Found {len(papers)} total papers")
    
    # Handle random sampling if requested
    if args.sample_size:
        if args.sample_size > len(papers):
            print(f"Warning: Sample size ({args.sample_size}) is larger than available papers ({len(papers)})")
            print("Processing all available papers instead.")
        else:
            # Set random seed for reproducibility
            random.seed(args.seed)
            papers = random.sample(papers, args.sample_size)
            print(f"Randomly selected {len(papers)} papers for classification (seed: {args.seed})")
    
    print(f"Processing {len(papers)} papers to classify")
    print(f"Using model: {args.model}")
    
    if args.batch_size:
        print(f"Using batch processing: {args.batch_size} papers per API call")
    else:
        print("Using individual paper processing (1 paper per API call)")
    
    # Classify papers
    results = []
    start_time = time.time()
    
    if args.batch_size:
        # Batch processing mode
        total_batches = (len(papers) + args.batch_size - 1) // args.batch_size  # Ceiling division
        
        for batch_num in range(total_batches):
            start_idx = batch_num * args.batch_size
            end_idx = min(start_idx + args.batch_size, len(papers))
            batch_papers = papers[start_idx:end_idx]
            
            # Calculate progress metrics
            papers_processed = end_idx
            progress_percent = (papers_processed / len(papers)) * 100
            elapsed_time = time.time() - start_time
            
            if batch_num > 0:  # Avoid division by zero
                avg_time_per_batch = elapsed_time / batch_num
                remaining_batches = total_batches - batch_num
                estimated_remaining = remaining_batches * avg_time_per_batch
                eta_minutes = int(estimated_remaining // 60)
                eta_seconds = int(estimated_remaining % 60)
                eta_str = f"{eta_minutes}m {eta_seconds}s"
            else:
                eta_str = "calculating..."
            
            if args.verbose:
                print(f"[Batch {batch_num + 1}/{total_batches} - {progress_percent:.1f}%] Processing {len(batch_papers)} papers")
                print(f"  ETA: {eta_str}")
            else:
                print(f"Batch Progress: {batch_num + 1}/{total_batches} ({progress_percent:.1f}%) - ETA: {eta_str}", end='\r', flush=True)
            
            # Classify the batch
            batch_classifications = classify_papers_batch(client, batch_papers, args.model)
            
            # Add results
            for i, (paper, classification) in enumerate(zip(batch_papers, batch_classifications)):
                results.append({
                    'DOI': paper['doi'],
                    'Title': paper['title'],
                    'Predicted_Course': classification
                })
                
                if args.verbose:
                    title_preview = paper['title'][:60] + "..." if len(paper['title']) > 60 else paper['title']
                    print(f"    Paper {start_idx + i + 1}: {title_preview} → {classification}")
            
            if args.verbose:
                print()  # Add blank line for readability
            
            # Rate limiting between batches
            if batch_num < total_batches - 1:  # Don't delay after the last batch
                time.sleep(args.delay)
        
        # Clear the progress line
        if not args.verbose:
            print()  # Move to new line after progress indicator
            
    else:
        # Individual processing mode (original behavior)
        for i, paper in enumerate(papers, 1):
            # Calculate progress metrics
            progress_percent = (i / len(papers)) * 100
            elapsed_time = time.time() - start_time
            if i > 1:  # Avoid division by zero
                avg_time_per_paper = elapsed_time / (i - 1)
                remaining_papers = len(papers) - i
                estimated_remaining = remaining_papers * avg_time_per_paper
                eta_minutes = int(estimated_remaining // 60)
                eta_seconds = int(estimated_remaining % 60)
                eta_str = f"{eta_minutes}m {eta_seconds}s"
            else:
                eta_str = "calculating..."
            
            if args.verbose:
                title_preview = paper['title'][:80] + "..." if len(paper['title']) > 80 else paper['title']
                print(f"[{i}/{len(papers)} - {progress_percent:.1f}%] {title_preview}")
                print(f"  ETA: {eta_str}")
            else:
                # Show compact progress for non-verbose mode
                print(f"Progress: {i}/{len(papers)} ({progress_percent:.1f}%) - ETA: {eta_str}", end='\r', flush=True)
            
            predicted_course = classify_paper(client, paper, args.model)
            
            results.append({
                'DOI': paper['doi'],
                'Title': paper['title'],
                'Predicted_Course': predicted_course
            })
            
            if args.verbose:
                print(f"  → {predicted_course}")
                print()  # Add blank line for readability
            
            # Rate limiting
            if i < len(papers):  # Don't delay after the last paper
                time.sleep(args.delay)
        
        # Clear the progress line and show completion
        if not args.verbose:
            print()  # Move to new line after progress indicator
    
    total_time = time.time() - start_time
    total_minutes = int(total_time // 60)
    total_seconds = int(total_time % 60)
    print(f"Classification completed in {total_minutes}m {total_seconds}s")
    
    # Save results to CSV
    try:
        with open(args.output, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['DOI', 'Title', 'Predicted_Course']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for result in results:
                writer.writerow(result)
        
        print(f"\nResults saved to: {args.output}")
        
        # Show summary statistics
        course_counts = {}
        for result in results:
            course = result['Predicted_Course']
            course_counts[course] = course_counts.get(course, 0) + 1
        
        print(f"\nClassification Summary:")
        print("-" * 40)
        for course, count in sorted(course_counts.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / len(results)) * 100
            print(f"{course}: {count} papers ({percentage:.1f}%)")
        
        # Show sampling info if used
        if args.sample_size:
            print(f"\nSampling Info:")
            print(f"Random seed used: {args.seed}")
            print(f"Sample size: {len(results)} out of total available papers")
        
        # Show processing mode info
        if args.batch_size:
            actual_batches = (len(papers) + args.batch_size - 1) // args.batch_size
            print(f"\nBatch Processing Info:")
            print(f"Batch size: {args.batch_size} papers per API call")
            print(f"Total API calls made: {actual_batches} (vs {len(papers)} for individual processing)")
            time_saved_percent = ((len(papers) - actual_batches) / len(papers)) * 100
            print(f"API calls reduced by: {time_saved_percent:.1f}%")
        
        # Generate horizontal bar chart if requested
        if args.plot_chart:
            create_subject_chart(results, args.chart_output, args.max_subjects)
        
        # Generate and save chart if requested (legacy functionality)
        if args.chart:
            output_chart_file = args.output_chart if args.output_chart else "classification_chart.png"
            plot_classification_results(results, output_chart_file)
            create_subject_chart(results, args.output_chart.replace('.png', '_subjects.png'))
        
    except Exception as e:
        print(f"Error saving results: {e}")

if __name__ == "__main__":
    main()