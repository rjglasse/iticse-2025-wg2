SLR Toolkit Unification Analysis & Recommendations
=================================================

Date: 2025-06-27
Analysis of 14 Python scripts in iticse-2025-wg2 repository

## IDENTIFIED OVERLAPS AND REDUNDANCIES

### 1. BibTeX Processing (6+ scripts affected)
DUPLICATED CODE:
- bibtexparser library initialization
- Entry iteration and field extraction patterns
- Title/abstract/DOI field handling

AFFECTED SCRIPTS:
- bibtex2csv.py
- extract_bib_items.py  
- set_of_dois.py
- subject_vibe.py
- tf_idf.py
- topic_frequency.py

SAVINGS POTENTIAL: ~200-300 lines of duplicated code

### 2. DOI Normalization (8+ scripts affected)
DUPLICATED CODE:
```python
# This exact pattern appears in 8+ scripts:
if doi.startswith('https://doi.org/'):
    doi = doi[16:]
elif doi.startswith('http://dx.doi.org/'):
    doi = doi[18:]
elif doi.startswith('dx.doi.org/'):
    doi = doi[11:]
```

AFFECTED SCRIPTS: Nearly every script that handles DOIs
SAVINGS POTENTIAL: ~15-20 lines per script × 8 scripts = 120-160 lines

### 3. Text Cleaning (5+ scripts affected)
DUPLICATED CODE:
```python
# LaTeX command removal appears identically in multiple scripts:
text = re.sub(r'\\[a-zA-Z]+\{[^}]*\}', '', text)
text = re.sub(r'\\[a-zA-Z]+', '', text)
text = ' '.join(text.split())  # whitespace normalization
```

AFFECTED SCRIPTS:
- bibtex2csv.py
- subject_vibe.py
- tf_idf.py
- short_description_and_category.py
- springer_crawl.py

SAVINGS POTENTIAL: ~20-30 lines per script × 5 scripts = 100-150 lines

### 4. OpenAI API Integration (3 scripts affected)
DUPLICATED CODE:
- Client initialization and API key handling
- Rate limiting logic (time.sleep patterns)
- Error handling for API calls
- Progress tracking with ETA calculations

AFFECTED SCRIPTS:
- subject_vibe.py (590 lines)
- short_description_and_category.py (315 lines)
- not_relevant_sanity_check.py (404 lines)

SAVINGS POTENTIAL: ~100-150 lines per script × 3 scripts = 300-450 lines

### 5. Chart Generation (3 scripts affected)
DUPLICATED CODE:
- Matplotlib figure setup and styling
- Viridis color palette configuration
- Horizontal bar chart formatting
- PNG export with consistent DPI settings

AFFECTED SCRIPTS:
- subject_vibe.py (chart generation functions)
- subject_chart.py (221 lines, primarily chart generation)
- topic_frequency.py (chart generation functions)

SAVINGS POTENTIAL: ~50-100 lines per script × 3 scripts = 150-300 lines

## PROPOSED UNIFIED ARCHITECTURE

### Core Library Structure:
```
slr_toolkit/
├── __init__.py
├── core/
│   ├── __init__.py
│   ├── bibtex.py      # Centralized BibTeX parsing and entry management
│   ├── doi.py         # DOI validation, normalization, Crossref API integration
│   ├── text.py        # Text cleaning, LaTeX removal, tokenization
│   ├── ai.py          # OpenAI integration, rate limiting, batch processing
│   └── viz.py         # Consistent chart generation and styling
├── commands/
│   ├── __init__.py
│   ├── convert.py     # Format conversions (BibTeX↔CSV, etc.)
│   ├── analyze.py     # Content analysis (TF-IDF, topic frequency)
│   ├── classify.py    # AI-powered classification and categorization
│   ├── validate.py    # DOI validation, relevance checking
│   └── crawl.py       # Data collection from external sources
├── cli.py             # Unified command-line interface
└── config.py          # Configuration management
```

### Unified CLI Interface Examples:
```bash
# Single entry point replacing 14 separate scripts
slr-toolkit convert bibtex-to-csv papers.bib
slr-toolkit convert csv-to-bibtex papers.csv --output papers.bib

slr-toolkit validate dois --file dois.txt --concurrent 5
slr-toolkit validate relevance --bibtex papers.bib --sample 20

slr-toolkit analyze tfidf papers.bib --min-df 2 --max-df 0.8
slr-toolkit analyze topics papers.bib --topics topics.txt --chart
slr-toolkit analyze overlap --dois dois.txt --bibtex papers.bib

slr-toolkit classify subjects papers.bib --model gpt-4o --chart
slr-toolkit classify relevance papers.bib --model gpt-4o --batch-size 5

slr-toolkit crawl springer --url "rss_url" --pages 10 --delay 1.5
slr-toolkit extract dois papers.bib --output dois.txt
slr-toolkit extract entries --dois dois.txt --bibtex papers.bib

# Visualization
slr-toolkit chart subjects --data subjects.csv --max-subjects 20
slr-toolkit chart topics --data topics.csv --style viridis
```

## QUANTIFIED BENEFITS

### Code Reduction:
- **Total estimated savings: 1000-1500 lines of duplicated code**
- **Maintenance reduction: ~70% fewer files to maintain**
- **Testing surface: Centralized logic = fewer test cases needed**

### User Experience:
- **Single installation**: pip install slr-toolkit
- **Consistent interface**: Predictable argument patterns across all functions
- **Unified help system**: slr-toolkit --help, slr-toolkit convert --help
- **Shared configuration**: API keys, output formats, rate limits centralized

### Technical Benefits:
- **Better error handling**: Unified logging and exception management
- **Performance optimization**: Shared caching, connection pooling
- **Extensibility**: Easy to add new analysis methods or data sources
- **Type safety**: Centralized data models and validation

## MIGRATION STRATEGY

### Phase 1: Core Library (Week 1)
1. Extract common utilities into slr_toolkit.core modules
2. Create shared data models (Paper, DOI, etc.)
3. Implement unified configuration system

### Phase 2: Command Conversion (Week 2)
1. Convert existing scripts to subcommands using shared core
2. Implement unified CLI with argument parsing
3. Add comprehensive help and documentation

### Phase 3: Enhancement (Week 3)
1. Add unified configuration file support
2. Implement better error handling and logging
3. Add progress bars and improved user feedback

### Phase 4: Testing & Documentation (Week 4)
1. Comprehensive test suite for core modules
2. User documentation and examples
3. Migration guide from individual scripts

### Backward Compatibility:
- Keep existing scripts as thin wrappers around new CLI
- Maintain exact same functionality and output formats
- Gradual deprecation path with clear migration instructions

## CURRENT SCRIPT MAPPING TO NEW STRUCTURE

| Current Script | New Command | Core Modules Used |
|---------------|-------------|-------------------|
| bibtex2csv.py | convert bibtex-to-csv | bibtex.py, text.py |
| check_dois_valid.py | validate dois | doi.py |
| doi_overlap.py | analyze overlap | bibtex.py, doi.py |
| extract_bib_items.py | extract entries | bibtex.py, doi.py |
| find_dois.py | validate find-dois | doi.py (Crossref) |
| set_of_dois.py | extract dois | bibtex.py, doi.py |
| subject_vibe.py | classify subjects | bibtex.py, ai.py, viz.py |
| tf_idf.py | analyze tfidf | bibtex.py, text.py |
| topic_frequency.py | analyze topics | bibtex.py, viz.py |
| springer_crawl.py | crawl springer | text.py, doi.py |
| subject_chart.py | chart subjects | viz.py |
| short_description_and_category.py | classify categories | bibtex.py, ai.py |
| not_relevant_sanity_check.py | validate relevance | bibtex.py, ai.py |
| member_map.py | [standalone] | (visualization tool) |

## IMPLEMENTATION PRIORITY

### HIGH PRIORITY (immediate impact):
1. Core BibTeX processing (affects 6+ scripts)
2. DOI normalization utilities (affects 8+ scripts)  
3. Text cleaning functions (affects 5+ scripts)

### MEDIUM PRIORITY (quality of life):
4. OpenAI API integration (affects 3 scripts)
5. Chart generation utilities (affects 3 scripts)
6. Unified CLI interface

### LOW PRIORITY (nice to have):
7. Configuration management
8. Advanced error handling
9. Performance optimizations

## ESTIMATED DEVELOPMENT TIME
- **Total effort**: 3-4 weeks for complete unification
- **Immediate benefits**: Can be realized incrementally
- **Risk**: Low (maintaining backward compatibility)
- **ROI**: High (significant maintenance burden reduction)

## CONCLUSION
The current repository contains substantial code duplication that can be eliminated through careful refactoring into a unified toolkit. This would reduce maintenance overhead by ~70% while providing users with a much more coherent and discoverable interface.

The modular design ensures that individual components can be updated independently while maintaining the benefits of code reuse and consistent interfaces.