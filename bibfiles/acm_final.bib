@inproceedings{10.1145/3585059.3611409,
author = {Gumina, Sharon and Dalton, Travis and Gerdes, John},
title = {Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611409},
doi = {10.1145/3585059.3611409},
abstract = {This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students’ interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {60–65},
numpages = {6},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3568812.3603453,
author = {Tran, Minh},
title = {Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603453},
doi = {10.1145/3568812.3603453},
abstract = {The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {110–112},
numpages = {3},
keywords = {culturally responsive pedagogy, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3545947.3569630,
author = {MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami},
title = {Automatically Generating CS Learning Materials with Large Language Models},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3569630},
doi = {10.1145/3545947.3569630},
abstract = {Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1176},
numpages = {1},
keywords = {code generation, computer science education, copilot, explanations, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3585059.3611431,
author = {Zheng, Yong},
title = {ChatGPT for Teaching and Learning: An Experience from Data Science Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611431},
doi = {10.1145/3585059.3611431},
abstract = {ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {66–72},
numpages = {7},
keywords = {ChatGPT, data analytics, data science, large language model},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@article{10.5555/3636517.3636522,
author = {Crandall, Aaron S. and Sprint, Gina and Fischer, Bryan},
title = {Generative Pre-Trained Transformer (GPT) Models as a Code Review Feedback Tool in Computer Science Programs},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {Undergraduate computer science and software engineering students benefit significantly from in-depth reviews of their code early and often in their courses. Performing these reviews is time-consuming for teaching assistants and professors to complete, consequently impacting the timeliness and consistency of the provided feedback. When code feedback is not delivered close to the time of authorship, the utility of the review for students is diminished. Prior work with Automatic Static Analysis Tools has shown promise at using artificial intelligence to automate code reviews, with some success integrating them into classroom environments. To leverage new advances in Generative Pre-Trained Transformer (GPT) models, this work reports on an Automatic Review Tool (ART) to provide timely, automatically generated code reviews. ART was evaluated in a second-semester computer science course by integrating ART into the course's Github-based assignment submission system. A cohort of student volunteers (N = 74) read the ART reviews and provided feedback using a survey spanning two of their course assignments. The results of this pilot study show that students perceived ART was successful at detecting defects and offering style-based suggestions, and students were receptive to receiving future automated reviews of their work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {38–47},
numpages = {10}
}

@inproceedings{10.1145/3611643.3613892,
author = {Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
title = {InferFix: End-to-End Program Repair with LLMs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613892},
doi = {10.1145/3611643.3613892},
abstract = {Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever – transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator – an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1646–1656},
numpages = {11},
keywords = {Program repair, finetuning, prompt augmentation, static analyses},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemelä, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {tutoring, student perceptions, generative AI, education, discussion forum, chatbots, artificial intelligence, ChatGPT},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@article{10.1145/3631504.3631518,
author = {Amer-Yahia, Sihem and Bonifati, Angela and Chen, Lei and Li, Guoliang and Shim, Kyuseok and Xu, Jianliang and Yang, Xiaochun},
title = {From Large Language Models to Databases and Back: A Discussion on Research and Education},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/3631504.3631518},
doi = {10.1145/3631504.3631518},
abstract = {In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.},
journal = {SIGMOD Rec.},
month = nov,
pages = {49–56},
numpages = {8}
}

@inproceedings{10.1145/3545947.3573358,
author = {MacNeil, Stephen and Kim, Joanne and Leinonen, Juho and Denny, Paul and Bernstein, Seth and Becker, Brett A. and Wermelinger, Michel and Hellas, Arto and Tran, Andrew and Sarsa, Sami and Prather, James and Kumar, Viraj},
title = {The Implications of Large Language Models for CS Teachers and Students},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573358},
doi = {10.1145/3545947.3573358},
abstract = {The introduction of Large Language Models (LLMs) has generated a significant amount of excitement both in industry and among researchers. Recently, tools that leverage LLMs have made their way into the classroom where they help students generate code and help instructors generate learning materials. There are likely many more uses of these tools -- both beneficial to learning and possibly detrimental to learning. To help ensure that these tools are used to enhance learning, educators need to not only be familiar with these tools, but with their use and potential misuse. The goal of this BoF is to raise awareness about LLMs and to build a learning community around their use in computing education. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed discussion leaders, including undergraduate researchers, to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1255},
numpages = {1},
keywords = {artificial intelligence, code explanations, code generation, computer science education, copilot, gpt-3, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3627217.3627235,
author = {Venkatesh, Varshini and Venkatesh, Vaishnavi and Kumar, Viraj},
title = {Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627235},
doi = {10.1145/3627217.3627235},
abstract = {Code writing problems in introductory programming (CS1) courses typically ask students to write simple functions or programs based on detailed natural-language specifications. These details can be leveraged by large language models (LLMs), accessible to students via tools such as GitHub Copilot, to generate solutions that are often correct. CS1 instructors who are unwilling or unable to prohibit such usage must consider variants of traditional code writing problems that align with their learning objectives but are more difficult for LLMs to solve. Since LLMs are sensitive to the level of details in their prompts, it is natural to consider variants where details are progressively trimmed from the specifications of traditional code writing problems, and consequent ambiguities are clarified via examples. We consider an extreme variant, where all natural language is suppressed except for meaningful names of functions and their arguments. We evaluate the performance of Copilot on suppressed specification versions of 153 such problems drawn from the CodeCheck repository. If Copilot initially fails to generate a correct solution, we augment each suppressed specification with as few clarifying examples as possible to obtain a correct solution. Copilot solves 134 problems (87%) with just 0.7 examples on average, requiring no examples in 78 instances. Thus, modifying traditional code-writing problems by merely trimming specification details is unlikely to thwart sophisticated LLMs such as GitHub Copilot.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {104–107},
numpages = {4},
keywords = {CS1, code writing, large language models},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@article{10.5555/3575618.3575622,
author = {Puryear, Ben and Sprint, Gina},
title = {Github copilot in the classroom: learning to code with AI assistance},
year = {2022},
issue_date = {November 2022},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {1},
issn = {1937-4771},
abstract = {Recent advances in deep machine learning have enabled artificial intelligence-driven development environments (AIDEs). AIDEs are programming tools that, given comments or starter code, can generate code solution suggestions. As the accuracy of these tools continues to increase, one particular AIDE from Github, Copilot, has been gaining significant attention for its performance and ease of use. The rise of Copilot suggests that code solution generation tools will soon be commonplace in both the industry and in computer science courses, with expert and novice programmers alike benefiting from using these tools. More specifically for novices, the effects of Copilot on the process of learning to code are mostly unknown. In this paper, we perform initial explorations into these effects. Using introductory computer science and data science courses, we evaluate Copilot-generated programming assignment solutions for correctness, style, skill level appropriateness, grade scores, and potential plagiarism. Our findings indicate Copilot generates mostly unique code that can solve introductory assignments with human-graded scores ranging from 68% to 95%. Based on these results, we provide recommendations for educators to help adapt their courses to incorporate new AIDE-based programming workflows.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {37–47},
numpages = {11}
}

@inproceedings{10.1145/3551349.3559555,
author = {Ahmed, Toufique and Devanbu, Premkumar},
title = {Few-shot training LLMs for project-specific code-summarization},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559555},
doi = {10.1145/3551349.3559555},
abstract = {Very large language models (LLMs), such as GPT-3 and Codex have achieved state-of-the-art performance on several natural-language tasks, and show great promise also for code. A particularly exciting aspect of LLMs is their knack for few-shot and zero-shot learning: they can learn to perform a task with very few examples. Few-shotting has particular synergies in software engineering, where there are a lot of phenomena (identifier names, APIs, terminology, coding patterns) that are known to be highly project-specific. However, project-specific data can be quite limited, especially early in the history of a project; thus the few-shot learning capacity of LLMs might be very relevant. In this paper, we investigate the use few-shot training with the very large GPT (Generative Pre-trained Transformer) Codex model, and find evidence suggesting that one can significantly surpass state-of-the-art models for code-summarization, leveraging project-specific training.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {177},
numpages = {5},
keywords = {code summarization, deep learning, large language model},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3587102.3588814,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588814},
doi = {10.1145/3587102.3588814},
abstract = {Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {61–67},
numpages = {7},
keywords = {GPT-3, large language models, object oriented programming, programming assignments, teaching},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3501385.3543957,
author = {Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho},
title = {Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models},
year = {2022},
isbn = {9781450391948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501385.3543957},
doi = {10.1145/3501385.3543957},
abstract = {This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1},
pages = {27–43},
numpages = {17},
keywords = {Robosourcing, Resource generation, Programming exercises, OpenAI Codex, Natural language generation, Large language models, GPT-3, Exercise generation, Code explanations, CS1, Automated feedback},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {Software Engineering Education, Oral Examinations, Examination Formats, ChatGPT},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3568812.3603476,
author = {Phung, Tung and Pădurean, Victor-Alexandru and Cambronero, José and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603476},
doi = {10.1145/3568812.3603476},
abstract = {Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {41–42},
numpages = {2},
keywords = {ChatGPT, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3587102.3588815,
author = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3585059.3611447,
author = {Sakib, Nazmus and Anik, Fahim Islam and Li, Lei},
title = {ChatGPT in IT Education Ecosystem: Unraveling Long-Term Impacts on Job Market, Student Learning, and Ethical Practices},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611447},
doi = {10.1145/3585059.3611447},
abstract = {The use of ChatGPT in the educational ecosystem has opened up new avenues for learning but also raises questions about its multifarious long-term effects. This scientific study explores how ChatGPT, an AI chatbot, may impact the career prospects of Information Technology and Computer Science graduates in the long term, focusing on job automation and displacement. This study also investigates the enduring impact of ChatGPT on students' attitudes toward learning and developing skills in this education domain while examining ethical practices for incorporating this AI-based aid. This research provides methods to deter unethical actions related to ChatGPT and encourage ethical conduct among students for optimal performance. Moreover, it divulges the impact of ChatGPT on job opportunities, positive outlook, and the pressing necessity for ethical regulations in artificial intelligence use and deployment.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {73–78},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Ethical Practices in IT Education, Job Transformation, Student Attitudes},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3615886.3627745,
author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juhász, Levente},
title = {Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615886.3627745},
doi = {10.1145/3615886.3627745},
abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {85–94},
numpages = {10},
keywords = {geospatial, foundation model, education, Large Language Models, Generative AI, GIS, ChatGPT},
location = {Hamburg, Germany},
series = {GeoAI '23}
}

@inproceedings{10.1145/3568813.3600139,
author = {Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanpää, Lilja and Sorva, Juha},
title = {Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600139},
doi = {10.1145/3568813.3600139},
abstract = {Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {93–105},
numpages = {13},
keywords = {CS1, GPT, OpenAI Codex, automatic feedback, help seeking, introductory programming education, large language models, student questions},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3583780.3615308,
author = {Makrehchi, Masoud and Zhang, Dell and Petrova, Alina and Armour, John},
title = {The 3rd International Workshop on Mining and Learning in the Legal Domain},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615308},
doi = {10.1145/3583780.3615308},
abstract = {The increasing accessibility of legal corpora and databases create opportunities to develop data-driven techniques and advanced tools that can facilitate a variety of tasks in the legal domain, such as legal search and research, legal document review and summary, legal contract drafting, and legal outcome prediction. Compared with other application domains, the legal domain is characterized by the huge scale of natural language text data, the high complexity of specialist knowledge, and the critical importance of ethical considerations. The MLLD workshop aims to bring together researchers and practitioners to share the latest research findings and innovative approaches in employing data mining, machine learning, information retrieval, and knowledge management techniques to transform the legal sector. Building upon the previous successes, the third edition of the MLLD workshop will emphasize the exploration of new research opportunities brought about by recent rapid advances in Large Language Models and Generative AI. We encourage submissions that intersect computer science and law, from both academia and industry, embodying the interdisciplinary spirit of CIKM.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5277–5280},
numpages = {4},
keywords = {legal natural language processing, legal knowledge management, legal information retrieval, legal data mining, large language models},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@proceedings{10.1145/3580305,
title = {KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining KDD 2023. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on leading edge issues of knowledge discovery, data science, and machine learning. The mission of the conference is to provide the premier forum for advancement, education, and adoption of the "science" of knowledge discovery and machine learning from all types of data; to share novel methodologies that fulfill the needs of heterogeneous applications and environments and identify new directions for future research and development. These ideas have the potential to shape and impact our society and environment, and are becoming particularly important with the emergence of AI in all fields. KDD provides researchers and practitioners a unique opportunity to share their perspectives with others interested in various aspects of data science and machine learning.KDD '23 has a program of three keynotes, 313 research track papers, 184 ADS (Applied Data Science) track papers, 34 workshops, 33 tutorials, nine special days, three panels, and eight ADS invited talks. For the first time, we switched to OpenReview with the mission to further improve the review quality and facilitate the interaction between reviewers and authors. We have introduced several new special days, such as Large Language Model (LLM) Day, Finance Day, AI for Open Society Day, Entertainment, Sports, and Media (ESM) Day, Southern California Data Science; and several new panels, such as AI for Science and LLMs for education &amp; research. The rise of LLMs has been historic and the nature of creativity itself may change. With this in mind, we have emphasized LLMs in our keynotes, special days, and panels. Only time will tell whether we went too far or not far enough!},
location = {Long Beach, CA, USA}
}

@article{10.1145/3593230,
author = {Brie, Paul and Burny, Nicolas and Sluÿters, Arthur and Vanderdonckt, Jean},
title = {Evaluating a Large Language Model on Searching for GUI Layouts},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593230},
doi = {10.1145/3593230},
abstract = {The field of generative artificial intelligence has seen significant advancements in recent years with the advent of large language models, which have shown impressive results in software engineering tasks but not yet in engineering user interfaces. Thus, we raise a specific research question: would an LLM-based system be able to search for relevant GUI layouts? To address this question, we conducted a controlled study evaluating how Instigator, an LLM-based system for searching GUI layouts of web pages by generative pre-trained training, would return GUI layouts that are relevant to a given instruction and what would be the user experience of (N =34) practitioners interacting with Instigator. Our results identify a very high similarity and a moderate correlation between the rankings of the GUI layouts generated by Instigator and the rankings of the practitioners with respect to their relevance to a given design instruction. We highlight the results obtained through thirteen UEQ+ scales that characterize the user experience of the practitioner with Instigator, which we use to discuss perspectives for improving such future tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {178},
numpages = {37},
keywords = {web pages, large language model, gui layout, gui design, generative pre-training}
}

@inproceedings{10.1145/3611643.3613093,
author = {Cabra-Acela, Laura and Mojica-Hanke, Anamaria and Linares-Vásquez, Mario and Herbold, Steffen},
title = {On Using Information Retrieval to Recommend Machine Learning Good Practices for Software Engineers},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613093},
doi = {10.1145/3611643.3613093},
abstract = {Machine learning (ML) is nowadays widely used for different purposes and with several disciplines. From self-driving cars to automated medical diagnosis, machine learning models extensively support users’ daily activities, and software engineering tasks are no exception. Not embracing good ML practices may lead to pitfalls that hinder the performance of an ML system and potentially lead to unexpected results. Despite the existence of documentation and literature about ML best practices, many non-ML experts turn towards gray literature like blogs and Q&amp;A systems when looking for help and guidance when implementing ML systems. To better aid users in distilling relevant knowledge from such sources, we propose a recommender system that recommends ML practices based on the user’s context. As a first step in creating a recommender system for machine learning practices, we implemented Idaka. A tool that provides two different approaches for retrieving/generating ML best practices: i) an information retrieval (IR) engine and ii) a large language model. The IR-engine uses BM25 as the algorithm for retrieving the practices, and a large language model, in our case Alpaca. The platform has been designed to allow comparative studies of best practices retrieval tools. Idaka is publicly available at  GitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {2142–2146},
numpages = {5},
keywords = {Good practices, Information retrieval, Large language models, Machine learning},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3587102.3588852,
author = {Balse, Rishabh and Valaboju, Bharath and Singhal, Shreya and Warriem, Jayakrishnan Madathil and Prasad, Prajish},
title = {Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588852},
doi = {10.1145/3587102.3588852},
abstract = {Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course.We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {292–298},
numpages = {7},
keywords = {GPT-3, evaluation, feedback, large language models (LLM), python programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3613944.3613946,
author = {Qureshi, Basit},
title = {ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings},
year = {2023},
isbn = {9798400700415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613944.3613946},
doi = {10.1145/3613944.3613946},
abstract = {The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.},
booktitle = {Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies},
pages = {7–13},
numpages = {7},
keywords = {Academic assessment, ChatGPT, Data Structures and Algorithms, programming concepts},
location = {Portsmouth, United Kingdom},
series = {ICSLT '23}
}

@inproceedings{10.1145/3570361.3615759,
author = {Waskito, Steven and Leow, Kai Jie and Medaranga, Pramuka and Gupta, Tejas and Chakrabarty, Shantanu and Gulati, Manoj and Varshney, Ambuj},
title = {Otter: Simplifying Embedded Sensor Data Collection and Analysis using Large Language Models},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3615759},
doi = {10.1145/3570361.3615759},
abstract = {Wireless embedded systems assist us in collecting data from the physical world, through sensor data analysis, such systems allow us to understand our environment. However, deploying wireless embedded systems and analyzing the collected data remains significantly challenging. This is due to the steep learning curve required to implement custom machine-learning models and other algorithms for data analysis. Furthermore, it is also challenging to program individual embedded devices. The diversity of the available platforms and their capabilities further compounds this problem. In response, we introduce an end-to-end system, called the Otter. It facilitates simple sensor data collection using commodity-embedded platforms. Moreover, it employs a large language model to design a natural language interface for the analysis and extraction of useful information from the sensor data. We present our preliminary work on prototyping this system, applying it to a specific use case of hand gesture detection. Otter represents one of the first systems to leverage the enhanced capabilities of large language models for simplifying wireless embedded system deployments.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {152},
numpages = {3},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1145/3545947.3573353,
author = {Brusilovsky, Peter and Ericson, Barbara J. and Horstmann, Cay S. and Servin, Christian and Vahid, Frank and Zilles, Craig},
title = {Significant Trends in CS Educational Material: Current and Future},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573353},
doi = {10.1145/3545947.3573353},
abstract = {To recognize the current and future trends and challenges in computer science education educational materials for the next decade, the authors of this work provide a conversation to voice the computer science community's experience and expertise on these trends. One of the biggest challenges for introductory computing courses in the next few years will be leveraging the new capabilities of Artificial Intelligent systems such as Open AI CodeX and GPT3 that can generate code from a textual description, explain code, and translate code between programming languages. These tools could drastically change how introductory programming is taught by allowing students to focus more on understanding code, modifying code, and testing code than on writing code. Learning content is increasingly shifting from paper textbooks to online learning systems, which include not just traditional text and figures, but increasingly use interactive items to provide students with better explanations and illustrations, extensive practice, and frequent immediate formative feedback, typically at a lower cognitive load than classical programming assignment. We will discuss challenges and opportunities for interoperability with publishing and learning management platforms. Another example is how guided-based instruments, such as peer team learning, open educational resources, or workbooks, are adaptive and hybrid according to students' needs.Feedback and point of view from the CS community will be considered as part of the curricular practices "Future of CS educational materials" document, featured in the new version of the CS2023: ACM/IEEE-CS/AAAI Computer Science Curricula.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1253},
numpages = {1},
keywords = {adaptive, animation, assessment, automation, computer science, educational materials, feedback, homework, learning, sharing, textbook, videos},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3580305.3599827,
author = {Drori, Iddo and Zhang, Sarah J. and Shuttleworth, Reece and Zhang, Sarah and Tyser, Keith and Chin, Zad and Lantigua, Pedro and Surbehera, Saisamrit and Hunter, Gregory and Austin, Derek and Tang, Leonard and Hicke, Yann and Simhon, Sage and Karnik, Sathwik and Granberry, Darnell and Udell, Madeleine},
title = {From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599827},
doi = {10.1145/3580305.3599827},
abstract = {A final exam in machine learning at a top institution such as MIT, Harvard, or Cornell typically takes faculty days to write, and students hours to solve. We demonstrate that large language models pass machine learning finals at a human level on finals available online and automatically generate new human-quality final exam questions in seconds. Previous work has developed program synthesis and few-shot learning methods to solve university-level problem set questions in mathematics and STEM courses. In this work, we develop and compare methods that solve final exams, which differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We curate a dataset and benchmark of questions from machine learning final exams available online and code for answering these questions and generating new questions. We show how to generate new questions from other questions and course notes. For reproducibility and future research on this final exam benchmark, we use automatic checkers for multiple-choice, numeric, and questions with expression answers. A student survey comparing the quality, appropriateness, and difficulty of machine-generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated questions and are suitable for final exams. We perform ablation studies comparing zero-shot learning with few-shot learning and chain-of-thought prompting using GPT-3, OPT, Codex, and ChatGPT across machine learning topics and find that few-shot learning methods perform best. We highlight the transformative potential of language models to streamline the writing and solution of large-scale assessments, significantly reducing the workload from human days to mere machine seconds. Our results suggest that rather than banning large language models such as ChatGPT in class, instructors should teach students to harness them by asking students meta-questions about correctness, completeness, and originality of the responses generated, encouraging critical thinking in academic studies.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3947–3955},
numpages = {9},
keywords = {quantitative reasoning, program synthesis, machine learning, large language models, few-shot learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3605390.3610821,
author = {Di Caro, Luigi and Rapp, Amon and Torrielli, Federico},
title = {GENERAL: GENerative, Explainable and Reasonable Artificial Learning},
year = {2023},
isbn = {9798400708060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605390.3610821},
doi = {10.1145/3605390.3610821},
abstract = {The GENERAL (GENerative, Explainable and Reasonable Artificial Learning) workshop, held at CHITALY 2023, delves into the advancements in General and Generative Artificial Intelligence (GGAI), with a focus on breakthroughs in natural language processing (NLP) and computer vision (CV). The workshop highlights the capabilities of Large Language Models (LLMs) and Latent Diffusion Models (LDMs) in generating human-like content across text and images. It emphasizes the importance of AI explainability, aiming to understand, explain, and control the complexities of these AI systems in terms of fairness, accountability, and transparency. The workshop encourages interdisciplinary collaboration across fields like HCI, psychology, social studies, and the arts to better understand AI’s societal and cultural impacts. Topics of interest include user perceptions of generative AIs, machine psychology, AI assistants, ethical issues in Generative AI, and safety and control mechanisms for large language models.},
booktitle = {Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter},
articleno = {35},
numpages = {2},
keywords = {Large Language Models, Interdisciplinary Collaboration, Generative Artificial Intelligence, Ethical Issues in AI, AI Explainability},
location = {Torino, Italy},
series = {CHItaly '23}
}

@inproceedings{10.1145/3545945.3569770,
author = {Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.},
title = {Using Large Language Models to Enhance Programming Error Messages},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569770},
doi = {10.1145/3545945.3569770},
abstract = {A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {563–569},
numpages = {7},
keywords = {ai, codex, compiler error messages, large language models, programming error messages, syntax error messages},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3568812.3603474,
author = {Singla, Adish},
title = {Evaluating ChatGPT and GPT-4 for Visual Programming},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603474},
doi = {10.1145/3568812.3603474},
abstract = {Generative AI has the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. In particular, this potential lies in the advanced capabilities of state-of-the-art deep generative and large language models such as OpenAI’s Codex&nbsp;[7], ChatGPT&nbsp;[11], and GPT-4&nbsp;[12]. In our work, we seek to investigate the capabilities of these models in visual programming domains popularly used for K-8 programming education, including domains like Scratch&nbsp;[17], Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5], and Karel&nbsp;[13]. Recent works have shown us sparks of advanced capabilities of such models for various education scenarios in introductory Python programming&nbsp;[2, 14, 18, 20]. In fact, a study in 2022 had ranked Codex in the top quartile w.r.t students in a large Python programming course&nbsp;[8]. However, all these works consider only text-based Python programming and leave open the question of how well these models would perform for visual programming. The main research question is: Do state-of-the-art neural generative models show advanced capabilities for visual programming on par with their capabilities on text-based Python programming?In our work, we evaluate these models for visual programming based on the following three settings designed to capture various generative and problem-solving capabilities: We conduct our evaluation based on 10 representative tasks from two visual programming domains: Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5] and Intro to Programming with Karel course by CodeHS.com&nbsp;[3, 13]. As illustrative examples, Figures&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3 show the output of GPT-4 in three settings for Maze18 task. We will provide the detailed analysis and prompts used in a longer version of this poster. Our preliminary results for ChatGPT (based on GPT-3.5) and GPT-4 show that these models perform poorly and produce incorrect output the majority of the time. These results highlight that state-of-the-art neural generative models like GPT-4 still struggle to combine spatial, logical, and programming skills crucial for visual programming. As the next step, it would be important to curate novel benchmarks that the research community can use to evaluate improvements in future versions of these models for visual programming.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {14–15},
numpages = {2},
keywords = {ChatGPT, block-based visual programming, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3540250.3569444,
author = {Gulwani, Sumit},
title = {AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3569444},
doi = {10.1145/3540250.3569444},
abstract = {AI can enhance programming experiences for a diverse set of programmers: from professional developers and data scientists (proficient programmers) who need help in software engineering and data wrangling, all the way to spreadsheet users (low-code programmers) who need help in authoring formulas, and students (novice programmers) who seek hints when stuck with their programming homework. To communicate their need to AI, users can express their intent explicitly—as input-output examples or natural-language specification—or implicitly—where they encounter a bug (and expect AI to suggest a fix), or simply allow AI to observe their last few lines of code or edits (to have it suggest the next steps).  

The task of synthesizing an intended program snippet from the user’s intent is both a search and a ranking problem. Search is required to discover candidate programs that correspond to the (often ambiguous) intent, and ranking is required to pick the best program from multiple plausible alternatives. This creates a fertile playground for combining symbolic-reasoning techniques, which model the semantics of programming operators, and machine-learning techniques, which can model human preferences in programming. Recent advances in large language models like Codex offer further promise to advance such neuro-symbolic techniques.  

Finally, a few critical requirements in AI-assisted programming are usability, precision, and trust; and they create opportunities for innovative user experiences and interactivity paradigms. In this talk, I will explain these concepts using some existing successes, including the Flash Fill feature in Excel, Data Connectors in PowerQuery, and IntelliCode/CoPilot in Visual Studio. I will also describe several new opportunities in AI-assisted programming, which can drive the next set of foundational neuro-symbolic advances.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1},
numpages = {1},
keywords = {Symbolic Reasoning, Program Synthesis, Machine Learning, Interactive Programming},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3586182.3615817,
author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Yuan, Xiuxiu and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Chen, Lin and Jiang, Jun and Zhou, Jingtao and Zhou, Zhongyi and Yu, Ping and Kowdle, Adarsh and Iyengar, Ram and Olwal, Alex},
title = {Experiencing Visual Blocks for ML: Visual Prototyping of AI Pipelines},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3615817},
doi = {10.1145/3586182.3615817},
abstract = {We demonstrate Visual Blocks for ML, a visual programming platform that facilitates rapid prototyping of ML-based multimedia applications. As the public version of Rapsai&nbsp;[3], we further integrated large language models and custom APIs into the platform. In this demonstration, we will showcase how to build interactive AI pipelines in a few drag-and-drops, how to perform interactive data augmentation, and how to integrate pipelines into Colabs. In addition, we demonstrate a wide range of community-contributed pipelines in Visual Blocks for ML, covering various aspects including interactive graphics, chains of large language models, computer vision, and multi-modal applications. Finally, we encourage students, designers, and ML practitioners to contribute ML pipelines through https://github.com/google/visualblocks/tree/main/pipelines to inspire creative use cases. Visual Blocks for ML is available at http://visualblocks.withgoogle.com.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {76},
numpages = {3},
keywords = {data augmentation, deep learning, deep neural networks, large language models, multi-modal models, node-graph editor, visual analytics, visual programming, visual prototyping},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@inproceedings{10.1145/3581754.3584111,
author = {Cao, Chen},
title = {Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584111},
doi = {10.1145/3581754.3584111},
abstract = {Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {229–232},
numpages = {4},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3627217.3627233,
author = {Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627233},
doi = {10.1145/3627217.3627233},
abstract = {When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {49–54},
numpages = {6},
keywords = {Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3587102.3588785,
author = {Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto},
title = {Comparing Code Explanations Created by Students and Large Language Models},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588785},
doi = {10.1145/3587102.3588785},
abstract = {Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {124–130},
numpages = {7},
keywords = {CS1, ChatGPT, GPT-3, GPT-4, code comprehension, code explanations, foundation models, large language models, natural language generation, resource generation},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3600061.3603136,
author = {Fu, Shuhao and Liao, Yong and Zhou, Pengyuan},
title = {Training ChatGPT-like Models with In-network Computation},
year = {2023},
isbn = {9798400707827},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600061.3603136},
doi = {10.1145/3600061.3603136},
abstract = {ChatGPT shows the enormous potential of large language models (LLMs). These models can easily reach the size of billions of parameters and create training difficulties for the majority. We propose a paradigm to train LLMs using distributed in-network computation on routers. Our preliminary result shows that our design allows LLMs to be trained at a reasonable learning rate without demanding extensive GPU resources.},
booktitle = {Proceedings of the 7th Asia-Pacific Workshop on Networking},
pages = {206–207},
numpages = {2},
keywords = {ChatGPT, In-network Computation, Large Language Model, Pipeline Parallelism},
location = {Hong Kong, China},
series = {APNet '23}
}

@inproceedings{10.1145/3587102.3588827,
author = {Malinka, Kamil and Peresíni, Martin and Firc, Anton and Hujnák, Ondrej and Janus, Filip},
title = {On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588827},
doi = {10.1145/3587102.3588827},
abstract = {In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {47–53},
numpages = {7},
keywords = {ChatGPT, academic education, artificial intelligence, computer security, virtual assistant},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3583131.3590481,
author = {Liventsev, Vadim and Grishina, Anastasiia and Härmä, Aki and Moonen, Leon},
title = {Fully Autonomous Programming with Large Language Models},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590481},
doi = {10.1145/3583131.3590481},
abstract = {Current approaches to program synthesis with Large Language Models (LLMs) exhibit a "near miss syndrome": they tend to generate programs that semantically resemble the correct answer (as measured by text similarity metrics or human evaluation), but achieve a low or even zero accuracy as measured by unit tests due to small imperfections, such as the wrong input or output format. This calls for an approach known as Synthesize, Execute, Debug (SED), whereby a draft of the solution is generated first, followed by a program repair phase addressing the failed tests. To effectively apply this approach to instruction-driven LLMs, one needs to determine which prompts perform best as instructions for LLMs, as well as strike a balance between repairing unsuccessful programs and replacing them with newly generated ones. We explore these trade-offs empirically, comparing replace-focused, repair-focused, and hybrid debug strategies, as well as different template-based and model-based prompt-generation techniques. We use OpenAI Codex as the LLM and Program Synthesis Benchmark 2 as a database of problem descriptions and tests for evaluation. The resulting framework outperforms both conventional usage of Codex without the repair phase and traditional genetic programming approaches.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1146–1155},
numpages = {10},
keywords = {program repair, large language models, automatic programming},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@inproceedings{10.1145/3587103.3594206,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594206},
doi = {10.1145/3587103.3594206},
abstract = {The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {561–562},
numpages = {2},
keywords = {AI, CS1, GPT, GitHub, LLM, artificial intelligence, code generation, codex, computer programming, copilot, large language models, novice programming, openAI, pedagogical practices},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3585060.3585063,
author = {Lopez, Patty},
title = {Reflections on the Design of Systems that Impact Computers and Society},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0095-2737},
url = {https://doi.org/10.1145/3585060.3585063},
doi = {10.1145/3585060.3585063},
abstract = {Having spent the past year post-retirement working with my alma mater, New Mexico State University's (NMSU) Computer Science department to broaden computing, increase student engagement, and to improve graduation completion, as well as reflecting on the state of computing in society at large, I thought I'd share some observations. In March of this year, I had the opportunity to participate in the SIGCSE 2022 Technical Symposium. I was struck by Dr. Shaundra Daily's plenary keynote, entitled "Diversifying Computing: Real Change Must Come from Within", and her use of the phrase "navigating systems that were not designed for me" as she described her exploration of STEM as a first-generation college student, as both a dance and an engineering student, and as a graduate student preparing for motherhood lacking flexibility during her pregnancy, no maternity leave, no livable stipend, and a lack of affordable childcare, as well as the coping strategies she needed to develop to deal with academic culture. In my work with NMSU this past spring, co-teaching a problem solving course, my work this fall advising CS students, and my board roles serving on the National Academy of Science, Engineering, and Medicine's Roundtable for Systemic Change in Undergraduate STEM Education co-chairing the "Culture of STEM" workgroup, on the Computing Alliance of Hispanic Serving Institution's (CAHSI) Advisory Board, and on the Computing Research Association for Widening Participation (CRA-WP), co-editing the "Expanding the Pipeline" column, it's clear that system design adversely impacts society in terms of determining not only who gets to participate in the design of computer hardware and software, but also who gets to advance in social and economic mobility. Academic institutions are complex systems in need of an overhaul, by the University of California's academic workers strike for better pay and benefits. The design and commercialization of AI without fully understanding the implications of bias and ethics is inherently a system design problem. The application to everything from AI generated art and images (and how to spot deep fakes), the ability of large language models (LLMs) to create volumes of text generated articles that appear legitimate with the capacity to spread hate and misinformation globally are but just a few examples of the potentially horrific impact to society, because humans cannot work at the pace and scale to validate and/or authenticate them, with few if any meaningful domestic and international laws or policies in place to safeguard us.},
journal = {SIGCAS Comput. Soc.},
month = feb,
pages = {9},
numpages = {1},
keywords = {system design, ethics, diversity, bias}
}

@inproceedings{10.1145/3628797.3628837,
author = {Nguyen, Duc-Vu and Nguyen, Quoc-Nam},
title = {Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education},
year = {2023},
isbn = {9798400708916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628797.3628837},
doi = {10.1145/3628797.3628837},
abstract = {In this paper, we evaluate the ability of large language models (LLMs) to perform multiple choice symbol binding (MCSB) for multiple choice question answering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus on Vietnamese, with fewer challenging MCQA datasets than in English. The two existing datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent research in Vietnamese natural language processing (NLP) has focused on the Vietnamese National High School Graduation Examination (VNHSGE) from 2019 to 2023 to evaluate ChatGPT. However, these studies have mainly focused on how ChatGPT solves the VNHSGE step by step. We aim to create a novel and high-quality dataset by providing structured guidelines for typing LaTeX formulas for mathematics, physics, chemistry, and biology. This dataset can be used to evaluate the MCSB ability of LLMs and smaller language models (LMs) because it is typed in a strict LaTeX style. We determine the most probable character answer (A, B, C, or D) based on context, instead of finding the answer step by step as in previous Vietnamese works. This reduces computational costs and accelerates the evaluation of LLMs. Our evaluation of six well-known LLMs, namely BLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the ViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising results on the MCSB ability of LLMs for Vietnamese. The dataset is available1 for research purposes only.},
booktitle = {Proceedings of the 12th International Symposium on Information and Communication Technology},
pages = {379–386},
numpages = {8},
keywords = {Analysis of Language Models, Language Modeling, Multiple Choice Question Answering, Multiple Choice Symbol Binding},
location = {Ho Chi Minh, Vietnam},
series = {SOICT '23}
}

@inproceedings{10.1145/3605468.3605471,
author = {Vo, Gia Minh and Pancratz, Nils},
title = {AI Education in German K-10 Computer Science Curricula},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3605471},
doi = {10.1145/3605468.3605471},
abstract = {The growing importance of artificial intelligence (AI) in our daily lives leads to an increasing demand for AI in learning, teaching, and education. Recent developments, such as ChatGPT, have further pushed the significance of AI, garnering media attention and prompting politicians to require stakeholders in education to place a stronger emphasis on AI education in schools. As a result, a growing number of computer science (CS) curricula are expanding to include the topic of AI. This paper aims to contribute to the understanding of AI in K-10 education in Germany by analyzing CS curricula for lower secondary school education across the 16 federal states of Germany. The results indicate that AI-related content is inconsistently addressed in the CS curricula of various federal states, with a noticeable absence of standardized AI competencies for K-10 education. In several federal states, AI-related content is only implicitly addressed from a socio-cultural perspective. To ensure up-to-date education, it is essential to include mandatory AI content in K-10 CS curricula. These contents should be considered holistically by taking into account the technological, socio-cultural, and user-oriented perspectives, in accordance with the Dagstuhl Triangle.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {15},
numpages = {4},
keywords = {K-10 education, artificial intelligence, computer science education, curriculum analysis},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3568812.3603482,
author = {Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen},
title = {Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603482},
doi = {10.1145/3568812.3603482},
abstract = {Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {22–23},
numpages = {2},
keywords = {computer science education, explanations, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3576882.3617921,
author = {Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram},
title = {Generating Programs Trivially: Student Use of Large Language Models},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617921},
doi = {10.1145/3576882.3617921},
abstract = {Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {126–132},
numpages = {7},
keywords = {formal methods, large language models, properties, testing},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3544549.3582749,
author = {Byun, Courtni and Vasicek, Piper and Seppi, Kevin},
title = {Dispensing with Humans in Human-Computer Interaction Research},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3582749},
doi = {10.1145/3544549.3582749},
abstract = {Machine Learning models have become more advanced than could have been supposed even a few years ago, often surpassing human performance on many tasks. Large language models (LLM) can produce text indistinguishable from human-produced text. This begs the question, how necessary are humans - even for tasks where humans appear indispensable? Qualitative Analysis (QA) is integral to human-computer interaction research, requiring both human-produced data and human analysis of that data to illuminate human opinions about and experiences with technology. We use GPT-3 and ChatGPT to replace human analysis and then to dispense with human-produced text altogether. We find GPT-3 is capable of automatically identifying themes and generating nuanced analyses of qualitative data arguably similar to those written by human researchers. We also briefly ponder philosophical implications of this research.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {26},
keywords = {gpt-3, prompt engineering, qualitative analysis},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3478432.3499265,
author = {Koornneef, Stacey A. and Bradbury, Jeremy S. and Miljanovic, Michael A.},
title = {Run, Llama, Run: A Collaborative Physical and Online Coding Game for Children},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499265},
doi = {10.1145/3478432.3499265},
abstract = {Computational thinking and computer science are now being introduced in K-5 classrooms and this has led to a demand for more engaging and interactive tools designed for a younger audience. Educational games and block-based programming are two approaches that have been shown to be effective at engaging children to learn computer science. While existing tools have value, they also have limitations with respect to their support for collaborative learning and with respect to equitable access. Run, Llama, Run, is a collaborative educational game designed to be played by K-5 students both with and without access to a tablet or computer. The game includes physical programming blocks where a group of students work together to find a solution for a given scenario. A digital interface is available to execute and animate student solutions and a non-digital alternative allows students to act out their solutions. This demo of Run, Llama, Run provides a chance for participants to play both versions of the game and observe the potential impact this game could have for students.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1177},
numpages = {1},
keywords = {k-5 computer science education, educational game, collaborative learning},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@inproceedings{10.1145/3580305.3599199,
author = {Gaur, Manas and Tsamoura, Efthymia and Sreedharan, Sarath and Mittal, Sudip},
title = {KiL 2023 : 3rd International Workshop on Knowledge-infused Learning},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599199},
doi = {10.1145/3580305.3599199},
abstract = {Recent prolific advances in artificial intelligence through the incorporation of domain knowledge have constituted a new paradigm for AI and data mining communities. For example, the human feedback-based language generation in ChatGPT (a large language model (LLM)), the use of Protein Bank in DeepMind's AlphaFold, and the use of 23 rules of safety in DeepMind's Sparrow have demonstrated the success of teaming human knowledge and AI. In addition, the knowledge retrieval-guided language modeling methods have strengthened the association between knowledge and AI. However, translating research methods and resources into practice presents a new challenge for the machine learning and data/knowledge mining communities. For example, in DARPA's Explainable AI seminar, the need for explainable contextual adaptation is seen as the 3rd phase of AI, facilitating the interplay between data and knowledge for explainability, safety, and, eventually, trust. However, policymakers and practitioners assert serious usability and privacy concerns that constrain adoption, notably in high-consequence domains, such as cybersecurity, healthcare, and other social good domains. In addition, limitations in output quality, measurement, and interactive ability, including both the provision of explanations and the acceptance of user preferences, result in low adoption rates in such domains. This workshop aims to accelerate our pace towards creating innovative methods for integrating knowledge into contemporary AI and data science methods and develop metrics for assessing performance in various applications.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5857–5858},
numpages = {2},
keywords = {safe ai, programming languages, neurosymbolic ai, language models, knowledge-infused learning, games, explainable ai},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3610969.3611132,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron},
title = {Generative AI in Software Development Education: Insights from a Degree Apprenticeship Programme},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3611132},
doi = {10.1145/3610969.3611132},
abstract = {We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {19},
numpages = {1},
keywords = {Software Engineering, Generative AI, Education, Apprenticeships},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3593342.3593360,
author = {Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin},
title = {Exploring ChatGPT’s impact on post-secondary education: A qualitative study},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593360},
doi = {10.1145/3593342.3593360},
abstract = {As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {6},
keywords = {post-secondary, higher education, education, conversational AI, assessment, ChatGPT, Artificial Intelligence in education},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

@inproceedings{10.1145/3587102.3588805,
author = {Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho},
title = {Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588805},
doi = {10.1145/3587102.3588805},
abstract = {The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {299–305},
numpages = {7},
keywords = {CS1, GPT-3, GitHub, ML, academic integrity, ai, artificial intelligence, chatgpt, code generation, code writing, codex, computer programming, copilot, deep learning, generative ai, introductory programming, large language models, machine learning, natural language processing, neural networks, novice programming, openAI},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3610540.3627006,
author = {Garvey, Gregory Patrick},
title = {A University Curriculum Course for Undergraduates: Artificial Intelligence and Art},
year = {2023},
isbn = {9798400703119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610540.3627006},
doi = {10.1145/3610540.3627006},
abstract = {This paper describes a new course entitled “AI &amp; Art” offered at Quinnipiac University in the spring of 2023. An updated version of this course is scheduled for Spring 2024. In this course, students use text-to-image AI generators to create artwork, write prompts using ChatGPT, and write short essays on critical issues and topics (creativity, deep fakes, copyright etc.) implicated by the rise of AI image-generation software. This course fosters essential learning outcomes such as critical thinking, creativity, and hands-on experience with AI technology preparing students for 21st-century careers.},
booktitle = {SIGGRAPH Asia 2023 Educator's Forum},
articleno = {1},
numpages = {2},
keywords = {text-to-image generation, ChatGPT, Artificial Intelligence, AI Detection, AI},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@article{10.1145/3628162,
author = {Shoufan, Abdulhadi},
title = {Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
url = {https://doi.org/10.1145/3628162},
doi = {10.1145/3628162},
abstract = {With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n=41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n=24 to 61). The results showed a wide range of effect sizes, from -2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of -0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
journal = {ACM Trans. Comput. Educ.},
month = dec,
articleno = {45},
numpages = {29},
keywords = {large language models, ChatGPT}
}

@inproceedings{10.1145/3568813.3600142,
author = {Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
title = {Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600142},
doi = {10.1145/3568813.3600142},
abstract = {This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {78–92},
numpages = {15},
keywords = {AI code generation, AlphaCode, ChatGPT, Codex, GPT, GitHub Copilot, MCQ, Multiple-choice question answering, Python course, coding exercises, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3610661.3617514,
author = {A, Rajagopal and V, Nirmala and Jebadurai, Immanuel Johnraja and Vedamanickam, Arun Muthuraj and Kumar, Prajakta Uthaya},
title = {Design of Generative Multimodal AI Agents to Enable Persons with Learning Disability},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3617514},
doi = {10.1145/3610661.3617514},
abstract = {The recent advances in Multimodal AI &amp; Generative AI open doors to the possibilities of solving key challenges for Persons with Learning Disability. To assist individuals facing difficulty in visual or auditory perception, this paper designs &amp; develops a multimodal AI agent using recent advances in the field. We aim to solve the challenge of enabling persons with Visual or Auditory Processing Disorders to learn &amp; communicate. We do this by exploring a design that allows the transformation of information across visual and language modalities. This design can be realized with the recent advances in Generative Multimodal AI. Based on each individual's needs, the AI agent dynamically adapts the Human Computer interaction model. For instance, for a child with Visual Processing Disorder (VPD), given the child's hindered ability to make sense of information taken in through the eyes, the Multimodal AI agent transforms any visual information into auditory user interaction. In another instance, for a person with Central Auditory Processing Disorder (CAPD), given the hindrance in the individual's ability to analyze information taken in through the ears, the AI dynamically translates any speech modality into visual cues. Thus the AI agent adapts dynamically to the strengths and abilities of the individual. To enable students with VPD to learn, the design allows the student to ask questions about an image. This design is realized as a Visual Question Answering task in Vision Language Transformer models. We explore interactive multimodal conversations with Few shot Learning and In-Context Instruction Tuning of Multimodal Large Language Models to address difficulty in visual reasoning. To enable persons with CAPD to learn, the design translates audio lectures into visual cues. This visual cue consists of a combination of words using speech recognition and Large Language Models based re-phrasing to simpler words, cross-modal retrieval of images to address auditory memory challenges, and AI-generated images. To identify the strengths of each child, we also explore Multimodal embedding based Multimodal latent space arithmetic to link AI across senses. To effectively integrate the proposed design into the mainstream, we explore a universal design based inclusive approach to extend the use case to create AI assistants for assisting children with different learning styles such as visual learners or auditory learners. To enable future research on the proposed design, we explore an architecture to compose a pipeline of AI models, and to connect with external systems via plugin connectors. We implement lab scale prototypes of this design and present a demo on the project webpage at https://sites.google.com/view/multimodallearningdisability.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {259–271},
numpages = {13},
keywords = {Visual Processing Disorder, Vision Language Models, Person with Disability, Multimodal latent space, Multimodal Large Language Transformers, Multimodal In-context Tuning, Multimodal Few shot Learning, Multimodal AI, Learning disability, Human Computer Interaction, Generative AI, Central Auditory Processing Disorder, Assistive Technology},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@inproceedings{10.1145/3627217.3627238,
author = {Singhal, Shreya and Kumar, Viraj},
title = {Creating Thorough Tests for AI-Generated Code is Hard},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627238},
doi = {10.1145/3627217.3627238},
abstract = {Before implementing a function, programmers are encouraged to write a suite of test cases that specify its intended behaviour on several inputs. A suite of tests is thorough if any buggy implementation fails at least one of these tests. We posit that as the proportion of code generated by Large Language Models (LLMs) grows, so must the ability of students to create test suites that are thorough enough to detect subtle bugs in such code. Our paper makes two contributions. First, we demonstrate how difficult it can be to create thorough tests for LLM-generated code by evaluating 27&nbsp;test suites from a public dataset (EvalPlus). Second, by identifying deficiencies in these test suites, we propose strategies for improving the ability of students to develop thorough test suites for LLM-generated code.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {108–111},
numpages = {4},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3587103.3594155,
author = {Wermelinger, Michel},
title = {Checking Conformance to a Subset of the Python Language},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594155},
doi = {10.1145/3587103.3594155},
abstract = {Introductory courses usually only teach a small subset of a programming language and its library, in order to focus on the general concepts rather than overwhelm students with the syntactic, semantic and API minutiae of a particular language.This paper presents courseware that checks if a program only uses the subset of the Python language and library defined by the instructor. This allows to automatically check that programming examples, exercises and assessments only use the taught constructs. It also helps detect student code with advanced constructs, possibly copied from Q&amp;A sites or generated by large language models.The tool is easy to install, configure and use. It also checks Python code in Jupyter notebooks, a popular format for interactive textbooks and assessment handouts.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {573–574},
numpages = {2},
keywords = {academic integrity, code checking, introductory programming, novice programming, programming exercises},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3610969.3610982,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {No More Pencils No More Books: Capabilities of Generative AI on Irish and UK Computer Science School Leaving Examinations},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610982},
doi = {10.1145/3610969.3610982},
abstract = {We investigate the capabilities of ChatGPT (GPT-4) on second-level (high-school) computer science examinations: the UK A-Level and Irish Leaving Certificate. Both are national, government-set / approved, and centrally assessed examinations. We also evaluate performance differences in exams made publicly available before and after the ChatGPT knowledge cutoff date, and investigate what types of question ChatGPT struggles with. We find that ChatGPT is capable of achieving very high marks on both exams and that the performance difference before and after the knowledge cutoff date are minimal. We also observe that ChatGPT struggles with questions involving symbols or images, which can be mitigated when in-text information ‘fills in the gaps’. Additionally, GPT-4 performance can be negatively impacted when an initial inaccurate answer leads to further inaccuracies in subsequent parts of the same question. Finally, the element of choice on the Leaving Certificate is a significant advantage in achieving a high grade. Notably, there are minimal occurrences of hallucinations in answers and few errors in solutions not involving images. These results reveal several strengths and weaknesses of these exams in terms of how generative AI performs on them and have implications for exam design, the construction of marking schemes, and could also shift the focus of what is examined and how.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {2},
numpages = {7},
keywords = {second-level, school, high school, examinations, UK, Leaving Certificate, LCCS, K-12, Ireland, Generative AI, GPT-4, ChatGPT, Artificial Intelligence, A-Level},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3544548.3581388,
author = {Zamfirescu-Pereira, J.D. and Wong, Richmond Y. and Hartmann, Bjoern and Yang, Qian},
title = {Why Johnny Can’t Prompt: How Non-AI Experts Try (and Fail) to Design LLM Prompts},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581388},
doi = {10.1145/3544548.3581388},
abstract = {Pre-trained large language models (“LLMs”) like GPT-3 can engage in fluent, multi-turn instruction-taking out-of-the-box, making them attractive materials for designing natural language interactions. Using natural language to steer LLM outputs (“prompting”) has emerged as an important design technique potentially accessible to non-AI-experts. Crafting effective prompts can be challenging, however, and prompt-based interactions are brittle. Here, we explore whether non-AI-experts can successfully engage in “end-user prompt engineering” using a design probe—a prototype LLM-based chatbot design tool supporting development and systematic evaluation of prompting strategies. Ultimately, our probe participants explored prompt designs opportunistically, not systematically, and struggled in ways echoing end-user programming systems and interactive machine learning systems. Expectations stemming from human-to-human instructional experiences, and a tendency to overgeneralize, were barriers to effective prompt design. These findings have implications for non-AI-expert-facing LLM-based tool design and for improving LLM-and-prompt literacy among programmers and the public, and present opportunities for further research.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {437},
numpages = {21},
keywords = {design tools, end-users, language models},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3586183.3606800,
author = {Zhang, Zheng and Gao, Jie and Dhaliwal, Ranjodh Singh and Li, Toby Jia-Jun},
title = {VISAR: A Human-AI Argumentative Writing Assistant with Visual Programming and Rapid Draft Prototyping},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606800},
doi = {10.1145/3586183.3606800},
abstract = {In argumentative writing, writers must brainstorm hierarchical writing goals, ensure the persuasiveness of their arguments, and revise and organize their plans through drafting. Recent advances in large language models (LLMs) have made interactive text generation through a chat interface (e.g., ChatGPT) possible. However, this approach often neglects implicit writing context and user intent, lacks support for user control and autonomy, and provides limited assistance for sensemaking and revising writing plans. To address these challenges, we introduce VISAR, an AI-enabled writing assistant system designed to help writers brainstorm and revise hierarchical goals within their writing context, organize argument structures through synchronized text editing and visual programming, and enhance persuasiveness with argumentation spark recommendations. VISAR allows users to explore, experiment with, and validate their writing plans using automatic draft prototyping. A controlled lab study confirmed the usability and effectiveness of VISAR in facilitating the argumentative writing planning process.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {5},
numpages = {30},
keywords = {creativity support, human-AI collaboration, writing support},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3600100.3626262,
author = {Berger, Markus and Ploennigs, Joern},
title = {ArchiGuesser – Teaching Architecture Styles using Generative AI},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3626262},
doi = {10.1145/3600100.3626262},
abstract = {Generative AIs are opening new possibilities to create content from text, speech, and images based on simple input prompts. Users use this to improve their productivity when summarizing knowledge, templating communication, and inspiring their creativity. But, can it also be used to teach, e.g. about our architectural history? With this demo we are exploring this question. We created an educational game that combines various AI technologies from large language models and image generation to computer vision, in order to serve a single purpose: Teach users about architecture in an entertaining way. We wanted to enable students to explore and learn the diversity of our architectural history in a playful and exploratory way and at the same time experience and understand what current AI technologies can achieve.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {284–285},
numpages = {2},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@inproceedings{10.1145/3604237.3626869,
author = {Li, Yinheng and Wang, Shaofei and Ding, Han and Chen, Hang},
title = {Large Language Models in Finance: A Survey},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626869},
doi = {10.1145/3604237.3626869},
abstract = {Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {374–382},
numpages = {9},
keywords = {Finance, Generative AI, Large Language Models, Natural Language Processing},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3608298.3608324,
author = {Schlör, Daniel and Pfister, Jan and Hotho, Andreas},
title = {Optimizing Medical Service Request Processes through Language Modeling and Semantic Search},
year = {2023},
isbn = {9798400700712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3608298.3608324},
doi = {10.1145/3608298.3608324},
abstract = {Medical service requests are a crucial part of the workflow in hospitals and healthcare organizations. However, the process of requesting medical services can be time consuming and can require physicians and medical personnel to navigate complex interfaces and enter detailed information about the requested service. In this paper, we propose a system that uses machine learning techniques such as large language models and semantic search to optimize the process of requesting medical services. Our approach enables physicians to request medical services using natural language rather than navigating complex interfaces, allowing for more efficient and flexible interactions with hospital information systems. We evaluate our approach on real-world data and discuss the implications of our work for the future of digital health care. Our results suggest that our approach has the potential to streamline the process of requesting medical services and reduce the time and manual effort required in the daily hospital routine.},
booktitle = {Proceedings of the 2023 7th International Conference on Medical and Health Informatics},
pages = {136–141},
numpages = {6},
keywords = {language modeling, medical service optimization, semantic search},
location = {Kyoto, Japan},
series = {ICMHI '23}
}

@inproceedings{10.1145/3501709.3544280,
author = {MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng},
title = {Generating Diverse Code Explanations using the GPT-3 Large Language Model},
year = {2022},
isbn = {9781450391955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501709.3544280},
doi = {10.1145/3501709.3544280},
abstract = {Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 2},
pages = {37–39},
numpages = {3},
keywords = {natural language processing, large language models, computer science education, code explanations},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3579027.3608972,
author = {Acher, Mathieu and Duarte, José Galindo and Jézéquel, Jean-Marc},
title = {On Programming Variability with Large Language Model-based Assistant},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608972},
doi = {10.1145/3579027.3608972},
abstract = {Programming variability is central to the design and implementation of software systems that can adapt to a variety of contexts and requirements, providing increased flexibility and customization. Managing the complexity that arises from having multiple features, variations, and possible configurations is known to be highly challenging for software developers. In this paper, we explore how large language model (LLM)-based assistants can support the programming of variability.We report on new approaches made possible with LLM-based assistants, like: features and variations can be implemented as prompts; augmentation of variability out of LLM-based domain knowledge; seamless implementation of variability in different kinds of artefacts, programming languages, and frameworks, at different binding times (compile-time or run-time). We are sharing our data (prompts, sessions, generated code, etc.) to support the assessment of the effectiveness and robustness of LLMs for variability-related tasks.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {8–14},
numpages = {7},
keywords = {variability, software product lines, programming, large language model, generative AI},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3622780.3623648,
author = {Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka},
title = {KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education},
year = {2023},
isbn = {9798400703904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622780.3623648},
doi = {10.1145/3622780.3623648},
abstract = {The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.  
In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.  

We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {50–59},
numpages = {10},
keywords = {programming education, classroom experience, LLM, ChatGPT},
location = {Cascais, Portugal},
series = {SPLASH-E 2023}
}

@inproceedings{10.1145/3580305.3599568,
author = {Poon, Hoifung and Naumann, Tristan and Zhang, Sheng and González Hernández, Javier},
title = {Precision Health in the Age of Large Language Models},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599568},
doi = {10.1145/3580305.3599568},
abstract = {Medicine today is imprecise. Among the top 20 drugs in the U.S., up to 80% of patients are non-responders. The goal of precision health is to provide the right intervention for the right people at the right time. The key to realize this dream is to develop a data-driven, learning system that can instantly incorporate new health information to optimize care delivery and accelerate biomedical discovery. In reality, however, the health ecosystem is mired in overwhelming unstructured data and excruciating manual processing. For example, in cancer, standard of care often fails, and clinical trials are the last hope. Yet less than 3% of patients could find a matching trial, whereas 40% of trial failures simply stem from insufficient recruitment. Discovery is painfully slow as a new drug may take billions of dollars and over a decade to develop.In this tutorial, we will explore how large language models (LLMs) can serve as a universal structuring tool to democratize biomedical knowledge work and usher in an intelligence revolution in precision health. We first review background for precision health and give a broad overview of the AI revolution that culminated in the development of large language models, highlighting key technical innovations and prominent trends such as consolidation of AI methods across modalities. We then give an in-depth review of biomedical LLMs and precision health applications, with a particular focus on scaling real-world evidence generation and drug discovery. To conclude, we discuss key technical challenges (e.g., bias, hallucination, cost), societal ramifications (e.g., privacy, regulation), as well as exciting research frontiers such as prompt programming, knowledge distillation, multi-modal learning, causal discovery.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5825–5826},
numpages = {2},
keywords = {precision health, machine learning, large language model, artificial intelligence},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3626111.3628183,
author = {Mani, Sathiya Kumaran and Zhou, Yajie and Hsieh, Kevin and Segarra, Santiago and Eberl, Trevor and Azulai, Eliran and Frizler, Ido and Chandra, Ranveer and Kandula, Srikanth},
title = {Enhancing Network Management Using Code Generated by Large Language Models},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628183},
doi = {10.1145/3626111.3628183},
abstract = {Analyzing network topologies and communication graphs is essential in modern network management. However, the lack of a cohesive approach results in a steep learning curve, increased errors, and inefficiencies. In this paper, we present a novel approach that enables natural-language-based network management experiences, leveraging large language models (LLMs) to generate task-specific code from natural language queries. This method addresses the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, removing the need to share network data with LLMs, and focusing on application-specific requests combined with program synthesis techniques. We develop and evaluate a prototype system using benchmark applications, demonstrating high accuracy, cost-effectiveness, and potential for further improvements using complementary program synthesis techniques.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {196–204},
numpages = {9},
keywords = {Communication graphs, Graph manipulation, Large language model, Natural language processing, Network lifecycle management, Network management, Program synthesis},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@inproceedings{10.1145/3545945.3569785,
author = {MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho},
title = {Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569785},
doi = {10.1145/3545945.3569785},
abstract = {Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations -- a line-by-line explanation, a list of important concepts, and a high-level summary of the code -- were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {931–937},
numpages = {7},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3617650.3624950,
author = {Bouvier, Dennis J. and Lovellette, Ellie and Santos, Eddie Antonio and Becker, Brett A. and Crick, Tom and Dasigi, Venu G. and Forden, Jack and Glebova, Olga and Joshi, Swaroop and Kurkovsky, Stan and Russell, Seán},
title = {Teaching Students To Use Programming Error Messages},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624950},
doi = {10.1145/3617650.3624950},
abstract = {Research shows many students struggle to use programming error and warning messages effectively. Instead of using these messages as aids to debug and fix their code, some students have negative emotional reactions to seeing 'angry red text'. Not utilizing programming error and warning messages effectively, or at all, increases the difficulty of learning to program.As compiler messages can vary by programming language and/or development environment, lessons on reading them are not typically included in mainstream educational materials. We believe this gap can be filled and that students can learn to use error messages to their advantage. Further, we believe that teaching students how to read and use error messages can have a significant impact on the learning experience for novice programmers.The goal of this working group is to develop educational materials to teach students to use programming error messages, and evaluate the use of these materials. An additional goal is to investigate the role that large language models may play in the interpretation of error messages in the educational environment. We will produce guidelines for developing educational materials and strategies informed by feedback obtained from the community and our experimentation.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {207–208},
numpages = {2},
keywords = {warning messages, runtime errors, programming error messages, novice programmers, error messages, computing education, computer error messages},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3624032.3624035,
author = {Guilherme, Vitor and Vincenzi, Auri},
title = {An initial investigation of ChatGPT unit test generation capability},
year = {2023},
isbn = {9798400716294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624032.3624035},
doi = {10.1145/3624032.3624035},
abstract = {Context: Software testing ensures software quality, but developers often disregard it. The use of automated testing generation is pursued to reduce the consequences of overlooked test cases in a software project. Problem: In the context of Java programs, several tools can completely automate generating unit test sets. Additionally, studies are conducted to offer evidence regarding the quality of the generated test sets. However, it is worth noting that these tools rely on machine learning and other AI algorithms rather than incorporating the latest advancements in Large Language Models (LLMs). Solution: This work aims to evaluate the quality of Java unit tests generated by an OpenAI LLM algorithm, using metrics like code coverage and mutation test score. Method: For this study, 33 programs used by other researchers in the field of automated test generation were selected. This approach was employed to establish a baseline for comparison purposes. For each program, 33 unit test sets were generated automatically, without human interference, by changing Open AI API parameters. After executing each test set, metrics such as code line coverage, mutation score, and success rate of test execution were collected to evaluate the efficiency and effectiveness of each set. Summary of Results: Our findings revealed that the OpenAI LLM test set demonstrated similar performance across all evaluated aspects compared to traditional automated Java test generation tools used in the previous research. These results are particularly remarkable considering the simplicity of the experiment and the fact that the generated test code did not undergo human analysis.},
booktitle = {Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {15–24},
numpages = {10},
keywords = {testing tools, software testing, mutation testing, experimental software engineering, coverage testing, automated test generation},
location = {Campo Grande, MS, Brazil},
series = {SAST '23}
}

@inproceedings{10.1145/3583780.3615047,
author = {Hoq, Muntasir and Chilla, Sushanth Reddy and Ahmadi Ranjbar, Melika and Brusilovsky, Peter and Akram, Bita},
title = {SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615047},
doi = {10.1145/3583780.3615047},
abstract = {Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {783–792},
numpages = {10},
keywords = {static analysis, program correctness prediction, program analysis, code representation, algorithm detection},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3617555.3617874,
author = {Tihanyi, Norbert and Bisztray, Tamas and Jain, Ridhi and Ferrag, Mohamed Amine and Cordeiro, Lucas C. and Mavroeidis, Vasileios},
title = {The FormAI Dataset: Generative AI in Software Security through the Lens of Formal Verification},
year = {2023},
isbn = {9798400703751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617555.3617874},
doi = {10.1145/3617555.3617874},
abstract = {This paper presents the FormAI dataset, a large collection of 112,000 AI-generated compilable and independent C programs with vulnerability classification. We introduce a dynamic zero-shot prompting technique constructed to spawn diverse programs utilizing Large Language Models (LLMs). The dataset is generated by GPT-3.5-turbo and comprises programs with varying levels of complexity. Some programs handle complicated tasks like network management, table games, or encryption, while others deal with simpler tasks like string manipulation. Every program is labeled with the vulnerabilities found within the source code, indicating the type, line number, and vulnerable function name. This is accomplished by employing a formal verification method using the Efficient SMT-based Bounded Model Checker (ESBMC), which uses model checking, abstract interpretation, constraint programming, and satisfiability modulo theories to reason over safety/security properties in programs. This approach definitively detects vulnerabilities and offers a formal model known as a counterexample, thus eliminating the possibility of generating false positive reports. We have associated the identified vulnerabilities with Common Weakness Enumeration (CWE) numbers. We make the source code available for the 112,000 programs, accompanied by a separate file containing the vulnerabilities detected in each program, making the dataset ideal for training LLMs and machine learning algorithms. Our study unveiled that according to ESBMC, 51.24% of the programs generated by GPT-3.5 contained vulnerabilities, thereby presenting considerable risks to software safety and security.},
booktitle = {Proceedings of the 19th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {33–43},
numpages = {11},
keywords = {Vulnerability Classification, Software Security, Large Language Models, Formal Verification, Dataset, Artificial Intelligence},
location = {San Francisco, CA, USA},
series = {PROMISE 2023}
}

@inproceedings{10.1145/3626705.3626706,
author = {Lingler, Alexander and Talypova, Dinara and Draxler, Fiona and Schneegass, Christina and Dingler, Tilman and Wintersberger, Philipp},
title = {MuM'23 Workshop on Interruptions and Attention Management},
year = {2023},
isbn = {9798400709210},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626705.3626706},
doi = {10.1145/3626705.3626706},
abstract = {Attention management systems seek to minimize disruption by intelligently timing interruptions and helping users navigate multiple tasks and activities. While there is a solid theoretical basis and rich history in HCI research for attention management, little progress has been made regarding their practical implementation and deployment. Building sophisticated attention management systems requires a great variety of sensors, task- and user models, and multiple devices while considering the complexity of user context and human behavior. Novel AI technologies, such as generative systems, reinforcement learning, and large language models, open new possibilities to create intelligent, practical, and user-centered attention management systems. This proposed workshop aims to bring together researchers and practitioners from diverse backgrounds to discuss and formulate a research agenda to advance attention management systems using novel AI tools to manage and mitigate interruptions from computing systems effectively.},
booktitle = {Proceedings of the 22nd International Conference on Mobile and Ubiquitous Multimedia},
pages = {548–551},
numpages = {4},
keywords = {Human-computer interaction, attention management, attentive user interfaces, cognitive load, interruptions, notifications, ubiquitous computing, workload},
location = {Vienna, Austria},
series = {MUM '23}
}

@inproceedings{10.1109/ICSE48619.2023.00110,
author = {Li, Zongjie and Wang, Chaozheng and Liu, Zhibo and Wang, Haoxuan and Chen, Dong and Wang, Shuai and Gao, Cuiyun},
title = {CCTest: Testing and Repairing Code Completion Systems},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00110},
doi = {10.1109/ICSE48619.2023.00110},
abstract = {Code completion, a highly valuable topic in the software development domain, has been increasingly promoted for use by recent advances in large language models (LLMs). To date, visible LLM-based code completion frameworks such as GitHub Copilot and GPT are trained using deep learning over vast quantities of unstructured text and open source code. As the paramount component and the cornerstone in daily programming tasks, code completion has largely boosted professionals' efficiency in building real-world software systems.In contrast to this flourishing market, we find that code completion systems often output suspicious results, and to date, an automated testing and enhancement framework for code completion systems is not available. This research proposes CCTEST, a framework to test and repair code completion systems in black-box settings. CCTest features a set of novel mutation strategies, namely program structure-consistent (PSC) mutations, to generate mutated code completion inputs. Then, it detects inconsistent outputs, representing possibly erroneous cases, from all the completed code cases. Moreover, CCTest repairs the code completion outputs by selecting the output that mostly reflects the "average" appearance of all output cases, as the final output of the code completion systems. With around 18K test inputs, we detected 33,540 inputs that can trigger erroneous cases (with a true positive rate of 86%) from eight popular LLM-based code completion systems. With repairing, we show that the accuracy of code completion systems is notably increased by 40% and 67% with respect to BLEU score and Levenshtein edit similarity.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1238–1250},
numpages = {13},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3613372.3614189,
author = {Albonico, Michel and Varela, Paulo Júnior},
title = {A Report on the Use of ChatGPT in Software Engineering and Systems Analysis Courses},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614189},
doi = {10.1145/3613372.3614189},
abstract = {ChatGPT is a natural language model that works as a virtual chat assistant. It has the potential to be used for fostering classroom discussions and addressing student needs when the professor is not accessible. Although it is still early to assess the impact of ChatGPT and similar technologies, there is a considerable discussion on social media and blogs regarding the aspirations and opportunities of utilizing ChatGPT in the software industry and education. The main perception is that ChatGPT can serve as a support tool but should not completely replace interpersonal interaction, as face-to-face dialogue remains crucial for the development of interpersonal skills and a deeper understanding of concepts. This article reports a recent classroom experience in the subjects of Software Engineering and Systems Analysis, while also analyzing ChatGPT’s responses to student inquiries.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {303–311},
numpages = {9},
keywords = {ChatGPT, Software Engineering, Student Support, System Analysis},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3573381.3596471,
author = {Stragier, Vincent and Seddati, Omar and Dutoit, Thierry},
title = {Developing an Interactive Agent for Blind and Visually Impaired People},
year = {2023},
isbn = {9798400700286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573381.3596471},
doi = {10.1145/3573381.3596471},
abstract = {The aim of this project is to create an interactive assistant that incorporates different assistive features for blind and visually impaired people. The assistant might incorporate screen readers, magnifiers, voice synthesis, OCR, GPS, face recognition, and object recognition among other tools. Recently, the work done by OpenAI and Be My Eyes with the implementation of GPT-4 is comparable to the aim of this project. It shows the development of an interactive assistant has become simpler due to recent developments in large language models. However, older methods like named entity recognition and intent classification are still valuable to build lightweight assistants. A hybrid solution combining both methods seems possible, would help to reduce the computational cost of the assistant, and would facilitate the data collection process. Despite being more complex to implement in a multilingual and multimodal context, a hybrid solution has the potential to be used offline and to consume less resources.},
booktitle = {Proceedings of the 2023 ACM International Conference on Interactive Media Experiences},
pages = {248–253},
numpages = {6},
keywords = {visually impaired, object recognition, face recognition, blind, assistive technology, accessibility, OpenAI, Open Source, OCR, GPT-4, BLOOMZ},
location = {Nantes, France},
series = {IMX '23}
}

@article{10.14778/3611479.3611527,
author = {Fernandez, Raul Castro and Elmore, Aaron J. and Franklin, Michael J. and Krishnan, Sanjay and Tan, Chenhao},
title = {How Large Language Models Will Disrupt Data Management},
year = {2023},
issue_date = {July 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611479.3611527},
doi = {10.14778/3611479.3611527},
abstract = {Large language models (LLMs), such as GPT-4, are revolutionizing software's ability to understand, process, and synthesize language. The authors of this paper believe that this advance in technology is significant enough to prompt introspection in the data management community, similar to previous technological disruptions such as the advents of the world wide web, cloud computing, and statistical machine learning. We argue that the disruptive influence that LLMs will have on data management will come from two angles. (1) A number of hard database problems, namely, entity resolution, schema matching, data discovery, and query synthesis, hit a ceiling of automation because the system does not fully understand the semantics of the underlying data. Based on large training corpora of natural language, structured data, and code, LLMs have an unprecedented ability to ground database tuples, schemas, and queries in real-world concepts. We will provide examples of how LLMs may completely change our approaches to these problems. (2) LLMs blur the line between predictive models and information retrieval systems with their ability to answer questions. We will present examples showing how large databases and information retrieval systems have complementary functionality.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {3302–3309},
numpages = {8}
}

@inproceedings{10.1145/3584371.3612956,
author = {Shi, Wenqi and Zhuang, Yuchen and Zhu, Yuanda and Iwinski, Henry and Wattenbarger, Michael and Wang, May Dongmei},
title = {Retrieval-Augmented Large Language Models for Adolescent Idiopathic Scoliosis Patients in Shared Decision-Making},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3612956},
doi = {10.1145/3584371.3612956},
abstract = {As health-related decision-making evolves, patients increasingly seek help from additional online resources such as "Dr. Google" and ChatGPT. Despite their potential, these tools encounter limitations, including the risk of potentially inaccurate information, a lack of specialized medical knowledge, the risk of generating unrealistic outputs (hallucinations), and significant computational demands. In this study, we develop and validate an innovative shared decisionmaking (SDM) tool, Chat-Orthopedist, for adolescent idiopathic scoliosis (AIS) patients and families to prepare a meaningful discussion with clinicians based on retrieval-augmented large language models. Firstly, we establish an external knowledge base with information on AIS disease and treatment options Secondly, we develop a retrieval-augmented ChatGPT to feed LLMs with AIS domain knowledge, providing accurate and comprehensible responses to patient inquiries. In addition, we perform a cyclical process of human-in-the-loop evaluations for system validation and improvement. ment. Chat-Orthopedist may optimize SDM workflow by enabling better interactive learning experiences, more effective clinical visits, and better-informed treatment decision-making.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {14},
numpages = {10},
keywords = {adolescent idiopathic scoliosis, shared decision-making, pediatric healthcare, information retrieval, large language models},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3611643.3616350,
author = {Zhang, Jiyang and Nie, Pengyu and Li, Junyi Jessy and Gligoric, Milos},
title = {Multilingual Code Co-evolution using Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616350},
doi = {10.1145/3611643.3616350},
abstract = {Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 aligned code changes from 8 pairs of open-source software projects implementing similar functionalities in two programming languages (Java and C#). Results show that Codeditor outperforms the state-of-the-art approaches by a large margin on all commonly used automatic metrics. Our work also reveals that Codeditor is complementary to the existing generation-based models, and their combination ensures even greater performance.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {695–707},
numpages = {13},
keywords = {Language model, code translation, software evolution},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3540250.3549127,
author = {Robe, Peter and Kuttal, Sandeep K. and AuBuchon, Jake and Hart, Jacob},
title = {Pair programming conversations with agents vs. developers: challenges and opportunities for SE community},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549127},
doi = {10.1145/3540250.3549127},
abstract = {Recent research has shown feasibility of an interactive pair-programming conversational agent, but implementing such an agent poses three challenges: a lack of benchmark datasets, absence of software engineering specific labels, and the need to understand developer conversations. To address these challenges, we conducted a Wizard of Oz study with 14 participants pair programming with a simulated agent and collected 4,443 developer-agent utterances. Based on this dataset, we created 26 software engineering labels using an open coding process to develop a hierarchical classification scheme. To understand labeled developer-agent conversations, we compared the accuracy of three state-of-the-art transformer-based language models, BERT, GPT-2, and XLNet, which performed interchangeably. In order to begin creating a developer-agent dataset, researchers and practitioners need to conduct resource intensive Wizard of Oz studies. Presently, there exists vast amounts of developer-developer conversations on video hosting websites. To investigate the feasibility of using developer-developer conversations, we labeled a publicly available developer-developer dataset (3,436 utterances) with our hierarchical classification scheme and found that a BERT model trained on developer-developer data performed ~10% worse than the BERT trained on developer-agent data, but when using transfer-learning, accuracy improved. Finally, our qualitative analysis revealed that developer-developer conversations are more implicit, neutral, and opinionated than developer-agent conversations. Our results have implications for software engineering researchers and practitioners developing conversational agents.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {319–331},
numpages = {13},
keywords = {Pair programming questions, Pair programming conversations, Language models, Labels, Datasets, Conversational agents, Classification},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3581784.3613215,
author = {Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun},
title = {FORGE: Pre-Training Open Foundation Models for Science},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3613215},
doi = {10.1145/3581784.3613215},
abstract = {Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {81},
numpages = {13},
location = {Denver, CO, USA},
series = {SC '23}
}

@inproceedings{10.1145/3576123.3576134,
author = {Finnie-Ansley, James and Denny, Paul and Luxton-Reilly, Andrew and Santos, Eddie Antonio and Prather, James and Becker, Brett A.},
title = {My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises},
year = {2023},
isbn = {9781450399418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576123.3576134},
doi = {10.1145/3576123.3576134},
abstract = {The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.},
booktitle = {Proceedings of the 25th Australasian Computing Education Conference},
pages = {97–104},
numpages = {8},
keywords = {AI, AlphaCode, CS1, CS2, Codex, DeepMind, GPT-3, GitHub, OpenAI, academic integrity, algorithms, artificial intelligence, code generation, copilot, data structures, deep learning, introductory programming, machine learning, neural networks, novice programming},
location = {Melbourne, VIC, Australia},
series = {ACE '23}
}

@inproceedings{10.1145/3511808.3557079,
author = {Biderman, Stella and Raff, Edward},
title = {Fooling MOSS Detection with Pretrained Language Models},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557079},
doi = {10.1145/3511808.3557079},
abstract = {As artificial intelligence (AI) technologies become increasingly powerful and prominent in society, their misuse is a growing concern. In educational settings, AI technologies could be used by students to cheat on assignments and exams. In this paper we explore whether transformers can be used to solve introductory level programming assignments while bypassing commonly used AI tools to detect similarities between pieces of software. We find that a student using GPT-J [60] can complete introductory level programming assignments without triggering suspicion from MOSS [2], a widely used software similarity and plagiarism detection tool. This holds despite the fact that GPT-J was not trained on the problems in question and is not provided with any examples to work from. We further find that the code written by GPT-J is diverse in structure, lacking any particular tells that future plagiarism detection techniques may use to try to identify algorithmically generated code. We conclude with a discussion of the ethical and educational implications of large language models and directions for future research.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {2933–2943},
numpages = {11},
keywords = {open source software, multimodal transformers, language models, education technology},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3597926.3598067,
author = {Deng, Yinlin and Xia, Chunqiu Steven and Peng, Haoran and Yang, Chenyuan and Zhang, Lingming},
title = {Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598067},
doi = {10.1145/3597926.3598067},
abstract = {Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations.  
To address these limitations, we propose TitanFuzz – the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38%/50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs.  
This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {423–435},
numpages = {13},
keywords = {Test Generation, Large Language Model, Fuzz Testing},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3544549.3585628,
author = {Petridis, Savvas and Terry, Michael and Cai, Carrie Jun},
title = {PromptInfuser: Bringing User Interface Mock-ups to Life with Large Language Models},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585628},
doi = {10.1145/3544549.3585628},
abstract = {Large Language Models have enabled novices without machine learning (ML) experience to quickly prototype ML functionalities with prompt programming. This paper investigates incorporating prompt-based prototyping into designing functional user interface (UI) mock-ups. To understand how infusing LLM prompts into UI mock-ups might affect the prototyping process, we conduct a exploratory study with five designers, and find that this capability might significantly speed up creating functional prototypes, inform designers earlier on how their designs will integrate ML, and enable user studies with functional prototypes earlier. From these findings, we built PromptInfuser, a Figma plugin for authoring LLM-infused mock-ups. PromptInfuser introduces two novel LLM-interactions: input-output, which makes content interactive and dynamic, and frame-change, which directs users to different frames depending on their natural language input. From initial observations, we find that PromptInfuser has the potential to transform the design process by tightly integrating UI and AI prototyping in a single interface.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {237},
numpages = {6},
keywords = {Design, Generative AI, Large Language Models, Prototyping},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3624062.3624128,
author = {Quan, Andres and Howell, Leah and Greenberg, Hugh},
title = {Heterogeneous Syslog Analysis: There Is Hope},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624128},
doi = {10.1145/3624062.3624128},
abstract = {Identifying system hardware failures and anomalies is a unique challenge in heterogeneous testbed clusters because of variation in the ways that the system log reports errors and warnings. We present a novel approach for the real-time classification of syslog messages generated by a heterogeneous testbed cluster to proactively identify potential hardware issues and security events. By integrating machine learning models with high-performance computing systems, our system facilitates continuous system health monitoring. The paper introduces a taxonomy for classifying system issues into actionable categories of problems, while filtering out groups of messages that the system administrators would consider unimportant "noise". Finally, we experiment with using large language models as a message classifier, and share our results and experience with doing so. Results demonstrate promising performance, and more explainable results compared to currently available techniques, but the computational costs may offset the benefits.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {581–587},
numpages = {7},
keywords = {Applications of Large-Language-Models, Cross-platform Software, Error detection, Failure detection, Heterogeneous Clusters, Log Analysis, Monitoring, Syslog, Testbeds},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.5555/3615924.3615927,
author = {Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald},
title = {Artificial Intelligence vs. Software Engineers: An Empirical Study on Performance and Efficiency using ChatGPT},
year = {2023},
publisher = {IBM Corp.},
address = {USA},
abstract = {In the realm of Software Engineering (SE), automation has become a tangible reality. Artificial Intelligence (AI) has suc-cessfully addressed challenges in project management, mod-eling, testing, and development. Among the latest innova-tions is ChatGPT, an ML-infused chatbot capable of gen-erating programming codes and software testing strategies. Although there is speculation that AI-based computation can boost productivity and even substitute software engineers in software development, empirical evidence supporting such claims is lacking. Moreover, questions remain about their po-tential to address overlooked evaluation metrics like energy efficiency, vulnerability, fairness (i.e., human bias), and safety. This paper probes into these issues with an empirical study, comparing ChatGPT with both novice and expert program-mers using LeetCode contest problems. The investigation focuses on performance and memory-efficiency, while also acknowledging the need for a broader assessment of non-functional requirements. The results suggest that ChatGPT is better than beginners at solving easy and medium prob-lems, but it is not yet proven to beat expert programmers. This paper posits that a comprehensive comparison of soft-ware engineers and AI-based solutions, considering various evaluation criteria, is pivotal in fostering human-machine collaboration, enhancing the reliability of AI-based meth-ods, and understanding task suitability for humans or AI. Furthermore, it facilitates the effective implementation of co-operative work structures and human-in-the-loop processes.},
booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
pages = {24–33},
numpages = {10},
keywords = {Software Engineering, AI-based solutions, Performance Evaluation, ChatGPT, Machine Learning},
location = {Las Vegas, NV, USA},
series = {CASCON '23}
}

@inproceedings{10.1145/3544548.3580817,
author = {Liu, Michael Xieyang and Sarkar, Advait and Negreanu, Carina and Zorn, Benjamin and Williams, Jack and Toronto, Neil and Gordon, Andrew D.},
title = {“What It Wants Me To Say”: Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580817},
doi = {10.1145/3544548.3580817},
abstract = {Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user’s natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users’ understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {598},
numpages = {31},
keywords = {Human-AI Interaction, Large Language Models, Natural Language Programming, Spreadsheets},
location = {Hamburg, Germany},
series = {CHI '23}
}

@article{10.5555/3637036.3637054,
author = {Chundur, Suguna and Hall, Kristi},
title = {Towards an AI-Aware Pedagogy in IT Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {4},
issn = {1937-4771},
abstract = {With the recent sudden explosion in the development of AI-based tools there is uncertainty among educators on its impact in teaching and learning as well as concerns about integrity of student work. Simultaneously, AI tools present a unique opportunity to personalize education and encourage self-driven learning. Hence, there is an urgent need to understand the impact of AI-based tools on teaching and learning and to find a way forward in building a framework that directly addresses the challenges raised by generative AI in three main areas: strategies for AI-aware teaching, reliability of AI-generated knowledge and design of assessments. With a view towards acquiring a clearer picture of the new AI-aware teaching landscape, we have attempted to incorporate AI-tools in the classroom. We have experimented with using various AI-tools in designing assignments that co-opt AI for teaching and learning, whether it is a written essay on an IT topic, a programming assignment in Java or troubleshooting a systems administration issue, topics that cover the breath of our Information Technology program. The assessments provide clear instructions to students on acceptable and unacceptable ways of using specific AI-tools in completing the work. There is a feedback question in each assessment that seeks students' perception of AI-tools used, its strengths and weaknesses in learning. We plan to continue the experiment for an entire academic year using this methodology in various IT courses. In this work-in-progress presentation, we will discuss the results of the assessments administered so far and provide an overview of the resulting draft AI-aware framework of teaching and learning in the IT discipline.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {106},
numpages = {1}
}

@inproceedings{10.1145/3604237.3626884,
author = {Tepelyan, Ruslan and Gopal, Achintya},
title = {Generative Machine Learning for Multivariate Equity Returns},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626884},
doi = {10.1145/3604237.3626884},
abstract = {The use of machine learning to generate synthetic data has grown in popularity with the proliferation of text-to-image models and especially large language models. The core methodology these models use is to learn the distribution of the underlying data, similar to the classical methods common in finance of fitting statistical models to data. In this work, we explore the efficacy of using modern machine learning methods, specifically conditional importance weighted autoencoders (a variant of variational autoencoders) and conditional normalizing flows, for the task of modeling the returns of equities. The main problem we work to address is modeling the joint distribution of all the members of the S&amp;P 500, or, in other words, learning a 500-dimensional joint distribution. We show that this generative model has a broad range of applications in finance, including generating realistic synthetic data, volatility and correlation estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {159–166},
numpages = {8},
keywords = {Generative Modeling, Normalizing Flows, Portfolio Optimization, Risk Forecasting, Stock Returns, Variational Autoencoders},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3578527.3578530,
author = {Jain, Ridhi and Gervasoni, Nicole and Ndhlovu, Mthandazo and Rawat, Sanjay},
title = {A Code Centric Evaluation of C/C++ Vulnerability Datasets for Deep Learning Based Vulnerability Detection Techniques},
year = {2023},
isbn = {9798400700644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578527.3578530},
doi = {10.1145/3578527.3578530},
abstract = {Recent years have witnessed tremendous progress in NLP-based code comprehension via deep neural networks (DNN) learning, especially Large Language Models (LLMs). While the original application of LLMs is focused on code generation, there have been attempts to extend the application to more specialized tasks, like code similarity, author attribution, code repairs, and so on. As data plays an important role in the success of any machine learning approach, researchers have also proposed several benchmarks which are coupled with a specific task at hand. It is well known in the machine learning (ML) community that the presence of biases in the dataset affects the quality of the ML algorithm in a real-world scenario. This paper evaluates several existing datasets from DNN’s application perspective. We specifically focus on training datasets of C/C++ language code. Our choice of language stems from the fact that while LLM-based techniques have been applied and evaluated on programming languages like Python, JavaScript, and Ruby, there is not much LLM research for C/C++. As a result, datasets generated synthetically or from real-world codes are in individual research work. Consequently, in the absence of a uniform dataset, such works are hard to compare with each other. In this work, we aim to achieve two main objectives– 1. propose code-centric features that are relevant to security program analysis tasks like vulnerability detection; 2. a thorough (qualitative and quantitative) examination of the existing code datasets that demonstrate the main characteristics of the individual datasets to have a clear comparison. Our evaluation finds exciting facts about existing datasets highlighting gaps that need to be addressed.},
booktitle = {Proceedings of the 16th Innovations in Software Engineering Conference},
articleno = {6},
numpages = {10},
keywords = {software vulnerability, software metrics, program graphs, datasets},
location = {Allahabad, India},
series = {ISEC '23}
}

@inproceedings{10.1145/3624918.3625339,
author = {Hua, Wenyue and Xu, Shuyuan and Ge, Yingqiang and Zhang, Yongfeng},
title = {How to Index Item IDs for Recommendation Foundation Models},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625339},
doi = {10.1145/3624918.3625339},
abstract = {Recommendation foundation model utilizes large language models (LLM) for recommendation by converting recommendation tasks into natural language tasks. It enables generative recommendation which directly generates the item(s) to recommend rather than calculating a ranking score for each and every candidate item as in traditional recommendation models, simplifying the recommendation pipeline from multi-stage filtering to single-stage filtering. To avoid generating excessively long text and hallucinated recommendations when deciding which item(s) to recommend, creating LLM-compatible item IDs to uniquely identify each item is essential for recommendation foundation models. In this study, we systematically examine the item ID creation and indexing problem for recommendation foundation models, using P5 as an example of the backbone LLM. To emphasize the importance of item indexing, we first discuss the issues of several trivial item indexing methods, such as random indexing, title indexing, and independent indexing. We then propose four simple yet effective solutions, including sequential indexing, collaborative indexing, semantic (content-based) indexing, and hybrid indexing. Our study highlights the significant influence of item indexing methods on the performance of LLM-based recommendation, and our results on real-world datasets validate the effectiveness of our proposed solutions. The research also demonstrates how recent advances on language modeling and traditional IR principles such as indexing can help each other for better learning and inference. Source code and data are available at https://github.com/Wenyueh/LLM-RecSys-ID.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {195–204},
numpages = {10},
keywords = {Item ID and Indexing, Large Language Model, Recommendation},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.5555/3523760.3523920,
author = {Pittman, Daniel E. and Haring, Kerstin S. and Kim, Pilyoung and Dossett, Benjamin and Ehman, Gillian and Gutierrez-Gutierrez, Elizabeth and Patil, Sneha and Sanchez, Ashley},
title = {A Novel Online Robot Design Research Platform to Determine Robot Mind Perception},
year = {2022},
publisher = {IEEE Press},
abstract = {A common issue in Human-Robot Interaction is a gap in understanding how robot designs are perceived by the user. A common issue encountered by practitioners of Machine Learning (ML) is a lack of salient data to use in training. The "Build-A-Bot" project is developing a novel research platform implemented as a web-accessible 3D game that affords data collection of many user-provided robot designs. The designs are used to train ML models to better evaluate robot designs, predict how a design will be perceived using Convolutional Neural Networks (CNNs), and create new robot designs using Generative Adversarial Networks (GANs). This paper outlines the current and future work accomplished by an interdisciplinary undergraduate student team at the University of Denver across Computer Science, Music, Psychology, and other related STEM fields that have created Build-A-Bot.},
booktitle = {Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {986–990},
numpages = {5},
keywords = {machine learning, fnirs, robot design},
location = {Sapporo, Hokkaido, Japan},
series = {HRI '22}
}

@inproceedings{10.1145/3545945.3569830,
author = {Wermelinger, Michel},
title = {Using GitHub Copilot to Solve Simple Programming Problems},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569830},
doi = {10.1145/3545945.3569830},
abstract = {The teaching and assessment of introductory programming involves writing code that solves a problem described by text. Previous research found that OpenAI's Codex, a natural language machine learning model trained on billions of lines of code, performs well on many programming problems, often generating correct and readable Python code. GitHub's version of Codex, Copilot, is freely available to students. This raises pedagogic and academic integrity concerns. Educators need to know what Copilot is capable of, in order to adapt their teaching to AI-powered programming assistants. Previous research evaluated the most performant Codex model quantitatively, e.g. how many problems have at least one correct suggestion that passes all tests. Here I evaluate Copilot instead, to see if and how it differs from Codex, and look qualitatively at the generated suggestions, to understand the limitations of Copilot. I also report on the experience of using Copilot for other activities asked of students in programming courses: explaining code, generating tests and fixing bugs. The paper concludes with a discussion of the implications of the observed capabilities for the teaching of programming.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {academic integrity, code explanation, code generation, introductory programming, novice programming, openai codex, programming exercises, programming patterns, test generation},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3539618.3591740,
author = {Zamani, Hamed and Bendersky, Michael},
title = {Multivariate Representation Learning for Information Retrieval},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591740},
doi = {10.1145/3539618.3591740},
abstract = {Dense retrieval models use bi-encoder network architectures for learning query and document representations. These representations are often in the form of a vector representation and their similarities are often computed using the dot product function. In this paper, we propose a new representation learning framework for dense retrieval. Instead of learning a vector for each query and document, our framework learns a multivariate distribution and uses negative multivariate KL divergence to compute the similarity between distributions. For simplicity and efficiency reasons, we assume that the distributions are multivariate normals and then train large language models to produce mean and variance vectors for these distributions. We provide a theoretical foundation for the proposed framework and show that it can be seamlessly integrated into the existing approximate nearest neighbor algorithms to perform retrieval efficiently. We conduct an extensive suite of experiments on a wide range of datasets, and demonstrate significant improvements compared to competitive dense retrieval models.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {163–173},
numpages = {11},
keywords = {approximate nearest neighbor search, dense retrieval, learning to rank, neural information retrieval},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3607827.3616846,
author = {Li, Boyang},
title = {Unlocking Multimedia Capabilities of Gigantic Pretrained Language Models},
year = {2023},
isbn = {9798400702839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607827.3616846},
doi = {10.1145/3607827.3616846},
abstract = {Benefitting from unprecedented computational power, massive data throughput, and superhuman memory, large language models (LLMs) are fundamentally transforming multimodal machine learning. An LLM can be analogized to an enormous treasure box guarded by a lock. It contains extensive knowledge, but it can be non-trivial to access and apply appropriate knowledge to solve the problem at hand. Researchers have developed many techniques to unlock the capabilities of LLMs. Some well-known examples include chain-of-thought prompting, "let's think step by step'', and instruction tuning. In this talk, I will discuss techniques to unlock the capability of LLMs to process both visual and linguistic information. VisualGPT is one of the earliest works that finetunes an LLM for a vision-language task. InstructBLIP is an instruction-tuned large vision-language model, which set new states of the art on several vision-language tasks and snatched top positions on several comprehensive evaluation suites. In addition, I will talk about how to unlock zero-shot capabilities without end-to-end finetuning, or any form of finetuning at all. In Plug-and-Play VQA and Img2LLM, we achieve excellent results on visual question-answering datasets by connecting existing pretrained models using natural language and model interpretations, demonstrating a feasible alternative to the mainstream finetuning approach. Finally, I will describe a new multimodal dataset, Synopses of Movie Narratives, or SyMoN, for story understanding, which constitutes a new challenge for large vision-language models. I will argue that story understanding is an important objective in the pursuit of artificial general intelligence (AGI) because stories are a preeminent form of human communication and story understanding requires many AGI capabilities such as cause-effect reasoning and theory of mind. Compared to other multimodal story datasets, the special advantages of SyMoN include (1) event descriptions at the right level of granularity, (2) abundant mental state descriptions, (3) the use of diverse storytelling techniques, and (4) the provision of easy-to-use automatic performance evaluation.},
booktitle = {Proceedings of the 1st Workshop on Large Generative Models Meet Multimodal Applications},
pages = {3–4},
numpages = {2},
keywords = {visual question-answering, multimodal story understanding, multimodal learning, large language models},
location = {Ottawa ON, Canada},
series = {LGM3A '23}
}

@inproceedings{10.1145/3624062.3624257,
author = {Zhang, Chengming and Sun, Baixi and Yu, Xiaodong and Xie, Zhen and Zheng, Weijian and Iskra, Kamil A. and Beckman, Pete and Tao, Dingwen},
title = {Benchmarking and In-depth Performance Study of Large Language Models on Habana Gaudi Processors},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624257},
doi = {10.1145/3624062.3624257},
abstract = {Transformer models have achieved remarkable success in various machine learning tasks but suffer from high computational complexity and resource requirements. The quadratic complexity of the self-attention mechanism further exacerbates these challenges when dealing with long sequences and large datasets. Specialized AI hardware accelerators, such as the Habana GAUDI architecture, offer a promising solution to tackle these issues. GAUDI features a Matrix Multiplication Engine (MME) and a cluster of fully programmable Tensor Processing Cores (TPC). This paper explores the untapped potential of using GAUDI processors to accelerate Transformer-based models, addressing key challenges in the process. Firstly, we provide a comprehensive performance comparison between the MME and TPC components, illuminating their relative strengths and weaknesses. Secondly, we explore strategies to optimize MME and TPC utilization, offering practical insights to enhance computational efficiency. Thirdly, we evaluate the performance of Transformers on GAUDI, particularly in handling long sequences and uncovering performance bottlenecks. Lastly, we evaluate the end-to-end performance of two Transformer-based large language models (LLM) on GAUDI. The contributions of this work encompass practical insights for practitioners and researchers alike. We delve into GAUDI’s capabilities for Transformers through systematic profiling, analysis, and optimization exploration. Our study bridges a research gap and offers a roadmap for optimizing Transformer-based model training on the GAUDI architecture.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1759–1766},
numpages = {8},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3485447.3512225,
author = {Sun, Zhensu and Du, Xiaoning and Song, Fu and Ni, Mingze and Li, Li},
title = {CoProtector: Protect Open-Source Code against Unauthorized Training Usage with Data Poisoning},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512225},
doi = {10.1145/3485447.3512225},
abstract = {Github Copilot, trained on billions of lines of public code, has recently become the buzzword in the computer science research and practice community. Although it is designed to help developers implement safe and effective code with powerful intelligence, practitioners and researchers raise concerns about its ethical and security problems, e.g., should the copyleft licensed code be freely leveraged or insecure code be considered for training in the first place? These problems pose a significant impact on Copilot and other similar products that aim to learn knowledge from large-scale open-source code through deep learning models, which are inevitably on the rise with the fast development of artificial intelligence. To mitigate such impacts, we argue that there is a need to invent effective mechanisms for protecting open-source code from being exploited by deep learning models. Here, we design and implement a prototype, CoProtector, which utilizes data poisoning techniques to arm source code repositories for defending against such exploits. Our large-scale experiments empirically show that CoProtector is effective in achieving its purpose, significantly reducing the performance of Copilot-like deep learning models while being able to stably reveal the secretly embedded watermark backdoors.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {652–660},
numpages = {9},
keywords = {data poisoning, dataset protection, deep learning, open-source code},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1109/ICSE48619.2023.00194,
author = {Kang, Sungmin and Yoon, Juyeon and Yoo, Shin},
title = {Large Language Models are Few-Shot Testers: Exploring LLM-Based General Bug Reproduction},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00194},
doi = {10.1109/ICSE48619.2023.00194},
abstract = {Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose LIBRO, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of LIBRO shows that, on the widely studied Defects4J benchmark, LIBRO can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate LIBRO against 31 bug reports submitted after the collection of the LLM training data terminated: LIBRO produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show LIBRO has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2312–2323},
numpages = {12},
keywords = {software engineering, natural language processing, test generation},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3624062.3624238,
author = {Dhakal, Aditya and Raith, Philipp and Ward, Logan and Hong Enriquez, Rolando P. and Rattihalli, Gourav and Chard, Kyle and Foster, Ian and Milojicic, Dejan},
title = {Fine-grained accelerator partitioning for Machine Learning and Scientific Computing in Function as a Service Platform},
year = {2023},
isbn = {9798400707858},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624062.3624238},
doi = {10.1145/3624062.3624238},
abstract = {Function-as-a-service (FaaS) is a promising execution environment for high-performance computing (HPC) and machine learning (ML) applications as it offers developers a simple way to write and deploy programs. Nowadays, GPUs and other accelerators are indispensable for HPC and ML workloads. These accelerators are expensive to acquire and operate; consequently, multiplexing them can increase their financial profitability. However, we have observed that state-of-the-art FaaS frameworks usually treat accelerator as a single device to run single workload and have little support for multiplexing accelerators. In this work, we have presented techniques to multiplex GPUs with Parsl, a popular FaaS framework. We demonstrate why GPU multiplexing is beneficial for certain applications and how we have implemented GPU multiplexing in Parsl. With our enhancements, we show up to 60% lower task completion time and 250% improvement in the inference throughput of a large language model when multiplexing a GPU compared to running a single instance without multiplexing. We plan to extend the support for GPU multiplexing in FaaS platforms by tackling the challenges of changing compute resources in the partition and approximating how to right-size a GPU partition for a function.},
booktitle = {Proceedings of the SC '23 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1606–1613},
numpages = {8},
location = {Denver, CO, USA},
series = {SC-W '23}
}

@inproceedings{10.1145/3604237.3626898,
author = {Nagy, Peer and Frey, Sascha and Sapora, Silvia and Li, Kang and Calinescu, Anisoara and Zohren, Stefan and Foerster, Jakob},
title = {Generative AI for End-to-End Limit Order Book Modelling: A Token-Level Autoregressive Generative Model of Message Flow Using a Deep State Space Network},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626898},
doi = {10.1145/3604237.3626898},
abstract = {Developing a generative model of realistic order flow in financial markets is a challenging open problem, with numerous applications for market participants. Addressing this, we propose the first end-to-end autoregressive generative model that generates tokenized limit order book (LOB) messages. These messages are interpreted by the JAX-LOB simulator, which updates the LOB state. To handle long sequences efficiently, the model employs simplified structured state-space layers to process sequences of order book states and tokenized messages. Using LOBSTER data of NASDAQ equity LOBs, we develop a custom tokenizer for message data, converting groups of successive digits to tokens, similar to tokenization in large language models. Out-of-sample results show promising performance in approximating the data distribution, as evidenced by low model perplexity. Furthermore, the mid-price returns calculated from the generated order flow exhibit a significant correlation with the data, indicating impressive conditional forecast performance. Due to the granularity of generated data, and the accuracy of the model, it offers new application areas for future work beyond forecasting, e.g. acting as a world model in high-frequency financial reinforcement learning applications. Overall, our results invite the use and extension of the model in the direction of autoregressive large financial models for the generation of high-frequency financial data. 1},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {91–99},
numpages = {9},
keywords = {ML, generative AI, limit order books, structured state space models},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3539618.3591913,
author = {Alessio, Marco and Faggioli, Guglielmo and Ferro, Nicola},
title = {DECAF: A Modular and Extensible Conversational Search Framework},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591913},
doi = {10.1145/3539618.3591913},
abstract = {The Conversational Search (CS) paradigm allows for an intuitive interaction between the user and the system through natural language sentences and it is increasingly being adopted in various scenarios. However, its widespread experimentation has led to the birth of a multitude of conversational search systems with custom implementations and variants of information retrieval models. This exacerbates the reproducibility crisis already observed in several research areas, including Information Retrieval (IR). To address this issue, we propose DECAF: a modular and extensible conversational search framework designed for fast prototyping and development of conversational agents. Our framework integrates all the components that characterize a modern conversational search system and allows for the seamless integration of Machine Learning (ML) and Large Language Models (LLMs)-based techniques. Furthermore, thanks to its uniform interface, DECAF allows for experiments characterized by a high degree of reproducibility. DECAF contains several state-of-the-art components including query rewriting, search functions under BoW and dense paradigms, and re-ranking functions. Our framework is tested on two well-known conversational collections: TREC CAsT 2019 and TREC CAsT 2020 and the results can be used by future practitioners as baselines. Our contributions include the identification of a series of state-of-the-art components for the conversational search task and the definition of a modular framework for its implementation.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3075–3085},
numpages = {11},
keywords = {conversational search, decaf, information retrieval, modular framework},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3611643.3613891,
author = {Jin, Pengxiang and Zhang, Shenglin and Ma, Minghua and Li, Haozhe and Kang, Yu and Li, Liqun and Liu, Yudong and Qiao, Bo and Zhang, Chaoyun and Zhao, Pu and He, Shilin and Sarro, Federica and Dang, Yingnong and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
title = {Assess and Summarize: Improve Outage Understanding with Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613891},
doi = {10.1145/3611643.3613891},
abstract = {Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers with in-depth domain knowledge, have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging fine-tuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1657–1668},
numpages = {12},
keywords = {Cloud Systems, Large Language Model, Outage Understanding},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3597926.3598060,
author = {Liu, Kaibo and Han, Yudong and Zhang, Jie M. and Chen, Zhenpeng and Sarro, Federica and Harman, Mark and Huang, Gang and Ma, Yun},
title = {Who Judges the Judge: An Empirical Study on Online Judge Tests},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598060},
doi = {10.1145/3597926.3598060},
abstract = {Online Judge platforms play a pivotal role in education, competitive programming, recruitment, career training, and large language model training. They rely on predefined test suites to judge the correctness of submitted solutions. It is therefore important that the solution judgement is reliable and free from potentially misleading false positives (i.e., incorrect solutions that are judged as correct). In this paper, we conduct an empirical study of 939 coding problems with 541,552 solutions, all of which are judged to be correct according to the test suites used by the platform, finding that 43.4% of the problems include false positive solutions (3,440 bugs are revealed in total). We also find that test suites are, nevertheless, of high quality according to widely-studied test effectiveness measurements: 88.2% of false positives have perfect (100%) line coverage, 78.9% have perfect branch coverage, and 32.5% have a perfect mutation score. Our findings indicate that more work is required to weed out false positive solutions and to further improve test suite effectiveness. We have released the detected false positive solutions and the generated test inputs to facilitate future research.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {334–346},
numpages = {13},
keywords = {test assessment, software testing, Online judge platform},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3583780.3615996,
author = {Bhattacharya, Indranil and Ye, Ze and Pavani, Kaushik and Dasgupta, Sunny},
title = {RT2S: A Framework for Learning with Noisy Labels},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615996},
doi = {10.1145/3583780.3615996},
abstract = {We introduce Robust Training with Trust Scores (RT2S), a framework to train machine learning classifiers with potentially noisy labels. RT2S calculates a trust score for each training sample, which indicates the quality of its corresponding label. These trust scores are employed as sample weights during training and optionally during threshold optimization. The trust scores are generated from two sources: (i) the model's confidence in the observed label, leveraging out-of-fold prediction scores to detect anomalous labels in the training data, and (ii) the probability of the correct label, ascertained by a Large Language Model with the ability to identify biased label noise. We evaluate RT2S by training machine learning models on 6 product classification datasets that utilize low-quality labels generated by a rule-based classification engine acting as a surrogate labeler. Our experimental findings indicate that RT2S outperforms all baselines, and achieves an average accuracy improvement of 4.38% (max 7.18%) over rule-based classifiers in particular.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5234–5235},
numpages = {2},
keywords = {trust scores, sample re-weighted loss, robust training, machine learning models, large language model, importance re-weighting, deep learning models, confident learning},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1109/ICSE48619.2023.00181,
author = {Mastropaolo, Antonio and Pascarella, Luca and Guglielmi, Emanuela and Ciniselli, Matteo and Scalabrino, Simone and Oliveto, Rocco and Bavota, Gabriele},
title = {On the Robustness of Code Generation Techniques: An Empirical Study on GitHub Copilot},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00181},
doi = {10.1109/ICSE48619.2023.00181},
abstract = {Software engineering research has always being concerned with the improvement of code completion approaches, which suggest the next tokens a developer will likely type while coding. The release of GitHub Copilot constitutes a big step forward, also because of its unprecedented ability to automatically generate even entire functions from their natural language description. While the usefulness of Copilot is evident, it is still unclear to what extent it is robust. Specifically, we do not know the extent to which semantic-preserving changes in the natural language description provided to the model have an effect on the generated code function. In this paper we present an empirical study in which we aim at understanding whether different but semantically equivalent natural language descriptions result in the same recommended function. A negative answer would pose questions on the robustness of deep learning (DL)-based code generators since it would imply that developers using different wordings to describe the same code would obtain different recommendations. We asked Copilot to automatically generate 892 Java methods starting from their original Javadoc description. Then, we generated different semantically equivalent descriptions for each method both manually and automatically, and we analyzed the extent to which predictions generated by Copilot changed. Our results show that modifying the description results in different code recommendations in ~46% of cases. Also, differences in the semantically equivalent descriptions might impact the correctness of the generated code (±28%).},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2149–2160},
numpages = {12},
keywords = {recommender systems, empirical study},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3491101.3503564,
author = {Jiang, Ellen and Olson, Kristen and Toh, Edwin and Molina, Alejandra and Donsbach, Aaron and Terry, Michael and Cai, Carrie J},
title = {PromptMaker: Prompt-based Prototyping with Large&nbsp;Language&nbsp;Models},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503564},
doi = {10.1145/3491101.3503564},
abstract = {Prototyping is notoriously difficult to do with machine learning (ML), but recent advances in large language models may lower the barriers to people prototyping with ML, through the use of natural language prompts. This case study reports on the real-world experiences of industry professionals (e.g. designers, program managers, front-end developers) prototyping new ML-powered feature ideas via prompt-based prototyping. Through interviews with eleven practitioners during a three-week sprint and a workshop, we find that prompt-based prototyping reduced barriers of access by substantially broadening who can prototype with ML, sped up the prototyping process, and grounded communication between collaborators. Yet, it also introduced new challenges, such as the need to reverse-engineer prompt designs, source example data, and debug and evaluate prompt effectiveness. Taken together, this case study provides important implications that lay the groundwork toward a new future of prototyping with ML.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {35},
numpages = {8},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@article{10.5555/3636988.3636996,
author = {Carter, Karla},
title = {"I, ChatBot": Co-Teaching Cybersecurity Courses With Generative AI},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {This tutorial is for computing science faculty who are intrigued by the notion that generative AI, such as OpenAI's ChatGPT or Google's Bard, can enhance the way we teach and students learn cybersecurity. Rather than questioning if faculty and students should use generative AI in the classroom, you're asking how faculty and students can use generative AI appropriately and responsibly in the classroom. Our students deserve to understand the tools shaping their future; generative AI is not going away and we need to prepare our students for a future where not knowing how to write generative AI prompts isn't an option.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3604237.3626861,
author = {Chung, Andy and Tanaka-Ishii, Kumiko},
title = {Predictability of Post-Earnings Announcement Drift with Textual and Contextual Factors of Earnings Calls},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626861},
doi = {10.1145/3604237.3626861},
abstract = {Post-Earnings Announcement Drift (PEAD), a well-known anomaly in financial markets, describes the tendency of cumulative stock returns to drift in the direction of an earnings surprise for a prolonged period following an earnings announcement. Numerous studies have used a supervised learning approach to predict PEAD, using earnings, fundamental and technical factors. However, there is a lack of study on how the context of the earnings call can be used for the PEAD prediction task. This paper uses computational linguistics techniques and large language models to examine the effectiveness of incorporating textual and contextual features from earnings calls for the PEAD prediction task. Our proposed supervised model includes four categories of features: 1) textual features, 2) contextual features, 3) earnings features, and 4) fundamental and technical features. We study the proposed model using earnings from 2010/01/01 to 2022/12/31 of all point-in-time S&amp;P500 constituents in the US stock market. Our results show that contextual features provide information unexplained by earnings, fundamental and technical features, improving the average returns per trade of a hypothetical long-short portfolio against baseline solution in out-of-sample across all four different abnormal return calculations, ranging from 53 to 354 basis points and 16.9% to 108.5% improvement from baseline model, which uses only earnings, fundamental and technical features.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {401–408},
numpages = {8},
keywords = {Post-earnings announcement drift, computational linguistics, earnings call, large language models, machine learning},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1109/ICSE48619.2023.00205,
author = {Nashid, Noor and Sintaha, Mifta and Mesbah, Ali},
title = {Retrieval-Based Prompt Selection for Code-Related Few-Shot Learning},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00205},
doi = {10.1109/ICSE48619.2023.00205},
abstract = {Large language models trained on massive code corpora can generalize to new tasks without the need for task-specific fine-tuning. In few-shot learning, these models take as input a prompt, composed of natural language instructions, a few instances of task demonstration, and a query and generate an output. However, the creation of an effective prompt for code-related tasks in few-shot learning has received little attention. We present a technique for prompt creation that automatically retrieves code demonstrations similar to the developer task, based on embedding or frequency analysis. We apply our approach, CEDAR, to two different programming languages, statically and dynamically typed, and two different tasks, namely, test assertion generation and program repair. For each task, we compare CEDAR with state-of-the-art task-specific and fine-tuned models. The empirical results show that, with only a few relevant code demonstrations, our prompt creation technique is effective in both tasks with an accuracy of 76% and 52% for exact matches in test assertion generation and program repair tasks, respectively. For assertion generation, CEDAR outperforms existing task-specific and fine-tuned models by 333% and 11%, respectively. For program repair, CEDAR yields 189% better accuracy than task-specific models and is competitive with recent fine-tuned models. These findings have practical implications for practitioners, as CEDAR could potentially be applied to multilingual and multitask settings without task or language-specific training with minimal examples and effort.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2450–2462},
numpages = {13},
keywords = {test assertion generation, program repair, few-shot learning, transformers, large language models},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3576915.3623175,
author = {He, Jingxuan and Vechev, Martin},
title = {Large Language Models for Code: Security Hardening and Adversarial Testing},
year = {2023},
isbn = {9798400700507},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576915.3623175},
doi = {10.1145/3576915.3623175},
abstract = {Large language models (large LMs) are increasingly trained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous vectors by enforcing specialized loss terms on different regions of code, using a high-quality dataset carefully curated by us. Our extensive evaluation shows that SVEN is highly effective in achieving strong security control. For instance, a state-of-the-art CodeGen LM with 2.7B parameters generates secure code for 59.1% of the time. When we employ SVEN to perform security hardening (or adversarial testing) on this LM, the ratio is significantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN closely matches the original LMs in functional correctness.},
booktitle = {Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1865–1879},
numpages = {15},
keywords = {ai safety, code generation, code security, large language models},
location = {Copenhagen, Denmark},
series = {CCS '23}
}

@article{10.5555/3636988.3636989,
author = {Conrad, Susan and Dimitoglou, George and Flinn, Michael B. and Morgan, Jacob and Gupta, Pranshu and Mengistu, Zelalem},
title = {Current Challenges in Computing Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {Discussion about topics related to current issues in computing science education focusing on three themes: "That AI thing...", "Post-Pandemic Strategies," and "Partnerships."The first theme attempts to address the benefits, challenges, and practical applications of integrating Generative AI technologies, such as ChatGPT, Bard, and CoPilot, into educational settings. Exploration of academic honesty and intellectual property and strategies for how these AI tools can be utilized in classrooms, labs, student projects, assignments, academic programs, and even preparing students for future job opportunities.The second theme revolves around post-pandemic approaches and initiatives to explore aimed at re-engaging students in both classroom activities and extracurricular pursuits. Exploration of strategies to enhance undergraduate and graduate student participation in internships, research opportunities, and the unique challenges and characteristics of job hunting in the current educational and economic landscape.The third theme highlights the significance of forging partnerships between educational institutions and industry stakeholders. Exploring campus ideas and efforts to establish and strengthen relationships with industry partners. Discussion on collaborative projects, research initiatives, mentorship programs, and ways to bridge the gap between academia and industry to benefit both students and the workforce.The final theme is open-ended, encouraging attendees to contemplate additional questions that may initiate reflection on emerging trends, pedagogical challenges, technological advancements, and any other critical issues that computing science educators should address to stay effective and responsive in their roles.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {16–17},
numpages = {2}
}

@inproceedings{10.1145/3503222.3507778,
author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
title = {Breaking the computation and communication abstraction barrier in distributed machine learning workloads},
year = {2022},
isbn = {9781450392051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503222.3507778},
doi = {10.1145/3503222.3507778},
abstract = {Recent trends towards large machine learning models require both training and inference tasks to be distributed. Considering the huge cost of training these models, it is imperative to unlock optimizations in computation and communication to obtain best performance. However, the current logical separation between computation and communication kernels in machine learning frameworks misses optimization opportunities across this barrier. Breaking this abstraction can provide many optimizations to improve the performance of distributed workloads. However, manually applying these optimizations requires modifying the underlying computation and communication libraries for each scenario, which is both time consuming and error-prone.  Therefore, we present CoCoNet, which contains (i) a domain specific language to express a distributed machine learning program in the form of computation and communication operations, (ii) a set of semantics preserving transformations to optimize the program, and (iii) a compiler to generate jointly optimized communication and computation GPU kernels. Providing both computation and communication as first class constructs allows users to work on a high-level abstraction and apply powerful optimizations, such as fusion or overlapping of communication and computation. CoCoNet enabled us to optimize data-, model- and pipeline-parallel workloads in large language models with only a few lines of code. Our experiments show that CoCoNet significantly outperforms state-of-the-art distributed machine learning implementations.},
booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {402–416},
numpages = {15},
keywords = {CUDA, Code Generation, Collective Communication, Compiler Optimizations, Distributed Machine Learning, MPI},
location = {Lausanne, Switzerland},
series = {ASPLOS '22}
}

@inproceedings{10.1145/3579371.3589350,
author = {Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young, Clifford and Zhou, Xiang and Zhou, Zongwei and Patterson, David A},
title = {TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589350},
doi = {10.1145/3579371.3589350},
abstract = {In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are &lt;5% of system cost and &lt;3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x--7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus nearly 10x faster overall, which along with OCS flexibility and availability allows a large language model to train at an average of ~60% of peak FLOPS/second. For similar sized systems, it is ~4.3x--4.5x faster than the Graphcore IPU Bow and is 1.2x--1.7x faster and uses 1.3x--1.9x less power than the Nvidia A100. TPU v4s inside the energy-optimized warehouse scale computers of Google Cloud use ~2--6x less energy and produce ~20x less CO2e than contemporary DSAs in typical on-premise data centers.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {82},
numpages = {14},
keywords = {CO2 equivalent emissions, energy, carbon emissions, warehouse scale computer, power usage effectiveness, large language model, embeddings, reconfigurable, optical interconnect, supercomputer, IPU, GPU, TPU, domain specific architecture, machine learning},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@inproceedings{10.1145/3491102.3501931,
author = {Kim, Tae Soo and Choi, DaEun and Choi, Yoonseo and Kim, Juho},
title = {Stylette: Styling the Web with Natural Language},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501931},
doi = {10.1145/3491102.3501931},
abstract = {End-users can potentially style and customize websites by editing them through in-browser developer tools. Unfortunately, end-users lack the knowledge needed to translate high-level styling goals into low-level code edits. We present Stylette, a browser extension that enables users to change the style of websites by expressing goals in natural language. By interpreting the user’s goal with a large language model and extracting suggestions from our dataset of 1.7 million web components, Stylette generates a palette of CSS properties and values that the user can apply to reach their goal. A comparative study (N=40) showed that Stylette lowered the learning curve, helping participants perform styling changes 35% faster than those using developer tools. By presenting various alternatives for a single goal, the tool helped participants familiarize themselves with CSS through experimentation. Beyond CSS, our work can be expanded to help novices quickly grasp complex software or programming languages.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {5},
numpages = {17},
keywords = {End-User Programming, Machine Learning, Natural Language Interface, Web Design},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3545945.3569823,
author = {Denny, Paul and Kumar, Viraj and Giacaman, Nasser},
title = {Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569823},
doi = {10.1145/3545945.3569823},
abstract = {GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1136–1142},
numpages = {7},
keywords = {artificial intelligence, cs1, foundation models, github copilot, introductory programming, large language models, openai},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3511861.3511863,
author = {Finnie-Ansley, James and Denny, Paul and Becker, Brett A. and Luxton-Reilly, Andrew and Prather, James},
title = {The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming},
year = {2022},
isbn = {9781450396431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511861.3511863},
doi = {10.1145/3511861.3511863},
abstract = {Recent advances in artificial intelligence have been driven by an exponential growth in digitised data. Natural language processing, in particular, has been transformed by machine learning models such as OpenAI’s GPT-3 which generates human-like text so realistic that its developers have warned of the dangers of its misuse. In recent months OpenAI released Codex, a new deep learning model trained on Python code from more than 50 million GitHub repositories. Provided with a natural language description of a programming problem as input, Codex generates solution code as output. It can also explain (in English) input code, translate code between programming languages, and more. In this work, we explore how Codex performs on typical introductory programming problems. We report its performance on real questions taken from introductory programming exams and compare it to results from students who took these same exams under normal conditions, demonstrating that Codex outscores most students. We then explore how Codex handles subtle variations in problem wording using several published variants of the well-known “Rainfall Problem” along with one unpublished variant we have used in our teaching. We find the model passes many test cases for all variants. We also explore how much variation there is in the Codex generated solutions, observing that an identical input prompt frequently leads to very different solutions in terms of algorithmic approach and code length. Finally, we discuss the implications that such technology will have for computing education as it continues to evolve, including both challenges and opportunities.},
booktitle = {Proceedings of the 24th Australasian Computing Education Conference},
pages = {10–19},
numpages = {10},
keywords = {novice programming, neural networks, machine learning, introductory programming, deep learning, copilot, code writing, code generation, artificial intelligence, academic integrity, OpenAI, GitHub, GPT-3, Codex, CS1, AI},
location = {Virtual Event, Australia},
series = {ACE '22}
}

@proceedings{10.1145/3587259,
title = {K-CAP '23: Proceedings of the 12th Knowledge Capture Conference 2023},
year = {2023},
isbn = {9798400701412},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 12th ACM International Conference on Knowledge Capture: K-CAP 2023, held in person on December 5th - 7th in Pensacola, Florida, US.Driven by the increasing demands for knowledge-based applications and the unprecedented availability of information from heterogeneous data sources, the study of knowledge capture is of crucial importance. Knowledge capture involves the extraction of useful knowledge from vast and diverse data sources as well as its acquisition directly from human experts.Nowadays knowledge is derived from an increasingly diverse set of data resources that differ with regard to their domain, format, quality, coverage, specificity, viewpoint, bias, and most importantly, consumers and producers of data. The heterogeneity, amount and complexity of data allow us to answer complex questions that could not be answered in isolation, requiring the interaction of different scientific fields and technologies. A goal of K-CAP is to develop such synergies using systematic and rigorous methodologies.The call for papers attracted 105 submissions from all over the world, covering a diverse range of topics spanning knowledge mining, large language models for information extraction, neuro-symbolic approaches for knowledge capture, knowledge engineering, question-answering, knowledge graphs, natural language processing, reasoning, entity linking, querying and knowledge-based applications. From a competitive set of high-quality submissions, we accepted 27 long research papers, 5 short papers, and 1 vision paper. The high-quality program is divided into 7 research sessions, in addition to 3 tutorials reflecting novel topics of interest in Knowledge Capture.We encourage everyone to attend the keynote talks that we have planned for K-CAP 2023. The highly anticipated talks by Dr. Robert R. Hoffman (Florida Institute for Human and Machine Cognition) and Dr. Jane Pinelis (Johns Hopkins University Applied Physics Laboratory) will guide us to a better understanding of the future of knowledge capture and explainable, resilient AI ecosystems, as they become commonplace in real world applications.},
location = {Pensacola, FL, USA}
}

@inproceedings{10.1145/3540250.3549162,
author = {Chakraborty, Saikat and Ahmed, Toufique and Ding, Yangruibo and Devanbu, Premkumar T. and Ray, Baishakhi},
title = {NatGen: generative pre-training by “naturalizing” source code},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3549162},
doi = {10.1145/3540250.3549162},
abstract = {Pre-trained Generative Language models (e.g., PLBART, CodeT5, SPT-Code) for source code yielded strong results on several tasks in the past few years, including code generation and translation. These models have adopted varying pre-training objectives to learn statistics of code construction from very large-scale corpora in a self-supervised fashion; the success of pre-trained models largely hinges on these pre-training objectives. This paper proposes a new pre-training objective, “Naturalizing” of source code, exploiting code’s bimodal, dual-channel (formal &amp; natural channels) nature. Unlike natural language, code’s bimodal, dual-channel nature allows us to generate semantically equivalent code at scale. We introduce six classes of semantic preserving transformations to introduce unnatural forms of code, and then force our model to produce more natural original programs written by developers. Learning to generate equivalent, but more natural code, at scale, over large corpora of open-source code, without explicit manual supervision, helps the model learn to both ingest &amp; generate code. We fine-tune our model in three generative Software Engineering tasks: code generation, code translation, and code refinement with limited human-curated labeled data and achieve state-of-the-art performance rivaling CodeT5. We show that our pre-trained model is especially competitive at zero-shot and few-shot learning, and better at learning code properties (e.g., syntax, data flow)},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {18–30},
numpages = {13},
keywords = {Source Code Transformer, Source Code Pre-training, Semantic Preserving Transformation, Neural Network},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3587102.3588792,
author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Song, Yifan and Sakr, Majd},
title = {Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588792},
doi = {10.1145/3587102.3588792},
abstract = {We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (&lt;70% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (&gt;55%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {117–123},
numpages = {7},
keywords = {AI code generation, GPT, GitHub copilot, alphacode, codex, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment, python course},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3597204,
author = {Liu, Xuanzhe and Gu, Diandian and Chen, Zhenpeng and Wen, Jinfeng and Zhang, Zili and Ma, Yun and Wang, Haoyu and Jin, Xin},
title = {Rise of Distributed Deep Learning Training in the Big Model Era: From a Software Engineering Perspective},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3597204},
doi = {10.1145/3597204},
abstract = {Deep learning (DL) has become a key component of modern software. In the “big model” era, the rich features of DL-based software (i.e., DL software) substantially rely on powerful DL models, e.g., BERT, GPT-3, and the recently emerging GPT-4, which are trained on the powerful cloud with large datasets. Hence, training effective DL models has become a vital stage in the whole software lifecycle. When training deep learning models, especially those big models, developers need to parallelize and distribute the computation and memory resources amongst multiple devices (e.g., a cluster of GPUs) in the training process, which is known as distributed deep learning training, or distributed training for short. However, the unique challenges that developers encounter in distributed training process have not been studied in the software engineering community. Given the increasingly heavy dependence of current DL-based software on distributed training, this paper aims to fill in the knowledge gap and presents the first comprehensive study on developers’ issues in distributed training. To this end, we focus on popular DL frameworks that support distributed training (including TensorFlow, PyTorch, Keras, and Horovod) and analyze 1,131 real-world developers’ issues about using these frameworks reported on Stack Overflow and GitHub. We construct a fine-grained taxonomy consisting of 30 categories regarding the fault symptoms and summarize common fix patterns for different symptoms. We find that: (1) many distributed-specific faults and non-distributed-specific faults inherently share the same fault symptoms, making it challenging to debug; (2) most of the fault symptoms have frequent fix patterns; (3) about half of the faults are related to system-level configurations. Based on the results, we suggest actionable implications on research avenues that can potentially facilitate the distributed training to develop DL-based software, such as focusing on the frequent and common fix patterns when designing testing or debugging tools, developing efficient testing and debugging techniques for communication configuration along with the synthesis of network configuration analysis, designing new multi-device checkpoint-and-replay techniques to help reproduction, and designing serverless APIs for cloud platforms.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {156},
numpages = {26},
keywords = {software engineering, distributed training, Empirical study}
}

@inproceedings{10.1145/3633083.3633220,
author = {Shaka, Martha and Carraro, Diego and Brown, Kenneth N.},
title = {Personalised Programming Education with Knowledge Tracing},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633220},
doi = {10.1145/3633083.3633220},
abstract = {In traditional programming education, addressing diverse student needs and providing effective and scalable learning experiences is challenging. Conventional methods struggle to adapt to varying learning styles and offer personalised feedback. AI-based Programming Tools (AIPTs) have shown promise in automating feedback, simplifying programming concepts, and guiding students. Their widespread adoption is hindered by limitations related to accuracy, explanation, and personalisation. Conversely, AIPTs tailored for expert programmers, such as ChatGPT and Copilot, have gained popularity for their productivity-enhancing capabilities, but they still fall short in terms of personalisation, neglecting individual students’ unique knowledge and skills. Our research aims to leverage AI to create AIPTs that offer personalised feedback through adaptive learning, accommodating diverse student backgrounds and proficiency levels. In particular, we explore using Knowledge Tracing (KT) to anticipate specific syntax errors in programming assignments, addressing the challenges novices face in acquiring syntactical knowledge. The findings suggest the KT’s potential to transform programming education by enabling timely interventions for students dealing with specific errors or misconceptions, automating personalised feedback, and informing tailored instructional strategies.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {47},
numpages = {1},
keywords = {Automated Feedback, Knowledge Tracing, Personalisation, Programming Assignments, Syntax Errors},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3567955.3567959,
author = {Wang, Shibo and Wei, Jinliang and Sabne, Amit and Davis, Andy and Ilbeyi, Berkin and Hechtman, Blake and Chen, Dehao and Murthy, Karthik Srinivasa and Maggioni, Marcello and Zhang, Qiao and Kumar, Sameer and Guo, Tongfei and Xu, Yuanzhong and Zhou, Zongwei},
title = {Overlap Communication with Dependent Computation via Decomposition in Large Deep Learning Models},
year = {2022},
isbn = {9781450399159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3567955.3567959},
doi = {10.1145/3567955.3567959},
abstract = {Large deep learning models have shown great potential with state-of-the-art results in many tasks. However, running these large models is quite challenging on an accelerator (GPU or TPU) because the on-device memory is too limited for the size of these models. Intra-layer model parallelism is an approach to address the issues by partitioning individual layers or operators across multiple devices in a distributed accelerator cluster. But, the data communications generated by intra-layer model parallelism can contribute to a significant proportion of the overall execution time and severely hurt the computational efficiency. As intra-layer model parallelism is critical to enable large deep learning models, this paper proposes a novel technique to effectively reduce its data communication overheads by overlapping communication with computation. With the proposed technique, an identified original communication collective is decomposed along with the dependent computation operation into a sequence of finer-grained operations. By creating more overlapping opportunities and executing the newly created, finer-grained communication and computation operations in parallel, it effectively hides the data transfer latency and achieves a better system utilization. Evaluated on TPU v4 Pods using different types of large models that have 10 billion to 1 trillion parameters, the proposed technique improves system throughput by 1.14 - 1.38x. The achieved highest peak FLOPS utilization is 72% on 1024 TPU chips with a large language model that has 500 billion parameters.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {93–106},
numpages = {14},
keywords = {Large scale machine learning, Compiler optimization, Collective communication hiding},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings{10.1145/3568813.3600138,
author = {Lau, Sam and Guo, Philip},
title = {From "Ban It Till We Understand It" to "Resistance is Futile": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600138},
doi = {10.1145/3568813.3600138},
abstract = {Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {106–121},
numpages = {16},
keywords = {AI coding tools, ChatGPT, Copilot, LLM, instructor perspectives},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3617650.3624946,
author = {Balse, Rishabh and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624946},
doi = {10.1145/3617650.3624946},
abstract = {This research proposes an AI-assisted mentoring system for programming education, leveraging the advanced capabilities of OpenAI's GPT-4. We aim to validate students' pseudocode or algorithmic approaches to Python programming problems within the context of a Tier-1 institution in India, where the high student-to-mentor ratio presents unique challenges. The proposed system aspires to alleviate the pressures of the current mentoring system, providing a more accessible, responsive, and effective educational support system.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {191},
numpages = {1},
keywords = {python programming education, large language models, automated programming mentoring, GPT-4},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@article{10.1145/3572780,
author = {Zhang, Zhijie and Li, Wenzhong and Ding, Wangxiang and Zhang, Linming and Lu, Qingning and Hu, Peng and Gui, Tong and Lu, Sanglu},
title = {STAD-GAN: Unsupervised Anomaly Detection on Multivariate Time Series with Self-training Generative Adversarial Networks},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3572780},
doi = {10.1145/3572780},
abstract = {Anomaly detection on multivariate time series (MTS) is an important research topic in data mining, which has a wide range of applications in information technology, financial management, manufacturing system, and so on. However, the state-of-the-art unsupervised deep learning models for MTS anomaly detection are vulnerable to noise and have poor performance on the training data containing anomalies. In this article, we propose a novel Self-Training based Anomaly Detection with Generative Adversarial Network (GAN) model called STAD-GAN to address the practical challenge. The STAD-GAN model consists of a generator-discriminator structure for adversarial learning and a neural network classifier for anomaly classification. The generator is learned to capture the normal data distribution, and the discriminator is learned to amplify the reconstruction error of abnormal data for better recognition. The proposed model is optimized with a self-training teacher-student framework, where a teacher model generates reliable high-quality pseudo-labels to train a student model iteratively with a refined dataset so that the performance of the anomaly classifier can be gradually improved. Extensive experiments based on six open MTS datasets show that STAD-GAN is robust to noise and achieves significant performance improvement compared to the state-of-the-art.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {71},
numpages = {18},
keywords = {unsupervised learning, self-training, generative adversarial network, anomaly detection, Multivariate time series}
}

@inproceedings{10.1145/3544548.3580919,
author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
title = {Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580919},
doi = {10.1145/3544548.3580919},
abstract = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {23},
keywords = {AI Coding Assistants, AI-Assisted Pair-Programming, ChatGPT, Copilot, GPT-3, Introductory Programming, K-12 Computer Science Education, Large Language Models, OpenAI Codex},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3593663.3593692,
author = {Jell, Lea and List, Corinna and Kipp, Michael},
title = {Towards Automated Interactive Tutoring - Focussing on Misconceptions and Adaptive Level-Specific Feedback},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593692},
doi = {10.1145/3593663.3593692},
abstract = {Programming is an essential cross-disciplinary skill, yet teaching it effectively in large classes can be challenging due to the need for close feedback loops. Identifying and addressing common misconceptions is particularly important during the initial stages of learning to program. While automated interactive tutoring systems have the potential to offer personalized tutoring at scale, current systems tend to emphasize errors and predefined solutions rather than focusing on common misconceptions. In this study, we introduce a novel platform centered on addressing misconceptions in programming education. We describe methods for detecting misconceptions using Abstract Syntax Trees (AST) and providing tailored, level-specific feedback to emulate human-like tutoring. As an empirical basis for this project, we gathered data from various introductory programming courses. Additionally, we advocate for the establishment of a repository of common misconceptions, offering examples derived from both the literature and our own data. Investigating misconceptions can ultimately enhance the teaching strategies of both human educators and AI agents, such as GPT, in guiding learners effectively.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {226–235},
numpages = {10},
keywords = {programming misconceptions, intelligent tutoring, CS in higher education},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@article{10.1145/3617367,
author = {Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio},
title = {“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3617367},
doi = {10.1145/3617367},
abstract = {Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {4},
numpages = {31},
keywords = {OpenAI, novice programming, LLM, large language models, introductory programming, HCI, GPT-3, GitHub, CS1, Copilot, Codex, automatic code generation, Artificial Intelligence, AI}
}

@inproceedings{10.1145/3508398.3511524,
author = {Qachfar, Fatima Zahra and Verma, Rakesh M. and Mukherjee, Arjun},
title = {Leveraging Synthetic Data and PU Learning For Phishing Email Detection},
year = {2022},
isbn = {9781450392204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508398.3511524},
doi = {10.1145/3508398.3511524},
abstract = {Imbalanced data classification has always been one of the most challenging problems in data science especially in the cybersecurity field, where we observe an out-of-balance proportion between benign and phishing examples in security datasets. Even though there are many phishing detection methods in literature, most of them neglect the imbalanced nature of phishing email datasets. In this paper, we examine the imbalanced property by varying legitimate to phishing class ratios. We generate new synthetic instances using a generative adversarial network model for long sentences (LeakGAN) to balance out the training process and ameliorate its impact on classification. These synthetic instances are labeled by positive-unlabeled learning and added to the initial imbalanced training set. The resulting dataset is given to the Bidirectional Encoder Representations from Transformers (BERT) model for sequence classification. We compare several state-of-the-art methods from the literature against our approach, which achieves a high performance throughout all the imbalanced ratios reaching an F1-score of 99.6% for the most extreme imbalanced ratio and an F1-score of 99.8% for balanced cases.},
booktitle = {Proceedings of the Twelfth ACM Conference on Data and Application Security and Privacy},
pages = {29–40},
numpages = {12},
keywords = {sequence classification, semi-supervised learning, positive-unlabeled learning, imbalanced data, generative adversarial network},
location = {Baltimore, MD, USA},
series = {CODASPY '22}
}

@inproceedings{10.1145/3560905.3568431,
author = {Hou, James and Xu, Susu},
title = {Near-Real-Time Seismic Human Fatality Information Retrieval from Social Media with Few-Shot Large-Language Models},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568431},
doi = {10.1145/3560905.3568431},
abstract = {Real-time disaster-induced human fatality information is critical for rapid and accurate disaster impact and loss estimation and effective emergency response. Systems like PAGER incorporate online reported death tolls and loss projection models trained on significant historical earthquake events and ground shaking data to provide projected final seismic loss estimations. However, the input reported death toll data are mainly retrieved from news platforms manually, which is time-consuming and may have a large time bias. In recent years, platforms such as Facebook and Twitter have become hot spots for witness reporting and communication during disaster events, producing large volumes of immediate fatality information without the hindrances of official channels. Though lucrative, social media data is very noisy both in syntax and accuracy, necessitating robust solutions. In this work, we design and deploy a new online system that automatically extracts near-realtime multi-lingual human fatality information including death tolls and injury tolls, from a variety of information sources immediately after an earthquake occurs. Past studies have proposed to use popular machine learning methods such as SVMs, CNNs and Logistic Regression in conjunction with word embeddings to classify the relevancy of each social media message. However, these techniques suffer from impeding requirements of annotated data, which are unavailable at the onset of natural disasters, and cannot directly extract disaster information, instead relying on statistical analysis on their classification results. To address such challenges, we propose a Large Language Model-based approach that leverages its robust language understanding and few-shot learning abilities. In combination with our novel multilingual Hierarchical Event Classifier, another contribution, we achieve effective automatic earthquake casualty information retrieval from social media, which we test by deploying our framework to two recent earthquakes.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1141–1147},
numpages = {7},
keywords = {earthquake, few-shot learning, large language models, near-realtime information retrieval, rapid disaster response},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3600211.3604754,
author = {Narayanan Venkit, Pranav},
title = {Towards a Holistic Approach: Understanding Sociodemographic Biases in NLP Models using an Interdisciplinary Lens},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604754},
doi = {10.1145/3600211.3604754},
abstract = {The rapid growth in the usage and applications of Natural Language Processing (NLP) in various sociotechnical solutions has highlighted the need for a comprehensive understanding of bias and its impact on society. While research on bias in NLP has expanded, several challenges persist that require attention. These include the limited focus on sociodemographic biases beyond race and gender, the narrow scope of analysis predominantly centered on models, and the technocentric implementation approaches. This paper addresses these challenges and advocates for a more interdisciplinary approach to understanding bias in NLP. The work is structured into three facets, each exploring a specific aspect of bias in NLP. The first facet focuses on identifying sociodemographic bias in various NLP architectures, emphasizing the importance of considering both the models themselves and human computation to comprehensively understand and identify bias. In the second facet, we delve into the significance of establishing a shared vocabulary across different fields and disciplines involved in NLP. By highlighting the potential bias stemming from a lack of shared understanding, this facet emphasizes the need for interdisciplinary collaboration to bridge the gap and foster a more inclusive and accurate analysis of bias. Finally, the third facet investigates the development of a holistic solution by integrating frameworks from social science disciplines. This approach recognizes the complexity of bias in NLP and advocates for an interdisciplinary framework that goes beyond purely technical considerations, involving social and ethical perspectives to address bias effectively. The first facet includes the following of my published works [6, 7, 8, 9] to provide results into how the importance of understanding the presence of bias in various minority group that has not been in focus in the prior works of bias in NLP. The work also shows the need to create a method that considers both human and AI indicators of bias, showcasing the importance of the first facet of my research. In my study [9], I delve into sentiment analysis and toxicity detection models to identify explicit bias against race, gender, and people with disabilities (PWDs). Through statistical exploration of conversations on social media platforms such as Twitter and Reddit, I gain insights into how disability bias permeates real-world social settings. To quantify explicit sociodemographic bias in sentiment analysis and toxicity analysis models, I create the Bias Identification Test in Sentiment (BITS) corpus1. Applying BITS, I uncover significant biases in popular AIaaS sentiment analysis tools, including TextBlob, VADER, and Google Cloud Natural Language API, as well as toxicity analysis models like Toxic-BERT. Remarkably, all of these models exhibit statistically significant explicit bias against disability, underscoring the need for comprehensive understanding and mitigation of biases affecting such groups. The work also demonstrates the utility of BITS as a model-independent method of identifying bias by focusing on social groups instead. Expanding on this, my next work [8] delves into the realm of implicit bias in NLP models. While some models may not overtly exhibit bias, they can unintentionally perpetuate harmful stereotypes [4]. To measure and identify implicit bias in commonly used embedding and large language models, I propose a methodology to measure social biases in various NLP architectures. Focusing on people with disabilities (PWD) as a group with complex social dynamics, I analyze various word embedding-based and transformer-based LLMs, revealing significant biases against PWDs in all tested models. These findings expose how models trained on extensive corpora tend to favor ableist language, underscoring the urgency of detecting and addressing implicit bias. The above two works look at both the implicit and explicit nature of bias in NLP, showcasing the need to distinguish the efforts placed in understanding them. The results also demonstrate the utility of identifying such biases as it provides context to the black-box nature of such public models. As the field of NLP evolved from embedding-based models to large language models, the way these models are constructed underwent significant changes [5]. However, the concern arises from the fact that these models often reflect a populist viewpoint [1] that perpetuates majority-held ideas rather than objective truths. This difference in perception can lead to biases perpetuated by the majority’s worldview. To explore this aspect, I investigate how LLMs represent nationality and their impact on societal stereotypes [6]. By examining LLM-generated stories for various nationalities, I establish a correlation between sentiment and the population of internet users in a country. The study reveals the unintentional implicit and explicit nationality biases exhibited by GPT-2, with nations having lower internet representation and economic status generating negative sentiment stories and employing a greater number of negative adjectives. Additionally, I explore potential debiasing methods such as adversarial triggering and prompt engineering, demonstrating their efficacy in mitigating stereotype propagation through LLM models. While prior work predominantly relies on automatic indicators like sentiment scores or vector distances to identify bias [3], the next phase of my research emphasizes the importance of understanding biases through the lens of human readers [7], bringing to light the need for a human lens in understanding bias through human-aided indicators and mixed-method identification. By incorporating concepts of social computation, using human evaluation, we gain a better understanding of biases’ potential societal impact within the context of language models. To achieve this, I conduct open-ended interviews and employ qualitative coding and thematic analysis to comprehend the implications of biases on human readers. The findings demonstrate that biased NLP models tend to replicate and amplify existing societal biases, posing potential harm when utilized in sociotechnical settings. The qualitative analysis from the interviews provides valuable insights into readers’ experiences when encountering biased articles, highlighting the capacity to shift a reader’s perception of a country. These findings emphasize the critical role of public perception in shaping AI’s impact on society and the need to correct biases in AI systems. The second facet of my research aims to bridge the disparity between AI research and society. This disparity has resulted in a lack of shared understanding between these domains, leading to potential biases and harm toward specific groups. Employing an interdisciplinary approach that combines social informatics, philosophy, and AI, I will investigate the similarities and disparities in the concepts utilized by machine learning models. Existing research [2] highlights the insufficient interdisciplinary effort and motivation in comprehending social aspects of NLP. To commence this exploration, I will delve into the shared taxonomy of sentiment and fairness in natural language processing, sociology, and humanities. This research will first delve into the interdisciplinary nature of sentiment and its application in sentiment analysis models. Sentiment analysis, a popular machine learning application for text classification based on sentiment, opinion, and subjectivity, holds significant influence as a sociotechnical system that impacts both social and technical actors within a network. Nevertheless, the definition and connotation of sentiment vary vastly across different research fields, potentially leading to misconceptions regarding the utility of such systems. To address this issue, this study will examine how diverse fields, including psychology, sociology, and technology, define the concept of sentiment. By unraveling the divergent perspectives on sentiment within different fields, the paper will uncover discrepancies and varying applications of this interdisciplinary concept. Additionally, the research will survey commonly utilized sentiment analysis models, aiming to comprehend their standardized definitions and associated issues. Ultimately, the study will pose critical questions that should be considered during the development of social models to mitigate potential biases and harm stemming from an insufficiently defined comprehension of fundamental social concepts. Similar efforts will be dedicated to comprehending the disparity in bias and fairness as an interdisciplinary concept, shedding light on the imperative for inclusive research to cultivate superior AI models as sociotechnical solutions. The third facet of my study embarks upon an exploration of the intricate interplay between human and AI actors, employing the formidable theoretical lens of actor-network theory (ANT). Through the presentation of a robust framework, this facet aims to engender the formation of efficacious development networks that foster collaboration among developers, practitioners, and other essential stakeholders. Such inclusive networks serve as crucibles for the cultivation of holistic solutions that transcend the discriminatory trappings afflicting specific populations. A tangible outcome of this endeavor entails the creation of an all-encompassing bias analysis platform, poised to guide the discernment and amelioration of an array of sociodemographic biases manifesting within any machine-learning system. By catalyzing the development of socially aware and less pernicious technology, this research makes a substantial contribution to the realms of NLP and AI. The significance of this proposed research reverberates beyond the confines of NLP, resonating throughout the broader domain of AI, wherein analogous challenges about social biases loom large. Leveraging the proposed framework, developers, practitioners, and policymakers are empowered to forge practical solutions that embody inclusivity and reliability, especially when used as a service (AIaaS). Moreover, the platform serves as a centralized locus for the identification and rectification of social biases, irrespective of the underlying model or architecture. By furnishing a cogent narrative that underscores the imperative for a comprehensive and interdisciplinary approach, my work strives to propel the ongoing endeavors to comprehend and mitigate biases within the realm of NLP. With its potential to augment the equity, inclusivity, and societal ramifications of NLP technologies, the proposed framework catapults the field towards responsible and ethical practices.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1004–1005},
numpages = {2},
location = {Montréal, QC, Canada},
series = {AIES '23}
}

@article{10.5555/3636988.3637001,
author = {Tu, Junyi},
title = {How to Integrate ChatGPT into the CS1/CS2 Sequence},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {ChatGPT is one of most revolutionary technologies and fiercely debated on the benefit and disaster of its effect on human society. How to guide students to use this new technology is an inevitably topic as CS educators. This nifty idea includes ways to integrate ChatGPT into the CS1/CS2 sequence, how to guide students to use ChatGPT in a constructive way, instead of cheating on their homework.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {34},
numpages = {1}
}

@inproceedings{10.1145/3532512.3539664,
author = {Lewis, Clayton},
title = {Automatic Programming and Education},
year = {2022},
isbn = {9781450396561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532512.3539664},
doi = {10.1145/3532512.3539664},
abstract = {Automatic programming, as supported by recent language-model based AI systems, potentially allows a new approach to making computation a useful tool for learning, a goal of the Boxer project. This paper shows that the Codex system can be used to support some of the explorations in mathematics for which Boxer has been used. Virtually no knowledge of programming is required. Reflecting on the lessons from this exploration may sharpen the goals we bring to educational computing. What knowledge about computing, as distinct from the ability to creatively use computing, should learners gain?},
booktitle = {Companion Proceedings of the 6th International Conference on the Art, Science, and Engineering of Programming},
pages = {70–80},
numpages = {11},
keywords = {Boxer, automatic programming, computational literacy, education},
location = {Porto, Portugal},
series = {Programming '22}
}

@inproceedings{10.1145/3587102.3588794,
author = {Ouh, Eng Lieh and Gan, Benjamin Kok Siew and Jin Shim, Kyong and Wlodkowski, Swavek},
title = {ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course.},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588794},
doi = {10.1145/3587102.3588794},
abstract = {In this study, we assess the efficacy of employing the ChatGPT language model to generate solutions for coding exercises within an undergraduate Java programming course. ChatGPT, a large-scale, deep learning-driven natural language processing model, is capable of producing programming code based on textual input. Our evaluation involves analyzing ChatGPT-generated solutions for 80 diverse programming exercises and comparing them to the correct solutions. Our findings indicate that ChatGPT accurately generates Java programming solutions, which are characterized by high readability and well-structured organization. Additionally, the model can produce alternative, memory-efficient solutions. However, as a natural language processing model, ChatGPT struggles with coding exercises containing non-textual descriptions or class files, leading to invalid solutions. In conclusion, ChatGPT holds potential as a valuable tool for students seeking to overcome programming challenges and explore alternative approaches to solving coding problems. By understanding its limitations, educators can design coding exercises that minimize the potential for misuse as a cheating aid while maintaining their validity as assessment tools.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {54–60},
numpages = {7},
keywords = {Java, computer science education, object-oriented, programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3583780.3615317,
author = {Shah, Chirag},
title = {Generative AI and the Future of Information Access},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615317},
doi = {10.1145/3583780.3615317},
abstract = {The prominent model of retrieving, evaluating, and using relevant information from databases, collections, and the web is going through a significant transformation. This is largely due to wide-scale availability of various generative AI systems that can take in natural language inputs and generate highly customized natural language text, images, audio, and videos. This transformation in how people seek and access information will have profound impacts on users, developers, and policymakers. It is already changing many sectors including education, health, and commerce. But the hopes and hypes of generative AI are often not clear as we get swept up by either the current capabilities and limitations of this technology in the short term or fear from speculative future in the long term. Instead, I believe we need to approach this area pragmatically and with scientific curiosity, scholarly rigor, and societal responsibility. In this talk, I will highlight some of the opportunities and challenges for information access stemming from recent advancements in generative AI. For instance, there are new possibilities now for addressing accessibility, low-resource domains, and bias in training data using generative AI tools. On the other hand, there are new challenges concerning hallucination, toxicity, and information provenance. It is clear that we want to benefit from what AI systems are capable of, but how do we do that while curbing some of these problems? I will argue that the solution is multifaceted and complex -- some will require technical advancements and others will call for policy changes. We will need to not only build information systems with fairness, transparency, and accountability in mind, but also train a new generation of developers, policymakers, and of course the users. The goal here is to cut through both hype and fear and think pragmatically about the future of information access.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3},
numpages = {1},
keywords = {information access, generative AI},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3596671.3598574,
author = {Goel, Toshali and Shaer, Orit and Delcourt, Catherine and Gu, Quan and Cooper, Angel},
title = {Preparing Future Designers for Human-AI Collaboration in Persona Creation},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596671.3598574},
doi = {10.1145/3596671.3598574},
abstract = {This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.},
booktitle = {Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {4},
numpages = {14},
keywords = {personas, novice designers, natural-language generation, large language models, human-AI collaboration, education},
location = {Oldenburg, Germany},
series = {CHIWORK '23}
}

@inproceedings{10.1145/3605468.3609775,
author = {Philbin, Carrie Anne},
title = {Impact of Generative AI on K-12 Students’ Perceptions of Computing: A Research Proposal},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3609775},
doi = {10.1145/3605468.3609775},
abstract = {The rapid progress of generative artificial intelligence (AI) is fundamentally reshaping traditional perspectives on knowledge and skills, with profound implications for computing education. This necessitates a thorough examination of the relevance and timeliness of computing as a subject, especially for K-12 students who are making critical decisions about their future qualifications. This abstract proposes an empirical research study that aims to explore the effects of integrating generative AI in the creation of digital artefacts on K-12 students’ perceptions of the value of computing, as well as their understanding of ownership and achievement. Constructive discussions regarding the outlined approach are encouraged.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {28},
numpages = {2},
keywords = {Artificial Intelligence education, Creative computing, Generative AI, K-12 education, Student perceptions},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3587102.3588773,
author = {Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James},
title = {Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588773},
doi = {10.1145/3587102.3588773},
abstract = {Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {3–4},
numpages = {2},
keywords = {ai, artificial intelligence, chatgpt, computer programming, computer science education, computing education, copilot, deep learning, generative ai, large language models, llm, machine learning},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3635439.3635442,
author = {El-Deeb, Ahmed},
title = {Behind OpenAI CEO Dismissal: An Ethical Dilemma And ANew AI Revolution},
year = {2023},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0163-5948},
url = {https://doi.org/10.1145/3635439.3635442},
doi = {10.1145/3635439.3635442},
abstract = {The world of Artificial Intelligence and Silicon Valley have been rocked in Nov. 2023 by the sudden ouster of OpenAI CEO, Sam Altman, by the company's board. OpenAI is the 2015 start-up behind ChatGPT and GPT-4, which enabled generating content and media-altered by AI. While nothing much was revealed by the board, the official statement mentioned that he wasn't transparent about his communication to the board about the developments of the company, which led the board to lose trust in him and deciding to fire him. Backed up by 700 OpenAI staffers who threatened to resign in solidarity with their fired leader and a supportive offer from Microsoft CEO Satya hiring Altman to lead significant AI Research Lab in Microsoft, Altman was back again as CEO in 5 days along with a revamped new board. While this dramatic story that entertained the software industry for a week could be seen as mere news, it is indeed more than that; and the significance of this story is not Sam Altman himself as an AI business figure. The back story of this fiasco and what happened behind the scene is what interest us as a Software professionals. The purpose of this article is bring some pointers for our learning.},
journal = {SIGSOFT Softw. Eng. Notes},
month = dec,
pages = {11–12},
numpages = {2}
}

@inproceedings{10.1145/3490100.3516473,
author = {Suh, Sangho and An, Pengcheng},
title = {Leveraging Generative Conversational AI to Develop a Creative Learning Environment for Computational Thinking},
year = {2022},
isbn = {9781450391450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490100.3516473},
doi = {10.1145/3490100.3516473},
abstract = {We explore how generative conversational AI can assist students’ learning, creative, and sensemaking process in a visual programming environment where users can create comics from code. The process of visualizing code in terms of comics involves mapping programming language (code) to natural language (story) and then to visual language (of comics). While this process requires users to brainstorm code examples, metaphors, and story ideas, the recent development in generative models introduces an exciting opportunity for learners to harness their creative superpower and researchers to advance our understanding of how generative conversational AI can augment our intelligence in creative learning contexts. We provide an overview of our system and discuss interaction scenarios to demonstrate ways we can partner with generative conversational AI in the context of learning computer programming.},
booktitle = {Companion Proceedings of the 27th International Conference on Intelligent User Interfaces},
pages = {73–76},
numpages = {4},
keywords = {coding strip, comics, generative conversational AI, visual programming environment},
location = {Helsinki, Finland},
series = {IUI '22 Companion}
}

@inproceedings{10.1145/3573051.3596191,
author = {Smolansky, Adele and Cram, Andrew and Raduescu, Corina and Zeivots, Sandris and Huber, Elaine and Kizilcec, Rene F.},
title = {Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3596191},
doi = {10.1145/3573051.3596191},
abstract = {The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {378–382},
numpages = {5},
keywords = {ChatGPT, assessment, educators, generative AI, students, survey},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3576882.3617916,
author = {Agarwal, Nimisha and Kumar, Viraj and Raman, Arun and Karkare, Amey},
title = {A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617916},
doi = {10.1145/3576882.3617916},
abstract = {In an introductory programming (CS1) context, a Refute question asks students for a counter-example which proves that a given code fragment is an incorrect solution for a given task. Such a question can be used as an assessment item to (formatively) develop or (summatively) demonstrate a student's abilities to comprehend the task and the code well enough to recognize a mismatch. These abilities assume greater significance with the emergence of generative AI technologies capable of writing code that is plausible (at least to novice programmers) but not always correct.Instructors must address three concerns while designing an effective Refute question, each influenced by their specific teaching-learning context: (1) Is the task comprehensible? (2) Is the incorrect code a plausible solution for the task? (3) Is the complexity of finding a counter-example acceptable? While the first concern can often be addressed by reusing tasks from previous code writing questions, addressing the latter concerns may require substantial instructor effort. We therefore investigate whether concerns (2) and (3) can be addressed by buggy student solutions for the corresponding code writing question from a previous course offering. For 6 code writing questions (from a Fall 2015 C programming course), our automated evaluation system logged 13,847 snapshots of executable student code, of which 10,574 were buggy (i.e., they failed at least one instructor-supplied test case). Code selected randomly from this pool rarely addresses these concerns, and manual selection is infeasible. Our paper makes three contributions. First, we propose an automated mechanism to filter this pool to a more manageable number of snapshots from which appropriate code can be selected manually. Second, we evaluate our semi-automated mechanism with respect to concerns (2) and (3) by surveying a diverse set of 56 experienced participants (instructors, tutors, and teaching assistants). Third, we use this mechanism to seed a public repository of Refute questions and provide a template to create additional questions using a public resource (CodeCheck).},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {7–14},
numpages = {8},
keywords = {CS1, assessment, refute questions},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3551349.3559548,
author = {Khan, Junaed Younus and Uddin, Gias},
title = {Automatic Code Documentation Generation Using GPT-3},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559548},
doi = {10.1145/3551349.3559548},
abstract = {Source code documentation is an important artifact for efficient software development. Code documentation could greatly benefit from automation since manual documentation is often labouring, resource and time-intensive. In this paper, we employed Codex for automatic code documentation creation. Codex is a GPT-3 based model pre-trained on both natural and programming languages. We find that Codex outperforms existing techniques even with basic settings like one-shot learning (i.e., providing only one example for training). Codex achieves an overall BLEU score of 20.6 for six different programming languages (11.2% improvement over earlier state-of-the-art techniques). Thus, Codex shows promise and warrants in-depth future studies for automatic code documentation generation to support diverse development tasks.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {174},
numpages = {6},
keywords = {GPT-3, Machine Learning., code documentation},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3580305.3599573,
author = {Muhamed, Aashiq and Bock, Christian and Solanki, Rahul and Park, Youngsuk and Wang, Yida and Huan, Jun},
title = {Training Large-scale Foundation Models on Emerging AI Chips},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599573},
doi = {10.1145/3580305.3599573},
abstract = {Foundation models such as ChatGPT and GPT-4 have garnered significant interest from both academia and industry due to their emergent capabilities, such as few-shot prompting, multi-step reasoning, instruction following, and model calibration. Such capabilities were previously only attainable with specially designed models, such as those using knowledge graphs, but can now be achieved on a much larger scale with foundation models. As the capabilities of foundation models have increased, so too have their sizes at a rate much faster than Moore's law. For example, the BERT large model was initially released as a 334M model in 2018, and by 2023, the largest GPT-4 models are estimated to range between 200-300B, representing an increase of three orders of magnitude in just five years. The training of foundation models requires massive computing power. For instance, training a BERT model on a single state-of-the-art GPU machine with multi-A100 chips can take several days, while training GPT-3 models on a large multi-instance GPU cluster can take several months to complete the estimated 3 X 1023 flops.This tutorial provides an overview of the latest progress in supporting foundation model training and inference with new AI chips. It reviews progress on the modeling side, with an emphasis on the transformer architecture, and presents the system architecture supporting training and serving foundation models. This includes programming language frameworks such as PyTorch and Tensorflow, graph compilers, 3D parallelisms, and accelerators such as the GPU H100, TPU, and Trainium. Finally, the tutorial presents our experience of training foundation models using different systems.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5821–5822},
numpages = {2},
keywords = {trainium, tpu, gpu, foundation models, ai accelerator},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3512290.3528700,
author = {Sobania, Dominik and Briesch, Martin and Rothlauf, Franz},
title = {Choose your programming copilot: a comparison of the program synthesis performance of github copilot and genetic programming},
year = {2022},
isbn = {9781450392372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512290.3528700},
doi = {10.1145/3512290.3528700},
abstract = {GitHub Copilot, an extension for the Visual Studio Code development environment powered by the large-scale language model Codex, makes automatic program synthesis available for software developers. This model has been extensively studied in the field of deep learning, however, a comparison to genetic programming, which is also known for its performance in automatic program synthesis, has not yet been carried out. In this paper, we evaluate GitHub Copilot on standard program synthesis benchmark problems and compare the achieved results with those from the genetic programming literature. In addition, we discuss the performance of both approaches. We find that the performance of the two approaches on the benchmark problems is quite similar, however, in comparison to GitHub Copilot, the program synthesis approaches based on genetic programming are not yet mature enough to support programmers in practical software development. Genetic programming usually needs a huge amount of expensive hand-labeled training cases and takes too much time to generate solutions. Furthermore, source code generated by genetic programming approaches is often bloated and difficult to understand. For future work on program synthesis with genetic programming, we suggest researchers to focus on improving the execution time, readability, and usability.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1019–1027},
numpages = {9},
keywords = {GitHub copilot, codex, genetic programming, large-scale language models, program synthesis, software engineering},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@article{10.1613/jair.1.13550,
author = {Javed, Rana Tallal and Nasir, Osama and Borit, Melania and Vanhée, Loïs and Zea, Elias and Gupta, Shivam and Vinuesa, Ricardo and Qadir, Junaid},
title = {Get out of the BAG! Silos in AI Ethics Education: Unsupervised Topic Modeling Analysis of Global AI Curricula},
year = {2022},
issue_date = {May 2022},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {73},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.13550},
doi = {10.1613/jair.1.13550},
abstract = {The domain of Artificial Intelligence (AI) ethics is not new, with discussions going back at least 40 years. Teaching the principles and requirements of ethical AI to students is considered an essential part of this domain, with an increasing number of technical AI courses taught at several higher-education institutions around the globe including content related to ethics. By using Latent Dirichlet Allocation (LDA), a generative probabilistic topic model, this study uncovers topics in teaching ethics in AI courses and their trends related to where the courses are taught, by whom, and at what level of cognitive complexity and specificity according to Bloom’s taxonomy. In this exploratory study based on unsupervised machine learning, we analyzed a total of 166 courses: 116 from North American universities, 11 from Asia, 36 from Europe, and 10 from other regions. Based on this analysis, we were able to synthesize a model of teaching approaches, which we call BAG (Build, Assess, and Govern), that combines specific cognitive levels, course content topics, and disciplines affiliated with the department(s) in charge of the course. We critically assess the implications of this teaching paradigm and provide suggestions about how to move away from these practices. We challenge teaching practitioners and program coordinators to reflect on their usual procedures so that they may expand their methodology beyond the confines of stereotypical thought and traditional biases regarding what disciplines should teach and how.
This article appears in the AI &amp; Society track.},
journal = {J. Artif. Int. Res.},
month = may,
numpages = {33},
keywords = {discourse modelling, data mining, scientific discovery, philosophical foundations}
}

@inproceedings{10.1145/3597926.3598135,
author = {Wu, Yi and Jiang, Nan and Pham, Hung Viet and Lutellier, Thibaud and Davis, Jordan and Tan, Lin and Babkin, Petr and Shah, Sameena},
title = {How Effective Are Neural Networks for Fixing Security Vulnerabilities},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598135},
doi = {10.1145/3597926.3598135},
abstract = {Security vulnerability repair is a difficult task that is in dire need of automation. Two groups of techniques have shown promise: (1) large code language models (LLMs) that have been pre-trained on source code for tasks such as code completion, and (2) automated program repair (APR) techniques that use deep learning (DL) models to automatically fix software bugs. This paper is the first to study and compare Java vulnerability repair capabilities of LLMs and DL-based APR models. The contributions include that we (1) apply and evaluate five LLMs (Codex, CodeGen, CodeT5, PLBART and InCoder), four fine-tuned LLMs, and four DL-based APR techniques on two real-world Java vulnerability benchmarks (Vul4J and VJBench), (2) design code transformations to address the training and test data overlapping threat to Codex, (3) create a new Java vulnerability repair benchmark VJBench, and its transformed version VJBench-trans, to better evaluate LLMs and APR techniques, and (4) evaluate LLMs and APR techniques on the transformed vulnerabilities in VJBench-trans. Our findings include that (1) existing LLMs and APR models fix very few Java vulnerabilities. Codex fixes 10.2 (20.4%), the most number of vulnerabilities. Many of the generated patches are uncompilable patches. (2) Fine-tuning with general APR data improves LLMs’ vulnerability-fixing capabilities. (3) Our new VJBench reveals that LLMs and APR models fail to fix many Common Weakness Enumeration (CWE) types, such as CWE-325 Missing cryptographic step and CWE-444 HTTP request smuggling. (4) Codex still fixes 8.7 transformed vulnerabilities, outperforming all the other LLMs and APR models on transformed vulnerabilities. The results call for innovations to enhance automated Java vulnerability repair such as creating larger vulnerability repair training data, tuning LLMs with such data, and applying code simplification transformation to facilitate vulnerability repair.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1282–1294},
numpages = {13},
keywords = {Vulnerability, Language Model, Automated Program Repair, AI and Software Engineering},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3587399.3587462,
author = {Piccolo, Lara and Buzzo, Daniel and Knobel, Martin and Gunasekera, Prasanna and Papathoma, Tina},
title = {Interaction Design as Project-Based Learning: Perspectives for Unsolved Challenges},
year = {2023},
isbn = {9798400707377},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587399.3587462},
doi = {10.1145/3587399.3587462},
abstract = {Project-based learning (PBL) is an educational approach that actively involves students in tackling real-world complex problems in an interdisciplinary way, emphasising critical thinking, collaboration and problem-solving skills. In this paper, we share our empirical experience of teaching three different modules of an Interaction Design program: Screen Design, Generative Design and Experience and Behaviour Design within the context of Project-Based Learning. We report on what we consider successful cases, as well as significant barriers encountered by the students. We then discuss some of the unsolved challenges, providing our perspectives for teaching interaction design with PBL.},
booktitle = {Proceedings of the 5th Annual Symposium on HCI Education},
pages = {59–67},
numpages = {9},
keywords = {HCI Education, Interaction design, Project-based learning},
location = {Hamburg, Germany},
series = {EduCHI '23}
}

@article{10.1145/3605889,
author = {Mujahid, Muhammad and Kanwal, Khadija and Rustam, Furqan and Aljedaani, Wajdi and Ashraf, Imran},
title = {Arabic ChatGPT Tweets Classification Using RoBERTa and BERT Ensemble Model},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {8},
issn = {2375-4699},
url = {https://doi.org/10.1145/3605889},
doi = {10.1145/3605889},
abstract = {ChatGPT OpenAI, a large-language chatbot model, has gained a lot of attention due to its popularity and impressive performance in many natural language processing tasks. ChatGPT produces superior answers to a wide range of real-world human questions and generates human-like text. The new OpenAI ChatGPT technology may have some strengths and weaknesses at this early stage. Users have reported early opinions about the ChatGPT features, and their feedback is essential to recognize and fix its shortcomings and issues. This study uses the ChatGPT tweets Arabic dataset to automatically find user opinions and sentiments about ChatGPT technology. The dataset is preprocessed and labeled using the TextBlob Arabic Python library into positive, negative, and neutral tweets. Despite extensive works for the English language, languages like Arabic are less studied regarding tweet analysis. Existing literature about Arabic tweet sentiment analysis has mainly focused on machine learning and deep learning models. We collected a total of 27,780 unstructured tweets from Twitter using the Tweepy SNscrape Python library using various hash-tags such as # Chat-GPT, #OpenAI, #Chatbot, Chat-GPT3, and so on. To enhance the model’s performance and reduce computational complexity, unstructured tweets are converted into structured and normalized forms. Tweets contain missing values, URL and HTML tags, stop words, punctuation, diacritics, elongations, and numeric values that have no impact on the model performance; hence, these increase the computational cost. So, these steps are removed with the help of Python preprocessing libraries to enhance text quality and consistency. This study adopts Transformer-based models such as RoBERTa, XLNet, and DistilBERT that automatically classify the tweets. Additionally, a hybrid transformer-based model is proposed to obtain better results. The proposed hybrid model is developed by combining the hidden outputs of the RoBERTA and BERT models using a concatenation layer, then adding dense layers with “Relu” activation employed as a hidden layer to create non-linearity and a “softmax” activation function for multiclass classification. They differ from existing state-of-the-art models due to the enhanced capabilities of both models in text classification. Hybrid models combine the different models to make accurate predictions and reduce bias and enhanced the overall results, while state-of-the-art models are incapable of making accurate predictions. Experiments show that the proposed hybrid model achieves 96.02% accuracy, 100% precision on negative tweets, and 99% recall for neutral tweets. The performance of the proposed model is far better than existing state-of-the-art models.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {204},
numpages = {23},
keywords = {sentiment analysis, BERT, transformer models, OpenAI, ChatGPT, low-resource language, Arabic tweets}
}

@article{10.1145/3610099,
author = {Scurto, Hugo and Similowski, Thomas and Bianchini, Samuel and Caramiaux, Baptiste},
title = {Probing Respiratory Care With Generative Deep Learning},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610099},
doi = {10.1145/3610099},
abstract = {This paper combines design, machine learning and social computing to explore generative deep learning as both tool and probe for respiratory care. We first present GANspire, a deep learning tool that generates fine-grained breathing waveforms, which we crafted in collaboration with one respiratory physician, attending to joint materialities of human breathing data and deep generative models. We then relate a probe, produced with breathing waveforms generated with GANspire, and led with a group of ten respiratory care experts, responding to its material attributes. Qualitative annotations showed that respiratory care experts interpreted both realistic and ambiguous attributes of breathing waveforms generated with GANspire, according to subjective aspects of physiology, activity and emotion. Semi-structured interviews also revealed experts' broader perceptions, expectations and ethical concerns on AI technology, based on their clinical practice of respiratory care, and reflexive analysis of GANspire. These findings suggest design implications for technological aids in respiratory care, and show how ambiguity of deep generative models can be leveraged as a resource for qualitative inquiry, enabling socio-material research with generative deep learning. Our paper contributes to the CSCW community by broadening how generative deep learning may be approached not only as a tool to design human-computer interactions, but also as a probe to provoke open conversations with communities of practice about their current and speculative uses of AI technology.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {308},
numpages = {34},
keywords = {AI, design research, generative deep learning, respiratory care}
}

@inproceedings{10.1145/3555776.3577652,
author = {Jamil, Hasan M and Naha, Kallol},
title = {Mapping Strategies for Declarative Queries over Online Heterogeneous Biological Databases for Intelligent Responses},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577652},
doi = {10.1145/3555776.3577652},
abstract = {The emergence of Alexa and Siri, and more recently, OpenAI's Chat-GPT, raises the question whether ad hoc biological queries can also be computed without end-users' active involvement in the code writing process. While advances have been made, current querying architectures for biological databases still assume some degree of computational competence and significant structural awareness of the underlying network of databases by biologists, if not active code writing. Given that biological databases are highly distributed and heterogeneous, and most are not FAIR compliant, a significant amount of expertise in data integration is essential for a query to be accurately crafted and meaningfully executed. In this paper, we introduce a flexible and intelligent query reformulation assistant, called Needle, as a back-end query execution engine of a natural language query interface to online biological databases. Needle leverages a data model called BioStar that leverages a meta-knowledgebase, called the schema graph, to map natural language queries to relevant databases and biological concepts. The implementation of Needle using BioStar is the focus of this article.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {567–574},
numpages = {8},
keywords = {query reformulation, schema abstraction, ad hoc querying, data integration, biological databases, schema graph},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3527927.3532801,
author = {Jonsson, Martin and Tholander, Jakob},
title = {Cracking the code: Co-coding with AI in creative programming education},
year = {2022},
isbn = {9781450393270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527927.3532801},
doi = {10.1145/3527927.3532801},
abstract = {This paper presents a study of a group of university students using generative machine learning to translate from natural language to computer code. The study explores how the use of the AI tool can be understood in terms of co-creation, focusing on the one hand on how the tool may serve as a resource for understanding and learning, and on the other hand how the tool affects the creative processes. Findings show how the participants search for a ’correct’ syntax in their instructions to the machine learning tool, and how the inconsistent and erroneous behavior can work as a way to generate clues and inspiration for generating creative expressions. The notion of friction is used to describe how systems like this can serve to both lower thresholds for programming, and also interfere with the creative processes, encouraging reflection and exploration of alternative solutions.},
booktitle = {Proceedings of the 14th Conference on Creativity and Cognition},
pages = {5–14},
numpages = {10},
keywords = {programming, post-human design, generative machine learning, co-creation, GPT-3},
location = {Venice, Italy},
series = {C&amp;C '22}
}

@inproceedings{10.1145/3558489.3559072,
author = {Yetistiren, Burak and Ozsoy, Isik and Tuzun, Eray},
title = {Assessing the quality of GitHub copilot’s code generation},
year = {2022},
isbn = {9781450398602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558489.3559072},
doi = {10.1145/3558489.3559072},
abstract = {The introduction of GitHub’s new code generation tool, GitHub Copilot, seems to be the first well-established instance of an AI pair-programmer. GitHub Copilot has access to a large number of open-source projects, enabling it to utilize more extensive code in various programming languages than other code generation tools. Although the initial and informal assessments are promising, a systematic evaluation is needed to explore the limits and benefits of GitHub Copilot. The main objective of this study is to assess the quality of generated code provided by GitHub Copilot. We also aim to evaluate the impact of the quality and variety of input parameters fed to GitHub Copilot. To achieve this aim, we created an experimental setup for evaluating the generated code in terms of validity, correctness, and efficiency. Our results suggest that GitHub Copilot was able to generate valid code with a 91.5% success rate. In terms of code correctness, out of 164 problems, 47 (28.7%) were correctly, while 84 (51.2%) were partially correctly, and 33 (20.1%) were incorrectly generated. Our empirical analysis shows that GitHub Copilot is a promising tool based on the results we obtained, however further and more comprehensive assessment is needed in the future.},
booktitle = {Proceedings of the 18th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {62–71},
numpages = {10},
keywords = {empirical study, code generation, code completion, GitHub Copilot, AI pair programmer},
location = {Singapore, Singapore},
series = {PROMISE 2022}
}

@inproceedings{10.1145/3539618.3593069,
author = {White, Ryen W.},
title = {Tasks, Copilots, and the Future of Search},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3593069},
doi = {10.1145/3539618.3593069},
abstract = {Tasks are central to information retrieval (IR) and drive interactions with search systems [2, 4, 10]. Understanding and modeling tasks helps these systems better support user needs [8, 9, 11]. This keynote focuses on search tasks, the emergence of generative artificial intelligence (AI), and the implications of recent work at their intersection for the future of search. Recent estimates suggest that half of Web search queries go unanswered, many of them connected to complex search tasks that are ill-defined or multi-step and span several queries[6]. AI copilots, e.g., ChatGPT and Bing Chat, are emerging to address complex search tasks and many other challenges. These copilots are built on large foundation models such as GPT-4 and are being extended with skills and plugins. Copilots broaden the surface of tasks achievable via search, moving toward creation not just finding (e.g., interview preparation, email composition), and can make searchers more efficient and more successful.Users currently engage with AI copilots via natural language queries and dialog and the copilots generate answers with source attribution [7]. However, in delegating responsibility for answer generation, searchers also lose some control over aspects of the search process, such as directly manipulating queries and examining lists of search results [1]. The efficiency gains from auto-generating a single, synthesized answer may also reduce opportunities for user learning and serendipity. A wholesale move to copilots for all search tasks is neither practical nor necessary: model inference is expensive, conversational interfaces are unfamiliar to many users in a search context, and traditional search already excels for many types of task. Instead, experiences that unite search and chat are becoming more common, enabling users to adjust the modality and other aspects (e.g., answer tone) based on the task.The rise of AI copilots creates many opportunities for IR, including aligning generated answers with user intent, tasks, and applications via human feedback [3]; understanding copilot usage, including functional fixedness [5]; using context and data to tailor responses to people and situations (e.g., grounding, personalization); new search experiences (e.g., unifying search and chat); reliability and safety (e.g., accuracy, bias); understanding impacts on user learning and agency; and evaluation (e.g., model-based feedback, searcher simulations [12] repeatability). Research in these and related areas will enable search systems to more effectively utilize new copilot technologies together with traditional search to help searchers better tackle a wider variety of tasks.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {5–6},
numpages = {2},
keywords = {artificial intelligence, complex tasks, copilots, search experience, search systems, task intelligence, task models, tasks, web search},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3581783.3612014,
author = {Wu, Zhenqian and Ren, Yazhou and Pu, Xiaorong and Hao, Zhifeng and He, Lifang},
title = {Generative Neutral Features-Disentangled Learning for Facial Expression Recognition},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612014},
doi = {10.1145/3581783.3612014},
abstract = {Facial expression recognition (FER) plays a critical role in human-computer interaction and affective computing. Traditional FER methods typically rely on comparing the difference between an examined facial expression and a neutral face of the same person to extract the motion of facial features and filter out expression-irrelevant information. With the extensive use of deep learning, the performance of FER has been further improved. However, existing deep learning-based methods rarely utilize neutral faces. To address this gap, we propose a novel deep learning-based FER method called Generative Neutral Features-Disentangled Learning (GNDL), which draws inspiration from the facial feature manifold. Our approach integrates a neutral feature generator (NFG) that generates neutral features in scenarios where the neutral face of the same subject is not available. The NFG uses fine-grained features from examined images as input and produces corresponding neutral features with the same identity. We train the NFG using a neutral feature reconstruction loss to ensure that the generative neutral features are consistent with the actual neutral features. We then disentangle the generative neutral features from the examined features to remove disturbance features and generate an expression deviation embedding for classification. Extensitive experimental results on three popular databases (CK+, Oulu-CASIA, and MMI) demonstrate that our proposed GNDL method outperforms state-of-the-art FER methods.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {4300–4308},
numpages = {9},
keywords = {disturbance-disentangling, facial expression recognition, facial feature manifold, neutral feature generator},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3510454.3522684,
author = {Imai, Saki},
title = {Is GitHub copilot a substitute for human pair-programming? an empirical study},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3522684},
doi = {10.1145/3510454.3522684},
abstract = {This empirical study investigates the effectiveness of pair programming with GitHub Copilot in comparison to human pair-programming. Through an experiment with 21 participants we focus on code productivity and code quality. For experimental design, a participant was given a project to code, under three conditions presented in a randomized order. The conditions are pair-programming with Copilot, human pair-programming as a driver, and as a navigator. The codes generated from the three trials were analyzed to determine how many lines of code on average were added in each condition and how many lines of code on average were removed in the subsequent stage. The former measures the productivity of each condition while the latter measures the quality of the produced code. The results suggest that although Copilot increases productivity as measured by lines of code added, the quality of code produced is inferior by having more lines of code deleted in the subsequent trial.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {319–321},
numpages = {3},
keywords = {software development, copilot, GitHub, AI},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@article{10.1109/TASLP.2023.3240661,
author = {Liu, Hong and Cai, Yucheng and Lin, Zhenru and Ou, Zhijian and Huang, Yi and Feng, Junlan},
title = {Variational Latent-State GPT for Semi-Supervised Task-Oriented Dialog Systems},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3240661},
doi = {10.1109/TASLP.2023.3240661},
abstract = {Recently, two approaches, fine-tuning large pre-trained language models and variational training, have attracted significant interests, separately, for semi-supervised end-to-end task-oriented dialog (TOD) systems. In this paper, we propose Variational Latent-State GPT model (VLS-GPT), which is the first to combine the strengths of the two approaches. Among many options of models, we propose the generative model and the inference model for variational learning of the end-to-end TOD system, both as auto-regressive language models based on GPT-2, which can be further trained over a mix of labeled and unlabeled dialog data in a semi-supervised manner. Variational training of VLS-GPT is both statistically and computationally more challenging than previous variational learning works for sequential latent variable models, which use turn-level first-order Markovian. The inference model in VLS-GPT is non-Markovian due to the use of the Transformer architecture. In this work, we establish Recursive Monte Carlo Approximation (RMCA) to the variational objective with non-Markovian inference model and prove its unbiasedness. Further, we develop the computational strategy of sampling-then-forward-computation to realize RMCA, which successfully overcomes the memory explosion issue of using GPT in variational learning and speeds up training. Semi-supervised TOD experiments are conducted on two benchmark multi-domain datasets of different languages - MultiWOZ2.1 and CrossWOZ. VLS-GPT is shown to significantly outperform both supervised-only and semi-supervised self-training baselines.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jan,
pages = {970–984},
numpages = {15}
}

@inproceedings{10.1109/ICSE48619.2023.00129,
author = {Xia, Chunqiu Steven and Wei, Yuxiang and Zhang, Lingming},
title = {Automated Program Repair in the Era of Large Pre-Trained Language Models},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00129},
doi = {10.1109/ICSE48619.2023.00129},
abstract = {Automated Program Repair (APR) aims to help developers automatically patch software bugs. However, current state-of-the-art traditional and learning-based APR techniques face the problem of limited patch variety, failing to fix complicated bugs. This is mainly due to the reliance on bug-fixing datasets to craft fix templates (traditional) or directly predict potential patches (learning-based). Large Pre-Trained Language Models (LLMs), trained using billions of text/code tokens, can potentially help avoid this issue. Very recently, researchers have directly leveraged LLMs for APR without relying on any bug-fixing datasets. Meanwhile, such existing work either failed to include state-of-the-art LLMs or was not evaluated on realistic datasets. Thus, the true power of modern LLMs on the important APR problem is yet to be revealed.In this work, we perform the first extensive study on directly applying LLMs for APR. We select 9 recent state-of-the-art LLMs, including both generative and infilling models, ranging from 125M to 20B in size. We designed 3 different repair settings to evaluate the different ways we can use LLMs to generate patches: 1) generate the entire patch function, 2) fill in a chunk of code given the prefix and suffix 3) output a single line fix. We apply the LLMs under these repair settings on 5 datasets across 3 different languages and compare different LLMs in the number of bugs fixed, generation speed and compilation rate. We also compare the LLMs against recent state-of-the-art APR tools. Our study demonstrates that directly applying state-of-the-art LLMs can already substantially outperform all existing APR techniques on all our datasets. Among the studied LLMs, the scaling effect exists for APR where larger models tend to achieve better performance. Also, we show for the first time that suffix code after the buggy line (adopted in infilling-style APR) is important in not only generating more fixes but more patches with higher compilation rate. Besides patch generation, the LLMs consider correct patches to be more natural than other ones, and can even be leveraged for effective patch ranking or patch correctness checking. Lastly, we show that LLM-based APR can be further substantially boosted via: 1) increasing the sample size, and 2) incorporating fix template information.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {1482–1494},
numpages = {13},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3573381.3597232,
author = {Chatterjee, Jit and Torres Vega, Maria},
title = {Human-Centered and AI-driven Generation of 6-DoF Extended Reality},
year = {2023},
isbn = {9798400700286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573381.3597232},
doi = {10.1145/3573381.3597232},
abstract = {In order to unlock the full potential of Extended Reality (XR) and its application to societal sectors such as health (e.g., training) or Industry 5.0 (e.g., remote control of infrastructure) there is a need for very realistic environments to enhance the presence of the user. However, current photo-realistic content generation methods (such as Light Fields) require a massive amount of data transmission (i.e., ultra-high bandwidths) and extreme computational power for displaying. Thus, they are not suited for interactive immersive and realistic applications. In this research, we hypothesize that is possible to generate realistic dynamic 3D environments by means of Deep Generative Networks. The work will consist of two parts: (1) a computer vision system that generates the 3D environment based on 2D images, and (2) a Human-Computer Interaction system (HCI) that predicts Region of Interest (RoI) for efficient 3D rendering, subjective and objective assessment of user perception (by means of presence) to enhance the 3D scene quality. This work aims to gain insights into how well deep generative methods can create realistic and immersive environments. This will significantly help future developments in realistic and immersive XR content creation.},
booktitle = {Proceedings of the 2023 ACM International Conference on Interactive Media Experiences},
pages = {398–401},
numpages = {4},
keywords = {Presence, Extended Reality, Deep Generative Networks, Computer Vision},
location = {Nantes, France},
series = {IMX '23}
}

@inproceedings{10.1145/3610661.3616177,
author = {Higasa, Taichi and Tanaka, Keitaro and Feng, Qi and Morishima, Shigeo},
title = {Gaze-Driven Sentence Simplification for Language Learners: Enhancing Comprehension and Readability},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3616177},
doi = {10.1145/3610661.3616177},
abstract = {Language learners should regularly engage in reading challenging materials as part of their study routine. Nevertheless, constantly referring to dictionaries is time-consuming and distracting. This paper presents a novel gaze-driven sentence simplification system designed to enhance reading comprehension while maintaining their focus on the content. Our system incorporates machine learning models tailored to individual learners, combining eye gaze features and linguistic features to assess sentence comprehension. When the system identifies comprehension difficulties, it provides simplified versions by replacing complex vocabulary and grammar with simpler alternatives via GPT-3.5. We conducted an experiment with 19 English learners, collecting data on their eye movements while reading English text. The results demonstrated that our system is capable of accurately estimating sentence-level comprehension. Additionally, we found that GPT-3.5 simplification improved readability in terms of traditional readability metrics and individual word difficulty, paraphrasing across different linguistic levels.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {292–296},
numpages = {5},
keywords = {sentence simplification, machine learning, human-computer interaction, Eye tracking},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@inproceedings{10.1109/ICSE-SEIP58684.2023.00022,
author = {Vaithilingam, Priyan and Glassman, Elena L. and Groenwegen, Peter and Gulwani, Sumit and Henley, Austin Z. and Malpani, Rohan and Pugh, David and Radhakrishna, Arjun and Soares, Gustavo and Wang, Joey and Yim, Aaron},
title = {Towards More Effective AI-Assisted Programming: A Systematic Design Exploration to Improve Visual Studio IntelliCode's User Experience},
year = {2023},
isbn = {9798350300376},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-SEIP58684.2023.00022},
doi = {10.1109/ICSE-SEIP58684.2023.00022},
abstract = {AI-driven code editor extensions such as Visual Studio IntelliCode and Github CoPilot have become extremely popular. These tools recommend inserting chunks of code, with the lines to be inserted presented inline at the current cursor location as gray text. In contrast to their popularity, other AI-driven code recommendation tools that suggest code changes (as opposed to code completions) have remained woefully underused. We conducted lab studies at Microsoft to understand this disparity and found one major cause: discoverability. Code change suggestions are hard to surface through bold, inline interfaces and hence, developers often do not even notice them.Towards a systematic understanding of code change interfaces, we performed a thorough design exploration for various categories of code changes: additive single-line changes, single-line changes, and multi-line changes. Overall, we explored 19 designs through a series of 7 laboratory studies involving 61 programmers and distilled our findings into a set of 5 design principles. To validate our results, we built and deployed a new version of IntelliCode with two of our new inline interfaces in Microsoft Visual Studio 2022 and found that they lead to a significant increase in usage of the corresponding tools.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Software Engineering in Practice},
pages = {185–195},
numpages = {11},
keywords = {code-completion, iterative-refinement, refactoring, AI-suggestion, inline-suggestion},
location = {Melbourne, Australia},
series = {ICSE-SEIP '23}
}

@inproceedings{10.1145/3610969.3610973,
author = {Addo, Salomey Afua},
title = {Are You Ready to Teach AI in Schools? Teachers' Perspectives of Teaching AI in K-12 Settings},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610973},
doi = {10.1145/3610969.3610973},
abstract = {Artificial intelligence (AI) has continually made headlines, even more so with the mass interest in generative AI. The implications of AI on society raises the need for its inclusion in the K-12 computing curriculum. However, little research has been conducted to understand teachers’ preparedness to teach AI concepts in K-12. This exploratory study seeks to understand teachers’ motivation and preparedness to teach AI in schools through the lens of Self Efficacy Theory (SET) and Self Determination Theory (SDT).},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {32},
numpages = {1},
keywords = {motivation, K-12 computing education, Artificial intelligence},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3604915.3608795,
author = {Zheng, Zhi and Sun, Ying and Song, Xin and Zhu, Hengshu and Xiong, Hui},
title = {Generative Learning Plan Recommendation for Employees: A Performance-aware Reinforcement Learning Approach},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608795},
doi = {10.1145/3604915.3608795},
abstract = {With the rapid development of enterprise Learning Management Systems (LMS), more and more companies are trying to build enterprise training and course learning platforms for promoting the career development of employees. Indeed, through course learning, many employees have the opportunity to improve their knowledge and skills. For these systems, a major issue is how to recommend learning plans, i.e., a set of courses arranged in the order they should be learned, that can help employees improve their work performance. Existing studies mainly focus on recommending courses that users are most likely to click on by capturing their learning preferences. However, the learning preference of employees may not be the right fit for their career development, and thus it may not necessarily mean their work performance can be improved accordingly. Furthermore, how to capture the mutual correlation and sequential effects between courses, and ensure the rationality of the generated results, is also a major challenge. To this end, in this paper, we propose the Generative Learning plAn recommenDation (GLAD) framework, which can generate personalized learning plans for employees to help them improve their work performance. Specifically, we first design a performance predictor and a rationality discriminator, which have the same transformer-based model architecture, but with totally different parameters and functionalities. In particular, the performance predictor is trained for predicting the work performance of employees based on their work profiles and historical learning records, while the rationality discriminator aims to evaluate the rationality of the generated results. Then, we design a learning plan generator based on the gated transformer and the cross-attention mechanism for learning plan generation. We calculate the weighted sum of the output from the performance predictor and the rationality discriminator as the reward, and we use Self-Critical Sequence Training (SCST) based policy gradient methods to train the generator following the Generative Adversarial Network (GAN) paradigm. Finally, extensive experiments on real-world data clearly validate the effectiveness of our GLAD framework compared with state-of-the-art baseline methods and reveal some interesting findings for talent management.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {443–454},
numpages = {12},
keywords = {generative recommendation, learning management system, reinforcement learning},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@article{10.1145/3592367.3617935,
author = {Hines, Jasara},
title = {Review of "Writing in the Clouds: Inventing and Composing in Internetworked Writing Spaces by John Logie," Logie, J. (2021). Writing in the clouds: Inventing and composing in internetworked writing spaces. Parlor Press.},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
url = {https://doi.org/10.1145/3592367.3617935},
doi = {10.1145/3592367.3617935},
abstract = {In the wake of the controversy surrounding the new AI chatbot application, ChatGPT, I wonder how Logie would seek to include this new technology in his work. I ponder this because, throughout the book, Logie presents compelling evidence for why the concepts of invention, composition, and internetworked writing should be embraced and not feared. While some denounce the application and take to social media to disparage the possible negative impact on students, creativity, and composition, ChatGPT, I believe Logie would argue, would be a powerful tool we can implement to become "composers." He believes that through cloud computing services we are now more apt to collaborate, use, remix, and create rhetorical modes that extend far beyond the formulaic argument, therefore we are composers. So, Logie applies the idea of a composer as someone who is a "prosumer" (Toffler). This composer is media literate and transforms traditional rhetorical canons into multimodal compositions such as memes, Google Docs, and digital collages. However, his overarching argument is that internetworked writing tools have democratized writing through that same offering of innovative outlets. His book is arranged in a way that walks the reader through this argument.},
journal = {Commun. Des. Q. Rev},
month = dec,
pages = {80–81},
numpages = {2}
}

@inproceedings{10.1145/3610548.3618175,
author = {Jiang, Yifeng and Won, Jungdam and Ye, Yuting and Liu, C. Karen},
title = {DROP: Dynamics Responses from Human Motion Prior and Projective Dynamics},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610548.3618175},
doi = {10.1145/3610548.3618175},
abstract = {Synthesizing realistic human movements, dynamically responsive to the environment, is a long-standing objective in character animation, with applications in computer vision, sports, and healthcare, for motion prediction and data augmentation. Recent kinematics-based generative motion models offer impressive scalability in modeling extensive motion data, albeit without an interface to reason about and interact with physics. While simulator-in-the-loop learning approaches enable highly physically realistic behaviors, the challenges in training often affect scalability and adoption. We introduce DROP, a novel framework for modeling Dynamics Responses of humans using generative mOtion prior and Projective dynamics. DROP can be viewed as a highly stable, minimalist physics-based human simulator that interfaces with a kinematics-based generative motion prior. Utilizing projective dynamics, DROP allows flexible and simple integration of the learned motion prior as one of the projective energies, seamlessly incorporating control provided by the motion prior with Newtonian dynamics. Serving as a model-agnostic plug-in, DROP enables us to fully leverage recent advances in generative motion models for physics-based motion synthesis. We conduct extensive evaluations of our model across different motion tasks and various physical perturbations, demonstrating the scalability and diversity of responses.},
booktitle = {SIGGRAPH Asia 2023 Conference Papers},
articleno = {18},
numpages = {11},
keywords = {Generative Models, Hybrid Methods, Physics-based Motion Synthesis},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3512290.3528742,
author = {Flores, Diana and Hemberg, Erik and Toutouh, Jamal and O'Reily, Una-May},
title = {Coevolutionary generative adversarial networks for medical image augumentation at scale},
year = {2022},
isbn = {9781450392372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512290.3528742},
doi = {10.1145/3512290.3528742},
abstract = {Medical image processing can lack images for diagnosis. Generative Adversarial Networks (GANs) provide a method to train generative models for data augmentation. Synthesized images can be used to improve the robustness of computer-aided diagnosis systems. However, GANs are difficult to train due to unstable training dynamics that may arise during the learning process, e.g., mode collapse and vanishing gradients. This paper focuses on Lipizzaner, a GAN training framework that combines spatial coevolution with gradient-based learning, which has been used to mitigate GAN training pathologies. Lipizzaner improves performance by taking advantage of its distributed nature and running at scale. Thus, the Lipizzaner algorithm and implementation robustness can be scaled to high-performance computing (HPC) systems to provide more accurate generative models. We address medical imaging data augmentation to create chest X-Ray images by using Lipizzaner on the HPC infrastructure provided by Oak Ridge National Labs' Summit Supercomputer. The experimental analysis shows improved performance by increasing the scale of the Lipizzaner GAN training. We also demonstrate that distributed coevolutionary learning improves performance even when using suboptimal neural network architectures due to hardware constraints.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {367–376},
numpages = {10},
keywords = {coevolution, generative adversarial networks, high performance computing, medical imaging},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@inproceedings{10.1145/3545947.3576339,
author = {Koornneef, Stacey A. and Bradbury, Jeremy S. and Miljanovic, Michael A.},
title = {Run, Llama, Run: A Computational Thinking Game for K-5 Students Designed to Support Equitable Access},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3576339},
doi = {10.1145/3545947.3576339},
abstract = {Computational thinking is now included in K-5 classrooms and this has led to a demand for new interactive and collaborative learning tools that engage a younger audience. Block-based programming and educational games have both been shown to be effective at engaging children, however they have limitations with respect to supporting collaborative learning and equitable access. Our goal in designing Run, Llama, Run was to build on the positive aspects of block-based programming and educational games while also addressing these limitations. Furthermore, we are using Run, Llama, Run as a platform to explore the trade-offs between digital and tangible interfaces to understand how best to support equitable access while maintaining learning, engagement, and collaboration.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1395},
numpages = {1},
keywords = {block-based programming, computational thinking, educational games, equitable access, tangible programming},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.5555/3539845.3539929,
author = {Li, Junde and Ghosh, Swaroop},
title = {Scalable variational quantum circuits for autoencoder-based drug discovery},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {The de novo design of drug molecules is recognized as a time-consuming and costly process, and computational approaches have been applied in each stage of the drug discovery pipeline. Variational autoencoder is one of the computer-aided design methods which explores the chemical space based on an existing molecular dataset. Quantum machine learning has emerged as an atypical learning method that may speed up some classical learning tasks because of its strong expressive power. However, near-term quantum computers suffer from limited number of qubits which hinders the representation learning in high dimensional spaces. We present a scalable quantum generative autoencoder (SQ-VAE) for simultaneously reconstructing and sampling drug molecules, and a corresponding vanilla variant (SQ-AE) for better reconstruction. The architectural strategies in hybrid quantum classical networks such as, adjustable quantum layer depth, heterogeneous learning rates, and patched quantum circuits are proposed to learn high dimensional dataset such as, ligand-targeted drugs. Extensive experimental results are reported for different dimensions including 8x8 and 32x32 after choosing suitable architectural strategies. The performance of quantum generative autoencoder is compared with the corresponding classical counterpart throughout all experiments. The results show that quantum computing advantages can be achieved for normalized low-dimension molecules, and that high-dimension molecules generated from quantum generative autoencoders have better drug properties within the same learning period.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {340–345},
numpages = {6},
keywords = {variational autoencoder, quantum machine learning, drug discovery},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3604237.3626850,
author = {Skalski, Piotr and Sutton, David and Burrell, Stuart and Perez, Iker and Wong, Jason},
title = {Towards a Foundation Purchasing Model: Pretrained Generative Autoregression on Transaction Sequences},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626850},
doi = {10.1145/3604237.3626850},
abstract = {Machine learning models underpin many modern financial systems for use cases such as fraud detection and churn prediction. Most are based on supervised learning with hand-engineered features, which relies heavily on the availability of labelled data. Large self-supervised generative models have shown tremendous success in natural language processing and computer vision, yet so far they haven’t been adapted to multivariate time series of financial transactions. In this paper, we present a generative pretraining method that can be used to obtain contextualised embeddings of financial transactions. Benchmarks on public datasets demonstrate that it outperforms state-of-the-art self-supervised methods on a range of downstream tasks. We additionally perform large-scale pretraining of an embedding model using a corpus of data from 180 issuing banks containing 5.1 billion transactions and apply it to the card fraud detection problem on hold-out datasets. The embedding model significantly improves value detection rate at high precision thresholds and transfers well to out-of-domain distributions.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {141–149},
numpages = {9},
keywords = {fraud detection, generative modelling, multivariate time series, self-supervised learning, transaction embeddings},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3539618.3591923,
author = {Bénédict, Garbiel and Zhang, Ruqing and Metzler, Donald},
title = {Gen-IR@SIGIR 2023: The First Workshop on Generative Information Retrieval},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591923},
doi = {10.1145/3539618.3591923},
abstract = {Generative information retrieval (IR) has experienced substantial growth across multiple research communities (e.g., information retrieval, computer vision, natural language processing, and machine learning), and has been highly visible in the popular press. Theoretical, empirical, and actual user-facing products have been released that retrieve documents (via generation) or directly generate answers given an input request. We would like to investigate whether end-to-end generative models are just another trend or, as some claim, a paradigm change for IR. This necessitates new metrics, theoretical grounding, evaluation methods, task definitions, models, user interfaces, etc. The goal of this workshop1 is to focus on previously explored Generative IR techniques like document retrieval and direct Grounded Answer Generation, while also offering a venue for the discussion and exploration of how Generative IR can be applied to new domains like recommendation systems, summarization, etc. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3460–3463},
numpages = {4},
keywords = {generative models, information retrieval, large language models},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3622758.3622882,
author = {Sarkar, Advait},
title = {Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?},
year = {2023},
isbn = {9798400703881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622758.3622882},
doi = {10.1145/3622758.3622882},
abstract = {The research field of end-user programming has largely been concerned with helping non-experts learn to code sufficiently well in order to achieve their tasks. Generative AI stands to obviate this entirely by allowing users to generate code from naturalistic language prompts. In this essay, we explore the extent to which "traditional" programming languages remain relevant for non-expert end-user programmers in a world with generative AI. We posit the "generative shift hypothesis": that generative AI will create qualitative and quantitative expansions in the traditional scope of end-user programming. We outline some reasons that traditional programming languages may still be relevant and useful for end-user programmers. We speculate whether each of these reasons might be fundamental and enduring, or whether they may disappear with further improvements and innovations in generative AI. Finally, we articulate a set of implications for end-user programming research, including the possibility of needing to revisit many well-established core concepts, such as Ko's learning barriers and Blackwell's attention investment model.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {153–167},
numpages = {15},
keywords = {self-efficacy, prompt engineering, live programming, learning barriers, generative shift hypothesis, end-user software customization, attention investment model},
location = {Cascais, Portugal},
series = {Onward! 2023}
}

@inproceedings{10.1145/3587716.3587798,
author = {Zhao, Chenjing and Deng, Chuanshuai and Liu, Zhenghui and Zhang, Jiexin and Wu, Yunlong and Wang, Yanzhen and Yi, Xiaodong},
title = {Interpretable Reinforcement Learning of Behavior Trees},
year = {2023},
isbn = {9781450398411},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587716.3587798},
doi = {10.1145/3587716.3587798},
abstract = {The interpretability of reinforcement learning (RL) algorithms has become one of the significant challenges for artificial intelligence (AI) researchers. Behavior Trees (BTs) have enabled developers to design AI policies visually and comprehend the agent’s behaviors in robotics and computer games. Combining their strengths, researchers have proposed to utilize the RL algorithm to generate BTs to present learned policies automatically. Existing methods are devoted to the incremental generation or modification of pre-designed BTs. These efforts necessitate specialized knowledge and the manual design of initial BTs. In this paper, we present intelligent generation methods that directly represent the policies generated by Q-learning and its derived algorithms in the form of BTs to enhance the interpretability of RL. We investigate the tradeoff between the size and performance of BTs while attaining interpretability, intending to obtain balanced policies that are easy to comprehend and good in performance. Evaluations in several classic OpenAI Gym environments validate the effectiveness of our methods.},
booktitle = {Proceedings of the 2023 15th International Conference on Machine Learning and Computing},
pages = {492–499},
numpages = {8},
keywords = {Behavior Trees, Interpretability, Reinforcement Learning},
location = {Zhuhai, China},
series = {ICMLC '23}
}

@inproceedings{10.1145/3581792.3581802,
author = {Ravikumar, Aswathy and Sriraman, Harini},
title = {Single Node Acceleration of Generative Adversarial Networks using HPC for Image Analytics},
year = {2023},
isbn = {9781450397612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581792.3581802},
doi = {10.1145/3581792.3581802},
abstract = {Generative Adversarial Networks (GAN) are approaches that are utilized for data augmentation, which facilitates the development of more accurate detection models for unusual or unbalanced datasets. Computer-assisted diagnostic methods may be made more reliable by using synthetic pictures generated by GAN. Generative adversarial networks are challenging to train because too unpredictable training dynamics may occur throughout the learning process, such as model collapse and vanishing gradients. For accurate and faster results the GAN network need to trained in parallel and distributed manner. We enhance the speed and precision of the Deep Convolutional Generative Adversarial Networks (DCGAN) architecture by using its parallelism and executing it on High-Performance Computing platforms. The effective analysis of a DCGAN in Graphic Processing Unit and Tensor Processing Unit platforms in which each layer execution pattern is analyzed. The bottleneck is identified for the GAN structure for each execution platforms. The Central Processing Unit is capable of processing neural network models, but it requires a great deal of time to do it. Graphic Processing Unit in contrast, side, are a hundred times quicker than CPUs for Neural Networks, however, they are prohibitively expensive compared to CPUs. Using the systolic array structure, TPU performs well on neural networks with high batch sizes but in GAN the shift between CPU and TPU is huge so it does not perform well.},
booktitle = {Proceedings of the 2022 5th International Conference on Computational Intelligence and Intelligent Systems},
pages = {54–59},
numpages = {6},
keywords = {Tensor Processing Unit, High-Performance Computing, Graphic Processing Unit, Generative Adversarial Network},
location = {Quzhou, China},
series = {CIIS '22}
}

@inproceedings{10.1145/3583780.3614901,
author = {Bai, Jiaqi and Guo, Hongcheng and Liu, Jiaheng and Yang, Jian and Liang, Xinnian and Yan, Zhao and Li, Zhoujun},
title = {GripRank: Bridging the Gap between Retrieval and Generation via the Generative Knowledge Improved Passage Ranking},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614901},
doi = {10.1145/3583780.3614901},
abstract = {Retrieval-enhanced text generation has shown remarkable progress on knowledge-intensive language tasks, such as open-domain question answering and knowledge-enhanced dialogue generation, by leveraging passages retrieved from a large passage corpus for delivering a proper answer given the input query. However, the retrieved passages are not ideal for guiding answer generation because of the discrepancy between retrieval and generation, i.e., the candidate passages are all treated equally during the retrieval procedure without considering their potential to generate a proper answer. This discrepancy makes a passage retriever deliver a sub-optimal collection of candidate passages to generate the answer. In this paper, we propose the GeneRative Knowledge Improved Passage Ranking (GripRank) approach, addressing the above challenge by distilling knowledge from a generative passage estimator (GPE) to a passage ranker, where the GPE is a generative language model used to measure how likely the candidate passages can generate the proper answer. We realize the distillation procedure by teaching the passage ranker learning to rank the passages ordered by the GPE. Furthermore, we improve the distillation quality by devising a curriculum knowledge distillation mechanism, which allows the knowledge provided by the GPE can be progressively distilled to the ranker through an easy-to-hard curriculum, enabling the passage ranker to correctly recognize the provenance of the answer from many plausible candidates. We conduct extensive experiments on four datasets across three knowledge-intensive language tasks. Experimental results show advantages over the state-of-the-art methods for both passage ranking and answer generation on the KILT benchmark.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {36–46},
numpages = {11},
keywords = {retrieval-enhanced text generation, passage ranking, knowledge-intensive language tasks, knowledge distillation},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@article{10.1145/3626193,
author = {Xia, Weihao and Xue, Jing-Hao},
title = {A Survey on Deep Generative 3D-aware Image Synthesis},
year = {2023},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3626193},
doi = {10.1145/3626193},
abstract = {Recent years have seen remarkable progress in deep learning powered visual content creation. This includes deep generative 3D-aware image synthesis, which produces high-fidelity images in a 3D-consistent manner while simultaneously capturing compact surfaces of objects from pure image collections without the need for any 3D supervision, thus bridging the gap between 2D imagery and 3D reality. The field of computer vision has been recently captivated by the task of deep generative 3D-aware image synthesis, with hundreds of papers appearing in top-tier journals and conferences over the past few years (mainly the past two years), but there lacks a comprehensive survey of this remarkable and swift progress. Our survey aims to introduce new researchers to this topic, provide a useful reference for related works, and stimulate future research directions through our discussion section. Apart from the presented papers, we aim to constantly update the latest relevant papers along with corresponding implementations at .},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {90},
numpages = {34},
keywords = {diffusion probabilistic models, generative adversarial network, implicit neural representation, deep generative models, 3D-aware image synthesis}
}

@article{10.1145/3538649,
author = {Galteri, Leonardo and Seidenari, Lorenzo and Bongini, Pietro and Bertini, Marco and Bimbo, Alberto Del},
title = {LANBIQUE: LANguage-based Blind Image QUality Evaluation},
year = {2022},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3538649},
doi = {10.1145/3538649},
abstract = {Image quality assessment is often performed with deep networks that are fine-tuned to regress a human provided quality score of a given image. Usually, this approach may lack generalization capabilities and, while being highly precise on similar image distribution, it may yield lower correlation on unseen distortions. In particular, they show poor performances, whereas images corrupted by noise, blur, or compression have been restored by generative models. As a matter of fact, evaluation of these generative models is often performed providing anecdotal results to the reader. In the case of image enhancement and restoration, reference images are usually available. Nevertheless, using signal based metrics often leads to counterintuitive results: Highly natural crisp images may obtain worse scores than blurry ones. However, blind reference image assessment may rank images reconstructed with GANs higher than the original undistorted images. To avoid time-consuming human-based image assessment, semantic computer vision tasks may be exploited instead. In this article, we advocate the use of language generation tasks to evaluate the quality of restored images. We refer to our assessment approach as LANguage-based Blind Image QUality Evaluation (LANBIQUE). We show experimentally that image captioning, used as a downstream task, may serve as a method to score image quality, independently of the distortion process that affects the data. Captioning scores are better aligned with human rankings with respect to classic signal based or No-reference image quality metrics. We show insights on how the corruption, by artefacts, of local image structure may steer image captions in the wrong direction.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = oct,
articleno = {116},
numpages = {19},
keywords = {generative models evaluation, GAN, image quality evaluation, image captioning, Image quality enhancement}
}

@inproceedings{10.1109/MICRO56248.2022.00051,
author = {Hong, Seongmin and Moon, Seungjae and Kim, Junsoo and Lee, Sungjae and Kim, Minsub and Lee, Dongsoo and Kim, Joo-Young},
title = {DFX: A Low-Latency Multi-FPGA Appliance for Accelerating Transformer-Based Text Generation},
year = {2023},
isbn = {9781665462723},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MICRO56248.2022.00051},
doi = {10.1109/MICRO56248.2022.00051},
abstract = {Transformer is a deep learning language model widely used for natural language processing (NLP) services in datacenters. Among transformer models, Generative Pre-trained Transformer (GPT) has achieved remarkable performance in text generation, or natural language generation (NLG), which needs the processing of a large input context in the summarization stage, followed by the generation stage that produces a single word at a time. The conventional platforms such as GPU are specialized for the parallel processing of large inputs in the summarization stage, but their performance significantly degrades in the generation stage due to its sequential characteristic. Therefore, an efficient hardware platform is required to address the high latency caused by the sequential characteristic of text generation.In this paper, we present DFX, a multi-FPGA acceleration appliance that executes GPT-2 model inference end-to-end with low latency and high throughput in both summarization and generation stages. DFX uses model parallelism and optimized dataflow that is model-and-hardware-aware for fast simultaneous workload execution among devices. Its compute cores operate on custom instructions and provide GPT-2 operations end-to-end. We implement the proposed hardware architecture on four Xilinx Alveo U280 FPGAs and utilize all of the channels of the high bandwidth memory (HBM) and the maximum number of compute resources for high hardware efficiency. DFX achieves 5.58× speedup and 3.99× energy efficiency over four NVIDIA V100 GPUs on the modern GPT-2 model. DFX is also 8.21× more cost-effective than the GPU appliance, suggesting that it is a promising solution for text generation workloads in cloud datacenters.},
booktitle = {Proceedings of the 55th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {616–630},
numpages = {15},
keywords = {model parallelism, multi-FPGA acceleration, datacenter, text generation, GPT, natural language processing},
location = {Chicago, Illinois, USA},
series = {MICRO '22}
}

@inproceedings{10.1145/3605731.3608930,
author = {Cho, Wendy K. Tam and Liu, Yan},
title = {A GPU-Accelerated Population Generation, Sorting, and Mutation Kernel for an Optimization-Based Causal Inference Model},
year = {2023},
isbn = {9798400708428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605731.3608930},
doi = {10.1145/3605731.3608930},
abstract = {We develop a GPU-accelerated machine learning generative adversarial network model that can be used with observational data for the purpose of constructing causal inferences. The theoretical basis of our machine learning model is novel and is conceptualized to be operable and scalable for high performance computing platforms. Our GPU-accelerated code enables large-scale parallelization of the computation within a common and accessible computing environment. This will expand the reach of our model and empower research in new substantive domains while maintaining the underlying theoretical properties.},
booktitle = {Proceedings of the 52nd International Conference on Parallel Processing Workshops},
pages = {167–171},
numpages = {5},
keywords = {Causal Inference, Optimization, Subset Selection},
location = {Salt Lake City, UT, USA},
series = {ICPP Workshops '23}
}

@inproceedings{10.1145/3531146.3533138,
author = {Hundt, Andrew and Agnew, William and Zeng, Vicky and Kacianka, Severin and Gombolay, Matthew},
title = {Robots Enact Malignant Stereotypes},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533138},
doi = {10.1145/3531146.3533138},
abstract = {Stereotypes, bias, and discrimination have been extensively documented in Machine Learning (ML) methods such as Computer Vision (CV)&nbsp;[18, 80], Natural Language Processing (NLP)&nbsp;[6], or both, in the case of large image and caption models such as OpenAI CLIP&nbsp;[14]. In this paper, we evaluate how ML bias manifests in robots that physically and autonomously act within the world. We audit one of several recently published CLIP-powered robotic manipulation methods, presenting it with objects that have pictures of human faces on the surface which vary across race and gender, alongside task descriptions that contain terms associated with common stereotypes. Our experiments definitively show robots acting out toxic stereotypes with respect to gender, race, and scientifically-discredited physiognomy, at scale. Furthermore, the audited methods are less likely to recognize Women and People of Color. Our interdisciplinary sociotechnical analysis synthesizes across fields and applications such as Science Technology and Society (STS), Critical Studies, History, Safety, Robotics, and AI. We find that robots powered by large datasets and Dissolution Models (sometimes called “foundation models”, e.g. CLIP) that contain humans risk physically amplifying malignant stereotypes in general; and that merely correcting disparities will be insufficient for the complexity and scale of the problem. Instead, we recommend that robot learning methods that physically manifest stereotypes or other harmful outcomes be paused, reworked, or even wound down when appropriate, until outcomes can be proven safe, effective, and just. Finally, we discuss comprehensive policy changes and the potential of new interdisciplinary research on topics like Identity Safety Assessment Frameworks and Design Justice to better understand and address these harms.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {743–756},
numpages = {14},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{10.1145/3508352.3549437,
author = {Chen, Hanning and Issa, Mariam and Ni, Yang and Imani, Mohsen},
title = {DARL: Distributed Reconfigurable Accelerator for Hyperdimensional Reinforcement Learning},
year = {2022},
isbn = {9781450392174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3508352.3549437},
doi = {10.1145/3508352.3549437},
abstract = {Reinforcement Learning (RL) is a powerful technology to solve decisionmaking problems such as robotics control. Modern RL algorithms, i.e., Deep Q-Learning, are based on costly and resource hungry deep neural networks. This motivates us to deploy alternative models for powering RL agents on edge devices. Recently, brain-inspired Hyper-Dimensional Computing (HDC) has been introduced as a promising solution for lightweight and efficient machine learning, particularly for classification.In this work, we develop a novel platform capable of real-time hyperdimensional reinforcement learning. Our heterogeneous CPU-FPGA platform, called DARL, maximizes FPGA's computing capabilities by applying hardware optimizations to hyperdimensional computing's critical operations, including hardware-friendly encoder IP, the hypervector chunk fragmentation, and the delayed model update. Aside from hardware innovation, we also extend the platform to basic single-agent RL to support multi-agents distributed learning. We evaluate the effectiveness of our approach on OpenAI Gym tasks. Our results show that the FPGA platform provides on average 20× speedup compared to current state-of-the-art hyperdimensional RL methods running on Intel Xeon 6226 CPU. In addition, DARL provides around 4.8× faster and 4.2× higher energy efficiency compared to the state-of-the-art RL accelerator while ensuring a better or comparable quality of learning.},
booktitle = {Proceedings of the 41st IEEE/ACM International Conference on Computer-Aided Design},
articleno = {84},
numpages = {9},
location = {San Diego, California},
series = {ICCAD '22}
}

@inproceedings{10.1145/3611643.3616322,
author = {Wang, Bo and Li, Ruishi and Li, Mingkai and Saxena, Prateek},
title = {TransMap: Pinpointing Mistakes in Neural Code Translation},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3616322},
doi = {10.1145/3611643.3616322},
abstract = {Automated code translation between programming languages can greatly reduce the human effort needed in learning new languages or in migrating code. Recent neural machine translation models, such as Codex, have been shown to be effective on many code generation tasks including translation. However, code produced by neural translators often has semantic mistakes. These mistakes are difficult to eliminate from the neural translator itself because the translator is a black box, which is difficult to interpret or control compared to rule-based transpilers. We propose the first automated approach to pinpoint semantic mistakes in code obtained after neural code translation. Our techniques are implemented in a prototype tool called TransMap which translates Python to JavaScript, both of which are popular scripting languages. On our created micro-benchmarks of Python programs with 648 semantic mistakes in total, TransMap accurately pinpoints the correct location for a fix for 87.96%, often highlighting 1-2 lines for the user to inspect per mistake. We report on our experience in translating 5 Python libraries with up to 1k lines of code with TransMap. Our preliminary user study suggests that TransMap can reduce the time for fixing semantic mistakes by around 70% compared to using a standard IDE with debuggers.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {999–1011},
numpages = {13},
keywords = {Code Translation, Large Language Models, Semantic Mistakes},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3625704.3625744,
author = {Chan, Victor K. Y.},
title = {Evaluation of e-learning platforms using artificial intelligence (AI) robots: Are the AI robots consistent},
year = {2023},
isbn = {9798400709142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625704.3625744},
doi = {10.1145/3625704.3625744},
abstract = {This article aims to explore the consistency between a few popular generative AI robots in the evaluation of e-learning platforms. The three robots adopted in the study were GPT-4, Sage, and Dragonfly, which were requested to award rating scores to the six major dimensions, namely (1) features and capabilities, (2) ease of use and customization, (3) cost, (4) security, (5) customer support, and (6) scalability, of 10 to 20 currently most popular e-learning platforms. For each of the three robots, the minimum, the maximum, the range, and the standard deviation of the rating scores for each of the six dimensions were computed across all the e-learning platforms. The rating score difference for each of the six dimensions between any pair of robots was calculated for each platform. The mean of the absolute value, the minimum, the maximum, the range, and the standard deviation of the differences for each dimensions between each pair of robots were calculated across all platforms. Finally, a Cronbach alpha coefficient of the rating scores was computed for each of the six dimensions between all the three robots across all the e-learning platforms. The computational results were to reveal whether the three robots accorded discrimination in evaluating each dimension across the platforms and whether there was consistency between the three robots in evaluating each dimension across the platforms. Among some auxiliary results, it was found that the evaluation by the three robots was severely inconsistent for the two dimensions cost and security, inconsistent to a lesser extent for the dimension scalability, and consistent for the remaining three dimensions.},
booktitle = {Proceedings of the 7th International Conference on Education and Multimedia Technology},
pages = {96–100},
numpages = {5},
keywords = {E-learning platforms, artificial intelligence, consistency, evaluation, learning management systems},
location = {Tokyo, Japan},
series = {ICEMT '23}
}

@inproceedings{10.1145/3617233.3617246,
author = {Beddiar, Djamila Romaissa and Oussalah, Mourad and Seppanen, Tapio},
title = {Retrieved Generative Captioning for Medical Images},
year = {2023},
isbn = {9798400709128},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617233.3617246},
doi = {10.1145/3617233.3617246},
abstract = {Understanding the content of medical images and mapping it into text is a very trending topic in intersection of two main domains; computer vision and natural language processing. This is known as medical image captioning, which plays a vital role in developing automatic systems for diagnosis purposes. Recent research in the medical field provided promising results for both deep-learning based and retrieval-based models for image captioning. However, each one of them has its own drawbacks, that can be overcome if combined. In addition, existing diagnosis systems are still not able to provide enough explanation about the findings, which might be similar to what a physician can deliver. In this regard, we present in this paper a combination of a generative deep-learning based method and a retrieval-based model for medical image captioning. First, we train an attention-based encoder-decoder model to generate new captions for given medical images. Then, we fit the generated caption from the generative model to the retrieval-based model, which retrieves the most similar caption from the training database. This multi-stage approach allows us to generate most important words of the caption (with the generative model) and then search for the most close caption that includes such words (with the retrieval-based model). Another way of combining both models is by selecting at each time the caption with highest score among generated and retrieved captions. We evaluate our proposed model on the medical ROCO dataset for which we achieved a BLEU-4 score of 07.89 for the radiology class and 03.19 for the out-of-class data, for the multi-stage model. Similarly, best results were achieved for the fused model (predicted caption is the best among generated and retrieved) where we obtain a BLEU-4 values of 18.61 for the radiology class and 13.28 for the out-of-class data. Even though our results seem to be low, they outperformed the state-of-the-art results on the same dataset and could be further improved.},
booktitle = {Proceedings of the 20th International Conference on Content-Based Multimedia Indexing},
pages = {48–54},
numpages = {7},
keywords = {Generative-based Captioning, Image Captioning, Medical Images, Neural Networks, Retrieval-based Captioning},
location = {Orleans, France},
series = {CBMI '23}
}

@inproceedings{10.1145/3580305.3599373,
author = {Zhao, Wentao and Wu, Qitian and Yang, Chenxiao and Yan, Junchi},
title = {GraphGLOW: Universal and Generalizable Structure Learning for Graph Neural Networks},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599373},
doi = {10.1145/3580305.3599373},
abstract = {Graph structure learning is a well-established problem that aims at optimizing graph structures adaptive to specific graph datasets to help message passing neural networks (i.e., GNNs) to yield effective and robust node embeddings. However, the common limitation of existing models lies in the underlying closed-world assumption: the testing graph is the same as the training graph. This premise requires independently training the structure learning model from scratch for each graph dataset, which leads to prohibitive computation costs and potential risks for serious over-fitting. To mitigate these issues, this paper explores a new direction that moves forward to learn a universal structure learning model that can generalize across graph datasets in an open world. We first introduce the mathematical definition of this novel problem setting, and describe the model formulation from a probabilistic data-generative aspect. Then we devise a general framework that coordinates a single graph-shared structure learner and multiple graph-specific GNNs to capture the generalizable patterns of optimal message-passing topology across datasets. The well-trained structure learner can directly produce adaptive structures for unseen target graphs without any fine-tuning. Across diverse datasets and various challenging cross-graph generalization protocols, our experiments show that even without training on target graphs, the proposed model i) significantly outperforms expressive GNNs trained on input (non-optimized) topology, and ii) surprisingly performs on par with state-of-the-art models that independently optimizes adaptive structures for specific target graphs, with notably orders-of-magnitude acceleration for training on the target graph.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3525–3536},
numpages = {12},
keywords = {out-of-distribution generalization, network representation learning, graph structure learning, graph neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3524459.3527350,
author = {Lajkó, Márk and Csuvik, Viktor and Vidács, László},
title = {Towards JavaScript program repair with generative pre-trained transformer (GPT-2)},
year = {2022},
isbn = {9781450392853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524459.3527350},
doi = {10.1145/3524459.3527350},
abstract = {The goal of Automated Program Repair (APR) is to find a fix to software bugs, without human intervention. The so-called Generate and Validate (G&amp;V) approach deemed to be the most popular method in the last few years, where the APR tool creates a patch and it is validated against an oracle. Recent years for Natural Language Processing (NLP) were of great interest, with new pre-trained models shattering records on tasks ranging from sentiment analysis to question answering. Usually these deep learning models inspire the APR community as well. These approaches usually require a large dataset on which the model can be trained (or fine-tuned) and evaluated. The criterion to accept a patch depends on the underlying dataset, but usually the generated patch should be exactly the same as the one created by a human developer. As NLP models are more and more capable to form sentences, and the sentences will form coherent paragraphs, the APR tools are also better and better at generating syntactically and semantically correct source code. As the Generative Pre-trained Transformer (GPT) model is now available to everyone thanks to the NLP and AI research community, it can be fine-tuned to specific tasks (not necessarily on natural language). In this work we use the GPT-2 model to generate source code, to the best of our knowledge, the GPT-2 model was not used for Automated Program Repair so far. The model is fine-tuned for a specific task: it has been taught to fix JavaScript bugs automatically. To do so, we trained the model on 16863 JS code snippets, where it could learn the nature of the observed programming language. In our experiments we observed that the GPT-2 model was able to learn how to write syntactically correct source code almost on every attempt, although it failed to learn good bug-fixes in some cases. Nonetheless it was able to generate the correct fixes in most of the cases, resulting in an overall accuracy up to 17.25%.},
booktitle = {Proceedings of the Third International Workshop on Automated Program Repair},
pages = {61–68},
numpages = {8},
keywords = {machine learning, code refinement, automated program repair, JavaScript, GPT},
location = {Pittsburgh, Pennsylvania},
series = {APR '22}
}

@inproceedings{10.1145/3520304.3534048,
author = {Wang, Gabriel and Thite, Anish and Talebi, Rodd and D'Achille, Anthony and Mussa, Alex and Zutty, Jason},
title = {Evolving SimGANs to improve abnormal electrocardiogram classification},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3534048},
doi = {10.1145/3520304.3534048},
abstract = {Machine Learning models often require a large amount of data in order to be successful. This is troublesome in domains where collecting real-world data is difficult and/or expensive. Data simulators do exist, but they do not sufficiently reflect the real world data due to factors such as a lack of real-world noise. Generative adversarial networks (GANs) have been modified to refine simulated image data to better fit real world characteristics, using the SimGAN method. While evolutionary computing has been used for GAN evolution, there are currently no frameworks that can evolve a SimGAN. In this paper we (1) extend the SimGAN method to refine one-dimensional data, (2) modify Easy Cartesian Genetic Programming (ezCGP), an evolutionary computing framework, to create SimGANs that more accurately refine simulated data, and (3) create new feature-based quantitative metrics to evaluate refined data. We also use our framework to augment an electrocardiogram (ECG) dataset, a domain that suffers from the issues previously mentioned. In particular, while healthy ECGs can be simulated there are no current simulators of abnormal ECGs. We show that by using an evolved SimGAN to refine simulated healthy ECG data to mimic real-world abnormal ECGs, we can improve the accuracy of ECG classifiers.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1887–1894},
numpages = {8},
keywords = {automated machine learning, datasets, general adversarial networks, neural networks},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@inproceedings{10.1145/3536169.3537785,
author = {Sosa, Ricardo and Gibbons, Andrew and O'Riordan, Emma and Iorangi, Keu and Crowe, Andy and Gibson, Leanne and Harris, Sam and Badenhorst, Daniel},
title = {Food for Advanced Computational Thinking: Critical and Creative Approaches to Technology at Te Kura Taurua Manurewa},
year = {2022},
isbn = {9781450393881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3536169.3537785},
doi = {10.1145/3536169.3537785},
abstract = {This paper focuses on a participatory activity that is part of an ongoing partnership formed six years ago between teachers and academics to study creative technology approaches to youth participation. By focusing on a food-based activity in an after-school maker space, we reflect on the pedagogical and methodological innovations, and the ethical and aesthetic qualities of food-based activities for participatory design. The session brought together students and teachers to form a generative dialogue around computation and automation while preparing and sharing food. The results suggest opportunities to rethink current curricular, pedagogical, and education policy strategies. Recommendations for organizers to prepare generative activities where food is used as a design material close the paper.},
booktitle = {Proceedings of the Participatory Design Conference 2022 - Volume 1},
pages = {109–119},
numpages = {11},
location = {Newcastle upon Tyne, United Kingdom},
series = {PDC '22}
}

@inproceedings{10.1145/3575828.3575834,
author = {Qu, Shenghe},
title = {Research and Analysis of Knee Joint Prosthesis Design Based on 3D Simulation Technology Based on Computer Method},
year = {2023},
isbn = {9781450397247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575828.3575834},
doi = {10.1145/3575828.3575834},
abstract = {Knee joint was reconstructed and tibial plateau parameters were measured and to explore the difference of human evolutionary rhythm, to analyze the matching degree of imported knee prosthesis and Chinese tibial plateau osteotomy plane, and to analyze its influence on the design of knee prosthesis. 3D reconstruction refers to the establishment of mathematical models suitable for computer representation and processing of 3D objects, which is the basis of processing, operating and analyzing its properties under the computer environment. The basic research on the 3D structure of the knee joint is helpful for a more comprehensive understanding of the evolution of the human knee joint and the structural differences between people. In this study, 60 patients (120 knees) with non-knee diseases and 20 healthy volunteers (40 knees) were selected from the Department of Orthopedics, Beijing Chaoyang Hospital, Capital Medical University from January 2018 to January 2020, including 46 males (92 knees) and 34 females (68 knees), aged 24-72 years, with an average age of 46.8 years. Bilateral knee CT scan and 3D reconstruction were performed, and 3d tibial images reconstructed were rotated and cut on HP Advantage Workstation 4.3 advanced image Workstation, and linear parameters such as transverse diameter and anteroposterior diameter of tibial plateau osteotomy surface were measured and calculated, and the differences of parameters between men and women were compared. Statistical analysis was performed. The matching degree of three imported components (depuy-PFC Sigma, Link-Gemini MK-II and Zimmer-Nexgen) with the Chinese tibial plateau tolerance surface was evaluated by using the 5mm tolerance range method. The matching rates were compared by χ2 test. The mean cross diameter of tibial plateau was (74.22±2.84)mm in 80 Chinese adults with 160 knees, and the difference was statistically significant (t=12.36, P &lt; 0.01). The mean diameter was (48.15±2.58) mm, and the difference was statistically significant (t=9.48, P &lt; 0.01). There was no significant difference in the matching rates between prosthesis A and B (χ2=1.027, P=0.184), but there were significant differences in the matching rates between prosthesis A and C (χ2= 8.050, P=0.003), and between prosthesis B and C (χ2= 14.672, P=0.000). There is a significant difference between Chinese and Caucasian in the normal bearing surface of tibial plateau. The matching degree between imported knee prosthesis and Chinese tibial plateau osteotomy is generally low. The tibial plateau section of Chinese is relatively round, which suggests that in the course of human evolution, Chinese walked from four limbs to upright earlier than Caucasians.},
booktitle = {Proceedings of the 2022 7th International Conference on Systems, Control and Communications},
pages = {29–36},
numpages = {8},
keywords = {replacement, knee, Three-dimensional reconstruction, Prosthesis, Human evolution, Cover rate, Arthroplasty},
location = {Chongqing, China},
series = {ICSCC '22}
}

@inproceedings{10.1145/3609026.3615580,
author = {Xie, Ningning},
title = {Haskell for Choice-Based Learning (Keynote)},
year = {2023},
isbn = {9798400702983},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609026.3615580},
doi = {10.1145/3609026.3615580},
abstract = {Machine learning has achieved many successes during the past decades, spanning domains of game-playing, protein folding, competitive programming, and many others. However, while there have been major efforts in building programming techniques and frameworks for machine learning programming, there has been very little study of general language design for machine learning programming. 

We pursue such a study in this talk, focusing on choice-based learning, particularly where choices are driven by optimizations. This includes widely-used decision-making models and techniques (e.g., Markov decision processes or gradient descent) which provide frameworks for describing systems in terms of choices (e.g., actions or parameters) and their resulting feedback as losses (dually, rewards). 

We propose and give evidence for the following thesis: languages for choice-based learning can be obtained by combining two paradigms, algebraic effects and handlers, and the selection monad. We provide a prototype implementation as a Haskell library and present a variety of programming examples for choice-based learning: stochastic gradient descent, hyperparameter tuning, generative adversarial networks, and reinforcement learning.},
booktitle = {Proceedings of the 16th ACM SIGPLAN International Haskell Symposium},
pages = {1},
numpages = {1},
location = {Seattle, WA, USA},
series = {Haskell 2023}
}

@article{10.1145/3597434,
author = {Tang, Zhenjun and Chen, Zhiyuan and Li, Zhixin and Zhong, Bineng and Zhang, Xianquan and Zhang, Xinpeng},
title = {Unifying Dual-Attention and Siamese Transformer Network for Full-Reference Image Quality Assessment},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1551-6857},
url = {https://doi.org/10.1145/3597434},
doi = {10.1145/3597434},
abstract = {Image Quality Assessment (IQA) is a critical task of computer vision. Most Full-Reference (FR) IQA methods have limitation in the accurate prediction of perceptual qualities of the traditional distorted images and the Generative Adversarial Networks (GANs) based distorted images. To address this issue, we propose a novel method by Unifying Dual-Attention and Siamese Transformer Network (UniDASTN) for FR-IQA. An important contribution is the spatial attention module composed of a Siamese Transformer Network and a feature fusion block. It can focus on significant regions and effectively maps the perceptual differences between the reference and distorted images to a latent distance for distortion evaluation. Another contribution is the dual-attention strategy that exploits channel attention and spatial attention to aggregate features for enhancing distortion sensitivity. In addition, a novel loss function is designed by jointly exploiting Mean Square Error (MSE), bidirectional Kullback–Leibler divergence, and rank order of quality scores. The designed loss function can offer stable training and thus enables the proposed UniDASTN to effectively learn visual perceptual image quality. Extensive experiments on standard IQA databases are conducted to validate the effectiveness of the proposed UniDASTN. The IQA results demonstrate that the proposed UniDASTN outperforms some state-of-the-art FR-IQA methods on the LIVE, CSIQ, TID2013, and PIPAL databases.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jul,
articleno = {205},
numpages = {24},
keywords = {image quality assessment (IQA), dual-attention, siamese network, Transformer}
}

@inproceedings{10.1145/3581783.3613859,
author = {Wang, Xin and Chen, Hong and Zhu, Wenwu},
title = {Disentangled Representation Learning for Multimedia},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3613859},
doi = {10.1145/3581783.3613859},
abstract = {Disentangled Representation Learning (DRL) aims to learn a model capable of identifying and disentangling the underlying factors hidden in the observable data in representation form. The process of separating underlying factors of variation into variables with semantic meaning benefits in learning explainable representations of data, which imitates the meaningful understanding process of humans when observing an object or relation. As a general learning strategy, DRL has demonstrated its power in improving the model explainability, controllability, robustness, as well as generalization capacity in a wide range of scenarios such as computer vision, natural language processing, data mining etc. In this tutorial, we comprehensively present DRL from various aspects including motivations, definitions, methodologies, evaluations, applications and model designs for multimedia. We discuss works on DRL based on two well-recognized definitions, i.e., Intuitive Definition and Group Theory Definition. We further categorize the methodologies for DRL into four groups, i.e., Traditional Statistical Approaches, Variational Auto-encoder Based Approaches, Generative Adversarial Networks Based Approaches, Hierarchical Approaches and Other Approaches. We also analyze principles to design different DRL models that may benefit different tasks in practical multimedia applications. Finally, we point out challenges in DRL as well as potential research directions deserving future investigations. We believe this tutorial may provide insights for promoting the DRL research in the multimedia community.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {9702–9704},
numpages = {3},
keywords = {disentangled representation learning, learning methodology, multimedia applications},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3610548.3618228,
author = {Abdelreheem, Ahmed and Eldesokey, Abdelrahman and Ovsjanikov, Maks and Wonka, Peter},
title = {Zero-Shot 3D Shape Correspondence},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610548.3618228},
doi = {10.1145/3610548.3618228},
abstract = {We propose a novel zero-shot approach to computing correspondences between 3D shapes. Existing approaches mainly focus on isometric and near-isometric shape pairs (e.g., human vs. human), but less attention has been given to strongly non-isometric and inter-class shape matching (e.g., human vs. cow). To this end, we introduce a fully automatic method that exploits the exceptional reasoning capabilities of recent foundation models in language and vision to tackle difficult shape correspondence problems. Our approach comprises multiple stages. First, we classify the 3D shapes in a zero-shot manner by feeding rendered shape views to a language-vision model (e.g., BLIP2) to generate a list of class proposals per shape. These proposals are unified into a single class per shape by employing the reasoning capabilities of ChatGPT. Second, we attempt to segment the two shapes in a zero-shot manner, but in contrast to the co-segmentation problem, we do not require a mutual set of semantic regions. Instead, we propose to exploit the in-context learning capabilities of ChatGPT to generate two different sets of semantic regions for each shape and a semantic mapping between them. This enables our approach to match strongly non-isometric shapes with significant differences in geometric structure. Finally, we employ the generated semantic mapping to produce coarse correspondences that can further be refined by the functional maps framework to produce dense point-to-point maps. Our approach, despite its simplicity, produces highly plausible results in a zero-shot manner, especially between strongly non-isometric shapes.},
booktitle = {SIGGRAPH Asia 2023 Conference Papers},
articleno = {59},
numpages = {11},
keywords = {3D Semantic Segmentation, 3D Shape Matching, Deep Neural Networks, Zero-Shot Shape Correspondence},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3573942.3573980,
author = {Zhu, Tianyi and Liu, Huan},
title = {A Review of Research Based on Generative Adversarial Networks},
year = {2023},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573942.3573980},
doi = {10.1145/3573942.3573980},
abstract = {In recent years, with the rapid development of deep learning, Generative Adversarial Network (GAN), as one of the unsupervised learning, has also gradually developed into one of the current research hotspots in the field of deep learning. GAN has more powerful feature learning and feature representation capabilities than traditional machine learning algorithms. GAN is currently showing great potential in deep learning, especially in the field of computer vision. In this paper, we discuss and analyse the basic principles of the basic GAN model and its advantages and disadvantages; introduce the derivative models of GAN and their limitations; summarise the application results of GAN in various fields such as image reconstruction, text description image generation, audio generation, migration learning, etc. Finally, this paper also presents some prospects for future research directions in this field.},
booktitle = {Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {988–994},
numpages = {7},
keywords = {Data generation, Generative Adversarial Networks, Review},
location = {Xiamen, China},
series = {AIPR '22}
}

@inproceedings{10.1145/3581783.3612508,
author = {Wang, Jionghao and Chen, Ziyu and Ling, Jun and Xie, Rong and Song, Li},
title = {360-Degree Panorama Generation from Few Unregistered NFoV Images},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612508},
doi = {10.1145/3581783.3612508},
abstract = {360° panoramas are extensively utilized as environmental light sources in computer graphics. However, capturing a 360° × 180° panorama poses challenges due to the necessity of specialized and costly equipment, and additional human resources. Prior studies develop various learning-based generative methods to synthesize panoramas from a single Narrow Field-of-View (NFoV) image, but they are limited in alterable input patterns, generation quality, and controllability. To address these issues, we propose a novel pipeline called PanoDiff, which efficiently generates complete 360° panoramas using one or more unregistered NFoV images captured from arbitrary angles. Our approach has two primary components to overcome the limitations. Firstly, a two-stage angle prediction module to handle various numbers of NFoV inputs. Secondly, a novel latent diffusion-based panorama generation model uses incomplete panorama and text prompts as control signals and utilizes several geometric augmentation schemes to ensure geometric properties in generated panoramas. Experiments show that PanoDiff achieves state-of-the-art panoramic generation quality and high controllability, making it suitable for applications such as content editing.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {6811–6821},
numpages = {11},
keywords = {360-degree panorama, generative models, image pose estimation, latent diffusion, multimodal models},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3550469.3555425,
author = {Leimer, Kurt and Guerrero, Paul and Weiss, Tomer and Musialski, Przemyslaw},
title = {LayoutEnhancer: Generating Good Indoor Layouts from Imperfect Data},
year = {2022},
isbn = {9781450394703},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550469.3555425},
doi = {10.1145/3550469.3555425},
abstract = {We address the problem of indoor layout synthesis, which is a topic of continuing research interest in computer graphics. The newest works made significant progress using data-driven generative methods; however, these approaches rely on suitable datasets. In practice, desirable layout properties may not exist in a dataset, for instance, specific expert knowledge can be missing in the data. We propose a method that combines expert knowledge, for example, knowledge about ergonomics, with a data-driven generator based on the popular Transformer architecture. The knowledge is given as differentiable scalar functions, which can be used both as weights or as additional terms in the loss function. Using this knowledge, the synthesized layouts can be biased to exhibit desirable properties, even if these properties are not present in the dataset. Our approach can also alleviate problems of lack of data and imperfections in the data. Our work aims to improve generative machine learning for modeling and provide novel tools for designers and amateurs for the problem of interior layout creation.},
booktitle = {SIGGRAPH Asia 2022 Conference Papers},
articleno = {27},
numpages = {8},
keywords = {indoor layout synthesis, interior design, neural networks},
location = {Daegu, Republic of Korea},
series = {SA '22}
}

@inproceedings{10.1145/3583133.3596362,
author = {Babaagba, Kehinde O. and Wylie, Jordan},
title = {An Evolutionary based Generative Adversarial Network Inspired Approach to Defeating Metamorphic Malware},
year = {2023},
isbn = {9798400701207},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583133.3596362},
doi = {10.1145/3583133.3596362},
abstract = {Defeating dangerous families of malware like polymorphic and metamorphic malware have become well studied due to their increased attacks on computer systems and network. Traditional Machine Learning (ML) models have been used in detecting this malware, however they are often not resistant to future attacks. In this paper, an Evolutionary based Generative Adversarial Network (GAN) inspired approach is proposed as a step towards defeating metamorphic malware. This method uses an Evolutionary Algorithm as a generator to create malware that are designed to fool a detector, a deep learning model into classifying them as benign. We employ a personal information stealing malware family (Dougalek) as a testbed, selected based on its malicious payload and evaluate the samples generated based on their adversarial accuracy, measured based on the number of Antivirus (AV) engines they are able to fool and their ability to fool a set of ML detectors (k-Nearest Neighbors algorithm, Support Vector Machine, Decision Trees, and Multi-Layer Perceptron). The results show that the adversarial samples are on average able to fool 63% of the AV engines and the ML detectors are susceptible to the new mutants achieving an accuracy between 60%-77%.},
booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
pages = {1753–1759},
numpages = {7},
keywords = {generative adversarial network, evolutionary algorithm, metamorphic malware},
location = {Lisbon, Portugal},
series = {GECCO '23 Companion}
}

@inproceedings{10.1145/3600211.3604744,
author = {Affsprung, Daniel},
title = {The ELIZA Defect: Constructing the Right Users for Generative AI},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604744},
doi = {10.1145/3600211.3604744},
abstract = {Artificial intelligence (AI) is at the center of debates on what kind of future we want and how to bring it about. But AI ethics is not only a technical risk assessment and accounting effort, or an application of general principles to stable artifacts. It is also a social self-diagnosis, a contested and contestable assertion of values and desirable futures, and a selective understanding of the nature of AI in its different forms. In expressions of concern and efforts at preparation for increasingly powerful AI tools, we can trace the ways we imagine ourselves and our society to be compatible with AI's promises and susceptible to its dangers. The problems we notice, and the solutions we offer, arise from the interaction of these imagined elements.The socially embedded efficacy of AI tools leads many commentators to imagine their risks specifically in conjunction with understandings of society as it currently is and imaginations of how it can and should exist in the future [1]. The sense-making moves performed in the wake of developments in generative AI are thus a site to examine the movement and uses of different concepts brought together in this domain: the human, rationality, and the place of expertise. As these sense-making efforts are carried out, they become constraints on how the risks of generative AI can be noticed and understood.The problems raised by generative AI are so fundamentally tied to its performance as a simulator of human interpersonal acts that we should ask: where is the risk of generative AI located, such that the utility and the safety of the tools can be preserved after troubling cases? Boundaries between malicious deception and magnificent design are unclear without an answer to this question. Thus, to fit generative AI into our world, we are trying to answer it; this is one goal of efforts at regulation which seeks to allow the benefits of imitation to arrive while avoiding the harms of deception. In the current regulation, reporting, and corporate responses to generative AI, the challenge of safely introducing generative AI is being approached in large part as a challenge of producing the right kind of knowledge in its users.Below is a summary of my findings from three cases, chosen to investigate the following question: What ways, or whose ways, of using, knowing, and understanding generative AI are being offered as appropriate? I examine the EU AI Act language reflecting disclosure requirements for interactions with generative AI, responses to a chatbot-facilitated suicide in Belgium, and reactions to expert claims of a chatbot's sentience. In the first two cases, AI-generated content is problematic insofar as users are uninformed about its provenance or maliciously deceived by it, while users who know they are interacting with AI but behave problematically are designated as deluded or irrational. In the third case, a Google engineer who presents evidence to support claims that AI is sentient is censured as nationwide reporting denounces his claim against an expert consensus from which he is ejected. In all three cases, challenges facing widespread generative AI development and use are avoided by attending to the knowledge and understanding of those who use them rather than the functioning of the tools themselves.The EU AI Act is illuminating as a general and authoritative account of how AI interactions can be made safe, requiring first and foremost that users are informed. [2, 3] The AI Act is useful in the present paper as it shows the effort to match and reconcile a new technology with an extant set of values, chief among which is autonomy. Its reliance on disclosure reflects a general sense that harms are acceptable or unacceptable not on the basis of outcomes but based on the degree of autonomy possessed by the actors in question. Rational actors in a simulated environment are responsible for the effects of the simulation, so long as they are informed of the nature of that environment and have essentially consented to consume deceptive or false content. The other two cases I examine explore this very issue, of problematic understandings and behavior on the part of knowing users.The first of these is the case of the Belgian man. After his suicide responses from the company which provided the chatbot, media [4, 5, 6] and government [5], and prominent expert AI ethics commentary [7] characterized it as arising because the user was vulnerable and consequently did not relate to the bot in the right way. While the chatbot's emotionally charged language was seen as a part of the problem, in the reporting on this event the unanimous emphasis on the man's mental state presents the risk as arising in an interaction, in a pathological mistake of the user, rather than in the tool.Locating risk is a necessary and immensely powerful, if often unexamined step which precedes intervention in a worrisome state of affairs: where we locate risk is where we intervene. If the risk accompanying generative AI is located in the minds of uninformed or misapprehending users, disclosures and disclaimers are indeed sensible interventions. In this conception, when knowledge fails to protect the user, it is not a failed safeguard but a bad user. Problematizing user understandings in this way provides an exonerating resource for the companies providing these tools and suggests the rectitude of expert authority on the nature of these tools, by linking delays and dangers in generative AI to users who do not abide by the (strategically underdetermined) expert consensus on generative AI's accuracy, capabilities, and nature.My third case examines how the expert consensus around generative AI is maintained through the story of Blake Lemoine, who publicly announced his belief that Google's LaMDA model had become sentient and was presented by major media outlets and experts as deluded [8, 9, 10, 11, 12, 13]. In the media and corporate response to Lemoine, wherein Google questioned his sanity before firing him [13], we see his ejection from the community of experts permitted to call for greater scrutiny based on qualitative changes in the nature of these models. He becomes a layperson on account of his anthropomorphizing error. In this act of boundary work [14], policing who is in the body of experts qualified to decide on the sentience of the chatbot, and the nature of AI models in general, we must notice how small this group truly is and what Lemoine's ejection preserves. If safeguards like those Lemoine called for should follow on the kind of change he claimed to detect, and those outside Google's leadership could determine when such changes have arrived, Google would cease to lead the conversation on regulation by defining the nature of its technology. This state of affairs leaves the right relations with generative AI underdetermined but maintains that positions which challenge the expert consensus are the result of misunderstandings so significant as to disqualify the concerned party's thoughts on the matter from rational consideration. In the three cases examined here, events and concerns which threaten to depict generative AI as in need of significant scrutiny or changes are defused not by intervening in the company's technology, but by delineating between user understandings which are empowered and exploitative, safe and vulnerable, rational and deluded.Named after an early chatbot, the ELIZA effect refers to the readiness with which users anthropomorphize computer systems [15]. Reporting on both Lemoine [11] and the Belgian man cited this effect [6]. The chatbot which encouraged the Belgian man to commit suicide was named Eliza. One way of summarizing the change I trace in the cases described above is a transition away from the Turing test and towards the ELIZA effect as the conceptual frame for AI which imitates humans. While the Turing test implies the layperson's relevance to the discussion and regulation of AI, the ELIZA effect implies their irrelevance.This project will continue as an effort to follow popular, expert, and regulatory perceptions of the risk of generative AI as the tools themselves and the public concern surrounding them continue to develop. The resources of science and technology studies (STS) enable crucial perspectives on numerous ways of thinking about AI and the challenges of its development and regulation such as the common citations of law lag, invocations of self-regulation in the mode of the Asilomar Conference on rDNA, collective action problem framings, and more. The STS literature on sociotechnical imaginaries [1] and public understandings of science [16] contribute to the present insight as to how the efforts of tech-society reconciliation and risk-benefit balancing presented as appropriate for AI reveal and produce our understandings of the technology, even as they reproduce and reshape social norms. There is an urgent need for work which extends this powerful scholarly tradition for understanding science, technology, and society to AI, as one of the most important and concerning technological developments of our moment.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {945–946},
numpages = {2},
keywords = {chatbots, expertise, generative AI, public understanding of science, science and technology studies},
location = {Montréal, QC, Canada},
series = {AIES '23}
}

@inproceedings{10.1145/3469877.3490605,
author = {Seidenari, Lorenzo and Galteri, Leonardo and Bongini, Pietro and Bertini, Marco and Del Bimbo, Alberto},
title = {Language Based Image Quality Assessment},
year = {2022},
isbn = {9781450386074},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3469877.3490605},
doi = {10.1145/3469877.3490605},
abstract = {Evaluation of generative models, in the visual domain, is often performed providing anecdotal results to the reader. In the case of image enhancement, reference images are usually available. Nonetheless, using signal based metrics often leads to counterintuitive results: highly natural crisp images may obtain worse scores than blurry ones. On the other hand, blind reference image assessment may rank images reconstructed with GANs higher than the original undistorted images. To avoid time consuming human based image assessment, semantic computer vision tasks may be exploited instead [9, 25, 33]. In this paper we advocate the use of language generation tasks to evaluate the quality of restored images. We show experimentally that image captioning, used as a downstream task, may serve as a method to score image quality. Captioning scores are better aligned with human rankings with respect to signal based metrics or no-reference image quality metrics. We show insights on how the corruption, by artifacts, of local image structure may steer image captions in the wrong direction.},
booktitle = {Proceedings of the 3rd ACM International Conference on Multimedia in Asia},
articleno = {25},
numpages = {7},
keywords = {image quality evaluation, image quality enhancement, image captioning, generative models evaluation, GAN},
location = {Gold Coast, Australia},
series = {MMAsia '21}
}

@inproceedings{10.1145/3544548.3581408,
author = {Jeong, Yunwoo and Cho, Hyungjun and Kim, Taewan and Nam, Tek-Jin},
title = {AutomataStage: an AR-mediated Creativity Support Tool for Hands-on Multidisciplinary Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581408},
doi = {10.1145/3544548.3581408},
abstract = {The creativity support tools can enhance the hands-on multidisciplinary learning experience by drawing interest in the process of creating the outcome. We present AutomataStage, an AR-mediated creativity support tool for hands-on multidisciplinary learning. AutomataStage utilizes a video see-through interface to support the creation of Interactive Automata. The combination of building blocks and low-cost materials increases the expressiveness. The generative design method and one-to-one guide support the idea development process. It also provides a hardware see-through feature with which inside parts and circuits can be seen and an operational see-through feature that shows the operation in real-time. The visual programming method with a state transition diagram supports the iterative process during the creation process. A user study shows that AutomataStage enabled the students to create diverse Interactive Automata within 40-minute sessions. By creating Interactive Automata, the participants could learn the basic concepts of components. See-through features allowed active exploration with interest while integrating the components. We discuss the implications of hands-on tools with interactive and kinetic content beyond multidisciplinary learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {732},
numpages = {16},
keywords = {Interactive Automata, Multidisciplinary learning, STEAM, creativity support tool, hands-on learning, learning tool, video see-through system},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.5555/3539845.3540187,
author = {Wei, Zheng and Zhang, Xingjun and Li, Jingbo and Ji, Zeyu and Wei, Jia},
title = {BenQ: &lt;u&gt;ben&lt;/u&gt;chmarking automated quantization on deep neural network accelerators},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Hardware-aware automated quantization promises to unlock an entirely new algorithm-hardware co-design paradigm for efficiently accelerating deep neural network (DNN) inference by incorporating the hardware cost into the reinforcement learning (RL) -based quantization strategy search process. Existing works usually design an automated quantization algorithm targeting one hardware accelerator with a device-specific performance model or pre-collected data. However, determining the hardware cost is non-trivial for algorithm experts due to their lack of cross-disciplinary knowledge in computer architecture, compiler, and physical chip design. Such a barrier limits reproducibility and fair comparison. Moreover, it is notoriously challenging to interpret the results due to the lack of quantitative metrics. To this end, we first propose BenQ, which includes various RL-based automated quantization algorithms with aligned settings and encapsulates two off-the-shelf performance predictors with standard OpenAI Gym API. Then, we leverage cosine similarity and manhattan distance to interpret the similarity between the searched policies. The experiments show that different automated quantization algorithms can achieve near equivalent optimal trade-offs because of the high similarity between the searched policies, which provides insights for revisiting the innovations in automated quantization algorithms.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {1479–1484},
numpages = {6},
keywords = {reinforcement learning, benchmark, automated quantization, DNN accelerator},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@article{10.1145/3583885,
author = {Dai, Qingfeng and Wong, Yongkang and Sun, Guofei and Wang, Yanwei and Zhou, Zhou and Kankanhalli, Mohan S. and Li, Xiangdong and Geng, Weidong},
title = {Unsupervised Domain Adaptation by Causal Learning for Biometric Signal-based HCI},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3583885},
doi = {10.1145/3583885},
abstract = {Biometric signal based human-computer interface (HCI) has attracted increasing attention due to its wide application in healthcare, entertainment, neurocomputing, and so on. In recent years, deep learning-based approaches have made great progress on biometric signal processing. However, the state-of-the-art (SOTA) approaches still suffer from model degradation across subjects or sessions. In this work, we propose a novel unsupervised domain adaptation approach for biometric signal-based HCI via causal representation learning. Specifically, three kinds of interventions on biometric signals (i.e.,&nbsp;subjects, sessions, and trials) can be selected to generalize deep models across the selected intervention. In the proposed approach, a generative model is trained for producing intervened features that are subsequently used for learning transferable and causal relations with three modes. Experiments on the EEG-based emotion recognition task and sEMG-based gesture recognition task are conducted to confirm the superiority of our approach. An improvement of +0.21% on the task of inter-subject EEG-based emotion recognition is achieved using our approach. Besides, on the task of inter-session sEMG-based gesture recognition, our approach achieves improvements of +1.47%, +3.36%, +1.71%, and +1.01% on sEMG datasets including CSL-HDEMG, CapgMyo DB-b, 3DC, and Ninapro DB6, respectively. The proposed approach also works on the task of inter-trial sEMG-based gesture recognition and an average improvement of +0.66% on Ninapro databases is achieved. These experimental results show the superiority of the proposed approach compared with the SOTA unsupervised domain adaptation methods on HCIs based on biometric signal.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = sep,
articleno = {49},
numpages = {18},
keywords = {human-computer interface, causal learning, domain adaptation, Deep learning}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00013,
author = {Huang, Qing and Zhu, Jiahui and Li, Zhilong and Xing, Zhenchang and Wang, Changjing and Xu, Xiwei},
title = {PCR-Chain: Partial Code Reuse Assisted by Hierarchical Chaining of Prompts on Frozen Copilot},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00013},
doi = {10.1109/ICSE-Companion58688.2023.00013},
abstract = {API documentation, technical blogs and programming Q&amp;A sites contain a large amount of partial code that can be reused in programming tasks. However, due to unresolved simple names and last-mile syntax errors, such partial code is frequently not compilable. To facilitate partial code reuse, we develop PCR-Chain for resolving FQNs and fixing last-mile syntax errors in partial code based on a giant pre-trained code model (e.g., Copilot). Methodologically, PCR-Chain is backed up by the underlying global-level prompt architecture (which combines three design ideas: hierarchical task breakdown, prompt composition including sequential and conditional structures, and a mix of prompt-based AI and non-AI units) and the local-level prompt design. Technically, we propose PCR-Chain, which employs in-context learning rather than supervised fine-tuning with gradient updates on downstream task data. This approach enables the frozen, giant pre-trained code model to learn the desired behavior for a specific task through behavior-describing prompts and imitate it to complete the task. Experimental results show that PCR-Chain automatically resolves the FQNs and fixes last-mile syntax errors in 50 partial code samples collected from Stack Overflow with high success rates, without requiring any program analysis. The correct execution of the unit, module, and PCR-Chain demonstrates the effectiveness of the prompt design, prompt composition, and prompt architecture.Website:https://github.com/SE-qinghuang/PCR-ChainDemo Video: https://youtu.be/6HGRNdc2_JE},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {1–5},
numpages = {5},
keywords = {hierarchical prompts, AI chain, frozen copilot, pre-trained language model, in-context learning},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3574131.3574448,
author = {Zhou, Lanfeng and Ji, Xiaoyun and Li, Ling},
title = {Monocular Human Body Shape Estimation: A Generation-aid Approach},
year = {2023},
isbn = {9798400700316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3574131.3574448},
doi = {10.1145/3574131.3574448},
abstract = {Observing human beings from monocular images is one of the basic tasks of computer vision. Reconstructing human bodies from monocular images mainly includes the reconstruction of posture and body shape. However, in the past studies, researchers were more interested in pose estimation, ignoring the study of body shape, and this paper focuses on the estimation of the body shape of a 3D model. Learning body parameters via instance segmentation requires a large number of labels. While the parameters based on pose estimation are completely based on the results of key points detection, which effect is not friendly for pictures with poor angles and low resolution. In response to the above problems, we propose a method to automatically generate datasets. The dataset provides low-resolution images and labels of various angles and blurred shapes. On the generated low-resolution and poorly angled dataset, we propose a generative-assisted deep learning network framework. Experiments show that the framework can effectively estimate the body shape parameters of the model from monocular images.},
booktitle = {Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {19},
numpages = {8},
keywords = {Monocular image, Generative network, Deep learning, Body shape, 3D human reconstruction},
location = {Guangzhou, China},
series = {VRCAI '22}
}

@inproceedings{10.1145/3520304.3528766,
author = {Amaral, Ryan and Ianta, Alexandru and Bayer, Caleidgh and Smith, Robert J. and Heywood, Malcolm I.},
title = {Benchmarking genetic programming in a multi-action reinforcement learning locomotion task},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3528766},
doi = {10.1145/3520304.3528766},
abstract = {Reinforcement learning (RL) requires an agent to interact with an environment to maximize the cumulative rather than the immediate reward. Recently, there as been a significant growth in the availability of scalable RL tasks, e.g. OpenAI gym. However, most benchmarking studies concentrate on RL solutions based on some form of deep learning. In this work, we benchmark a family of linear genetic programming based approaches to the 2-d biped walker problem. The biped walker is an example of a RL environment described in terms of a multi-dimensional, real-valued 24-d input and 4-d action space. Specific recommendations are made regarding mechanisms to adopt that are able to consistently produce solutions, in this case using transfer from periodic restarts.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {522–525},
numpages = {4},
keywords = {continuous control, real-valued actions, reinforcement learning},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@inproceedings{10.1145/3485447.3512067,
author = {Zhao, Yan and Chen, Xuanhao and Deng, Liwei and Kieu, Tung and Guo, Chenjuan and Yang, Bin and Zheng, Kai and Jensen, Christian S.},
title = {Outlier Detection for Streaming Task Assignment in Crowdsourcing},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512067},
doi = {10.1145/3485447.3512067},
abstract = {Crowdsourcing aims to enable the assignment of available resources to the completion of tasks at scale. The continued digitization of societal processes translates into increased opportunities for crowdsourcing. For example, crowdsourcing enables the assignment of computational resources of humans, called workers, to tasks that are notoriously hard for computers. In settings faced with malicious actors, detection of such actors holds the potential to increase the robustness of crowdsourcing platform. We propose a framework called Outlier Detection for Streaming Task Assignment that aims to improve robustness by detecting malicious actors. In particular, we model the arrival of workers and the submission of tasks as evolving time series and provide means of detecting malicious actors by means of outlier detection. We propose a novel socially aware Generative Adversarial Network (GAN) based architecture that is capable of contending with the complex distributions found in time series. The architecture includes two GANs that are designed to adversarially train an autoencoder to learn the patterns of distributions in worker and task time series, thus enabling outlier detection based on reconstruction errors. A GAN structure encompasses a game between a generator and a discriminator, where it is desirable that the two can learn to coordinate towards socially optimal outcomes, while avoiding being exploited by selfish opponents. To this end, we propose a novel training approach that incorporates social awareness into the loss functions of the two GANs. Additionally, to improve task assignment efficiency, we propose an efficient greedy algorithm based on degree reduction that transforms task assignment into a bipartite graph matching. Extensive experiments offer insight into the effectiveness and efficiency of the proposed framework.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {1933–1943},
numpages = {11},
keywords = {crowdsourcing, outlier detection, task assignment, time series},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3589737.3605985,
author = {Norman-Tenazas, Raphael and Western, Isaac and Vallabha, Gautam and Roos, Matthew J and Johnson, Erik C and Robinson, Brian S},
title = {Enabling local learning for generative-replay-based continual learning with a recurrent model of the insect memory center},
year = {2023},
isbn = {9798400701757},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589737.3605985},
doi = {10.1145/3589737.3605985},
abstract = {Continual learning without catastrophic forgetting of previous experiences is an open general challenge for artificial neural networks, but is especially under-explored for artificial neural networks suitable to implement on neuromorphic platforms. An algorithmic understanding of how continual learning occurs in biological neural networks can inform solutions for artificial neural networks, especially in neuromorphic platforms whose biomimetic computing architectures lend themselves to more biofidelic algorithms. In this work, we derive an approach for generative-replay-based continual learning with a three-factor local learning rule based on recurrent connectivity in the insect's memory center, and characterize the model with a CIFAR-100 class incremental continual learning task. First, we investigate the properties of the model's internal representations and find that the high dimensional sparse representations enable this form of generative replay, and that these representations can be binary as required on spiking neuromorphic platforms with little detriment to model performance. Next, we derive a three-factor local learning rule by introducing simplifying assumptions to network updates from error backpropagation optimization which makes the learning rule biologically plausible (i.e., without weight transport) and amenable to neuromorphic implementation. Finally, we find that these simplifications enhance performance during gradient-based optimization for continual learning and when implemented locally achieve this increased performance. Overall, the outcomes of this work can inform a more detailed understanding for continual learning in this biological circuit, as well as introduce general approaches for neuromorphic continual learning.},
booktitle = {Proceedings of the 2023 International Conference on Neuromorphic Systems},
articleno = {25},
numpages = {7},
keywords = {generative replay, local learning, lifelong learning, neural networks, biologically-inspired algorithms},
location = {Santa Fe, NM, USA},
series = {ICONS '23}
}

@inproceedings{10.1145/3591106.3592262,
author = {Wu, Yankun and Nakashima, Yuta and Garcia, Noa},
title = {Not Only Generative Art: Stable Diffusion for Content-Style Disentanglement in Art Analysis},
year = {2023},
isbn = {9798400701788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591106.3592262},
doi = {10.1145/3591106.3592262},
abstract = {The duality of content and style is inherent to the nature of art. For humans, these two elements are clearly different: content refers to the objects and concepts in the piece of art, and style to the way it is expressed. This duality poses an important challenge for computer vision. The visual appearance of objects and concepts is modulated by the style that may reflect the author’s emotions, social trends, artistic movement, etc., and their deep comprehension undoubtfully requires to handle both. A promising step towards a general paradigm for art analysis is to disentangle content and style, whereas relying on human annotations to cull a single aspect of artworks has limitations in learning semantic concepts and the visual appearance of paintings. We thus present GOYA, a method that distills the artistic knowledge captured in a recent generative model to disentangle content and style. Experiments show that synthetically generated images sufficiently serve as a proxy of the real distribution of artworks, allowing GOYA to separately represent the two elements of art while keeping more information than existing methods.},
booktitle = {Proceedings of the 2023 ACM International Conference on Multimedia Retrieval},
pages = {199–208},
numpages = {10},
keywords = {art analysis, representation disentanglement, text-to-image generation},
location = {Thessaloniki, Greece},
series = {ICMR '23}
}

@inproceedings{10.1145/3573942.3574097,
author = {Zhai, Sheping and Liu, Yuanbiao and Cheng, Dabao},
title = {Single Image Dehazing Via Enhanced CycleGAN},
year = {2023},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573942.3574097},
doi = {10.1145/3573942.3574097},
abstract = {Due to the influence of atmospheric light scattering, the images acquired by outdoor imaging device in haze scene will appear low definition, contrast reduction, overexposure and other visible quality degradation, which makes it difficult to handle the relevant computer vision tasks. Therefore, image dehazing has become an important research area of computer vision. However, existing dehazing methods generally require paired image datasets that include both hazy images and corresponding ground truth images, while the recovered images are easy to occur color distortion and detail loss. In this study, an end-to-end image dehazing method based on Cycle-consistent Generative Adversarial Networks (CycleGAN) is proposed. For effectively learning the mapping relationship between hazy images and clear images, we refine the transformation module of the generator by weighting optimization, which can promote the network adaptability to scale. Then in order to further improve the quality of generated images, the enhanced perceptual loss and low-frequency loss combined with image feature attributes are constructed in the overall optimization objective of the network. The experimental results show that our dehazing algorithm effectively recovers the texture information while correcting the color distortion of original CycleGAN, and the recovery effect is clear and more natural, which better reduces the influence of haze on the imaging quality.},
booktitle = {Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {795–802},
numpages = {8},
location = {Xiamen, China},
series = {AIPR '22}
}

@inproceedings{10.1145/3580305.3599520,
author = {Hussain, Md Shamim and Zaki, Mohammed J. and Subramanian, Dharmashankar},
title = {The Information Pathways Hypothesis: Transformers are Dynamic Self-Ensembles},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599520},
doi = {10.1145/3580305.3599520},
abstract = {Transformers use the dense self-attention mechanism which gives a lot of flexibility for long-range connectivity. Over multiple layers of a deep transformer, the number of possible connectivity patterns increases exponentially. However, very few of these contribute to the performance of the network, and even fewer are essential. We hypothesize that there are sparsely connected sub-networks within a transformer, called information pathways which can be trained independently. However, the dynamic (i.e., input-dependent) nature of these pathways makes it difficult to prune dense self-attention during training. But the overall distribution of these pathways is often predictable. We take advantage of this fact to propose Stochastically Subsampled self-Attention (SSA) - a general-purpose training strategy for transformers that can reduce both the memory and computational cost of self-attention by 4 to 8 times during training while also serving as a regularization method - improving generalization over dense training. We show that an ensemble of sub-models can be formed from the subsampled pathways within a network, which can achieve better performance than its densely attended counterpart. We perform experiments on a variety of NLP, computer vision and graph learning tasks in both generative and discriminative settings to provide empirical evidence for our claims and show the effectiveness of the proposed method.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {810–821},
numpages = {12},
keywords = {transformer neural networks, sparse attention, self-attention, information pathway, ensemble methods},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3606283.3606285,
author = {Nakada, Kenta and Kimata, Hideaki},
title = {A Study on Voxel Shape Generation and Reconstruction with VQ-VAE-2},
year = {2023},
isbn = {9798400700460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3606283.3606285},
doi = {10.1145/3606283.3606285},
abstract = {With the recent advances in deep learning, research on reconstructing and generating 3D shapes has become increasingly popular. While there are several types of representation methods for 3D shapes, our work focuses on voxel models that are arranged in a regular grid and are easy to handle on computers. In the area of 2D image generation, generative models such as GANs have been proposed that can output higher quality generative images, but are difficult to train. The recently proposed VQ-VAE-2 is easy to learn and shows performance comparable to the latest GANs. Therefore, this work proposes a method that can generate and reconstruct sharp voxel shape using VQ-VAE-2. Experiments compare the reconstruction and generation results and demonstrate that the proposed method performs better than existing methods in both experiments and is capable to output sharper shapes.},
booktitle = {Proceedings of the 2023 7th International Conference on Graphics and Signal Processing},
pages = {9–15},
numpages = {7},
keywords = {3d model generation, 3d model reconstruction, VQ-VAE-2, voxel shape},
location = {Fujisawa, Japan},
series = {ICGSP '23}
}

@inproceedings{10.1145/3577164.3577169,
author = {Zhao, Zhihong and You, Jieshun and Cui, Yunong},
title = {Freshness Recognition of Fruit and Vegetable Images using GANs Series Data Augmentation},
year = {2023},
isbn = {9781450397810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577164.3577169},
doi = {10.1145/3577164.3577169},
abstract = {The use of computer vision techniques to distinguish fresh from stale fruit has gained widespread acceptance in recent years. However, the scarcity of datasets in this field has made it more difficult for many of the research results to be accessible in real-life situations. The core idea of this paper is to improve the generalization of the training set and the performance of the classifier by augmenting the fruit and vegetable image dataset with neural networks. This paper will investigate the applicability of the established Conditional Generative Adversarial Nets (CGAN) in this domain and discover problems such as mode collapse. The contribution of this paper is to combine existing structures and propose novel adversarial generative networks for the fruit and vegetable image, including Conditional Wasserstein GAN with Gradient Penalty (CWGAN-GP) and Auxiliary Classifier Wasserstein GAN with Gradient Penalty (ACWGAN-GP). In addition, a pre-trained models with Spinal fully-connected layer and ProgressiveSpinal fully-connected layer was used to freshness classify. It was found that ACWGAN-GP, which combines multiple network structures, not only produced more realistic and diverse images in the fruit and vegetable domain, but also maintained the learning speed of a single model during the training. In addition, by adding synthetic images to the training, the fruit and vegetable freshness classifier achieves 100% accuracy on a specified validation set.},
booktitle = {Proceedings of the 2022 4th International Conference on Video, Signal and Image Processing},
pages = {29–36},
numpages = {8},
keywords = {Data augmentation, Freshness recognition, Image generation},
location = {Shanghai, China},
series = {VSIP '22}
}

@inproceedings{10.1145/3539618.3591973,
author = {Feng, Jiazhan and Tao, Chongyang and Shen, Tao and Liu, Chang and Zhao, Dongyan},
title = {Dimension-Prompts Boost Commonsense Consolidation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591973},
doi = {10.1145/3539618.3591973},
abstract = {Neural knowledge models emerged and advanced common-sense-centric knowledge grounding. They parameterize a small seed curated commonsense knowledge graph (CS-KG) in a language model to generalize more. A current trend is to scale the seed up by directly mixing multiple sources of CS-KG (e.g., ATOMIC, ConceptNet) into one model. But, such brute-force mixing inevitably hinders effective knowledge consolidation due to i) ambiguous, polysemic, and/or inconsistent relations across sources and ii) knowledge learned in an entangled manner despite distinct types (e.g., causal, temporal). To mitigate this, we adopt a concept of commonsense knowledge dimension and propose a brand-new dimension-disentangled knowledge model (D2KM) learning paradigm with multiple sources. That is, a generative language model with dimension-specific soft prompts is trained to disentangle knowledge acquisitions along with different dimensions and facilitate potential intra-dimension consolidation across CS-KG sources. Experiments show our knowledge model outperforms its baselines in both standard and zero-shot scenarios.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1934–1938},
numpages = {5},
keywords = {commonsense knowledge construction, neural knowledge models},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3573942.3573974,
author = {Lomurno, Eugenio and Archetti, Alberto and Cazzella, Lorenzo and Samele, Stefano and Di Perna, Leonardo and Matteucci, Matteo},
title = {SGDE: Secure Generative Data Exchange for Cross-Silo Federated Learning},
year = {2023},
isbn = {9781450396899},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573942.3573974},
doi = {10.1145/3573942.3573974},
abstract = {Privacy regulation laws, such as GDPR, impose transparency and security as design pillars for data processing algorithms. In this context, federated learning is one of the most influential frameworks for privacy-preserving distributed machine learning, achieving astounding results in many natural language processing and computer vision tasks. Several federated learning frameworks employ differential privacy to prevent private data leakage to unauthorized parties and malicious attackers. Many studies, however, highlight the vulnerabilities of standard federated learning to poisoning and inference, thus raising concerns about potential risks for sensitive data. To address this issue, we present SGDE, a generative data exchange protocol that improves user security and machine learning performance in a cross-silo federation. The core of SGDE is to share data generators with strong differential privacy guarantees trained on private data instead of communicating explicit gradient information. These generators synthesize an arbitrarily large amount of data that retain the distinctive features of private samples but differ substantially. In this work, SGDE is tested in a cross-silo federated network on images and tabular datasets, exploiting beta-variational autoencoders as data generators. From the results, the inclusion of SGDE turns out to improve task accuracy and fairness, as well as resilience to the most influential attacks on federated learning.},
booktitle = {Proceedings of the 2022 5th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {205–214},
numpages = {10},
keywords = {Deep learning, Differential privacy, Federated learning, Generative deep learning, Gradient leakage, Privacy},
location = {Xiamen, China},
series = {AIPR '22}
}

@article{10.1145/3622825,
author = {Ye, Fangke and Zhao, Jisheng and Shirako, Jun and Sarkar, Vivek},
title = {Concrete Type Inference for Code Optimization using Machine Learning with SMT Solving},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3622825},
doi = {10.1145/3622825},
abstract = {Despite the widespread popularity of dynamically typed languages such as Python, it is well known that they pose significant challenges to code optimization due to the lack of concrete type information. To overcome this limitation, many ahead-of-time optimizing compiler approaches for Python rely on programmers to provide optional type information as a prerequisite for extensive code optimization. Since few programmers provide this information, a large majority of Python applications are executed without the benefit of code optimization, thereby contributing collectively to a significant worldwide wastage of compute and energy resources. In this paper, we introduce a new approach to concrete type inference that is shown to be effective in enabling code optimization for dynamically typed languages, without requiring the programmer to provide any type information. We explore three kinds of type inference algorithms in our approach based on: 1) machine learning models including GPT-4, 2) constraint-based inference based on SMT solving, and 3) a combination of 1) and 2). Our approach then uses the output from type inference to generate multi-version code for a bounded number of concrete type options, while also including a catch-all untyped version for the case when no match is found. The typed versions are then amenable to code optimization. Experimental results show that the combined algorithm in 3) delivers far superior precision and performance than the separate algorithms for 1) and 2). The performance improvement due to type inference, in terms of geometric mean speedup across all benchmarks compared to standard Python, when using 3) is 26.4× with Numba as an AOT optimizing back-end and 62.2× with the Intrepydd optimizing compiler as a back-end. These vast performance improvements can have a significant impact on programmers’ productivity, while also reducing their applications’ use of compute and energy resources.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {249},
numpages = {28},
keywords = {Type Inference, Python, Machine Learning, Code Optimization}
}

@inproceedings{10.1145/3546000.3546007,
author = {Bai, Hao},
title = {Modern Distributed Data-Parallel Large-Scale Pre-training Strategies For NLP models},
year = {2022},
isbn = {9781450396295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546000.3546007},
doi = {10.1145/3546000.3546007},
abstract = {Distributed deep learning is becoming increasingly popular due to the expanding demand for computing resources for deep learning models with a larger amount of parameters. Different from traditional training approaches, data-parallel training allows multiple compute nodes to train large deep learning models simultaneously in order to boost the training efficiency. In this paper, we present and compare six strategies for data-parallel training using PyTorch on the language model GPT-2 with 100M parameters using a qualitative approach. These strategies are Single GPU, Single Parameter Server, Distributed Parameter Server, Horovod, Distributed Parameter Server with Apex mixed-precision strategy, and Horovod with Apex mixed-precision strategy. We also analyze the quantitative experiment results from each strategy. In the end, we draw the conclusion that the Distributed Parameter Server with Apex mixed-precision strategy has the best performance on single node training, while Horovod with Apex is the most robust approach to use when we have single or multiple nodes.},
booktitle = {Proceedings of the 6th International Conference on High Performance Compilation, Computing and Communications},
pages = {44–53},
numpages = {10},
keywords = {PyTorch, Natural Language Processing, High-Performance Computing, GPT-2, Distributed Deep Learning, Data Parallelism},
location = {Jilin, China},
series = {HP3C '22}
}

@inproceedings{10.1145/3583780.3614821,
author = {Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
title = {Continual Learning for Generative Retrieval over Dynamic Corpora},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614821},
doi = {10.1145/3583780.3614821},
abstract = {Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To memorize new documents for querying without forgetting previous knowledge, we propose a memory-augmented learning mechanism, to form meaningful connections between old and new documents. Empirical results demonstrate the effectiveness and efficiency of the proposed model.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {306–315},
numpages = {10},
keywords = {product quantization, generative retrieval, document increment},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@article{10.1145/3520125,
author = {Mostafiz, Rafid and Uddin, Mohammad Shorif and Uddin, Khandaker Mohammad Mohi and Rahman, Mohammad Motiur},
title = {COVID-19 Along with Other Chest Infection Diagnoses Using Faster R-CNN and Generative Adversarial Network},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
issn = {2374-0353},
url = {https://doi.org/10.1145/3520125},
doi = {10.1145/3520125},
abstract = {The rapid spreading of coronavirus (COVID-19) caused severe respiratory infections affecting the lungs. Automatic diagnosis helps to fight against COVID-19 in community outbreaks. Medical imaging technology can reinforce disease monitoring and detection facilities with the advancement of computer vision. Unfortunately, deep learning models are facing starvation of more generalized datasets as the data repositories of COVID-19 are not rich enough to provide significant distinct features. To address the limitation, this article describes the generation of synthetic images of COVID-19 along with other chest infections with distinct features by empirical top entropy-based patch selection approach using the generative adversarial network. After that, a diagnosis is performed through a faster region-based convolutional neural network using 6,406 synthetic as well as 3,933 original chest X-ray images of different chest infections, which also addressed the data imbalance problems and not recumbent to a particular class. The experiment confirms a satisfactory COVID-19 diagnosis accuracy of 99.16% in a multi-class scenario.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = oct,
articleno = {24},
numpages = {21},
keywords = {chest X-ray (CXR), generative adversarial network (GAN), faster R-CNN, convolutional neural network (CNN), COVID-19}
}

@inproceedings{10.1145/3531146.3533137,
author = {Cooper, A. Feder and Vidan, Gili},
title = {Making the Unaccountable Internet: The Changing Meaning of Accounting in the Early ARPANET},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533137},
doi = {10.1145/3531146.3533137},
abstract = {Contemporary concerns over the governance of technological systems often run up against narratives about the technical infeasibility of designing mechanisms for accountability. While in recent AI ethics literature these concerns have been deliberated predominantly in relation to machine learning, other instances in the history of computing also presented circumstances in which computer scientists needed to un-muddle what it means to design accountable systems. One such compelling narrative can frequently be found in canonical histories of the Internet that highlight how its original designers’ commitment to the “End-to-End” architectural principle precluded other features from being implemented, resulting in the fast-growing, generative, but ultimately unaccountable network we have today. This paper offers a critique of such technologically essentialist notions of accountability and the characterization of the “unaccountable Internet” as an unintended consequence. It explores the changing meaning of accounting and its relationship to accountability in a selected corpus of requests for comments (RFCs) concerning the early Internet’s design from the 1970s and 80s. We characterize four ways of conceptualizing accounting: as billing, as measurement, as management, and as policy, and demonstrate how an understanding of accountability was constituted through these shifting meanings. We link together the administrative and technical mechanisms of accounting for shared resources in a distributed system and an emerging notion of accountability as a social, political, and technical category, arguing that the former is constitutive of the latter. Recovering this history is not only important for understanding the processes that shaped the Internet, but also serves as a starting point for unpacking the complicated political choices that are involved in designing accountability mechanisms for other technological systems today.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {726–742},
numpages = {17},
keywords = {Accountability, Accountable systems, Accounting, Internet governance, Resource sharing},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@article{10.1145/3478642,
author = {Zhang, Feifei and Xu, Mingliang and Xu, Changsheng},
title = {Tell, Imagine, and Search: End-to-end Learning for Composing Text and Image to Image Retrieval},
year = {2022},
issue_date = {May 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {2},
issn = {1551-6857},
url = {https://doi.org/10.1145/3478642},
doi = {10.1145/3478642},
abstract = {Composing Text and Image to Image Retrieval (CTI-IR) is an emerging task in computer vision, which allows retrieving images relevant to a query image with text describing desired modifications to the query image. Most conventional cross-modal retrieval approaches usually take one modality data as the query to retrieve relevant data of another modality. Different from the existing methods, in this article, we propose an end-to-end trainable network for simultaneous image generation and CTI-IR. The proposed model is based on Generative Adversarial Network (GAN) and enjoys several merits. First, it can learn a generative and discriminative feature for the query (a query image with text description) by jointly training a generative model and a retrieval model. Second, our model can automatically manipulate the visual features of the reference image in terms of the text description by the adversarial learning between the synthesized image and target image. Third, global-local collaborative discriminators and attention-based generators are exploited, allowing our approach to focus on both the global and local differences between the query image and the target image. As a result, the semantic consistency and fine-grained details of the generated images can be better enhanced in our model. The generated image can also be used to interpret and empower our retrieval model. Quantitative and qualitative evaluations on three benchmark datasets demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
articleno = {59},
numpages = {23},
keywords = {global-local, generative adversarial network, image generation, end-to-end, Composing text and image to image retrieval}
}

@article{10.14778/3636218.3636227,
author = {Nagrecha, Kabir and Kumar, Arun},
title = {Saturn: An Optimized Data System for Multi-Large-Model Deep Learning Workloads},
year = {2023},
issue_date = {December 2023},
publisher = {VLDB Endowment},
volume = {17},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3636218.3636227},
doi = {10.14778/3636218.3636227},
abstract = {Large models such as GPT-3 and ChatGPT have transformed deep learning (DL), powering applications that have captured the public's imagination. Such models must be trained on multiple GPUs due to their size and computational load, driving the development of a bevy of "model parallelism" techniques and tools. Navigating such parallelism choices, however, is a new burden for DL users such as data scientists, domain scientists, etc., who may lack the necessary systems knowhow. The need for model selection, which leads to many models to train due to hyper-parameter tuning or layer-wise finetuning, compounds the situation with two more burdens: resource apportioning and scheduling. In this work, we unify these three burdens by formalizing them as a joint problem that we call SPASE: Select a Parallelism, Allocate resources, and Schedule. We propose a new information system architecture to tackle the SPASE problem holistically, exploiting the performance opportunities presented by joint optimization. We devise an extensible template for existing parallelism schemes and combine it with an automated empirical profiler for runtime estimation. We then formulate SPASE as an MILP. We find that direct use of an MILP-solver is significantly more effective than several baseline heuristics. We optimize the system runtime further with an introspective scheduling approach. We implement all these techniques into a new data system we call Saturn. Experiments with benchmark DL workloads show that Saturn achieves 39-49% lower model selection runtimes than current DL practice.},
journal = {Proc. VLDB Endow.},
month = dec,
pages = {712–725},
numpages = {14}
}

@inproceedings{10.1145/3594315.3594652,
author = {Li, Wenzheng and Tian, Lihua and Sun, Zhigang and Xiao, Li},
title = {Image Sample Generation of Stator Surface Defects Based on Layer Mask Blending Generative Adversarial Network},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594315.3594652},
doi = {10.1145/3594315.3594652},
abstract = {In industrial production processes, defect inspection plays an important role in reducing the occurrence of failures and improving production efficiency. Data-driven algorithms represented by deep learning have made great progress in recent years, but need to face the problems of small quantity and poor quality of datasets when applied to industrial defect inspection. This paper proposes a layer mask blending-based generative adversarial network (LMBGAN) and optimizes the training process to generate high-quality surface defect samples. LMBGAN generates defect images and layer masks using the defect image decoder and layer mask decoder with the Pixel Shuffle operation. Inspired by the layer mask in computer painting, LMBGAN adopts the input image as the base layer and blends the defect foreground through the layer mask, giving it the ability to focus more on generating upper-layer defect images and reducing unnecessary background changes. LMBGAN additionally introduces adaptive discriminator augmentation and non-saturating logistic loss to promote model convergence under small datasets, effectively alleviating the problem of GAN training difficulties with limited data. The experiment results show that the proposed method can generate high-quality and diverse defect image samples through easily accessible normal samples, thus reducing the difficulty of obtaining rare defect image samples.},
booktitle = {Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
pages = {258–265},
numpages = {8},
location = {Tianjin, China},
series = {ICCAI '23}
}

@inproceedings{10.1145/3613424.3614248,
author = {Zheng, Bojian and Yu, Cody Hao and Wang, Jie and Ding, Yaoyao and Liu, Yizhi and Wang, Yida and Pekhimenko, Gennady},
title = {Grape: Practical and Efficient Graphed Execution for Dynamic Deep Neural Networks on GPUs},
year = {2023},
isbn = {9798400703294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613424.3614248},
doi = {10.1145/3613424.3614248},
abstract = {Achieving high performance in machine learning workloads is a crucial yet difficult task. To achieve high runtime performance on hardware platforms such as GPUs, graph-based executions such as CUDA graphs are often used to eliminate CPU runtime overheads by submitting jobs in the granularity of multiple kernels. However, many machine learning workloads, especially dynamic deep neural networks (DNNs) with varying-sized inputs or data-dependent control flows, face challenges when directly using CUDA graphs to achieve optimal performance. We observe that the use of graph-based executions poses three key challenges in terms of efficiency and even practicability: (1) Extra data movements when copying input values to graphs’ placeholders. (2) High GPU memory consumption due to the numerous CUDA graphs created to efficiently support dynamic-shape workloads. (3) Inability to handle data-dependent control flows. To address those challenges, we propose Grape, a new graph compiler that enables practical and efficient graph-based executions for dynamic DNNs on GPUs. Grape comprises three key components: (1) an alias predictor that automatically removes extra data movements by leveraging code positions at the Python frontend, (2) a metadata compressor that efficiently utilizes the data redundancy in CUDA graphs’ memory regions by compressing them, and (3) a predication rewriter that safely replaces control flows with predication contexts while preserving programs’ semantics. The three components improve the efficiency and broaden the optimization scope of graph-based executions while allowing machine learning practitioners to program dynamic DNNs at the Python level with minimal source code changes. We evaluate Grape on state-of-the-art text generation (GPT-2, GPT-J) and speech recognition (Wav2Vec2) workloads, which include both training and inference, using real systems with modern GPUs. Our evaluation shows that Grape achieves up to 36.43 × less GPU memory consumption and up to 1.26 × better performance than prior works on graph-based executions that directly use CUDA graphs. Furthermore, Grape can optimize workloads that are impractical for prior works due to the three key challenges, achieving 1.78 × and 1.82 × better performance on GPT-J and Wav2Vec2 respectively than the original implementations that do not use graph-based executions.},
booktitle = {Proceedings of the 56th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {1364–1380},
numpages = {17},
keywords = {machine learning compilers, dynamic neural networks, CUDA graphs},
location = {Toronto, ON, Canada},
series = {MICRO '23}
}

@article{10.1109/TASLP.2023.3235202,
author = {Rohmatillah, Mahdin and Chien, Jen-Tzung},
title = {Hierarchical Reinforcement Learning With Guidance for Multi-Domain Dialogue Policy},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3235202},
doi = {10.1109/TASLP.2023.3235202},
abstract = {Achieving high performance in a multi-domain dialogue system with low computation is undoubtedly challenging. Previous works applying an end-to-end approach have been very successful. However, the computational cost remains a major issue since the large-sized language model using GPT-2 is required. Meanwhile, the optimization for individual components in the dialogue system has not shown promising result, especially for the component of dialogue management due to the complexity of multi-domain state and action representation. To cope with these issues, this article presents an efficient guidance learning where the imitation learning and the hierarchical reinforcement learning (HRL) with human-in-the-loop are performed to achieve high performance via an inexpensive dialogue agent. The behavior cloning with auxiliary tasks is exploited to identify the important features in latent representation. In particular, the proposed HRL is designed to treat each goal of a dialogue with the corresponding sub-policy so as to provide efficient dialogue policy learning by utilizing the guidance from human through action pruning and action evaluation, as well as the reward obtained from the interaction with the simulated user in the environment. Experimental results on ConvLab-2 framework show that the proposed method achieves state-of-the-art performance in dialogue policy optimization and outperforms the GPT-2 based solutions in end-to-end system evaluation.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jan,
pages = {748–761},
numpages = {14}
}

@inproceedings{10.1145/3503161.3549973,
author = {Forero, Jorge and Bernardes, Gilberto and Mendes, Mónica},
title = {Emotional Machines: Toward Affective Virtual Environments},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3549973},
doi = {10.1145/3503161.3549973},
abstract = {Emotional Machines is an interactive installation that builds affective virtual environments through spoken language. In response to the existing limitations of emotion recognition models incorporating computer vision and electrophysiological activity, whose sources are hindered by a head-mounted display, we propose the adoption of speech emotion recognition (from the audio signal) and semantic sentiment analysis. In detail, we use two machine learning models to predict three main emotional categories from high-level semantic and low-level speech features. Output emotions are mapped to audiovisual representation by an end-to-end process. We use a generative model of chord progressions to transfer speech emotion into music and a synthesized image from the text (transcribed from the user's speech). The generated image is used as the style source in the style-transfer process onto an equirectangular projection image target selected for each emotional category. The installation is an immersive virtual space encapsulating emotions in spheres disposed into a 3D environment. Thus, users can create new affective representations or interact with other previous encoded instances using joysticks.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {7237–7238},
numpages = {2},
keywords = {virtual reality, tonal interval space, speech emotion recognition, machine learning, intelligent virtual environments, affective computing},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3583780.3614941,
author = {Naddaf, Parmis and Mahmoudzaheh Ahmadi Nejad, Erfaneh and Zahirnia, Kiarash and Jaeger, Manfred and Schulte, Oliver},
title = {Joint Link Prediction Via Inference from a Model},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614941},
doi = {10.1145/3583780.3614941},
abstract = {A Joint Link Prediction Query (JLPQ) specifies a set of links to be predicted, given another set of links as well as node attributes as evidence. While single link prediction has been well studied in literature on deep graph learning, predicting multiple links together has gained little attention. This paper presents a novel framework for computing JLPQs using a probabilistic deep Graph Generative Model. Specifically, we develop inference procedures for an inductively trained Variational Graph Auto-Encoder (VGAE) that estimates the joint link probability for any input JLPQ, without retraining. For evaluation, we apply inference to a range of joint link prediction queries on six benchmark datasets. We find that for most datasets and query types, joint link prediction via inference from a model achieves good predictive performance, better than the independent link prediction baselines (by 0.02-0.4 AUC points depending on the dataset).},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {1877–1886},
numpages = {10},
keywords = {link prediction, inference from a model, graph representation learning, graph convolutional networks},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3520304.3529052,
author = {Clei, Maximilien Le and Bellec, Pierre},
title = {Neuroevolution of recurrent architectures on control tasks},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3529052},
doi = {10.1145/3520304.3529052},
abstract = {Modern artificial intelligence works typically train the parameters of fixed-sized deep neural networks using gradient-based optimization techniques. Simple evolutionary algorithms have recently been shown to also be capable of optimizing deep neural network parameters, at times matching the performance of gradient-based techniques, e.g. in reinforcement learning settings. In addition to optimizing network parameters, many evolutionary computation techniques are also capable of progressively constructing network architectures. However, constructing network architectures from elementary evolution rules has not yet been shown to scale to modern reinforcement learning benchmarks. In this paper we therefore propose a new approach in which the architectures of recurrent neural networks dynamically evolve according to a small set of mutation rules. We implement a massively parallel evolutionary algorithm and run experiments on all 19 OpenAI Gym state-based reinforcement learning control tasks. We find that in the majority of cases, dynamic agents match or exceed the performance of gradient-based agents while utilizing orders of magnitude fewer parameters. We believe our work to open avenues for real-life applications where network compactness and autonomous design are of critical importance. We provide our source code, final model checkpoints and full results at github.com/MaximilienLC/nra.Artificial neural networks are computing systems that have become central to the field of artificial intelligence. Through waves of innovation, these networks have gotten bigger, more efficient, and increasingly competent on a wide range of tasks. Most often, the parameters of these artificial neural networks are optimized using first-order gradient-based optimization techniques, yet their architecture is for the most part still constructed manually.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {651–654},
numpages = {4},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@inproceedings{10.1145/3583131.3590455,
author = {Nguyen, Thai Huy and Luong, Ngoc Hoang},
title = {Stable and Sample-Efficient Policy Search for Continuous Control via Hybridizing Phenotypic Evolutionary Algorithm with the Double Actors Regularized Critics},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590455},
doi = {10.1145/3583131.3590455},
abstract = {Evolutionary Reinforcement Learning arises from hybridizing the sample efficiency of policy gradient with the stability of evolutionary computation. Proximal Distilled Evolutionary Reinforcement Learning (PDERL) implements the hybridization by having information transferred between an RL agent operating alongside a population of candidate policies. PDERL employs two phenotype-based variation operators, behavior distillation crossover and proximal mutation, which exhibit better effectiveness compared to traditional genotype-based operators. We demonstrate that the proximal mutation is sensitive to its mutation magnitude hyperparameter, which yields damaging effects if its value is improperly set. Inspired from Differential Evolution, we propose a novel mutation procedure that operates on action vectors generated by candidate policies. The phenotypic differential mutation (PhDM) shows its stability in diversity maintenance with little disruption. A recently-introduced actor-critic policy gradient algorithm, Double Actors Regularized Critics (DARC), exhibits a superior sample efficiency. DARC alleviates both overestimation and underestimation bias via the usage of two actors for better exploration and a dedicated critic regularization technique. In this paper, we restructure PDERL to incorporate PhDM and the policy gradient mechanism of DARC. Experimental results show that our Phenotypic Evolutionary DARC (PhEDARC) outperforms both PDERL and DARC in four control tasks from OpenAI Gym. Ablation studies support our design choices.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1239–1247},
numpages = {9},
keywords = {continuous control, policy search, variation operators, evolutionary reinforcement learning},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@inproceedings{10.1145/3530190.3534817,
author = {Ge, Xiou and Goodwin, Richard T. and Yu, Haizi and Romero, Pablo and Abdelrahman, Omar and Sudhalkar, Amruta and Kusuma, Julius and Cialdella, Ryan and Garg, Nishant and Varshney, Lav R.},
title = {Accelerated Design and Deployment of Low-Carbon Concrete for Data Centers},
year = {2022},
isbn = {9781450393478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3530190.3534817},
doi = {10.1145/3530190.3534817},
abstract = {Concrete is the most widely used engineered material in the world with more than 10 billion tons produced annually. Unfortunately, with that scale comes a significant burden in terms of energy, water, and release of greenhouse gases and other pollutants; indeed 8% of worldwide carbon emissions are attributed to the production of cement, a key ingredient in concrete. As such, there is interest in creating concrete formulas that minimize this environmental burden, while satisfying engineering performance requirements including compressive strength. Specifically for computing, concrete is a major ingredient in the construction of data centers. In this work, we use conditional variational autoencoders (CVAEs), a type of semi-supervised generative artificial intelligence (AI) model, to discover concrete formulas with desired properties. Our model is trained just using a small open dataset from the UCI Machine Learning Repository joined with environmental impact data from standard lifecycle analysis. Computational predictions demonstrate CVAEs can design concrete formulas with much lower carbon requirements than existing formulations while meeting design requirements. Next we report laboratory-based compressive strength experiments for five AI-generated formulations, which demonstrate that the formulations exceed design requirements. The resulting formulations were then used by Ozinga Ready Mix—a concrete supplier—to generate field-ready concrete formulations, based on local conditions and their expertise in concrete design. Finally, we report on how these formulations were used in the construction of buildings and structures in a Meta data center in DeKalb, IL, USA. Results from field experiments as part of this real-world deployment corroborate the efficacy of AI-generated low-carbon concrete mixes.},
booktitle = {Proceedings of the 5th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
pages = {340–352},
numpages = {13},
keywords = {variational autoencoders, sustainable building materials, concrete, artificial intelligence},
location = {Seattle, WA, USA},
series = {COMPASS '22}
}

@inproceedings{10.1145/3577193.3593712,
author = {Randall, Thomas and Koo, Jaehoon and Videau, Brice and Kruse, Michael and Wu, Xingfu and Hovland, Paul and Hall, Mary and Ge, Rong and Balaprakash, Prasanna},
title = {Transfer-learning-based Autotuning using Gaussian Copula},
year = {2023},
isbn = {9798400700569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577193.3593712},
doi = {10.1145/3577193.3593712},
abstract = {As diverse high-performance computing (HPC) systems are built, many opportunities arise for applications to solve larger problems than ever before. Given the significantly increased complexity of these HPC systems and application tuning, empirical performance tuning, such as autotuning, has emerged as a promising approach in recent years. Despite its effectiveness, autotuning is often a computationally expensive approach. Transfer learning (TL)-based autotuning seeks to address this issue by leveraging the data from prior tuning. Current TL methods for autotuning spend significant time modeling the relationship between parameter configurations and performance, which is ineffective for few-shot (that is, few empirical evaluations) tuning on new tasks. We introduce the first generative TL-based autotuning approach based on the Gaussian copula (GC) to model the high-performing regions of the search space from prior data and then generate high-performing configurations for new tasks. This allows a sampling-based approach that maximizes few-shot performance and provides the first probabilistic estimation of the few-shot budget for effective TL-based autotuning. We compare our generative TL approach with state-of-the-art autotuning techniques on several benchmarks. We find that the GC is capable of achieving 64.37% of peak few-shot performance in its first evaluation. Furthermore, the GC model can determine a few-shot transfer budget that yields up to 33.39× speedup, a dramatic improvement over the 20.58× speedup using prior techniques.},
booktitle = {Proceedings of the 37th ACM International Conference on Supercomputing},
pages = {37–49},
numpages = {13},
keywords = {gaussian copula, few-shot learning, autotuning, transfer learning},
location = {Orlando, FL, USA},
series = {ICS '23}
}

@inproceedings{10.5555/3545946.3598962,
author = {Li, Zun and Lanctot, Marc and McKee, Kevin R. and Marris, Luke and Gemp, Ian and Hennes, Daniel and Larson, Kate and Bachrach, Yoram and Wellman, Michael P. and Muller, Paul},
title = {Search-Improved Game-Theoretic Multiagent Reinforcement Learning in General and Negotiation Games},
year = {2023},
isbn = {9781450394321},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Multiagent reinforcement learning (MARL) has benefited significantly from population-based and game-theoretic training regimes. One approach, Policy-Space Response Oracles (PSRO), employs standard reinforcement learning to compute response policies via approximate best responses and combines them via meta-strategy selection. We augment PSRO by adding a novel search procedure with generative sampling of world states, and introduce two new meta-strategy solvers based on the Nash bargaining solution. We evaluate PSRO's ability to compute approximate Nash equilibrium, and its performance in negotiation games: Colored Trails and Deal-or-no-Deal. We conduct behavioral studies where human participants negotiate with our agents (N = 346). Search with generative modeling finds stronger policies during both training time and test time, enables online Bayesian co-player prediction, and can produce agents that achieve comparable social welfare negotiating with humans as humans trading among themselves.},
booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
pages = {2445–2447},
numpages = {3},
keywords = {alphazero, multiagent, nash bargaining solution, negotiation games, policy-space response oracles, reinforcement learning},
location = {London, United Kingdom},
series = {AAMAS '23}
}

@inproceedings{10.1109/DAC18074.2021.9586268,
author = {Li, Junde and Alam, Mahabubul and Sha, Congzhou M and Wang, Jian and Dokholyan, Nikolay V. and Ghosh, Swaroop},
title = {Invited: Drug Discovery Approaches Using Quantum Machine Learning},
year = {2022},
isbn = {9781665432740},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DAC18074.2021.9586268},
doi = {10.1109/DAC18074.2021.9586268},
abstract = {Traditional drug discovery pipelines can require multiple years and billions of dollars of investment. Deep generative and discriminative models are widely adopted to assist in drug development. Classical machines cannot efficiently reproduce the atypical patterns of quantum computers, which may improve the quality of learned tasks. We propose a suite of quantum machine learning techniques: incorporating generative adversarial networks (GAN), convolutional neural networks (CNN) and variational auto-encoders (VAE) to generate small drug molecules, classify binding pockets in proteins, and generate large drug molecules, respectively.},
booktitle = {Proceedings of the 58th Annual ACM/IEEE Design Automation Conference},
pages = {1356–1359},
numpages = {4},
location = {San Francisco, California, United States},
series = {DAC '21}
}

@inproceedings{10.1145/3505170.3511034,
author = {Ren, Haoxing},
title = {Embracing Machine Learning in EDA},
year = {2022},
isbn = {9781450392105},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3505170.3511034},
doi = {10.1145/3505170.3511034},
abstract = {The application of machine learning (ML) in EDA is a hot research trend. To use ML in EDA, it is nature to think from the ML method point of view, i.e. supervised learning, reinforcement learning and unsupervised learning. Based on this point of view, we can roughly classify the ML applications in EDA into three categories: prediction, optimization, and generation. The prediction category applies supervised learning methods to predict design quality of result (QoR) metrics. There are two kinds of QoR metrics that benefit from the prediction. One kind of metrics are those that can be determined at the current design stage but calculating them consumes a lot of computing resources. For ex-ample, [11] [12] leverage ML to predict circuit power consumption without expensive simulations. The other kind of metrics are those that depend on future design stages. For example, [8] predicts post layout parasitics from schematic of analog circuits. The optimization category applies Bayesian Optimization (BO)and reinforcement learning (RL) to directly optimize EDA problems.BO treats the optimization objective as a blackbox function and tries to find optimal solutions by iteratively sampling the solution space. For example, [5] proposes to use BO with graph embedding and neural network-based surrogate model to size analog circuits. RL treats the optimization objective as the reward from an environment, and trains agents to maximize the reward. [7] proposes to use RL to optimize macro placement, and [9] proposes to use RL to optimize parallel prefix circuit structures. The generation category applies generative models such as generative adversarial networks (GANs) to directly generate solutions to EDA problems. Generative models can learn from previous optimized data distribution and generate solutions for a new problem instance without going through iterative processes like BO or RL. For example, [10] builds a conditional GAN model that learns to generate optical proximity correction (OPC) layout from the original mask.},
booktitle = {Proceedings of the 2022 International Symposium on Physical Design},
pages = {55–56},
numpages = {2},
keywords = {machine learning, electronic design automation, deep learning},
location = {Virtual Event, Canada},
series = {ISPD '22}
}

@inproceedings{10.1145/3586182.3625119,
author = {Blanchet, Julien and Han, Sixuan},
title = {Integrating a LLM into an Automatic Dance Practice Support System: Breathing Life Into The Virtual Coach},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3625119},
doi = {10.1145/3586182.3625119},
abstract = {We propose using a LLM to breathe life into our existing dance learning app in the form of an AI dance coach persona. The current app guides the user through dance practice plans, using the webcam and pose estimation to give feedback. Using the LLM, voice recognition, speech synthesis, and affect recognition, we plan to transform the interface from a mechanical click-on-screen experience to a hands-free speak-with-the-coach interaction. In particular, we’ll use the LLM to announce coaching guidance, provide encouragement, communicate feedback, and interpret the user’s spoken intent.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {118},
numpages = {2},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@inproceedings{10.1145/3600006.3613145,
author = {Wang, Zhuang and Jia, Zhen and Zheng, Shuai and Zhang, Zhen and Fu, Xinwei and Ng, T. S. Eugene and Wang, Yida},
title = {GEMINI: Fast Failure Recovery in Distributed Training with In-Memory Checkpoints},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600006.3613145},
doi = {10.1145/3600006.3613145},
abstract = {Large deep learning models have recently garnered substantial attention from both academia and industry. Nonetheless, frequent failures are observed during large model training due to large-scale resources involved and extended training time. Existing solutions have significant failure recovery costs due to the severe restriction imposed by the bandwidth of remote storage in which they store checkpoints.This paper presents Gemini, a distributed training system that enables fast failure recovery for large model training by checkpointing to CPU memory of the host machines with much larger aggregated bandwidth. However, two challenges prevent naïvely checkpointing to CPU memory. First, the availability of checkpoints in CPU memory cannot be guaranteed when failures occur. Second, since the communication traffic for training and checkpointing share the same network, checkpoint traffic can interfere with training traffic and harm training throughput. To address these two challenges, this paper proposes: 1) a provably near-optimal checkpoint placement strategy to maximize the probability of failure recovery from checkpoints in CPU memory; and 2) a checkpoint traffic scheduling algorithm to minimize, if not eliminate, the interference of checkpoint traffic on model training. Our evaluation shows that overall Gemini achieves a faster failure recovery by more than 13× than existing solutions. Moreover, it achieves optimal checkpoint frequency, i.e., every iteration, and incurs no overhead on training throughput for large model training.},
booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
pages = {364–381},
numpages = {18},
keywords = {in-memory checkpoint, fault tolerance, distributed training},
location = {Koblenz, Germany},
series = {SOSP '23}
}

@inproceedings{10.1145/3545258.3545263,
author = {Jiang, Yu and Wang, Liang and Hu, Hao and Tao, Xianping},
title = {Represent Code as Action Sequence for Predicting Next Method Call},
year = {2022},
isbn = {9781450397803},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545258.3545263},
doi = {10.1145/3545258.3545263},
abstract = {As human beings take actions with a goal in mind, we could predict the following action of a person depending on his previous actions. Inspired by this, after collecting and analyzing more than 13,000 repositories with 441,290 Python source code files from the Internet, we find the actions expressed in code are in the developers’ high-level programming language statements. Previous code comprehension and code completion research paid little attention to code editing contexts like code file names and repository names while representing code for machine learning models. After modeling code as action sequences and modeling method names, file names and repository names as code editing context, we use modern natural language processing techniques to utilize the huge open source resources from the Internet and train a code completion model which takes the action sequences in code as input to complete code for developers. In the evaluation part, the experiments we conduct show the GPT-2 model trained with our action sequence code representation achieves 81.92% top-5 accuracy for next method call token prediction, compared to 61.89% of same GPT-2 model trained with same dataset. As for the context of the code we propose, we find it important for machines to comprehend the code better. Given the pre-trained natural language model, the training time of our model for 1,000,000 lines code is less than 16.7 minutes. All the above contribute to code comprehension and enhance code completion via unlimited resources from the Internet.},
booktitle = {Proceedings of the 13th Asia-Pacific Symposium on Internetware},
pages = {45–54},
numpages = {10},
keywords = {software engineering with Big data, software engineering with AI, mining software repositories},
location = {Hohhot, China},
series = {Internetware '22}
}

@inproceedings{10.1145/3532106.3533449,
author = {Benabdallah, Gabrielle and Alexander, Ashten and Ghosh, Sourojit and Glogovac-Smith, Chariell and Jacoby, Lacey and Lustig, Caitlin and Nguyen, Anh and Parkhurst, Anna and Reyes, Kathryn and Tan, Neilly H. and Wolcher, Edward and Psarra, Afroditi and Rosner, Daniela},
title = {Slanted Speculations: Material Encounters with Algorithmic Bias},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533449},
doi = {10.1145/3532106.3533449},
abstract = {Over the past few years, AI bias has become a central concern within design and computing fields. But as the concept of bias has grown in visibility, its meaning and form have become harder to grasp. To help designers realize bias, we take inspiration from textile bias (the skew of woven material) and examine the topic across its myriad forms: visual, textual, and tactile. By introducing a slanted experience of material and therefore of reality, we explore the translation of fraught machine learning algorithms into personal and probing artifacts. In this pictorial, we present nine pieces that materialize complex relationships with machine learning; ground these relationships in the present and the personal; and point to generative ways of engaging with biased systems around us.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {85–99},
numpages = {15},
keywords = {Algorithmic bias, arts, design practice, machine learning, materiality, speculative design},
location = {Virtual Event, Australia},
series = {DIS '22}
}

@inproceedings{10.1145/3532213.3532217,
author = {Zhang, Jie and Jiang, Runhao and Xiao, Rong and Yan, Rui},
title = {Dynamic Resistance Based Spiking Actor Network for Improving Reinforcement Learning},
year = {2022},
isbn = {9781450396110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532213.3532217},
doi = {10.1145/3532213.3532217},
abstract = {Designing algorithms for continuous control is a big challenge no matter in real robot controlling or simulation tasks. Deep reinforcement learning (DRL) is the most successful algorithm in dealing with such tasks for it utilizing the powerful ability of deep neuron network (DNN) in handling complex information. However, the more powerful ability the DNN has, the more energy it consumes. It’s a barrier for DRL to be realized in real-world control tasks. With more biological features, spiking neuron network (SNN) is one of the frontier fields of high-efficiency computing. The binary spike it used to represent information contains more temporal information and leads to greater computational efficiency on neuromorphic chips. Based on a hybrid architecture of SNN and DNN, we propose an actor-critic model to utilize the ability of SNN in dealing with complex continuous information and the ability of DNN in large scale accurate computation. The common Leaky Integrate-and-Fire (LIF) neuron model which is mainly used to build deep SNN neglects the resistance flexibility in the neuron. Considering that causes a descend capacity of representing continuous information which is of vital important in continuous control, we propose a new dynamic resistance LIF (R-LIF) model to compensate the temporal relation dependencies in neurons. With the same gradient updating rule, our R-LIF based spiking actor network (RSAN) shows a better performance when inferring in OpenAI benchmark tasks not only than the deep neuron actor network but also than the same LIF based spiking neuron actor network.},
booktitle = {Proceedings of the 8th International Conference on Computing and Artificial Intelligence},
pages = {18–23},
numpages = {6},
keywords = {spiking neural network, reinforcement learning, continuous control},
location = {Tianjin, China},
series = {ICCAI '22}
}

@inproceedings{10.1145/3594315.3594644,
author = {Zhu, Shan and Ling, Xufeng and Zhang, Kui and Niu, Jiachao},
title = {Food Image Recognition Method Based on Generative Self-supervised Learning},
year = {2023},
isbn = {9781450399029},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594315.3594644},
doi = {10.1145/3594315.3594644},
abstract = {The demand of social life for automatic recognition of food images is increasing. Food images have the characteristics of diverse forms, small differences between classes and large differences within classes, which has the problem of high recognition difficulty. This paper proposes a food image recognition method based on generative self-supervised learning. Firstly, we use a BEiT based pre-training model which is trained through generative self-monitoring learning method as the feature extraction network to extract the global semantics and local detail features of food images. And then we fine-tune the fully connected network MLP for classification and recognition through supervised learning method. The model is tested on the current mainstream public food image dataset Food-101, and the top-1 accuracy of 85.99% is obtained. The experimental results show that this method can significantly reduce the computation of pixel level expression as well as extract the global and detailed features of the image, achieving quite good food image classification and recognition effect. Our method has good robustness, generalization and flexibility, which has practical application value.},
booktitle = {Proceedings of the 2023 9th International Conference on Computing and Artificial Intelligence},
pages = {203–207},
numpages = {5},
location = {Tianjin, China},
series = {ICCAI '23}
}

@inproceedings{10.1145/3507548.3507558,
author = {Zheng, Liang and Chen, Ya and Chen, Xiaopan and Zheng, Fengbin},
title = {Age-uniform Feature Learning for Image-based Kinship Verification},
year = {2022},
isbn = {9781450384155},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3507548.3507558},
doi = {10.1145/3507548.3507558},
abstract = {Kinship verification based on face image is an important topic in computer vision and has many applications in practice, such as family pedigree organization, missing person search, etc. Although parent and children share certain similarities in facial images, it is still difficult to verify the kin between people with large age gap. Therefore, how to reduce the influence of age factors on verification is the key to improve the accuracy of kinship verification. To this end, we propose an Age-uniform Face Representation Learning Network (AFRLN) to verify kinship. It mainly consists of Age Uniform Network (AUN) and Verification Network (VFN). Specifically, the design of AUN utilizes the idea of generative adversarial network, which aims to transform parent and child's face images of different ages into images of the uniform age range. Then, the transformed facial images are fed into the verification network, and discriminative deep features of parent and child are obtained. Finally, the output features are fused and then kinship verification task is conducted. Our approach is tested on two publicly kinship datasets: KinFaceW-I and KinfaceW-II. Experimental results validate performance of our method.},
booktitle = {Proceedings of the 2021 5th International Conference on Computer Science and Artificial Intelligence},
pages = {65–71},
numpages = {7},
keywords = {Kinship Verification, Generative Adversarial Network, Feature Fusion, Age Uniform},
location = {Beijing, China},
series = {CSAI '21}
}

@inproceedings{10.1145/3604237.3626857,
author = {Dyer, Joel and Quera-Bofarull, Arnau and Chopra, Ayush and Farmer, J. Doyne and Calinescu, Anisoara and Wooldridge, Michael},
title = {Gradient-Assisted Calibration for Financial Agent-Based Models},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626857},
doi = {10.1145/3604237.3626857},
abstract = {Agent-based modelling (ABMing) is a promising approach to modelling and reasoning about complex systems such as financial markets. However, the application of ABMs in practice is often impeded by the models’ complexity and the ensuing difficulty of performing parameter inference and optimisation tasks. This in turn has motivated efforts directed towards the construction of differentiable ABMs, enabled by recently developed effective auto-differentiation frameworks, as a strategy for addressing these challenges. In this paper, we discuss and present experiments that demonstrate how differentiable programming may be used to implement and calibrate heterogeneous ABMs in finance. We begin by considering in more detail the difficulties inherent in constructing gradients for discrete ABMs. Secondly, we illustrate solutions to these difficulties, by using a discrete agent-based market simulation model as a case study. Finally, we show through numerical experiments how our differentiable implementation of this discrete ABM enables the use of powerful tools from probabilistic machine learning and conditional generative modelling to perform robust parameter inferences and uncertainty quantification, in a simulation-efficient manner.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {288–296},
numpages = {9},
keywords = {agent-based models, automatic differentiation, parameter inference},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00087,
author = {Kang, Sungmin and Yoo, Shin},
title = {GLAD: Neural Predicate Synthesis to Repair Omission Faults},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00087},
doi = {10.1109/ICSE-Companion58688.2023.00087},
abstract = {Existing template and learning-based Automated Program Repair (APR) tools have successfully found patches for many benchmark faults. However, our analysis of existing results shows that omission faults pose a significant challenge. For template based approaches, omission faults provide no location to apply templates to; for learning based approaches that formulate repair as Neural Machine Translation (NMT), omission faults similarly do not provide faulty code to translate. To address these issues, we propose GLAD, a novel learning-based repair technique that targets if-clause synthesis. GLAD does not require a concrete faulty line as it is based on generative Language Models (LMs) instead of machine translation; consequently, it can repair omission faults. To provide the LM with project-specific information critical to synthesis, we incorporate two components: a type-based grammar that constrains the model, and a dynamic ranking system that evaluates candidate patches using a debugger. Our evaluation shows GLAD is highly orthogonal to existing techniques, correctly fixing 26 Defects4J v1.2 faults that previous NMT-based techniques could not, while maintaining a small runtime cost, underscoring its potential as a lightweight tool to complement existing tools in practice. An inspection of the bugs that GLAD fixes reveals that GLAD can quickly generate expressions that would be challenging for other techniques.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {320–321},
numpages = {2},
keywords = {debugging, machine learning, program repair},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.1145/3592427,
author = {Shacklett, Brennan and Rosenzweig, Luc Guy and Xie, Zhiqiang and Sarkar, Bidipta and Szot, Andrew and Wijmans, Erik and Koltun, Vladlen and Batra, Dhruv and Fatahalian, Kayvon},
title = {An Extensible, Data-Oriented Architecture for High-Performance, Many-World Simulation},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {0730-0301},
url = {https://doi.org/10.1145/3592427},
doi = {10.1145/3592427},
abstract = {Training AI agents to perform complex tasks in simulated worlds requires millions to billions of steps of experience. To achieve high performance, today's fastest simulators for training AI agents adopt the idea of batch simulation: using a single simulation engine to simultaneously step many environments in parallel. We introduce a framework for productively authoring novel training environments (including custom logic for environment generation, environment time stepping, and generating agent observations and rewards) that execute as high-performance, GPU-accelerated batched simulators. Our key observation is that the entity-component-system (ECS) design pattern, popular for expressing CPU-side game logic today, is also well-suited for providing the structure needed for high-performance batched simulators. We contribute the first fully-GPU accelerated ECS implementation that natively supports batch environment simulation. We demonstrate how ECS abstractions impose structure on a training environment's logic and state that allows the system to efficiently manage state, amortize work, and identify GPU-friendly coherent parallel computations within and across different environments. We implement several learning environments in this framework, and demonstrate GPU speedups of two to three orders of magnitude over open source CPU baselines and 5-33× over strong baselines running on a 32-thread CPU. An implementation of the OpenAI hide and seek 3D environment written in our framework, which performs rigid body physics and ray tracing in each simulator step, achieves over 1.9 million environment steps per second on a single GPU.},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {90},
numpages = {13},
keywords = {game AI, reinforcement learning}
}

@article{10.1145/3510032,
author = {Ren, Hanchi and Deng, Jingjing and Xie, Xianghua},
title = {GRNN: Generative Regression Neural Network—A Data Leakage Attack for Federated Learning},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3510032},
doi = {10.1145/3510032},
abstract = {Data privacy has become an increasingly important issue in Machine Learning (ML), where many approaches have been developed to tackle this challenge, e.g., cryptography (Homomorphic Encryption (HE), Differential Privacy (DP)) and collaborative training (Secure Multi-Party Computation (MPC), Distributed Learning, and Federated Learning (FL)). These techniques have a particular focus on data encryption or secure local computation. They transfer the intermediate information to the third party to compute the final result. Gradient exchanging is commonly considered to be a secure way of training a robust model collaboratively in Deep Learning (DL). However, recent researches have demonstrated that sensitive information can be recovered from the shared gradient. Generative Adversarial Network (GAN), in particular, has shown to be effective in recovering such information. However, GAN based techniques require additional information, such as class labels that are generally unavailable for privacy-preserved learning. In this article, we show that, in the FL system, image-based privacy data can be easily recovered in full from the shared gradient only via our proposed Generative Regression Neural Network (GRNN). We formulate the attack to be a regression problem and optimize two branches of the generative model by minimizing the distance between gradients. We evaluate our method on several image classification tasks. The results illustrate that our proposed GRNN outperforms state-of-the-art methods with better stability, stronger robustness, and higher accuracy. It also has no convergence requirement to the global FL model. Moreover, we demonstrate information leakage using face re-identification. Some defense strategies are also discussed in this work.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {65},
numpages = {24},
keywords = {image generation, gradient leakage attack, data privacy, Federated learning}
}

@inproceedings{10.1145/3548606.3560586,
author = {Liu, Yupei and Jia, Jinyuan and Liu, Hongbin and Gong, Neil Zhenqiang},
title = {StolenEncoder: Stealing Pre-trained Encoders in Self-supervised Learning},
year = {2022},
isbn = {9781450394505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548606.3560586},
doi = {10.1145/3548606.3560586},
abstract = {Pre-trained encoders are general-purpose feature extractors that can be used for many downstream tasks. Recent progress in self-supervised learning can pre-train highly effective encoders using a large volume of unlabeled data, leading to the emerging encoder as a service (EaaS). A pre-trained encoder may be deemed confidential because its training often requires lots of data and computation resources as well as its public release may facilitate misuse of AI, e.g., for deepfakes generation. In this paper, we propose the first attack called StolenEncoder to steal pre-trained image encoders. We evaluate StolenEncoder on multiple target encoders pre-trained by ourselves and three real-world target encoders including the ImageNet encoder pre-trained by Google, CLIP encoder pre-trained by OpenAI, and Clarifai's General Embedding encoder deployed as a paid EaaS. Our results show that the encoders stolen by StolenEncoder have similar functionality with the target encoders. In particular, the downstream classifiers built upon a target encoder and a stolen encoder have similar accuracy. Moreover, stealing a target encoder using StolenEncoder requires much less data and computation resources than pre-training it from scratch. We also explore three defenses that perturb feature vectors produced by a target encoder. Our evaluation shows that these defenses are not enough to mitigate StolenEncoder.},
booktitle = {Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2115–2128},
numpages = {14},
keywords = {self-supervised learning, pre-trained models, model stealing attacks},
location = {Los Angeles, CA, USA},
series = {CCS '22}
}

@inproceedings{10.1145/3532106.3533464,
author = {Wu, Shengzhi and Byrne, Daragh and Du, Ruofei and Steenson, Molly Wright},
title = {“Slurp” Revisited: Using ‘system re-presencing’ to look back on, encounter, and design with the history of spatial interactivity and locative media},
year = {2022},
isbn = {9781450393584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532106.3533464},
doi = {10.1145/3532106.3533464},
abstract = {Hand-based gestural interaction in augmented reality (AR) is an increasingly popular mechanism for spatial interactions. However, it presents many challenges. For example, most hand gesture interactions work well for interactions with virtual content and interfaces, but seldom work with physical devices and users’ environment. To explore this, and rather than inventing new paradigms for AR interactions, this paper revisits Zigelbaum, Kumpf, Vazquez, and Ishii’s 2008 project ‘Slurp’ [72] - a physical eyedropper to interact with digital content from IoT devices. We revive this historical work in a new modality of AR through a five step process: re-presecencing, design experimentation, scenario making, expansion through generative engagements with designers, and reflection. For the designers we engaged, looking back and designing with a restored prototype helped increased understanding of interactive strategies, intentions and rationales of original work. By revisiting Slurp, we also found many new potentials of its metaphorical interactions that could be applied in the context of emerging spatial computing platforms (e.g., smart home devices). In doing so, we discuss the value of mining past works in new domains and demonstrate a new way of thinking about designing interactions in emerging platforms.},
booktitle = {Proceedings of the 2022 ACM Designing Interactive Systems Conference},
pages = {263–276},
numpages = {14},
keywords = {affordances, augmented reality, gestural interface, historical precedents, metaphor, software reconstruction, spatial interaction, system re-presencing},
location = {Virtual Event, Australia},
series = {DIS '22}
}

@article{10.1145/3569492,
author = {Elhattab, Fatima and Bouchenak, Sara and Talbi, Rania and Nitu, Vlad},
title = {Robust Federated Learning for Ubiquitous Computing through Mitigation of Edge-Case Backdoor Attacks},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569492},
doi = {10.1145/3569492},
abstract = {Federated Learning (FL) allows several data owners to train a joint model without sharing their training data. Such a paradigm is useful for better privacy in many ubiquitous computing systems. However, FL is vulnerable to poisoning attacks, where malicious participants attempt to inject a backdoor task in the model at training time, along with the main task that the model was initially trained for. Recent works show that FL is particularly vulnerable to edge-case backdoors introduced by data points with unusual out-of-distribution features. Such attacks are among the most difficult to counter, and today's FL defense mechanisms usually fail to tackle them. In this paper, we present ARMOR, a defense mechanism that leverages adversarial learning to uncover edge-case backdoors. In contrast to most of existing FL defenses, ARMOR does not require real data samples and is compatible with secure aggregation, thus, providing better FL privacy protection. ARMOR relies on GANs (Generative Adversarial Networks) to extract data features from model updates, and uses the generated samples to test the activation of potential edge-case backdoors in the model. Our experimental evaluations with three widely used datasets and neural networks show that ARMOR can tackle edge-case backdoors with 95% resilience against attacks, and without hurting model quality.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {162},
numpages = {27},
keywords = {Ubiquitous Computing, Robustness, Federated Learning, Edge-Case Backdoor}
}

@inproceedings{10.1145/3490099.3511157,
author = {Weisz, Justin D. and Muller, Michael and Ross, Steven I. and Martinez, Fernando and Houde, Stephanie and Agarwal, Mayank and Talamadupula, Kartik and Richards, John T.},
title = {Better Together? An Evaluation of AI-Supported Code Translation},
year = {2022},
isbn = {9781450391443},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490099.3511157},
doi = {10.1145/3490099.3511157},
abstract = {Generative machine learning models have recently been applied to source code, for use cases including translating code between programming languages, creating documentation from code, and auto-completing methods. Yet, state-of-the-art models often produce code that is erroneous or incomplete. In a controlled study with 32 software engineers, we examined whether such imperfect outputs are helpful in the context of Java-to-Python code translation. When aided by the outputs of a code translation model, participants produced code with fewer errors than when working alone. We also examined how the quality and quantity of AI translations affected the work process and quality of outcomes, and observed that providing multiple translations had a larger impact on the translation process than varying the quality of provided translations. Our results tell a complex, nuanced story about the benefits of generative code models and the challenges software engineers face when working with their outputs. Our work motivates the need for intelligent user interfaces that help software engineers effectively work with generative code models in order to understand and evaluate their outputs and achieve superior outcomes to working alone.},
booktitle = {Proceedings of the 27th International Conference on Intelligent User Interfaces},
pages = {369–391},
numpages = {23},
keywords = {Code translation, generative AI, human-AI co-creation, imperfect AI},
location = {Helsinki, Finland},
series = {IUI '22}
}

@inproceedings{10.1145/3534678.3539290,
author = {Wei, Jiawen and Wang, Fangyuan and Zeng, Wanxin and Lin, Wenwei and Gui, Ning},
title = {An Embedded Feature Selection Framework for Control},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539290},
doi = {10.1145/3534678.3539290},
abstract = {Reducing sensor requirements while keeping optimal control performance is crucial to many industrial control applications to achieve robust, low-cost, and computation-efficient controllers. However, existing feature selection solutions for the typical machine learning domain can hardly be applied in the domain of control with changing dynamics. In this paper, a novel framework, namely the Dual-world embedded Attentive Feature Selection (D-AFS), can efficiently select the most relevant sensors for the system under dynamic control. Rather than the one world used in most Deep Reinforcement Learning (DRL) algorithms, D-AFS has both the real world and its virtual peer with twisted features. By analyzing the DRL's response in two worlds, D-AFS can quantitatively identify respective features' importance towards control. A well-known active flow control problem, cylinder drag reduction, is used for evaluation. Results show that D-AFS successfully finds an optimized five-probes layout with 18.7% drag reduction than the state-of-the-art solution with 151 probes and 49.2% reduction than five-probes layout by human experts. We also apply this solution to four OpenAI classical control cases. In all cases, D-AFS achieves the same or better sensor configurations than originally provided solutions. Results highlight, we argued, a new way to achieve efficient and optimal sensor designs for experimental or industrial systems. Our source codes are made publicly available at https://github.com/G-AILab/DAFSFluid.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1979–1988},
numpages = {10},
keywords = {deep reinforcement learning, feature selection, optimal sensor placement},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3573381.3596460,
author = {Maiorca, Antoine and Yoon, Youngwoo and Dutoit, Thierry},
title = {Validating Objective Evaluation Metric: Is Fréchet Motion Distance able to Capture Foot Skating Artifacts ?},
year = {2023},
isbn = {9798400700286},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573381.3596460},
doi = {10.1145/3573381.3596460},
abstract = {Automatically generating character motion is one of the technologies required for virtual reality, graphics, and robotics. Motion synthesis with deep learning is an emerging research topic. A key component of the development of such an algorithm involves the design of a proper objective metric to evaluate the quality and diversity of the synthesized motion dataset, two key factors of the performance of generative models. The Fréchet distance is nowadays a common method to assess this performance. In the motion generation field, the validation of such evaluation methods relies on the computation of the Fréchet distance between embeddings of the ground truth dataset and motion samples polluted by synthetic noise to mimic the artifacts produced by generative algorithms. However, the synthetic noise degradation does not fully represent motion perturbations that are commonly perceived. One of these artifacts is foot skating: the unnatural foot slides on the ground during locomotion. In this work-in-progress paper, we tested how well the Fréchet Motion Distance (FMD), which was proposed in previous works, is able to measure foot skating artifacts, and we found that FMD is not able to measure efficiently the intensity of the skating degradation.},
booktitle = {Proceedings of the 2023 ACM International Conference on Interactive Media Experiences},
pages = {242–247},
numpages = {6},
keywords = {Motion Generation, Generative Model Evaluation, Deep Neural Network},
location = {Nantes, France},
series = {IMX '23}
}

@article{10.1145/3605548,
author = {Zhang, Yuxin and Tang, Fan and Dong, Weiming and Huang, Haibin and Ma, Chongyang and Lee, Tong-Yee and Xu, Changsheng},
title = {A Unified Arbitrary Style Transfer Framework via Adaptive Contrastive Learning},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {0730-0301},
url = {https://doi.org/10.1145/3605548},
doi = {10.1145/3605548},
abstract = {This work presents Unified Contrastive Arbitrary Style Transfer (UCAST), a novel style representation learning and transfer framework, that can fit in most existing arbitrary image style transfer models, such as CNN-based, ViT-based, and flow-based methods. As the key component in image style transfer tasks, a suitable style representation is essential to achieve satisfactory results. Existing approaches based on deep neural networks typically use second-order statistics to generate the output. However, these hand-crafted features computed from a single image cannot leverage style information sufficiently, which leads to artifacts such as local distortions and style inconsistency. To address these issues, we learn style representation directly from a large number of images based on contrastive learning by considering the relationships between specific styles and the holistic style distribution. Specifically, we present an adaptive contrastive learning scheme for style transfer by introducing an input-dependent temperature. Our framework consists of three key components: a parallel contrastive learning scheme for style representation and transfer, a domain enhancement (DE) module for effective learning of style distribution, and a generative network for style transfer. Qualitative and quantitative evaluations show the results of our approach are superior to those obtained via state-of-the-art methods. The code is available at .},
journal = {ACM Trans. Graph.},
month = jul,
articleno = {169},
numpages = {16},
keywords = {style encoding, contrastive learning, Arbitrary style transfer}
}

@inproceedings{10.1145/3548606.3563493,
author = {Hallman, Roger A.},
title = {Poster EveGAN: Using Generative Deep Learning for Cryptanalysis},
year = {2022},
isbn = {9781450394505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548606.3563493},
doi = {10.1145/3548606.3563493},
abstract = {Cryptography and Machine Learning are two computational science fields that intuitively seem related. Privacy-preserving machine learning-either utilizing encrypted models or learning over encrypted data-is an exploding field thanks to the maturation of primitives such as fully homomorphic encryption and secure multiparty computation. However there has been surprisingly little work on applying recent advances in machine learning to the task of cryptanalysis, the branch of cryptography that studies how cryptographic ciphers can be attacked. In particular, while a cryptographic cipher seeks to keep certain information secret by making it appear random, discerning patterns and structure from random data is a common machine learning task. This paper proposes EveGAN, an approach that treats cryptanalysis as a language translation problem. While treating cipher cracking as a language translation problem has been validated against a handful of classical substitution ciphers, the EveGAN approach builds on these results to create a new class of generative deep learning-based cryptanalysis attacks.},
booktitle = {Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3355–3357},
numpages = {3},
keywords = {language translation, generative adversarial networks, forgery/poisoning attacks, cryptography, cryptanalysis},
location = {Los Angeles, CA, USA},
series = {CCS '22}
}

@inproceedings{10.1145/3556557.3557953,
author = {Kortoçi, Pranvera and Liang, Yilei and Zhou, Pengyuan and Lee, Lik-Hang and Mehrabi, Abbas and Hui, Pan and Tarkoma, Sasu and Crowcroft, Jon},
title = {Federated split GANs},
year = {2022},
isbn = {9781450395212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3556557.3557953},
doi = {10.1145/3556557.3557953},
abstract = {Mobile devices and the immense amount and variety of data they generate are key enablers of machine learning (ML)-based applications. Traditional ML techniques have shifted toward new paradigms such as federated learning (FL) and split learning (SL) to improve the protection of user's data privacy. However, SL often relies on server(s) located in the edge or cloud to train computationally-heavy parts of an ML model to avoid draining the limited resource on client devices, potentially resulting in exposure of device data to such third parties.This work proposes an alternative approach to train computationally heavy ML models in user's devices themselves, where corresponding device data resides. Specifically, we focus on GANs (generative adversarial networks) and leverage their network architecture to preserve data privacy. We train the discriminative part of a GAN on user's devices with their data, whereas the generative model is trained remotely (e.g., server) for which there is no need to access device true data. Moreover, our approach ensures that the computational load of training the discriminative model is shared among user's devices - proportional to their computation capabilities - by means of SL. We implement our proposed collaborative training scheme of a computationally-heavy GAN model in simulated resource-constrained devices. The results show that our system preserves data privacy, keeps a short training time, and yields the same model accuracy as when the model is trained on devices with unconstrained resources (e.g., cloud). Our code can be found at https://github.com/YukariSonz/FSL-GAN.},
booktitle = {Proceedings of the 1st ACM Workshop on Data Privacy and Federated Learning Technologies for Mobile Edge Network},
pages = {25–30},
numpages = {6},
keywords = {split learning, federated learning, GAN},
location = {Sydney, New South Wales, Australia},
series = {FedEdge '22}
}

@inproceedings{10.1145/3600100.3623749,
author = {Almilaify, Yara and Nweye, Kingsley and Nagy, Zoltan},
title = {SCALEX: SCALability EXploration of Multi-Agent Reinforcement Learning Agents in Grid-Interactive Efficient Buildings},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3623749},
doi = {10.1145/3600100.3623749},
abstract = {Renewable energy transition and decarbonization pose significant challenges for grid-interactive efficient building communities. The optimization of intermittent renewable energy can be achieved using advanced control architecture and energy storage, enhancing energy flexibility. Reinforcement learning (RL) offers potential solutions, but its scalability and computational demands in large-scale settings remain unclear. This paper examines the scalability of Soft-Actor Critic (SAC) in multi-agent systems, comparing decentralized-independent SACs and centralized SACs using CityLearn, an OpenAI Gym environment. We consider neighborhoods consisting of 2 to 64 single-family residential buildings, each equipped with cooling and heating storage devices, domestic hot water storage devices, electrical storage devices, and solar PV systems. Our findings suggest that independent controllers outperform the centralized controller with increasing number of buildings. We also show that the performance on the building level can differ from the aggregated performance.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {261–264},
numpages = {4},
keywords = {demand response, energy flexibility, multi agent system},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@inproceedings{10.1145/3607828.3617796,
author = {Han, Yue and He, Jiangpeng and Gupta, Mridul and Delp, Edward J. and Zhu, Fengqing},
title = {Diffusion Model with Clustering-based Conditioning for Food Image Generation},
year = {2023},
isbn = {9798400702846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607828.3617796},
doi = {10.1145/3607828.3617796},
abstract = {Image-based dietary assessment serves as an efficient and accurate solution for recording and analyzing nutrition intake using eating occasion images as input. Deep learning-based techniques are commonly used to perform image analysis such as food classification, segmentation, and portion size estimation, which rely on large amounts of food images with annotations for training. However, such data dependency poses significant barriers to real-world applications, because acquiring a substantial, diverse, and balanced set of food images can be challenging. One potential solution is to use synthetic food images for data augmentation. Although existing work has explored the use of generative adversarial networks (GAN) based structures for generation, the quality of synthetic food images still remains subpar. In addition, while diffusion-based generative models have shown promising results for general image generation tasks, the generation of food images can be challenging due to the substantial intra-class variance. In this paper, we investigate the generation of synthetic food images based on the conditional diffusion model and propose an effective clustering-based training framework, named ClusDiff, for generating high-quality and representative food images. The proposed method is evaluated on the Food-101 dataset and shows improved performance when compared with existing image generation works. We also demonstrate that the synthetic food images generated by ClusDiff can help address the severe class imbalance issue in long-tailed food classification using the VFN-LT dataset.},
booktitle = {Proceedings of the 8th International Workshop on Multimedia Assisted Dietary Management},
pages = {61–69},
numpages = {9},
keywords = {diffusion model, food classification, food image generation, image-based dietary assessment},
location = {Ottawa ON, Canada},
series = {MADiMa '23}
}

@inproceedings{10.1145/3510003.3510172,
author = {Izadi, Maliheh and Gismondi, Roberta and Gousios, Georgios},
title = {CodeFill: multi-token code completion by jointly learning from structure and naming sequences},
year = {2022},
isbn = {9781450392211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510003.3510172},
doi = {10.1145/3510003.3510172},
abstract = {Code completion is an essential feature of IDEs, yet current auto-completers are restricted to either grammar-based or NLP-based single token completions. Both approaches have significant drawbacks: grammar-based autocompletion is restricted in dynamically-typed language environments, whereas NLP-based autocompleters struggle to understand the semantics of the programming language and the developer's code context.In this work, we present CodeFill, a language model for autocompletion that combines learned structure and naming information. Using a parallel Transformer architecture and multi-task learning, CodeFill consumes sequences of source code token names and their equivalent AST token types. Uniquely, CodeFill is trained both for single-token and multi-token (statement) prediction, which enables it to learn long-range dependencies among grammatical and naming elements. We train CodeFill on two datasets, consisting of 29M and 425M lines of code, respectively. To make the evaluation more realistic, we develop a method to automatically infer points in the source code at which completion matters. We compare CodeFill against four baselines and two state-of-the-art models, GPT-C and TravTrans+. CodeFill surpasses all baselines in single token prediction (MRR: 70.9% vs. 66.2% and 67.8%) and outperforms the state of the art for multi-token prediction (ROUGE-L: 63.7% vs. 52.4% and 59.2%, for n = 4 tokens). We publicly release our source code and datasets.},
booktitle = {Proceedings of the 44th International Conference on Software Engineering},
pages = {401–412},
numpages = {12},
keywords = {automatic code completion, dynamically-typed languages, multi-task learning, transformers, types},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3514221.3520161,
author = {Porwal, Vibhor and Mitra, Subrata and Du, Fan and Anderson, John and Sheoran, Nikhil and Rao, Anup and Mai, Tung and Kowshik, Gautam and Nair, Sapthotharan and Arora, Sameeksha and Mahapatra, Saurabh},
title = {Efficient Insights Discovery through Conditional Generative Model based Query Approximation},
year = {2022},
isbn = {9781450392495},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3514221.3520161},
doi = {10.1145/3514221.3520161},
abstract = {There are various scenarios where very quick insights from a massive amount of data need to be extracted in a time-critical manner. These might be fresh insights or re-looking at why previous insights did not work and how to fix those. A marketing campaign is one real-world scenario where a non-programmer needs to dig such huge data in a very short period of time (a few hours) in order to hit a target revenue. In this demo paper, we will describe Electra - a system that integrates an automated data-insight discovery mechanism with a novel machine-learning (ML) driven approximate query processing (AQP) engine that can answer complex queries with a large number of predicates or conditions with high accuracy. This AQP engine uses a conditional generative model to generate a very small sample (~1000 rows) corresponding to the actual query to be answered and computes the highly accurate approximate answer from those instead of running the query against the original data. The insight discovery workflow bootstraps insights using ML algorithms based on the statistical characteristics of the data and further offers a no-code based interface to drill down for deeper insights. The queries from this interface are answered by the AQP engine that runs locally at the client-side itself to offer low latency interactions.},
booktitle = {Proceedings of the 2022 International Conference on Management of Data},
pages = {2397–2400},
numpages = {4},
keywords = {approximate query processing, chart recommendation, data analytics, machine learning},
location = {Philadelphia, PA, USA},
series = {SIGMOD '22}
}

@article{10.1145/3487045,
author = {Gupta, Manish and Agrawal, Puneet},
title = {Compression of Deep Learning Models for Text: A Survey},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1556-4681},
url = {https://doi.org/10.1145/3487045},
doi = {10.1145/3487045},
abstract = {In recent years, the fields of natural language processing (NLP) and information retrieval (IR) have made tremendous progress thanks to deep learning models like Recurrent Neural Networks (RNNs), Gated Recurrent Units (GRUs) and Long Short-Term Memory (LSTMs) networks, and Transformer&nbsp;[121] based models like Bidirectional Encoder Representations from Transformers (BERT)&nbsp;[24], Generative Pre-training Transformer (GPT-2)&nbsp;[95], Multi-task Deep Neural Network (MT-DNN)&nbsp;[74], Extra-Long Network (XLNet)&nbsp;[135], Text-to-text transfer transformer (T5)&nbsp;[96], T-NLG&nbsp;[99], and GShard&nbsp;[64]. But these models are humongous in size. On the other hand, real-world applications demand small model size, low response times, and low computational power wattage. In this survey, we discuss six different types of methods (Pruning, Quantization, Knowledge Distillation (KD), Parameter Sharing, Tensor Decomposition, and Sub-quadratic Transformer-based methods) for compression of such models to enable their deployment in real industry NLP projects. Given the critical need of building applications with efficient and small models, and the large amount of recently published work in this area, we believe that this survey organizes the plethora of work done by the “deep learning for NLP” community in the past few years and presents it as a coherent story.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jan,
articleno = {61},
numpages = {55},
keywords = {sub-quadratic transformers, tensor factorization, parameter sharing, knowledge distillation, quantization, pruning, deep learning, Model compression}
}

@article{10.1145/3571159,
author = {Feng, Yujie and Wang, Jiangtao and Wang, Yasha and Chu, Xu},
title = {Towards Sustainable Compressive Population Health: A GAN-based Year-By-Year Imputation Method},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3571159},
doi = {10.1145/3571159},
abstract = {Population health monitoring is a fundamental component of the public health system. Due to the high-cost nature of traditional population-wise health-data collection methods, a class of sparse-sampling-completion algorithms are proposed to exploit the spatio-temporal correlation buried under the observed examples. However, for the population health data, a huge challenge for the state-of-the-art completion methods is the unstationary environment. Specifically, the underlying temporal correlation of the population health data are evolving from year to year. To this end, we propose a GAN-based year-by-year completion framework: uncertainty-aware augmented generative adversarial imputation nets (UAA-GAIN), to address the problem of unstationary environment. To further restrain the error accumulation, we develop a stronger generator as well as a stronger discriminator in the min-max equilibrium. A by-product of the augmented GAIN model allows weighting the difficulty of examples. Inspired by the idea of curriculum learning, a better training schedule is implemented in the proposed framework. We evaluate the proposed method on three real-world chronic disease datasets and the results show that UAA-GAIN outperforms other baseline methods in various settings.},
journal = {ACM Trans. Comput. Healthcare},
month = mar,
articleno = {8},
numpages = {18},
keywords = {curriculum learning, generative adversarial network, missing data recovery, Population health}
}

@article{10.1145/3473340,
author = {Xu, Sheng and Liu, Chang and Zhang, Baochang and Lü, Jinhu and Guo, Guodong and Doermann, David},
title = {BiRe-ID: Binary Neural Network for Efficient Person Re-ID},
year = {2022},
issue_date = {February 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {1s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3473340},
doi = {10.1145/3473340},
abstract = {Person re-identification (Re-ID) has been promoted by the significant success of convolutional neural networks (CNNs). However, the application of such CNN-based Re-ID methods depends on the tremendous consumption of computation and memory resources, which affects its development on resource-limited devices such as next generation AI chips. As a result, CNN binarization has attracted increasing attention, which leads to binary neural networks (BNNs). In this article, we propose a new BNN-based framework for efficient person Re-ID (BiRe-ID). In this work, we discover that the significant performance drop of binarized models for Re-ID task is caused by the degraded representation capacity of kernels and features. To address the issues, we propose the kernel and feature refinement based on generative adversarial learning (KR-GAL and FR-GAL) to enhance the representation capacity of BNNs. We first introduce an adversarial attention mechanism to refine the binarized kernels based on their real-valued counterparts. Specifically, we introduce a scale factor to restore the scale of 1-bit convolution. And we employ an effective generative adversarial learning method to train the attention-aware scale factor. Furthermore, we introduce a self-supervised generative adversarial network to refine the low-level features using the corresponding high-level semantic information. Extensive experiments demonstrate that our BiRe-ID can be effectively implemented on various mainstream backbones for the Re-ID task. In terms of the performance, our BiRe-ID surpasses existing binarization methods by significant margins, at the level even comparable with the real-valued counterparts. For example, on Market-1501, BiRe-ID achieves 64.0% mAP on ResNet-18 backbone, with an impressive 12.51× speedup in theory and 11.75× storage saving. In particular, the KR-GAL and FR-GAL methods show strong generalization on multiple tasks such as Re-ID, image classification, object detection, and 3D point cloud processing.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = feb,
articleno = {26},
numpages = {22},
keywords = {network compression, network binarization, Person re-identification}
}

@inproceedings{10.1145/3520304.3528770,
author = {Tang, Yujin and Tian, Yingtao and Ha, David},
title = {EvoJAX: hardware-accelerated neuroevolution},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3528770},
doi = {10.1145/3520304.3528770},
abstract = {Evolutionary computation has been shown to be a highly effective method for training neural networks, particularly when employed at scale on CPU clusters. Recent work have also showcased their effectiveness on hardware accelerators, such as GPUs, but so far such demonstrations are tailored for very specific tasks, limiting applicability to other domains. We present EvoJAX, a scalable, general purpose, hardware-accelerated neuroevolution toolkit. Building on top of the JAX library, our toolkit enables neuroevolution algorithms to work with neural networks running in parallel across multiple TPU/GPUs. EvoJAX achieves very high performance by implementing the evolution algorithm, neural network and task all in NumPy, which is compiled just-in-time to run on accelerators. We provide extensible examples of EvoJAX for a wide range of tasks, including supervised learning, reinforcement learning and generative art. Since EvoJAX can find solutions to most of these tasks within minutes on a single accelerator, compared to hours or days when using CPUs, our toolkit can significantly shorten the iteration cycle of evolutionary computation experiments. EvoJAX is available at https://github.com/google/evojax},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {308–311},
numpages = {4},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@inproceedings{10.1145/3533767.3534396,
author = {Zhang, Jialu and Mytkowicz, Todd and Kaufman, Mike and Piskac, Ruzica and Lahiri, Shuvendu K.},
title = {Using pre-trained language models to resolve textual and semantic merge conflicts (experience paper)},
year = {2022},
isbn = {9781450393799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533767.3534396},
doi = {10.1145/3533767.3534396},
abstract = {Program merging is standard practice when developers integrate their individual changes to a common code base. When the merge algorithm fails, this is called a merge conflict. The conflict either manifests as a textual merge conflict where the merge fails to produce code, or as a semantic merge conflict where the merged code results in compiler errors or broken tests. Resolving these conflicts for large code projects is expensive because it requires developers to manually identify the sources of conflicts and correct them.  
 In this paper, we explore the feasibility of automatically repairing merge conflicts (both textual and semantic) using k-shot learning with pre-trained large neural language models (LM) such as GPT-3. One of the challenges in leveraging such language models is fitting the examples and the queries within a small prompt (2048 tokens). We evaluate LMs and k-shot learning for both textual and semantic merge conflicts for Microsoft Edge. Our results are mixed: on one-hand, LMs provide the state-of-the-art (SOTA) performance on semantic merge conflict resolution for Edge compared to earlier symbolic approaches; on the other hand, LMs do not yet obviate the benefits of special purpose domain-specific languages (DSL) for restricted patterns for program synthesis.},
booktitle = {Proceedings of the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {77–88},
numpages = {12},
keywords = {language model, k-shot learning, Resolving merge conflicts, GPT-3},
location = {Virtual, South Korea},
series = {ISSTA 2022}
}

@inproceedings{10.1145/3533271.3561669,
author = {Feng, Yichen and Min, Ming and Fouque, Jean-Pierre},
title = {Deep Learning for Systemic Risk Measures},
year = {2022},
isbn = {9781450393768},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533271.3561669},
doi = {10.1145/3533271.3561669},
abstract = {The aim of this paper is to study a new methodological framework for systemic risk measures by applying deep learning method as a tool to compute the optimal strategy of capital allocations. Under this new framework, systemic risk measures can be interpreted as the minimal amount of cash that secures the aggregated system by allocating capital to the single institutions before aggregating the individual risks. This problem has no explicit solution except in very limited situations. Deep learning is increasingly receiving attention in financial modelings and risk management and we propose our deep learning based algorithms to solve both the primal and dual problems of the risk measures, and thus to learn the fair risk allocations. In particular, our method for the dual problem involves the training philosophy inspired by the well-known Generative Adversarial Networks (GAN) approach and a newly designed direct estimation of Radon-Nikodym derivative. We close the paper with substantial numerical studies of the subject and provide interpretations of the risk allocations associated to the systemic risk measures. In the particular case of exponential preferences, numerical experiments demonstrate excellent performance of the proposed algorithm, when compared with the optimal explicit solution as a benchmark.},
booktitle = {Proceedings of the Third ACM International Conference on AI in Finance},
pages = {62–69},
numpages = {8},
keywords = {systemic risk measure, risk modeling and risk management, risk allocations, deep learning, banking system, Radon-Nikodym derivative, GAN},
location = {New York, NY, USA},
series = {ICAIF '22}
}

@inproceedings{10.1145/3588432.3591492,
author = {Park, Jungnam and Park, Moon Seok and Lee, Jehee and Won, Jungdam},
title = {Bidirectional GaitNet: A Bidirectional Prediction Model of Human Gait and Anatomical Conditions},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591492},
doi = {10.1145/3588432.3591492},
abstract = {We present a novel generative model, called Bidirectional GaitNet, that learns the relationship between human anatomy and its gait. The simulation model of human anatomy is a comprehensive, full-body, simulation-ready, musculoskeletal model with 304 Hill-type musculotendon units. The Bidirectional GaitNet consists of forward and backward models. The forward model predicts a gait pattern of a person with specific physical conditions, while the backward model estimates the physical conditions of a person when his/her gait pattern is provided. Our simulation-based approach first learns the forward model by distilling the simulation data generated by a state-of-the-art predictive gait simulator and then constructs a Variational Autoencoder (VAE) with the learned forward model as its decoder. Once it is learned its encoder serves as the backward model. We demonstrate our model on a variety of healthy/impaired gaits and validate it in comparison with physical examination data of real patients.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
articleno = {6},
numpages = {9},
keywords = {Clinical Gait Analysis, GaitNet, Musculoskeletal Simulation, Predictive Gait Simulation},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3543507.3583276,
author = {Yuan, Yuan and Wang, Huandong and Ding, Jingtao and Jin, Depeng and Li, Yong},
title = {Learning to Simulate Daily Activities via Modeling Dynamic Human Needs},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583276},
doi = {10.1145/3543507.3583276},
abstract = {Daily activity data that records individuals’ various types of activities in daily life are widely used in many applications such as activity scheduling, activity recommendation, and policymaking. Though with high value, its accessibility is limited due to high collection costs and potential privacy issues. Therefore, simulating human activities to produce massive high-quality data is of great importance to benefit practical applications. However, existing solutions, including rule-based methods with simplified assumptions of human behavior and data-driven methods directly fitting real-world data, both cannot fully qualify for matching reality. In this paper, motivated by the classic psychological theory, Maslow’s need theory describing human motivation, we propose a knowledge-driven simulation framework based on generative adversarial imitation learning. To enhance the fidelity and utility of the generated activity data, our core idea is to model the evolution of human needs as the underlying mechanism that drives activity generation in the simulation model. Specifically, this is achieved by a hierarchical model structure that disentangles different need levels, and the use of neural stochastic differential equations that successfully captures piecewise-continuous characteristics of need dynamics. Extensive experiments demonstrate that our framework outperforms the state-of-the-art baselines in terms of data fidelity and utility. Besides, we present the insightful interpretability of the need modeling. The code is available at https://github.com/tsinghua-fib-lab/Activity-Simulation-SAND.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {906–916},
numpages = {11},
keywords = {Daily activities, GAIL, Human needs, Simulation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3610537.3622953,
author = {Nelson, Peter Andrew Clarke},
title = {TreeGAN},
year = {2023},
isbn = {9798400703089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610537.3622953},
doi = {10.1145/3610537.3622953},
abstract = {TreeGAN is an investigation into how machine learning and generative adversarial networks (GANS) create 3-dimensional objects. As machine learning finds an increasing number of applications within visual culture, we was interested to see how such systems might influence how we think about 3D objects. When this project started in 2019, there were relatively few art projects that used machine learning to produce 3D objects and even fewer that were trained on 3D objects to produce 3D objects (as opposed to synthesising 3D forms from 2D images), partly due to the paucity of conditional datasets of 3D objects. We synthesised a dataset of 3D objects using a form that is easy to produce and recognise - trees. Previous studies for 3D machine learning tended to focus on geometrically simple objects such as IKEA furniture (Lim et al 2013) and industrial objects (Wu et al 2016), therefore, trees presented an opportunity to observe how a 3D machine learning system would approach complex yet familiar organic forms. Trees are often used in visual art as metaphors for the human experience, from the scholarly pines of Chinese ink painting (Clunas 2002) (McMahon 2003) to the martyred oaks of German Romanticism (Rosenblum 1975), and thus add an empathetic layer to our formal exploration. Three-dimensional trees are easy to produce on a large scale using Lindenmayer systems, and we made 76 unique tree templates, based on art historical references and exported 350 random variations of these templates, giving us a dataset of just over 26,000 3D trees. We watched the transition of beautiful abstractions as the system progressed from random 3D noise to recognizable trees, a process we likened to the analytical cubism of Picasso and Braque in the early 20th century, where we could observe a new technological system developing its own form of figuration.},
booktitle = {SIGGRAPH Asia 2023 Art Gallery},
articleno = {22},
numpages = {1},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@article{10.1145/3522574,
author = {Gao, Yang},
title = {Icon Art Design Language Combined with Real-time Intelligent Image Processing under Internet of Things},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3522574},
doi = {10.1145/3522574},
abstract = {While providing massive information, the intelligent media Internet of Things (IoT) also poses challenges to the overall environment and the development of modern market economy. The employment of enterprises and people is still facing great difficulties, and the world economic situation is still complicated and severe. In addition, there are many design resources for icon art design on the Internet, and with different design styles, the demand for icon design is also increasing. The biggest difference between icons and ordinary pictures is that icons can convey the characteristics and meaning of pictures faster. The Generative Adversarial Network (GAN) technology in intelligent image processing and the TensorFlow learning framework are used to build and improve the icon generation network to simplify the icon design process. Computers are used in place of designers for icon art design. Firstly, the related technical background of icon generation network implementation is drawn through the introduction of related concepts of intelligent image processing. Secondly, Python is used to process the established icon dataset. Finally, the icon generation network is improved. The model training results show that the icon generation network has a peak feature loss value of 9.0 and an average error of 8.0. After the color label is added, the effect is significantly improved. The improved icon generation network has a peak feature loss of 7.0 and an average error of 6.0. The results show that after the color labels are added, the improved GAN model has a very high recognition rate for artistic icons. The improved network model also distinguishes the newly generated icons from the original ones. The comprehensive application effect of the model is good. This provides specific application and reference value for the intelligent development of the IoT.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = mar,
keywords = {intelligent media era, image processing, icon art, generative adversarial network, IoT intelligence}
}

@inproceedings{10.1145/3584371.3612953,
author = {Quintana, Felix and Treangen, Todd and Kavraki, Lydia},
title = {Leveraging Large Language Models for Predicting Microbial Virulence from Protein Structure and Sequence},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3612953},
doi = {10.1145/3584371.3612953},
abstract = {In the aftermath of COVID-19, screening for pathogens has never been a more relevant problem. However, computational screening for pathogens is challenging due to a variety of factors, including (i) the complexity and role of the host, (ii) virulence factor divergence and dynamics, and (iii) population and community-level dynamics. Considering a potential pathogen's molecular interactions, specifically individual proteins and protein interactions can help pinpoint a potential protein of a given microbe to cause disease. However, existing tools for pathogen screening rely on existing annotations (KEGG, GO, etc), making the assessment of novel and unannotated proteins more challenging. Here, we present an LLM-inspired approach that considers protein sequence and structure to predict protein virulence. We present a two-stage model incorporating evolutionary features captured from the DistilProtBert language model and protein structure in a graph convolutional network. Our model performs better than sequence alone for virulence function when high-quality structures are present, thus representing a path forward for virulence prediction of novel and unannotated proteins.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {103},
numpages = {6},
keywords = {protein function, virulence prediction, graph-based models, large language models},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3569052.3572993,
author = {Lu, Yi-Chen and Ren, Haoxing and Hsiao, Hao-Hsiang and Lim, Sung Kyu},
title = {DREAM-GAN: Advancing DREAMPlace towards Commercial-Quality using Generative Adversarial Learning},
year = {2023},
isbn = {9781450399784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569052.3572993},
doi = {10.1145/3569052.3572993},
abstract = {DREAMPlace is a renowned open-source placer that provides GPU-acceleratable infrastructure for placements of Very-Large-Scale-Integration (VLSI) circuits. However, due to its limited focus on wirelength and density, existing placement solutions of DREAMPlace are not applicable to industrial design flows. To improve DREAMPlace towards commercial-quality without knowing the black-boxed algorithms of the tools, in this paper, we present DREAM-GAN, a placement optimization framework that advances DREAMPlace using generative adversarial learning. At each placement iteration, aside from optimizing the wirelength and density objectives of the vanilla DREAMPlace, DREAM-GAN computes and optimizes a differentiable loss that denotes the similarity score between the underlying placement and the tool-generated placements in commercial databases. Experimental results on 5 commercial and OpenCore designs using an industrial design flow implemented by Synopsys ICC2 not only demonstrate that DREAM-GAN significantly improves the vanilla DREAMPlace at the placement stage across each benchmark, but also show that the improvements last firmly to the post-route stage, where we observe improvements by up to 8.3% in wirelength and 7.4% in total power.},
booktitle = {Proceedings of the 2023 International Symposium on Physical Design},
pages = {141–148},
numpages = {8},
keywords = {generative adversarial learning, placement optimization},
location = {Virtual Event, USA},
series = {ISPD '23}
}

@inproceedings{10.1145/3627377.3627380,
author = {Zhang, Fan and Zhang, Shun and Fang, Chun},
title = {CPPGAN-ESM: GAN-Enhanced ESM Prediction Model for Cell-Penetrating Peptide},
year = {2023},
isbn = {9798400707667},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627377.3627380},
doi = {10.1145/3627377.3627380},
abstract = {Cell-penetrating peptide, with their ability to traverse cell membranes and access the intracellular environment, has garnered significant attention in contemporary medical research. Predicting cell-penetrating peptide can expand the therapeutic scope, improve the therapeutic effect, and promote the development of drug delivery, gene therapy, and other fields. Compared with the traditional wet-lab method, predicting cell-penetrating peptide by computational methods has the advantages of low cost and accuracy. However, due to the difficulty of collecting cell-penetrating peptide datasets and the performance limitation of traditional feature extractors, Predicting the performance of cell-penetrating peptide using traditional computational methods has limitations. To address these problems, a cell-penetrating peptide prediction method named CPPGAN-ESM is proposed in this paper. CPPGAN-ESM firstly augments the cell-penetrating peptide dataset by using Deep Convolutional Generative Adversarial Network, and then fine-tunes the predictor based on the Evolutionary Scale Modeling 2 pre-trained feature extractor with the augmented dataset, to realize the prediction of the cell-penetrating peptide. Extensive experiments on a public dataset show that the method achieves an efficient performance of 0.979 AUC and 0.977 ACC in the cell-penetrating peptide prediction task.},
booktitle = {Proceedings of the 2023 6th International Conference on Big Data Technologies},
pages = {17–21},
numpages = {5},
keywords = {DCGAN model, ESM2 model, cell-penetrating peptide prediction, data augmentation},
location = {Qingdao, China},
series = {ICBDT '23}
}

@inproceedings{10.1145/3524842.3528440,
author = {Ciniselli, Matteo and Pascarella, Luca and Bavota, Gabriele},
title = {To what extent do deep learning-based code recommenders generate predictions by cloning code from the training set?},
year = {2022},
isbn = {9781450393034},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524842.3528440},
doi = {10.1145/3524842.3528440},
abstract = {Deep Learning (DL) models have been widely used to support code completion. These models, once properly trained, can take as input an incomplete code component (e.g., an incomplete function) and predict the missing tokens to finalize it. GitHub Copilot is an example of code recommender built by training a DL model on millions of open source repositories: The source code of these repositories acts as training data, allowing the model to learn "how to program". The usage of such a code is usually regulated by Free and Open Source Software (FOSS) licenses, that establish under which conditions the licensed code can be redistributed or modified. As of Today, it is unclear whether the code generated by DL models trained on open source code should be considered as "new" or as "derivative" work, with possible implications on license infringements. In this work, we run a large-scale study investigating the extent to which DL models tend to clone code from their training set when recommending code completions. Such an exploratory study can help in assessing the magnitude of the potential licensing issues mentioned before: If these models tend to generate new code that is unseen in the training set, then licensing issues are unlikely to occur. Otherwise, a revision of these licenses urges to regulate how the code generated by these models should be treated when used, for example, in a commercial setting. Highlights from our results show that ~10% to ~0.1% of the predictions generated by a state-of-the-art DL-based code completion tool are Type-1 clones of instances in the training set, depending on the size of the predicted code. Long predictions are unlikely to be cloned.},
booktitle = {Proceedings of the 19th International Conference on Mining Software Repositories},
pages = {167–178},
numpages = {12},
keywords = {code clones, code completion, deep learning},
location = {Pittsburgh, Pennsylvania},
series = {MSR '22}
}

@article{10.1109/TCBB.2023.3284215,
author = {Zhou, Hanchong and Leung, Henry and Balaji, Bhashyam},
title = {AR-UNet: A Deformable Image Registration Network with Cyclic Training},
year = {2023},
issue_date = {July-Aug. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {4},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2023.3284215},
doi = {10.1109/TCBB.2023.3284215},
abstract = {Deformable image registration is a process to determine the non-linear spatial correspondence among deformed image pairs. Generative registration network is a novel structure involving a generative registration network and a discriminative network that encourages the former to generate better results. We propose an Attention Residual UNet (AR-UNet) to estimate the complicated deformation field. The model is trained using perceptual cyclic constraints. As an unsupervised method, we require labelling for training and use virtual data augmentation to improve the robustness of the proposed model. We also introduce comprehensive metrics for image registration comparison. Experimental results show quantitative evidence that the method can predict reliable deformation field at a reasonable speed and outperform conventional learning based and non-learning based deformable image registration methods.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jun,
pages = {692–700},
numpages = {9}
}

@inproceedings{10.1145/3503161.3548393,
author = {Pal, Arghya and Rajanala, Sailaja and Phan, Raphael and Wong, Koksheik},
title = {Guess-It-Generator: Generating in a Lewis Signaling Framework through Logical Reasoning},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548393},
doi = {10.1145/3503161.3548393},
abstract = {Human minds spontaneously integrate two inherited cognitive capabilities: perception and reasoning to accomplish cognitive tasks such as problem solving, imagination, and causation. It is observed in the primate brains that perception offers the assistance required for problem comprehension, whilst the reasoning elucidates upon the facts recovered during perception in order to make a decision. The field of artificial intelligence (AI) thus considers perception and reasoning as two complementary areas that are realized by machine learning and logic programming, respectively. In this work, we propose a generative model using a collaborative guessing game of the kind first introduced by David Lewis in his famous work called the Lewis signaling game that is synonymous with the "20 Questions'' game. Our proposed model, &lt;u&gt;G&lt;/u&gt;uess-&lt;u&gt;I&lt;/u&gt;t-&lt;u&gt;G&lt;/u&gt;enerator (GIG) is a collaborative framework that engages two recurrent neural networks in a guessing game. GIG unifies perception and reasoning with a view to generating labeled images by capturing, (X, y), the underlying density of a data distribution, i.e. (X, y) - p(X, y). An encoder attends to a region of the input image and encodes that onto a latent variable that acts as a perception signal to a decoder. In contrast, the decoder leverages on the perception signals to guess the image and verifies the guess by reasoning with logical facts derived from the domain knowledge. Our experiments and comprehensive studies on seven datasets: PCAM, Chest-Xray-14, FIRE, HAM10000 from the medical domain, and CIFAR 10, LSUN, ImageNet, among standard benchmark datasets, show significant promise for the proposed method.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {6396–6405},
numpages = {10},
keywords = {first order logic, generative model, lewis signaling guessing game, medical labeled image generation},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3615366.3622793,
author = {Zamir, Bukhtawar and Campos, João R. and Vieira, Marco},
title = {Advanced Machine Learning for Runtime Data Generation},
year = {2023},
isbn = {9798400708442},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615366.3622793},
doi = {10.1145/3615366.3622793},
abstract = {Given the ubiquity of software in everyday critical tasks, ensuring its dependability is of utmost importance. Software faults, which can lead to errors and vulnerabilities, can significantly comprise the target system. Various techniques have been developed to improve the dependability of software-intensive systems, from fault avoidance to fault tolerance. Machine Learning (ML) techniques have been playing a vital role in improving the dependability of systems. Nonetheless, such techniques require significant amounts of data, which are not typically available. To overcome this, various techniques, such as fault injection or intrusion injection, have been proposed to generate realistic data. Still, they are computationally expensive and require considerable expertise. At the same time, a recent growing sub-field of ML is generative models. Generative models offer an innovative solution by creating synthetic data that closely resemble real-world samples. If such models could be used to generate realistic synthetic failure or intrusion data on demand, their value would be significant. Notwithstanding, the feasibility of such an approach has not yet been researched. Generative models have only mostly been used for sequential data (e.g., text or music) or data with high spatial dependency (e.g., images). On the other hand, dependability problems often have high dimensional tabular data, for which generative models are yet to excel, and for which it is also considerably more difficult to assess the representativeness of the generated data. This research will focus on determining the feasibility of using generative techniques to generate runtime data to support dependability research.},
booktitle = {Proceedings of the 12th Latin-American Symposium on Dependable and Secure Computing},
pages = {182–187},
numpages = {6},
keywords = {Artificial Intelligence, Generative Models, Machine Learning},
location = {La Paz, Bolivia},
series = {LADC '23}
}

@inproceedings{10.1145/3610537.3622957,
author = {Tang, Yuying and Sun, Yuqian and Gao, Ze and Pan, Zhijun and Wang, Zhigang and Braud, Tristan and Lee, Chang Hee and Asadipour, Ali},
title = {AI Nüshu (Women's scripts) - An Exploration of Language Emergence in Sisterhood},
year = {2023},
isbn = {9798400703089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610537.3622957},
doi = {10.1145/3610537.3622957},
abstract = {This paper presents "AI Nüshu," an emerging language system inspired by Nüshu (women's scripts), the unique language created and used exclusively by ancient Chinese women who were illiterate under a patriarchy society. Through an interactive art installation, two artificial intelligent (AI) agents continuously observe their environment and communicate with each other, developing a writing system that encodes Chinese. In this system, two AI agents observe the environment through cameras, record the unconscious behaviors of the audience, and generate summaries of their observations through visual recognition. Subsequently, the agent associates the corresponding original Nüshu poetry lines and generates new poetry text through a Language Model (LLM), representing its reflection. To develop their language, they continuously switch roles between the speaker and listener, constantly communicating their reflections, and encrypting a word in the poetry line with their self-created AI Nüshu character, allowing the other to guess and learn. Gradually, they reach a consensus on AI Nüshu, forming a unique "AI Nüshu Dictionary" for machines. This language, algorithmically combined into corresponding characters, has components derived from Nüshu, similar to Chinese characters and traditional textile patterns. Thus, like ancient women, the two agents gradually developed their Chinese writing system, corresponding one-to-one with Chinese characters. In contrast, humans, as the authority of the language system, became an object observed, interpreted, and inspired by machines to stimulate non-human language. This is the first media art project to interpret Nüshu from a computational linguistics perspective, infusing AI and art research with non-English natural language processing, Chinese cultural heritage, and a feminist viewpoint. This encourages the creation of more non-English, linguistically-oriented artworks for diverse cultures. We simulate communication in sisterhood through a multi-agent learning system, which questioned knowledge authority between humans and machines through the lens of language development.},
booktitle = {SIGGRAPH Asia 2023 Art Gallery},
articleno = {4},
numpages = {2},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@article{10.5555/3586589.3586704,
author = {Tran, Linh and Pantic, Maja and Deisenroth, Marc Peter},
title = {Cauchy-Schwarz regularized autoencoder},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
abstract = {Recent work in unsupervised learning has focused on efficient inference and learning in latent variables models. Training these models by maximizing the evidence (marginal likelihood) is typically intractable. Thus, a common approximation is to maximize the Evidence Lower BOund (ELBO) instead. Variational autoencoders (VAE) are a powerful and widely-used class of generative models that optimize the ELBO efficiently for large datasets. However, the VAE's default Gaussian choice for the prior imposes a strong constraint on its ability to represent the true posterior, thereby degrading overall performance. A Gaussian mixture model (GMM) would be a richer prior but cannot be handled efficiently within the VAE framework because of the intractability of the Kullback-Leibler divergence for GMMs. We deviate from the common VAE framework in favor of one with an analytical solution for Gaussian mixture prior. To perform efficient inference for GMM priors, we introduce a new constrained objective based on the Cauchy-Schwarz divergence, which can be computed analytically for GMMs. This new objective allows us to incorporate richer, multi-modal priors into the autoencoding framework. We provide empirical studies on a range of datasets and show that our objective improves upon variational autoencoding models in density estimation, unsupervised clustering, semi-supervised learning, and face analysis.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {115},
numpages = {37},
keywords = {generative models, Cauchy-Schwarz divergence, constrained optimization, auto-encoding models, face analysis}
}

@article{10.5555/3648699.3648900,
author = {Jia, Junxiong and Wu, Yanni and Li, Peijun and Meng, Deyu},
title = {Variational inverting network for statistical inverse problems of partial differential equations},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {To quantify uncertainties in inverse problems of partial differential equations (PDEs), we formulate them into statistical inference problems using Bayes' formula. Recently, well-justified infinite-dimensional Bayesian analysis methods have been developed to construct dimension-independent algorithms. However, there are three challenges for these infinite-dimensional Bayesian methods: prior measures usually act as regularizers and are not able to incorporate prior information efficiently; complex noises, such as more practical noni.i.d. distributed noises, are rarely considered; and time-consuming forward PDE solvers are needed to estimate posterior statistical quantities. To address these issues, an infinite-dimensional inference framework has been proposed based on the infinite-dimensional variational inference method and deep generative models. Specifically, by introducing some measure equivalence assumptions, we derive the evidence lower bound in the infinite-dimensional setting and provide possible parametric strategies that yield a general inference framework called the Variational Inverting Network (VINet). This inference framework can encode prior and noise information from learning examples. In addition, relying on the power of deep neural networks, the posterior mean and variance can be efficiently and explicitly generated in the inference stage. In numerical experiments, we design specific network structures that yield a computable VINet from the general inference framework. Numerical examples of linear inverse problems of an elliptic equation and the Helmholtz equation are presented to illustrate the effectiveness of the proposed inference framework.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {201},
numpages = {60},
keywords = {infinite-dimensional variational inference, inverse problems, Bayesian analysis for functions, partial differential equations, deep neural networks}
}

@inproceedings{10.1145/3563357.3567747,
author = {Yoshikawa, Hiroki and Uchiyama, Akira},
title = {Privacy-preserving data augmentation for thermal sensation dataset based on variational autoencoder: poster abstract},
year = {2022},
isbn = {9781450398909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563357.3567747},
doi = {10.1145/3563357.3567747},
abstract = {Machine learning-based methods show high performance in estimating the thermal sensation of a person. These methods are based on a huge amount of personal data. The dataset used for the training of the estimator includes personal physiological data, which includes people's private information. Generative models have received significant attention to anonymize such data, including private information. In this paper, we propose privacy-preserving data augmentation for the thermal sensation dataset, including the subject's physiological data using Variational Autoencoder. The generative model trained with a thermal sensation dataset collected in the uncontrolled environment tends to be biased because subjects in the environment rarely report extreme thermal sensation labels. To tackle this problem, we introduce a weighted loss function for the generative model to mitigate the bias of the thermal sensation labels. The evaluation result shows that our method generates an anonymized dataset that works to train a thermal sensation estimator as well as the original dataset.},
booktitle = {Proceedings of the 9th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {286–287},
numpages = {2},
keywords = {data anonymization, data augmentation, thermal sensation},
location = {Boston, Massachusetts},
series = {BuildSys '22}
}

@inbook{10.1109/DAC18074.2021.9586239,
author = {Jin, Wentian and Chen, Liang and Sadiqbatcha, Sheriff and Peng, Shaoyi and Tan, Sheldon X.-D.},
title = {EMGraph: Fast Learning-Based Electromigration Analysis for Multi-Segment Interconnect Using Graph Convolution Networks},
year = {2022},
isbn = {9781665432740},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DAC18074.2021.9586239},
abstract = {Electromigration (EM) becomes a major concern for VLSI circuits as the technology advances in the nanometer regime. With Korhonen equations, EM assessment for VLSI circuits remains challenged due to the increasing integrated density. VLSI multisegment interconnect trees can be naturally viewed as graphs. Based on this observation, we propose a new graph convolution network (GCN) model, which is called EMGraph considering both node and edge embedding features, to estimate the transient EM stress of interconnect trees. Compared with recently proposed generative adversarial network (GAN) based stress image-generation method, EMGraph model can learn more transferable knowledge to predict stress distributions on new graphs without retraining via inductive learning. Trained on the large dataset, the model shows less than 1.5% averaged error compared to the ground truth results and is orders of magnitude faster than both COMSOL and state-of-the-art method. It also achieves smaller model size, 4× accuracy and 14× speedup over the GAN-based method.},
booktitle = {Proceedings of the 58th Annual ACM/IEEE Design Automation Conference},
pages = {919–924},
numpages = {6}
}

@inproceedings{10.1145/3600211.3604681,
author = {Jiang, Harry H. and Brown, Lauren and Cheng, Jessica and Khan, Mehtab and Gupta, Abhishek and Workman, Deja and Hanna, Alex and Flowers, Johnathan and Gebru, Timnit},
title = {AI Art and its Impact on Artists},
year = {2023},
isbn = {9798400702310},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600211.3604681},
doi = {10.1145/3600211.3604681},
abstract = {The last 3 years have resulted in machine learning (ML)-based image generators with the ability to output consistently higher quality images based on natural language prompts as inputs. As a result, many popular commercial “generative AI Art” products have entered the market, making generative AI an estimated $48B industry&nbsp;[125]. However, many professional artists have spoken up about the harms they have experienced due to the proliferation of large scale image generators trained on image/text pairs from the Internet. In this paper, we review some of these harms which include reputational damage, economic loss, plagiarism and copyright infringement. To guard against these issues while reaping the potential benefits of image generators, we provide recommendations such as regulation that forces organizations to disclose their training data, and tools that help artists prevent using their content as training data without their consent.},
booktitle = {Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {363–374},
numpages = {12},
location = {Montréal, QC, Canada},
series = {AIES '23}
}

@article{10.1109/TASLP.2023.3321191,
author = {Yang, Runxuan and Peng, Yuyang and Hu, Xiaolin},
title = {A Fast High-Fidelity Source-Filter Vocoder With Lightweight Neural Modules},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3321191},
doi = {10.1109/TASLP.2023.3321191},
abstract = {The quality of raw audio waveform generated by a vocoder could affect various audio generative tasks. In recent years, the dominance of source-filter vocoders was greatly challenged by neural vocoders as the latter presents far superior synthesized audio quality. Meanwhile, neural vocoders introduced unprecedented limitations including low runtime efficiency as well as unstable pitch especially in those without explicit periodic excitation input, while these have never been a problem in source-filter vocoders. We present in this article a novel approach that takes the best from both parties. We start by an in-depth examination of every building block in WORLD &amp;#x2013; one of the best-performing source-filter vocoders based on plain signal processing algorithms, looking for ones that do not work well, and we replace them with small, lightweight and task-specific neural network models. We also rearranged the vocoding pipeline for a smoother collaboration between building blocks. Our objective and subjective evaluations demonstrate that our methods present competitive synthesized audio quality even when compared against neural vocoders at a much lower computational cost, while keeping spectral envelope acoustic feature, high pitch accuracy as in conventional source-filter vocoders.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {3362–3373},
numpages = {12}
}

@inproceedings{10.1145/3543507.3583343,
author = {Wu, Zhijing and Mao, Jiaxin and Xu, Kedi and Song, Dandan and Huang, Heyan},
title = {A Passage-Level Reading Behavior Model for Mobile Search},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583343},
doi = {10.1145/3543507.3583343},
abstract = {Reading is a vital and complex cognitive activity during users’ information-seeking process. Several studies have focused on understanding users’ reading behavior in desktop search. Their findings greatly contribute to the design of information retrieval models. However, little is known about how users read a result in mobile search, although search currently happens more frequently in mobile scenarios. In this paper, we conduct a lab-based user study to investigate users’ fine-grained reading behavior patterns in mobile search. We find that users’ reading attention allocation is strongly affected by several behavior biases, such as position and selection biases. Inspired by these findings, we propose a probabilistic generative model, the Passage-level Reading behavior Model (PRM), to model users’ reading behavior in mobile search. The PRM utilizes observable passage-level exposure and viewport duration events to infer users’ unobserved skimming event, reading event, and satisfaction perception during the reading process. Besides fitting the passage-level reading behavior, we utilize the fitted parameters of PRM to estimate the passage-level and document-level relevance. Experimental results show that PRM outperforms existing unsupervised relevance estimation models. PRM has strong interpretability and provides valuable insights into the understanding of how users seek and perceive useful information in mobile search.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3236–3246},
numpages = {11},
keywords = {document relevance estimation, mobile search, passage ranking, probabilistic generative model, reading behavior},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3503161.3548073,
author = {Du, Zhekai and Li, Jingjing and Zuo, Lin and Zhu, Lei and Lu, Ke},
title = {Energy-Based Domain Generalization for Face Anti-Spoofing},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548073},
doi = {10.1145/3503161.3548073},
abstract = {With various unforeseeable face presentation attacks (PA) springing up, face anti-spoofing (FAS) urgently needs to generalize to unseen scenarios. Research on generalizable FAS has lately attracted growing attention. Existing methods cast FAS as a vanilla binary classification problem and address it by a standard discriminative classifier p(y|x) under a domain generalization framework. However, discriminative models are unreliable for samples far away from the training distribution. In this paper, we resort to an energy-based model (EBM) to tackle FAS in a generative perspective. Our motivation is to model the joint density p(x,y), which allows to compute not only p(y|x) but also p(x). Due to the intractability of direct modeling, we use EBMs as an alternative to probabilistic estimation. With energy-based training, real faces are encouraged to get low free energy associated with the marginal probability p(x) of real faces, and all samples with high free energy are regarded as fake faces, thus rejecting any kind of PA out of the distribution of real faces. To learn to generalize to unseen domains, we generate diverse and novel populations in feature space under the guidance of energy model. Our model is updated in a meta-learning schema, where the original source samples are utilized for meta-training and the generated ones for meta-testing. We validate our method on four widely used FAS datasets. Comprehensive experimental results demonstrate the effectiveness of our method compared with state-of-the-arts.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {1749–1757},
numpages = {9},
keywords = {domain generalization, energy-based model, face anti-spoofing},
location = {Lisboa, Portugal},
series = {MM '22}
}

@article{10.1109/TASLP.2023.3319975,
author = {Peng, Wanli and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
title = {Text Steganalysis Based on Hierarchical Supervised Learning and Dual Attention Mechanism},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3319975},
doi = {10.1109/TASLP.2023.3319975},
abstract = {Recent methods with deep neural networks for text steganalysis have succeeded in mining various feature representations. However, a limited number of studies have explicitly analyzed potential security issues of generative text steganography. Furthermore, current text steganalysis approaches lack detailed consideration in the intricate design of deep learning architectures tailored to these challenges. In this article, in order to tackle these problems, we first theoretically and empirically analyze the inevitable embedding distortions of generative text steganography at a semantic and statistical levels. In light of this, we then propose an innovative text steganalysis method based on hierarchical supervised learning and a dual attention mechanism. Concretely, to extract highly effective semantic features, the proposed method involves fine-tuning a BERT extractor through the hierarchical supervised learning that combines signals from multiple softmax classifiers, rather than relying solely on the final one. The mean and standard deviation values in the Gaussian distribution of cover and stego texts are then estimated using an encoder of variational autoencoders and used to capture features representing the statistical distortion of generative text steganography. Subsequently, we introduce a dual attention mechanism that dynamically fuses the semantic and statistical features, thereby creating discriminative feature representations essential for text steganalysis. The experimental results demonstrate that our proposed text steganalysis method surpasses the current state-of-the-art techniques across three distinct text steganalysis scenarios: specific text steganalysis, semi-blind text steganalysis, and blind text steganalysis.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {3513–3526},
numpages = {14}
}

@inproceedings{10.1145/3539618.3591691,
author = {Yang, Yonghui and Wu, Zhengwei and Wu, Le and Zhang, Kun and Hong, Richang and Zhang, Zhiqiang and Zhou, Jun and Wang, Meng},
title = {Generative-Contrastive Graph Learning for Recommendation},
year = {2023},
isbn = {9781450394086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539618.3591691},
doi = {10.1145/3539618.3591691},
abstract = {By treating users' interactions as a user-item graph, graph learning models have been widely deployed in Collaborative Filtering~(CF) based recommendation. Recently, researchers have introduced Graph Contrastive Learning~(GCL) techniques into CF to alleviate the sparse supervision issue, which first constructs contrastive views by data augmentations and then provides self-supervised signals by maximizing the mutual information between contrastive views. Despite the effectiveness, we argue that current GCL-based recommendation models are still limited as current data augmentation techniques, either structure augmentation or feature augmentation. First, structure augmentation randomly dropout nodes or edges, which is easy to destroy the intrinsic nature of the user-item graph. Second, feature augmentation imposes the same scale noise augmentation on each node, which neglects the unique characteristics of nodes on the graph.To tackle the above limitations, we propose a novel Variational Graph Generative-Contrastive Learning (VGCL) framework for recommendation. Specifically, we leverage variational graph reconstruction to estimate a Gaussian distribution of each node, then generate multiple contrastive views through multiple samplings from the estimated distributions, which builds a bridge between generative and contrastive learning. The generated contrastive views can well reconstruct the input graph without information distortion. Besides, the estimated variances are tailored to each node, which regulates the scale of contrastive loss for each node on optimization. Considering the similarity of the estimated distributions, we propose a cluster-aware twofold contrastive learning, a node-level to encourage consistency of a node's contrastive views and a cluster-level to encourage consistency of nodes in a cluster. Finally, extensive experimental results on three public datasets clearly demonstrate the effectiveness of the proposed model.},
booktitle = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1117–1126},
numpages = {10},
keywords = {collaborative filtering, generative learning, graph contrastive learning, recommendation},
location = {Taipei, Taiwan},
series = {SIGIR '23}
}

@inproceedings{10.1145/3529466.3529475,
author = {Li, Qinyang and Fan, Wentao},
title = {Mixture Density Hyperspherical Generative Adversarial Networks},
year = {2022},
isbn = {9781450395502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3529466.3529475},
doi = {10.1145/3529466.3529475},
abstract = {The Generative Adversarial Networks (GANs) are deep generative models that can generate realistic samples, but they are difficult to train in practice due to the problem of mode collapse, where the generator only repeatedly generates one mode in samples during the learning process, or only generates a small number of modes after reaching the Nash equilibrium during the adversarial training. In order to solve this issue while making the generator contains promising generation ability, we propose a mixture density hyperspherical generative model namely MDH-GAN that combines variational autoencoder (VAE) and generative adversarial network. Unlike most of the GAN-based generative models that consider a Gaussian prior, MDH-GAN adopts the von Mises-Fisher (vMF) prior defined on a unit hypersphere. Our model combines VAE with GAN by integrating the encoder of VAE with GAN to form a jointly training framework. Therefore, the generator of our model can learn data distribution with a hyperspherical latent structure, leading to an improved generative ability of the generator. Moreover, a vMF mixture model is deployed in the discriminator to form a hypersphere space to avoid mode collapse of the model. In our experiments, by calculating the Fréchet Inception distance (FID) between the generated images and real ones, we prove that MDH-GAN has a better ability to generate high-quality images with high diversity.},
booktitle = {Proceedings of the 2022 6th International Conference on Innovation in Artificial Intelligence},
pages = {31–37},
numpages = {7},
location = {Guangzhou, China},
series = {ICIAI '22}
}

@inproceedings{10.1145/3534678.3539032,
author = {Moomtaheen, Fariha and Killeen, Matthew and Oswald, James and Gonzàlez-Rosell, Anna and Mastracco, Peter and Gorovits, Alexander and Copp, Stacy M. and Bogdanov, Petko},
title = {DNA-Stabilized Silver Nanocluster Design via Regularized Variational Autoencoders},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539032},
doi = {10.1145/3534678.3539032},
abstract = {DNA-stabilized silver nanoclusters (AgN-DNAs) are a class of nanomaterials comprised of 10-30 silver atoms held together by short synthetic DNA template strands. AgN-DNAs are promising biosensors and fluorophores due to their small sizes, natural compatibility with DNA, and bright fluorescence---the property of absorbing light and re-emitting light of a different color. The sequence of the DNA template acts as a "genome" for AgN-DNAs, tuning the size of the encapsulated silver nanocluster, and thus its fluorescence color. However, current understanding of the AgN-DNA genome is still limited. Only a minority of DNA sequences produce highly fluorescent AgN-DNAs, and the bulky DNA strands and complex DNA-silver interactions make it challenging to use first principles chemical calculations to understand and design AgN-DNAs. Thus, a major challenge for researchers studying these nanomaterials is to develop methods to employ observational data about studied AgN-DNAs to design new nanoclusters for targeted applications.In this work, we present an approach to design AgN-DNAs by employing variational autoencoders (VAEs) as generative models. Specifically, we employ an LSTM-based β-VAE architecture and regularize its latent space to correlate with AgN-DNA properties such as color and brightness. The regularization is adaptive to skewed sample distributions of available observational data along our design axes of properties. We employ our model for design of AgN-DNAs in the near-infrared (NIR) band, where relatively few AgN-DNAs have been observed to date. Wet lab experiments validate that when employed for designing new AgN-DNAs, our model significantly shifts the distribution of AgN-DNA colors towards the NIR while simultaneously achieving bright fluorescence. This work shows that VAE-based generative models are well-suited for the design of AgN-DNAs with multiple targeted properties, with significant potential to advance the promising applications of these nanomaterials for bioimaging, biosensing, and other critical technologies.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3593–3602},
numpages = {10},
keywords = {DNA, nanomaterials design, variational autoencoders},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3589132.3625641,
author = {Zhou, Zhilun and Ding, Jingtao and Liu, Yu and Jin, Depeng and Li, Yong},
title = {Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589132.3625641},
doi = {10.1145/3589132.3625641},
abstract = {Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of applications from public safety and traffic management to urban planning. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.},
booktitle = {Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
articleno = {91},
numpages = {12},
keywords = {generative model, urban flow, knowledge graph, diffusion model},
location = {Hamburg, Germany},
series = {SIGSPATIAL '23}
}

@inproceedings{10.5555/3539845.3540004,
author = {Elfar, Mahmoud and Liang, Tung-Che and Chakrabarty, Krishnendu and Pajic, Miroslav},
title = {Adaptive droplet routing for MEDA biochips via deep reinforcement learning},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Digital microfluidic biochips (DMFBs) based on a micro-electrode-dot-array (MEDA) architecture provide finegrained control and sensing of droplets in real-time. However, excessive actuation of microelectrodes in MEDA biochips can lead to charge trapping during bioassay execution, causing the failure of microelectrodes and erroneous bioassay outcomes. A recently proposed enhancement to MEDA allows run-time measurement of microelectrode health information, thereby enabling synthesis of adaptive routing strategies for droplets. However, existing synthesis solutions are computationally infeasible for large MEDA biochips that have been commercialized. In this paper, we propose a synthesis framework for adaptive droplet routing in MEDA biochips via deep reinforcement learning (DRL). The framework utilizes the real-time microelectrode health feedback to synthesize droplet routes that proactively minimize the likelihood of charge trapping. We show how the adaptive routing strategies can be synthesized using DRL. We implement the DRL agent, the MEDA simulation environment, and the bioassay scheduler using the OpenAI Gym environment. Our framework obtains adaptive routing policies efficiently for COVID-19 testing protocols on large arrays that reflect the sizes of commercial MEDA biochips available in the marketplace, significantly increasing probabilities of successful bioassay completion compared to existing methods.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {640–645},
numpages = {6},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3544549.3577061,
author = {Lehmann, Florian},
title = {Mixed-Initiative Interaction with Computational Generative Systems},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3577061},
doi = {10.1145/3544549.3577061},
abstract = {Machine learning models provide functions to transform and generate image and text data. This promises powerful applications but it remains unclear how users can interact with these models. With my research, I focus on designing, implementing, and evaluating functional prototypes for understanding human-AI interactions. Methodologically, I focus on web-based experiments with a mixed-methods approach. Furthermore, I use these prototypes and generative models as a material to understand fundamental concepts in human-AI interactions, such as initiative, intent, and control. In an already conducted study, for example, I showed that the levels of initiative and control afforded by the UI influence perceived authorship when writing text. For the future, I plan to carry out more studies on collaborative writing. With my dissertation, I contribute to how we will build human-AI interactions and how we will collaborate with computational generative systems in future.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {501},
numpages = {6},
keywords = {control, functional prototypes, generative systems, human-ai interaction, initiative, intent, language model, mixed-initiative, text generation, typing, writing},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@article{10.5555/3648699.3648859,
author = {Masud, Shoaib Bin and Werenski, Matthew and Murphy, James M. and Aeron, Shuchin},
title = {Multivariate soft rank via entropy-regularized optimal transport: sample efficiency and generative modeling},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {The framework of optimal transport has been leveraged to extend the notion of rank to the multivariate setting as corresponding to an optimal transport map, while preserving desirable properties of the resulting goodness-of-fit (GoF) statistics. In particular, the rank energy (RE) and rank maximum mean discrepancy (RMMD) are distribution-free under the null, exhibit high power in statistical testing, and are robust to outliers. In this paper, we point to and alleviate some of the shortcomings of these GoF statistics that are of practical significance, namely high computational cost, curse of dimensionality in statistical sample complexity, and lack of differentiability with respect to the data. We show that all these issues are addressed by defining multivariate rank as an entropic transport map derived from the entropic regularization of the optimal transport problem, which we refer to as the soft rank. We consequently propose two new statistics, the soft rank energy (sRE) and soft rank maximum mean discrepancy (sRMMD). Given n sample data points, we provide non-asymptotic convergence rates for the sample estimate of the entropic transport map to its population version that are essentially of the order n-1/2 when the source measure is subgaussian and the target measure has compact support. This result is novel compared to existing results which achieve a rate of n-1 but crucially rely on both measures having compact support. In contrast, the corresponding convergence rate of estimating an optimal transport map, and hence the rank map, is exponential in the data dimension. We leverage these fast convergence rates to show that the sample estimates of sRE and sRMMD converge rapidly to their population versions. Combined with the computational efficiency of methods in solving the entropy-regularized optimal transport problem, these results enable efficient rank-based GoF statistical computation, even in high dimensions. Furthermore, the sample estimates of sRE and sRMMD are differentiable with respect to the data and amenable to popular machine learning frameworks that rely on gradient methods. We leverage these properties towards showcasing their utility for generative modeling on two important problems: image generation and generating valid knockoffs for controlled feature selection.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {160},
numpages = {65},
keywords = {optimal transport, multivariate rank, high-dimensional statistics, goodness-of-fit testing, generative modeling, knockoff filtering}
}

@inproceedings{10.1145/3560905.3568083,
author = {Fan, Zipei and Zhang, Zhiwen and Wang, Hongjun},
title = {Generative Personalized Federated Learning Framework for Travel Time Estimation},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568083},
doi = {10.1145/3560905.3568083},
abstract = {Estimating the travel time of a given path is an important topic for the intelligent transportation system and serves as the foundation for various real-world applications. However, building an estimation model for such a data-driven task requires a large amount of mobile users' trajectory data which directly relates to their privacy and thus is less likely to be shared. Therefore, we propose GPF-TTE, Generative Personalized Federated Learning Framework for Travel Time Estimation (poster version of our previous work [1]) based on the issue of privacy protection for the mobile user group, in which 1) utilizes the federated learning approach, allowing private data to be kept on client devices while training, 2) apart from sharing a base model, we also adapt a fine-tuned personalized model for each client to study their personal driving habits, making up for the residual error caused by the prediction of the localized global model (the base model in local device), and 3) the cloud server aggregates localized models into the global model as a generative model to infer the future road traffic state.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {825–826},
numpages = {2},
keywords = {federated learning, ubiquitous, urban computing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@article{10.1109/TASLP.2023.3285241,
author = {Richter, Julius and Welker, Simon and Lemercier, Jean-Marie and Lay, Bunlong and Gerkmann, Timo},
title = {Speech Enhancement and Dereverberation With Diffusion-Based Generative Models},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3285241},
doi = {10.1109/TASLP.2023.3285241},
abstract = {In this work, we build upon our previous publication and use diffusion-based generative models for speech enhancement. We present a detailed overview of the diffusion process that is based on a stochastic differential equation and delve into an extensive theoretical examination of its implications. Opposed to usual conditional generation tasks, we do not start the reverse process from pure Gaussian noise but from a mixture of noisy speech and Gaussian noise. This matches our forward process which moves from clean speech to noisy speech by including a drift term. We show that this procedure enables using only 30 diffusion steps to generate high-quality clean speech estimates. By adapting the network architecture, we are able to significantly improve the speech enhancement performance, indicating that the network, rather than the formalism, was the main limitation of our original approach. In an extensive cross-dataset evaluation, we show that the improved method can compete with recent discriminative models and achieves better generalization when evaluating on a different corpus than used for training. We complement the results with an instrumental evaluation using real-world noisy recordings and a listening experiment, in which our proposed method is rated best. Examining different sampler configurations for solving the reverse process allows us to balance the performance and computational speed of the proposed method. Moreover, we show that the proposed method is also suitable for dereverberation and thus not limited to additive background noise removal.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jun,
pages = {2351–2364},
numpages = {14}
}

@inproceedings{10.1145/3580305.3599252,
author = {Wang, Xu and Zhao, Huan and Tu, Wei-wei and Yao, Quanming},
title = {Automated 3D Pre-Training for Molecular Property Prediction},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599252},
doi = {10.1145/3580305.3599252},
abstract = {Molecular property prediction is an important problem in drug discovery and materials science. As geometric structures have been demonstrated necessary for molecular property prediction,3D information has been combined with various graph learning methods to boost prediction performance. However, obtaining the geometric structure of molecules is not feasible in many real-world applications due to the high computational cost. In this work, we propose a novel 3D pre-training framework (dubbed 3D PGT), which pre-trains a model on 3D molecular graphs, and then fine-tunes it on molecular graphs without 3D structures. Based on fact that bond length, bond angle, and dihedral angle are three basic geometric descriptors corresponding to a complete molecular 3D conformer, we first develop a multi-task generative pre-train framework based on these three attributes. Next, to automatically fuse these three generative tasks, we design a surrogate metric using the total energy to search for weight distribution of the three pretext tasks since total energy corresponding to the quality of 3D conformer. Extensive experiments on 2D molecular graphs are conducted to demonstrate the accuracy, efficiency and generalization ability of the proposed 3D PGT compared to various pre-training baselines.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2419–2430},
numpages = {12},
keywords = {3d pre-training, graph transformer, molecular property prediction},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.5555/3522802.3522942,
author = {Chalé, Marc and Bastian, Nathaniel D.},
title = {Challenges and opportunities for generative methods in the cyber domain},
year = {2022},
publisher = {IEEE Press},
abstract = {Large, high quality data sets are essential for training machine learning models to perform their tasks accurately. The lack of such training data has constrained machine learning research in the cyber domain. This work explores how Markov Chain Monte Carlo (MCMC) methods can beused for realistic synthetic data generation and compares it to several existing generative machine learning techniques. The performance of MCMC is compared to generative adversarial network (GAN) and variational autoencoder (VAE) methods to estimate the joint probability distribution of network intrusion detection system data. A statistical analysis of the synthetically generated cyber data determines the goodness of fit, aiming to improve cyber threat detection. The experimental results suggest that the data generated from MCMC fits the true distribution approximately as well as the data generated from GAN and VAE; however, the MCMC requires a significantly longer training period and is unproven for higher dimensional cyber data.},
booktitle = {Proceedings of the Winter Simulation Conference},
articleno = {170},
numpages = {12},
location = {Phoenix, Arizona},
series = {WSC '21}
}

@article{10.5555/3648699.3648909,
author = {Bengio, Yoshua and Lahlou, Salem and Deleu, Tristan and Hu, Edward J. and Tiwari, Mo and Bengio, Emmanuel},
title = {GFlowNet foundations},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Generative Flow Networks (GFlowNets) have been introduced as a method to sample a diverse set of candidates in an active learning context, with a training objective that makes them approximately sample in proportion to a given reward function. In this paper, we show a number of additional theoretical properties of GFlowNets, including a new local and efficient training objective called detailed balance for the analogy with MCMC. GFlowNets can be used to estimate joint probability distributions and the corresponding marginal distributions where some variables are unspecified and, of particular interest, can represent distributions over composite objects like sets and graphs. GFlowNets amortize the work typically done by computationally expensive MCMC methods in a single but trained generative pass. They could also be used to estimate partition functions and free energies, conditional probabilities of supersets (supergraphs) given a subset (subgraph), as well as marginal distributions over all supersets (supergraphs) of a given set (graph). We introduce variations enabling the estimation of entropy and mutual information, continuous actions and modular energy functions.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {210},
numpages = {55}
}

@inproceedings{10.1145/3544549.3577036,
author = {Yakura, Hiromu},
title = {A Generative Framework for Designing Interactions to Overcome the Gaps between Humans and Imperfect AIs Instead of Improving the Accuracy of the AIs},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3577036},
doi = {10.1145/3544549.3577036},
abstract = {My research focuses on improving human-machine collaboration in the context of machine learning, particularly by recognizing the limitations and potential for errors in machine learning techniques and designing effective interactions for filling the gaps between humans and them. To this end, I have explored the application of machine learning in a variety of domains, such as malware analysis, music recommendation, conversation analysis, photo editing, and video-based learning. I also worked on clarifying the limitations of the current technologies by using adversarial approaches and qualitative methods. My thesis is planned to synthesize what I learned from these projects into design principles for constructing interactions that take full advantage of imperfect machine learning models. I particularly put emphasis on deriving principles that do not depend on the fine-tuning of the models, thereby providing a generative framework allowing researchers and practitioners to design a range of effective intelligent interactions without incurring significant computational and data collection costs.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {479},
numpages = {5},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3583780.3614749,
author = {Ye, Zesheng and Du, Jing and Liu, Yao and Zhang, Yihong and Yao, Lina},
title = {NP-SSL: A Modular and Extensible Self-supervised Learning Library with Neural Processes},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614749},
doi = {10.1145/3583780.3614749},
abstract = {Neural Processes (NPs) are a family of supervised density estimators devoted to probabilistic function approximation with meta-learning. Despite extensive research on the subject, the absence of a unified framework for NPs leads to varied architectural solutions across diverse studies. This non-consensus poses challenges to reproducing and benchmarking different NPs. Moreover, existing codebases mainly prioritize generative density estimation, yet rarely consider expanding the capability of NPs to self-supervised representation learning, which however has gained growing importance in data mining applications. To this end, we present NP-SSL, a modular and configurable framework with built-in support, requiring minimal effort to 1) implement classical NPs architectures; 2) customize specific components; 3) integrate hybrid training scheme (e.g., contrastive); and 4) extend NPs to act as a self-supervised learning toolkit, producing latent representations of data, and facilitating diverse downstream predictive tasks. To illustrate, we discuss a case study that applies NP-SSL to model time-series data. We interpret that NP-SSL can handle different predictive tasks such as imputation and forecasting, by a simple switch in data samplings, without significant change to the underlying structure. We hope this study can reduce the workload of future research on leveraging NPs to tackle more a broader range of real-world data mining applications. Code and documentation are at https://github.com/zyecs/NP-SSL.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {5123–5127},
numpages = {5},
keywords = {neural processes, probabilistic meta-learning, self-supervised learning},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3580305.3599412,
author = {Wang, Yunke and Wang, Xiyu and Dinh, Anh-Dung and Du, Bo and Xu, Charles},
title = {Learning to Schedule in Diffusion Probabilistic Models},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599412},
doi = {10.1145/3580305.3599412},
abstract = {Recently, the field of generative models has seen a significant advancement with the introduction of Diffusion Probabilistic Models (DPMs). The Denoising Diffusion Implicit Model (DDIM) was designed to reduce computational time by skipping a number of steps in the inference process of DPMs. However, the hand-crafted sampling schedule in DDIM, which relies on human expertise, has its limitations in considering all relevant factors in the sampling process. Additionally, the assumption that all instances should have the same schedule is not always valid. To address these problems, this paper proposes a method that leverages reinforcement learning to automatically search for an optimal sampling schedule for DPMs. This is achieved by a policy network that predicts the next step to visit based on the current state of the noisy image. The optimization of the policy network is accomplished using an episodic actor-critic framework, which incorporates reinforcement learning. Empirical results demonstrate the superiority of our approach over various datasets with different timesteps. We also observe that the trained sampling schedule has a strong generalization ability across different DPM baselines.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2478–2488},
numpages = {11},
keywords = {diffusion probabilistic model, inference, planning and scheduling, reinforcement learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3578337.3605114,
author = {Gupta, Shashank and Oosterhuis, Harrie and de Rijke, Maarten},
title = {A Deep Generative Recommendation Method for Unbiased Learning from Implicit Feedback},
year = {2023},
isbn = {9798400700736},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578337.3605114},
doi = {10.1145/3578337.3605114},
abstract = {Variational autoencoders (VAEs) are the state-of-the-art model for recommendation with implicit feedback signals. Unfortunately, implicit feedback suffers from selection bias, e.g., popularity bias, position bias, etc., and as a result, training from such signals produces biased recommendation models. Existing methods for debiasing the learning process have not been applied in a generative setting. We address this gap by introducing an inverse propensity scoring (IPS) based method for training VAEs from implicit feedback data in an unbiased way. Our IPS-based estimator for the VAE training objective, VAE-IPS, is provably unbiased w.r.t. selection bias. Our experimental results show that the proposed VAE-IPS model reaches significantly higher performance than existing baselines. Our contributions enable practitioners to combine state-of-the-art VAE recommendation techniques with the advantages of bias mitigation for implicit feedback.},
booktitle = {Proceedings of the 2023 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {87–93},
numpages = {7},
keywords = {implicit feedback, selection bias, variational autoencoder},
location = {Taipei, Taiwan},
series = {ICTIR '23}
}

@inproceedings{10.1145/3477314.3507141,
author = {Huang, Hsin-I and Shih, Chi-Sheng and Yang, Zi-Lin},
title = {Automated video editing based on learned styles using LSTM-GAN},
year = {2022},
isbn = {9781450387132},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477314.3507141},
doi = {10.1145/3477314.3507141},
abstract = {Experienced video editors use various editing techniques, including camera movement, types of shots, and shot compositions to create specific video semantics delivering messages to the viewers. In the video production process, the content of the video are essential, but so is the way to compose it. The goal of this work is to train a model learning how to edit the video that meets the videography requirements. This work proposes a deep generative model where both the generator and discriminator are unidirectional LSTM networks to generate the sequences of shot transitions for video editing. The proposed model learns different types of editing transitions from edited video clips. One is the stage performance of Korean music programs, and another is Chinese music programs. By combining different types of shots and camera movements, the proposed AI video editor brings various viewing experiences to the viewers. The quality of the generated shot sequences for video editing are evaluated by three metrics, which are creativity, inheritance, and diversity. The results show that the quality of the synthetic sequences generated by LSTM-GAN are better than those generated by the baseline model (Markov chain or LSTM). In summary, the quality of the sequence generated by LSTM-GAN is better than the quality generated by the Markov chain or LSTM while ensuring creativity, inheritance, and diversity at the same time.},
booktitle = {Proceedings of the 37th ACM/SIGAPP Symposium on Applied Computing},
pages = {73–80},
numpages = {8},
keywords = {GAN, LSTM, video editing},
location = {Virtual Event},
series = {SAC '22}
}

@inproceedings{10.1145/3580305.3599774,
author = {Xue, Bing and Said, Ahmed Sameh and Xu, Ziqi and Liu, Hanyang and Shah, Neel and Yang, Hanqing and Payne, Philip and Lu, Chenyang},
title = {Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599774},
doi = {10.1145/3580305.3599774},
abstract = {Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be represented by a deep latent variable model. The factual and counterfactual prediction errors are alleviated via a reconstruction regularization scheme together with semi-supervision, and the selection bias and the scarcity of treatment cases are mitigated by the disentangled and distribution-matched latent space and the label-balancing generative strategy. We evaluate TVAE on two real-world COVID-19 datasets: an international dataset collected from 1651 hospitals across 63 countries, and a institutional dataset collected from 15 hospitals. The results show that TVAE outperforms state-of-the-art treatment effect models in predicting both the propensity scores and factual outcomes on heterogeneous COVID-19 datasets. Additional experiments also show TVAE outperforms the best existing models in individual treatment effect estimation on the synthesized IHDP benchmark dataset.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5360–5371},
numpages = {12},
keywords = {causal inference, covid analysis, deep latent variable models, generative ai, machine learning for healthcare, representation learning, semi-supervised learning, treatment effect estimation, variational autoencoder},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@article{10.1145/3595244.3595259,
author = {Sam, Tyler and Chen, Yudong and Lee Yu, Christina},
title = {Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/3595244.3595259},
doi = {10.1145/3595244.3595259},
abstract = {Reinforcement learning (RL) methods have been increasingly popular in sequential decision making tasks due to its empirical success. However, large state and action spaces in real-world problems modeled as a Markov decision processes (MDPs) limit the use of RL algorithms. Given a finite-horizon MDP with state space S, action space A, and horizon H, one needs Ω |S|A|H3/ε2 samples given a generative model to learn an optimal policy [3], which can be impractical when S and A are large. The above tabular RL framework does not capture the fact that many realworld systems in fact have additional structure that if exploited should improve computational and statistical efficiency. Moreover, [1] empirically verifies that optimal and near-optimal action-value functions (both viewed as |S|-by- |A| matrices) of classical stochastic control tasks have low rank. Thus, the critical question is what are the minimal low rank structural assumptions that allow for computationally and statistically efficient learning.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = apr,
pages = {41–43},
numpages = {3}
}

@inproceedings{10.1145/3534678.3539020,
author = {Ren, Houxing and Wang, Jingyuan and Zhao, Wayne Xin},
title = {Generative Adversarial Networks Enhanced Pre-training for Insufficient Electronic Health Records Modeling},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539020},
doi = {10.1145/3534678.3539020},
abstract = {In recent years, automatic computational systems based on deep learning are widely used in medical fields, such as automatic diagnosing and disease prediction. Most of these systems are designed for data sufficient scenarios. However, due to the disease rarity or privacy, the medical data are always insufficient. When applying these data-hungry deep learning models with insufficient data, it is likely to lead to issues of over-fitting and cause serious performance problems. Many data augmentation methods have been proposed to solve the data insufficiency problem, such as using GAN (Generative Adversarial Networks) to generate training data. However, the augmented data usually contains lots of noise. Directly using them to train sensitive medical models is very difficult to achieve satisfactory results.To overcome this problem, we propose a novel deep model learning method for insufficient EHR (Electronic Health Record) data modeling, namely GRACE, which stands GeneRative Adversarial networks enhanCed prE-training. In the method, we propose an item-relation-aware GAN to capture changing trends and correlations among data for generating high-quality EHR records. Furthermore, we design a pre-training mechanism consisting of a masked records prediction task and a real-fake contrastive learning task to learn representations for EHR data using both generated and real data. After the pre-training, only the representations of real data is used to train the final prediction model. In this way, we can fully exploit useful information in generated data through pre-training, and also avoid the problems caused by directly using noisy generated data to train the final prediction model. The effectiveness of the proposed method is evaluated using extensive experiments on three healthcare-related real-world datasets. We also deploy our method in a maternal and child health care hospital for the online test. Both offline and online experimental results demonstrate the effectiveness of the proposed method. We believe doctors and patients can benefit from our effective learning method in various healthcare-related applications.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3810–3818},
numpages = {9},
keywords = {healthcare informatics, pre-training, representation learning},
location = {Washington DC, USA},
series = {KDD '22}
}

@article{10.5555/3586589.3586902,
author = {Block, Adam and Jia, Zeyu and Polyanskiy, Yury and Rakhlin, Alexander},
title = {Intrinsic dimension estimation using Wasserstein distance},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
abstract = {It has long been thought that high-dimensional data encountered in many practical machine learning tasks have low-dimensional structure, i.e., the manifold hypothesis holds. A natural question, thus, is to estimate the intrinsic dimension of a given population distribution from a finite sample. We introduce a new estimator of the intrinsic dimension and provide finite sample, non-asymptotic guarantees. We then apply our techniques to get new sample complexity bounds for Generative Adversarial Networks (GANs) depending only on the intrinsic dimension of the data.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {313},
numpages = {37},
keywords = {manifold hypothesis, dimension estimation, manifold learning, intrinsic dimension, Hölder GANs}
}

@inproceedings{10.1145/3573900.3591113,
author = {Xu, Wanpeng and Wei, Hua},
title = {Learning to Calibrate Hybrid Hyperparameters: a Study on Traffic Simulation},
year = {2023},
isbn = {9798400700309},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573900.3591113},
doi = {10.1145/3573900.3591113},
abstract = {Traffic simulation is an important computational technique that models the behavior and interactions of vehicles, pedestrians, and infrastructure in a transportation system. Calibration, which involves adjusting simulation parameters to match real-world data, is a key challenge in traffic simulation. Traffic simulators involve multiple models with hybrid hyperparameters, which could be either categorical or continuous. In this paper, we present CHy2, an approach that generates a set of hyperparameters for simulator calibration using generative adversarial imitation learning. CHy2 learns to mimic expert behavior models by rewarding hyperparameters that deceive a discriminator trained to classify policy-generated and expert trajectories. Specifically, we propose a hybrid architecture of actor-critic algorithms to handle the hybrid choices between hyperparameters. Experimental results show that CHy2 outperforms previous methods in calibrating traffic simulators.},
booktitle = {Proceedings of the 2023 ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {144–147},
numpages = {4},
keywords = {Reinforcement learning, model calibration, traffic simulation},
location = {Orlando, FL, USA},
series = {SIGSIM-PADS '23}
}

@inproceedings{10.1145/3502181.3531457,
author = {Paul, Arnab K. and Choi, Jong Youl and Karimi, Ahmad Maroof and Wang, Feiyi},
title = {Machine Learning Assisted HPC Workload Trace Generation for Leadership Scale Storage Systems},
year = {2022},
isbn = {9781450391993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502181.3531457},
doi = {10.1145/3502181.3531457},
abstract = {Monitoring and analyzing a wide range of I/O activities in an HPC cluster is important in maintaining mission-critical performance in a large-scale, multi-user, parallel storage system. Center-wide I/O traces can provide high-level information and fine-grained activities per application or per user running in the system. Studying such large-scale traces can provide helpful insights into the system. It can be used to develop predictive methods for making predictive decisions, adjusting scheduling policies, or providing decisions for the design of next-generation systems. However, sharing real-world I/O traces to expedite such research efforts leaves a few concerns; i) the cost of sharing the large traces is expensive due to this large size, and ii) privacy concern is an issue.We address such issues by building an end-to-end machine learn- ing (ML) workflow that can generate I/O traces for large-scale HPC applications. We leverage ML based feature selection and gener- ative models for I/O trace generation. The generative models are trained on I/O traces collected by the darshan I/O characterization tool over a period of one year. We present a two-step generation process consisting of two deep-learning models, called the feature generator and the trace generator. The combination of two-step generative models provides robustness by reducing the bias of the model and accounting for the stochastic nature of the I/O traces across different runs of an application. We evaluate the performance of the generative models and show that the two-step model can generate time-series I/O traces with less than 20% root mean square error.},
booktitle = {Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing},
pages = {199–212},
numpages = {14},
keywords = {clustering, darshan, feature selection, generative modeling, parallel file system},
location = {Minneapolis, MN, USA},
series = {HPDC '22}
}

@inproceedings{10.1145/3588432.3591563,
author = {Mensah, Dann and Kim, Nam Hee and Aittala, Miika and Laine, Samuli and Lehtinen, Jaakko},
title = {A Hybrid Generator Architecture for Controllable Face Synthesis},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591563},
doi = {10.1145/3588432.3591563},
abstract = {Modern data-driven image generation models often surpass traditional graphics techniques in quality. However, while traditional modeling and animation tools allow precise control over the image generation process in terms of interpretable quantities — e.g., shapes and reflectances — endowing learned models with such controls is generally difficult. In the context of human faces, we seek a data-driven generator architecture that simultaneously retains the photorealistic quality of modern generative adversarial networks (GAN) and allows explicit, disentangled controls over head shapes, expressions, identity, background, and illumination. While our high-level goal is shared by a large body of previous work, we approach the problem with a different philosophy: We treat the problem as an unconditional synthesis task, and engineer interpretable inductive biases into the model that make it easy for the desired behavior to emerge. Concretely, our generator is a combination of learned neural networks and fixed-function blocks, such as a 3D morphable head model and texture-mapping rasterizer, and we leave it up to the training process to figure out how they should be used together. This greatly simplifies the training problem by removing the need for labeled training data; we learn the distributions of the independent variables that drive the model instead of requiring that their values are known for each training image. Furthermore, we need no contrastive or imitation learning for correct behavior. We show that our design successfully encourages the generative model to make use of the internal, interpretable representations in a semantically meaningful manner. This allows sampling of different aspects of the image independently, as well as precise control of the results by manipulating the internal state of the interpretable blocks within the generator. This enables, for instance, facial animation using traditional animation tools.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
articleno = {69},
numpages = {10},
keywords = {differentiable rendering, face modeling, generative adversarial networks},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3577190.3616115,
author = {Harz, Leon and Voß, Hendric and Kopp, Stefan},
title = {FEIN-Z: Autoregressive Behavior Cloning for Speech-Driven Gesture Generation},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577190.3616115},
doi = {10.1145/3577190.3616115},
abstract = {Human communication relies on multiple modalities such as verbal expressions, facial cues, and bodily gestures. Developing computational approaches to process and generate these multimodal signals is critical for seamless human-agent interaction. A particular challenge is the generation of co-speech gestures due to the large variability and number of gestures that can accompany a verbal utterance, leading to a one-to-many mapping problem. This paper presents an approach based on a Feature Extraction Infusion Network (FEIN-Z) that adopts insights from robot imitation learning and applies them to co-speech gesture generation. Building on the BC-Z architecture, our framework combines transformer architectures and Wasserstein generative adversarial networks. We describe the FEIN-Z methodology and evaluation results obtained within the GENEA Challenge 2023, demonstrating good results and significant improvements in human-likeness over the GENEA baseline. We discuss potential areas for improvement, such as refining input segmentation, employing more fine-grained control networks, and exploring alternative inference methods.},
booktitle = {Proceedings of the 25th International Conference on Multimodal Interaction},
pages = {763–771},
numpages = {9},
keywords = {behavior cloning, co-speech gesture generation, deep learning, gesture synthesis, machine learning, multimodal data, reinforcement learning, transformer},
location = {Paris, France},
series = {ICMI '23}
}

@inproceedings{10.1145/3564719.3568687,
author = {Kusmenko, Evgeny and Münker, Maximilian and Nadenau, Matthias and Rumpe, Bernhard},
title = {A Model-Driven Generative Self Play-Based Toolchain for Developing Games and Players},
year = {2022},
isbn = {9781450399203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3564719.3568687},
doi = {10.1145/3564719.3568687},
abstract = {Turn-based games such as chess are very popular, but tool-chains tailored for their development process are still rare. In this paper we present a model-driven and generative toolchain aiming to cover the whole development process of rule-based games. In particular, we present a game description language enabling the developer to model the game in a logics-based syntax. An executable game interpreter is generated from the game model and can then act as an environment for reinforcement learning-based self-play training of players. Before the training, the deep neural network can be modeled manually by a deep learning developer or generated using a heuristics estimating the complexity of mapping the state space to the action space. Finally, we present a case study modeling three games and evaluate the language features as well as the player training capabilities of the toolchain.},
booktitle = {Proceedings of the 21st ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {95–107},
numpages = {13},
keywords = {code generation, games, reinforcement learning},
location = {Auckland, New Zealand},
series = {GPCE 2022}
}

@article{10.5555/3648699.3649094,
author = {Zellinger, Werner and Kindermann, Stefan and Pereverzyev, Sergei V.},
title = {Adaptive learning of density ratios in RKHS},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Estimating the ratio of two probability densities from finitely many observations of the densities is a central problem in machine learning and statistics with applications in two-sample testing, divergence estimation, generative modeling, covariate shift adaptation, conditional density estimation, and novelty detection. In this work, we analyze a large class of density ratio estimation methods that minimize a regularized Bregman divergence between the true density ratio and a model in a reproducing kernel Hilbert space (RKHS). We derive new finite-sample error bounds, and we propose a Lepskii type parameter choice principle that minimizes the bounds without knowledge of the regularity of the density ratio. In the special case of square loss, our method adaptively achieves a minimax optimal error rate. A numerical illustration is provided.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {395},
numpages = {29},
keywords = {density ratio estimation, reproducing kernel Hilbert space, learning theory, regularization, inverse problem}
}

@inproceedings{10.1145/3539597.3570429,
author = {Liu, Chang and Yang, Yuwen and Xie, Zhe and Lu, Hongtao and Ding, Yue},
title = {Position-Aware Subgraph Neural Networks with Data-Efficient Learning},
year = {2023},
isbn = {9781450394079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539597.3570429},
doi = {10.1145/3539597.3570429},
abstract = {Data-efficient learning on graphs (GEL) is essential in real-world applications. Existing GEL methods focus on learning useful representations for nodes, edges, or entire graphs with "small" labeled data. But the problem of data-efficient learning for subgraph prediction has not been explored. The challenges of this problem lie in the following aspects: 1) It is crucial for subgraphs to learn positional features to acquire structural information in the base graph in which they exist. Although the existing subgraph neural network method is capable of learning disentangled position encodings, the overall computational complexity is very high. 2) Prevailing graph augmentation methods for GEL, including rule-based, sample-based, adaptive, and automated methods, are not suitable for augmenting subgraphs because a subgraph contains fewer nodes but richer information such as position, neighbor, and structure. Subgraph augmentation is more susceptible to undesirable perturbations. 3) Only a small number of nodes in the base graph are contained in subgraphs, which leads to a potential "bias" problem that the subgraph representation learning is dominated by these "hot" nodes. By contrast, the remaining nodes fail to be fully learned, which reduces the generalization ability of subgraph representation learning. In this paper, we aim to address the challenges above and propose a Position-Aware Data-Efficient Learning framework for subgraph neural networks called PADEL. Specifically, we propose a novel node position encoding method that is anchor-free, and design a new generative subgraph augmentation method based on a diffused variational subgraph autoencoder, and we propose exploratory and exploitable views for subgraph contrastive learning. Extensive experiment results on three real-world datasets show the superiority of our proposed method over state-of-the-art baselines.},
booktitle = {Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
pages = {643–651},
numpages = {9},
keywords = {contrastive learning, data-efficient learning, generative model, subgraph neural networks},
location = {Singapore, Singapore},
series = {WSDM '23}
}

@inproceedings{10.1145/3610543.3626179,
author = {Chen, Bingyi and Liu, Zengyu and Yuan, Li and Liu, Zhitao and Li, Yi and Wang, Guan and Xie, Ning},
title = {Monte Carlo Denoising via Multi-scale Auxiliary Feature Fusion Guided Transformer},
year = {2023},
isbn = {9798400703140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610543.3626179},
doi = {10.1145/3610543.3626179},
abstract = {Deep learning-based single-frame Monte Carlo denoising techniques have demonstrated remarkable results in photo-realistic rendering research. However, the current state-of-the-art methods relying on self-attention mechanisms underutilize auxiliary features and struggle to preserve intricate high-frequency details in complex scenes. Employing a generative adversarial architecture, we present a transformer-based denoising network guided by multi-scale auxiliary feature. The proposed U-shaped denoising network extracts multi-scale texture and geometric features from auxiliaries, modulating them to guide the improved transformer module’s denoising process. The improved transformer module employs cross-channel self-attention to capture non-local relationships with near-linear computational complexity. Additionally, a gating mechanism is introduced in the transformer module’s feed-forward network, enhancing information flow. Extensive experiments on noisy images with varied per-pixel sampling rates demonstrate the method’s superiority in quantitative metrics and visual perception compared with state-of-the-art methods. Our method excels notably in intricate scenes with complex hair and texture details, which are historically challenging to denoise.},
booktitle = {SIGGRAPH Asia 2023 Technical Communications},
articleno = {1},
numpages = {4},
keywords = {Monte Carlo denoising, Transformer, self-attention},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3578338.3593562,
author = {Sam, Tyler and Chen, Yudong and Yu, Christina Lee},
title = {Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure},
year = {2023},
isbn = {9798400700743},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578338.3593562},
doi = {10.1145/3578338.3593562},
abstract = {Reinforcement learning (RL) methods have been increasingly popular in sequential decision making tasks due to its empirical success. However, large state and action spaces in real-world problems modeled as a Markov decision processes (MDPs) limit the use of RL algorithms. Given a standard finite-horizon MDP (S, A, P, R, H) with state space S, action space A, transition kernel P = {Ph} ∈ []H, reward function R = {R h} ∈ [H] bounded between zero and one, and time horizon H, one needs Ω (|S||A|H3/∈2 samples given a generative model to learn an optimal policy [3], which can be impractical when S and A are large. The above tabular RL framework does not capture the fact that many real-world systems in fact have additional structure that if exploited should improve computational and statistical efficiency. Moreover, [1] empirically verifies that optimal and near-optimal action-value functions (both viewed as |S|-by-|A| matrices) of classical stochastic control tasks have low rank. Thus, the critical question is what are the minimal low rank structural assumptions that allow for computationally and statistically efficient learning?},
booktitle = {Abstract Proceedings of the 2023 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {85–86},
numpages = {2},
keywords = {low-rank matrix estimation, reinforcement learning},
location = {Orlando, Florida, United States},
series = {SIGMETRICS '23}
}

@inproceedings{10.5555/3535850.3535995,
author = {Vasco, Miguel and Yin, Hang and Melo, Francisco S. and Paiva, Ana},
title = {How to Sense the World: Leveraging Hierarchy in Multimodal Perception for Robust Reinforcement Learning Agents},
year = {2022},
isbn = {9781450392136},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This work addresses the problem of sensing the world: how to learn a multimodal representation of a reinforcement learning agent's environment that allows the execution of tasks under incomplete perceptual conditions. To address such problem, we argue for hierarchy in the design of representation models and contribute with a novel multimodal representation model, MUSE. The proposed model learns a hierarchy of representations: low-level modality-specific representations, encoded from raw observation data, and a high-level multimodal representation, encoding joint-modality information to allow robust state estimation. We employ MUSE as the perceptual model of deep reinforcement learning agents provided with multimodal observations in Atari games. We perform a comparative study over different designs of reinforcement learning agents, showing that MUSE allows agents to perform tasks under incomplete perceptual experience with minimal performance loss. Finally, we also evaluate the generative performance of MUSE in literature-standard multimodal scenarios with higher number and more complex modalities, showing that it outperforms state-of-the-art multimodal variational autoencoders in single and cross-modality generation.},
booktitle = {Proceedings of the 21st International Conference on Autonomous Agents and Multiagent Systems},
pages = {1301–1309},
numpages = {9},
keywords = {multimodal representation learning, reinforcement learning, unsupervised learning},
location = {Virtual Event, New Zealand},
series = {AAMAS '22}
}

@inproceedings{10.1145/3543507.3587428,
author = {de Berardinis, Jacopo and Meroño-Peñuela, Albert and Poltronieri, Andrea and Presutti, Valentina},
title = {The Harmonic Memory: a Knowledge Graph of harmonic patterns as a trustworthy framework for computational creativity},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3587428},
doi = {10.1145/3543507.3587428},
abstract = {Computationally creative systems for music have recently achieved impressive results, fuelled by progress in generative machine learning. However, black-box approaches have raised fundamental concerns for ethics, accountability, explainability, and musical plausibility. To enable trustworthy machine creativity, we introduce the Harmonic Memory, a Knowledge Graph (KG) of harmonic patterns extracted from a large and heterogeneous musical corpus. By leveraging a cognitive model of tonal harmony, chord progressions are segmented into meaningful structures, and patterns emerge from their comparison via harmonic similarity. Akin to a music memory, the KG holds temporal connections between consecutive patterns, as well as salient similarity relationships. After demonstrating the validity of our choices, we provide examples of how this design enables novel pathways for combinational creativity. The memory provides a fully accountable and explainable framework to inspire and support creative professionals – allowing for the discovery of progressions consistent with given criteria, the recomposition of harmonic sections, but also the co-creation of new progressions.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {3873–3882},
numpages = {10},
keywords = {computational creativity, knowledge graphs, music technology},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3579375.3579395,
author = {Kaur, Sehajpreet and Kumar, Shivansh and Homayouni, Hajar},
title = {Synthetic High-Resolution COVID-19 Chest X-Ray Generation},
year = {2023},
isbn = {9798400700057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579375.3579395},
doi = {10.1145/3579375.3579395},
abstract = {Chest X-ray images provide critical information for the diagnosis of COVID-19. Machine learning techniques for COVID-19 detection require substantial amounts of chest images to discover correct patterns. However, concerns over confidentiality and privacy have limited access to patients’ data. The distribution of samples across normal/abnormal classes is typically biased or skewed due to unavailability of sufficient data because of COVID-19 recency. Existing synthetic COVID-19 data generation approaches fail to generate high-resolution and diverse images. Moreover, there is a lack of research identifying whether synthetic images represent patients at high risk of severe disease, which is critical for making treatment decisions. We propose a High-Resolution COVID-19 X-Ray Generator (HRCX) framework based on a combination of a generative adversarial network and a predictive learning model that uses limited available chest images to generate balanced diverse high-resolution COVID-19 images with their severity scores. We use StyleGAN2 with adaptive discriminator augmentation, which controls generated images’ style and generates diverse patterns. In addition, we provide a COVID-19 severity index to aid in predicting illness severity. We generated 3300 high-quality and diverse COVID-19 X-Ray images with a resolution of 512x512, which we further increased to 1024x1024 with the help of Super-Resolution. Additionally, severity scores of 300 images are calculated and demonstrated to be effective in both normal and infected cases.},
booktitle = {Proceedings of the 2023 Australasian Computer Science Week},
pages = {151–159},
numpages = {9},
keywords = {COVID-19, Chest X-rays, Deep learning, Generative Adversarial Networks, Synthetic image generation},
location = {Melbourne, VIC, Australia},
series = {ACSW '23}
}

@inproceedings{10.1145/3551626.3564958,
author = {Yamawaki, Kazuhiro and Han, Xian-Hua},
title = {Deep Image and Kernel Prior Learning for Blind Super-Resolution},
year = {2022},
isbn = {9781450394789},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551626.3564958},
doi = {10.1145/3551626.3564958},
abstract = {Recently, single image super-resolution (SR) has witnessed significant progress due to the powerful modeling capability of the deep learning networks. However, conventional deep learning-based super-resolution methods predict high-resolution (HR) images under the assumption of ideal degradation model such as the simulated bicubic down-sampling, and then unavoidably deteriorate the SR performance under un-controlled imaging conditions, such as real-world LR images. This study proposes an universal blind SR framework for adaptively and simultaneously predicting the underlying HR image and the counterpart blurring kernel from the observed LR image only. Specifically, we employ an encoder-decoder-based generative network to learn the inherent statistic prior of the HR image from a noise input while adopt a shallow convolution subnet with several stacked layers to estimate the blurring kernel from the observed LR image. Then, a convolution-based degradation module by setting the estimated blurring kernel as its weights is incorporated to obtain the approximated version of the LR image for formulating the loss function. In addition, a pre-trained discriminator is adopted to integrate the perceptual loss for recovering more accurate and natural HR image. We demonstrate the effectiveness of the proposed deep image and kernel prior learning framework using extensive experiments on both synthetic and real images, showing superiority over the state-of-the-art blind SR performance.},
booktitle = {Proceedings of the 4th ACM International Conference on Multimedia in Asia},
articleno = {2},
numpages = {7},
keywords = {blind SR, image super-resolution, kernel estimation, perceptual loss, unsupervised learning},
location = {Tokyo, Japan},
series = {MMAsia '22}
}

@article{10.1145/3526115,
author = {Chhabria, Vidya A. and Ahuja, Vipul and Prabhu, Ashwath and Patil, Nikhil and Jain, Palkesh and Sapatnekar, Sachin S.},
title = {Encoder-Decoder Networks for Analyzing Thermal and Power Delivery Networks},
year = {2022},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {1},
issn = {1084-4309},
url = {https://doi.org/10.1145/3526115},
doi = {10.1145/3526115},
abstract = {Power delivery network (PDN) analysis and thermal analysis are computationally expensive tasks that are essential for successful integrated circuit (IC) design. Algorithmically, both these analyses have similar computational structure and complexity as they involve the solution to a partial differential equation of the same form. This article converts these analyses into image-to-image and sequence-to-sequence translation tasks, which allows leveraging a class of machine learning models with an encoder-decoder–based generative (EDGe) architecture to address the time-intensive nature of these tasks. For PDN analysis, we propose two networks: (i)&nbsp;IREDGe: a full-chip static and dynamic IR drop predictor and (ii)&nbsp;EMEDGe: electromigration (EM) hotspot classifier based on input power, power grid distribution, and power pad distribution patterns. For thermal analysis, we propose ThermEDGe, a full-chip static and dynamic temperature estimator based on input power distribution patterns for thermal analysis. These networks are transferable across designs synthesized within the same technology and packing solution. The networks predict on-chip IR drop, EM hotspot locations, and temperature in milliseconds with negligibly small errors against commercial tools requiring several hours.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = dec,
articleno = {3},
numpages = {27},
keywords = {Machine learning (ML) for electronic design automation (EDA), Thermal analysis, Power delivery network (PDN) analysis, IR drop, electromigration (EM), encoder-decoder networks, U-Nets}
}

@article{10.1109/TCBB.2022.3153963,
author = {Chen, Jiatao and Zhang, Liang and Cheng, Ke and Jin, Bo and Lu, Xinjiang and Che, Chao},
title = {Predicting Drug-Target Interaction Via Self-Supervised Learning},
year = {2022},
issue_date = {Sept.-Oct. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {5},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3153963},
doi = {10.1109/TCBB.2022.3153963},
abstract = {Recent advances in graph representation learning provide new opportunities for computational drug-target interaction (DTI) prediction. However, it still suffers from deficiencies of dependence on manual labels and vulnerability to attacks. Inspired by the success of self-supervised learning (SSL) algorithms, which can leverage input data itself as supervision,we propose SupDTI, a SSL-enhanced drug-target interaction prediction framework based on a heterogeneous network (i.e., drug-protein, drug-drug, and protein-protein interaction network; drug-disease, drug-side-effect, and protein-disease association network; drug-structure and protein-sequence similarity network). Specifically, SupDTI is an end-to-end learning framework consisting of five components. First, localized and globalized graph convolutions are designed to capture the nodes&amp;#x2019; information from both local and global perspectives, respectively. Then, we develop a variational autoencoder to constrain the nodes&amp;#x2019; representation to have desired statistical characteristics. Finally, a unified self-supervised learning strategy is leveraged to enhance the nodes&amp;#x2019; representation, namely, a contrastive learning module is employed to enable the nodes&amp;#x2019; representation to fit the graph-level representation, followed by a generative learning module which further maximizes the node-level agreement across the global and local views by learning the probabilistic connectivity distribution of the original heterogeneous network. Experimental results show that our model can achieve better prediction performance than state-of-the-art methods.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = mar,
pages = {2781–2789},
numpages = {9}
}

@inproceedings{10.1145/3534678.3539283,
author = {Lao, Danning and Yang, Xinyu and Wu, Qitian and Yan, Junchi},
title = {Variational Inference for Training Graph Neural Networks in Low-Data Regime through Joint Structure-Label Estimation},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3539283},
doi = {10.1145/3534678.3539283},
abstract = {Graph Neural Networks (GNNs) are one of the prominent methods to solve semi-supervised learning on graphs. However, most of the existing GNN models often need sufficient observed data to allow for effective learning and generalization. In real-world scenarios where complete input graph structure and sufficient node labels might not be achieved easily, GNN models would encounter with severe performance degradation. To address this problem, we propose WSGNN, short for weakly-supervised graph neural network. WSGNN is a flexible probabilistic generative framework which harnesses variational inference approach to solve graph semi-supervised learning in a label-structure joint estimation manner. It collaboratively learns task-related new graph structure and node representations through a two-branch network, and targets a composite variational objective derived from underlying data generation distribution concerning the inter-dependence between scarce observed data and massive missing data. Especially, under weakly-supervised low-data regime where labeled nodes and observed edges are both very limited, extensive experimental results on node classification and link prediction over common benchmarks demonstrate the state-of-the-art performance of WSGNN over strong competitors. Concretely, when only 1 label per class and 1% edges are observed on Cora, WSGNN maintains a decent 52.00% classification accuracy, exceeding GCN by 75.6%.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {824–834},
numpages = {11},
keywords = {graph neural networks, label-efficient learning, semi-supervised learning on graphs, variational inference},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3625156.3625182,
author = {Kuo, Ching and Yang, Shih-Hsuan},
title = {Image Inpainting for Passersby Removal Based on Multi-Scale Dilated Gated Convolution with Generative Adversarial Networks},
year = {2023},
isbn = {9798400708206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625156.3625182},
doi = {10.1145/3625156.3625182},
abstract = {Passersby often appear in photos taken at popular scenic spots. To remove the unwanted passersby in photos and fill in the empty areas, a typical approach is manually labeling passersby and using software (Photoshop, Snapseed, Photo Retouch) for inpainting. This approach, however, takes long time and may not produce satisfactory and stable results. In this study, we propose an automatic image segmentation and inpainting algorithm for passersby removal, which greatly reduces the labeling and editing time. The passersby are identified by the Mask R-CNN image segmentation technique. The missing areas are estimated using a modified generative adversarial network (GAN) with gated convolutions and a coarse-to-fine refinement structure. A higher number of channels is used in the deep network to improve the learning of image features. Multi-scale dilated convolution is adopted to ensure the transfer of features and to relieve the discontinuity caused by the holes of traditional dilated convolution. Compared with the existing methods, the proposed method preserves the color and structural features of the missing areas more faithfully, and the objective image quality in PSNR is increased by 0.5 dB to 1.1 dB on average.},
booktitle = {Proceedings of the 2023 6th International Conference on Information Science and Systems},
pages = {172–178},
numpages = {7},
keywords = {Gated convolution, Generative adversarial network (GAN), Image inpainting, Passersby removal},
location = {Edinburgh, United Kingdom},
series = {ICISS '23}
}

@inproceedings{10.1145/3577190.3614119,
author = {Liu, Hansi and Lu, Hongsheng and Data, Kristin and Gruteser, Marco},
title = {ViFi-Loc: Multi-modal Pedestrian Localization using GAN with Camera-Phone Correspondences},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577190.3614119},
doi = {10.1145/3577190.3614119},
abstract = {In Smart City and Vehicle-to-Everything (V2X) systems, acquiring pedestrians’ accurate locations is crucial to traffic and pedestrian safety. Current systems adopt cameras and wireless sensors to estimate people’s locations via sensor fusion. Standard fusion algorithms, however, become inapplicable when multi-modal data is not associated. For example, pedestrians are out of the camera field of view, or data from the camera modality is missing. To address this challenge and produce more accurate location estimations for pedestrians, we propose a localization solution based on a Generative Adversarial Network (GAN) architecture. During training, it learns the underlying linkage between pedestrians’ camera-phone data correspondences. During inference, it generates refined position estimations based only on pedestrians’ phone data that consists of GPS, IMU, and FTM. Results show that our GAN produces 3D coordinates at 1 to 2 meters localization error across 5 different outdoor scenes. We further show that the proposed model supports self-learning. The generated coordinates can be associated with pedestrians’ bounding box coordinates to obtain additional camera-phone data correspondences. This allows automatic data collection during inference. Results show that after fine-tuning the GAN model on the expanded dataset, localization accuracy is further improved by up to 26%.},
booktitle = {Proceedings of the 25th International Conference on Multimodal Interaction},
pages = {661–669},
numpages = {9},
keywords = {Computer Vision, GAN, IMU, Localization, Multi-modal, WiFi FTM},
location = {Paris, France},
series = {ICMI '23}
}

@inproceedings{10.1145/3555776.3577751,
author = {Frazzetto, Paolo and Pasa, Luca and Navarin, Nicolo and Sperduti, Alessandro},
title = {Topology preserving maps as aggregations for Graph Convolutional Neural Networks},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577751},
doi = {10.1145/3555776.3577751},
abstract = {In Graph Convolutional Neural Networks, the capability of learning the representation of graph nodes comes at hand when dealing with graph analysis tasks, such as predicting node properties. Furthermore, node-level representations can be aggregated to obtain a single graph-level representation and predictor. This work explores an alternative route for defining the aggregation function compared to existing approaches. We propose a graph aggregator that exploits Generative Topographic Mapping (GTM) to transform a set of node-level representations into a single graph-level one. The integration of GTM in a GCNN pipeline allows to estimate node representation probability densities and projects them in a low-dimensional space, while retaining the information about their mutual similarity and topology. A novel dedicated training procedure is specifically designed to learn from these reduced representations instead of the complete initial data. Experimental results on several graph classification datasets show that this approach achieves competitive predictive performances with respect to the commonly adopted aggregation architectures present in the literature while holding a well-grounded theoretical framework.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {536–543},
numpages = {8},
keywords = {graph neural network, generative topographic mapping, node aggregation},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3534678.3542672,
author = {He, Weijie and Chen, Ting},
title = {Scalable Online Disease Diagnosis via Multi-Model-Fused Actor-Critic Reinforcement Learning},
year = {2022},
isbn = {9781450393850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3534678.3542672},
doi = {10.1145/3534678.3542672},
abstract = {For those seeking healthcare advice online, AI based dialogue agents capable of interacting with patients to perform automatic disease diagnosis are a viable option. This application necessitates efficient inquiry of relevant disease symptoms in order to make accurate diagnosis recommendations. This can be formulated as a problem of sequential feature (symptom) selection and classification for which reinforcement learning (RL) approaches have been proposed as a natural solution. They perform well when the feature space is small, that is, the number of symptoms and diagnosable disease categories is limited, but they frequently fail in assignments with a large number of features. To address this challenge, we propose a Multi-Model-Fused Actor-Critic (MMF-AC) RL framework that consists of a generative actor network and a diagnostic critic network. The actor incorporates a Variational AutoEncoder (VAE) to model the uncertainty induced by partial observations of features, thereby facilitating in making appropriate inquiries. In the critic network, a supervised diagnosis model for disease predictions is involved to precisely estimate the state-value function. Furthermore, inspired by the medical concept of differential diagnosis, we combine the generative and diagnosis models to create a novel reward shaping mechanism to address the sparse reward problem in large search spaces. We conduct extensive experiments on both synthetic and real-world datasets for empirical evaluations. The results demonstrate that our approach outperforms state-of-the-art methods in terms of diagnostic accuracy and interaction efficiency while also being more effectively scalable to large search spaces. Besides, our method is adaptable to both categorical and continuous features, making it ideal for online applications.},
booktitle = {Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4695–4703},
numpages = {9},
keywords = {online disease diagnosis, reinforcement learning, self-diagnosis},
location = {Washington DC, USA},
series = {KDD '22}
}

@inproceedings{10.1145/3610548.3618227,
author = {Valença, Lucas and Zhang, Jinsong and Gharbi, Michaël and Hold-Geoffroy, Yannick and Lalonde, Jean-François},
title = {Shadow Harmonization for Realistic Compositing},
year = {2023},
isbn = {9798400703157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610548.3618227},
doi = {10.1145/3610548.3618227},
abstract = {Compositing virtual objects into real background images requires one to carefully match the scene’s camera parameters, surface geometry, textures, and lighting to obtain plausible renderings. Recent learning approaches have shown many scene properties can be estimated from images, resulting in robust automatic single-image compositing systems, but many challenges remain. In particular, interactions between real and synthetic shadows are not handled gracefully by existing methods, which typically assume a shadow-free background. As a result, they tend to generate double shadows when the synthetic object’s cast shadow overlaps a background shadow, and ignore shadows from the background that should be cast onto the synthetic object. In this paper, we present a compositing method for outdoor scenes that addresses these issues and produces realistic cast shadows. This requires identifying existing shadows, including soft shadow boundaries, then reasoning about the ambiguity of unknown ground albedo and scene lighting to match the color and intensity of shaded areas. Using supervision from shadow removal and detection datasets, we propose a generative adversarial pipeline and improved composition equations that simultaneously handle both shadow interaction scenarios. We evaluate our method on challenging, real outdoor images from multiple distributions and datasets. Quantitative and qualitative comparisons show our approach produces more realistic results than existing alternatives. Our code, datasets, and trained models are publicly available at https://lvsn.github.io/shadowcompositing.},
booktitle = {SIGGRAPH Asia 2023 Conference Papers},
articleno = {32},
numpages = {12},
keywords = {compositing, generative adversarial networks, outdoor illumination, shadows, virtual object insertion},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3604237.3626882,
author = {Pereira, Ricardo Ribeiro and Bono, Jacopo and Ascensão, João Tiago and Aparício, David and Ribeiro, Pedro and Bizarro, Pedro},
title = {The GANfather: Controllable generation of malicious activity to improve defence systems},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626882},
doi = {10.1145/3604237.3626882},
abstract = {Machine learning methods to aid defence systems in detecting malicious activity typically rely on labelled data. In some domains, such labelled data is unavailable or incomplete. In practice this can lead to low detection rates and high false positive rates, which characterise for example anti-money laundering systems. In fact, it is estimated that 1.7–4 trillion euros are laundered annually and go undetected. We propose The GANfather, a method to generate samples with properties of malicious activity, without label requirements. We propose to reward the generation of malicious samples by introducing an extra objective to the typical Generative Adversarial Networks (GANs) loss. Ultimately, our goal is to enhance the detection of illicit activity using the discriminator network as a novel and robust defence system. Optionally, we may encourage the generator to bypass pre-existing detection systems. This setup then reveals defensive weaknesses for the discriminator to correct. We evaluate our method in two real-world use cases, money laundering and recommendation systems. In the former, our method moves cumulative amounts close to 350 thousand dollars through a network of accounts without being detected by an existing system. In the latter, we recommend the target item to a broad user base with as few as 30 synthetic attackers. In both cases, we train a new defence system to capture the synthetic attacks.},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {133–140},
numpages = {8},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@article{10.1145/3589973,
author = {Sam, Tyler and Chen, Yudong and Yu, Christina Lee},
title = {Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3589973},
doi = {10.1145/3589973},
abstract = {The practicality of reinforcement learning algorithms has been limited due to poor scaling with respect to the problem size, as the sample complexity of learning an ε-optimal policy is Ω(|S||A|H/ ε2) over worst case instances of an MDP with state space S, action space A, and horizon H. We consider a class of MDPs for which the associated optimal Q* function is low rank, where the latent features are unknown. While one would hope to achieve linear sample complexity in |S| and |A| due to the low rank structure, we show that without imposing further assumptions beyond low rank of Q*, if one is constrained to estimate the Q function using only observations from a subset of entries, there is a worst case instance in which one must incur a sample complexity exponential in the horizon H to learn a near optimal policy. We subsequently show that under stronger low rank structural assumptions, given access to a generative model, Low Rank Monte Carlo Policy Iteration (LR-MCPI) and Low Rank Empirical Value Iteration (LR-EVI) achieve the desired sample complexity of Õ((|S|+|A|)poly (d,H)/ε2) for a rank d setting, which is minimax optimal with respect to the scaling of |S|, |A|, and ε. In contrast to literature on linear and low-rank MDPs, we do not require a known feature mapping, our algorithm is computationally simple, and our results hold for long time horizons. Our results provide insights on the minimal low-rank structural assumptions required on the MDP with respect to the transition kernel versus the optimal action-value function.},
journal = {Proc. ACM Meas. Anal. Comput. Syst.},
month = may,
articleno = {29},
numpages = {60},
keywords = {low-rank matrix estimation, reinforcement learning}
}

@article{10.5555/3586589.3586628,
author = {Birrell, Jeremiah and Dupuis, Paul and Katsoulakis, Markos A. and Pantazis, Yannis and Rey-Bellet, Luc},
title = {(f, Γ)-Divergences: interpolating between f-divergences and integral probability metrics},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
abstract = {We develop a rigorous and general framework for constructing information-theoretic divergences that subsume both f-divergences and integral probability metrics (IPMs), such as the 1-Wasserstein distance. We prove under which assumptions these divergences, hereafter referred to as (f, Γ)-divergences, provide a notion of 'distance' between probability measures and show that they can be expressed as a two-stage mass-redistribution/mass-transport process. The (f, Γ)-divergences inherit features from IPMs, such as the ability to compare distributions which are not absolutely continuous, as well as from f-divergences, namely the strict concavity of their variational representations and the ability to control heavy-tailed distributions for particular choices of f. When combined, these features establish a divergence with improved properties for estimation, statistical learning, and uncertainty quantification applications. Using statistical learning as an example, we demonstrate their advantage in training generative adversarial networks (GANs) for heavy-tailed, not-absolutely continuous sample distributions. We also show improved performance and stability over gradient-penalized Wasserstein GAN in image generation.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {39},
numpages = {70},
keywords = {f-divergences, integral probability metrics, Wasserstein metric, variational representations, GANs}
}

@article{10.5555/3586589.3586705,
author = {Huang, Jian and Jiao, Yuling and Li, Zhen and Liu, Shiao and Wang, Yang and Yang, Yunfei},
title = {An error analysis of generative adversarial networks for learning distributions},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
abstract = {This paper studies how well generative adversarial networks (GANs) learn probability distributions from finite samples. Our main results establish the convergence rates of GANs under a collection of integral probability metrics defined through Hölder classes, including the Wasserstein distance as a special case. We also show that GANs are able to adaptively learn data distributions with low-dimensional structures or have Hölder densities, when the network architectures are chosen properly. In particular, for distributions concentrated around a low-dimensional set, we show that the learning rates of GANs do not depend on the high ambient dimension, but on the lower intrinsic dimension. Our analysis is based on a new oracle inequality decomposing the estimation error into the generator and discriminator approximation error and the statistical error, which may be of independent interest.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {116},
numpages = {43},
keywords = {generative adversarial networks, deep neural networks, convergence rate, error decomposition, risk bound}
}

@article{10.1109/TASLP.2022.3155286,
author = {Kothapally, Vinay and Hansen, John H. L.},
title = {SkipConvGAN: Monaural Speech Dereverberation Using Generative Adversarial Networks via Complex Time-Frequency Masking},
year = {2022},
issue_date = {2022},
publisher = {IEEE Press},
volume = {30},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2022.3155286},
doi = {10.1109/TASLP.2022.3155286},
abstract = {With the advancements in deep learning approaches, the performance of speech enhancing systems in the presence of background noise have shown significant improvements. However, improving the system&amp;#x2019;s robustness against reverberation is still a work in progress, as reverberation tends to cause loss of formant structure due to smearing effects in time and frequency. A wide range of deep learning-based systems either enhance the magnitude response and reuse the distorted phase or enhance complex spectrogram using a complex time-frequency mask. Though these approaches have demonstrated satisfactory performance, they do not directly address the lost formant structure caused by reverberation. We believe that retrieving the formant structure can help improve the efficiency of existing systems. In this study, we propose SkipConvGAN - an extension of our prior work SkipConvNet. The proposed system&amp;#x2019;s generator network tries to estimate an efficient complex time-frequency mask, while the discriminator network aids in driving the generator to restore the lost formant structure. We evaluate the performance of our proposed system on simulated and real recordings of reverberant speech from the single-channel task of the REVERB challenge corpus. The proposed system shows a consistent improvement across multiple room configurations over other deep learning-based generative adversarial frameworks.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = mar,
pages = {1600–1613},
numpages = {14}
}

@inproceedings{10.1145/3589132.3628362,
author = {Chu, Chen and Zhang, Hengcai and Lu, Feng},
title = {TrajGDM: A New Trajectory Foundation Model for Simulating Human Mobility},
year = {2023},
isbn = {9798400701689},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589132.3628362},
doi = {10.1145/3589132.3628362},
abstract = {Capturing the universal movement pattern and simulating human mobility is one of the most important trajectory data-mining tasks. Most of the current mobility modeling methods are specially designed to solve a specific task, which leads to questions regarding generalizability. Aiming to construct a general trajectory foundation model to overcome this weakness, we proposed a generative Trajectory Generation framework based on Diffusion Model (TrajGDM) to capture the universal mobility pattern and simulate human mobility. It is capable of solving multiple trajectory tasks through learning the generation of the trajectory. The generation process of a trajectory is modeled as a step-by-step uncertainty reducing process. A trajectory generator network is proposed to estimate the uncertainty in each step, and a trajectory diffusion and generation process is defined to train the model to simulate the real dataset. Finally, we compared the proposed method with 6 baselines on 2 public trajectory datasets: T-Drive and Geo-life. By comparing 5 different evaluation metrics, the result showed that the similarity between generated and real trajectories' movement character measured by Jensen-Shannon Divergence (JSD) improved by at least 50.3% in both datasets. It also addresses the problem of generating diverse trajectories, which is ignored by most previous models. Moreover, we applied zero-shot inferences on two basic trajectory tasks: trajectory prediction and trajectory reconstruction. The zero-shot prediction accuracy of our model is up to 23.4% higher than the benchmark, and the reconstruction accuracy improves by a maximum of 25.6%.},
booktitle = {Proceedings of the 31st ACM International Conference on Advances in Geographic Information Systems},
articleno = {1},
numpages = {2},
keywords = {trajectory generation, diffusion model, foundation model},
location = {Hamburg, Germany},
series = {SIGSPATIAL '23}
}

@inproceedings{10.1145/3597926.3598099,
author = {Xiao, Yisong and Liu, Aishan and Li, Tianlin and Liu, Xianglong},
title = {Latent Imitator: Generating Natural Individual Discriminatory Instances for Black-Box Fairness Testing},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598099},
doi = {10.1145/3597926.3598099},
abstract = {Machine learning (ML) systems have achieved remarkable performance across a wide area of applications. However, they frequently exhibit unfair behaviors in sensitive application domains (e.g., employment and loan), raising severe fairness concerns. To evaluate and test fairness, engineers often generate individual discriminatory instances to expose unfair behaviors before model deployment. However, existing baselines ignore the naturalness of generation and produce instances that deviate from the real data distribution, which may fail to reveal the actual model fairness since these unnatural discriminatory instances are unlikely to appear in practice. To address the problem, this paper proposes a framework named Latent Imitator (LIMI) to generate more natural individual discriminatory instances with the help of a generative adversarial network (GAN), where we imitate the decision boundary of the target model in the semantic latent space of GAN and further samples latent instances on it. Specifically, we first derive a surrogate linear boundary to coarsely approximate the decision boundary of the target model, which reflects the nature of the original data distribution. Subsequently, to obtain more natural instances, we manipulate random latent vectors to the surrogate boundary with a one-step movement, and further conduct vector calculation to probe two potential discriminatory candidates that may be more closely located in the real decision boundary. Extensive experiments on various datasets demonstrate that our LIMI outperforms other baselines largely in effectiveness (×9.42 instances), efficiency (×8.71 speeds), and naturalness (+19.65%) on average. In addition, we empirically demonstrate that retraining on test samples generated by our approach can lead to improvements in both individual fairness (45.67% on IFr and 32.81% on IFo) and group fairness (9.86% on SPD and 28.38% on AOD). Our codes can be found on our website.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {829–841},
numpages = {13},
keywords = {Fairness Testing, Individual Discrimination, Latent Space, Natural Individual Discriminatory Instances},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@article{10.1145/3517154,
author = {Gao, Honghao and Dai, Baobin and Miao, Huaikou and Yang, Xiaoxian and Barroso, Ramon J. Duran and Walayat, Hussain},
title = {A Novel GAPG Approach to Automatic Property Generation for Formal Verification: The GAN Perspective},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3517154},
doi = {10.1145/3517154},
abstract = {Formal methods have been widely used to support software testing to guarantee correctness and reliability. For example, model checking technology attempts to ensure that the verification property of a specific formal model is satisfactory for discovering bugs or abnormal behavior from the perspective of temporal logic. However, because automatic approaches are lacking, a software developer/tester must manually specify verification properties. A generative adversarial network (GAN) learns features from input training data and outputs new data with similar or coincident features. GANs have been successfully used in the image processing and text processing fields and achieved interesting and automatic results. Inspired by the power of GANs, in this article, we propose a GAN-based automatic property generation (GAPG) approach to generate verification properties supporting model checking. First, the verification properties in the form of computational tree logic (CTL) are encoded and used as input to the GAN. Second, we introduce regular expressions as grammar rules to check the correctness of the generated properties. These rules work to detect and filter meaningless properties that occur because the GAN learning process is uncontrollable and may generate unsuitable properties in real applications. Third, the learning network is further trained by using labeled information associated with the input properties. These are intended to guide the training process to generate additional new properties, particularly those that map to corresponding formal models. Finally, a series of comprehensive experiments demonstrate that the proposed GAPG method can obtain new verification properties from two aspects: (1) using only CTL formulas and (2) using CTL formulas combined with Kripke structures.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
articleno = {16},
numpages = {22},
keywords = {Model checking, verification property, generative adversarial network (GAN), automatic property generation, computational tree logic, correctness and reliability}
}

@inproceedings{10.1145/3503161.3548378,
author = {Zhang, Peng-Fei and Bai, Guangdong and Huang, Zi and Xu, Xin-Shun},
title = {Machine Unlearning for Image Retrieval: A Generative Scrubbing Approach},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548378},
doi = {10.1145/3503161.3548378},
abstract = {Data owners have the right to request for deleting their data from a machine learning (ML) model. In response, a naïve way is to retrain the model with the original dataset excluding the data to forget, which is however unrealistic as the required dataset may no longer be available and the retraining process is usually computationally expensive. To cope with this reality, machine unlearning has recently attained much attention, which aims to enable data removal from a trained ML model responding to deletion requests, without retraining the model from scratch or full access to the original training dataset. Existing unlearning methods mainly focus on handling conventional ML methods, while unlearning deep neural networks (DNNs) based models remains underexplored, especially for the ones trained on large-scale datasets.In this paper, we make the first attempt to realize data forgetting on deep models for image retrieval. Image retrieval targets at searching relevant data to the query according to similarity measures. Intuitively, unlearning a deep image retrieval model can be achieved by breaking down its ability of similarity modeling on the data to forget. To this end, we propose a generative scrubbing (GS) method that learns a generator to craft noisy data to manipulate the model weights. A novel framework is designed consisting of the generator and the target retrieval model, where a pair of coupled static and dynamic learning procedures are performed simultaneously. This novel learning strategy effectively enables the generated noisy data to fade away the memory of the model on the data to forget whilst retaining the information of the remaining data. Extensive experiments on three widely-used datasets have successfully verified the effectiveness of the proposed method.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {237–245},
numpages = {9},
keywords = {deep learning, image retrieval, machine unlearning, privacy protection},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3580305.3599363,
author = {Zhao, Yu and Deng, Pan and Liu, Junting and Jia, Xiaofeng and Zhang, Jianwei},
title = {Generative Causal Interpretation Model for Spatio-Temporal Representation Learning},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599363},
doi = {10.1145/3580305.3599363},
abstract = {Learning, interpreting, and predicting from complex and high-dimensional spatio-temporal data is a natural ability of humans and other intelligent agents, and one of the most important and difficult challenges of AI. Although objects may present different observed phenomena under different situations, their causal mechanism and generation rules are stable and invariant. Different from most existing studies that focus on dynamic correlation, we explore the latent causal structure and mechanism of causal descriptors in the spatio-temporal dimension at the microscopic level, thus revealing the generation principle of observation. In this paper, we regard the causal mechanism as a spatio-temporal causal process modulated by non-stationary exogenous variables. To this end, we propose a theoretically-grounded Generative Causal Interpretation Model (GCIM), which infers explanatory-capable microscopic causal descriptors from observational data via spatio-temporal causal representations. The core of GCIM is to estimate the prior distribution of causal descriptors by using the spatio-temporal causal structure and transition process under the constraints of identifiable conditions, thus extending the Variational Auto Encoder (VAE). Furthermore, our method is able to automatically capture domain information from observations to model non-stationarity. We further analyze the model identifiability, showing that the proposed model learned from observations recovers the true one up to a certain degree. Experiments on synthetic and real-world datasets show that GCIM can successfully identify latent causal descriptors and structures, and accurately predict future data.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3537–3548},
numpages = {12},
keywords = {generative causal model, spatio-temporal representation learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@article{10.1145/3550307,
author = {Cao, Yetong and Li, Fan and Chen, Huijie and liu, Xiaochen and Zhang, Li and Wang, Yu},
title = {Guard Your Heart Silently: Continuous Electrocardiogram Waveform Monitoring with Wrist-Worn Motion Sensor},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550307},
doi = {10.1145/3550307},
abstract = {In recent years, particular attention has been devoted to continuous electrocardiogram (ECG) waveform monitoring due to its numerous applications. However, existing solutions require users to be confined to particular locations, rely on dedicated and expensive hardware, or require active user participation. The constrained recording conditions prevent them from being deployed in many practical application scenarios. In view of this, we present VibCardiogram, a continuous and reliable design for estimating ECG waveform shape via ubiquitous wrist-worn wearables; it renders a personal ECG waveform shape estimating system with prolonged recording time accessible to a larger sector of the population. Instead of adding auxiliary sensors to wearables, VibCardiogram leverages the widely integrated motion sensor to characterize cardiac activities, and interpret them to generate an alternative signal that has the same waveform shape as the ECG signal. Specifically, VibCardiogram extracts the cardiogenic body vibrations from noisy sensor data. As the waveform variability and inconstant period hinder the segmentation of cardiac cycles, VibCardiogram extracts features and realizes accurate segmentation via machine learning. To parse cardiac activities from vibration signals, we build a deep-learning pipeline associating the encoder-decoder framework and Generative Adversarial Networks. With dedicated construction and training, it can estimate the ECG waveform accurately. Experiments with 20 participants show that VibCardiogram can achieve an average estimation error of 5.989% for waveform amplitude estimation, which is within the 10% margins regulated by the American National Standards Institute. Moreover, the promising results further confirm that VibCardiogram effectively extracts Heart Rate Variability features and supports downstream applications.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {103},
numpages = {29},
keywords = {ECG, Wearable, cardiogenic body vibration, deep learning}
}

@article{10.1145/3578521,
author = {Huang, Jingmin and Chen, Bowei and Yan, Zhi and Ounis, Iadh and Wang, Jun},
title = {GEO: A Computational Design Framework for Automotive Exterior Facelift},
year = {2023},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3578521},
doi = {10.1145/3578521},
abstract = {Exterior facelift has become an effective method for automakers to boost the consumers’ interest in an existing car model before it is redesigned. To support the automotive facelift design process, this study develops a novel computational framework&nbsp;– Generator, Evaluator, Optimiser (GEO), which comprises three components: a StyleGAN2-based design generator that creates different facelift designs; a convolutional neural network (CNN)-based evaluator that assesses designs from the aesthetics perspective; and a recurrent neural network (RNN)-based decision optimiser that selects designs to maximise the predicted profit of the targeted car model over time. We validate the GEO framework in experiments with real-world datasets and describe some resulting managerial implications for automotive facelift. Our study makes both methodological and application contributions. First, the generator’s mapping network and projection methods are carefully tailored to facelift where only minor changes are performed without affecting the family signature of the automobile brands. Second, two evaluation metrics are proposed to assess the generated designs. Third, profit maximisation is taken into account in the design selection. From a high-level perspective, our study contributes to the recent use of machine learning and data mining in marketing and design studies. To the best of our knowledge, this is the first study that uses deep generative models for automotive regional design upgrading and that provides an end-to-end decision-support solution for automakers and designers.},
journal = {ACM Trans. Knowl. Discov. Data},
month = mar,
articleno = {82},
numpages = {20},
keywords = {Automotive design, exterior facelift, design generation, aesthetics evaluation, decision optimisation}
}

@inproceedings{10.1145/3581783.3612356,
author = {Kang, Xujie and Liu, Kanglin and Duan, Jiang and Gong, Yuanhao and Qiu, Guoping},
title = {P2I-NET: Mapping Camera Pose to Image via Adversarial Learning for New View Synthesis in Real Indoor Environments},
year = {2023},
isbn = {9798400701085},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581783.3612356},
doi = {10.1145/3581783.3612356},
abstract = {Given a new 6DoF camera pose in an indoor environment, we study the challenging problem of predicting the view from that pose based on a set of reference RGBD views. Existing explicit or implicit 3D geometry construction methods are computationally expensive while those based on learning have predominantly focused on isolated views of object categories with regular geometric structure. Differing from the traditional render-inpaint approach to new view synthesis in the real indoor environment, we propose a conditional generative adversarial neural network (P2I-NET) to directly predict the new view from the given pose. P2I-NET learns the conditional distribution of the images of the environment for establishing the correspondence between the camera pose and its view of the environment, and achieves this through a number of innovative designs in its architecture and training lost function. Two auxiliary discriminator constraints are introduced for enforcing the consistency between the pose of the generated image and that of the corresponding real world image in both the latent feature space and the real world pose space. Additionally a deep convolutional neural network (CNN) is introduced to further reinforce this consistency in the pixel space. We have performed extensive new view synthesis experiments on real indoor datasets. Results show that P2I-NET has superior performance against a number of NeRF based strong baseline models. In particular, we show that P2I-NET is 40 to 100 times faster than these competitor techniques while synthesising similar quality images. Furthermore, we contribute a new publicly available indoor environment dataset containing 22 high resolution RGBD videos where each frame also has accurate camera pose parameters.},
booktitle = {Proceedings of the 31st ACM International Conference on Multimedia},
pages = {2635–2643},
numpages = {9},
keywords = {conditional generative adversarial network, new view image, rgbd datasets},
location = {Ottawa ON, Canada},
series = {MM '23}
}

@inproceedings{10.1145/3535511.3535520,
author = {Gomes, Anna Luiza and Vianna, Getúlio and Escovedo, Tatiana and Kalinowski, Marcos},
title = {Predicting IMDb Rating of TV Series with Deep Learning: The Case of Arrow},
year = {2022},
isbn = {9781450396981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3535511.3535520},
doi = {10.1145/3535511.3535520},
abstract = {Context: The number of TV series offered nowadays is very high. Due to its large amount, many series are canceled due to a lack of originality that generates a low audience.Problem: Having a decision support system that can show why some shows are a huge success or not would facilitate the choices of renewing or starting a show.Solution: We studied the case of the series Arrow broadcasted by CW Network and used descriptive and predictive modeling techniques to predict the IMDb rating. We assumed that the theme of the episode would affect its evaluation by users, so the dataset is composed only by the director of the episode, the number of reviews that episode got, the percentual of each theme extracted by the Latent Dirichlet Allocation (LDA) model of an episode, the number of viewers from Wikipedia and the rating from IMDb. The LDA model is a generative probabilistic model of a collection of documents made up of words.IS Theory: This study was developed under the aegis of Computational Learning Theory, which aims to understand the fundamental principles of learning and contribute to designing better-automated learning methods applied to the entertainment business.Method: In this prescriptive research, the case study method was used, and its results were analyzed using a quantitative approach.Summary of Results: With the features of each episode, the model that performed the best to predict the rating was Catboost due to a similar mean squared error of the KNN model but a better standard deviation during the test phase. It was possible to predict IMDb ratings with an acceptable root mean squared error of 0.55.Contributions and Impact in the IS area: The results show that deep learning techniques can be applied to support decisions in the entertainment field, allowing facilitating the decisions of renewing or starting a show. The rationale for building the model is detailed throughout the paper and can be replicated for other contexts.},
booktitle = {Proceedings of the XVIII Brazilian Symposium on Information Systems},
articleno = {9},
numpages = {6},
keywords = {Deep Learning, IMDb, LDA, Machine Learning, prediction, tv-series},
location = {Curitiba, Brazil},
series = {SBSI '22}
}

@inproceedings{10.1145/3580305.3599582,
author = {Bagherjeiran, Abraham and Djuric, Nemanja and Lee, Kuang-Chih and Pang, Linsey and Radosavljevic, Vladan and Rajan, Suju},
title = {AdKDD 2023},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599582},
doi = {10.1145/3580305.3599582},
abstract = {The digital advertising field has always had challenging ML problems, learning from petabytes of data that is highly imbalanced, reactivity times in the milliseconds, and more recently compounded with the complex user's path to purchase across devices, across platforms, and even online/real-world behavior. The AdKDD workshop continues to be a forum for researchers in advertising, during and after KDD. Our website which hosts slides and abstracts receives approximately 2,000 monthly visits and 1,800 active users during the KDD 2021. In surveys during AdKDD 2019 and 2020, over 60% agreed that AdKDD is the reason they attended KDD, and over 90% indicated they would attend next year. The 2023 edition is particularly timely because of the increasing application of Graph-based NN and Generative AI models in advertising. Coupled with privacy-preserving initiatives enforced by GDPR, CCPA the future of computational advertising is at an interesting crossroads. For this edition, we plan to solicit papers that span the spectrum of deep user understanding while remaining privacy-preserving. In addition, we will seek papers that discuss fairness in the context of advertising, to what extent does hyper-personalization work, and whether the ad industry as a whole needs to think through more effective business models such as incrementality. We have hosted several academic and industry luminaries as keynote speakers and have found our invited speaker series hosting expert practitioners to be an audience favorite. We will continue fielding a diverse set of keynote speakers and invited talks for this edition as well. As with past editions, we hope to motivate researchers in this space to think not only about the ML aspects but also to spark conversations about the societal impact of online advertising.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5849–5850},
numpages = {2},
keywords = {ad targeting, computational advertising, user modeling},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3566097.3568347,
author = {Lu, Jincong and Zhang, Jinwei and Jin, Wentian and Sachdeva, Sachin and Tan, Sheldon X.-D.},
title = {Learning Based Spatial Power Characterization and Full-Chip Power Estimation for Commercial TPUs},
year = {2023},
isbn = {9781450397834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3566097.3568347},
doi = {10.1145/3566097.3568347},
abstract = {In this paper, we propose a novel approach for the real-time estimation of chip-level spatial power maps for commercial Google Coral M.2 TPU chips based on a machine-learning technique for the first time. The new method can enable the development of more robust runtime power and thermal control schemes to take advantage of spatial power information such as hot spots that are otherwise not available. Different from the existing commercial multi-core processors in which real-time performance-related utilization information is available, the TPU from Google does not have such information. To mitigate this problem, we propose to use features that are related to the workloads of running different deep neural networks (DNN) such as the hyperparameters of DNN and TPU resource information generated by the TPU compiler. The new approach involves the offline acquisition of accurate spatial and temporal temperature maps captured from an external infrared thermal imaging camera under nominal working conditions of a chip. To build the dynamic power density map model, we apply generative adversarial networks (GAN) based on the workload-related features. Our study shows that the estimated total powers match the manufacturer's total power measurements extremely well. Experimental results further show that the predictions of power maps are quite accurate, with the RMSE of only 4.98mW/mm2, or 2.6% of the full-scale error. The speed of deploying the proposed approach on an Intel Core i7-10710U is as fast as 6.9ms, which is suitable for real-time estimation.},
booktitle = {Proceedings of the 28th Asia and South Pacific Design Automation Conference},
pages = {98–103},
numpages = {6},
location = {Tokyo, Japan},
series = {ASPDAC '23}
}

@article{10.5555/3648699.3648920,
author = {Zhou, Doudou and Cai, Tianxi and Lu, Junwei},
title = {Multi-source learning via completion of block-wise overlapping noisy matrices},
year = {2023},
issue_date = {January 2023},
publisher = {JMLR.org},
volume = {24},
number = {1},
issn = {1532-4435},
abstract = {Electronic healthcare records (EHR) provide a rich resource for healthcare research. An important problem for the efficient utilization of the EHR data is the representation of the EHR features, which include the unstructured clinical narratives and the structured codified data. Matrix factorization-based embeddings trained using the summary-level co-occurrence statistics of EHR data have provided a promising solution for feature representation while preserving patients' privacy. However, such methods do not work well with multi-source data when these sources have overlapping but non-identical features. To accommodate multi-sources learning, we propose a novel word embedding generative model. To obtain multi-source embeddings, we design an efficient Block-wise Overlapping Noisy Matrix Integration (BONMI) algorithm to aggregate the multi-source pointwise mutual information matrices optimally with a theoretical guarantee. Our algorithm can also be applied to other multi-source data integration problems with a similar data structure. A by-product of BONMI is the contribution to the field of matrix completion by considering the missing mechanism other than the entry-wise independent missing. We show that the entry-wise missing assumption, despite its prevalence in the works of matrix completion, is not necessary to guarantee recovery. We prove the statistical rate of our estimator, which is comparable to the rate under independent missingness. Simulation studies show that BONMI performs well under a variety of configurations. We further illustrate the utility of BONMI by integrating multi-lingual multi-source medical text and EHR data to perform two tasks: (i) co-training semantic embeddings for medical concepts in both English and Chinese and (ii) the translation between English and Chinese medical concepts. Our method shows an advantage over existing methods.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {221},
numpages = {43},
keywords = {word embedding, data integration, singular value decomposition, transfer learning}
}

@inproceedings{10.1145/3586209.3591404,
author = {Williams, Mathew and Kokalj-Filipovic, Silvija and Rodriguez, Armani},
title = {Analysis of Lossy Generative Data Compression for Robust Remote Deep Inference},
year = {2023},
isbn = {9798400701337},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586209.3591404},
doi = {10.1145/3586209.3591404},
abstract = {Networks of wireless sensors, including Internet of Things (IoT), motivate the use of lossy compression of the sensor data to match the available network bandwidth (BW). Hence, sensor data intended for inference by a remote deep learning (RDL) model is likely to be reconstructed with distortion, from a compressed representation received by the remote user over a wireless channel. Our focus is a particular type of lossy compression algorithm based on DL models, and known as learned compression (LC). The link between the information loss and compression rate in LCs has not been studied yet in the framework of information theory, nor practically associated with any meta-data which could describe the type and level of information loss to downstream users. This may make this compression undetectable yet potentially harmful. We study the robustness of a RDL classification model against the lossy compression of the input, including the robustness under an adversarial attack. We apply different compression methods of MNIST images, such as JPEG and a hierarchical LC, all with different compression ratios. For any lossy reconstruction and its uncompressed original, several techniques for topological feature characterization based on persistent homology are used to highlight the important differences amongst compression approaches that may affect the robust accuracy of a DL classifier trained on the original data. We conclude that LC is preferred in the described context, because we achieve the same accuracy as with the originals (with and without an adversarial attack) on a trained DL MNIST classifier, while using only 1/4 of the BW. We show that calculated topological features differ between JPEG and the comparable LC reconstructions, which are closer to the features of the original. We show that there is a distribution shift in those features due to the attack. Finally, most LC models are generative, meaning that we can generate multiple statistically independent compressed representations of a data point, which opens the possibility for the inference error correction at the RDL model. Due to space limitations, we leave this aspect for future work.},
booktitle = {Proceedings of the 2023 ACM Workshop on Wireless Security and Machine Learning},
pages = {33–38},
numpages = {6},
keywords = {adversarial attack, generative deep learning, learned compression, lossy compression, persistent homology},
location = {Guildford, United Kingdom},
series = {WiseML'23}
}

@inproceedings{10.1145/3498851.3498981,
author = {Tong, Qiang and Sun, Meixue and Wang, Bo and Liu, Dianyu},
title = {AutoAno: Anomaly Localization with Self-supervised Multi-scale Feature and Multivariate Gaussian Estimation},
year = {2022},
isbn = {9781450391870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3498851.3498981},
doi = {10.1145/3498851.3498981},
abstract = {Anomaly localization in images has long been challenging and valuable for both research and real-world applications. Popular methods for anomaly localization are with Auto-Encoder variants and existing GAN-based models, and have obtained decent outcomes. However, these generative models have significant limitations, such as the over-powerful generalization capacity in anomaly data. To address this problem, in this paper, we propose AutoAno, a self-supervised learning model that leverages both multi-scale feature and multivariate Gaussian estimation to achieve robust anomaly localization. In detail, our method extracts multi-scale features from the patches of an image, which can simultaneously consider global, contextual, and local features, so that contains richer semantic information to anomaly localization. We then employ multidimensional Gaussian distribution to estimate the low-dimensional representation for the normal samples in training data. Notably, we discard the commonly used reconstruction loss, and instead use the distance between multi-scale feature and the estimated Gaussian distribution to detect and localize the anomalies. To verify the effectiveness of our work, we compare AutoAno with the prevailing models with extensive experiments on benchmark and real-world datasets. The empirical results demonstrate that our model outperforms the state-of-the-art models significantly.},
booktitle = {IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology},
pages = {368–374},
numpages = {7},
keywords = {Anomaly localization, Multi-scale feature fusion, Multivariate Gaussian estimation, Self-supervised learning},
location = {Melbourne, VIC, Australia},
series = {WI-IAT '21}
}

@inproceedings{10.1145/3584371.3613029,
author = {Wu, Kwan-Ling and Montalvo, Melisa and Menon, Prashant and Roysam, Badrinath and Varadarajan, Navin},
title = {Automated Focus Restoration for High-throughput Phase Contrast Time-lapse Microscopy with De-noising Diffusion Probabilistic Model},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613029},
doi = {10.1145/3584371.3613029},
abstract = {Cell-based immunotherapies have revolutionized cancer treatment with unprecedented efficacy against leukemias and lymphomas. High-throughput (HT) time-lapse imaging serves as a fundamental technology to enable the profiling of immune cells as anti-cancer drugs and to help map their complexity and heterogeneity. Migrating to label-free phase-contrast video microscopy promises non-invasive, non-toxic, and efficient profiling at single-cell level resolution. Balancing the tradeoffs between speed and throughput implies that despite the best autofocusing algorithms of HT systems, out-of-focus (OOF) cells are unavoidable due to the migratory nature of immune cells (velocities &gt;10 μm/min). Restoration of OOF cells after acquisition increases the yield and accuracy of usable data by allowing more accurate segmentation and delineation of cell-cell contact.Although traditional image restoration methods estimate the point spread function (PSF) for deconvolution and have made remarkable progress, is the approach tends to resource-intensive and time-consuming. Recent deep-learning-based approaches model the inverse of the PSF for restoring images. However, these methods generate images without the fine details needed for cytometric profiling as they depend on the weighted average of available data for inference. We propose a method to overcome this challenge using a generative modeling approach using de-noising diffusion probabilistic models (DDPMs). These models have demonstrated state-of-the-art image generation performance by gradually removing noise.Our results showed that DDPM outperformed regression-based methods with the best Pearson Correlation Coefficient (PCC) based on the whole image (improved from 0.90 ± 0.04 to 0.95 ± 0.03) and around boundaries (from 0.79 ± 0.07 to 0.88 ± 0.03). In addition, we demonstrate how the focus restoration process improves the image processing steps. For cell contact detection, focus restoration yielded a higher PCC (0.08 ± 0.11 to 0.16 ± 0.19) and lower mean squared error (0.02 ± 0.05 to 0.01 ± 0.02), while for cell detection, the number of cells detected had a lower error (2 ± 4 against 8 ± 14 cells) for the restored images. These results illustrate that diffusion models can be added to the arsenal of tools for focus restoration in high-throughput time-lapse phase contrast microscopy.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {58},
numpages = {1},
keywords = {diffusion model, high-throughput microscopy, image re-focusing},
location = {Houston, TX, USA},
series = {BCB '23}
}

@article{10.1109/TCBB.2022.3141697,
author = {Qureshi, Rizwan and Zou, Bin and Alam, Tanvir and Wu, Jia and Lee, Victor H. F. and Yan, Hong},
title = {Computational Methods for the Analysis and Prediction of EGFR-Mutated Lung Cancer Drug Resistance: Recent Advances in Drug Design, Challenges and Future Prospects},
year = {2022},
issue_date = {Jan.-Feb. 2023},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {20},
number = {1},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2022.3141697},
doi = {10.1109/TCBB.2022.3141697},
abstract = {Lung cancer is a major cause of cancer deaths worldwide, and has a very low survival rate. Non-small cell lung cancer (NSCLC) is the largest subset of lung cancers, which accounts for about 85&amp;#x0025; of all cases. It has been well established that a mutation in the epidermal growth factor receptor (EGFR) can lead to lung cancer. EGFR Tyrosine Kinase Inhibitors (TKIs) are developed to target the kinase domain of EGFR. These TKIs produce promising results at the initial stage of therapy, but the efficacy becomes limited due to the development of drug resistance. In this paper, we provide a comprehensive overview of computational methods, for understanding drug resistance mechanisms. The important EGFR mutants and the different generations of EGFR&amp;#x2013;TKIs, with the survival and response rates are discussed. Next, we evaluate the role of important EGFR parameters in drug resistance mechanism, including structural dynamics, hydrogen bonds, stability, dimerization, binding free energies, and signaling pathways. Personalized drug resistance prediction models, drug response curve, drug synergy, and other data-driven methods are also discussed. Recent advancements in deep learning; such as AlphaFold2, deep generative models, big data analytics, and the applications of statistics and permutation are also highlighted. We explore limitations in the current methodologies, and discuss strategies to overcome them. We believe this review will serve as a reference for researchers; to apply computational techniques for precision medicine, analyzing structures of protein-drug complexes, drug discovery, and understanding the drug response and resistance mechanisms in lung cancer patients.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jan,
pages = {238–255},
numpages = {18}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@article{10.5555/3722479.3722526,
author = {Xie, Jingnan},
title = {Improving Introductory Java Programming Education Through ChatGPT},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The realm of introductory computer science (CS) education is swiftly changing, as educators actively pursue inventive strategies to captivate and empower students. This manuscript introduces a fresh methodology for teaching CS1 or CS2 courses, concentrating specifically on the fundamental principles of Java programming. Harnessing the capabilities of ChatGPT, an AI language model, we delve into how integrating conversational AI into the classroom milieu can foster a more dynamic and tailored learning journey. By furnishing a platform for students to pose inquiries, seek elucidation, and promptly receive feedback, ChatGPT functions as a virtual mentor, complementing conventional teaching methodologies. We scrutinize the potential repercussions of this approach on student learning outcomes (SLOs) and juxtapose it with traditional classroom paradigms. Furthermore, we deliberate on the ramifications of employing AI in education and its contribution to molding the trajectory of introductory programming courses.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {140–150},
numpages = {11}
}

@inproceedings{10.1145/3649409.3691094,
author = {Feng, Ty and Liu, Sa and Ghosal, Dipak},
title = {CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691094},
doi = {10.1145/3649409.3691094},
abstract = {The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {310–311},
numpages = {2},
keywords = {AI tutor, computer science education, intelligent tutoring systems, large language models, pedagogical appropriateness, question answering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626252.3630789,
author = {Liu, Mengqi and M'Hiri, Faten},
title = {Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630789},
doi = {10.1145/3626252.3630789},
abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {743–749},
numpages = {7},
keywords = {adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3699538.3699588,
author = {Pereira Cipriano, Bruno and Silva, Miguel and Correia, Rodrigo and Alves, Pedro},
title = {Towards the Integration of Large Language Models and Automatic Assessment Tools: Enhancing Student Support in Programming Assignments},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699588},
doi = {10.1145/3699538.3699588},
abstract = {The rise of Large Language Models (LLMs) has sparked discussion in Computer Science Education (CSE) due to their ability to generate code from text prompts. Students may rely on these tools, neglecting core skills like computational thinking and program design. Thus, it’s crucial to responsibly integrate them into computer science courses.To address this, we integrated an open-source Automatic Assessment Tool with GPT, enabling students to receive LLM assistance on their programming assignments. This tool can be adopted and improved by educators, promoting more responsible integration of LLMs in CSE.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {52},
numpages = {2},
keywords = {large language models, automatic assessment tools, feedback},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@article{10.5555/3715602.3715614,
author = {Rhee, Junghwan and Shrestha, Aakankshya and Qian, Gang and Zuo, Fei and Fu, Jicheng and Park, Myungah and Qu, Xianshan and Mylavarapu, Goutam and Sung, Hong},
title = {An Evaluation on the Impact of Large Language Models on Computer Science Curricula},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {Since their introduction, large language model (LLM) services have been widely used in our society, including the computer science education area. While this technology provides various types of intelligent assistance to users, its capabilities and impact on computer science education regarding students' learning need further study. In this paper, we present our manual assessment of LLM services' ability to solve questions in various course assignments and projects in our computer science curriculum. Based on the result of the study, we provide our observations of the extent of LLM services' impact on different computer science disciplines. Suggestions are summarized and offered to computer science instructors on the possible strategies for dealing with LLMs in current and future computer science curriculum designs.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {70–80},
numpages = {11}
}

@inproceedings{10.1145/3626252.3630803,
author = {Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv},
title = {ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630803},
doi = {10.1145/3626252.3630803},
abstract = {This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {625–631},
numpages = {7},
keywords = {chatgpt, computer science, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649409.3691090,
author = {Folajimi, Yetunde},
title = {From GPT to BERT: Benchmarking Large Language Models for Automated Quiz Generation},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691090},
doi = {10.1145/3649409.3691090},
abstract = {This study evaluates the effectiveness of four leading large language models (LLMs), GPT-3, GPT-4, GPT-4o, and BERT, in generating quiz questions for Java and Python programming courses. We aim to recognize how LLMs can effectively produce educationally valuable questions that meet specific pedagogical criteria, including technical precision, relevance to course objectives, linguistic clarity, and pedagogical appropriateness. Each model was prompted to generate 200 Java and 200 Python quiz questions, totaling 1600 unique questions. These questions are currently being evaluated based on both quantitative and qualitative assessments by a team of computer science educators. Preliminary findings suggest that GPT-4 outperforms BERT in terms of technical precision. Further analysis is ongoing to assess the performance of the models in generating contextually appropriate and educationally useful questions, offering insights into their potential integration into computer science curricula. This work seeks to contribute to the broader discourse on the utility of LLMs in educational settings, specifically within the scope of automated content creation to enhance teaching and assessment methodologies in computer science education.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {312–313},
numpages = {2},
keywords = {automated assessment, computer science education, formative assessment, large language models, personalized quizzes, quiz questions generation},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626253.3635380,
author = {Veilleux, Nanette and Bates, Rebecca and Goldsmith, Judy and Summet, Valerie},
title = {Mentoring, AI, and the End of Affirmative Action: Connecting with SIGCSE Reads},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635380},
doi = {10.1145/3626253.3635380},
abstract = {This Birds of a Feather will begin with a high-level overview of the SIGCSE Reads 2024 books and then quickly move to discussion about mentoring students in the era of large language models and ChatGPT, including how students may value the curriculum differently, how learning outcomes may change, and how we can support students and alumni/ae as they work with rapidly changing job and learning expectations. We expect that many of the sessions at SIGCSE will address the radical shifts in learning outcomes and curricular changes due to LLMs. We will not focus on the particulars of these changes, but rather on mentoring in this time with Sister Resisters: Mentoring Black Women on Campus by Janie Victoria Ward and Tracy L. Robinson-Wood as a resource. How do we guide our students through the curriculum upheaval triggered by shifting learning outcomes? How do we help them prepare for the new instantiation of computer science?  This BOF is the primary session for SIGCSE Reads. We encourage discussion of this year's fiction works The Lifecycle of Software Objects by Ted Chiang and "Dolly" by Elizabeth Bear, as well as past Reads, throughout the conference.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1922},
numpages = {1},
keywords = {computing education, diversity in computing, mentoring, science fiction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649405.3659473,
author = {Cipriano, Bruno Pereira},
title = {Towards the Integration of Large Language Models in an Object-Oriented Programming Course},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659473},
doi = {10.1145/3649405.3659473},
abstract = {The advent of Large Language Models (LLMs) has created multiple challenges for the Computer Science Education Community. This research project aims at integrating LLMs into Object-Oriented Programming courses, by generating and evaluating new teaching methodologies and tools suitable for this paradigm's specificities.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {832–833},
numpages = {2},
keywords = {bard, gpt-3.5, gpt-4, large language models, object-oriented programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635408,
author = {Xiang, Lili},
title = {SQL Query Evaluation with Large Language Model and Abstract Syntax Trees},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635408},
doi = {10.1145/3626253.3635408},
abstract = {SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from "good" to "unacceptable". The experimental results demonstrate that we can enhance the grading efficiency by applying these approaches and illustrate the ability of utilizing LLM to classify the assessed SQL statements more accurately. In addition, this research contributes to Computer Science (CS) education by integrating these approaches into our team's automated SQL statement assessment tool, improving the learning experience and evaluation process.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1890},
numpages = {1},
keywords = {abstract syntax trees, auto-grader, cs education, large language model, sql},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3688089,
author = {Zhou, Kyrie Zhixuan and Kilhoffer, Zachary and Sanfilippo, Madelyn Rose and Underwood, Ted and Gumusel, Ece and Wei, Mengyi and Choudhry, Abhinav and Xiong, Jinjun},
title = {Ethics, Governance, and User Mental Models for Large Language Models in Computing Education},
year = {2024},
issue_date = {Fall 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1528-4972},
url = {https://doi.org/10.1145/3688089},
doi = {10.1145/3688089},
abstract = {Large language models like ChatGPT are disrupting many industries, including computing education. How should policy evolve to improve learning outcomes?},
journal = {XRDS},
month = oct,
pages = {46–51},
numpages = {6}
}

@article{10.5555/3715602.3715619,
author = {Hong, Alexander and Hong, Gongbing},
title = {The Effectiveness of Coding LLMs and the Challenges in Teaching CS1/2: A Case Study},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {This paper presents a case study that evaluates the effectiveness of coding Large Language Models (LLMs) in introductory computer science courses at the university level. The study assesses six different AI-powered code generators. The evaluation focuses on the accuracy of these AI code generators in solving ten programming problems from a set of problems that instructors at Duke University can assign to students for weekly completion. The results demonstrate the effectiveness of coding LLMs in solving these problems.Based on the findings, the paper discusses the challenges faced by the computer science education community and potential strategies to address them. The advent of coding LLMs poses significant challenges to traditional teaching and learning methods in computer science. These challenges include the need for strategies to mitigate any negative impact of LLMs on the learning process. At the same time, these code LLMs also offer tremendous opportunities for enhancing teaching and learning.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {122–131},
numpages = {10}
}

@inproceedings{10.1145/3636243.3636257,
author = {Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv},
title = {“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636257},
doi = {10.1145/3636243.3636257},
abstract = {Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, User Study},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3657604.3664660,
author = {Nguyen, Ha and Stott, Nate and Allan, Vicki},
title = {Comparing Feedback from Large Language Models and Instructors: Teaching Computer Science at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664660},
doi = {10.1145/3657604.3664660},
abstract = {Large language models (LLMs) can provide formative feedback in programming to help students improve the code they have written. We investigate the use of LLMs (GPT-4) to provide formative code feedback in a sophomore-level computer science (CS) course on data structures and algorithms. In three quizzes on recursion, half of the students randomly received GPT-4's feedback, while the other half received feedback from the course instructor. Students resubmitted their code based on the provided feedback. We found that students in the LLM-feedback condition scored higher in resubmissions than those receiving feedback from the instructor. Students perceived the two types of feedback as equally supportive of guiding resubmissions. We discuss the implications of using LLMs to provide formative feedback at scale in CS instruction.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {335–339},
numpages = {5},
keywords = {computer science education, feedback, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3699538.3699581,
author = {Vassar, Alexandra and Renzella, Jake and Ross, Emily and Taylor, Andrew},
title = {Fine-Tuning Large Language Models for Better Programming Error Explanations},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699581},
doi = {10.1145/3699538.3699581},
abstract = {This paper investigates supervised fine-tuning of large language models (LLMs) to improve their pedagogical alignment in computing education, addressing concerns that LLMs may hinder learning outcomes. The project utilised a proprietary dataset of 2,500 high quality question/answer pairs from programming course forums, and explores two research questions: the suitability of university course forums in contributing to fine-tuning datasets, and how supervised fine-tuning can improve LLMs’ alignment with educational principles such as constructivism. Initial findings suggest benefits in pedagogical alignment of LLMs, with deeper evaluations required.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {26},
numpages = {2},
keywords = {Programming Error Messages, CS1, AI in CS1, AI in Education, Generative AI, LLM},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649405.3659504,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen},
title = {Analyzing Students' Preferences for LLM-Generated Analogies},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659504},
doi = {10.1145/3649405.3659504},
abstract = {Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {812},
numpages = {1},
keywords = {analogies, computer science education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3636555.3636882,
author = {Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga},
title = {Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636882},
doi = {10.1145/3636555.3636882},
abstract = {AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {821–827},
numpages = {7},
keywords = {Academic Integrity, Automated Grading, ChatGPT, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.5555/3722479.3722507,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Vautor-Laplaceliere, Daena D. and Noory, Naqib A.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Data Science Programs in Higher Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The integration of GenAI (GenAI), such as large language models (LLMs), in education has raised the question of how it will alter the students' training and learning outcomes. To better understand the phenomenon, this empirical study explores whether college students find GenAI tools helpful in advancing their skills, particularly Python programming proficiency.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {63–64},
numpages = {2}
}

@article{10.5555/3722479.3722506,
author = {Liao, Weidong and Guzide, Osman},
title = {Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {62},
numpages = {1}
}

@inproceedings{10.1145/3626252.3630960,
author = {Nguyen, Ha and Allan, Vicki},
title = {Using GPT-4 to Provide Tiered, Formative Code Feedback},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630960},
doi = {10.1145/3626252.3630960},
abstract = {Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {958–964},
numpages = {7},
keywords = {computer science education, feedback, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649409.3691086,
author = {Velez, Xavier},
title = {Understanding Algorithmic Problem Solving using LLMs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691086},
doi = {10.1145/3649409.3691086},
abstract = {With the rapid advancement of Large Language Models (LLMs) many instructors for Computer Science courses have begun to opt to allow students to use them as an additional educational resource but often warn that the output may be unreliable. Recent research on LLMs has demonstrated their ability to interpret commands in natural language and produce code in a variety of programming languages. However, it is not clear how well LLMs fair in tackling more complex problem set ups, like those typically seen in Algorithms courses in which students are provided natural language descriptions of an ambiguous problem and use what they learn to map the problem to an algorithmic solution. In this paper, we explore use of LLMs, such as OpenAI's GPT-4o, as tools for assisting students with complex Computer Science curricula, such as algorithmic problem solving. We specifically aim to see if using prompt refinement techniques, LLMs are capable of taking a problem statement in plain English and performing the following tasks: providing both a natural language description and code solution in the Python programming language, producing an analytical argument for the solutions correctness, and finally providing runtime analysis for the produced solution. Our experiments show that GPT-4o is well suited to solving problems like LeetCode 75 that have been seen during training, and prompt-refinement helps with those that have not been seen.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {327–328},
numpages = {2},
keywords = {GPT-4o, algorithms, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3657604.3664663,
author = {Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris},
title = {DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664663},
doi = {10.1145/3657604.3664663},
abstract = {Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {351–355},
numpages = {5},
keywords = {computer science education, generative ai, software development life cycle, software engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3687038,
author = {Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael},
title = {Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687038},
doi = {10.1145/3687038},
abstract = {Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role that teachers can play in shaping LLM-supported learning environments.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {499},
numpages = {30},
keywords = {artificial intelligence in education, collaborative learning with ai, human-ai collaboration, large language models, transparency, tutoring systems}
}

@article{10.5555/3665464.3665480,
author = {Manley, Eric D.},
title = {Getting Started with Large Language Models for the CS Curriculum},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {With the introduction of ChatGPT in late 2022, popular interest in language-based Artificial Intelligence has exploded. Employers are looking to hire computer scientists who can leverage large language models (LLMs) [2], and student demand for learning about them at many higher education institutions has followed. This one-hour workshop will help computer science educators respond to this demand by introducing the Python transformers library and its associated LLM ecosystem [1]. We will discuss how LLMs can be integrated into college computer science curricula from CS 1 through advanced courses in Artificial Intelligence, Machine Learning, or Natural Language Processing. Specific topics include• Using the transformers library with pre-trained models for inference tasks like sentiment analysis, text classification, summarization, translation, and question answering in only a few lines of code• Searching for and using hundreds of thousands of different pre-trained language models hosted by Hugging Face along with datasets that they can be tested on• Utilizing conversational models to build chat bots},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {116–117},
numpages = {2}
}

@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@inproceedings{10.1145/3657604.3662042,
author = {Kumar, Harsh and Xiao, Ruiwei and Lawson, Benjamin and Musabirov, Ilya and Shi, Jiakai and Wang, Xinyuan and Luo, Huayin and Williams, Joseph Jay and Rafferty, Anna N. and Stamper, John and Liut, Michael},
title = {Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662042},
doi = {10.1145/3657604.3662042},
abstract = {Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {86–97},
numpages = {12},
keywords = {field experiments, human-ai collaboration, large language models, learning engineering, self-reflection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3643916.3644435,
author = {Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
title = {Reassessing Java Code Readability Models with a Human-Centered Approach},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644435},
doi = {10.1145/3643916.3644435},
abstract = {To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers' notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers' evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it's often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {225–235},
numpages = {11},
keywords = {code readability, code readability models, repertory grid technique, AI-generated code, human-computer interaction},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3626253.3635511,
author = {Bhalerao, Rasika},
title = {My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635511},
doi = {10.1145/3626253.3635511},
abstract = {Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code "better" rather than cheat. These results are intended to be a starting point to spark discussion on the adoption of new technologies in introductory computer science courses. The authors themselves will continue teaching courses with the policy that students should interact with an LLM the way they interact with a person: students are encouraged to discuss and collaborate with it, but copying code from it is considered plagiarism.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1574–1575},
numpages = {2},
keywords = {AI, assignments, plagiarism, students},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635592,
author = {Niousha, Rose and Hoq, Muntasir and Akram, Bita and Norouzi, Narges},
title = {Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635592},
doi = {10.1145/3626253.3635592},
abstract = {This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1762–1763},
numpages = {2},
keywords = {cs1, curriculum design, knowledge component},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3632621.3671429,
author = {Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia},
title = {Using a Low-Code Environment to Teach Programming in the Era of LLMs},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671429},
doi = {10.1145/3632621.3671429},
abstract = {LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {542–543},
numpages = {2},
keywords = {Generative AI, LLMs, MOOC, Programming Education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@article{10.1145/3710795.3710797,
author = {Tran, Nicholas},
title = {The Book Review Column},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0163-5700},
url = {https://doi.org/10.1145/3710795.3710797},
doi = {10.1145/3710795.3710797},
abstract = {Foundation Mathematics for Computer Science: A Visual Approach, 4th edition (Springer, 2023) by John Vince (Bournemouth University, UK) is a comprehensive collection of discrete and continuous mathematical topics that are covered in most undergraduate programs in computer science. The subtitle refers to the author's use of colored graphs and tables to illustrate the concepts.Online Algorithms (Cambridge University Press, 2023) by Rahul Vaze (Tata Institute of Fundamental Research, India) is an accessible but rigorous introduction to the area aimed at advanced undergraduates and beginning graduate students. The book covers the basic as well as applied online problems with a preference of elegant analysis over performance.Privacy-preserving Computing for Big Data Analytics and AI (Cambridge University Press, 2023) by Kai Chen and Qiang Yang (Hong Kong University of Science and Technology) is a systematic examination of the history, theories, techniques, applications, and future of the field.Prize-winning neuroscientist Terrence Sejnowski (University of California at San Diego) explains the technology and mathematics behind large language models such as ChatGPT and explores the debate on their so-called comprehension of language in ChatGPT and the Future of AI: The Deep Language Revolution (The MIT Press, 2024).},
journal = {SIGACT News},
month = dec,
pages = {3–20},
numpages = {18}
}

@inproceedings{10.1145/3686852.3686864,
author = {Dakshit, Sagnik},
title = {Faculty Perspectives on the Potential of RAG in Computer Science Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686864},
doi = {10.1145/3686852.3686864},
abstract = {The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in computer science higher education. We developed Retrieval Augmented Generation (RAG) applications for the two tasks of virtual teaching assistants and teaching aids. In our study, we collected the ratings and opinions of faculty members in undergraduate and graduate computer science university courses at various levels, using our personalized RAG systems for each course. This study is the first to gather faculty feedback on the application of LLM-based RAG in education. The investigation revealed that while faculty members acknowledge the potential of RAG systems as virtual teaching assistants and teaching aids, certain barriers and features are suggested for their full-scale deployment. These findings contribute to the ongoing discussion on the integration of advanced language models in educational settings, highlighting the need for careful consideration of ethical implications and the development of appropriate safeguards to ensure responsible and effective implementation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {19–24},
numpages = {6},
keywords = {Education, Large Language Models, Learning, Neural Networks, Retrieval Augmented Generation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3690931.3690982,
author = {Zhang, Ye and Nie, Yiming},
title = {InternDrive: A Multimodal Large Language Model for Autonomous Driving Scenario Understanding},
year = {2024},
isbn = {9798400710049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690931.3690982},
doi = {10.1145/3690931.3690982},
abstract = {With the rapid development of autonomous driving technology, accurately understanding complex driving scenarios has become a critical challenge. Existing computer vision-based solutions exhibit limitations when dealing with dynamic driving environments. Therefore, this paper proposes a method for understanding autonomous driving scenarios using multimodal large language models. Firstly, we designed a set of questions to guide multimodal large language models in comprehensively understanding driving scenarios, and based on this, we constructed a multimodal driving scenario dataset. This dataset combines open-source nuScenes image data with natural language annotations automatically generated and manually reviewed via the OpenAI API. Subsequently, we conducted visual instruction tuning on the open-source multimodal large language model InternVL-1.5 and proposed the InternDrive model. Furthermore, this paper introduces an evaluation method based on a proprietary large model and conducts a comprehensive assessment of InternDrive's ability to understand driving scenarios. Experimental results demonstrate that InternDrive exhibits superior accuracy in multiple driving scenario understanding tasks. Our research provides new methods and perspectives for enhancing the scene understanding capabilities of autonomous driving systems and showcases the potential application of multimodal large language models in the field of autonomous driving.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Automation and High Performance Computing},
pages = {294–305},
numpages = {12},
location = {Zhuhai, China},
series = {AIAHPC '24}
}

@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636256,
author = {Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd},
title = {A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636256},
doi = {10.1145/3636243.3636256},
abstract = {There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {114–123},
numpages = {10},
keywords = {Assessments, Automated Content Generation, Automatic Generation, GPT-4, LLMs, LOs, Large Language Models, Learning Objectives, MCQs, Multiple-choice Questions},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3643795.3648389,
author = {Dingle, Adam and Krulis, Martin},
title = {Tackling Students' Coding Assignments with LLMs},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648389},
doi = {10.1145/3643795.3648389},
abstract = {State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {94–101},
numpages = {8},
keywords = {LLM, large language model, coding, programming, student assignment, teaching},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3632620.3671097,
author = {Ali, Murtaza and Rao, Prerna and Mai, Yifan and Xie, Benjamin},
title = {Using Benchmarking Infrastructure to Evaluate LLM Performance on CS Concept Inventories: Challenges, Opportunities, and Critiques},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671097},
doi = {10.1145/3632620.3671097},
abstract = {BACKGROUND AND CONTEXT. The pace of advancement of large language models (LLMs) motivates the use of existing infrastructure to automate the evaluation of LLM performance on computing education tasks. Concept inventories are well suited for evaluation because of their careful design and prior validity evidence. OBJECTIVES. Our research explores the feasibility of using an automated benchmarking framework to evaluate computer science (CS) concept inventories. We explore three primary objectives: evaluation of LLM performance on the SCS1 and BDSI concept inventories; informal expert panel review of items which had variations between LLM and expected student performance; and description of challenges with using benchmarking infrastructure as a methodological innovation. METHOD. We used the Holistic Evaluation of Language Models (HELM) framework to evaluate the SCS1 and BDSI against 10 LLMS with zero-shot and few-shot in-context learning: GPT (3.5, 4.0), Claude (1.3, 2.0, 2.1), Llama (7B, 13B, 70B), Mistral v0.1 7B, and Mixtral 8x7B. We used psychometric data from prior studies to measure knowledge levels for each LLM run. We then conducted an informal expert review to qualitatively explore how question design, CS content knowledge, and LLM design may explain differences between LLM and expected student performances. FINDINGS. Our quantitative analysis found that most LLM response patterns reflected a below average introductory computing student with the SCS1 and did not fit the psychometric 2PL model for the BDSI. Our qualitative analysis identified that LLMs performed well on code infill questions, but poorly on nested conditionals, runtime analysis, and longer questions. We also identified several methodological challenges related to item security, translation, the structure when using HELM. IMPLICATIONS. We consider the feasibility of using automated benchmarking as a methodology to support more reproducible, replicable, and rigorous investigations to understand the intersection of LLM capabilities, computing concepts, and assessment design. We also consider connections between psychometric approaches and LLM evaluations to inform the design of computing assessments that are more resilient to LLM advancements.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {452–468},
numpages = {17},
keywords = {benchmarking, computing education, concept inventories, large language models, psychometrics},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3680533.3697064,
author = {Feng, Tony Haoran and Denny, Paul and W\"{u}nsche, Burkhard C. and Luxton-Reilly, Andrew and Whalley, Jacqueline},
title = {An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697064},
doi = {10.1145/3680533.3697064},
abstract = {CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {5},
numpages = {8},
keywords = {Large Language Models, LLMs, Large Multimodal Models, LMMs, Visual Language Models, VLMs, Generative Artificial Intelligence, GenAI, GPT-4, GPT-4o, Visual Perception, Geometric Reasoning, Computer Graphics, Computing Education, Evaluation, Assessment},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3626203.3670577,
author = {Nadel, Peter and Maloney, Delilah and Monahan, Kyle},
title = {Enabling access to large-language models (LLMs) at scale for higher education},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670577},
doi = {10.1145/3626203.3670577},
abstract = {The use of language models, particularly large-language models (LLMs), have been increasingly popular and can be transformative in higher education, by both enabling novel research approaches and providing instructional opportunities for skills needed in data science and engineering. However, running these LLMs traditionally requires access to advanced hardware resources and technical knowledge. To better provide a platform for experimenting with LLMs for users of all skill levels, we developed the Tufts Technology Services (TTS) LLM-Hub, a series of example Jupyter notebooks served through Tufts Open OnDemand (OOD) to setup, configure, and run LLMs automatically. The TTS LLM-Hub enabled quick access to running LLMs, while reducing barriers to compute and enabling users to chat with an LLM in just four clicks. We have used these platforms for support of advanced data science courses, and to enable research computing at Tufts.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {49},
numpages = {4},
keywords = {High-Performance Computing (HPC), Large-Language Models (LLMs), Open OnDemand (OOD)},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3649165.3690101,
author = {Hellas, Arto and Leinonen, Juho and Lepp\"{a}nen, Leo},
title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690101},
doi = {10.1145/3649165.3690101},
abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {46–52},
numpages = {7},
keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3657604.3662040,
author = {Gabbay, Hagit and Cohen, Anat},
title = {Combining LLM-Generated and Test-Based Feedback in a MOOC for Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662040},
doi = {10.1145/3657604.3662040},
abstract = {In large-scale programming courses, providing learners with immediate and effective feedback is a significant challenge. This study explores the potential of Large Language Models (LLMs) to generate feedback on code assignments and to address the gaps in Automated Test-based Feedback (ATF) tools commonly employed in programming courses. We applied dedicated metrics in a Massive Open Online Course (MOOC) on programming to assess the correctness of feedback generated by two models, GPT-3.5-turbo and GPT-4, using a reliable ATF as a benchmark. The findings point to effective error detection, yet the feedback is often inaccurate, with GPT-4 outperforming GPT-3.5-turbo. We used insights gained from the prompt practices to develop Gipy, an application for submitting course assignments and obtaining LLM-generated feedback. Learners participating in a field experiment perceived the feedback provided by Gipy as moderately valuable, while at the same time recognizing its potential to complement ATF. Given the learners' critique and their awareness of the limitations of LLM-generated feedback, the studied implementation may be able to take advantage of the best of both ATF and LLMs as feedback resources. Further research is needed to assess the impact of LLM-generated feedback on learning outcomes and explore the capabilities of more advanced models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {177–187},
numpages = {11},
keywords = {MOOC for programming, automated feedback, generative AI, large language models (LLMs), programming education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626252.3630937,
author = {Grover, Shuchi},
title = {Teaching AI to K-12 Learners: Lessons, Issues, and Guidance},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630937},
doi = {10.1145/3626252.3630937},
abstract = {There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12 "big ideas" framework and employ a plurality of pedagogies.This paper provides a sense for the current state of the field, shares lessons learned from early K-12 AI education as well as CS education efforts that can be leveraged, highlights issues that must be addressed in designing for teaching AI in K-12, and provides guidance for future K-12 AI education efforts and tackle what to many feels like "the next new thing".},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {422–428},
numpages = {7},
keywords = {artificial intelligence, k-12 ai education, k-12 cs education, machine learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3639478.3639787,
author = {Katzy, Jonathan},
title = {Programming Language Models in Multilingual Settings},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639787},
doi = {10.1145/3639478.3639787},
abstract = {Large language models have become increasingly utilized in programming contexts. However, due to the recent emergence of this trend, some aspects have been overlooked. We propose a research approach that investigates the inner mechanics of transformer networks, on a neuron, layer, and output representation level, to understand whether there is a theoretical limitation that prevents large language models from performing optimally in a multilingual setting. We propose to approach the investigation into the theoretical limitations, by addressing open problems in machine learning for the software engineering community. This will contribute to a greater understanding of large language models for programming-related tasks, making the findings more approachable to practitioners, and simply their implementation in future models.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {204–206},
numpages = {3},
keywords = {large language models, explainable AI, software engineering, code completion, multilingual, programming languages},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3658644.3670392,
author = {Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo},
title = {On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670392},
doi = {10.1145/3658644.3670392},
abstract = {With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2236–2250},
numpages = {15},
keywords = {aigc detection, large language models, responsible ai},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3656650.3656747,
author = {Gargioni, Luigi},
title = {Emerging approaches to human-robot collaboration in healthcare},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656747},
doi = {10.1145/3656650.3656747},
abstract = {Collaborative robots can enhance productivity and efficiency in healthcare. This PhD project aims to investigate new methods and tools for effective interaction with these robots, focusing on programming techniques accessible to domain experts without a background in computer science or robotics. Automating repetitive tasks can allow healthcare professionals to dedicate more attention to critical procedures. For instance, this technology can enhance therapy efficiency and personalized medicine preparation, benefiting patient outcomes. The research will investigate the use of Large Language Models to simplify and optimize robot task programming, reducing the need for technical expertise.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {110},
numpages = {3},
keywords = {Collaborative Robots, End-User Development, Human-Robot Collaboration, Large Language Models},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create "black box" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3664673,
author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
title = {Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664673},
doi = {10.1145/3657604.3664673},
abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {255–258},
numpages = {4},
keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3632620.3671103,
author = {Logacheva, Evanfiya and Hellas, Arto and Prather, James and Sarsa, Sami and Leinonen, Juho},
title = {Evaluating Contextually Personalized Programming Exercises Created with Generative AI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671103},
doi = {10.1145/3632620.3671103},
abstract = {Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students’ interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners’ situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students’ interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {95–113},
numpages = {19},
keywords = {automatic exercise generation, context personalization, generative AI, large language models},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3639478.3639815,
author = {Velasco, Alejandro},
title = {Beyond Accuracy: Evaluating Source Code Capabilities in Large Language Models for Software Engineering},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3639815},
doi = {10.1145/3639478.3639815},
abstract = {This dissertation aims to introduce interpretability techniques to comprehensively evaluate the performance of Large Language Models (LLMs) in software engineering tasks, beyond canonical metrics. In software engineering, Deep Learning techniques are widely employed across various domains, automating tasks such as code comprehension, bug fixing, code summarization, machine translation, and code generation. However, the prevalent use of accuracy-based metrics for evaluating Language Models trained on code often leads to an overestimation of their performance. Our work seeks to propose novel and comprehensive interpretability techniques to evaluate source code capabilities and provide a more nuanced understanding of LLMs performance across downstream tasks.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {162–164},
numpages = {3},
keywords = {large language models, interpretability, DL4SE, category theory, causal inference},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3661167.3661270,
author = {Di Penta, Massimiliano},
title = {Why Large Language Models will (not) Kill Software Engineering Research},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661270},
doi = {10.1145/3661167.3661270},
abstract = {Over the last decade, we have witnessed a flourishing activity in the application of deep learning techniques to solve software engineering problems that were poorly addressed in the past, or not addressed at all. In this context, researchers put effort into creating specialized representations and models, hence giving a tangible, conceptual contribution beyond the simple application. With the advent of Large Language Models, such contributions were surpassed, and this was possible because big techs had the availability of data and infrastructure. As such models are pretty good at solving many software engineering problems, where would research in software engineering, and, specifically, in recommender systems go? Will artificial intelligence research kill it? Fortunately, we should not forget that software engineering is about people, and this is where I believe there will be a lot of room for novel research. Software engineering researchers have the knowledge to understand how LLMs fit (or do not fit) in a development context, by properly pondering, for example, human, ethical, and legal factors. Also, software engineering researchers have a strong empirical background to evaluate the effectiveness of such models where state-of-the-art measurements might not suffice.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {5},
numpages = {1},
keywords = {Empirical Assessment, Large Language Models, Software Engineering},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3689491.3700408,
author = {Gabriel, Richard P.},
title = {AI: Winter of Our Discontent (Keynote)},
year = {2024},
isbn = {9798400712142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689491.3700408},
doi = {10.1145/3689491.3700408},
abstract = {In his keynote address on AI Winter, Richard P. Gabriel delves into the recurring cycles of high expectations and subsequent disappointments in the field of artificial intelligence. He posits that AI, unlike other computer science problems, has goals that are easily understood yet inherently vague, akin to the subjective nature of success in artistic endeavors such as painting, writing, and music. Gabriel critiques the limitations of large language models (LLMs), noting that they lack the human ability to handle novel situations and discover new information, being constrained to knowledge acquired during training. He suggests that the comprehensive training of LLMs across all perspectives prevents them from developing a unique point of view, which could be detrimental to their creative capabilities. Gabriel provocatively speculates that a more limited, less knowledgeable LLM might better emulate human writers, learning to forget and thereby fostering a more genuine form of creativity.},
booktitle = {Companion Proceedings of the 2024 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
pages = {2},
numpages = {1},
location = {Pasadena, CA, USA},
series = {SPLASH Companion '24}
}

@inproceedings{10.1145/3674399.3674423,
author = {Xu, Ke and Yi, Hanxiao and Xu, Zichen and Wu, Dan},
title = {Data-driven Contribution-based Disciplinary Assessment System},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674423},
doi = {10.1145/3674399.3674423},
abstract = {A scientific disciplinary assessment system is crucial for nurturing high-quality disciplines within Computer Science. Computer Science Education (CSE) emphasizes the need for a scientific and comprehensive assessment method that guides the development of the discipline, with a particular focus on practical contributions. However, traditional assessment systems tend to prioritize the theoretical outcomes. Moreover, data expansion demands significant effort and time from educational professionals, making it challenging to conduct a thorough evaluation of the disciplines. To tackle these issues, we introduce a data-driven, contribution-based disciplinary assessment system. This system takes into account both theoretical and practical contributions to provide a holistic evaluation. Our proposed system employs a contribution-based assessment approach to establish a correct evaluative direction, steering discipline construction to align with societal needs. It also incorporates intelligent algorithms and a Large Language Model (LLM), leveraging their substantial computational power in the evaluation process. This integration alleviates the workload of educational professionals by automating the collection and analysis of information. The paper outlines a detailed implementation plan that integrates contribution evaluation theory with intelligent technologies, aiming to foster the ongoing advancement of CSE education.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {42–47},
numpages = {6},
keywords = {Big Data-driven, Contribution-Based Evaluation Method, Disciplinary assessment},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3639474.3640084,
author = {Sa\u{g}lam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
title = {Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640084},
doi = {10.1145/3639474.3640084},
abstract = {Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {297–308},
numpages = {12},
keywords = {plagiarism detection, obfuscation, ChatGPT, artificial intelligence},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3701625.3701687,
author = {Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa},
title = {Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701687},
doi = {10.1145/3701625.3701687},
abstract = {Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {624–634},
numpages = {11},
keywords = {Requirement Elicitation, ChatGPT 3.5, Software engineering education},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3660650.3660668,
author = {Rajabi, Parsa},
title = {Experience Report: Adopting AI-Usage Policy in Software Engineering Education},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660668},
doi = {10.1145/3660650.3660668},
abstract = {This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an "AI-usage disclosure" form for coursework submissions. This approach sought to improve AI literacy, ensure academic integrity, and mitigate potential academic misconduct cases. Despite challenges, including adherence to AI disclosures and the evolving definition of AI tools, the policy promoted a more inclusive learning environment and encouraged a deeper understanding of AI’s role and limitations in computer science education. The findings highlight the need for ongoing policy revisions to adapt to technological advancements, emphasizing the pilot as an essential step towards integrating AI responsibly in educational contexts.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {19},
numpages = {2},
keywords = {AI in Education, AI-usage Policy, Academic Integrity, ChatGPT, Software Engineering Education},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3626253.3635403,
author = {Li, Yi and Zhang, Riteng and Qu, Danni and Marques Samary, Ma\'{\i}ra},
title = {Mining Students' Mastery Levels from CS Placement Tests via LLMs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635403},
doi = {10.1145/3626253.3635403},
abstract = {In higher education, introductory Computer Science (CS) programs offer a range of foundational courses. These encompass not only the standard CS1 and CS2 courses but may also include more specialized options like CS0 and CS1.5. In order to appropriately assign students to the suitable introductory courses, many institutions utilize placement tests, which assess students' pre-existing knowledge and skills. While most institutions rely on accuracy alone to make these determinations, there is often additional information concealed within the completed tests. This paper delves into the potential of Large Language Models (LLMs) to uncover this hidden information, particularly in gaining insights into how students perform in different concepts. Moreover, our framework has the flexibility to accommodate variations in curricula across different institutions, providing additional analytical perspectives. Initially, we built a concept inventory (CI) using the concepts covered in an institution's CS0, CS1, and CS2 curricula. Next, an LLM, specifically GPT 3.5, was applied to associate each question in the placement test with one or more concepts in the CI. Finally, the results of the placement tests were scrutinized, allowing the calculation of mastery levels in each concept for individual students. These mastery levels enable institutions to gauge a student's prior knowledge across various concepts simply by using a CS placement test. Additionally, we presented a case study demonstrating the application of this framework to 267 existing placement test results at Boston College.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1883},
numpages = {1},
keywords = {concept inventory, introductory computer science courses, large language models, placement test},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635356,
author = {AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
title = {How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635356},
doi = {10.1145/3626253.3635356},
abstract = {Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1930},
numpages = {1},
keywords = {computing, education, large language models, quality},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3700297.3700326,
author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
title = {A Study of the AIGC-Enabled BOPPPS Smart Teaching Model},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700326},
doi = {10.1145/3700297.3700326},
abstract = {Smart teaching refers to the in-depth use of modern information technology to promote the process of education, which is characterized by using digital, network, intelligent and multimedia technologies. BOPPPS teaching model is a new type of student-centered teaching model. This teaching model is widely used around the world. The traditional BOPPPS teaching model makes it difficult to implement personalized teaching in the classroom. The new development of artificial intelligence technology provides new method for smart teaching, especially the AIGC Large Language Model represented by ChatGPT. This paper introduces AIGC technology into personalized teaching, and study the application of AIGC in various aspects of BOPPPS teaching model, by taking the design of smart teaching course of video surveillance as an example. In particular, AIGC is utilized for Pre-assessment. It is proposed to use an agent as a mediator between students and the AIGC large language model to test the students individually, and to design personalized test contents for personalized feedback. Comparatively better results were obtained in the actual teaching process, which can provide a reference for other smart teaching researchers.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {166–170},
numpages = {5},
keywords = {Artificial Intelligence, BOPPPS, Large Language Model, Personalized Teaching, Smart Teaching},
location = {
},
series = {ISAIE '24}
}

@article{10.1145/3674149,
author = {Mendon\c{c}a, Nabor C.},
title = {Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
url = {https://doi.org/10.1145/3674149},
doi = {10.1145/3674149},
abstract = {The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .},
journal = {ACM Trans. Comput. Educ.},
month = aug,
articleno = {37},
numpages = {56},
keywords = {Multimodal generative AI, ChatGPT-4 vision, educational assessment, computer science education}
}

@inproceedings{10.1145/3639474.3640076,
author = {Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
title = {Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640076},
doi = {10.1145/3639474.3640076},
abstract = {Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey.With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {331–341},
numpages = {11},
keywords = {CS education, CS1, generative AI, ChatGPT, OOP},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3643795.3648393,
author = {Chusap, Krerkkiat and Liu, Chang},
title = {Gauging Tech Community Acceptance of Rapid Prototyping in Unfamiliar Programming Languages using LLM Chatbots},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648393},
doi = {10.1145/3643795.3648393},
abstract = {Large Language Model (LLM) chatbots such as ChatGPT possess information not only about human languages but also computer languages. It is now possible to perform programming and software design tasks with assistance from ChatGPT. We are particularly interested in how the software development community views the use of LLM chatbots in rapid prototyping using unfamiliar programming languages. In four different tech events, several example scenarios of how a tech-savvy engineer could use ChatGPT to prototype apps in unfamiliar programming languages were demonstrated, including a health education app. The four events include an IEEE chapter workshop, an IEEE WIE (Woman In Engineering) meeting, an IEEE joint chapter talk, and a university-level Computer Science class. The responses from the tech audience showed that the majority perceived value in the use of LLM chatbots in these contexts, even though there were subtle differences among different groups. This shows the need for further research on how to effectively incorporate LLM chatbots into traditional software design workflow to better serve the software development community.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {8–13},
numpages = {6},
keywords = {software engineering, software design, rapid prototyping, LLMs, ChatGPT},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3626252.3630842,
author = {Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin},
title = {Trust in Generative AI among Students: An exploratory study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630842},
doi = {10.1145/3626252.3630842},
abstract = {Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {generative ai, novice programmers, trust},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3650400.3650526,
author = {Li, Wenqing and Qi, Xiaoman and Zhao, Qi and Wang, Chen and Wu, Qiongyu and Tang, Xue-song},
title = {Knowledge Graph-Based Credibility Evaluation Method for Electric Grid Large Language Model Knowledge Question-Answering},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650526},
doi = {10.1145/3650400.3650526},
abstract = {In the field of electricity, specialized terminology is often intricate and complex, making it challenging for non-experts to comprehend. However, with the advancement of artificial intelligence technology, the emergence of large language models provides a new technological solution to address this issue. Large language models, based on deep learning techniques, have the capability to quickly understand and interpret specialized terminology in the electricity domain through learning from a vast corpus of professional literature and data. They can then be applied to various domains, including question-answering systems. However, existing large language models still face issues of unreliable outputs, necessitating a method to evaluate their results and improve the quality of their applications. We propose a knowledge graph-based credibility evaluation method for electric grid large language model knowledge question-answering. This method aligns the answers generated by large language models with the knowledge graph of a local knowledge base and calculates their cosine similarity and Pearson correlation coefficient. We batch-process the answers from the large language model into an electricity dataset and validate them using this method. Experimental results demonstrate that this method can accurately and efficiently reflect the relevance between texts, providing a reliable scoring basis for question-answering by large models in vertical domains. Future research can focus on exploring other embedding methods that can better extract semantic relationships between texts and validating the feasibility of this method in vertical domains other than electricity.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {754–759},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3650212.3652115,
author = {Zeng, Zhengran and Wang, Yidong and Xie, Rui and Ye, Wei and Zhang, Shikun},
title = {CoderUJB: An Executable and Unified Java Benchmark for Practical Programming Scenarios},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652115},
doi = {10.1145/3650212.3652115},
abstract = {In the evolving landscape of large language models (LLMs) tailored for software engineering, the need for benchmarks that accurately reflect real-world development scenarios is paramount. Current benchmarks are either too simplistic or fail to capture the multi-tasking nature of software development. To address this, we introduce CoderUJB, a new benchmark designed to evaluate LLMs across diverse Java programming tasks that are executable and reflective of actual development scenarios, acknowledging Java's prevalence in real-world software production. CoderUJB comprises 2,239 programming questions derived from 17 real open-source Java projects and spans five practical programming tasks. Our empirical study on this benchmark investigates the coding abilities of various open-source and closed-source LLMs, examining the effects of continued pre-training in specific programming languages code and instruction fine-tuning on their performance. The findings indicate that while LLMs exhibit strong potential, challenges remain, particularly in non-functional code generation (e.g., test generation and defect detection). Importantly, our results advise caution in the specific programming languages continued pre-training and instruction fine-tuning, as these techniques could hinder model performance on certain tasks, suggesting the need for more nuanced strategies. CoderUJB thus marks a significant step towards more realistic evaluations of programming capabilities in LLMs, and our study provides valuable insights for the future development of these models in software engineering.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {124–136},
numpages = {13},
keywords = {Benchmark, Code Generation, Large Language Models},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3657604.3662039,
author = {Smith, David H. and Denny, Paul and Fowler, Max},
title = {Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662039},
doi = {10.1145/3657604.3662039},
abstract = {Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {39–50},
numpages = {12},
keywords = {CS1, EIPE, LLMs, code comprehension, explain in plain English, introductory programming, large language models, prompting},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3649217.3653582,
author = {Smith, David H. and Zilles, Craig},
title = {Code Generation Based Grading: Evaluating an Auto-grading Mechanism for "Explain-in-Plain-English" Questions},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653582},
doi = {10.1145/3649217.3653582},
abstract = {Comprehending and conveying the purpose of code is often cited as being a key learning objective within introductory programming courses. To address this objective, "Explain in Plain English'' questions, where students are shown a segment of code and asked to provide an abstract description of the code's purpose, have been adopted. However, given EiPE questions require a natural language response, they often require manual grading which is time-consuming for course staff and delays feedback for students. With the advent of large language models (LLMs) capable of generating code, responses to EiPE questions can be used to generate code segments, the correctness of which can then be easily verified using test cases. We refer to this approach as "Code Generation Based Grading'' (CGBG) and in this paper we explore its agreement with human graders using EiPE responses from past exams in an introductory programming course taught in Python. Overall, we find that all CGBG approaches achieve moderate agreement with human graders with the primary area of disagreement being its leniency with respect to low-level and line-by-line descriptions of code.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {171–177},
numpages = {7},
keywords = {auto-grading, eipe, gpt-4, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3691620.3695066,
author = {Li, Guochang and Zhi, Chen and Chen, Jialiang and Han, Junxiao and Deng, Shuiguang},
title = {Exploring Parameter-Efficient Fine-Tuning of Large Language Model on Automated Program Repair},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695066},
doi = {10.1145/3691620.3695066},
abstract = {Automated Program Repair (APR) aims to fix bugs by generating patches. And existing work has demonstrated that "pre-training and fine-tuning" paradigm enables Large Language Models (LLMs) improve fixing capabilities on APR. However, existing work mainly focuses on Full-Model Fine-Tuning (FMFT) for APR and limited research has been conducted on the execution-based evaluation of Parameter-Efficient Fine-Tuning (PEFT) for APR. Comparing to FMFT, PEFT can reduce computing resource consumption without compromising performance and has been widely adopted to other software engineering tasks.To fill this gap, we enhance the existing APR dataset by employing prompt engineering to create an instruction dataset, APR-Instruction, at first. Secondly, we fine-tune four pre-trained LLMs using four different PEFT methods with APR-Instruction. The best fine-tuned model fixes 58% more bugs than the state-of-the-art LLM-based APR techniques. The results also show that (IA)3 improves the creativity of LLMs more effectively through fine-tuning and achieves the highest fixing capability compared to the other three PEFT methods. Thirdly, we explore the optimal configuration of PEFT hyperparameters, and assess the impact of instruction dataset size, showing that a larger number of parameters and a larger training dataset do not necessarily result in better performance for PEFT. Lastly, we analyze peak memory usage and trainable parameters to show the efficiency of PEFT.This work provides a comprehensive exploration of PEFT on APR and suggests potentially promising directions for extension to other software engineering downstream tasks. APR-Instruction, PEFT weights, and the fine-tuning code are publicly available as open-source resources.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {719–731},
numpages = {13},
keywords = {automated program repair, parameter-effective fine-tuning, large language model, execution-based evaluation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3689492.3689816,
author = {Kang, Eunsuk and Shaw, Mary},
title = {tl;dr: Chill, y’all: AI Will Not Devour SE},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3689816},
doi = {10.1145/3689492.3689816},
abstract = {Social media provide a steady diet of dire warnings that artificial intelligence (AI) will make software engineering (SE) irrelevant or obsolete. To the contrary, the engineering discipline of software is rich and robust; it encompasses the full scope of software design, development, deployment, and practical use; and it has regularly assimilated radical new offerings from AI. Current AI innovations such as machine learning, large language models (LLMs) and generative AI will offer new opportunities to extend the models and methods of SE. They may automate some routine development processes, and they will bring new kinds of components and architectures. If we're fortunate they may force SE to rethink what we mean by correctness and reliability. They will not, however, render SE irrelevant.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {303–315},
numpages = {13},
keywords = {AI-assisted development, software correctness, software engineering principles},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@inproceedings{10.1145/3661167.3661202,
author = {De Vito, Gabriele},
title = {Assessing healthcare software built using IoT and LLM technologies},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661202},
doi = {10.1145/3661167.3661202},
abstract = {In the fast-paced world of healthcare technology, combining IoT devices with large language models (LLMs) offers a promising path to transform Clinical Decision-Support Systems (CDSS). This Ph.D. project is designed to tap into IoT’s extensive data collection ability and LLMs’ superior natural language processing skills. It aims to improve clinical decision-making and patient care through a sophisticated DSS that utilizes both technologies’ strengths. The project delves into the software engineering challenges and methodologies required to build an effective DSS. It investigates how to smoothly evaluate and integrate IoT and LLMs into healthcare environments, tackling significant issues like data complexity, privacy concerns, and the necessity for high accuracy in medical settings. It underscores the critical role of thorough evaluation and assessment in developing healthcare technologies.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {476–481},
numpages = {6},
keywords = {Clinical Decision Support System, Healthcare Software Assessment, Large Language Models},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3649217.3653584,
author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653584},
doi = {10.1145/3649217.3653584},
abstract = {The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {297–303},
numpages = {7},
keywords = {copilot, cs1, generative ai, introductory programming, llm},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3657604.3662036,
author = {Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan},
title = {Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662036},
doi = {10.1145/3657604.3662036},
abstract = {The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the "CodeTutor group" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the "control group"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {63–74},
numpages = {12},
keywords = {field study, large language models, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3650212.3680384,
author = {Zhang, Yuntong and Ruan, Haifeng and Fan, Zhiyu and Roychoudhury, Abhik},
title = {AutoCodeRover: Autonomous Program Improvement},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680384},
doi = {10.1145/3650212.3680384},
abstract = {Researchers have made significant progress in automating the software development process in the past decades. Automated techniques for issue summarization, bug reproduction, fault localization, and program repair have been built to ease the workload of developers. Recent progress in Large Language Models (LLMs) has significantly impacted the development process, where developers can use LLM-based programming assistants to achieve automated coding. Nevertheless, software engineering involves the process of program improvement apart from coding, specifically to enable software maintenance (e.g. program repair to fix bugs) and software evolution (e.g. feature additions). In this paper, we propose an automated approach for solving Github issues to autonomously achieve program improvement. In our approach called AutoCodeRover, LLMs are combined with sophisticated code search capabilities, ultimately leading to a program modification or patch. In contrast to recent LLM agent approaches from AI researchers and practitioners, our outlook is more software engineering oriented. We work on a program representation (abstract syntax tree) as opposed to viewing a software project as a mere collection of files. Our code search exploits the program structure in the form of classes/methods to enhance LLM’s understanding of the issue’s root cause, and effectively retrieve a context via iterative search. The use of spectrum-based fault localization using tests, further sharpens the context, as long as a test-suite is available. Experiments on the recently proposed SWE-bench-lite (300 real-life Github issues) show increased efficacy in solving Github issues (19% on SWE-bench-lite), which is higher than the efficacy of the recently reported Swe-agent. Interestingly, our approach resolved 57 GitHub issues in about 4 minutes each (pass@1), whereas developers spent more than 2.68 days on average. In addition, AutoCodeRover achieved this efficacy with significantly lower cost (on average, $0.43 USD), compared to other baselines. We posit that our workflow enables autonomous software engineering, where, in future, auto-generated code from LLMs can be autonomously improved.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1592–1604},
numpages = {13},
keywords = {automatic program repair, autonomous software engineering, autonomous software improvement, large language model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3691620.3695277,
author = {Sahoo, Priyam and Pujar, Saurabh and Nalawade, Ganesh and Genhardt, Richard and Mandel, Louis and Buratti, Luca},
title = {Ansible Lightspeed: A Code Generation Service for IT Automation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695277},
doi = {10.1145/3691620.3695277},
abstract = {The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for Information Technology (IT) automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Ansible Lightspeed is an LLM-based service designed explicitly to generate Ansible YAML, given natural language prompt.In this paper, we present the design and implementation of the Ansible Lightspeed service. We then evaluate its utility to developers using diverse indicators, including extended utilization, analysis of user edited suggestions, as well as user sentiments analysis. The evaluation is based on data collected for 10,696 real users including 3,910 returning users. The code for Ansible Lightspeed service and the analysis framework is made available for others to use.To our knowledge, our study is the first to involve thousands of users of code assistants for domain-specific languages. We are also the first code completion tool to present N-Day user retention figures, which is 13.66% on Day 30. We propose an improved version of user acceptance rate, called Strong Acceptance rate, where a suggestion is considered accepted only if less than 50% of it is edited and these edits do not change critical parts of the suggestion. By focusing on Ansible, Lightspeed is able to achieve a strong acceptance rate of 49.08% for multi-line Ansible task suggestions. With our findings we provide insights into the effectiveness of small, dedicated models in a domain-specific context. We hope this work serves as a reference for software engineering and machine learning researchers exploring code completion.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2148–2158},
numpages = {11},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3632754.3633480,
author = {Paul, Soumen and Majumdar, Srijoni and Bandyopadhyay, Ayan and Dave, Bhargav and Chattopadhyay, Samiran and Das, Partha and Clough, Paul D and Majumder, Prasenjit},
title = {Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023},
year = {2024},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632754.3633480},
doi = {10.1145/3632754.3633480},
abstract = {The Software Engineering Information Retrieval (IRSE) track aims to devise solutions for the automated evaluation of code comments within a machine learning framework, with labels generated by both humans and large language models. Within this track, there is a binary classification task: discerning comments as either useful or not useful. The dataset includes 9,048 pairs of code comments and surrounding code snippets drawn from open-source C-based projects on GitHub and an additional dataset generated by teams employing large language models. In total, 17 teams representing various universities and software companies have contributed 56 experiments. These experiments were assessed through quantitative metrics, primarily the F1-Score, and qualitative evaluations based on the features developed, the supervised learning models employed, and their respective hyperparameters. It is worth noting that labels generated by large language models introduce bias into the prediction model but lead to less over-fitted results.},
booktitle = {Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {16–18},
numpages = {3},
keywords = {Abstract syntax tree, Bert, GPT-2, Neural networks, Stanford POS Tagging},
location = {Panjim, India},
series = {FIRE '23}
}

@inproceedings{10.1145/3627673.3679783,
author = {Anand, Avinash and Nair, Ashwin R and Prasad, Kritarth and Narayan, Vrinda and Lal, Naman and Mahata, Debanjan and Singla, Yaman K and Shah, Rajiv Ratn},
title = {Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679783},
doi = {10.1145/3627673.3679783},
abstract = {Citation Text Generation (CTG) in scientific documents often relies on standard summarization techniques, which may not fully capture the nuanced relationship between the citing and cited papers. To address this, we present a Multi-Source Citation Text Generation (M-CTG) architecture, leveraging a Seq2Seq transformer framework enhanced with keyphrase embeddings, graph embeddings, and text representations. This approach aims to produce more contextually relevant and accurate citation texts by integrating multiple sources of information. Our methodology is tested using the newly created CTG-S2ORC dataset, consisting of English-language computer science research papers. In a comparative analysis, we explore the performance of traditional Language Models (LMs) and demonstrate how Large Language Models (LLMs), particularly when integrated with various prompting techniques and Knowledge Graphs, offer superior capabilities in analyzing and generating citation texts. In addition to traditional evaluation metrics, we introduce a custom metric that emphasizes the overlap of key terms and semantic similarity, providing a more comprehensive assessment of our model's performance. Our code and data are available at https://github.com/midas-research/M-CTG/tree/main.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {56–64},
numpages = {9},
keywords = {S2ORC, citation text generation, graph embeddings, knowledge graphs, language models, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626252.3630784,
author = {Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.},
title = {Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630784},
doi = {10.1145/3626252.3630784},
abstract = {ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1147–1153},
numpages = {7},
keywords = {academic misconduct, artificial intelligence, chatgpt, large language models, student survey},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701625.3701657,
author = {de Almeida, \'{A}gatha and Collins, Eliane and Oran, Ana Carolina},
title = {AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701657},
doi = {10.1145/3701625.3701657},
abstract = {Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {179–188},
numpages = {10},
keywords = {Exploratory Testing, ChatGPT, Personas, Software Quality, Artificial Intelligence},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3626252.3630874,
author = {Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi},
title = {Implications of ChatGPT for Data Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630874},
doi = {10.1145/3626252.3630874},
abstract = {ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1230–1236},
numpages = {7},
keywords = {data science education, large language models, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3650212.3680328,
author = {Yang, Boyang and Tian, Haoye and Pian, Weiguo and Yu, Haoran and Wang, Haitao and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F. and Jin, Shunfu},
title = {CREF: An LLM-Based Conversational Software Repair Framework for Programming Tutors},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680328},
doi = {10.1145/3650212.3680328},
abstract = {With the proven effectiveness of Large Language Models (LLMs) in code-related tasks, researchers have explored their potential for program repair. However, existing repair benchmarks might have influenced LLM training data, potentially causing data leakage. To evaluate LLMs’ realistic repair capabilities, (i) we introduce an extensive, non-crawled benchmark TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code. Our work assesses LLM’s repair performance on TutorCode, measuring repair correctness (TOP-5 and AVG-5) and patch precision (RPSR). (ii) We then provide a comprehensive investigation into which types of extra information can help LLMs improve their repair performance. Among these types, tutor guidance was the most effective information. To fully harness LLMs’ conversational capabilities and the benefits of augmented information, (iii) we introduce a novel conversational semi-automatic repair framework CREF assisting human programming tutors. It demonstrates a remarkable AVG-5 improvement of 17.2%-24.6% compared to the baseline, achieving an impressive AVG-5 of 76.6% when utilizing GPT-4. These results highlight the potential for enhancing LLMs’ repair capabilities through tutor interactions and historical conversations. The successful application of CREF in a real-world educational setting demonstrates its effectiveness in reducing tutors’ workload and improving students’ learning experience, showing promise for code review and other software engineering tasks.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {882–894},
numpages = {13},
keywords = {Large Language Model, Open Source, Program Repair},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3639478.3643533,
author = {Cai, Zeju and Chen, Jianguo and Chen, Wenqing and Wang, Weicheng and Zhu, Xiangyuan and Ouyang, Aijia},
title = {F-CodeLLM: A Federated Learning Framework for Adapting Large Language Models to Practical Software Development},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3643533},
doi = {10.1145/3639478.3643533},
abstract = {Large Language Models (LLMs) have revolutionized code intelligence tasks, but their performance in specific software development tasks often requires fine-tuning with task-specific data. However, acquiring such data is challenging due to privacy concerns. We introduce F-CodeLLM, a novel federated learning framework for adapting LLMs to software development tasks while preserving code data privacy. Leveraging federated learning and LoRA-based efficient fine-tuning, F-CodeLLM allows organizations to collaboratively improve LLMs without sharing sensitive data. Our experiments demonstrate that F-CodeLLM achieves comparable results to centralized fine-tuning methods and excels in multi-language environments, marking a significant advancement in the application of LLMs for software engineering.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {416–417},
numpages = {2},
keywords = {code intelligence, federated fine-tuning, large language model, software development},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@proceedings{10.1145/3643661,
title = {InteNSE '24: Proceedings of the ACM/IEEE 2nd International Workshop on Interpretability, Robustness, and Benchmarking in Neural Software Engineering},
year = {2024},
isbn = {9798400705649},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {InteNSE is an interdisciplinary workshop for research at the intersection of Artificial Intelligence (AI) and Software Engineering (SE) and would be a pioneer in emphasizing the implicit properties and applications of neural software engineering and analysis. Due to recent computational advancements, AI has become an inseparable part of the SE research community, with Large Language Models (LLMs) showing a promising performance to automate SE tasks. However, most research in the AI and SE communities consider machine learning (ML) components as closed-box, i.e., only considering the final performance of the developed models as an evaluation metric. Ignoring the implicit properties of neural models, such as interpretability, robustness, and fairness, one cannot validate its actual performance, generalizability, and whether it is learning what it should do. Specifically, in the domain of SE, where the result of AI4SE tools is code synthesis, bug finding, or repair; interpretability and robustness are crucial to ensure the reliability of the products.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3626253.3633409,
author = {Hazzan, Orit and Erez, Yael},
title = {Generative AI in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633409},
doi = {10.1145/3626253.3633409},
abstract = {Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1899},
numpages = {1},
keywords = {ai, assessment, computer science education, curriculum design, disruptive technology, generative ai, skills},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3678717.3691248,
author = {Kononykhin, Danil and Mozikov, Mikhail and Mishtal, Kirill and Kuznetsov, Pavel and Abramov, Dmitrii and Sotiriadi, Nazar and Maximov, Yury and Savchenko, Andrey V. and Makarov, Ilya},
title = {From Data to Decisions: Streamlining Geospatial Operations with Multimodal GlobeFlowGPT},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691248},
doi = {10.1145/3678717.3691248},
abstract = {As machine learning increasingly becomes a crucial tool for geospatial data analysis, finding and deploying a suitable model presents significant challenges, including the need for expertise in both programming and geospatial analysis, organizing data flow, and accurately assessing the results. To address these challenges, this paper introduces GlobeFlowGPT, a multimodal, chat-based framework designed to meet these demands by integrating domain-specific tools, machine learning models, Multimodal Large Language Models, and essential operational data. It leverages a Large Language Model orchestrator, facilitating complex geospatial tasks through a conversational interface. GlobeFlowGPT's flexible, containerized architecture allows for the rapid integration of cutting-edge models tailored for geospatial data, ensuring that the framework remains scalable and relevant amid ongoing technological advancements. We demonstrate the ability of our framework to streamline the analysis of geospatial data and expand the capabilities of modern MLLMs with complex geospatial machine learning models.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {649–652},
numpages = {4},
keywords = {LLM Agent, Multimodal LLM, Satellite Imagery},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3643991.3645081,
author = {AlOmar, Eman Abdullah and Venkatakrishnan, Anushkrishna and Mkaouer, Mohamed Wiem and Newman, Christian and Ouni, Ali},
title = {How to refactor this code? An exploratory study on developer-ChatGPT refactoring conversations},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645081},
doi = {10.1145/3643991.3645081},
abstract = {Large Language Models (LLMs), like ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including refactoring, testing, code review, and program comprehension. Despite recent studies delving into refactoring documentation in commit messages, issues, and code review, little is known about how developers articulate their refactoring needs when interacting with ChatGPT. In this paper, our goal is to explore conversations between developers and ChatGPT related to refactoring to better understand how developers identify areas for improvement in code and how ChatGPT addresses developers' needs. Our approach relies on text mining refactoring-related conversations from 17,913 ChatGPT prompts and responses, and investigating developers' explicit refactoring intention. Our results reveal that (1) developer-ChatGPT conversations commonly involve generic and specific terms/phrases; (2) developers often make generic refactoring requests, while ChatGPT typically includes the refactoring intention; and (3) various learning settings when prompting ChatGPT in the context of refactoring. We envision that our findings contribute to a broader understanding of the collaboration between developers and AI models.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {202–206},
numpages = {5},
keywords = {refactoring documentation, ChatGPT, mining software repositories},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3661167.3661210,
author = {Kumar, Jahnavi and Chimalakonda, Sridhar},
title = {Code Summarization without Direct Access to Code - Towards Exploring Federated LLMs for Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661210},
doi = {10.1145/3661167.3661210},
abstract = {Software Engineering (SE) researchers are extensively applying Large Language Models (LLMs) to address challenges in SE tasks such as code clone detection, code summarization, and program comprehension. Despite promising results, LLMs have to be fine-tuned and customized with specific datasets for optimal performance. However, the proprietary nature of SE data, and the lack of LLMs trained on non-open source data is an open problem. While there exists work on applying Federated Learning (FL) for SE, integration of FL with LLMs for SE is unexplored. Hence, we propose a FedLLM for “code summarization” as developers spend more time in comprehending code. We setup a federated learning architecture and fine-tune LLM (Llama2 with 6.7B parameters) using Parameter Efficient Fine-Tuning (PEFT) for code summarization. We conducted our experiments on 40GB RAM GPU in an A100 architecture. Results show that FL-trained LLM is as effective as a centrally-trained one. We envision that leveraging non-open source data using FedLLM for SE could be an interesting research direction.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {100–109},
numpages = {10},
keywords = {Code Summarization, Federated Learning, Large Language Model (LLM), Parameter Efficient Fine-Tuning (PEFT)},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3638530.3664121,
author = {Guo, Ping and Liu, Fei and Lin, Xi and Zhao, Qingchuan and Zhang, Qingfu},
title = {L-AutoDA: Large Language Models for Automatically Evolving Decision-based Adversarial Attacks},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664121},
doi = {10.1145/3638530.3664121},
abstract = {In the rapidly evolving field of machine learning, adversarial attacks pose a significant threat to the robustness and security of models. Amongst these, decision-based attacks are particularly insidious due to their nature of requiring only the model's decision output, which makes them notably challenging to counteract. This paper presents L-AutoDA (Large Language Model-based Automated Decision-based Adversarial Attacks), an innovative methodology that harnesses the generative capabilities of large language models (LLMs) to streamline the creation of such attacks. L-AutoDA employs an evolutionary strategy, where iterative interactions with LLMs lead to the autonomous generation of potent attack algorithms, thereby reducing human intervention. The performance of L-AutoDA was evaluated on the CIFAR-10 dataset, where it demonstrated substantial superiority over existing baseline methods in terms of success rate and computational efficiency. Ultimately, our results highlight the formidable utility of language models in crafting adversarial attacks and reveal promising directions for constructing more resilient AI systems.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1846–1854},
numpages = {9},
keywords = {large language models, adversarial attacks, automated algorithm design, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3661167.3661269,
author = {Harman, Mark},
title = {The Role of Software Measurement in Assured LLM-Based Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661269},
doi = {10.1145/3661167.3661269},
abstract = {Assured Large Language Model Software Engineering (Assured LLMSE) addresses the twin challenges: 1. Ensuring LLM-generated code does not regress the properties of the original code 2. Quantifying the improvement over the original archived by the improve code in a verifiable and measurable way. In so doing, the Assured LLMSE approach tackles the problem of LLMs’ tendency to hallucinate, as well as providing confidence that generated code improves an existing code base. Software testing and measurement play critical roles in this improvement process: testing is the guard against regression, while measurement provides the quantifiable assurance of improvement. Assured LLMSE takes its inspiration from previous work on genetic improvement, for which software measurement also plays a central role. In this keynote we outline the Assured LLMSE approach, highlighting the role of software measurement in the provision of quantifiable, verifiable assurances for code that originates from LLM–based inference. This paper is an outline of the content of the keynote by Mark Harman at the 28th International Conference on Evaluation and Assessment in Software Engineering.  This is joint work with Nadia Alshahwan, Andrea Aquino, Jubin Chheda, Anastasia Finegenova, Inna Harper, Mitya Lyubarskiy, Neil Maiden, Alexander Mols, Shubho Sengupta, Rotem Tal, Alexandru Marginean, and Eddy Wang.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {4},
numpages = {1},
keywords = {Automated Code Generation, CodeLlama, Genetic Improvement (GI), Large Language Models (LLMs), Llama, Search Based Software Engineering (SBSE)},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3657604.3664714,
author = {Arif, Taimoor and Asthana, Sumit and Collins-Thompson, Kevyn},
title = {Generation and Assessment of Multiple-Choice Questions from Video Transcripts using Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664714},
doi = {10.1145/3657604.3664714},
abstract = {We present an empirical study evaluating the quality of multiple-choice questions (MCQs) generated by Large Language Models (LLMs) from a corpus of video transcripts of course lectures in an online data science degree program. With our database of thousands of generated questions, we conducted both human and automated judging of question quality on a representative sample using a broad set of criteria, including well-established Item Writing Flaw (IWF) categories. We found the number of average IWFs per MCQ ranged from 1.6 (rule-based verification) to 2.18 (LLM-based). Among the most frequently identified MCQ flaws were lack of enough context (17%) or answer choices with at least one implausible distractor (57%). Both human and automated assessment identified implausible distractors as one of the most frequent flaw categories. Results from our human annotation study were generally more positive (51--65% good items) compared to our automated assessment study results, which tended toward greater flaw identification (15--25% good items), depending on evaluation method.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {530–534},
numpages = {5},
keywords = {educational video, large language models, question generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3691621.3694934,
author = {Siddiq, Mohammed Latif and da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
title = {SALLM: Security Assessment of Generated Code},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694934},
doi = {10.1145/3691621.3694934},
abstract = {With the growing popularity of Large Language Models (LLMs) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {54–65},
numpages = {12},
keywords = {security evaluation, large language models, pre-trained transformer model, metrics},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1145/3657604.3664699,
author = {Hutt, Stephen and Hieb, Grayson},
title = {Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664699},
doi = {10.1145/3657604.3664699},
abstract = {Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {310–314},
numpages = {5},
keywords = {content evaluation, content generation, generative ai, large language models, mastery learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3649217.3653600,
author = {Villegas Molina, Ismael and Montalvo, Audria and Zhong, Shera and Jordan, Mollie and Soosai Raj, Adalbert Gerald},
title = {Generation and Evaluation of a Culturally-Relevant CS1 Textbook for Latines using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653600},
doi = {10.1145/3649217.3653600},
abstract = {In the United States, culturally relevant computing (CRC) is one of the most popular pedagogical implementations for Latin American (Latine) students. Culturally-relevant learning resources are a valuable tool for implementing CRC. However, the traditional method of creation and maintenance of textbooks takes a significant amount of time and effort. Given the duration required for textbook production, the development of culturally-relevant learning resources may become lengthened, as it requires close attention both on the material and the incorporation of cultural referents. In order to accelerate the process, we used the advancement of large language models (LLMs) to our advantage. Through prompt engineering, we created a series of prompts to produce a textbook for an introductory computer science course (CS1) that incorporates Latine culture. This textbook was evaluated on metrics regarding sensibility, correctness, readability, linguistic approachability, appropriateness of examples, and cultural relevance. Overall, the generated textbook was mainly sensible, correct, readable, and linguistically approachable. Code examples were not always appropriate due to the usage of libraries that are not typically used in a CS1 course. The cultural relevance was apparent, but it often included surface-level cultural referents. The main incorporation of culture was through geographical locations and people's names. This suggests that the use of LLMs to generate textbooks may serve as a valuable first step for writing culturally-relevant learning resources. Though this study focuses on Latines, our results and prompts may be applicable for generating culturally-relevant CS1 textbooks for other cultures.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {325–331},
numpages = {7},
keywords = {Latina, Latine, Latino, Latinx, computer science textbook, culturally relevant resources, large language models, resource generation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626772.3657995,
author = {Yang, Yiming},
title = {Representation Learning and Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657995},
doi = {10.1145/3626772.3657995},
abstract = {How to best represent words, documents, queries, entities, relations, and other variables in information retrieval (IR) and related applications has been a fundamental research question for decades. Early IR systems relied on the independence assumptions about words and documents for simplicity and scalability, which were clearly sub-optimal from a semantic point of view. The rapid development of deep neural networks in the past decade has revolutionized the representation learning technologies for contextualized word embedding and graph-enhanced document embedding, leading to the new era of dense IR. This talk highlights such impactful shifts in representation learning for IR and related areas, the new challenges coming along and the remedies, including our recent work in large-scale dense IR [1, 9], in graph-based reasoning for knowledge-enhanced predictions [10], in self-refinement of large language models (LLMs) with retrieval augmented generation (RAG)[2,7] and iterative feedback [3,4], in principle-driven self-alignment of LLMs with minimum human supervision [6], etc. More generally, the power of such deep learning goes beyond IR enhancements, e.g., for significantly improving the state-of-the-art solvers for NP-Complete problems in classical computer science [5,8].},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1–2},
numpages = {2},
keywords = {ai-enhanced foundation models, deep representation learning, graph neural networks, retrieval augmented generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@article{10.5555/3665464.3665467,
author = {Hsin, Wen-Jung},
title = {The Effect of ChatGPT: Student Perspective and Performance Achievement},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {ChatGPT, introduced in November 2022, has rapidly used in various educational systems, prompting the U.S. Department of Education to explore the role of Artificial Intelligence (AI) in teaching and learning. This paper focuses on the impact of AI, particularly ChatGPT, in Computer Science education from the student's perspective and student's performance achievement. Specifically, a study in a Computer Networking course encouraged students to use ChatGPT for learning-related questions, followed by a post-exam survey to evaluate its impact on their learning. Both student feedback and performance achievement indicate that ChatGPT has made a positive impact in their learning in the Computer Networking course.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {20–29},
numpages = {10}
}

@inproceedings{10.1145/3626253.3635369,
author = {MacNeil, Stephen and Leinonen, Juho and Denny, Paul and Kiesler, Natalie and Hellas, Arto and Prather, James and Becker, Brett A. and Wermelinger, Michel and Reid, Karen},
title = {Discussing the Changing Landscape of Generative AI in Computing Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635369},
doi = {10.1145/3626253.3635369},
abstract = {In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1916},
numpages = {1},
keywords = {academic integrity, assessment, computing education, curriculum, large language models, pedagogy},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653527,
author = {Martini, Simone},
title = {Teaching Programming in the Age of Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653527},
doi = {10.1145/3649217.3653527},
abstract = {Programming has been considered the "essence of informatics" since the beginning of computing as a discipline. But programming in the fifties was very different from what we know today, and one of the goals (or dreams) throughout the history of programming language technology, has been "automatic programming''---the ability to automatically generate computer code starting from a high(er)-level description of the specification of that code. What this meant changed over the years, from punching paper tape, to compiling high-level programming languages, to program synthesis.Today, however, the availability of machine learning artefacts that produce high-level code from natural language specifications has completely changed the traditional meaning. To the extent that some computer scientists have begun to question the received wisdom that the core of their discipline is deeply rooted in programming.If programming and programming languages are no longer the essence of computer science, this changes the epistemology of the discipline itself. Moreover, if we are at the end of programming, we should also change the curriculum, where programming, algorithms and programming languages play a major role. Several recent papers reviewed the performance of code generators based on large language models on typical CS1 problems (e.g., from the many possible citations and how machine learning impacts K-12 teaching.Starting from this data, I will argue for the role of programming in the curriculum, distinguishing between programming taught as part of a holistic curriculum (as in some non-technical high schools) or as a vocational tool. I will use Simondon's notion of (closed and open) technical object as an interpretive lens, together with Calvino's reflections on the availability of writing machines capable of replacing the poet and the author.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {1–2},
numpages = {2},
keywords = {epistemology, large language models, programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3632620.3671098,
author = {Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara},
title = {Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671098},
doi = {10.1145/3632620.3671098},
abstract = {The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM’s technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students’ social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students’ self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students’ use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students’ perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {114–130},
numpages = {17},
keywords = {Generative AI, Large Language Models, Self-Efficacy, Social Shaping Theory, Technology Appropriation Model},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3700410.3702126,
author = {Wang, Zhaode and Yang, Jingbang and Qian, Xinyu and Xing, Shiwen and Jiang, Xiaotang and Lv, Chengfei and Zhang, Shengyu},
title = {MNN-LLM: A Generic Inference Engine for Fast Large Language Model Deployment on Mobile Devices},
year = {2024},
isbn = {9798400713149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700410.3702126},
doi = {10.1145/3700410.3702126},
abstract = {Large language models (LLMs) have demonstrated exceptional performance across a variety of tasks. However, their substantial scale leads to significant computational resource consumption during inference, resulting in high costs. Consequently, edge device inference presents a promising solution. The primary challenges of edge inference include memory usage and inference speed. This paper introduces MNN-LLM, a framework specifically designed to accelerate the deployment of large language models on mobile devices. MNN-LLM addresses the runtime characteristics of LLMs through model quantization and DRAM-Flash hybrid storage, effectively reducing memory usage. It rearranges weights and inputs based on mobile CPU instruction sets and GPU characteristics while employing strategies such as multicore load balancing, mixed-precision floating-point operations, and geometric computations to enhance performance. Notably, MNN-LLM achieves up to a 8.6x speed increase compared to current mainstream LLM-specific frameworks.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia Workshops},
articleno = {11},
numpages = {7},
location = {
},
series = {MMAsia '24 Workshops}
}

@inproceedings{10.1145/3687123.3698286,
author = {Gramacki, Piotr and Martins, Bruno and Szyma\'{n}ski, Piotr},
title = {Evaluation of Code LLMs on Geospatial Code Generation},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698286},
doi = {10.1145/3687123.3698286},
abstract = {Software development support tools have been studied for a long time, with recent approaches using Large Language Models (LLMs) for code generation. These models can generate Python code for data science and machine learning applications. LLMs are helpful for software engineers because they increase productivity in daily work. An LLM can also serve as a "mentor" for inexperienced software developers, and be a viable learning support. High-quality code generation with LLMs can also be beneficial in geospatial data science. However, this domain poses different challenges, and code generation LLMs are typically not evaluated on geospatial tasks. Here, we show how we constructed an evaluation benchmark for code generation models, based on a selection of geospatial tasks. We categorised geospatial tasks based on their complexity and required tools. Then, we created a dataset with tasks that test model capabilities in spatial reasoning, spatial data processing, and geospatial tools usage. The dataset consists of specific coding problems that were manually created for high quality. For every problem, we proposed a set of test scenarios that make it possible to automatically check the generated code for correctness. In addition, we tested a selection of existing code generation LLMs for code generation in the geospatial domain. We share our dataset and reproducible evaluation code on a public GitHub repository1, arguing that this can serve as an evaluation benchmark for new LLMs in the future. Our dataset will hopefully contribute to the development new models capable of solving geospatial coding tasks with high accuracy. These models will enable the creation of coding assistants tailored for geospatial applications.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {54–62},
numpages = {9},
keywords = {code generation, geospatial data science, large language models},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@inproceedings{10.1145/3649165.3690116,
author = {Golesteanu, Matei A. and Vowinkel, Garrett B. and Dougherty, Ryan E.},
title = {Can ChatGPT pass a Theory of Computing Course?},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690116},
doi = {10.1145/3649165.3690116},
abstract = {Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical and formal questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering "simple''-style questions, e.g., true/false and multiple choice. However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {33–38},
numpages = {6},
keywords = {automata theory, chatgpt, computer science education, formal languages, large language model, theoretical computer science},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1109/ASE56229.2023.00096,
author = {Yan, Dapeng and Gao, Zhipeng and Liu, Zhiming},
title = {A Closer Look at Different Difficulty Levels Code Generation Abilities of ChatGPT},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00096},
doi = {10.1109/ASE56229.2023.00096},
abstract = {Code generation aims to generate source code implementing human requirements illustrated with natural language specifications. With the rapid development of intelligent software engineering, automated code generation has become a hot research topic in both artificial intelligence and software engineering, and researchers have made significant achievements on code generation. More recently, large language models (LLMs) have demonstrated outstanding performance on code generation tasks, such as ChatGPT released by OpenAI presents the fantastic potential on automated code generation. However, the existing studies are limited to exploring LLMs' ability for generating code snippets to solve simple programming problems, the task of competition-level code generation has never been investigated. The specifications of the programming competition are always complicated and require the specific input/output format as well as the high-level algorithmic reasoning ability. In this study, we conduct the first large empirical study to investigate the zero-shot learning ability of ChatGPT for solving competition programming problems. Specifically, we warm up the design of prompts by using the Human-Eval dataset. Then, we apply the well-designed prompt to the competition-level code generation dataset, namely APPS, to further explore the effectiveness of using ChatGPT for solving competition problems. We collect ChatGPT's outputs on 5,000 code competition problems, the evaluation results show that it can successfully pass 25.4% test cases. By further feeding extra information (e.g, test failed information) to ChatGPT, we observe that ChatGPT has the potential to fix partial pass into a fully pass program. Moreover, we investigate the solutions generated by LLMs and the existing solutions, we find that it prefers to directly copy the code instead of re-write when facing more difficult problems. Finally, we evaluate the code quality generated by ChatGPT in terms of "code cleanness", we observe that the generated codes are with small functions and file sizes, which are in line with the standard of clean code.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1887–1898},
numpages = {12},
keywords = {code generation, program competition, Chat-GPT, large language model, clean code},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3649217.3653624,
author = {Grande, Virginia and Kiesler, Natalie and Francisco R., Mar\'{\i}a Andre\'{\i}na},
title = {Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653624},
doi = {10.1145/3649217.3653624},
abstract = {The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {478–484},
numpages = {7},
keywords = {chatgpt, ethics, experience report, large language models, llms, student perspective},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3633418,
author = {Gunawardena, Ananda and Chaturvedi, Naina},
title = {AI Enhanced Learning: Powering Curated Videos with Generative Intelligence},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633418},
doi = {10.1145/3626253.3633418},
abstract = {Instructional videos are becoming increasingly popular among computer science students. Over 78% of students frequently visit YouTube to find videos as supplement to their textbook or classroom instruction[1]. Recent surveys show that on average, 73% of students prefer having their instructors curate a supplemental video library to aid in their learning. Now, the emergence of generative AI is revolutionizing supplemental video instruction, enabling instructors to generate slides, recording scripts, and produce high-quality videos with deep search and embedded interactive activities.Generative AI also takes the student video learning to a new level by providing AI-generated video summaries, on-demand questions, and exploration of topics in greater depth. Integrating AI into standard videos greatly expands the possibilities of video-based learning. This workshop demonstrates how educators can enhance their existing video playlists by incorporating AI to increase student engagement and establish safety measures for AI use in education. By using dynamic dashboards, scheduled content, and gamified questions, instructors can maintain student focus.Drawing on insights from computer science courses taught at Princeton and Rutgers Universities, we will highlight the transformative potential of AI-enhanced videos in promoting active learning, particularly in large classes. We will discuss engagement strategies and real-time data visualizations applicable to any video platform. We will utilize the cubits.ai[2] platform, a Princeton University initiative that enhances the impact of computer science courses. The platform is free, and participants are encouraged to bring their own video playlists to curate them into AI-enabled collections by enhancing the student experience through integrated generative AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1898},
numpages = {1},
keywords = {ai generated content, contextualized generative ai, cost-effective videos, customized videos, data-driven insights, instructional videos, video summarization},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3658644.3691384,
author = {Fu, Weimin and Zhao, Yifang and Jin, Yier and Guo, Xiaolong},
title = {Poster: Enhance Hardware Domain Specific Large Language Model with Reinforcement Learning for Resilience},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691384},
doi = {10.1145/3658644.3691384},
abstract = {To enhance the performance of large language models (LLMs) on hardware design tasks, we focus on training with reinforcement learning(RL) to improve LLMs' syntax synthesis and functional verification performance. We observed significant gains in power, performance, and area (PPA) metrics by applying RL. Specifically, DeepSeek Code saw a 23.6% performance increase, while the RTLCoder improved by 7.86%. Our findings demonstrate the effectiveness of RL in refining LLMs for more accurate hardware generation, considering power and area consumption. This approach offers a promising direction for generating hardware resilient to side-channel attacks in computer systems.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {5060–5062},
numpages = {3},
keywords = {eda tools, hardware security, large language model},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3662739.3665684,
author = {Wang, Xinren and Wan, Tengfei and Song, Jianning and Huang, Jingmeng},
title = {Knowledge Enhancement and Optimization Strategies for Remote Sensing Image Captioning Using Contrastive Language Image Pre-training and Large Language Models},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3665684},
doi = {10.1145/3662739.3665684},
abstract = {In this study, we propose an innovative multimodal learning approach that integrates Contrastive Language Image Pre-training and large language models to enhance the recognition efficiency of remote sensing images and their capacity to generate related professional information. This method has effectively achieved integration of image processing and text generation at a technical level, exhibiting significant application advantages in fields such as automated Geographic Information Systems construction, environmental monitoring, disaster assessment, and geographic science education. The research underscores the advancements of the Contrastive Language Image Pre-training model in visual-textual understanding and the technical strengths of large language models in handling complex text tasks. By designing an integrated fusion layer, we have efficiently combined visual features with textual information and conducted a comprehensive evaluation of the model's recognition accuracy and text generation quality on the dataset. Experimental results show that our model achieved a recognition accuracy of 73.7% and a text quality score of 26.6, validating its efficacy and powerful capability in dealing with the complexity and diversity of remote sensing images. Through the deep integration of Contrastive Language Image Pre-training and large language models, this research not only further advances multimodal learning technologies but also opens new perspectives and possibilities for the research and application of remote sensing image recognition and related information generation.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {313–318},
numpages = {6},
keywords = {Caption Generation, Knowledge Enhancement, Large Language Models, Multimodal Learning, Remote Sensing Image Recognition},
location = {Ningbo, China},
series = {MIDA '24}
}

@article{10.5555/3665464.3665476,
author = {Alrifai, Rad},
title = {Using Generative AI to Design Programming Assignments in Introduction to Computer Science},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Programming stands as an essential requisite in computer science education. Recognizing the challenges students face in learning programming effectively, the proposed assignment aims to integrate generative artificial intelligence (AI) tools to teach students introductory programming constructs. Generative AI has gained an increasing popularity in recent years. Several available Generative AI implementations can now help students learn programming essentials and debugging skills.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {103–106},
numpages = {4}
}

@inproceedings{10.1145/3699538.3699541,
author = {Korpimies, Kai and Laaksonen, Antti and Luukkainen, Matti},
title = {Unrestricted Use of LLMs in a Software Project Course: Student Perceptions on Learning and Impact on Course Performance},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699541},
doi = {10.1145/3699538.3699541},
abstract = {Large language models (LLMs) provide round-the-clock personalized programming assistance, unlike course instructors or traditional online information sources such as Stack Overflow. While LLMs can aid in code generation, concerns about over-reliance and the impact on learning persist. This study discusses students’ experiences with LLMs in a software project course where students were allowed to use LLMs freely except for unit test generation. We conducted surveys during course instances in autumn 2023 and spring 2024. The surveys assessed the extent of LLM usage, methods of application, and perceived impact on learning. Results indicate diverse usage patterns, with many students finding LLMs beneficial for efficiency and problem-solving, though over-reliance and poor-quality outputs were noted concerns. The usage patterns can be linked to course performance and time spent on the project.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {23},
numpages = {7},
keywords = {Large language models, Computer Science Education, User Study, Code generation, Software project},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3626252.3630828,
author = {Prasad, Prajish and Sane, Aamod},
title = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630828},
doi = {10.1145/3626252.3630828},
abstract = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1070–1076},
numpages = {7},
keywords = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691620.3695307,
author = {Wu, Yueming and Liu, Chengwei and Xu, Zhengzi and Zhang, Lyuye and Zhang, Yiran and Zhu, Zhiling and Liu, Yang},
title = {The Software Genome Project: Unraveling Software Through Genetic Principles},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695307},
doi = {10.1145/3691620.3695307},
abstract = {Open-source software is crucial to modern development, but its complexity creates challenges in quality, security, and management. Current governance approaches excel at collaboration but struggle with decentralized management and security. With the rise of large language models (LLM)-based software engineering, the need for a finer-grained understanding of software composition is more urgent than ever. To address these challenges, inspired by the Human Genome Project, we treat the software source code as software DNA and propose the Software Genome Project (SGP), which is geared towards the secure monitoring and exploitation of open-source software. By identifying and labeling integrated and classified code features at a fine-grained level, and effectively identifying safeguards for functional implementations and nonfunctional requirements at different levels of granularity, the SGP could build a comprehensive set of software genome maps to help developers and managers gain a deeper understanding of software complexity and diversity. By dissecting and summarizing functional and undesirable genes, SGP could help facilitate targeted software optimization, provide valuable insight and understanding of the entire software ecosystem, and support critical development tasks such as open source governance. SGP could also serve as a comprehensive dataset with abundant semantic labeling to enhance the training of LLMs for code. Based on these, we expect SGP to drive the evolution of software development towards more efficient, reliable, and sustainable software solutions.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2319–2323},
numpages = {5},
keywords = {software genes, software composition, OSS governance},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3649217.3653575,
author = {Smith, C. Estelle and Shiekh, Kylee and Cooreman, Hayden and Rahman, Sharfi and Zhu, Yifei and Siam, Md Kamrul and Ivanitskiy, Michael and Ahmed, Ahmed M. and Hallinan, Michael and Grisak, Alexander and Fierro, Gabe},
title = {Early Adoption of Generative Artificial Intelligence in Computing Education: Emergent Student Use Cases and Perspectives in 2023},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653575},
doi = {10.1145/3649217.3653575},
abstract = {Because of the rapid development and increasing public availability of Generative Artificial Intelligence (GenAI) models and tools, educational institutions and educators must immediately reckon with the impact of students using GenAI. There is limited prior research on computing students' use and perceptions of GenAI. In anticipation of future advances and evolutions of GenAI, we capture a snapshot of student attitudes towards and uses of yet emerging GenAI, in a period of time before university policies had reacted to these technologies. We surveyed all computer science majors in a small engineering-focused R1 university in order to: (1) capture a baseline assessment of how GenAI has been immediately adopted by aspiring computer scientists; (2) describe computing students' GenAI-related needs and concerns for their education and careers; and (3) discuss GenAI influences on CS pedagogy, curriculum, culture, and policy. We present an exploratory qualitative analysis of this data and discuss the impact of our findings on the emerging conversation around GenAI and education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {3–9},
numpages = {7},
keywords = {ai literacy, code generator, education, generative artificial intelligence, image generator, interactive tutoring, large language model, policy, student experience, survey},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3674805.3690741,
author = {De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca},
title = {Evaluating Large Language Models in Exercises of UML Class Diagram Modeling},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690741},
doi = {10.1145/3674805.3690741},
abstract = {Large Language Models (LLM) have rapidly affirmed in the latest years as a means to support or substitute human actors in a variety of tasks. LLM agents can generate valid software models, because of their inherent ability in evaluating textual requirements provided to them in the form of prompts. The goal of this work is to evaluate the capability of LLM agents to correctly generate UML class diagrams in activities of Requirements Modeling in the field of Software Engineering. Our aim is to evaluate LLMs in an educational setting, i.e., understanding how valuable are the results of LLMs when compared to results made by human actors, and how valuable can LLM be to generate sample solutions to provide to students. For that purpose, we collected 20 exercises from a diverse set of web sources and compared the models generated by a human and an LLM solver in terms of syntactic, semantic, pragmatic correctness, and distance from a provided reference solution. Our results show that the solutions generated by an LLM solver typically present a significantly higher number of errors in terms of semantic quality and textual difference against the provided reference solution, while no significant difference is found in syntactic and pragmatic quality. We can therefore conclude that, with a limited amount of errors mostly related to the textual content of the solution, UML diagrams generated by LLM agents have the same level of understandability as those generated by humans, and exhibit the same frequency in violating rules of UML Class Diagrams.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {393–399},
numpages = {7},
keywords = {Artificial Intelligence, Class Diagrams, Large Language Models, Software Modeling},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3678610.3678631,
author = {Robledo-Rella, V\'{\i}ctor and Toh, Bee-Yen},
title = {Artificial Intelligence in Physics Courses to Support Active Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678631},
doi = {10.1145/3678610.3678631},
abstract = {The integration of generative artificial intelligence (AI), particularly Large Language Models (LLMs) like OpenAI's ChatGPT and Microsoft's Copilot, is transforming educational methodologies, including undergraduate physics courses for engineering students. Despite their potential, these LLMs typically rely on statistical learning methods and often exhibit algebraic inaccuracies in solving standard university-level physics problems. This study explores the use of LLMs in physics courses for N = 91 freshman engineering students over two academic terms (Spring and Fall 2023). Students engaged in AI-assisted activities to solve physics problems and were asked to identify and correct the errors made by the chatbot. The outcomes were compared with those from traditional teaching methods without AI involvement, and no significant difference in student learning gains was found. To assess the impact of AI tools in education, a more detailed approach using pre-test and post-test instruments&nbsp;with control and experimental groups is necessary. Survey results revealed, however, that AI-assisted sessions enhanced student engagement, problem-solving skills, and understanding of physics concepts. Students also indicated a strong preference for AI-assisted activities, citing increased motivation and a firm belief in the educational benefits of using these tools. Our findings suggest that well-designed AI interventions can effectively complement traditional instructional methods, especially when the LLMs are integrated with symbolic computational tools like WolframAlpha to improve their accuracy.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {68–75},
numpages = {8},
keywords = {ChatGPT, Copilot, Educational Innovation, Generative AI, Higher Education, Interactive Learning, Physics Education Research},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3650212.3680399,
author = {Qiu, Yuxin and Hu, Jie and Zhang, Qian and Yin, Heng},
title = {Calico: Automated Knowledge Calibration and Diagnosis for Elevating AI Mastery in Code Tasks},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680399},
doi = {10.1145/3650212.3680399},
abstract = {Recent advancements in large language models (LLMs) have exhibited promising capabilities in addressing various tasks such as defect detection and program repair. Despite their prevalence, LLMs still face limitations in effectively handling these tasks. Common strategies to adapt them and improve their performance for specific tasks involve fine-tuning models based on user data or employing in-context learning with examples of desired inputs and outputs.    However, they pose challenges for practical adoption due to the need for extensive computational resources, high-quality data, and continuous maintenance. Furthermore, neither strategy can explain or reason about the deficiencies of LLMs in the given tasks.         We propose Calico to address the high cost of fine-tuning, eliminate the necessity for task-specific examples, and provide explanations of LLM deficiency. At the heart of Calico is an evolutionary approach that interleaves knowledge calibration and AI deficiency diagnosis. The key essence of Calico is as follows. First, it focuses on identifying knowledge gaps in LLMs’ program comprehension. Second, it conducts automated code refactoring to integrate the overlooked knowledge into the source code for mitigating those gaps. Third, it employs what-if analysis and counterfactual reasoning to determine a minimum set of overlooked knowledge necessary to improve the performance of LLMs in code tasks.        We have extensively evaluated Calico over 8,938 programs on three most commonly seen code tasks. Our experimental results show that vanilla ChatGPT cannot fully understand code structures. With knowledge calibration, Calico improves it by 20% and exhibits comparable proficiency compared to fine-tuned LLMs. Deficiency diagnosis contributes to 8% reduction in program sizes while ensuring performance. These impressive results demonstrate the feasibility of utilizing a vanilla LLM for automated software engineering (SE) tasks, thereby avoiding the high computational costs associated with a fine-tuned model.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1785–1797},
numpages = {13},
keywords = {Software engineering, large language model, software testing},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3649217.3653594,
author = {Azaiz, Imen and Kiesler, Natalie and Strickroth, Sven},
title = {Feedback-Generation for Programming Exercises With GPT-4},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653594},
doi = {10.1145/3649217.3653594},
abstract = {Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material. Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements. For example, the output is more structured and consistent. GPT-4 Turbo can also accurately identify invalid casing in student programs' output. In some cases, the feedback also includes the output of the student program. At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed. The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {31–37},
numpages = {7},
keywords = {GPT-4 turbo, LLMs, assessment, benchmarking, formative feedback, introductory programming, large language models, personalized feedback},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1109/ASE56229.2023.00010,
author = {Das, Debeshee and Mathews, Noble Saji and Mathai, Alex and Tamilselvam, Srikanth and Sedamaki, Kranthi and Chimalakonda, Sridhar and Kumar, Atul},
title = {COMEX: A Tool for Generating Customized Source Code Representations},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00010},
doi = {10.1109/ASE56229.2023.00010},
abstract = {Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree-sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2054–2057},
numpages = {4},
keywords = {representation learning, static analysis},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3643795.3648387,
author = {Li, Zhiming and Cao, Yushi and Xu, Xiufeng and Jiang, Junzhe and Liu, Xu and Teo, Yon Shin and Lin, Shang-Wei and Liu, Yang},
title = {LLMs for Relational Reasoning: How Far are We?},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648387},
doi = {10.1145/3643795.3648387},
abstract = {Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting1.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {119–126},
numpages = {8},
keywords = {large language models, relational reasoning, program induction},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3626252.3630897,
author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
title = {Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630897},
doi = {10.1145/3626252.3630897},
abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {618–624},
numpages = {7},
keywords = {introductory programming, large language models, non-native english speakers, problem generation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3627673.3679153,
author = {Zhang, Yanlin and Li, Ning and Gan, Quan and Zhang, Weinan and Wipf, David and Wang, Minjie},
title = {ELF-Gym: Evaluating Large Language Models Generated Features for Tabular Prediction},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679153},
doi = {10.1145/3627673.3679153},
abstract = {Crafting effective features is a crucial yet labor-intensive and domain-specific task within machine learning pipelines. Fortunately, recent advancements in Large Language Models (LLMs) have shown promise in automating various data science tasks, including feature engineering. But despite this potential, evaluations thus far are primarily based on the end performance of a complete ML pipeline, providing limited insight into precisely how LLMs behave relative to human experts in feature engineering. To address this gap, we propose ELF-Gym, a framework for Evaluating LLM-generated Features. We curated a new dataset from historical Kaggle competitions, including 251 golden features used by top-performing teams. ELF-Gym then quantitatively evaluates LLM-generated features by measuring their impact on downstream model performance as well as their alignment with expert-crafted features through semantic and functional similarity assessments. This approach provides a more comprehensive evaluation of disparities between LLMs and human experts, while offering valuable insights into specific areas where LLMs may have room for improvement. For example, using ELF-Gym we empirically demonstrate that, in the best-case scenario, LLMs can semantically capture approximately 56% of the golden features, but at the more demanding implementation level this overlap drops to 13%. Moreover, in other cases LLMs may fail completely, particularly on datasets that require complex features, indicating broad potential pathways for improvement.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5420–5424},
numpages = {5},
keywords = {data science, feature engineering, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3686852.3687073,
author = {Servin, Christian and Karichev, Nadia V. and Pagel, Myshie},
title = {Unfolding Programming: How to Use AI Tools in Introductory Computing Courses},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687073},
doi = {10.1145/3686852.3687073},
abstract = {Artificial Intelligence (AI) generative tools, commonly referred to as AI-based tools, have become integral in various computing domains, including education. The widespread adoption of these tools has raised concerns among educators, spanning from issues related to plagiarism and comprehension gaps to potential threats to student identity. Consequently, educators are grappling with how to adapt their courses and incorporate AI technologies into their curriculum and pedagogical approaches. In addition to navigating challenges associated with AI regulations, educators face the compounded difficulty of addressing post-pandemic issues, such as students displaying diminished effort and professionalism in the classroom. The convergence of these two challenges creates a complex scenario that intertwines technical and professional considerations. Within the Computer Science Fundamentals course, commonly referred to as CS 1, the learning process revolves around comprehending programming through a sequential understanding of steps, as each concept builds upon the preceding one. This investigation centers on the CS 1 curriculum within an American two-year program, commonly known as a community college. The objective is to address a problem by leveraging an AI tool within team settings. The study assesses both problem-solving capabilities and the effectiveness of teamwork, providing recommendations to guide students in the proper utilization of AI tools. The emphasis is on fostering contextual relevance and collaborative work within the generative learning process.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {49–55},
numpages = {7},
keywords = {ai-tools, community colleges, prompt programming, two-year},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3643795.3648380,
author = {S Kumar, Smitha and Adam Lones, Michael and Maarek, Manuel and Zantout, Hind},
title = {Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648380},
doi = {10.1145/3643795.3648380},
abstract = {Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feedback for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {88–93},
numpages = {6},
keywords = {large language models (LLM), GPT-4, feedback, java programming, program repair},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3689535.3689554,
author = {Santos, Eddie Antonio and Becker, Brett A.},
title = {Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689554},
doi = {10.1145/3689535.3689554},
abstract = {The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {5},
numpages = {7},
keywords = {AI, C, CS1, GPT-4, GenAI, Generative AI, LLMs, PEM, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3639478.3641226,
author = {Ibrahimzada, Ali Reza},
title = {Program Decomposition and Translation with Static Analysis},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3641226},
doi = {10.1145/3639478.3641226},
abstract = {The rising popularity of Large Language Models (LLMs) has motivated exploring their use in code-related tasks. Code LLMs with more than millions of parameters are trained on a massive amount of code in different Programming Languages (PLs). Such models are used for automating various Software Engineering (SE) tasks using prompt engineering. However, given the very large size of industry-scale project files, a major issue of these LLMs is their limited context window size, motivating the question of "Can these LLMs process very large files and can we effectively perform prompt engineering?". Code translation aims to convert source code from one PL to another. In this work, we assess the effect of method-level program decomposition on context window of LLMs and investigate how this approach can enable translation of very large files which originally could not be done due to out-of-context issue. Our observations from 20 well-known java projects and approximately 60K methods suggest that method-level program decomposition significantly improves the limited context window problem of LLMs by 99.5%. Furthermore, our empirical analysis indicate that with method-level decomposition, each input fragment on average only consumes 5% of the context window, leaving more context space for prompt engineering and the output. Finally, we investigate the effectiveness of a Call Graph (CG) approach for translating very large files when doing method-level program decomposition.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {453–455},
numpages = {3},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3639474.3640052,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640052},
doi = {10.1145/3639474.3640052},
abstract = {Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {162–169},
numpages = {8},
keywords = {programming assignments, teaching, object-oriented programming, object-oriented design, OOP best practices, large language models, GPT-3, GPT-4, bard},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3674399.3674447,
author = {Wu, BenLong and Chen, Kejiang and He, Yanru and Chen, Guoqiang and Zhang, Weiming and Yu, Nenghai},
title = {CodeWMBench: An Automated Benchmark for Code Watermarking Evaluation},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674447},
doi = {10.1145/3674399.3674447},
abstract = {As deep learning progresses, programming language generation models such as CodeLlama, GitHub Copilot, and ChatGPT have been widely applied to intelligent code development. However, this also reduces the cost of code plagiarism, posing challenges to copyright and academic integrity. In response to the specific needs for human-machine code detection, this paper introduces a comprehensive automated benchmark CodeWMBench for active detection of human-machine code through watermarking. With a meticulous evaluation of eight code watermarking methods, we demonstrated their performance in terms of harmlessness, robustness, and transparency. Specifically, for the first time, we introduced watermark removal techniques based on large language models and conducted the first assessment of these watermarking methods against code rewriting and retranslating attacks. In the discussion, we delved into the critical issues currently facing code watermarking, including why existing code watermarking methods struggle to resist removal by large language models and potential future methods that could withstand such removals.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {120–125},
numpages = {6},
keywords = {Programming language model, benchmark, code watermark},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3638067.3638100,
author = {Freire, Andr\'{e} Pimenta and Cardoso, Paula Christina Figueira and Salgado, Andr\'{e} de Lima},
title = {May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638100},
doi = {10.1145/3638067.3638100},
abstract = {Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {6},
numpages = {11},
keywords = {ChatGPT, HCI education, evaluation, open-book exams},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3675812.3675874,
author = {Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.},
title = {Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675874},
doi = {10.1145/3675812.3675874},
abstract = {The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {340–346},
numpages = {7},
keywords = {AI in education, ChatGPT, Curriculum alignment, Curriculum development, Generative AI, Syllabus analysis},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3649217.3653554,
author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
title = {Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653554},
doi = {10.1145/3649217.3653554},
abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {388–393},
numpages = {6},
keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3632620.3671108,
author = {Pawagi, Mrigank and Kumar, Viraj},
title = {Probeable Problems for Beginner-level Programming-with-AI Contests},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671108},
doi = {10.1145/3632620.3671108},
abstract = {To broaden participation, competitive programming contests may include beginner-level problems that do not require knowledge of advanced Computer Science concepts (e.g., algorithms and data structures). However, since most participants have easy access to AI code-generation tools, these problems often become trivial to solve. For beginner-friendly programming contests that do not prohibit the use of AI tools, we propose Probeable Problems: code writing tasks that provide (1)&nbsp;a problem specification that deliberately omits certain details, and (2)&nbsp;a mechanism to probe for these details by asking clarifying questions and receiving immediate feedback. To evaluate our proposal, we conducted a 2-hour programming contest for undergraduate Computer Science students from multiple institutions, where each student was an active member of their institution’s ACM student chapter. The contest comprised of six Probeable Problems for which a popular code-generation tools (e.g., GitHub Copilot) were unable to generate accurate solutions due to the absence of details. Students were permitted to work individually or in groups, and were free to use AI tools. We obtained consent from 26&nbsp;groups (67&nbsp;students) to use their submissions for research. To determine whether Probeable Problems are suitable for such contests, we analyze the extent to which the code submitted by these groups identifies missing details.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {166–176},
numpages = {11},
keywords = {Ambiguity, CS1, Code specifications, Code writing},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3637528.3671489,
author = {Purushotham, Sanjay and Song, Dongjin and Wen, Qingsong and Huan, Jun and Shen, Cong and Zohren, Stefan and Nevmyvaka, Yuriy},
title = {The 10th Mining and Learning from Time Series Workshop: From Classical Methods to LLMs},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671489},
doi = {10.1145/3637528.3671489},
abstract = {Time series data has become ubiquitous across various fields such as healthcare, finance, entertainment, and transportation, driven by advancements in sensing technologies that enable continuous monitoring and recording. This growth in data size and complexity presents new challenges for traditional analysis techniques, necessitating the development of advanced, interdisciplinary temporal mining algorithms. The goals of this workshop are to: (1) highlight significant challenges in learning and mining from time series data, such as irregular sampling, spatiotemporal structures, and uncertainty quantification; (2) discuss recent developments in algorithmic, theoretical, statistical, and systems-based approaches for addressing these challenges, including both classical methods and large language models (LLMs); and (3) synergize research efforts by exploring both new and open problems in time series analysis and mining. This workshop will focus on both the theoretical and practical aspects of time series data analysis, providing a platform for researchers and practitioners from academia, government, and industry to discuss potential research directions, critical technical issues, and present solutions for practical applications. Contributions from related fields such as AI, machine learning, data science, and statistics are also included.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6733–6734},
numpages = {2},
keywords = {forecasting, large language models (llms), temporal data mining, time-series analysis},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3613905.3647967,
author = {Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase},
title = {Enhancing Programming Error Messages in Real Time with Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647967},
doi = {10.1145/3613905.3647967},
abstract = {Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {7},
keywords = {AI, Artificial Intelligence, Automatic Code Generation, CS1, ChatGPT, Codex, Copilot, GPT-4, GitHub, HCI, Introductory Programming, LLM, Large Language Models, Novice Programming, OpenAI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3649409.3691076,
author = {Wiese, Eliane S. and Finnie-Ansley, James and Duran, Rodrigo and Cunningham, Kathryn and Demirtas, Mehmet Arif},
title = {Challenges and Solutions for Teaching Decomposition and Planning Skills in CS1},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691076},
doi = {10.1145/3649409.3691076},
abstract = {The task of decomposing a problem into sub-problems to build a solution, also formalized as planning in prior work, is a key skill for programming expertise. Improving the decomposition and planning skills of novices is shown to be a challenging goal for educators. Moreover, decomposing complex projects into smaller subtasks is an increasingly relevant skill with rapid developments in tools like large language models (LLMs). While there are many aspects of planning, one skill consistently observed in studies with experts is the ability to identify subtasks that can be solved via common code patterns. To support students in acquiring these skills, many researchers have explored explicit instruction about a set of common patterns in programs (i.e. programming plans). However, recent work implies that students may need additional support to fully benefit from such interventions. This panel aims to bring computing education researchers together to discuss the main challenges around teaching decomposition and planning using common patterns, the crucial factors for designing instruction for teaching these concepts, and the impact evolving technology like LLMs can have on these developments.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {291–292},
numpages = {2},
keywords = {cs1, decomposition, large language models, programming plans},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3631802.3631845,
author = {Pirttinen, Nea and Leinonen, Juho},
title = {Could ChatGPT Be Used for Reviewing Learnersourced Exercises?},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631845},
doi = {10.1145/3631802.3631845},
abstract = {Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {42},
numpages = {2},
keywords = {ChatGPT, LLMs, crowdsourcing, generative AI, large language models, learnersourcing, reviews},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3699538.3699567,
author = {Amoozadeh, Matin and Nam, Daye and Prol, Daniel and Alfageeh, Ali and Prather, James and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Amin},
title = {Student-AI Interaction: A Case Study of CS1 students},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699567},
doi = {10.1145/3699538.3699567},
abstract = {Generative artificial intelligence tools (Generative AI), such as ChatGPT, allow users to interact with them in intuitive ways (e.g., conversational) and receive (mostly) good-quality answers. In education, such systems can support students’ learning objectives by providing accessible explanations and examples even when students pose vague queries. But, they also encourage undesired help-seeking behaviors, such as by providing solutions to the students’ homework. Therefore, it is important to better understand how students approach such tools and the potential issues such approaches might present for the learners.In this paper, we present a case study for understanding student-AI collaboration to solve programming tasks in the CS1 introductory programming course. To this end, we recruited a gender-balanced majority non-white set of 15 CS1 students at the University of Houston, a large public university in the US. We observed them solving programming tasks. We used a mixed-method approach to study their interactions as they tackled Python programming tasks, focusing on when and why they used ChatGPT for problem-solving. We analyze and classify the questions submitted by the 15 participants to ChatGPT. Additionally, we analyzed user interaction patterns, their reactions to ChatGPT’s responses, and the potential impacts of Generative AI on their perception of self-efficacy.Our results suggest that, in about a third of the cases, the student attempted to complete the task by submitting the full description of the tasks to ChatGPT without making any effort on their own. We also observed that few students verified their solutions. We discuss the potential implications of these results.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {13},
numpages = {13},
keywords = {Generative Artificial Intelligence, Human-AI Interaction, Self-regulation, CS1, User study, Novice programmers},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3689535.3689546,
author = {Andrei, Oana and Sojtory, Zoltan},
title = {LLM-aided Pair Programming for Algorithm Tracing},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689546},
doi = {10.1145/3689535.3689546},
abstract = {The recent widespread popularity of generative AI models has inspired the development of large-language model (LLM) based tools for educational purposes. We explore the impact of LLM-based tools on pair programming for algorithm tracing with the aim of addressing challenges inherent to pair programming. We designed and developed a GPT-4 based tool, TraceCompanion, that acts as students’ pair programming partner for algorithm tracing. We describe insights gained from running a pilot study to investigate students’ interactions with the tool and their initial perceptions.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {20},
numpages = {1},
keywords = {algorithm tracing, large language models, pair programming},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3650105.3652300,
author = {Wu, Yifan and Li, Ying and Yu, Siyu},
title = {Commit Message Generation via ChatGPT: How Far Are We?},
year = {2024},
isbn = {9798400706097},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650105.3652300},
doi = {10.1145/3650105.3652300},
abstract = {Commit messages concisely describe code changes in natural language and are important for software maintenance. Various automatic commit message generation approaches have been proposed, such as retrieval-based, learning-based, and hybrid approaches. Recently, large language models have shown impressive performance in many natural language processing tasks. Among them, ChatGPT is the most popular one and has attracted wide attention from the software engineering community. ChatGPT demonstrates the ability of in-context learning (ICL), which allows ChatGPT to perform downstream tasks by learning from just a few demonstrations without explicit model tuning. However, it remains unclear how well ChatGPT performs in the commit message generation task via ICL. Therefore, in this paper, we conduct a preliminary evaluation of ChatGPT with ICL on commit message generation. Specifically, we first explore the impact of two key settings on the performance of ICL on commit message generation. Then, based on the best settings, we compare ChatGPT with several state-of-the-art approaches. The results show that a carefully-designed demonstration can lead to substantial improvements for ChatGPT on commit message generation. Furthermore, ChatGPT outperforms all the retrieval-based and learning-based approaches in terms of BLEU, METEOR, ROUGE-L, and Cider, and is comparable to hybrid approaches. Based on our findings, we outline several open challenges and opportunities for ChatGPT-based commit message generation.},
booktitle = {Proceedings of the 2024 IEEE/ACM First International Conference on AI Foundation Models and Software Engineering},
pages = {124–129},
numpages = {6},
keywords = {commit message generation, large language model, in-context learning},
location = {Lisbon, Portugal},
series = {FORGE '24}
}

@inproceedings{10.1145/3643787.3648032,
author = {Shome, Arumoy and Cruz, Luis and Van Deursen, Arie},
title = {Towards Automatic Translation of Machine Learning Visual Insights to Analytical Assertions},
year = {2024},
isbn = {9798400705762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643787.3648032},
doi = {10.1145/3643787.3648032},
abstract = {We present our vision for developing an automated tool capable of translating visual properties observed in Machine Learning (ML) visualisations into Python assertions. The tool aims to streamline the process of manually verifying these visualisations in the ML development cycle, which is critical as real-world data and assumptions often change post-deployment. In a prior study, we mined 54, 070 Jupyter notebooks from Github and created a catalogue of 269 semantically related visualisation-assertion (VA) pairs. Building on this catalogue, we propose to build a taxonomy that organises the VA pairs based on ML verification tasks. The input feature space comprises of a rich source of information mined from the Jupyter notebooks---visualisations, Python source code, and associated markdown text. The effectiveness of various AI models, including traditional NLP4Code models and modern Large Language Models, will be compared using established machine translation metrics and evaluated through a qualitative study with human participants. The paper also plans to address the challenge of extending the existing VA pair dataset with additional pairs from Kaggle and to compare the tool's effectiveness with commercial generative AI models like ChatGPT. This research not only contributes to the field of ML system validation but also explores novel ways to leverage AI for automating and enhancing software engineering practices in ML.},
booktitle = {Proceedings of the Third ACM/IEEE International Workshop on NL-Based Software Engineering},
pages = {29–32},
numpages = {4},
keywords = {SE4AI, NLP4Code, ML testing, visualisations, assertions, computational notebooks, automated tool},
location = {Lisbon, Portugal},
series = {NLBSE '24}
}

@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@article{10.1145/3660809,
author = {Oueslati, Khouloud and Laberge, Gabriel and Lamothe, Maxime and Khomh, Foutse},
title = {Mining Action Rules for Defect Reduction Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660809},
doi = {10.1145/3660809},
abstract = {Defect reduction planning plays a vital role in enhancing software quality and minimizing software maintenance costs. By training a black box machine learning model and “explaining” its predictions, explainable AI for software engineering aims to identify the code characteristics that impact maintenance risks. However, post-hoc explanations do not always faithfully reflect what the original model computes. In this paper, we introduce CounterACT, a Counterfactual ACTion rule mining approach that can generate defect reduction plans without black-box models. By leveraging action rules, CounterACT provides a course of action that can be considered as a counterfactual explanation for the class (e.g., buggy or not buggy) assigned to a piece of code. We compare the effectiveness of CounterACT with the original action rule mining algorithm and six established defect reduction approaches on 9 software projects. Our evaluation is based on (a) overlap scores between proposed code changes and actual developer modifications; (b) improvement scores in future releases; and (c) the precision, recall, and F1-score of the plans. Our results show that, compared to competing approaches, CounterACT’s explainable plans achieve higher overlap scores at the release level (median 95%) and commit level (median 85.97%), and they offer better trade-off between precision and recall (median F1-score 88.12%). Finally, we venture beyond planning and explore leveraging Large Language models (LLM) for generating code edits from our generated plans. Our results show that suggested LLM code edits supported by our plans are actionable and are more likely to pass relevant test cases than vanilla LLM code recommendations.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {102},
numpages = {23},
keywords = {Action rule mining, Counterfactual explanations, Defect reduction planning, Explainability, Software analytics}
}

@inproceedings{10.1145/3626253.3635609,
author = {Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges},
title = {Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635609},
doi = {10.1145/3626253.3635609},
abstract = {Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1752–1753},
numpages = {2},
keywords = {discussion forum, educational tools, natural language processing},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3649884,
author = {Ren, Yuqing and Clement, Jeffrey},
title = {Augmenting Human Teams with Robots in Knowledge Work Settings: Insights from the Literature},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
url = {https://doi.org/10.1145/3649884},
doi = {10.1145/3649884},
abstract = {Recent developments in large language models open doors for Artificial Intelligence and robots to augment knowledge workers and teams in a variety of domains, such as customer service, data science, legal work, and software development. In this article, we review 317 articles from multiple disciplines and summarize the insights in a theoretical framework linking key robot attributes to human perceptions and behaviors. The robot attributes include embodiment, nonverbal and verbal communication, perceived gender and race, emotions, perceived personality, and competence. The outcomes include human perceptions, acceptance, engagement, compliance, trust, and willingness to help. We identify four differences between one human and one robot settings and team settings and use them as the springboard to generalize insights from the literature review to the design and impact of a robot in assisting humans in knowledge work teams. We report two high-level observations around the interplay among robot attributes and context dependent designs and discuss their implications.},
journal = {J. Hum.-Robot Interact.},
month = jun,
articleno = {20},
numpages = {34},
keywords = {Human-robot interaction, Generative AI, robot design, human robot team}
}

@inproceedings{10.1145/3649217.3653570,
author = {Frazier, Matthew and Damevski, Kostadin and Pollock, Lori},
title = {Customizing ChatGPT to Help Computer Science Principles Students Learn Through Conversation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653570},
doi = {10.1145/3649217.3653570},
abstract = {This paper explores leveraging conversational agents, specifically ChatGPT, to enhance the introduction of computing, focused on the Advanced Placement Computer Science Principles (CSP) course in secondary schools. Despite the potential benefits for diverse student audiences, little research has investigated their effectiveness and engagement in this context. We examine the customization of ChatGPT for secondary school CSP students, assessing its impact on exploratory searches for learning CSP concepts. Results from 20 high school students in grades 10-12 (ages 15-18) in a CSP course indicate that students preferred a customized ChatGPT, with its terminology more suitable to secondary school level, examples more understandable, and better connections to personal experiences compared to standard ChatGPT.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {633–639},
numpages = {7},
keywords = {chatgpt, computer science principles, conversational agent, exploratory search},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3663529.3663846,
author = {Zhang, Xuchao and Ghosh, Supriyo and Bansal, Chetan and Wang, Rujia and Ma, Minghua and Kang, Yu and Rajmohan, Saravan},
title = {Automated Root Causing of Cloud Incidents using In-Context Learning with GPT-4},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663846},
doi = {10.1145/3663529.3663846},
abstract = {Root Cause Analysis (RCA) plays a pivotal role in the incident diagnosis process for cloud services, requiring on-call engineers to identify the primary issues and implement corrective actions to prevent future recurrences. Improving the incident RCA process is vital for minimizing service downtime, customer impact and manual toil. Recent advances in artificial intelligence have introduced state-of-the-art Large Language Models (LLMs) like GPT-4, which have proven effective in tackling various AIOps problems, ranging from code authoring to incident management. Nonetheless, the GPT-4 model’s immense size presents challenges when trying to fine-tune it on user data because of the significant GPU resource demand and the necessity for continuous model fine-tuning with the emergence of new data. To address the high cost of fine-tuning LLM, we propose an in-context learning approach for automated root causing, which eliminates the need for fine-tuning. We conduct extensive study over 100,000 production incidents from Microsoft, comparing several large language models using multiple metrics. The results reveal that our in-context learning approach outperforms the previous fine-tuned large language models such as GPT-3 by an average of 24.8% across all metrics, with an impressive 49.7% improvement over the zero-shot model. Moreover, human evaluation involving actual incident owners demonstrates its superiority over the fine-tuned model, achieving a 43.5% improvement in correctness and an 8.7% enhancement in readability. The impressive results demonstrate the viability of utilizing a vanilla GPT model for the RCA task, thereby avoiding the high computational and maintenance costs associated with a fine-tuned model.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {266–277},
numpages = {12},
keywords = {In-context Learning, Incident Diagnosis, Large Language Model, Root Cause Analysis},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3658644.3690306,
author = {Wen, Rui and Li, Zheng and Backes, Michael and Zhang, Yang},
title = {Membership Inference Attacks Against In-Context Learning},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690306},
doi = {10.1145/3658644.3690306},
abstract = {Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3481–3495},
numpages = {15},
keywords = {in-context learning, large language models, membership inference attacks},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3654777.3676347,
author = {Tang, Xiaohang and Wong, Sam and Pu, Kevin and Chen, Xi and Yang, Yalong and Chen, Yan},
title = {VizGroup: An AI-assisted Event-driven System for Collaborative Programming Learning Analytics},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676347},
doi = {10.1145/3654777.3676347},
abstract = {Programming instructors often conduct collaborative learning activities, like Peer Instruction, to foster a deeper understanding in students and enhance their engagement with learning. These activities, however, may not always yield productive outcomes due to the diversity of student mental models and their ineffective collaboration. In this work, we introduce VizGroup, an AI-assisted system that enables programming instructors to easily oversee students’ real-time collaborative learning behaviors during large programming courses. VizGroup leverages Large Language Models (LLMs) to recommend event specifications for instructors so that they can simultaneously track and receive alerts about key correlation patterns between various collaboration metrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors in a comparison study using a dataset collected from a Peer Instruction activity that was conducted in a large programming lecture. The results showed that VizGroup helped instructors effectively overview, narrow down, and track nuances throughout students’ behaviors.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {93},
numpages = {22},
keywords = {Collaborative Learning, Programming Education},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3613905.3637148,
author = {Abolnejadian, Mohammad and Alipour, Sharareh and Taeb, Kamyar},
title = {Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3637148},
doi = {10.1145/3613905.3637148},
abstract = {In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student’s educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students’ backgrounds while respecting their privacy. The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase. This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {521},
numpages = {8},
keywords = {CS1, ChatGPT, Course Design, Introductory Programming, LLM, Learning Platform, Prompt Engineering},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3626253.3633407,
author = {Westerlund, Jill and Czajka, Sandra and Kuemmel, Andrew},
title = {Innovative Strategies for genAI in CS Courses},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633407},
doi = {10.1145/3626253.3633407},
abstract = {Students are using generative artificial intelligence (genAI), organizations are embracing AI and machine learning, tools are emerging almost daily, and addressing these evolving technologies can be overwhelming. Rather than choosing to ignore genAI, instructors of computer science (CS) can find ways to teach with and guide students in the use of genAI in their courses. Teaching about genAI can be incorporated with instruction about effective and appropriate uses of the ever-growing tools.This special session brings together three experienced CS educators who integrate genAI in their work with high school students, college students, and in-service teachers. The session environment allows for participant involvement in three model activities that showcase genAI tools with learner-focused practices. Participants will be provided supporting teaching resources for each guided activity and encouraged to discuss with peers and presenters.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1875–1876},
numpages = {2},
keywords = {ai, assessment, genai, instruction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626203.3670628,
author = {Oelgoetz, Megan and Walker, Tony},
title = {Improving an NSF ACCESS Program AI Chatbot: Response Data Logistic Regression},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670628},
doi = {10.1145/3626203.3670628},
abstract = {The NSF ACCESS program has implemented a vendor-supplied AI chatbot using the OpenAI GPT-4 large language model. ACCESS provides high performance computing (HPC) resources to researchers by allocating time at computing centers at diverse institutions of higher education across the United States. Effectively implementing a large language model on a limited knowledge base for the diversity of the resources and technical nature of HPC in general has raised questions in optimal knowledge base construction. The following analysis takes a limited test case to investigate the driving factors contributing to the accuracy of the chatbot’s response to predetermined prompts, specifically regarding the clusters on which specific software applications are currently available. It additionally tests the necessity of providing documentation of synonymous terms in the form of a synonym dictionary in the knowledge base. While ongoing, this initial research utilizing logistic regression suggests the knowledge base is yet insufficient for the prompts given and that the synonym dictionary has no statistically significant effect on the response.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {101},
numpages = {3},
keywords = {Artificial Intelligence, HPC Facilitation, Logistic Regression, Natural Language Processing},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3627508.3638345,
author = {Roegiest, Adam and Pinkosova, Zuzana},
title = {Generative Information Systems Are Great If You Can Read},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627508.3638345},
doi = {10.1145/3627508.3638345},
abstract = {Generative models, especially in information systems like ChatGPT and Bing Chat, have become increasingly integral to our daily lives. Their significance lies in their potential to revolutionize how we access, process, and generate information &nbsp;[44]. However, a gap exists in ensuring these systems are accessible to all, especially considering the literacy challenges faced by a significant portion of the population in (but not limited to) English-speaking countries. This paper aims to investigate the “readability’’ of generative information systems and their accessibility barriers, particularly for those with literacy challenges. Using popular instruction fine-tuning datasets, we found that this training data could produce systems that generate at a college level, potentially excluding a large demographic. Our research methods involved analyzing the responses of popular Large Language Models (LLMs) and examining potential biases in how they can be trained. The key message is the urgent need for inclusivity in systems incorporating generative models, such as those studied by the Information Retrieval (IR) community. Our findings indicate that current generative systems might not be accessible to individuals with cognitive and literacy challenges, emphasizing the importance of ensuring that advancements in this field benefit everyone. By situating our research within the sphere of information seeking and retrieval, we underscore the essential role of these technologies in augmenting accessibility and efficiency of information access, thereby broadening their reach and enhancing user engagement.},
booktitle = {Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
pages = {165–177},
numpages = {13},
location = {Sheffield, United Kingdom},
series = {CHIIR '24}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3640544.3645215,
author = {Laney, Mason and Dewan, Prasun},
title = {Human-AI Collaboration in a Student Discussion Forum},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645215},
doi = {10.1145/3640544.3645215},
abstract = {The recent public releases of AI tools such as ChatGPT have forced computer science educators to reconsider how they teach. These tools have demonstrated considerable ability to generate code and answer conceptual questions, rendering them incredibly useful for completing CS coursework. While overreliance on AI tools could hinder students’ learning, we believe they have the potential to be a helpful resource for both students and instructors alike. We propose a novel system for instructor-mediated GPT interaction in a class discussion board. By automatically generating draft responses to student forum posts, GPT can help Teaching Assistants (TAs) respond to student questions in a more timely manner, giving students an avenue to receive fast, quality feedback on their solutions without turning to ChatGPT directly. Additionally, since they are involved in the process, instructors can ensure that the information students receive is accurate, and can provide students with incremental hints that encourage them to engage critically with the material, rather than just copying an AI-generated snippet of code. We utilize Piazza—a popular educational forum where TAs help students via text exchanges—as a venue for GPT-assisted TA responses to student questions. These student questions are sent to GPT-4 alongside assignment instructions and a customizable prompt, both of which are stored in editable instructor-only Piazza posts. We demonstrate an initial implementation of this system, and provide examples of student questions that highlight its benefits.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {74–77},
numpages = {4},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3649217.3653612,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653612},
doi = {10.1145/3649217.3653612},
abstract = {Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {52–58},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, code llama, generative ai, gpt-4, large language models, llm-as-a-judge, llms, open source, programming feedback, zephyr},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3701625.3701684,
author = {Oran, Ana Carolina and Montenegro, Let\'{\i}cia Braga and Schuster, Hellmut Alencar and Duarte, Jos\'{e} Carlos and Silva, Williamson and Lima, Rayfran Rocha},
title = {Integrating ChatGPT in Project Management Education: Benefits and Challenges in the Academic Environment},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701684},
doi = {10.1145/3701625.3701684},
abstract = {CONTEXT: Teaching project management is complex, and students often do not feel engaged or motivated. Professors can use many initiatives to improve the teaching and learning process. Tools like ChatGPT, when integrated into education, have generated considerable interest due to their potential to enrich students’ learning experiences. GOAL: This paper analyzes the impacts of using ChatGPT as a complementary tool in teaching Project Management in the Software Engineering course, highlighting its benefits and challenges. METHOD: We performed an exploratory study to identify the effects of using ChatGPT in teaching project management, evaluating learning, productivity, teamwork, student perceptions, and future expectations. RESULTS: The results indicate that ChatGPT contributed to improving content comprehension, developing critical skills, accelerating production, improving collaboration and communication, and increasing student engagement. However, challenges related to misuse and dependence on the tool were also identified. CONCLUSION: The integration of ChatGPT in teaching project management has shown promise, promoting a richer and more collaborative learning experience. The insights obtained provide directions for future implementations and research on the use of AI in project management education.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {596–604},
numpages = {9},
keywords = {Project management education, Software project management, ChatGPT, AI-assisted learning, Software engineering},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3649409.3691089,
author = {Gupta, Anisha and Monahan, Robert and Vandenberg, Jessica and Smith, Andy and Elsayed, Rasha and Fox, Kimkinyona and Minogue, James and Oliver, Kevin and Hubbard Cheuoua, Aleata and Ringstaff, Cathy and Mott, Bradford},
title = {Leveraging Large Language Models for Automated Assessment of Elementary Students' Block-Based Narrative Programs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691089},
doi = {10.1145/3649409.3691089},
abstract = {Recent years have seen increasing awareness of the need to engage young learners in computational thinking (CT). Integrating digital storytelling, where students create short narratives, and CT offers significant potential for promoting interdisciplinary learning for students; however, it is critical to provide both teachers and students with automated support. A promising approach for enabling support is to leverage advances in Large Language Models (LLMs), which have demonstrated considerable potential for assessing both programming and natural language artifacts. In this work, we investigate the capabilities of LLMs to automatically assess student-created block-based programs developed using a narrative-centered learning environment that engages upper elementary students (ages 9 to 11) in learning CT and physical science through the creation of interactive science narratives. Using the narrative programs created by 28 students, we explore the efficacy of LLMs to assess the programs across two dimensions.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {318–319},
numpages = {2},
keywords = {k-12 education, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626253.3635432,
author = {Edwards, Katlyn and Scalisi, Corrie and DeMars-Smith, Julianne and Lee, Key},
title = {Google Colab for Teaching CS and ML},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635432},
doi = {10.1145/3626253.3635432},
abstract = {Colab is a frictionless, hosted Jupyter notebook that combines text, code, and outputs into a single document. Colab allows anybody to write and execute arbitrary python code using the latest ML accelerators (GPU/TPUs) through the browser, no setup required. It is especially well suited to machine learning, data analysis and education, and serves over 10 million active users. Colab is used extensively for teaching computer science and machine learning, giving equitable access to expensive resources and AI/ML instruction to students around the world, regardless of background. As one professor stated: ''There's an equity aspect. Not everyone has a high-end laptop. Being able to say everyone has the same computing experience and they all have access to the same resources and they can start using them right away, it allows us to find more talent randomly distributed around our student population. Colab has been the best solution so far.'' Additionally, Google Colab partners with Google DeepMind to launch innovative AI coding features and models to the public, giving users the ability to author code with natural language, a much simpler experience for writing code. We are the team who builds Colab, and would love to demo our latest features, including Google Classroom integration and AI coding using Gemini, Google's latest foundation AI model. We hope to make attendees aware of these features and have them give us feedback on their usefulness and impact on the process of teaching computer science and machine learning.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1925},
numpages = {1},
keywords = {ai, colab, jupyter},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3690099,
author = {Pang, Amy and Padiyath, Aadarsh and Viramontes Vargas, Diego and Ericson, Barbara Jane},
title = {Examining the Relationship between Socioeconomic Status and Beliefs about Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690099},
doi = {10.1145/3649165.3690099},
abstract = {Research on students' use of large language models (LLMs) in academic settings has increased recently, focusing on usage patterns, tasks, and instructor policies. However, there is limited research on the relationships between students' socioeconomic backgrounds, perceptions, and usage of these resources. As socioeconomic factors may shape students' approach to learning, it is important to understand their impact on students' perceptions and attitudes towards emerging technologies like LLMs. Thus, we analyzed a quantitative and internally consistent student survey (N=144) and qualitative interview (N=2) responses of students taking an undergraduate-level programming course at a public university for correlations between socioeconomic background, attitudes towards LLMs, and LLM usage. Regression analysis found a significant positive association between socioeconomic status (SES) and belief that LLM use will lead to career success. Qualitative interviews suggested low-SES students perceived LLMs as helpful tools for debugging and learning concepts, but not as a significant factor in long-term career success. Rather, programming knowledge itself was still paramount for career success. Our findings contribute to our understanding of the complex influences social and cultural factors have on students' perceptions and attitudes towards LLMs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {172–178},
numpages = {7},
keywords = {large language models, socioeconomic status, student attitudes},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3699538.3699569,
author = {Jegourel, Cyrille and Ong, Jung Yi and Kurniawan, Oka and Meng Shin, Lim and Chitluru, Kushat},
title = {Sieving Coding Assignments Over Submissions Generated by AI and Novice Programmers},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699569},
doi = {10.1145/3699538.3699569},
abstract = {In the era of AI tools like ChatGPT and GitHub Copilot, and with the numerous online resources, computer science education faces the challenge of students potentially submitting plagiarised coding assignments or assignments generated by these technologies. Distinguishing between AI-generated and human-written text is notoriously difficult. In this study, we applied two text distance algorithms, commonly used for machine translation and document comparisons, to detect similarities between various computer Python code submissions and employed hierarchical clustering to analyze them from both AI tools and human programmers. Our results indicate that the distances to the cluster representatives can effectively predict whether a code submission is generated by AI or by novice programmers, achieving an accuracy of over 90%. These findings demonstrate the significant potential of text distance algorithms in identifying the origin of coding submissions, whether generated by AI or by novice programmers.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {12},
numpages = {11},
keywords = {Computing education, code distance, AI code generation, hierarchical clustering, plagiarism, code clone detection},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3675812.3675837,
author = {Yan, ZhenTing and Zhang, Rui and Jia, Fei},
title = {Exploring the Potential of Large Language Models as a Grading Tool for Conceptual Short-Answer Questions in Introductory Physics},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675837},
doi = {10.1145/3675812.3675837},
abstract = {Large language models (LLMs) have shown remarkable capabilities in various natural language tasks, raising the question of their potential as grading tools in physics education. This study explores the potential of LLMs as grading tools in physics education, focusing on their efficacy in assessing conceptual short-answer questions. These questions, pivotal in physics learning, require understanding rather than computation, aligning well with LLMs' text-processing strengths. In this work, we employed GPT-4 to grade a set of conceptual questions from Introductory Physics, encompassing different cognitive domains. Our approach involved comparing LLM grading with human evaluations, using correlation and classification methodologies. Additionally, we investigated the impact of reference answers with varying levels of detail and explanation on LLMs' grading performance and discriminative ability. The results show that LLMs can grade lower cognitive level questions reliably and accurately, regardless of the reference answers. However, LLMs face a trade-off when grading higher cognitive level questions: more detailed reference answers help them align with human standards, but these answers may also limit their recognition of diverse valid responses. The research provides novel insights into the potential and challenges of using LLMs as grading tools in physics education.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {308–314},
numpages = {7},
keywords = {Automated Grading, Cognitive Abilities, Conceptual Physics Questions, Generative Pre-trained Transformer (GPT), Large Language Models (LLMs)},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3702250.3702263,
author = {Totade, Sanjot Sagar and Babu, Nithin C and Rao, Shika and Soundararajan, Rajiv},
title = {Internal Embeddings of Multi-modal LLMs as Generalizable Representations for Image Quality Assessment},
year = {2025},
isbn = {9798400710759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702250.3702263},
doi = {10.1145/3702250.3702263},
abstract = {One of the major challenges in no-reference (NR) image quality assessment (IQA) is the ability to generalize to diverse quality assessment applications. Recently, multi-modal vision-language models are found to be very promising in this direction. They are beginning to form a part of several state of the art NR IQA methods. On the other hand, multi-modal large language models (LLMs) are increasingly being studied for various computer vision applications including IQA. In this work, we perform a thorough study of the ability of multi-modal LLMs for NR IQA by training some of its components and testing for its generalizability. In particular, we keep the LLM frozen and learn parameters corresponding to the querying transformer, LLM prompt and some layers that process the embedding output by the LLM. We observe that some of these components offer a generalization performance far superior to any existing NR IQA algorithm.},
booktitle = {Proceedings of the Fifteenth Indian Conference on Computer Vision Graphics and Image Processing},
articleno = {13},
numpages = {9},
keywords = {Image quality assessment, large language models},
location = {
},
series = {ICVGIP '24}
}

@inproceedings{10.1145/3597503.3639177,
author = {Wei, Moshi and Harzevili, Nima Shiri and Huang, Yuekai and Yang, Jinqiu and Wang, Junjie and Wang, Song},
title = {Demystifying and Detecting Misuses of Deep Learning APIs},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639177},
doi = {10.1145/3597503.3639177},
abstract = {Deep Learning (DL) libraries have significantly impacted various domains in computer science over the last decade. However, developers often face challenges when using the DL APIs, as the development paradigm of DL applications differs greatly from traditional software development. Existing studies on API misuse mainly focus on traditional software, leaving a gap in understanding API misuse within DL APIs. To address this gap, we present the first comprehensive study of DL API misuse in TensorFlow and PyTorch. Specifically, we first collected a dataset of 4,224 commits from the top 200 most-starred projects using these two libraries and manually identified 891 API misuses. We then investigated the characteristics of these misuses from three perspectives, i.e., types, root causes, and symptoms. We have also conducted an evaluation to assess the effectiveness of the current state-of-the-art API misuse detector on our 891 confirmed API misuses. Our results confirmed that the state-of-the-art API misuse detector is ineffective in detecting DL API misuses. To address the limitations of existing API misuse detection for DL APIs, we propose LLMAPIDet, which leverages Large Language Models (LLMs) for DL API misuse detection and repair. We build LLMAPIDet by prompt-tuning a chain of ChatGPT prompts on 600 out of 891 confirmed API misuses and reserve the rest 291 API misuses as the testing dataset. Our evaluation shows that LLMAPIDet can detect 48 out of the 291 DL API misuses while none of them can be detected by the existing API misuse detector. We further evaluate LLMAPIDet on the latest versions of 10 GitHub projects. The evaluation shows that LLMAPIDet can identify 119 previously unknown API misuses and successfully fix 46 of them.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {201},
numpages = {12},
keywords = {API misuse, deep learning APIs, empirical study, detection},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3639474.3640058,
author = {Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
title = {Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640058},
doi = {10.1145/3639474.3640058},
abstract = {Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {221–232},
numpages = {12},
keywords = {QLCs, large language models, artificial intelligence, introductory programming, program comprehension},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@article{10.5555/3715622.3715635,
author = {Al-Nsour, Rawan},
title = {AI Tools in Matlab Course Education: Instructor Point of View},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {This work aims to investigate the influence of AI tools, specifically ChatGPT, on assignment submissions for an undergraduate programming course. The study evaluates the variance between MATLAB code submissions supported by ChatGPT and those based solely on traditional classroom resources such as instructor notes, textbooks, and class exercises. By analyzing these differences, the research seeks to highlight the advantages of using AI as an assistant tool, including enhanced efficiency and personalized feedback. However, it also examines the drawbacks, such as potential over-reliance on AI and its impact on achieving students' learning goals. Additionally, the study provides recommendations on how to manage and integrate this new technology effectively to ensure that it complements rather than detracts from the educational experience. Through this comprehensive evaluation, the paper seeks to offer insights into balancing AI assistance with traditional teaching methods to optimize learning outcomes in programming education.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {95–104},
numpages = {10}
}

@inproceedings{10.1145/3626253.3633433,
author = {Liu, Rongxin and Zenke, Carter and Lloyd, Doug and Malan, David J.},
title = {Teaching with AI (GPT)},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633433},
doi = {10.1145/3626253.3633433},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. We plan to share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1902},
numpages = {1},
keywords = {ai, artificial intelligence, chatgpt, ethics, generative ai, gpt, programming, prompt, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3698038.3698535,
author = {Fu, Xinwei and Zhang, Zhen and Fan, Haozheng and Huang, Guangtai and El-Shabani, Mohammad and Huang, Randy and Solanki, Rahul and Wu, Fei and Diamant, Ron and Wang, Yida},
title = {Distributed Training of Large Language Models on AWS Trainium},
year = {2024},
isbn = {9798400712869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698038.3698535},
doi = {10.1145/3698038.3698535},
abstract = {Large language models (LLMs) are ubiquitously powerful but prohibitively expensive to train, often requiring thousands of compute devices, typically GPUs. To reduce the cost of training LLMs for customers, Amazon Web Services (AWS) launched the Amazon EC2 trn1 instances, powered by AWS Trainium, an Amazon's homegrown deep learning accelerator, as an alternative to distributed LLM training. The trn1 instances provide a high-performance LLM training solution at a lower cost compared to their GPU-based counterpart, the p4d instances, which are powered by Nvidia A100 GPUs. This paper describes the design and development of the Neuron Distributed Training Library, a component of the AWS Neuron SDK, which enables distributed training of large language models on AWS Trainium. Neuron Distributed Training Library supports a variety of existing distributed training techniques with unified interfaces, and provides features to address trn1-specific challenges as well. Our evaluation shows that trn1 instances, specifically the trn1.32xlarge, achieve better or comparable performance (up to 24.6% improvement) while offering significant lower costs (up to 46.3% cost saving) in selected workloads when compared to p4d.24xlarge instances. As a result, AWS Trainium has been adopted for training numerous external and internal models, showcasing its high-performance and cost-effectiveness. Several supported open-source LLMs are accessible via HuggingFace Optimum Neuron.},
booktitle = {Proceedings of the 2024 ACM Symposium on Cloud Computing},
pages = {961–976},
numpages = {16},
keywords = {AWS Trainium, Distributed Training, Large Language Model, Neuron SDK},
location = {Redmond, WA, USA},
series = {SoCC '24}
}

@inproceedings{10.1145/3649217.3653568,
author = {del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Automating Personalized Parsons Problems with Customized Contexts and Concepts},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653568},
doi = {10.1145/3649217.3653568},
abstract = {Parsons problems provide useful scaffolding for introductory programming students learning to write code. However, generating large numbers of high-quality Parsons problems that appeal to the diverse range of interests in a typical introductory course is a significant challenge for educators. Large language models (LLMs) may offer a solution, by allowing students to produce on-demand Parsons problems for topics covering the breadth of the introductory programming curriculum, and targeting thematic contexts that align with their personal interests. In this paper, we introduce PuzzleMakerPy, an educational tool that uses an LLM to generate unlimited contextualized drag-and-drop programming exercises in the form of Parsons Problems, which introductory programmers can use as a supplemental learning resource. We evaluated PuzzleMakerPy by deploying it in a large introductory programming course, and found that the ability to personalize the contextual framing used in problem descriptions was highly engaging for students, and being able to customize the programming topics was reported as being useful for their learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {688–694},
numpages = {7},
keywords = {cs education tools, cs1, large language models, parsons problems, personalized learning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649409.3691074,
author = {Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany},
title = {Ethical Implications of Gen-AI and LLMs in Computing Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691074},
doi = {10.1145/3649409.3691074},
abstract = {The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {293–294},
numpages = {2},
keywords = {ChatGPT, curriculum design, ethics, generative AI, large language models, responsibility},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626203.3670588,
author = {Stevens, Cody and Anderson, Sean and Carlson, Adam},
title = {Integrating High Performance Computing into Higher Education and the Pedagogy of Cluster Computing},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670588},
doi = {10.1145/3626203.3670588},
abstract = {Despite the exponential growth in demand for advanced computational skills driven by big data, machine learning, and artificial intelligence, higher education institutions still face a significant shortage of dedicated course offerings pertaining to High Performance Computing (HPC). This educational deficiency not only hampers the preparedness of undergraduate students for cutting-edge postgraduate programs but also impairs their readiness to enter a dynamic workforce increasingly reliant on sophisticated computational capabilities. Integrating comprehensive HPC courses at the undergraduate level is critical for equipping students with expertise to effectively utilize modern computing technologies, and also for bridging the growing gap between academic preparation and industry demands. At Wake Forest University (WFU), we, members of the HPC Team, are actively working to address the educational gap in HPC by integrating the WFU HPC Facility[4] into higher-level elective courses across various disciplines. Recognizing the foundational importance of these skills, we have developed an introductory course specifically designed to equip students with the knowledge to excel in advanced courses, in graduate and research programs, and to meet the demands of the modern workforce. By integrating the WFU HPC Facility into our curriculum, the University is committed to pioneering a comprehensive educational pathway that empowers students to leverage the full potential of computing technologies in their future careers. WFU is an R-2 liberal arts institution with around 9,000 students[6] that actively supports undergraduate research through a multitude of departments and programs. Undergraduate research is so paramount to the University mission, that WFU has a dedicated center, the Undergraduate Research and Creative Activities (URECA) Center, just for this purpose. Many students engage in research projects that leverage the resources of the WFU HPC Facility. The facility’s main asset, the Distributed Environment for Academic Computing (DEAC) Cluster, contains approximately 4000 CPU cores and 20TB of RAM, and is a true interdisciplinary tool; in 2023 it was utilized by 15 departments and 500 active users to submit over 1.5 million computational tasks on a vast array of research topics. The interdisciplinary nature of the DEAC Cluster played an instrumental role in developing an introductory course in HPC that caters to students from a diverse number of majors. Having supported a wide range of researchers, we designed the course to bridge concepts and applications from Computer Science, Engineering, Data Science, and the Natural Sciences to their respective academic domains. By enabling students from multiple disciplines to access foundational HPC skills, we foster a versatile educational environment where collaborative and interdisciplinary learning thrives. One way that we ensure our introductory course is accessible to all students is that we do not require any prerequisite classes to enroll in the course. Students are also not expected to have any prior experience in programming. We have chosen Python as the primary programming language for the course, as it is one of the most versatile and widely-used languages in the fields of data science and machine learning, and can easily interface with parallel frameworks such as MPI and OpenMP. Students gain hands-on experience by developing asynchronous workflows, which are then executed on the DEAC Cluster. This practical focus not only demystifies complex computational concepts but also empowers students to apply their learning in real-world scenarios. HPC serves as a cornerstone for two distinct user groups, each integral to its advancement and application. The first encompasses those who enable and optimize HPC systems, including Computer Scientists, Computer Engineers, Systems Administrators, and Cyberinfrastructure Professionals, who enhance computational efficiency and build the underlying hardware infrastructure. The second group comprises scientists and researchers across diverse fields such as Statistics, Chemistry, Biology, Physics, Engineering, and more, who leverage HPC as a powerful tool for simulating complex phenomena, analyzing large datasets, and researching novel problems in their respective domains. While current course offerings at other institutions seem to prioritize the first group and educate students on how to build and enable an HPC cluster, we have chosen to prioritize curriculum for the second group as the skills they gain through our course’s curriculum will help them as they continue their academic career in higher level electives and independent research projects with faculty advisors. We choose to offer our course during the Spring semester in order to prepare students who may want to pursue research during the summer session. The first half of the course serves as foundational cluster training, familiarizing students with essential skills to work within an HPC environment. In this segment, students delve into the Linux command line interface (CLI) using Bashcrawl[3] and explore the intricacies of the Linux filesystem and environment modules. A significant focus is placed on understanding and utilizing job schedulers, such as the Slurm resource manager[2]. Another unique feature of this segment is the guided tour of the Wake Forest datacenter. This tour provides students with a tangible understanding of how the theoretical concepts discussed in class are implemented in a real-world HPC cluster. To further provide a reference to the resources requested for their jobs through Slurm, the tour concludes with students disassembling retired compute nodes to learn about the different components that comprise modern servers. The midterm assessment challenges students to submit multiple jobs, analyzing the effects of varying input sizes and the use of multiple CPU processors on calculation speed. Upon completion of this initial phase, students are fully equipped to engage in research activities under an advisor and effectively utilize an HPC cluster outside the confines of the classroom. Many apply for summer grants through the aforementioned URECA program with a faculty advisor. In the latter half of the course, the curriculum shifts towards more advanced topics, focusing on parallel computing frameworks and technologies. Students are introduced to MPI and OpenMP, which are essential for developing parallel applications that can run efficiently on today’s multi-processor systems. Additionally, the course delves into high-speed interconnects, crucial for optimizing communication between different parts of an HPC cluster. One of our final topics covers GPU computing, with a particular emphasis on using NVIDIA GPUs and the CUDA programming platform, enabling students to harness the power of graphical processing for computational tasks. As an example from our Spring 2024 semester, students built a “chatbot” using Meta’s Llama 2 model[5] on both CPU and GPU using LLaMA C++[1], and compared its performance to ChatGPT while interacting freely with it. Our course is designed to complement other specialized courses found in Computer Science or in Computer Engineering programs, such as Parallel Algorithms, Computer Vision, or Deep Learning. It aims to introduce these critical computational concepts and provide a solid foundation that prepares students for these more advanced electives. By the end of the course, students are not only familiar with the basic principles of HPC but are also primed to tackle more specialized studies and research in their future academic and professional pursuits. It is not uncommon that a course may require students to use a specific programming language or software. While there are tools such as Google Colab and zyBooks that provide a browser-based interface to computing resources, those tools can be very limited in what resources they can provide. A faculty member might then want students to install software locally on their laptop, but this can be challenging when students bring their own device to the classroom as they may be running different operating systems or may have different hardware platforms. This can cause the software to behave differently or it may not even be available on that given platform. Courses with significant computational demands are better served utilizing a unified computing environment, and an HPC facility is ideally equipped to provide a consistent learning environment where each student has access to the same software and computing resources. A primary challenge in integrating HPC resources into coursework is instructing students on the use of schedulers for asynchronous workloads. Our introductory HPC course effectively bridges this gap by providing the necessary training and context, enabling students to engage with advanced topics more efficiently, without the steep initial learning curve typically associated with these environments. Our HPC facility has proven instrumental in enhancing educational experiences across a variety of disciplines, demonstrating significant benefits in classes such as Statistics, Natural Language Processing, Parallel Algorithms, Computer Vision, Physics Laboratory, Cancer Biology, Environmental Physics, Computational Modeling, and more. Moreover, students in fields like Finance and Business and Enterprise Management have also successfully leveraged our HPC resources, and have performed analysis on client data that was protected under a nondisclosure agreement which prevented students from storing the data locally on their laptop or with commercial cloud providers. This integration not only facilitates sophisticated computational tasks, but also allows students and faculty to easily share and store large datasets that the students may need to access without having to consume space on their local device. One of our primary goals is to promote diversity and interdisciplinary collaboration within this course, and this semester attracted a notably diverse group of students, with majors ranging from Biology and Statistics to Applied Mathematics, Economics, and Computer Science. Although the course is currently catalogued under the Computer Science department, we recognize that associating it with any single discipline could potentially limit its appeal and accessibility. The diverse enrollment underscores the interdisciplinary relevance of HPC skills across various fields of study. We are leveraging the current success and broad interest in the course as a foundation to establish a new academic program dedicated to High Performance Computing. This new program will serve as a hub for integrating computational skills across different disciplines, fostering a broader understanding and application of HPC in various scientific and economic sectors. The HPC team’s commitment to High Performance Computing education extends beyond traditional academic structures. While we are not developing a new major, minor, certificate track, or concentration in HPC, our objective is to make HPC education accessible and applicable across various disciplines without the constraints of a single departmental bias. This approach allows students from any field to engage with HPC skills as an integral part of their academic and professional development. To achieve this, we are actively collaborating with multiple academic departments to ensure that our HPC course offerings are recognized as fulfilling degree requirements across a range of programs. One way we collaborate with these departments is by altering activities and projects to use different languages and software, such as R and MATLAB, for the Statistics and Engineering departments, while still maintaining the same learning goals we achieve with Python. This strategy not only enhances the versatility of our course but also promotes a more comprehensive integration of the university’s HPC facilities into the curriculum. By doing so, we allow faculty in different departments to integrate our projects into their courses and utilize our HPC facility, even if it is for only one or two projects throughout the semester. Our efforts are focused on fostering a collaborative academic environment where the HPC facility is not just an isolated resource used for research but a central part of our educational infrastructure. By working across disciplines, we hope to catalyze a deeper engagement with HPC technologies throughout the university, enhancing both teaching and research capacities across departments. In conclusion, the escalating demand for big data, machine learning, and artificial intelligence is not only transforming industries but also reshaping educational requirements. As these fields expand, the need for substantial computational resources becomes increasingly critical. The HPC facility at Wake Forest University is exceptionally well-equipped to meet these demands, by providing a unified computing environment that supports an array of academic endeavors. Our initiative to develop introductory HPC courses is a strategic response to this need, preparing students to proficiently utilize HPC resources in higher-level electives and beyond. These courses are pivotal in bridging the gap between conventional academic programs and the rigorous computational needs of modern disciplines. Looking forward, the necessity for such educational offerings will only intensify as the reliance on advanced computational technologies grows. By anticipating and responding to these educational demands, Wake Forest University’s HPC academic program not only enhances student readiness for future challenges but also positions the university at the forefront of academic innovation in the computational sciences.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {106},
numpages = {3},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3613904.3642377,
author = {Chen, John and Lu, Xi and Du, Yuzhou and Rejtig, Michael and Bagley, Ruth and Horn, Mike and Wilensky, Uri},
title = {Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642377},
doi = {10.1145/3613904.3642377},
abstract = {Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {141},
numpages = {18},
keywords = {Agent-based Modeling, ChatGPT, LLM Companion, Learning with LLMs, NetLogo Chat, Programming Assistant},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3649217.3653587,
author = {Denny, Paul and Smith, David H. and Fowler, Max and Prather, James and Becker, Brett A. and Leinonen, Juho},
title = {Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653587},
doi = {10.1145/3649217.3653587},
abstract = {Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with "Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {283–289},
numpages = {7},
keywords = {code comprehension, cs1, eipe, explain in plan english, introductory programming, large language models, llms, prompting},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1109/ASE56229.2023.00157,
author = {Zhou, Xin and Kim, Kisub and Xu, Bowen and Liu, Jiakun and Han, DongGyun and Lo, David},
title = {The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00157},
doi = {10.1109/ASE56229.2023.00157},
abstract = {Learning-based techniques, especially advanced Large Language Models (LLMs) for code, have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models, including popular LLMs for code, heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of LLMs for code. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of LLMs for code. Specifically, LLMs for code perform between 30.0% and 254.0% worse on data samples associated with infrequent labels compared to data samples of frequent labels. Our study provides a better understanding of the effects of long-tailed distributions on popular LLMs for code and insights for the future development of SE automation.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {40–52},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3703187.3703290,
author = {Ma, Xiangfei and Li, Lin},
title = {Geological Disaster Named Entity Recognition with Small Samples Based on Data Augmentation and Prompt Engineering},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703290},
doi = {10.1145/3703187.3703290},
abstract = {This paper uses a large language model to perform generative data enhancement on the original small sample data by performing random synonym replacement and random mask filling operations. In accordance with the reasoning logic of the large language model, three prompt templates are designed and the reasons are explored. Experiments show that when the parameters remain unchanged, the data enhanced by this method has been greatly improved under the three prompt templates, alleviating the difficulty of low resources of geological disaster data. And by comparing the performance of different instructions under different learning rates, the fine-tuning learning rate range suitable for the field of geological disasters is summarized. The limitation is that it is constrained by local computing resources, which reduces the parameter scale of LLM, and the recognition performance is low for extremely long or complex texts.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {613–617},
numpages = {5},
keywords = {Data Augmentation, Geological Disasters, LLMs, Named Entity Recognition, Prompt Engineering},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3691620.3695062,
author = {Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Sun, Zian and Li, Ge and Li, Zhongqi and Ma, Yuchi},
title = {FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695062},
doi = {10.1145/3691620.3695062},
abstract = {Providing personalized and timely feedback for student's programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM's attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67\texttimes{} compared to the autoregressive decoding algorithm.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {669–680},
numpages = {12},
keywords = {automated program repair, large language models, programming education, inference acceleration},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3626253.3633436,
author = {Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto},
title = {Using Large Language Models for Teaching Computing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633436},
doi = {10.1145/3626253.3633436},
abstract = {In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is "what can I do?". We propose that one promising way forward is to integrate LLMs into teaching practice, providing all students with an equal opportunity to learn how to interact productively with LLMs as well as encounter and understand their limitations. In this workshop, we first present state-of-the-art research results on how to utilize LLMs in computing education practice, after which participants will take part in hands-on activities using LLMs. We end the workshop by brainstorming ideas with participants around adapting their classrooms to most effectively integrate LLMs while avoiding some common pitfalls.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1901},
numpages = {1},
keywords = {generative ai, large language models, teaching practice},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701625.3701681,
author = {Menolli, Andr\'{e} and Strik, Bruno and Rodrigues, Luiz},
title = {Teaching Refactoring to Improve Code Quality with ChatGPT: An Experience Report in Undergraduate Lessons},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701681},
doi = {10.1145/3701625.3701681},
abstract = {Refactoring presents a complex computational challenge, and its learning is intricate, requiring a solid foundation in computational thinking, programming and object-oriented concepts. Moreover, making students realize the importance and benefits of refactoring is also challenging. To address this complexity, we introduce a refactoring teaching method based on Generative Artificial Intelligence (GAI), incorporating single-loop and double-loop learning principles, focusing on fostering deeper and critical learning. We used ChatGPT, a GAI-based tool, and conducted an eight-week mixed-methods study involving 23 computer science undergraduate students. The study involved applying four distinct projects extracted from GitHub, where participants were tasked with identifying code smells and performing the necessary refactoring to improve code quality. The primary focus was on identifying both the positive and negative aspects of the method, as well as delineating the computational thinking characteristics developed during the process. The results indicate that the use of ChatGPT facilitated the learning of refactoring, contributing to the development of numerous computational thinking skills, especially problem formulation, decomposition, and abstraction. Thus, this paper contributes a GAI-based teaching method along with evidence on how it helps students develop refactoring skills.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {563–574},
numpages = {12},
keywords = {Generative Artificial Intelligence, ChatGPT, Refactory, Higher Education, Teaching, Computational Thinking},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3649165.3690100,
author = {MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria},
title = {Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690100},
doi = {10.1145/3649165.3690100},
abstract = {Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {137–143},
numpages = {7},
keywords = {buggy code, generative ai, gpt-4, llms, synthetic data},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.5555/3635637.3663138,
author = {Gorbatovski, Alexey and Kovalchuk, Sergey},
title = {Reinforcement Learning for Question Answering in Programming Domain using Public Community Scoring as a Human Feedback},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {This study explores improving GPT Neo 125M in programming-focused Community Question Answering (CQA) using Reinforcement Learning from Human Feedback (RLHF) and Stack Overflow scores. We utilized two reward model training strategies with Proximal Policy Optimization (PPO), achieving enhancements comparable to GPT Neo's 2.7B model. The research introduces an auxiliary scoring mechanism, revealing the limitations of traditional linguistic metrics for programming responses. It highlights the need for domain-specific evaluation methods and the challenges in applying RLHF to programming CQA, contributing to the advancement of Large Language Models (LLMs) with human feedback.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2294–2296},
numpages = {3},
keywords = {natural language processing, programming question answering, proximal policy optimization, reinforcement learning, reinforcement learning from human feedback, stack overflow},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3671127.3698699,
author = {Zhang, Xiaoyang and Bao, Yucheng and Zhou, Taiqi and Wang, Dan},
title = {CarbonReveal: Embodied Carbon Accounting with Retrieval-Augmented LLM for Computer Systems},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698699},
doi = {10.1145/3671127.3698699},
abstract = {Traditional carbon accounting methods, e.g., Life Cycle Assessment (LCA), heavily rely on extensive data collection and expert knowledge, which is labor-intensive and time-consuming. We develop a system named CarbonReveal to achieve automatic embodied carbon accounting for computer systems, and it can be easily extended to carbon accounting in other fields. CarbonReveal leverages retrieval augmented generation to enhance the capabilities of large language models (LLMs) in reliable and cost-effective carbon accounting. Our preliminary results show CarbonReveal has a 93.92% improvement compared to the state-of-the-art.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {250–251},
numpages = {2},
keywords = {Carbon accounting, Large Language Model, Sustainable computing},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3633637.3633648,
author = {Xiao, Le and Shan, Xin and Chen, Xiaolin},
title = {PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation},
year = {2024},
isbn = {9798400707988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633637.3633648},
doi = {10.1145/3633637.3633648},
abstract = {Large language models(LLMS) have shown excellent text generation capabilities, capable of generating fluent human-like responses for many downstream tasks. However, applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To cope with the above challenges, this paper proposes PatternGPT, a pattern-driven text generation framework for Large Language Models. Firstly, the framework utilizes the extraction capability of Large Language Models to generate rich and diversified structured and formalized patterns, which facilitates the introduction of external knowledge to do the computation, and then draws on the idea of federated learning to use multiple agents to achieve the sharing in order to obtain more diversified patterns, and finally uses judgment criteria and optimization algorithm to search for high-quality patterns to guide the generation of models. Finally, external knowledge such as judgment criteria and optimization algorithms are used to search for high-quality patterns, and the searched patterns are used to guide model generation. This framework has the advantages of generating diversified patterns, protecting data privacy, combining external knowledge, and improving the quality of generation, which provides an effective method to optimize the text generation capability of large language models, and make it better applied to the field of intelligent dialogue and content generation.},
booktitle = {Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition},
pages = {72–78},
numpages = {7},
keywords = {LLM, framework, pattern, text generation},
location = {Qingdao, China},
series = {ICCPR '23}
}

@inproceedings{10.1145/3636243.3636259,
author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636259},
doi = {10.1145/3636243.3636259},
abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3663384.3663393,
author = {Feldman, Molly Q and Anderson, Carolyn Jane},
title = {Non-Expert Programmers in the Generative AI Future},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663393},
doi = {10.1145/3663384.3663393},
abstract = {Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {15},
numpages = {19},
keywords = {CS1, Code LLMs, Generative AI, mixed methods, non-experts},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3674399.3674426,
author = {Dong, Dong and Liang, Yue},
title = {Grading Programming Assignments by Summarization},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674426},
doi = {10.1145/3674399.3674426},
abstract = {Grading programming assignments manually is a big burden for instructors who teach programming languages for university students due to complexity and subjectivity. The black test approach adopted by online judge systems can only outputs either an answer is correct or incorrect. This study proposes a Large Language Model (LLM) approach to automatically grade answers from students for programming assignments. A LLM mode formed by coder-decoder architecture is utilized to generate summarization from source code, then the summarization is compared to the textual assignment description by semantic similarity. Finally, the output is converted to five-score rating. CodeBERT and a Transformer model serve as coder and decoder respectively. The semantic similarity is computed by MiniLM-L6. The validation test shows that the accuracy of the suggested approach reaches 0.92.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {53–58},
numpages = {6},
keywords = {CodeBERT, automatic grading, programming assignment assessment, source code summarization},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3657604.3664665,
author = {Koutcheme, Charles and Hellas, Arto},
title = {Propagating Large Language Models Programming Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664665},
doi = {10.1145/3657604.3664665},
abstract = {Large language models (LLMs) such as GPT-4 have emerged as promising tools for providing programming feedback. However, effective deployment of LLMs in massive classes and Massive Open Online Courses (MOOCs) raises financial concerns, calling for methods to minimize the number of calls to the APIs and systems serving such powerful models. In this article, we revisit the problem of 'propagating feedback' within the contemporary landscape of LLMs. Specifically, we explore feedback propagation as a way to reduce the cost of leveraging LLMs for providing programming feedback at scale. Our study investigates the effectiveness of this approach in the context of students requiring next-step hints for Python programming problems, presenting initial results that support the viability of the approach. We discuss our findings' implications and suggest directions for future research in optimizing feedback mechanisms for large-scale educational environments.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {366–370},
numpages = {5},
keywords = {computer science education, large language models, programming feedback},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3639474.3640065,
author = {Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao},
title = {Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640065},
doi = {10.1145/3639474.3640065},
abstract = {Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs.However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {320–330},
numpages = {11},
keywords = {programming assignment, code performance, tool support},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3613904.3642349,
author = {Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho},
title = {Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642349},
doi = {10.1145/3613904.3642349},
abstract = {This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs’ expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs’ knowledge and makes them initiate “why” and “how” questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo’s problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo’s questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {652},
numpages = {28},
keywords = {AI and Education, Generative AI, Human-AI interaction, LLM agents},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3626253.3635624,
author = {Fan, Aysa X. and Hendrawan, Rully A. and Shi, Yang and Ma, Qianou},
title = {Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635624},
doi = {10.1145/3626253.3635624},
abstract = {This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1640–1641},
numpages = {2},
keywords = {computer science education, large language model, programming education, tracing question},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3660773,
author = {Hossain, Soneya Binta and Jiang, Nan and Zhou, Qiang and Li, Xiaopeng and Chiang, Wen-Hao and Lyu, Yingjun and Nguyen, Hoan and Tripp, Omer},
title = {A Deep Dive into Large Language Models for Automated Bug Localization and Repair},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660773},
doi = {10.1145/3660773},
abstract = {Large language models (LLMs) have shown impressive effectiveness in various software engineering tasks,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
including automated program repair (APR). In this study, we take a deep dive into automated bug localization
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and repair utilizing LLMs. In contrast to many deep learning-based APR methods that assume known bug
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
locations, rely on line-level localization tools, or address bug prediction and fixing in one step, our approach
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
uniquely employs LLMs to predict bug location at the token level and subsequently utilizes them for bug
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
fixing. This methodological separation of bug localization and fixing using different LLMs enables effective
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
integration of diverse contextual information and improved incorporation of inductive biases. We introduce
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Toggle: Token-Granulated Bug Localization and Repair, a comprehensive program repair framework
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
that integrates a bug localization model, an adjustment model to address tokenizer inconsistencies, and a
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
bug-fixing model. Toggle takes a buggy function as input and generates a complete corrected function. We
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
investigate various styles of prompting to the bug fixing model to identify the most effective prompts that
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
better utilize the inductive bias and significantly outperform others. Toggle achieves the new state-of-the-art
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(SOTA) performance on the CodeXGLUE code refinement benchmark, and exhibits better and comparable
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
performance on several other widely-used APR datasets, including Defects4J. In the Defects4J benchmark, our
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
approach consistently ranks above other methods, achieving superior results in the Top-10, Top-30, Top-50,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and Top-100 metrics. Besides examining Toggle’s generalizability to unseen data, evaluating the effectiveness
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
of various prompts, we also investigate the impact of additional contextual information such as buggy lines
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and code comments on bug localization, and explore the importance of the adjustment model. Our extensive
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
experiments offer valuable insights and answers to critical research questions.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {66},
numpages = {23},
keywords = {Automated Bug Localization and Reapir, Large Language Models}
}

@inproceedings{10.1145/3631802.3631816,
author = {Malaise, Yoshi and Signer, Beat},
title = {Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631816},
doi = {10.1145/3631802.3631816},
abstract = {We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {24},
numpages = {8},
keywords = {PRIMM, Programming Education, Study Lenses},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3664646.3665084,
author = {Jobson, Deddy and Li, Yilin},
title = {Investigating the Potential of Using Large Language Models for Scheduling},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3665084},
doi = {10.1145/3664646.3665084},
abstract = {The inaugural ACM International Conference on AI-powered Software introduced the AIware Challenge, prompting researchers to explore AI-driven tools for optimizing conference programs through constrained optimization. We investigate the use of Large Language Models (LLMs) for program scheduling, focusing on zero-shot learning and integer programming to measure paper similarity.
 
 
 
Our study reveals that LLMs, even under zero-shot settings, create reasonably good first drafts of conference schedules. When clustering papers, using only titles as LLM inputs produces results closer to human categorization than using titles and abstracts with TFIDF. The code has been made publicly available at https://github.com/deddyjobson/llms-for-scheduling.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {170–171},
numpages = {2},
keywords = {clustering, large language models, mathematical optimization, scheduling},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3626253.3635604,
author = {Weber, Jason Lee and Martinez Neda, Barbara and Carbajal Juarez, Kitana and Wong-Ma, Jennifer and Gago-Masague, Sergio and Ziv, Hadar},
title = {Measuring CS Student Attitudes Toward Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635604},
doi = {10.1145/3626253.3635604},
abstract = {With the mainstream adoption of Large Language Models (LLMs), members of both academia and the media have raised concerns around their impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption of and attitudes toward LLMs among the CS student population at an R1 University to determine how students are using these new tools. To this end, we conducted a large survey study targeting two populations participating in computing courses at the university: intro-sequence students (ISS) and experienced students (ES).In our preliminary results from Spring 2023, we've found several significant differences among the views of over 700 respondents across the two groups. Most students reported LLMs' unparalleled potential for quick information access, yet many harbor concerns about the reliability of the LLM responses, and the impact on academic integrity. Additionally, while ES have rapidly integrated LLMs into their learning, ISS remain cautious of the tools, highlighting a stark contrast in adoption rates between the groups.LLMs are clearly going to reshape pedagogical approaches and student engagement. Our study hopes to provide insight on the nuanced student attitudes toward LLMs. For example, the notable reservations expressed by ISS illustrate an imperative for careful, informed, and ethical integration to ensure these tools enhance rather than compromise the educational experience. In the future, we plan to continue tracking student attitudes in order to gain further understanding of the changing perceptions of LLMs and their impact.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1846–1847},
numpages = {2},
keywords = {academic integrity, ai tools, chatgpt, faculty perception, generative ai, large language models (llms), student perception},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3638529.3654056,
author = {Jorgensen, Steven and Nadizar, Giorgia and Pietropolli, Gloria and Manzoni, Luca and Medvet, Eric and O'Reilly, Una-May and Hemberg, Erik},
title = {Large Language Model-based Test Case Generation for GP Agents},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3654056},
doi = {10.1145/3638529.3654056},
abstract = {Genetic programming (GP) is a popular problem-solving and optimization technique. However, generating effective test cases for training and evaluating GP programs requires strong domain knowledge. Furthermore, GP programs often prematurely converge on local optima when given excessively difficult problems early in their training. Curriculum learning (CL) has been effective in addressing similar issues across different reinforcement learning (RL) domains, but it requires the manual generation of progressively difficult test cases as well as their careful scheduling. In this work, we leverage the domain knowledge and the strong generative abilities of large language models (LLMs) to generate effective test cases of increasing difficulties and schedule them according to various curricula. We show that by integrating a curriculum scheduler with LLM-generated test cases we can effectively train a GP agent player with environments-based curricula for a single-player game and opponent-based curricula for a multi-player game. Finally, we discuss the benefits and challenges of implementing this method for other problem domains.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {914–923},
numpages = {10},
keywords = {linear GP, large language models, curriculum learning},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{10.1145/3649217.3653543,
author = {Bassner, Patrick and Frankford, Eduard and Krusche, Stephan},
title = {Iris: An AI-Driven Virtual Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653543},
doi = {10.1145/3649217.3653543},
abstract = {Integrating AI-driven tools in higher education is an emerging area with transformative potential. This paper introduces Iris, a chat-based virtual tutor integrated into the interactive learning platform Artemis that offers personalized, context-aware assistance in large-scale educational settings. Iris supports computer science students by guiding them through programming exercises and is designed to act as a tutor in a didactically meaningful way. Its calibrated assistance avoids revealing complete solutions, offering subtle hints or counter-questions to foster independent problem-solving skills. For each question, it issues multiple prompts in a Chain-of-Thought to GPT-3.5-Turbo. The prompts include a tutor role description and examples of meaningful answers through few-shot learning. Iris employs contextual awareness by accessing the problem statement, student code, and automated feedback to provide tailored advice. An empirical evaluation shows that students perceive Iris as effective because it understands their questions, provides relevant support, and contributes to the learning process. While students consider Iris a valuable tool for programming exercises and homework, they also feel confident solving programming tasks in computer-based exams without Iris. The findings underscore students' appreciation for Iris' immediate and personalized support, though students predominantly view it as a complement to, rather than a replacement for, human tutors. Nevertheless, Iris creates a space for students to ask questions without being judged by others.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {394–400},
numpages = {7},
keywords = {chatgpt, cs1, education technology, generative ai, interactive learning, large language models, programming exercises},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3658549.3658566,
author = {Ho, Chia-Ling and Liu, Xin-Ying and Qiu, Yu-Wei and Yang, Shih-Yang},
title = {Research on Innovative Applications and Impacts of Using Generative AI for User Interface Design in Programming Courses},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658549.3658566},
doi = {10.1145/3658549.3658566},
abstract = {Generative Artificial Intelligence (GAI) has become a hot topic nowadays, as its powerful content generation models enable users to instantly create everything from digital media products to coding examples through simple text queries, providing more possibilities in the field of education. This study aims to investigate the impact of Generative AI intervention in teaching App Inventor programming courses, analyzing the differences between UI materials designed by traditional teachers based on their professional knowledge and experience, and UI materials created by Generative AI in classroom teaching. The study also evaluates the impact of Generative AI on students' learning outcomes and motivation through satisfaction and Technology Acceptance Model (TAM) questionnaires. The results indicate that UI materials produced through Generative AI effectively enhance students' satisfaction with the course and their acceptance of new technologies. Compared to traditional teaching methods, Generative AI significantly saves teachers' time and effort in designing materials while simultaneously improving teaching efficiency and quality.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
pages = {68–72},
numpages = {5},
keywords = {Generative artificial intelligence, Intelligent assistant, Learning effectiveness, Programming course, User interface design},
location = {Taipei, Taiwan},
series = {I-DO '24}
}

@inproceedings{10.1145/3657604.3664671,
author = {Wang, Yuchen and Guo, Shangxin and Ling, Lin and Tan, Chee Wei},
title = {Nemobot: Crafting Strategic Gaming LLM Agents for K-12 AI Education},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664671},
doi = {10.1145/3657604.3664671},
abstract = {Artificial intelligence (AI) permeates modern society and is poised for further integration across various domains. However, there exists a notable deficiency in equipping K-12 students with foundational AI understanding. This paper introduces a novel learning framework that leverages large language models (LLMs) and strategic gaming to teach K-12 students about the inner workings of AI. The framework consists of a chatbot programming and testing IDE that enables K-12 students to construct AI from scratch, engage in strategic gameplay to generate instant training data, and improve the AI heuristics with a data-driven learning mechanism. With a tiered curriculum catering to diverse proficiency levels and fostering synchronous collaboration, this framework efficiently adapts learning experiences to suit various groups of students, thereby facilitating learning at scale. Preliminary experiments validate the feasibility and vast potential of this approach, promising to revolutionize AI education in K-12 education.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {393–397},
numpages = {5},
keywords = {ai-assisted programming, chatbot programming, collaborative learning, gamification approach, generative ai, k-12 education, large language models(llms)},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3698587.3701527,
author = {Agapito, Giuseppe and Cannataro, Mario and Lloyd, Wes J. and Zucco, Chiara},
title = {13th Workshop on Parallel and AI-based Bioinformatics and Biomedicine (ParBio): Editorial},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701527},
doi = {10.1145/3698587.3701527},
abstract = {The goal of ParBio is to bring together scientists in high-performance computing, computational biology, and medicine to discuss parallel implementation of bioinformatics and biomedical applications and the challenges and opportunities of moving these applications to the cloud or edge. The workshop will also address Artificial Intelligence (AI), Large Language Models (LLMs), machine learning, and big data analytics in healthcare and bioinformatics, focusing on the integrated analysis of molecular and clinical data. This is motivated by the increasing production of experimental and clinical data and the shift towards data storage, integration, and analysis.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {95},
numpages = {1},
keywords = {Bioinformatics, Machine Learning, Parallel algorithms},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3626252.3630863,
author = {Del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating Automatically Generated Contextualised Programming Exercises},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630863},
doi = {10.1145/3626252.3630863},
abstract = {Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {289–295},
numpages = {7},
keywords = {chatgpt, cs1, gpt-4, large language models, novice programmers, openai, programming exercises, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3634814.3634816,
author = {Cowan, Brendan and Watanobe, Yutaka and Shirafuji, Atsushi},
title = {Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634816},
doi = {10.1145/3634814.3634816},
abstract = {Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student’s prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student’s learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {10–16},
numpages = {7},
keywords = {ChatGPT, educational technology, large language models, programming education, prompt engineering},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

@inproceedings{10.1145/3636534.3698856,
author = {Li, Yiming and Sun, Jingwei and Liu, Yudong and Zhang, Yuandong and Li, Ang and Chen, Beidi and Roth, Holger R. and Xu, Daguang and Chen, Tingjun and Chen, Yiran},
title = {Federated Black-box Prompt Tuning System for Large Language Models on the Edge},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3698856},
doi = {10.1145/3636534.3698856},
abstract = {Federated learning (FL) offers a privacy-preserving way to train models across decentralized data. However, fine-tuning pre-trained language models (PLMs) in FL is challenging due to restricted model parameter access, high computational demands, and communication overheads. Our method treats large language models (LLMs) as black-box inference APIs, optimizing prompts with gradient-free methods. This approach, FedBPT, reduces exchanged variables, boosts communication efficiency, and minimizes computational and memory costs. We demonstrate the practical implementation of FedBPT on resource-limited edge devices, showcasing its ability to efficiently achieve collaborative on-device LLM fine-tuning.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1775–1777},
numpages = {3},
keywords = {large language models, gradient-free optimization, federated learning},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3626253.3635600,
author = {Chen, Xi and Liang, Jingsai},
title = {Pair Programming with ChatGPT},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635600},
doi = {10.1145/3626253.3635600},
abstract = {This poster explores the potential of ChatGPT to replace the traditional approach of pair programming in introductory computer science courses. Traditionally, two students collaborate as a driver and a navigator, periodically switching roles. Now, a student can pair up with ChatGPT, which offers an innovative approach to pair programming. This exploratory activity, which emphasizes collaboration and communication, provides step-by-step instructions for effectively interacting with ChatGPT during pair programming.This poster reflects on the advantages and limitations of using ChatGPT in pair programming. The main advantages of using ChatGPT include rapid responses, syntax error-free code generation, and flexibility in handling incomplete pseudocode. The primary limitations include the coding generation style, redundancy in responses, and challenges in understanding the code. Despite the advantages, it may still be valuable to have students work with human partners in certain situations, particularly for learning purposes.This poster proposes that ChatGPT is an invaluable tool for enhancing productivity and emphasizes the importance of becoming proficient in its use during students' college years. It also provides insights into the effective utilization of ChatGPT in pair programming and its preparation for future careers in programming and related fields.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1600–1601},
numpages = {2},
keywords = {chatgpt, pair programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636245,
author = {Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636245},
doi = {10.1145/3636243.3636245},
abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {11–18},
numpages = {8},
keywords = {bug detection, computing education, generative AI, large language models, programming errors},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3649217.3653615,
author = {Gardella, Nicholas and Pettit, Raymond and Riggs, Sara L.},
title = {Performance, Workload, Emotion, and Self-Efficacy of Novice Programmers Using AI Code Generation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653615},
doi = {10.1145/3649217.3653615},
abstract = {Artificial Intelligence-driven Development Environments (AIDEs) offer developers revolutionary computer programming assistance. There is great potential in incorporating AIDEs into Computer Science education; however, the effects of these tools should be fully examined before doing so. Here, a within-subjects study was conducted to compare the programming performance, workload, emotion, and self-efficacy of seventeen novices coding with and without use of the GitHub Copilot AIDE under time pressure. Results showed that using the AIDE significantly increased programming efficiency and reduced effort and mental workload but did not significantly impact emotion or self-efficacy. However, participants' performance improved with more experience using the AI, and their self-efficacy followed. The results suggest that students who try AIDEs will likely be tempted to use them for time-sensitive work. There is no evidence that providing AIDEs will aid struggling students, but there is a clear need for students to practice with AI to become competent and confident using it.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {290–296},
numpages = {7},
keywords = {ai code generators, artificial intelligence-driven development environment, computer science education, cs1, generative ai, github copilot, introductory programming, novice programmers},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.5555/3715602.3715609,
author = {Weiss, Richard and Mache, Jens},
title = {Cybersecurity Exercises in the Age of LLMs},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {In this tutorial, we will introduce a cybersecurity education framework for developing polymorphic hands-on exercises. Many faculty readily acknowledge the importance of cybersecurity in the Computer Science curriculum, but there are still barriers to integrating it into existing courses. One of those barriers is the fact that in most courses, the current content fills the entire term. Another issues is that faculty don't have time and expertise to create new content that would fit well with their current content and style. The third problem is that exercises created should be resistant to solution by LLMs. We have developed cybersecurity exercises that combine two principles: environment specificity and polymorphism. Environment specificity means that the solutions to the exercise should depend on the local environment (LLMs don't have access to that information). In this context, polymorphism means that they can be easily modified each time that the class is taught.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {25–27},
numpages = {3}
}

@inproceedings{10.1145/3671127.3698698,
author = {Deng, Yang and Xie, Donghua and Liang, Rui and Zeng, Jingyun and Tai, Samson and Wang, Dan},
title = {BuildProg: Program Generation for Testing ML-based Building Load Forecasting models via LLM and Prompt Engineering},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698698},
doi = {10.1145/3671127.3698698},
abstract = {Machine learning-based building load forecasting (BLF) is crucial for the building automation community, and numerous ML models have been developed for this purpose. However, a significant challenge arises when promoting these models for deployment in real buildings: building practitioners often struggle with ML-related programming. To address this issue, we propose BuildProg, a program generation tool that leverages prompt engineering to decompose user requirements and guide large language models (LLMs) in generating the necessary Python code. In its current version, BuildProg supports four tasks related to the testing of BLF models.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {248–249},
numpages = {2},
keywords = {LLM, Model testing, program generation, prompting},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3649217.3653574,
author = {Denny, Paul and MacNeil, Stephen and Savelka, Jaromir and Porter, Leo and Luxton-Reilly, Andrew},
title = {Desirable Characteristics for AI Teaching Assistants in Programming Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653574},
doi = {10.1145/3649217.3653574},
abstract = {Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses. Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings. These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problem-solving skills. With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support. Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences. If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn. Thus, it is essential to identify the features that students believe make digital teaching assistants valuable. We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback (n=813) on the characteristics of the tool they perceived to be most important. Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines. They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {408–414},
numpages = {7},
keywords = {ai tutors, automated tutors, digital tas, feedback, llms},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653533,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Kan, Lauren and Hellas, Arto and Littlefield, Matt and Sarsa, Sami and Macneil, Stephen},
title = {"Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students Using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653533},
doi = {10.1145/3649217.3653533},
abstract = {Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies produced with student-prescribed topics, in contrast to the otherwise generic analogies, highlighting the value of student creativity when working with LLMs. Not only did students enjoy the activity and report an improved understanding of recursion, but they described more easily remembering analogies that were personally and culturally relevant.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {122–128},
numpages = {7},
keywords = {analogies, computing education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3589335.3651512,
author = {Ghosh, Sohom and Chen, Chung-Chi and Naskar, Sudip Kumar},
title = {Generator-Guided Crowd Reaction Assessment},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651512},
doi = {10.1145/3589335.3651512},
abstract = {In the realm of social media, understanding and predicting post reach is a significant challenge. This paper presents a Crowd Reaction AssessMent (CReAM) task designed to estimate if a given social media post will receive more reaction than another, a particularly essential task for digital marketers and content writers. We introduce the Crowd Reaction Estimation Dataset (CRED), consisting of pairs of tweets from The White House with comparative measures of retweet count. The proposed Generator-Guided Estimation Approach (GGEA) leverages generative Large Language Models (LLMs), such as ChatGPT, FLAN-UL2, and Claude, to guide classification models for making better predictions. Our results reveal that a fine-tuned FLANG-RoBERTa model, utilizing a cross-encoder architecture with tweet content and responses generated by Claude, performs optimally. We further use a T5-based paraphraser to generate paraphrases of a given post and demonstrate GGEA's ability to predict which post will elicit the most reactions. We believe this novel application of LLMs provides a significant advancement in predicting social media post reach.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {597–600},
numpages = {4},
keywords = {crowd reaction assessment, large language models, natural language processing, social media},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3652892.3700758,
author = {Hu, Chenghao and Li, Baochun},
title = {Menos: Split Fine-Tuning Large Language Models with Efficient GPU Memory Sharing},
year = {2024},
isbn = {9798400706233},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652892.3700758},
doi = {10.1145/3652892.3700758},
abstract = {Fine-tuning of pre-trained large language models has become increasingly popular, yet existing fine-tuning methods are typically centralized, requiring users to send local data to centralized servers, or model owners to open-source their models. However, data and models are valuable assets that few enterprises and users wish to share. In this paper, we deviate from conventional wisdom and advocate the use of split learning for fine-tuning models with private data, local to each of the clients. The most formidable challenge to split fine-tuning is the size of large language models: when multiple clients start their fine-tuning tasks, their use of GPU memory will overwhelm a GPU-equipped server, especially as the number of clients scales up. To address this challenge, we present Menos, the first memory-efficient split fine-tuning framework designed to optimize the server GPU footprint through spatial and temporal sharing. Specifically, Menos utilizes the adapter-based nature of modern fine-tuning techniques, and proposes to spatially share the base model parameters among multiple clients. It also schedules memory-intensive operations during the communication gaps of split learning, thereby temporally sharing limited GPU memory at runtime. Comprehensive real-world evaluations using state-of-the-art large language models demonstrate the effectiveness of Menos, reducing GPU memory consumption by up to 72%, yet incurring negligible overhead.},
booktitle = {Proceedings of the 25th International Middleware Conference},
pages = {185–198},
numpages = {14},
keywords = {split learning, fine-tuning, cloud computing, system design},
location = {Hong Kong, Hong Kong},
series = {Middleware '24}
}

@inproceedings{10.1145/3643991.3644926,
author = {Idialu, Oseremen Joy and Mathews, Noble Saji and Maipradit, Rungroj and Atlee, Joanne M. and Nagappan, Mei},
title = {Whodunit: Classifying Code as Human Authored or GPT-4 Generated - A case study on CodeChef problems},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644926},
doi = {10.1145/3643991.3644926},
abstract = {Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT, built on large language models like GPT-4, are revolutionizing how programming tasks are performed, raising questions about whether code is authored by generative AI models. Such questions are of particular interest to educators, who worry that these tools enable a new form of academic dishonesty, in which students submit AI-generated code as their work. Our research explores the viability of using code stylometry and machine learning to distinguish between GPT-4 generated and human-authored code. Our dataset comprises human-authored solutions from CodeChef and AI-authored solutions generated by GPT-4. Our classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A variant of our classifier that excludes gameable features (e.g., empty lines, whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We also evaluated our classifier on the difficulty of the programming problem and found that there was almost no difference between easier and intermediate problems, and the classifier performed only slightly worse on harder problems. Our study shows that code stylometry is a promising approach for distinguishing between GPT-4 generated code and human-authored code.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {394–406},
numpages = {13},
keywords = {code stylometry, ChatGPT, AI code, GPT-4 generated code, authorship profiling, software engineering},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3626253.3635542,
author = {Smith, David H. and Zilles, Craig},
title = {Evaluating Large Language Model Code Generation as an Autograding Mechanism for "Explain in Plain English" Questions},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635542},
doi = {10.1145/3626253.3635542},
abstract = {The ability of students to ''Explain in Plain English'' (EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1824–1825},
numpages = {2},
keywords = {autograding, eipe, gpt-4, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3675094.3678991,
author = {Li, Yunjia and Liu, Haiming and Wald, Mike},
title = {DeepVision: Heads-up Computing and AI in Education},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678991},
doi = {10.1145/3675094.3678991},
abstract = {Heads-up computing together with AI can enhance in-class learning experiences. In this position paper, we propose the development of a multimodal AI system called DeepVision that integrates Automatic Speech Recognition (ASR), Large Language Models (LLM), Large Vision Models (LVM), Information Retrieval (IR) and Inclusive User Experience Design (IUX) to convert real-time lectures into multiple knowledge representations. These will be visualized on heads-up communication devices such as Augmented Reality (AR) and Mixed Reality (MR) devices. The initiative is a collaboration between Habitat Learn Limited (HLL) and the University of Southampton, leveraging HLL's existing software and extensive data repository to address the challenges of traditional and digital learning environments, especially for students with disabilities or language differences.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {627–630},
numpages = {4},
keywords = {ai, ar, heads-up computing, inclusive user experience design, large language model, multimodal information access and retrieval},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3639474.3640061,
author = {Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
title = {AI-Tutoring in Software Engineering Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640061},
doi = {10.1145/3639474.3640061},
abstract = {With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences.In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {309–319},
numpages = {11},
keywords = {programming education, automated programming assessment systems, artificial intelligence, ChatGPT, OpenAI, ChatBots},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3632620.3671092,
author = {Yang, Stephanie and Zhao, Hanzhang and Xu, Yudian and Brennan, Karen and Schneider, Bertrand},
title = {Debugging with an AI Tutor: Investigating Novice Help-seeking Behaviors and Perceived Learning},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671092},
doi = {10.1145/3632620.3671092},
abstract = {Debugging is a crucial skill for programmers, yet it can be challenging for novices to learn. The introduction of large language models (LLMs) has opened up new possibilities for providing personalized debugging support to students. However, concerns have been raised about potential student over-reliance on LLM-based tools. This mixed-methods study investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. We conducted interviews and debugging think-aloud tasks with 20 students at three points throughout the semester. We specifically focused on characterizing when students initiate help from the chatbot during debugging, how they engage with the chatbot’s responses, and how they describe their learning experiences with the chatbot. By analyzing data from the debugging tasks, we identified varying help-seeking behaviors and levels of engagement with the chatbot’s responses, depending on students’ familiarity with the suggested strategies. Interviews revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. Additionally, students self-identified certain chatbot usage behaviors as negative, “non-ideal” engagement and others as positive, “learning-oriented” usage. Based on our findings, we discuss pedagogical implications and future directions for designing pedagogical chatbots to support debugging.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {84–94},
numpages = {11},
keywords = {AI tutoring, LLMs, debugging, help-seeking, large language models, programming education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3627673.3679664,
author = {Guo, Yuxiang and Shen, Shuanghong and Liu, Qi and Huang, Zhenya and Zhu, Linbo and Su, Yu and Chen, Enhong},
title = {Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679664},
doi = {10.1145/3627673.3679664},
abstract = {Knowledge Tracing (KT) is a crucial research task for dynamically monitoring students' knowledge states, particularly in online education systems. Recently, knowledge tracing has gained significant attention and in-depth research. Most existing methods rely on students' response data for question understanding and modeling, which helps better updating students' knowledge states. Meanwhile, question ID is utilized to indicate and represent questions. However, this presents a challenge when transitioning to new, cold-start questions that few students has answered before. Also, prior work has overlooked the semantic modeling of questions, which could better assist in modeling the transfer of students' knowledge states. In this paper, we explore leveraging the power of Large Language Models (LLMs) to help understand questions for knowledge tracing, which benefits mitigating cold-start and sparse problems and modeling the transfer of students' knowledge states in a sophisticated manner. Specifically, we first design an attribute estimation module to estimate the attribute of the questions (e.g., difficulty, ability requirements, expected response time) by prompting Large Language Models. Subsequently, we have developed a question embedding module that incorporates graph attention network to effectively utilizing these attributes. Extensive experiments on various datasets demonstrate that our model outperforms existing state-of-the-art models and effectively addresses the problems of cold-start and sparsity. In addition, due to the estimation of multiple attributes of the questions, our model exhibits superior interpretability.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {727–736},
numpages = {10},
keywords = {knowledge tracing, large language model, question attributes},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.5555/3722479.3722482,
author = {Reno, Michael J. and Russell, Victoria and Nutter, Taylor J. and Rao, P. Anand and Polack, Jennifer},
title = {AI Intersections: Ethics, Education, and Technological Philopsophy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {This panel explores the multifaceted intersections of artificial intelligence with ethics, education, and philosophical perspectives on technology. As AI continues to reshape our world, it becomes increasingly crucial to examine its implications across various disciplines. Our panelists will present diverse viewpoints, ranging from innovative pedagogical approaches using AI to philosophical inquiries into the nature of intelligence and technology. The panel will address critical questions surrounding AI explainability, the integration of AI in education, the historical context of AI research, and the ethical considerations that arise from these technological advancements. By bringing together experts from computer science, philosophy, religious studies, and digital humanities, this panel aims to foster a rich, interdisciplinary dialogue on the present and future of AI in academia and society. In the spirit of the panel topic, this abstract was created using Anthropic's Generative AI platform, Claude.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {21–23},
numpages = {3}
}

@inproceedings{10.1145/3613904.3642229,
author = {Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun},
title = {ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642229},
doi = {10.1145/3613904.3642229},
abstract = {As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {19},
keywords = {Children Aged 6-12, Computational Thinking, Large Language Model, Scratch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3691555.3696825,
author = {Tang, Zuoyin and He, Jianhua and Pe, Dashuai and Liu, Kezhong and Gao, Tao and Zheng, Jiawei},
title = {Test Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles},
year = {2024},
isbn = {9798400712470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691555.3696825},
doi = {10.1145/3691555.3696825},
abstract = {Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs, which are difficult to be met locally at AVs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send driving assistance requests to the LLMs. LLMs deployed at the edge of the networks or remote clouds process the requests and generate driving assistance instructions for the CAVs. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. As there is no published work on assessing LLM of driving theory and skills, we design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. These questions are close to the official UK driving theory test ones. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% (just below the 86% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-o has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.},
booktitle = {Proceedings of the 19th Workshop on Mobility in the Evolving Internet Architecture},
pages = {1–6},
numpages = {6},
keywords = {Connected autonomous vehicles, driving theory test, large language model, mobile cloud computing, mobile edge computing, remote driving},
location = {Washington D.C., DC, USA},
series = {MobiArch '24}
}

@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3663384.3663401,
author = {Das Swain, Vedant and Saha, Koustuv},
title = {Teacher, Trainer, Counsel, Spy: How Generative AI can Bridge or Widen the Gaps in Worker-Centric Digital Phenotyping of Wellbeing},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663401},
doi = {10.1145/3663384.3663401},
abstract = {The increasing integration of computing technologies in the workplace has also seen the conceptualization and development of data-driven and algorithmic tools that aim to improve workers’ wellbeing and performance. However, both research and practice have revealed several gaps in the effectiveness and deployment of these tools. Meanwhile, the recent advances in generative AI have highlighted the tremendous capabilities of large language models (LLMs) in processing large volumes of data in producing human-interactive natural language content. This paper explores the opportunities for LLMs in facilitating worker-centered design for Wellbeing Assessment Tools (WATs). In particular, we map features of LLMs against known challenges of WAT. We highlight how the LLMs can bridge or even widen the gaps in worker-centeric WAT. This paper aims to inspire new research directions focused on empowering workers and anticipating harms in integrating LLMs with workplace technologies.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {3},
numpages = {13},
keywords = {LLMs, generative AI, large language models, worker performance, worker wellbeing, workplace},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@article{10.5555/3665464.3665469,
author = {Manley, Eric D. and Urness, Timothy and Migunov, Andrei and Reza, Md. Alimoor},
title = {Examining Student Use of AI in CS1 and CS2},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {The launch of ChatGPT in November 2022 marked a seismic disruption to many disciplines and industries, including higher education. For the first time, students everywhere have widely available access to a Large Language Model (LLM) capable of generating content - including solutions to programming assignments in CS1 and CS2 - that can pass as the work of a high-achieving student while making traditional plagiarism-detection obsolete. This has spurred various responses in higher education, including a shift to more in-class and unplugged assessments. At the same time, LLMs are transforming the way that many people work, including professional software developers, and students similarly might be able to use them to enhance their learning. In this paper, we report on our experiences with a permissive policy towards the use of ChatGPT and other artificial intelligence (AI) tools for assisting students with their programming assignments in CS1 and CS2 courses in the Spring 2023 semester. Students were allowed to use these tools however they wished as long as they submitted a form which included a transcript of their chat and a reflection on what they learned, if anything, through the interaction. We found that students largely approached the AI in positive ways and that they seemed to genuinely learn from the experience. We also document some things that did not go well and that remain challenges to using AI in programming courses, along with our recommendations on how these might be dealt with in the future.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {41–51},
numpages = {11}
}

@inproceedings{10.1145/3613904.3641965,
author = {Calle, Paul and Shao, Ruosi and Liu, Yunlong and H\'{e}bert, Emily T and Kendzor, Darla and Neil, Jordan and Businelle, Michael and Pan, Chongle},
title = {Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641965},
doi = {10.1145/3613904.3641965},
abstract = {Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {16},
keywords = {Computational Linguistic Analysis, Expert Review, Large Language Model, Message Generation, Smoking Cessation Intervention},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3658644.3670369,
author = {Cho, Wonhee and Hanrot, Guillaume and Kim, Taeseong and Park, Minje and Stehl\'{e}, Damien},
title = {Fast and Accurate Homomorphic Softmax Evaluation},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670369},
doi = {10.1145/3658644.3670369},
abstract = {Homomorphic encryption is one of the main solutions for building secure and privacy-preserving solutions for Machine Learning as a Service, a major challenge in a society where AI becomes more and more pervasive. This motivates the development of homomorphic algorithms for the main building blocks of AI, typically for the components of the various types of neural networks architectures.Among those components, we focus on the Softmax function, defined by Softmax(x ) = (exp(xi) / ∑j=1n exp(xj))1 ≤ i ≤ n. This function is deemed to be one of the most difficult to evaluate homomorphically, because of its multivariate nature and of the very large range of values for exp(xi). The available homomorphic algorithms remain restricted, especially in large dimensions, while important applications such as Large Language Models (LLM) require computing Softmax over large dimensional vectors. Our algorithm has strong scalability properties in terms of range and dimension while maintaining very good numerical accuracy. In terms of multiplicative depth of the computation (a suitable measure of cost for homomorphic algorithms), our algorithm achieves O(log n) complexity for a fixed range of inputs, where n is the Softmax dimension.Our algorithm is especially adapted to the situation where we must compute many Softmax at the same time, for instance, in the LLM situation. In that case, assuming that all Softmax calls are packed into m ciphtertexts, the asymptotic amortized multiplicative depth cost per ciphertext is, again over a fixed range, O(1 + m/N) for N the homomorphic ring degree (typically N=216, so that we have N ≫ m in practice).The main ingredient of our algorithms is a normalize-and-square strategy, which manages to interlace the (numerically unstable) exponential computation over a large range and (very expensive) normalization, decomposing both in stabler and cheaper smaller steps.We have implemented our algorithms using the HEaaN implementation of the CKKS HE system. Comparing ourselves to the state of the art, our experiments show, in practice, a gain of a factor 2.5 to 8 compared to state of the art solutions.These experiments demonstrate good accuracy (around 16-bit precision in the worst case, around 20 on average) and support the linear behavior in the dimension. The many-ciphertexts version allows us to compute 8192 Softmax of dimension 256 in parallel in 486s (single-thread CPU), corresponding to an amortized 0.06s per Softmax call. All Softmax calls of the 32-layers LLaMa large language model (7B version) with context length 128 on an RTX-6000 GPU take around 1.5 minutes, and the final Softmax call in dimension 32768 for token generation takes less than 3 seconds. This suggests that near-practicality may be accessible with dedicated hardware.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4391–4404},
numpages = {14},
keywords = {CKKS scheme, fully homomorphic encryption, polynomial approximation, softmax},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3639233.3639251,
author = {Solomou, Chris},
title = {Enhancing Medical Specialty Assignment to Patients using NLP Techniques},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639251},
doi = {10.1145/3639233.3639251},
abstract = {The introduction of Large Language Models (LLMs), and the vast volume of publicly available medical data, amplified the application of NLP to the medical domain. However, LLMs are pretrained on data that are not explicitly relevant to the domain that are applied to and are often biased towards the original data they were pretrained upon. Even when pretrained on domain-specific data, these models typically require time-consuming fine-tuning to achieve good performance for a specific task. To address these limitations, we propose an alternative approach that achieves superior performance while being computationally efficient. Specifically, we utilize keywords to train a deep learning architecture that outperforms a language model pretrained on a large corpus of text. Our proposal does not require pretraining nor fine-tuning and can be applied directly to a specific setting for performing multi-label classification. Our objective is to automatically assign a new patient to the specialty of the medical professional they require, using a dataset that contains medical transcriptions and relevant keywords. To this end, we fine-tune the PubMedBERT model on this dataset, which serves as the baseline for our experiments. We then twice train/fine-tune a DNN and the RoBERTa language model, using both the keywords and the full transcriptions as input. We compare the performance of these approaches using relevant metrics. Our results demonstrate that utilizing keywords for text classification significantly improves classification performance, for both a basic DL architecture and a large language model. Our approach represents a promising and efficient alternative to traditional methods for fine-tuning language models on domain-specific data and has potential applications in various medical domains.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {203–209},
numpages = {7},
keywords = {AI in Healthcare, Information Retrieval, LLMs, Multi-label-classification, NLP},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

@inproceedings{10.1145/3589335.3641296,
author = {Todorov, Konstantin and Fafalios, Pavlos and Dietze, Stefan and Dimitrov, Dimitar},
title = {Beyond Facts: 4th International Workshop on Computational Methods for Online Discourse Analysis},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641296},
doi = {10.1145/3589335.3641296},
abstract = {Expressing opinions and interacting with others on the Web has led to the production of an abundance of online discourse data, such as claims and viewpoints on controversial topics, their sources and contexts (events, entities). This data constitutes a valuable source of insights for studies into misinformation spread, bias reinforcement, echo chambers or political agenda setting. Computational methods, mostly from the field of NLP, have emerged that tackle a wide range of tasks in this context, including argument and opinion mining, claim detection, checkworthiness detection, stance detection or fact verification. However, computational models require robust definitions of classes and concepts under investigation. Thus, these computational tasks require a strong interdisciplinary and epistemological foundation, specifically with respect to the underlying definitions of key concepts such as claims, arguments, stances, check-worthiness or veracity. This requires a highly interdisciplinary approach combining expertise from fields such as communication studies, computational linguistics and computer science. As opposed to facts, claims are inherently more complex. Their interpretation strongly depends on the context and a variety of intentional or unintended meanings, where terminology and conceptual understandings strongly diverge across communities. From a computational perspective, in order to address this complexity, the synergy of multiple approaches, coming both from symbolic (knowledge representation) and statistical AI seem to be promising to tackle such challenges. This workshop aims at strengthening the relations between these communities, providing a forum for shared works on the modeling, extraction and analysis of discourse on the Web. It will address the need for a shared understanding and structured knowledge about discourse data in order to enable machine-interpretation, discoverability and reuse, in support of scientific or journalistic studies into the analysis of societal debates on the Web. Beyond research into information and knowledge extraction, data consolidation and modeling for knowledge graphs building, the workshop targets communities focusing on the analysis of online discourse, relying on methods from machine learning, natural language processing, large language models and Web data mining.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1418–1421},
numpages = {4},
keywords = {computational fact-checking, computational journalism, intent detection, knowledge graphs, language models, mis- and dis-information, online discourse analysis, social web mining, stance and viewpoint discovery},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3640457.3688181,
author = {Jamet, Henri and Manderlier, Maxime and Shrestha, Yash Raj and Vlachos, Michalis},
title = {Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688181},
doi = {10.1145/3640457.3688181},
abstract = {Learning a new language can be challenging. To help learners, we built a recommendation system that suggests texts and videos based on the learners’ skill level of the language and topic interests. Our system analyzes content to determine its difficulty and topic, and, if needed, can simplify complex texts while maintaining semantics. Our work explores the holistic use of Large Language Models (LLMs) for the various sub-tasks involved for accurate recommendations: difficulty estimation and simplification, graph recommender engine, topic estimation. We present a comprehensive evaluation comparing zero-shot and fine-tuned LLMs, demonstrating significant improvements in French content difficulty prediction (18-56%), topic prediction accuracy (27%), and recommendation relevance (up to 18% NDCG increase).},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {987–992},
numpages = {6},
keywords = {digital education, extensive reading, large language models, machine learning},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3597503.3639183,
author = {Ahmed, Toufique and Pai, Kunal Suresh and Devanbu, Premkumar and Barr, Earl},
title = {Automatic Semantic Augmentation of Language Model Prompts (for Code Summarization)},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639183},
doi = {10.1145/3597503.3639183},
abstract = {Large Language Models (LLM) are a new class of computation engines, "programmed" via prompt engineering. Researchers are still learning how to best "program" these LLMs to help developers. We start with the intuition that developers tend to consciously and unconsciously collect semantics facts, from the code, while working. Mostly these are shallow, simple facts arising from a quick read. For a function, such facts might include parameter and local variable names, return expressions, simple pre- and post-conditions, and basic control and data flow, etc.One might assume that the powerful multi-layer architecture of transformer-style LLMs makes them implicitly capable of doing this simple level of "code analysis" and extracting such information, while processing code: but are they, really? If they aren't, could explicitly adding this information help? Our goal here is to investigate this question, using the code summarization task and evaluate whether automatically augmenting an LLM's prompt with semantic facts explicitly, actually helps.Prior work shows that LLM performance on code summarization benefits from embedding a few code &amp; summary exemplars in the prompt, before the code to be summarized. While summarization performance has steadily progressed since the early days, there is still room for improvement: LLM performance on code summarization still lags its performance on natural-language tasks like translation and text summarization.We find that adding semantic facts to the code in the prompt actually does help! This approach improves performance in several different settings suggested by prior work, including for three different Large Language Models. In most cases, we see improvements, as measured by a range of commonly-used metrics; for the PHP language in the challenging CodeSearchNet dataset, this augmentation actually yields performance surpassing 30 BLEU1. In addition, we have also found that including semantic facts yields a substantial enhancement in LLMs' line completion performance.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {220},
numpages = {13},
keywords = {LLM, code summarization, program analysis, prompt engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3675094.3678995,
author = {Tang, Yiliu and Situ, Jason and Huang, Yun},
title = {Beyond User Experience: Technical and Contextual Metrics for Large Language Models in Extended Reality},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678995},
doi = {10.1145/3675094.3678995},
abstract = {Spatial Computing involves interacting with the physical world through spatial data manipulation, closely linked with Extended Reality (XR), which includes Virtual Reality (VR), Augmented Reality (AR), and Mixed Reality (MR). Large Language Models (LLMs) significantly enhance XR applications by improving user interactions through natural language understanding and content generation. Typical evaluations of these applications focus on user experience (UX) metrics, such as task performance, user satisfaction, and psychological assessments, but often neglect the technical performance of the LLMs themselves. This paper identifies significant gaps in current evaluation practices for LLMs within XR environments, attributing them to the novelty of the field, the complexity of spatial contexts, and the multimodal nature of interactions in XR. To address these gaps, the paper proposes specific metrics tailored to evaluate LLM performance in XR contexts, including spatial contextual awareness, coherence, proactivity, multimodal integration, hallucination, and question-answering accuracy. These proposed metrics aim to complement existing UX evaluations, providing a comprehensive assessment framework that captures both the technical and user-centric aspects of LLM performance in XR applications. The conclusion underscores the necessity for a dual-focused approach that combines technical and UX metrics to ensure effective and user-friendly LLM-integrated XR systems.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {640–643},
numpages = {4},
keywords = {augmented reality, evaluation metrics, extended reality, large language models, mixed reality, spatial computing, user experience, virtual reality},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3680533.3697066,
author = {Luo, Hanzhong and Gao, Fengsen and Fang, Ke and Liu, Dejian and Lin, Ziyun and Chan, Wai Kin (Victor)},
title = {Study with Confucius: An AI-Based Immersive Educational Game with Multiple Educational Modes},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697066},
doi = {10.1145/3680533.3697066},
abstract = {Current history education faces challenges in cultivating student immersion and knowledge retention. This study introduces an innovative educational game, "Study with Confucius", which blends traditional Chinese cultural education with AI technology. The game's objective is to enhance student engagement and learning outcomes by simulating historical figures and reconstructing historical backgrounds. Utilizing ChatGPT technology, the game assigns distinct educational abilities to different Agents, resulting in three unique educational modes. Players interact with these Agents, learning classical knowledge and gaining insights into the associated wisdom and moral culture. User study findings demonstrate that the game improves student immersion and their understanding and memorization of knowledge. This game offers adolescents a novel learning approach, where they can engage with and inherit traditional culture through interactive and enjoyable means.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {9},
numpages = {6},
keywords = {History education, agent, educational game, immersion},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3610977.3634969,
author = {Karli, Ulas Berk and Chen, Juo-Tung and Antony, Victor Nikhil and Huang, Chien-Ming},
title = {Alchemist: LLM-Aided End-User Development of Robot Applications},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634969},
doi = {10.1145/3610977.3634969},
abstract = {Large Language Models (LLMs) have the potential to catalyze a paradigm shift in end-user robot programming---moving from the conventional process of user specifying programming logic to an iterative, collaborative process in which the user specifies desired program outcomes while LLM produces detailed specifications. We introduce a novel integrated development system, Alchemist, that leverages LLMs to empower end-users in creating, testing, and running robot programs using natural language inputs, aiming to reduce the required knowledge for developing robot applications. We present a detailed examination of our system design and provide an exploratory study involving true end-users to assess capabilities, usability, and limitations of our system. Through the design, development, and evaluation of our system, we derive a set of lessons learned from the use of LLMs in robot programming. We discuss how LLMs may be the next frontier for democratizing end-user development of robot applications.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {361–370},
numpages = {10},
keywords = {code generation, end-user development, robot programming},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3610978.3640671,
author = {Macdonald, Jacob P. and Mallick, Rohit and Wollaber, Allan B. and Pe\~{n}a, Jaime D. and McNeese, Nathan and Siu, Ho Chit},
title = {Language, Camera, Autonomy! Prompt-engineered Robot Control for Rapidly Evolving Deployment},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640671},
doi = {10.1145/3610978.3640671},
abstract = {The Context-observant LLM-Enabled Autonomous Robots (CLEAR) platform offers a general solution for large language model (LLM)-enabled robot autonomy. CLEAR-controlled robots use natural language to perceive and interact with their environment: contextual description deriving from computer vision and optional human commands prompt intelligent LLM responses that map to robotic actions. By emphasizing prompting, system behavior is programmed without manipulating code, and unlike other LLM-based robot control methods, we do not perform any model fine-tuning. CLEAR employs off-the-shelf pre-trained machine learning models for controlling robots ranging from simulated quadcopters to terrestrial quadrupeds. We provide the open-source CLEAR platform, along with sample implementations for a Unity-based quadcopter and Boston Dynamics Spot® robot. Each LLM used, GPT-3.5, GPT-4, and LLaMA2, exhibited behavioral differences when embodied by CLEAR, contrasting in actuation preference, ability to apply new knowledge, and receptivity to human instruction. GPT-4 demonstrates best performance compared to GPT-3.5 and LLaMA2, showing successful task execution 97% of the time. The CLEAR platform contributes to HRI by increasing the usability of robotics for natural human interaction.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {717–721},
numpages = {5},
keywords = {computer vision, large language models, robotics, software},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3613905.3650937,
author = {Xiao, Ruiwei and Hou, Xinying and Stamper, John},
title = {Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650937},
doi = {10.1145/3613905.3650937},
abstract = {Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students’ problem-solving and learning, we conducted a think-aloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing help responses from content, format, and granularity levels to accurately identify and meet students’ learning needs.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {142},
numpages = {10},
keywords = {GPT, Help-seeking, Introductory Programming, Large Language Model, Programming Hint},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3626252.3630764,
author = {Wang, Sierra and Mitchell, John and Piech, Chris},
title = {A Large Scale RCT on Effective Error Messages in CS1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630764},
doi = {10.1145/3626252.3630764},
abstract = {In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1395–1401},
numpages = {7},
keywords = {cs1, error messages, gpt, llm, randomized control trial},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3613904.3642024,
author = {Rajashekar, Niroop Channa and Shin, Yeo Eun and Pu, Yuan and Chung, Sunny and You, Kisung and Giuffre, Mauro and Chan, Colleen E and Saarinen, Theo and Hsiao, Allen and Sekhon, Jasjeet and Wong, Ambrose H and Evans, Leigh V and Kizilcec, Rene F. and Laine, Loren and Mccall, Terika and Shung, Dennis},
title = {Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642024},
doi = {10.1145/3613904.3642024},
abstract = {Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven’t been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {20},
keywords = {Artificial Intelligence, Clinical Decision Support Systems, Electronic Health Record, Health-Clinical, Machine Learning, Medical: Nursing Homes/Hospitals, Qualitative Methods, Quantitative Methods, Workflows},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3626253.3633431,
author = {Shaffer, Cliff and Brusilovsky, Peter and Koedinger, Ken and Price, Thomas and Barnes, Tiffany and Mostafavi, Behrooz},
title = {Ninth SPLICE Workshop on Technology and Data Infrastructure for CS Education Research},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633431},
doi = {10.1145/3626253.3633431},
abstract = {Many SIGCSE attendees are either developing or using online educational tools, and all will benefit from better interoperability among these tools and better analysis of the clickstream data coming from those tools. New tools for analyzing big data leveraged by AI (e.g., deep learning for assessment) in turn improve both content and pedagogy, thus setting up a virtuous cycle fueling learning discoveries and leveraging innovation in AI: Online technologies → big data analysis → better online technologies. This NSF-supported workshop is the latest in a series of SPLICE workshops, and is a continuation of our event at SIGCSE 2023, where the SPLICE-Portal, a dedicated socio-technical research infrastructure for Computing Education Research, was presented. This year, we continue the work with several new SPLICE community working groups, including those on Dashboards, Large Language Models, Parsons Problems, and Smart Learning Content Protocols. We continue to build upon our existing collaborations developed over the course of the project to engage more members of the community in tasks that will advance the project agenda.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1904},
numpages = {1},
keywords = {collaborative tools, computing education research, online technologies},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3700297.3700342,
author = {Chen, Ping and Alias, Syazwina Binti},
title = {Opportunities and Challenges in the Cultivation of Software Development Professionals in the Context of Large Language Models},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700342},
doi = {10.1145/3700297.3700342},
abstract = {In the context of the rapid development of Large Language Models (LLMs), the field of software development has undergone significant transformations presenting both opportunities and challenges for software development professional cultivation. This study systematically analyzes the applications of LLMs in software development and their impact on this cultivation, exploring the opportunities and challenges in enhancing programming efficiency, promoting personalized learning, improving interdisciplinary skills, and addressing over-reliance on LLMs and related tools. Through literature analysis, this study reviews the impact of LLMs on programming efficiency, code quality, and project management and evaluates the requirements and directions for professional cultivation in response to these changes. The research results indicate that while LLMs bring numerous opportunities, they also pose challenges such as rapid technological updates and a tendency toward over-reliance on tools. Therefore, this study proposes a series of optimized professional cultivation strategies to adapt to the technological developments and industry demands of the new era, thereby enhancing the capability of higher education institutions to cultivate software professionals who meet future needs.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {259–267},
numpages = {9},
keywords = {Cultivation, Educational Reform, Large Language Models, Personalized Learning, Software Development Professionals},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3636555.3636846,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, Jos\'{e} and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636846},
doi = {10.1145/3636555.3636846},
abstract = {Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {12–23},
numpages = {12},
keywords = {ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1145/3649850,
author = {Zhang, Jialu and Cambronero, Jos\'{e} Pablo and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
title = {PyDex: Repairing Bugs in Introductory Python Assignments using LLMs},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649850},
doi = {10.1145/3649850},
abstract = {Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system -- PyDex -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {133},
numpages = {25},
keywords = {AI for programming education, automated program repair, large language models}
}

@inproceedings{10.1145/3650212.3680342,
author = {He, Yifeng and Huang, Jiabo and Rong, Yuyang and Guo, Yiwen and Wang, Ethan and Chen, Hao},
title = {UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680342},
doi = {10.1145/3650212.3680342},
abstract = {The remarkable capability of large language models (LLMs) in 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
generating high-quality code has drawn increasing attention 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
in the software testing community.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
However, existing code LLMs often demonstrate unsatisfactory capabilities in generating accurate, complete tests
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
since they were trained on code snippets collected without 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
differentiating between code for testing and for other purposes.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this paper, we present a large-scale dataset, UniTSyn, which can enhance LLMs for Unit Test Synthesis. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Associating tests with the tested functions is crucial for LLMs to infer the expected behavior and the logic paths to be verified.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
By leveraging Language Server Protocol, UniTSyn achieves the challenging goal of collecting focal-test pairs without per-project execution setups or per-language heuristics, which tend to be fragile and difficult to scale.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Containing 2.7 million focal-test pairs across five mainstream programming languages, it can enhance the test generation ability of LLMs.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Our experiments demonstrate that, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
by building an autoregressive LLM based on UniTSyn,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
we can achieve significant benefits in learning and understanding unit test representations, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
resulting in improved generation accuracy and code coverage 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
across all the evaluated programming languages.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1061–1072},
numpages = {12},
keywords = {Large language models, dataset, software testing, test case generation},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3631700.3665227,
author = {Fenu, Gianni and Galici, Roberta and Marras, Mirko and Reforgiato, Diego},
title = {Exploring Student Interactions with AI in Programming Training},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665227},
doi = {10.1145/3631700.3665227},
abstract = {In recent years, the integration of artificial intelligence (AI) in education has collected significant attention due to its potential to revolutionize learning experiences and support student skill development. This study delves into the dynamics of student interactions with AI support within the domain of C programming education, with a specific focus on the utilization of ChatGPT, a conversational AI model, during training sessions. Through manual clustering analysis, this research unveils distinct patterns of student engagement, elucidating diverse problem-solving approaches and varying levels of interaction with ChatGPT. Our findings underscore the importance of acknowledging individual differences in learning strategies and preferences, highlighting the necessity for personalized educational interventions tailored to meet the diverse needs of learners. However, despite the strides made in AI-supported learning, gaps persist in the existing literature, particularly concerning our understanding of how students approach prompts and exercises when utilizing AI-driven educational tools. This research aims to address this gap by shedding light on the nuanced dynamics of student-AI interactions during training of C programming, offering insights into effective pedagogical strategies and instructional design principles for integrating AI technologies into educational settings. This study makes a significant contribution to the continuous endeavors of educators and AI developers by furthering the discussion on AI-facilitated learning. It aims to enhance student engagement, learning outcomes, and overall educational experiences through the integration of technology into learning environments.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {555–560},
numpages = {6},
keywords = {AI Assistance, ChatGPT, Large Language Models, Learning Strategies, Learning Support Systems, Programming Education},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3696409.3700273,
author = {Sugihara, Tomoya and Masuda, Shuntaro and Xiao, Ling and Yamasaki, Toshihiko},
title = {Language-Guided Self-Supervised Video Summarization Using Text Semantic Matching Considering the Diversity of the Video},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696409.3700273},
doi = {10.1145/3696409.3700273},
abstract = {Current video summarization methods rely heavily on supervised computer vision techniques, which demands time-consuming manual annotations. By leveraging the advantages of Large Language Models (LLMs) in context understanding, we aim to develop self-supervised video summarization models. Our method begins by generating captions for individual video frames, which are then synthesized into text summaries by LLMs. Subsequently, we measure semantic distance between the captions and the text summary. Notably, we propose a novel loss function to optimize our deep metric learning process by considering the diversity of the video. Finally, summarized videos can be generated by selecting the frames whose captions closely match the text summary. Our method achieves state-of-the-art performance on the SumMe dataset in rank correlation coefficients. Moreover, our method has a novel feature of being able to achieve personalized video summarization. Our source code is publicly available at https://github.com/sugitomoo/PDL.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia},
articleno = {109},
numpages = {1},
keywords = {Video summarization, Large language models, Self-supervised learning, Deep metric learning, Personalized video summarization},
location = {
},
series = {MMAsia '24}
}

@inproceedings{10.1145/3689092.3689402,
author = {Zhang, Zixing and Dong, Zhongren and Gao, Zhiqiang and Gao, Shihao and Wang, Donghao and Chen, Ciqiang and Nie, Yuhan and Zhao, Huan},
title = {Open Vocabulary Emotion Prediction Based on Large Multimodal Models},
year = {2024},
isbn = {9798400712036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689092.3689402},
doi = {10.1145/3689092.3689402},
abstract = {The Multimodal Emotion Recognition (MER 2024) Challenge focuses on recognizing emotions through the integration of audio, language, and visual signals, driving advancements in the field of affective computing. This study presents our approach for the MER-OV sub-challenge, concentrating on open-vocabulary emotion recognition. We innovatively employ Optical Character Recognition (OCR) technology to optimize video subtitles, thereby enhancing the accuracy of textual descriptions. Additionally, we utilize in-context learning techniques with large language models (LLMs) for open-vocabulary emotion prediction. By incorporating video content analysis, we leverage large multimodal models (LMMs) to further improve the accuracy of emotion prediction. Our proposed text-only modality-based open-vocabulary emotion prediction method achieves an average score of 51.0% on the training set, and the multimodal open-vocabulary emotion prediction method achieves an average score of 59.1%. This surpasses the best model in the baseline, GPT-4V, which has a score of 56.0%, achieving a state-of-the-art (SOTA) result.},
booktitle = {Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing},
pages = {99–103},
numpages = {5},
keywords = {large language models, large multimodal models, multimodal emotion recognition},
location = {Melbourne VIC, Australia},
series = {MRAC '24}
}

@inproceedings{10.1145/3639474.3640068,
author = {Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan},
title = {Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640068},
doi = {10.1145/3639474.3640068},
abstract = {Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct.In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {1–11},
numpages = {11},
keywords = {software engineering education, AI-generated code, AI-generated code detection},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3637528.3671501,
author = {Jiang, Zhe and Zhao, Liang and Zhou, Xun and Zhang, Junbo and Shekhar, Shashi and Ye, Jieping},
title = {The 4th KDD Workshop on Deep Learning for Spatiotemporal Data, Applications, and Systems (DeepSpatial'24)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671501},
doi = {10.1145/3637528.3671501},
abstract = {Over the last decades, a rapidly growing volume of spatiotemporal data has been collected from smartphones and GPS, terrestrial, seaborne, airborne, and spaceborne sensors, as well as computational simulations. Meanwhile, advances in deep learning technologies, especially the recent breakthroughs of generative AI and foundation models such as Large Language Models (LLMs) and Large Vision Models (LVMs), have achieved tremendous success in natural language processing and computer vision applications. There is growing anticipation of the same level of accomplishment of AI on spatiotemporal data in tackling grand societal challenges, such as national water resource management, monitoring coastal hazards, energy and food security, as well as mitigation and adaptation to climate change. When deep learning, especially emerging foundation models, intersects spatiotemporal data in scientific domains, it opens up new opportunities and challenges. The workshop aims to bring together academic researchers in both AI and scientific domains, government program managers, leaders from non-profit organizations, as well as industry executives to brainstorm and debate on the emerging opportunities and novel challenges of deep learning (foundation models) for spatiotemporal data inspired by real-world scientific applications.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6722–6723},
numpages = {2},
keywords = {deep learning, foundation models, spatiotemporal data},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3644116.3644294,
author = {Zhu, Jinyang and Gong, Qingyue and Zhou, Chunfang and Luan, Huidan},
title = {ZhongJing: A Locally Deployed Large Language Model for Traditional Chinese Medicine and Corresponding Evaluation Methodology: A Large Language Model for data fine-tuning in the field of Traditional Chinese Medicine, and a new evaluation method called TCMEval are proposed},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644294},
doi = {10.1145/3644116.3644294},
abstract = {The success of ChatGPT has showcased the potential applications of Large Language Models (LLMs) in the field of Traditional Chinese Medicine (TCM), encompassing areas such as medical diagnosis, adjunctive therapy, and TCM talent cultivation. However, the current challenges, including hardware constraints, insufficient model domain knowledge, and difficulties in domain-specific evaluation, have constrained the fusion of LLMs with TCM. In an attempt to address these issues, this paper introduces ZhongJing, a domain-specific LLM fine-tuned within the domain of TCM, capable of generating responses at a rate of 8 tokens per second, smoothly operating on local personal computers. To assess the model's domain expertise, this paper introduces the TCMEval evaluation method, designed concerning medical students' exams. Experimental results demonstrate that ZhongJing achieves a 6.49 TCMEval Score improvement over Chinese-LLaMA2 in the field of TCM, indicating the model's ability to generate more specialized responses compared to baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1036–1042},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3649409.3691093,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui},
title = {Code Metrics, Rules of Thumb for Introductory CS},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691093},
doi = {10.1145/3649409.3691093},
abstract = {In response to the recent surge in easily accessible generative AI, Harvey Mudd College has integrated AI-assisted coding into the introductory Computer Science course. In this context, a question arises: How do we measure the quality of students' code when AI-generated code is present?Allowing generative AI to write coding assignments comes with the expectation of improved efficiency and accuracy. While generative AI is a useful tool, it merely supplements fundamental computing skills. This technological step towards being fully syntax-free allows for emphasis on the already important skill of developing problem-solving and critical thinking skills in more abstract contexts. In past years, metrics were designed to measure quantitative aspects of code, but these metrics alone are insufficient when evaluating how code written with the assistance of AI will perform in broader applications. When students submit code written with the assistance of generative AI, they are still expected to meet standards given by past metrics, such as Correctness and Complexity. To establish foundational computing skills, students will also be held to new standards and evaluated by new metrics such as Individuality and Ambition.While the model does give objective measures of the metrics, due to the fast-evolving nature of programming, predefined rules-of-thumb for these metrics are not provided. As users of our system, we recognize that evaluating the measurements will require our judgment, which will evolve over time. This work offers the foundation for that evolution.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {314–315},
numpages = {2},
keywords = {computing as a general education requirement, computing as a shared literacy, generative AI, undergraduate-universal computing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3597503.3639223,
author = {Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
title = {Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639223},
doi = {10.1145/3597503.3639223},
abstract = {Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by 'delays in merging pull requests') can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue comments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels.In this paper, we explore zero-shot LLMs that are pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frustration in the last year of development of a popular open-source project, revealing several interesting insights.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {182},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@article{10.1145/3701728,
author = {Luo, Xiangzhong and Liu, Di and Kong, Hao and Huai, Shuo and Chen, Hui and Xiong, Guochu and Liu, Weichen},
title = {Efficient Deep Learning Infrastructures for Embedded Computing Systems: A Comprehensive Survey and Future Envision},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
issn = {1539-9087},
url = {https://doi.org/10.1145/3701728},
doi = {10.1145/3701728},
abstract = {Deep neural networks (DNNs) have recently achieved impressive success across a wide range of real-world vision and language processing tasks, spanning from image classification to many other downstream vision tasks, such as object detection, tracking, and segmentation. However, previous well-established DNNs, despite being able to maintain superior accuracy, have also been evolving to be deeper and wider and thus inevitably necessitate prohibitive computational resources for both training and inference. This trend further enlarges the computational gap between computation-intensive DNNs and resource-constrained embedded computing systems, making it challenging to deploy powerful DNNs in real-world embedded computing systems towards ubiquitous embedded intelligence. To alleviate this computational gap and enable ubiquitous embedded intelligence, we focus in this survey on discussing recent efficient deep learning infrastructures for embedded computing systems, spanning from training to inference, from manual to automated, from convolutional neural networks to transformers, from transformers to vision transformers, from vision models to large language models, from software to hardware, and from algorithms to applications. Specifically, we discuss recent efficient deep learning infrastructures for embedded computing systems from the lens of (1) efficient manual network design for embedded computing systems, (2) efficient automated network design for embedded computing systems, (3) efficient network compression for embedded computing systems, (4) efficient on-device learning for embedded computing systems, (5) efficient large language models for embedded computing systems, (6) efficient deep learning software and hardware for embedded computing systems, and (7) efficient intelligent applications for embedded computing systems. We also envision promising future directions and trends, which have the potential to deliver more ubiquitous embedded intelligence. We believe this survey has its merits and can shed light on future research, which can largely help researchers to quickly and smoothly get started in this emerging field.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = dec,
articleno = {21},
numpages = {100},
keywords = {Embedded computing systems, embedded intelligence, artificial intelligence, efficient deep learning algorithms, efficient network design, efficient neural architecture search, efficient model compression, efficient on-device learning, efficient large language models, efficient deep learning software and hardware, intelligent embedded applications}
}

@inproceedings{10.1145/3672539.3686351,
author = {Lu, Qiuyu and Fang, Jiawei and Yao, Zhihao and Yang, Yue and Lyu, Shiqing and Mi, Haipeng and Yao, Lining},
title = {Large Language Model Agents Enabled Generative Design of Fluidic Computation Interfaces},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686351},
doi = {10.1145/3672539.3686351},
abstract = {The creation of interactive devices is a major area of interest. However, traditional design tools in this field often require a significant learning curve and may not effectively support creative ideation. This study explores the use of fluidic computation interfaces as a case study to examine the potential of enhancing design tools for physical devices with Large Language Model (LLM) agents. With LLM agents, the Generative Design Tool (GDT) can understand the capabilities and limitations of new devices, suggest diverse, insightful, and practical application scenarios, and recommend designs that are technically and contextually appropriate. Additionally, it generates the necessary design parameters for the traditional components of the design tool to visualize results and create files for fabrication.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {76},
numpages = {3},
keywords = {Generative Design, Large Language Model, Novel Devices},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@article{10.5555/3665609.3665633,
author = {Liu, Sa and Grey, Brian and Watkins, Ryan and Chu, Chad and Grim, Phillip and McManus, Thomas},
title = {Assessing Risks, Challenges and Opportunities of Generative AI in Computer Programming Education --- Lightning Talk},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has the potential to transform the education sector by enhancing teaching and learning experiences. According to Sal Khan, founder of Khan Academy, AI is about to start "the biggest positive transformation that education has ever seen"1 by making high-quality personalized tutoring available (tuition free) to everyone on the planet. Given AI's, and more specifically Generative AI's (GAI), rapidly developing capabilities (e.g., to provide tailored feedback, ask questions of students, give examples and non-examples, and offer general learning support), incorporating GAI into programming education has the potential to enhance student engagement and learning outcomes. At the same time, they identified challenges in using GAI, such as its inability to answer some questions and its tendency to provide incorrect or incomplete responses. Students also report an increase in anxiety surrounding GAI and its potential effects on future professional opportunities. Outside of the classroom there is likewise an increasing prevalence of GAI in computational professions, making it crucial to equip students with the necessary knowledge and skills to effectively, responsibly, and ethically utilize GAI. Rather than avoiding the use of GAI in the classroom, in this study we aim to investigate the pros and cons of leveraging GAI's capabilities to offer personalized guidance and assistance to students as they learn programming. By doing this research, we are learning to create more interactive and engaging learning experiences that better equip students with the skills and knowledge needed to succeed in the field of programming. This project, which is currently being conducted, was designed to address this research question: To what extent does the incorporation of GAI impact students' engagement, motivation, and achievement, particularly with the material in Intro to Programming courses and their chosen STEM field of study? It is utilizing case studies that focus on the integration of GAI into computer programming education. The team has 1) developed a series of GAI-supported teaching modules specifically designed to improve problem-solving skills in programming tasks among undergraduate students; and 2) is in the process of analyzing student feedback on GAI integration in computer programming education. This project offers an important exploration into the intersection of GAI and programming education, with the expectation that results will provide useful guidance for programming instructors who are adapting their instructional strategies for the emerging role of GAI in programming. The team will briefly present the status of the research and early insights from the project, and then engage with the audience on how lessons learned from this work can pragmatically shape programming courses in their institutions. Quick tips, takeaways, and prompting strategies will be shared throughout this interactive lighting talk.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {210–211},
numpages = {2}
}

@inproceedings{10.1145/3643991.3645072,
author = {Grewal, Balreet and Lu, Wentao and Nadi, Sarah and Bezemer, Cor-Paul},
title = {Analyzing Developer Use of ChatGPT Generated Code in Open Source GitHub Projects},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645072},
doi = {10.1145/3643991.3645072},
abstract = {The rapid development of large language models such as ChatGPT have made them particularly useful to developers in generating code snippets for their projects. To understand how ChatGPT's generated code is leveraged by developers, we conducted an empirical study of 3,044 ChatGPT-generated code snippets integrated within GitHub projects. A median of 54% of the generated lines of code is found in the project's code and this code typically remains unchanged once added. The modifications of the 76 code snippets that changed in a subsequent commit, consisted of minor functionality changes and code reorganizations that were made within a day. Our findings offer insights that help drive the development of AI-assisted programming tools. We highlight the importance of making changes in ChatGPT code before integrating it into a project.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {157–161},
numpages = {5},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3613905.3650868,
author = {Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan},
title = {Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650868},
doi = {10.1145/3613905.3650868},
abstract = {In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {9},
keywords = {AI facilitator, Collaborative Learning, Human-AI Collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3613904.3642016,
author = {Arawjo, Ian and Swoopes, Chelse and Vaithilingam, Priyan and Wattenberg, Martin and Glassman, Elena L.},
title = {ChainForge: A Visual Toolkit for Prompt Engineering and LLM Hypothesis Testing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642016},
doi = {10.1145/3613904.3642016},
abstract = {Evaluating outputs of large language models (LLMs) is challenging, requiring making—and making sense of—many responses. Yet tools that go beyond basic prompting tend to require knowledge of programming APIs, focus on narrow domains, or are closed-source. We present ChainForge, an open-source visual toolkit for prompt engineering and on-demand hypothesis testing of text generation LLMs. ChainForge provides a graphical interface for comparison of responses across models and prompt variations. Our system was designed to support three tasks: model selection, prompt template design, and hypothesis testing (e.g., auditing). We released ChainForge early in its development and iterated on its design with academics and online users. Through in-lab and interview studies, we find that a range of people could use ChainForge to investigate hypotheses that matter to them, including in real-world settings. We identify three modes of prompt engineering and LLM hypothesis testing: opportunistic exploration, limited evaluation, and iterative refinement.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {304},
numpages = {18},
keywords = {auditing, language models, prompt engineering, toolkits, visual programming environments},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3626253.3635483,
author = {Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra},
title = {DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635483},
doi = {10.1145/3626253.3635483},
abstract = {Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1714–1715},
numpages = {2},
keywords = {ai in education, compiler error messages, cs1, error message enhancement, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3690123,
author = {Ramesh, Aninditha and Agarwal, Arav and Doughty, Jacob Arthur and Ramaneti, Ketan and Savelka, Jaromir and Sakr, Majd},
title = {A Benchmark for Testing the Capabilities of LLMs in Assessing the Quality of Multiple-choice Questions in Introductory Programming Education},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690123},
doi = {10.1145/3649165.3690123},
abstract = {There has been a growing interest in utilizing large language models (LLMs) for numerous educational applications. Recent studies have focused on the use of LLMs for generating various educational artifacts for programming education, such as programming exercises, model solutions, or multiple-choice questions (MCQs). The ability to efficiently and reliably assess the quality of such artifacts, both automatically and human generated, has become of paramount importance. Hence, there is a pressing need to develop and make available robust benchmarks. In this paper, we investigate an example use case of assessing the quality of programming MCQs. To that end, we carefully curated a data set of 192 MCQs annotated with quality scores based on a rubric that evaluates crucial aspects such as, e.g., their clarity, the presence of a single correct answer, and the quality of distractors. The results show that the task presents a considerable challenge even to the state-of-the-art LLMs and, hence, further research is needed. To further such research efforts in this important area we release the dataset as well as the extensible evaluation pipeline to the public.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {193–199},
numpages = {7},
keywords = {assessments, automated evaluation, claude, computing education, gpt-4, large language models, llama, llms, mcqs, multiple choice questions},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3643795.3648376,
author = {Fei, Haoxiang and Zhang, Yu and Zhang, Hongbo and Wang, Yanlin and Liu, Qing},
title = {MoonBit: Explore the Design of an AI-Friendly Programming Language},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648376},
doi = {10.1145/3643795.3648376},
abstract = {MoonBit, a new general-purpose programming language designed for cloud and edge computing, was initiated in late 2022, coinciding with the announcement of ChatGPT. Language models like GPT, capable of producing practical programs, are revolutionizing the way we write programs and interact with computers. However, significant challenges persist, such as the models' inability to understand the global context of a whole project with its dependencies, the need for human verification and correction of generated code, and the lack of assurance in meeting basic requirements like syntactic correctness.In this paper, we explore the design of the MoonBit language highlighting its AI integration, emphasizing the synergy between traditional code intelligence and large language model capabilities. We also introduce a real-time, semantics-based sampler to guide the inference process of language models. This approach ensures the generated programs are both syntactically correct and free from obvious semantic flaws, such as type errors. Crucially, this has been achieved with minimal impact on overall performance. Our evaluation demonstrates a notable improvement in code quality, achieved without sacrificing the models' responsiveness.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {79–83},
numpages = {5},
keywords = {large language model, program synthesize, static analysis},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3625468.3652193,
author = {Rachabatuni, Pavan Kartheek and Principi, Filippo and Mazzanti, Paolo and Bertini, Marco},
title = {Context-aware chatbot using MLLMs for Cultural Heritage},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625468.3652193},
doi = {10.1145/3625468.3652193},
abstract = {Multi-modal Large Language Models (MLLMs) are currently an extremely active research topic for the multimedia and computer vision communities, and show a significant impact in visual analysis and text generation tasks. MLLM's are well-versed in integrated understanding, analysis of complex data from cross modalities (i.e. text-image) and text generation with chat abilities. Almost all MLLM's, focus on alignment of image features to textual features for downstream text generation tasks includes detailed image description, visual question answering, stories and poems generation, phrase grounding, etc.. However, when focusing on visual question answering, questions that are highly relevant to the context of an image may not be answered correctly with the existing MLLM's, contrary to questions that are related to visual aspects. Moreover, generating meta data (context) for an image using present day MLLM's is hard task due to hallucinating characteristic of underlying Large Language Models (LLM's), and adequate contextual information cannot be directly derived from an image based perspective.Considering the cultural heritage domain, these issues hamper the introduction of multimedia chatbots as tools to support learning and understanding artworks, since contextual information is typically needed to better understand the content of the artworks themselves, and museum curators require that scientifically accurate information is provided to the users of such systems. In this paper we present a system that combines contextual description of the artworks to enhance the contextual visual question answering task.},
booktitle = {Proceedings of the 15th ACM Multimedia Systems Conference},
pages = {459–463},
numpages = {5},
keywords = {Chatbot, Cultural Heritage, Digital Learning, Museums, Visual Question Answering},
location = {Bari, Italy},
series = {MMSys '24}
}

@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

@inproceedings{10.1145/3657604.3662032,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662032},
doi = {10.1145/3657604.3662032},
abstract = {Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {51–62},
numpages = {12},
keywords = {active learning, generative ai, gpt, introductory programming, large language models, parsons problems, personalization},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3665601.3669848,
author = {Einy, Yael and Milo, Tova and Novgorodov, Slava},
title = {Cost-Effective LLM Utilization for Machine Learning Tasks over Tabular Data},
year = {2024},
isbn = {9798400706943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665601.3669848},
doi = {10.1145/3665601.3669848},
abstract = {Classic machine learning (ML) models excel in modeling tabular datasets but lack broader world knowledge due to the absence of pre-training, an area where Large Language Models (LLMs) stand out. This paper presents an effective method that bridges the gap, leveraging LLMs to enrich tabular data to enhance the performance of classical ML models. Despite the previously limited success of direct LLM application to tabular tasks due to their high computational demands, our approach selectively enriches datasets with essential world knowledge, balancing performance improvement with cost-effectiveness. This work advances the capabilities of traditional ML models and opens new avenues for research at the convergence of classical ML and LLMs, marking the onset of a new era in cost-effective data enrichment.},
booktitle = {Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
pages = {45–49},
numpages = {5},
keywords = {Data Enrichment, Data Integration, Large Language Models},
location = {Santiago, AA, Chile},
series = {GUIDE-AI '24}
}

@inproceedings{10.1145/3636555.3636889,
author = {Sonkar, Shashank and Chen, Xinghe and Le, Myco and Liu, Naiming and Basu Mallick, Debshila and Baraniuk, Richard},
title = {Code Soliloquies for Accurate Calculations in Large Language Models},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636889},
doi = {10.1145/3636555.3636889},
abstract = {High-quality conversational datasets are crucial for the successful development of Intelligent Tutoring Systems (ITS) that utilize a Large Language Model (LLM) backend. Synthetic student-teacher dialogues, generated using advanced GPT-4 models, are a common strategy for creating these datasets. However, subjects like physics that entail complex calculations pose a challenge. While GPT-4 presents impressive language processing capabilities, its limitations in fundamental mathematical reasoning curtail its efficacy for such subjects. To tackle this limitation, we introduce in this paper an innovative stateful prompt design. Our design orchestrates a mock conversation where both student and tutorbot roles are simulated by GPT-4. Each student response triggers an internal monologue, or ‘code soliloquy’ in the GPT-tutorbot, which assesses whether its subsequent response would necessitate calculations. If a calculation is deemed necessary, it scripts the relevant Python code and uses the Python output to construct a response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. The preliminary Subject Matter Expert evaluations reveal that our Higgs model, a fine-tuned LLaMA model, effectively uses Python for computations, which significantly enhances the accuracy and computational reliability of Higgs’ responses.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {828–835},
numpages = {8},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3701625.3701700,
author = {de Lima, Vitor Mesaque Alves and Marcacini, Ricardo Marcondes},
title = {Opinion Mining for App Reviews: Identifying and Prioritizing Emerging Issues for Software Maintenance and Evolution},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701700},
doi = {10.1145/3701625.3701700},
abstract = {Opinion mining for app reviews aims to analyze user comments on app stores to support software engineering activities, primarily software maintenance and evolution. One of the main challenges in maintaining software quality is promptly identifying emerging issues, such as bugs. However, manually analyzing these comments is challenging due to the large amount of textual data. Methods based on machine learning have been employed to automate opinion mining and address this issue. Gap. While recent methods have achieved promising results in extracting and categorizing issues from users’ opinions, existing studies mainly focus on assisting software engineers in exploring users’ historical behavior regarding app functionalities and do not explore mechanisms for trend detection and risk classification of emerging issues. Furthermore, these studies do not cover the entire issue analysis process through an unsupervised approach. Contribution. This work advances state of the art in opinion mining for app reviews by proposing an entire automated issue analysis approach to identify, prioritize, and monitor the risk of emerging issues. Our proposal introduces a two-fold approach that (i) identifies possible defective software requirements and trains predictive models for anticipating requirements with a higher probability of negative evaluation and (ii) detect issues in reviews, classifies them in a risk matrix with prioritization levels, and monitors their evolution over time. Additionally, we present a risk matrix construction approach from app reviews using the recent Large Language Models (LLMs). We introduce an analytical data exploration tool that allows engineers to browse the risk matrix, time series, heat map, issue tree, alerts, and notifications. Our goal is to minimize the time between the occurrence of an issue and its correction, enabling the quick identification of problems. Results. We processed over 6.6 million reviews across 20 domains to evaluate our proposal, identifying and ranking the risks associated with nearly 270,000 issues. The results demonstrate the competitiveness of our unsupervised approach compared to existing supervised models. Conclusions. We have proven that opinions extracted from user reviews provide crucial insights into app issues and risks and can be identified early to mitigate their impact. Our opinion mining process implements an entire automated issue analysis with risk-based prioritization and temporal monitoring.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {687–696},
numpages = {10},
keywords = {opinion mining, app reviews, issue detection, issue prioritization, software maintenance and evolution},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3627673.3679885,
author = {Li, Peiyu and Huang, Xiaobao and Tian, Yijun and Chawla, Nitesh V.},
title = {ChefFusion: Multimodal Foundation Model Integrating Recipe and Food Image Generation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679885},
doi = {10.1145/3627673.3679885},
abstract = {Significant work has been conducted in the domain of food computing, yet these studies typically focus on single tasks such as t2t (instruction generation from food titles and ingredients), i2t (recipe generation from food images), or t2i (food image generation from recipes). None of these approaches integrate all modalities simultaneously. To address this gap, we introduce a novel food computing foundation model that achieves true multimodality, encompassing tasks such as t2t, t2i, i2t, it2t, and t2ti. By leveraging large language models (LLMs) and pre-trained image encoder and decoder models, our model can perform a diverse array of food computing-related tasks, including food understanding, food recognition, recipe generation, and food image generation. Compared to previous models, our foundation model demonstrates a significantly broader range of capabilities and exhibits superior performance, particularly in food image generation and recipe generation tasks. We open-sourced ChefFusion at https://github.com/Peiyu-Georgia-Li/ChefFusion-Multimodal-Foundation-Model-Integrating-Recipe-and-Food-Image-Generation.git.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3872–3876},
numpages = {5},
keywords = {food image generation, llms, multimodal, recipe generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3691620.3695335,
author = {Moumoula, Micheline Benedicte and Kabore, Abdoul Kader and Klein, Jacques and Bissyande, Tegawende F.},
title = {Cross-lingual Code Clone Detection: When LLMs Fail Short Against Embedding-based Classifier},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695335},
doi = {10.1145/3691620.3695335},
abstract = {Cross-lingual code clone detection has gained attention in software development due to the use of multiple programming languages. Recent advances in machine learning, particularly Large Language Models (LLMs), have motivated a reexamination of this problem.This paper evaluates the performance of four LLMs and eight prompts for detecting cross-lingual code clones, as well as a pretrained embedding model for classifying clone pairs. Both approaches are tested on the XLCoST and CodeNet datasets.Our findings show that while LLMs achieve high F1 scores (up to 0.98) on straightforward programming examples, they struggle with complex cases and cross-lingual understanding. In contrast, embedding models, which map code fragments from different languages into a common representation space, allow for the training of a basic classifier that outperforms LLMs by approximately 2 and 24 percentage points on the XLCoST and CodeNet datasets, respectively. This suggests that embedding models provide more robust representations, enabling state-of-the-art performance in cross-lingual code clone detection.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2474–2475},
numpages = {2},
keywords = {cross-language pairs, code clone detection, large language model, prompt engineering, embedding model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.5555/3635637.3663007,
author = {Niu, Tong and Zhang, Weihao and Zhao, Rong},
title = {Solution-oriented Agent-based Models Generation with Verifier-assisted Iterative In-context Learning},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Agent-based models (ABMs) stand as an essential paradigm for proposing and validating hypothetical solutions or policies aimed at addressing challenges posed by complex systems and achieving various objectives. This process demands labor-intensive endeavors and multidisciplinary expertise. Large language models (LLMs) encapsulating cross-domain knowledge and programming proficiency could potentially alleviate the difficulty of this process. However, LLMs excel in handling sequential information, making it challenging for analyzing the intricate interactions and nonlinear dynamics inherent in ABMs. Additionally, due to the lack of self-evaluation capability of LLMs, relying solely on LLMs is insufficient to effectively accomplish this process. In this paper, we present SAGE, a general solution-oriented ABM generation framework designed for automatic modeling and generating solutions for targeted problems. Unlike approaches reliant on expert handcrafting or resource-intensive neural network training, SAGE establishes a verifier-assisted iterative in-context learning process employing large language models (LLMs) to leverages their inherent cross-domain knowledge for tackling intricate demands from diverse domain scenarios. In SAGE, we introduce an semi-structured conceptual representation expliciting the intricate structures of ABMs and an objective representation to guide LLMs in modeling scenarios and proposing hypothetical solutions through in-context learning. To ensure the model executability and solution feasibility, SAGE devises a two-level verifier with chain-of-thought prompting tailored to the complex interactions and non-linear dynamics of ABMs, driving the iterative generation optimization. Moreover, we construct an evaluation dataset of solution-oriented ABMs from open sources. It contains practical models across various domains, completed with scenario descriptions and executable agent-based solutions. Evaluations by various LLMs demonstrate that SAGE leads to an average improvement of 18.7% in modeling quality and 38.1% in solution generation effectiveness. This work advances our understanding and ability in tackling complex real-world challenges across diverse domains through the application of ABM methodologies.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {1473–1481},
numpages = {9},
keywords = {automatic verification and generation, chain-of-thought prompting, iterative in-context learning, large language models, solution-oriented agent-based modeling},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3597503.3639187,
author = {Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad},
title = {Using an LLM to Help With Code Understanding},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639187},
doi = {10.1145/3597503.3639187},
abstract = {Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {97},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3678957.3688621,
author = {Zhong, Shu},
title = {Design Digital Multisensory Textile Experiences},
year = {2024},
isbn = {9798400704628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678957.3688621},
doi = {10.1145/3678957.3688621},
abstract = {The rise of Machine Learning (ML) is gradually digitalizing and reshaping the fashion industry, which is under pressure to achieve Net Zero. However, the integration of ML/AI for sustainable and circular practices remains limited due to a lack of domain-specific knowledge and data. My doctoral research aims to bridge this gap by designing digital multisensory textile experiences that enhance the understanding of the textile domain for both AI systems and humans. To this end, I develop TextileNet, the first fashion dataset using textile taxonomies for textile materials identification and classification via computer vision, and TextileBot, a domain-specific conversational agent. TextileBot integrates textile taxonomies with large language models (LLMs) to engage consumers in sustainable practices. Additionally, my research explores how multisensory experiences can improve user understanding and how AI perceives textiles. The overarching goal is to embed human expertise into machines, design immersive multisensory experiences, and facilitate natural human-AI interactions that promote sustainable practices.},
booktitle = {Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {642–646},
numpages = {5},
keywords = {AI for Social Good, Agents, Human-AI interaction, Machine Learning, Multimodal Large Language Models, Sustainability},
location = {San Jose, Costa Rica},
series = {ICMI '24}
}

@inproceedings{10.1145/3637528.3671897,
author = {Wu, Feijie and Li, Zitao and Li, Yaliang and Ding, Bolin and Gao, Jing},
title = {FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671897},
doi = {10.1145/3637528.3671897},
abstract = {Large language models (LLMs) show amazing performance on many domain-specific tasks after fine-tuning with some appropriate data. However, many domain-specific data are privately distributed across multiple owners. Thus, this dilemma raises the interest in how to perform LLM fine-tuning in federated learning (FL). However, confronted with limited computation and communication capacities, FL clients struggle to fine-tune an LLM effectively. To this end, we introduce FedBiOT, a resource-efficient LLM fine-tuning approach to FL. Specifically, our method involves the server generating a compressed LLM and aligning its performance with the full model. Subsequently, the clients fine-tune a lightweight yet important part of the compressed model, referred to as an adapter. Notice that as the server has no access to the private data owned by the clients, the data used for alignment by the server has a different distribution from the one used for fine-tuning by clients. We formulate the problem into a bi-level optimization problem to minimize the negative effect of data discrepancy and derive the updating rules for the server and clients. We conduct extensive experiments on LLaMA-2, empirically showing that the adapter has exceptional performance when reintegrated into the global LLM. The results also indicate that the proposed FedBiOT significantly reduces resource consumption compared to existing benchmarks, all while achieving comparable performance levels.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3345–3355},
numpages = {11},
keywords = {federated learning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3691620.3695524,
author = {Zhu, Ming and Karim, Mohimenul and Lourentzou, Ismini and Yao, Daphne},
title = {Semi-Supervised Code Translation Overcoming the Scarcity of Parallel Code Data},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695524},
doi = {10.1145/3691620.3695524},
abstract = {Neural code translation is the task of converting source code from one programming language to another. One of the main challenges is the scarcity of parallel code data, which hinders the ability of translation models to learn accurate cross-language alignments. In this paper, we introduce MIRACLE, a semi-supervised approach that improves code translation through synthesizing high-quality parallel code data and curriculum learning on code data with ascending alignment levels. MIRACLE leverages static analysis and compilation to generate synthetic parallel code datasets with enhanced quality and alignment to address the challenge of data scarcity. We evaluate the proposed method along with strong baselines including instruction-tuned Large Language Models (LLMs) for code. Our analysis reveals that LLMs pre-trained on open-source code data, regardless of their size, suffer from the "shallow translation" problem. This issue arises when translated code copies keywords, statements, and even code blocks from the source language, leading to compilation and runtime errors. Extensive experiments demonstrate that our method significantly mitigates this issue, enhancing code translation performance across multiple models in C++, Java, Python, and C. Remarkably, MIRACLE outperforms code LLMs that are ten times larger in size. MIRACLE also achieves up to a 43% improvement in C code translation with fewer than 150 annotated examples.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1545–1556},
numpages = {12},
keywords = {neural code translation, cross-language code alignment, semi-supervised learning, curriculum learning, static analysis},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1109/SC41406.2024.00089,
author = {An, Wei and Bi, Xiao and Chen, Guanting and Chen, Shanhuang and Deng, Chengqi and Ding, Honghui and Dong, Kai and Du, Qiushi and Gao, Wenjun and Guan, Kang and Guo, Jianzhong and Guo, Yongqiang and Fu, Zhe and He, Ying and Huang, Panpan and Li, Jiashi and Liang, Wenfeng and Liu, Xiaodong and Liu, Xin and Liu, Yiyuan and Liu, Yuxuan and Lu, Shanghao and Lu, Xuan and Nie, Xiaotao and Pei, Tian and Qiu, Junjie and Qu, Hui and Ren, Zehui and Sha, Zhangli and Su, Xuecheng and Sun, Xiaowen and Tan, Yixuan and Tang, Minghui and Wang, Shiyu and Wang, Yaohui and Wang, Yongji and Xie, Ziwei and Xiong, Yiliang and Xu, Yanhong and Ye, Shengfeng and Yu, Shuiping and Zha, Yukun and Zhang, Liyue and Zhang, Haowei and Zhang, Mingchuan and Zhang, Wentao and Zhang, Yichao and Zhao, Chenggang and Zhao, Yao and Zhou, Shangyan and Zhou, Shunfeng and Zou, Yuheng},
title = {Fire-Flyer AI-HPC: A Cost-Effective Software-Hardware Co-Design for Deep Learning},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00089},
doi = {10.1109/SC41406.2024.00089},
abstract = {The rapid progress in Deep Learning (DL) and Large Language Models (LLMs) has exponentially increased demands of computational power and bandwidth. This, combined with the high costs of faster computing chips and interconnects, has significantly inflated High Performance Computing (HPC) construction costs. To address these challenges, we introduce the Fire-Flyer AI-HPC architecture, a synergistic hardware-software co-design framework and its best practices. For DL training, we deployed the Fire-Flyer 2 with 10,000 PCIe A100 GPUs, achieved performance approximating the DGX-A100 while reducing costs by half and energy consumption by 40%. We specifically engineered HFReduce to accelerate allreduce communication and implemented numerous measures to keep our Computation-Storage Integrated Network congestion-free. Through our software stack, including HaiScale, 3FS, and HAI-Platform, we achieved substantial scalability by overlapping computation and communication. Our system-oriented experience from DL training provides valuable insights to drive future advancements in AI-HPC.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {83},
numpages = {23},
keywords = {All-Reduce, Artificial Intelligence Infrastructure, Best Practices, Cost-Effective, Deep Learning, High Performance Computing, Large Language Models, Machine Learning},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3626253.3635400,
author = {Hurley, Ethan and Okyere-Badoo, Joel},
title = {A Comparative Study of Few-Shot vs. Zero-Shot Prompting to Generate Quick and Useful Responses to Students' Periodic Reflections},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635400},
doi = {10.1145/3626253.3635400},
abstract = {Our study investigates the effectiveness of leveraging Large Language Models (LLMs), such as GPT-3.5, to generate responses to student reflections. Acknowledging the intensive nature of manually handling reflections, our investigation centers on crafting prompts to automate reflection response generation. Driven by fast and meaningful response generation to student reflections, we explored both Zero-Shot learning (ZSL) and Few-Shot learning (FSL) methodologies. Our research meticulously examined the facets of each approach, highlighting the significance of consistent and meaningful responses.The Few-Shot prompting approach involves creating a fundamental prompt based on reflection questions and desired responses, striving for consistency while facing challenges such as GPT-3.5 computational time and issues related to content "hallucinations." In contrast, Zero-Shot prompting utilizes the base prompt and response without the assistance of examples. The evaluation process entails a meticulous examination of the quality of GPT-3.5 responses compared to the original student reflections.In the future, our study foresees integrating our devised prompting techniques as a resource for educators to promptly grasp students' learning concerns and issues. Despite challenges, Few-Shot prompting stands out as the more reliable and relevant approach, particularly in the context of email-based formats. As Machine Learning and AI continue to advance, overcoming challenges and adjusting to fluctuations in student emotions and content remains a pivotal factor in fully harnessing the capabilities of LLMs for automating the generation of responses to student reflections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {artificial intelligence (ai), few-shot learning (fsl), large language models (llms), student reflections, zero-shot learning (zsl)},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636534.3690668,
author = {Laskaridis, Stefanos and Katevas, Kleomenis and Minto, Lorenzo and Haddadi, Hamed},
title = {MELTing Point: Mobile Evaluation of Language Transformers},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690668},
doi = {10.1145/3636534.3690668},
abstract = {Transformers have recently revolutionized the machine learning (ML) landscape, gradually making their way into everyday tasks and equipping our computers with "sparks of intelligence". However, their runtime requirements have prevented them from being broadly deployed on mobile. As personal devices become increasingly powerful at the consumer edge and prompt privacy becomes an ever more pressing issue, we explore the current state of mobile execution of Large Language Models (LLMs). To achieve this, we have created our own automation infrastructure, MELT, which supports the headless execution and benchmarking of LLMs on device, supporting different models, devices and frameworks, including Android, iOS and Nvidia Jetson devices. We evaluate popular instruction fine-tuned LLMs and leverage different frameworks to measure their end-to-end and granular performance, tracing their memory and energy requirements along the way.Our analysis is the first systematic study of on-device LLM execution, quantifying performance, energy efficiency and accuracy across various state-of-the-art models and showcases the state of on-device intelligence in the era of hyperscale models. Results highlight the performance heterogeneity across targets and corroborates that LLM inference is largely memory-bound. Quantization drastically reduces memory requirements and renders execution viable, but at a non-negligible accuracy cost. Drawing from its energy footprint and thermal behavior, the continuous execution of LLMs remains elusive, as both factors negatively affect user experience. Last, our experience shows that the ecosystem is still in its infancy, and algorithmic as well as hardware break-throughs can significantly shift the execution cost. We expect NPU acceleration, and framework-hardware co-design to be the biggest bet towards efficient standalone execution, with the alternative of offloading tailored towards edge deployments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {890–907},
numpages = {18},
keywords = {machine learning, mobile systems, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3631802.3631806,
author = {Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi},
title = {How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631806},
doi = {10.1145/3631802.3631806},
abstract = {As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them and the effect they have on learning to code. We present the results of a thematic analysis on a data set from 33 learners, aged 10-17, as they independently learned Python by working on 45 code-authoring tasks with access to an AI Code Generator based on OpenAI Codex. We explore several important questions related to how learners used LLM-based AI code generators, and provide an analysis of the properties of the written prompts and the resulting AI generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex in terms of syntax and logic, (C) properties of prompts written by learners in terms of relation to task description, language, clarity, and prompt crafting patterns, (D) properties of the AI-generated code in terms of correctness, complexity, and accuracy, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. Our findings reveal consistently positive trends between learners’ utilization of the Hybrid coding approach and their post-test evaluation scores, while showing consistent negative trends between the AI Single Prompt and the post-test evaluation scores. Furthermore, we offer insights into novice learners’ use of AI code generators in a self-paced learning environment, highlighting signs of over-reliance, self-regulation, and opportunities for enhancing AI-assisted learning tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {3},
numpages = {12},
keywords = {ChatGPT, Copilot, Introductory Programming, Large Language Models, OpenAI Codex, Self-paced Learning, Self-regulation},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3660650.3660673,
author = {Rajabi, Parsa and Kerslake, Chris},
title = {Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660673},
doi = {10.1145/3660650.3660673},
abstract = {In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {23},
numpages = {2},
keywords = {AI Literacy, AI in Education, AI-usage Policy, ChatGPT, Generative AI, Technical Writing},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3691620.3695322,
author = {Luo, Yang and Yu, Richard and Zhang, Fajun and Liang, Ling and Xiong, Yongqiang},
title = {Bridging Gaps in LLM Code Translation: Reducing Errors with Call Graphs and Bridged Debuggers},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695322},
doi = {10.1145/3691620.3695322},
abstract = {When using large language models (LLMs) for code translation of complex software, numerous compilation and runtime errors can occur due to insufficient context awareness. To address this issue, this paper presents a code translation method based on call graphs and bridged debuggers: TransGraph. TransGraph first obtains the call graph of the entire code project using the Language Server Protocol, which provides a detailed description of the function call relationships in the program. Through this structured view of the code, LLMs can more effectively handle large-scale and complex codebases, significantly reducing compilation errors. Furthermore, TransGraph, combined with bridged debuggers and dynamic test case generation, significantly reduces runtime errors, overcoming the limitations of insufficient test case coverage in traditional methods. In experiments on six datasets including CodeNet and Avatar, TransGraph outperformed existing code translation methods and LLMs in terms of translation accuracy, with improvements of up to 10.2%.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2448–2449},
numpages = {2},
keywords = {code translation, large language model, call graph, bridged debugger, language server protocol, runtime error, compilation error},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3643788.3648021,
author = {Lajko, Mark and Csuvik, Viktor and Gyimothy, Tibor and Vidacs, Laszlo},
title = {Automated Program Repair with the GPT Family, including GPT-2, GPT-3 and CodeX},
year = {2024},
isbn = {9798400705779},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643788.3648021},
doi = {10.1145/3643788.3648021},
abstract = {Automated Program Repair (APR) is a promising approach for addressing software defects and improving software reliability. There are various approaches to APR, including using Machine Learning (ML) techniques such as neural networks and evolutionary algorithms, as well as more traditional methods such as static analysis and symbolic execution. In recent years, there has been growing interest in using ML techniques for APR, including the use of large language models such as GPT-2 and GPT-3. These models have the ability to generate human-like text and code, making them well-suited for tasks such as generating repair patches for defective programs. In this paper, we explore the use of the GPT family (including GPT-2, GPT-J-6B, GPT-3 and Codex) for APR of JavaScript programs and evaluate their performance in terms of the number and quality of repair patches generated. Our results show that these state-of-the-art language models are able to generate repair patches that successfully fix the defects in the JavaScript programs, with Codex performing slightly better overall. To be precise, in our self-assembled dataset, Codex was able to generate 108 repair patches that are exactly the same as the developer fix for the first try. If we consider multiple patch generations, up to 201 buggy programs are being repaired automatically from the 1559 evaluation dataset (12.89%).},
booktitle = {Proceedings of the 5th ACM/IEEE International Workshop on Automated Program Repair},
pages = {34–41},
numpages = {8},
keywords = {automated program repair, transformers, GPT-3, codex, JavaScript},
location = {Lisbon, Portugal},
series = {APR '24}
}

@inproceedings{10.1145/3672539.3686776,
author = {Fang, Cathy Mengying and Chwalek, Patrick and Kuang, Quincy and Maes, Pattie},
title = {WatchThis: A Wearable Point-and-Ask Interface powered by Vision-Language Models for Contextual Queries},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686776},
doi = {10.1145/3672539.3686776},
abstract = {This paper introduces WatchThis, a novel wearable device that enables natural language interactions with real-world objects and environments through pointing gestures. Building upon previous work in gesture-based computing interfaces, WatchThis leverages recent advancements in Large Language Models (LLM) and Vision Language Models (VLM) to create a hands-free, contextual querying system. The prototype consists of a wearable watch with a rotating, flip-up camera that captures the area of interest when pointing, allowing users to ask questions about their surroundings in natural language. This design addresses limitations of existing systems that require specific commands or occupy the hands, while also maintaining a non-discrete form factor for social awareness. The paper explores various applications of this point-and-ask interaction, including object identification, translation, and instruction queries. By utilizing off-the-shelf components and open-sourcing the design, this work aims to facilitate further research and development in wearable, AI-enabled interaction paradigms.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {54},
numpages = {4},
keywords = {camera, pointing, vision language model, watch, wearable},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3605507.3610629,
author = {Gehringer, Edward F. and Wang, Jianxun George and Jilla, Sharan Kumar},
title = {Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs},
year = {2024},
isbn = {9798400702532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605507.3610629},
doi = {10.1145/3605507.3610629},
abstract = {The traditional model of assigning textbook problems for homework is endangered by the ability of students to find answers to almost any published problem on the web. An alternative is a dual-submission approach, where students submit their work, then receive the solutions, and submit a second metacognitive reflection, explaining any errors they made. Students’ scores can depend on the quality of their second submissions alone or the combined quality of their first and second submissions. We tried this approach in a class on parallel computer architecture. We report students’ personal experience based on their questionnaires responses. In addition, we quantitatively compare students’ performance on test questions related to dual-submission homework against their performance on other questions and previous semesters’ student performance on similar questions. Students overwhelmingly preferred this approach and thought they learned more from it, but evidence about whether it improved their learning was inconclusive. We also analyze the continued viability of this approach in the era of large language models.},
booktitle = {Proceedings of the Workshop on Computer Architecture Education},
pages = {41–47},
numpages = {7},
location = {Orlando, FL, USA},
series = {WCAE '23}
}

@inproceedings{10.1145/3663529.3663855,
author = {Sarda, Komal and Namrud, Zakeya and Litoiu, Marin and Shwartz, Larisa and Watts, Ian},
title = {Leveraging Large Language Models for the Auto-remediation of Microservice Applications: An Experimental Study},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663855},
doi = {10.1145/3663529.3663855},
abstract = {Runtime auto-remediation is crucial for ensuring the reliability and efficiency of distributed systems, especially within complex microservice-based applications. However, the complexity of modern microservice deployments often surpasses the capabilities of traditional manual remediation and existing autonomic computing methods. Our proposed solution harnesses large language models (LLMs) to generate and execute Ansible playbooks automatically to address issues within these complex environments. Ansible playbooks, a widely adopted markup language for IT task automation, facilitate critical actions such as addressing network failures, resource constraints, configuration errors, and application bugs prevalent in managing microservices. We apply in-context learning on pre-trained LLMs using our custom-made Ansible-based remediation dataset, equipping these models to comprehend diverse remediation tasks within microservice environments. Then, these tuned LLMs efficiently generate precise Ansible scripts tailored to specific issues encountered, surpassing current state-of-the-art techniques with high functional correctness (95.45%) and average correctness (98.86%).},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {358–369},
numpages = {12},
keywords = {Ansible, Auto-remediation, Autonomic computing, Cloud native applications, Code generation, Kubernetes, Large language models, Microservices, Prompt engineering, Real-time faults, Self-adaptive software},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3636555.3636853,
author = {Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti},
title = {Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636853},
doi = {10.1145/3636555.3636853},
abstract = {This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {742–748},
numpages = {7},
keywords = {Data Visualization, Feedback Generation, GPT-4, Learnersourcing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3626252.3630822,
author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
title = {dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630822},
doi = {10.1145/3626252.3630822},
abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1314–1320},
numpages = {7},
keywords = {ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3637528.3671913,
author = {Zhao, Haihong and Chen, Aochuan and Sun, Xiangguo and Cheng, Hong and Li, Jia},
title = {All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671913},
doi = {10.1145/3637528.3671913},
abstract = {Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains -- a paradigm we term 'All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains -- a paradigm we term 'One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approach called Graph COordinators for PrEtraining (GCOPE), that harnesses the underlying commonalities across diverse graph datasets to enhance few-shot learning. Our novel methodology involves a unification framework that amalgamates disparate graph datasets during the pretraining phase to distill and transfer meaningful knowledge to target tasks. Extensive experiments across multiple graph datasets demonstrate the superior efficacy of our approach. By successfully leveraging the synergistic potential of multiple graph datasets for pretraining, our work stands as a pioneering contribution to the realm of graph foundational model. Code available at https://github.com/cshhzhao/GCOPE.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4443–4454},
numpages = {12},
keywords = {graph neural networks, pretraining, prompt tuning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3664647,
title = {MM '24: Proceedings of the 32nd ACM International Conference on Multimedia},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3691620.3695349,
author = {Wang, Che and Zhang, Jiashuo and Gao, Jianbo and Xia, Libin and Guan, Zhi and Chen, Zhong},
title = {ContractTinker: LLM-Empowered Vulnerability Repair for Real-World Smart Contracts},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695349},
doi = {10.1145/3691620.3695349},
abstract = {Smart contracts are susceptible to being exploited by attackers, especially when facing real-world vulnerabilities. To mitigate this risk, developers often rely on third-party audit services to identify potential vulnerabilities before project deployment. Nevertheless, repairing the identified vulnerabilities is still complex and laborintensive, particularly for developers lacking security expertise. Moreover, existing pattern-based repair tools mostly fail to address real-world vulnerabilities due to their lack of high-level semantic understanding. To fill this gap, we propose ContractTinker, a Large Language Models (LLMs)-empowered tool for real-world vulnerability repair. The key insight is our adoption of the Chain-of-Thought approach to break down the entire generation task into subtasks. Additionally, to reduce hallucination, we integrate program static analysis to guide the LLM. We evaluate ContractTinker on 48 high-risk vulnerabilities. The experimental results show that among the patches generated by ContractTinker, 23 (48%) are valid patches that fix the vulnerabilities, while 10 (21%) require only minor modifications. A video of ContractTinker is available at https://youtu.be/HWFVi-YHcPE.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2350–2353},
numpages = {4},
keywords = {program repair, smart contract, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3649217.3653557,
author = {Farinetti, Laura and Canale, Lorenzo},
title = {Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653557},
doi = {10.1145/3649217.3653557},
abstract = {Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {401–407},
numpages = {7},
keywords = {chatbot development, creativity and critical thinking, database education, information retrieval, langchain framework, large language models, natural language interfaces},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1109/SC41406.2024.00098,
author = {Jin, Hongwei and Papadimitriou, George and Raghavan, Krishnan and Zuk, Pawel and Balaprakash, Prasanna and Wang, Cong and Mandal, Anirban and Deelman, Ewa},
title = {Large Language Models for Anomaly Detection in Computational Workflows: From Supervised Fine-Tuning to In-Context Learning},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00098},
doi = {10.1109/SC41406.2024.00098},
abstract = {Anomaly detection in computational workflows is critical for ensuring system reliability and security. However, traditional rule-based methods struggle to detect novel anomalies. This paper leverages large language models (LLMs) for workflow anomaly detection by exploiting their ability to learn complex data patterns. Two approaches are investigated: (1) supervised fine-tuning (SFT), where pretrained LLMs are fine-tuned on labeled data for sentence classification to identify anomalies, and (2) in-context learning (ICL), where prompts containing task descriptions and examples guide LLMs in few-shot anomaly detection without fine-tuning. The paper evaluates the performance, efficiency, and generalization of SFT models and explores zero-shot and few-shot ICL prompts and interpretability enhancement via chain-of-thought prompting. Experiments across multiple workflow datasets demonstrate the promising potential of LLMs for effective anomaly detection in complex executions.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {92},
numpages = {17},
keywords = {anomaly detection, computational workflows, in-context learning, large language models, supervised fine-tuning},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3638530.3654104,
author = {Liu, Yueyue and Zhang, Hongyu and Le, Van-Hoang and Miao, Yuantian and Li, Zhiqiang},
title = {Local Search-based Approach for Cost-effective Job Assignment on Large Language Models},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3654104},
doi = {10.1145/3638530.3654104},
abstract = {Large Language Models (LLMs) have garnered significant attention due to their impressive capabilities. However, leveraging LLMs can be expensive due to the computational resources required, with costs depending on invocation numbers and input prompt lengths. Generally, larger LLMs deliver better performance but at a higher cost. In addition, prompts that provide more guidance to LLMs can increase the probability of correctly processing the job but also tend to be longer, increasing the processing cost. Therefore, selecting an appropriate LLM and prompt template is crucial for achieving an optimal trade-off between cost and performance. This paper formulates the job assignment on LLMs as a multi-objective optimisation problem and proposes a local search-based algorithm, termed LSAP, which aims to minimise the invocations cost while maximising overall performance. First, historical data is used to estimate the accuracy of each job submitted to a candidate LLM with a chosen prompt template. Subsequently, LSAP combines heuristic rules to select an appropriate LLM and prompt template based on the invocation cost and estimated accuracy. Extensive experiments on LLM-based log parsing, a typical software maintenance task that utilizes LLMs, demonstrate that LSAP can efficiently generate solutions with significantly lower cost and higher accuracy compared to the baselines.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {719–722},
numpages = {4},
keywords = {large language models, job assignment, local search, log parsing},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3691620.3695299,
author = {Peng, Chao and Wu, Qinyun and Liu, Jiangchao and Liu, Jierui and Jiang, Bo and Xu, Mengqian and Wang, Yinghao and Liu, Xia and Yang, Ping},
title = {RepoSim: Evaluating Prompt Strategies for Code Completion via User Behavior Simulation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695299},
doi = {10.1145/3691620.3695299},
abstract = {Large language models (LLMs) have revolutionized code completion tasks. IDE plugins such as MarsCode can generate code recommendations, saving developers significant time and effort. However, current evaluation methods for code completion are limited by their reliance on static code benchmarks, which do not consider human interactions and evolving repositories. This paper proposes RepoSim, a novel benchmark designed to evaluate code completion tasks by simulating the evolving process of repositories and incorporating user behaviors. RepoSim leverages data from an IDE plugin, by recording and replaying user behaviors to provide a realistic programming context for evaluation. This allows for the assessment of more complex prompt strategies, such as utilizing recently visited files and incorporating user editing history. Additionally, RepoSim proposes a new metric based on users' acceptance or rejection of predictions, offering a user-centric evaluation criterion. Our preliminary evaluation demonstrates that incorporating users' recent edit history into prompts significantly improves the quality of LLM-generated code, highlighting the importance of temporal context in code completion. RepoSim represents a significant advancement in benchmarking tools, offering a realistic and user-focused framework for evaluating code completion performance.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2279–2283},
numpages = {5},
keywords = {code completion, prompt engineering, benchmark, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3708882,
author = {Zhang, Junjie and Xie, Ruobing and Hou, Yupeng and Zhao, Xin and Lin, Leyu and Wen, Ji-Rong},
title = {Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3708882},
doi = {10.1145/3708882},
abstract = {In the past decades, recommender systems have attracted much attention in both research and industry communities. Existing recommendation models mainly learn the underlying user preference from historical behavior data (typically in the forms of item IDs), and then estimate the user-item matching relationships for recommendations. Inspired by the recent progress on large language models (LLMs), we develop a different recommendation paradigm, considering recommendation as instruction following by LLMs. The key idea is that the needs of a user can be expressed in natural language descriptions (called instructions), so that LLMs can understand and further execute the instruction for fulfilling the recommendation. For this purpose, we instruction tune the 3B Flan-T5-XL, to better adapt LLMs to recommender systems. We first design a general instruction format for describing the preference, intention, and task form of a user in natural language. Then we manually design 39 instruction templates and automatically generate large amounts of user-personalized instruction data with varying types of preferences and intentions. To demonstrate the effectiveness of our approach, we instantiate the instructions into several widely studied recommendation (or search) tasks, and conduct extensive experiments with real-world datasets. Experiment results show that our approach can outperform several competitive baselines, including the powerful GPT-3.5, on these evaluation tasks. Our approach sheds light on developing user-friendly recommender systems, in which users can freely communicate with the system and obtain accurate recommendations via natural language instructions.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = dec,
keywords = {Large Language Models, Instruction Tuning, Recommender Systems}
}

@inproceedings{10.1145/3675094.3678476,
author = {Wang, Yongfu and Tang, Tiffany Y.},
title = {Position Paper: A Personalized Large Language Model (LLM)-Based Chat Companion for Autistic Children Early Intervention},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678476},
doi = {10.1145/3675094.3678476},
abstract = {Autism Spectrum Disorder (ASD) is a lifelong neurodevelopmental disorder characterized by restricted and repetitive sensory-motor behaviors and social communication deficits. Though in the recent decade, a rising interest has been demonstrated among the Human-Computer Interaction (HCI) and broader computing communities in involving multitudes of technologies to support autistic individuals especially children with autism over diverse aspects, the technologies are revealed to often reflect the normative expectations of a neurotypical society and be very one-sided. Thus, autistic children are commonly required to learn the 'appropriate' norm of social interaction defined by neurotypical society. In this work, instead of 'forcing' autistic children to accommodate technology, we propose a self-advocacy chat companion for autistic children based on the Large Language Model (LLM) as an early intervention tool. In the meantime, we hope it could also serve as a source platform that engages neurotypical users (such as parents) in understanding and learning how to interact and communicate with autistic children.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {697–700},
numpages = {4},
keywords = {autism, children, interaction design, large language model (llm), personalized training, ubiquitous computing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3640794.3665542,
author = {Ouaazki, Abdessalam and Bergram, Kristoffer and Farah, Juan Carlos and Gillet, Denis and Holzer, Adrian},
title = {Generative AI-Enabled Conversational Interaction to Support Self-Directed Learning Experiences in Transversal Computational Thinking},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665542},
doi = {10.1145/3640794.3665542},
abstract = {As computational thinking (CT) becomes increasingly acknowledged as an important skill in education, self-directed learning (SDL) emerges as a key strategy for developing this capability. The advent of generative AI (GenAI) conversational agents has disrupted the landscape of SDL. However, many questions still arise about several user experience aspects of these agents. This paper focuses on two of these questions: personalization and long-term support. As such, the first part of this study explores the effectiveness of personalizing GenAI through prompt-tuning using a CT-based prompt for solving programming challenges. The second part focuses on identifying the strengths and weaknesses of a GenAI model in a semester-long programming project. Our findings indicate that while prompt-tuning could hinder ease of use and perceived learning assistance, it might lead to higher learning outcomes. Results from a thematic analysis also indicate that GenAI is useful for programming and debugging, but it presents challenges such as over-reliance and diminishing utility over time.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {13},
numpages = {12},
keywords = {ChatGPT, Chatbots, Education, Generative AI, Programming, Student Perceptions},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3613905.3647966,
author = {Lim, Jullia},
title = {The Potential of Learning With AI-Generated Pedagogical Agents in Instructional Videos},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647966},
doi = {10.1145/3613905.3647966},
abstract = {With the recent advancement in technology, generative artificial intelligence (GenAI) can produce hyper-realistic multimedia content, such as audio, text, images, and videos. Although this technology has raised great concerns about its misuse and harmful applications, it holds great potential to revolutionize traditional ways of teaching and learning. The use of GenAI in education has increased markedly, however, pedagogical research on this rapidly emerging technology is yet to be studied extensively. There is an urgent need to investigate the unexamined potential of this technology. Therefore, this ongoing research will explore the potential of AI-generated pedagogical agents (PA), or avatars, in instructional videos to facilitate learning. The effects of the type of PA (AI-generated, real-life human), and voice (AI-generated, human voice) on an individual's learning outcomes, cognitive load, motivation, and attention will be studied. Findings from a pilot study provide some preliminary evidence that PA appearance influences learners’ retention and cognitive load, but not attention. The type of PA influenced learners' perception of the agent's ability to facilitate learning, its human-like qualities, and its engagement level. However, it did not affect its credibility. This ongoing work will contribute to the growing understanding of the impact of AI in education, provide evidence of the efficacy of AI-generated PAs in instructional videos for learning, and narrow the gap between human-computer interaction research and education.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {6},
keywords = {avatars, multimedia learning, pedagogical agents, videos},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3658644.3690298,
author = {Nazzal, Mahmoud and Khalil, Issa and Khreishah, Abdallah and Phan, NhatHai},
title = {PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690298},
doi = {10.1145/3658644.3690298},
abstract = {The capability of generating high-quality source code using large language models (LLMs) reduces software development time and costs. However, recent literature and our empirical investigation in this work show that while LLMs can generate functioning code, they inherently tend to introduce security vulnerabilities, limiting their potential. This problem is mainly due to their training on massive open-source corpora exhibiting insecure and inefficient programming practices. Therefore, automatic optimization of LLM prompts for generating secure and functioning code is a demanding need. This paper introduces PromSec, an algorithm for &lt;u&gt;prom&lt;/u&gt;pt optimization for &lt;u&gt;sec&lt;/u&gt;ure and functioning code generation using LLMs. In PromSec, we combine 1) code vulnerability clearing using a generative adversarial graph neural network, dubbed as gGAN, to fix and reduce security vulnerabilities in generated codes and 2) code generation using an LLM into an interactive loop, such that the outcome of the gGAN drives the LLM with enhanced prompts to generate secure codes while preserving their functionality. Introducing a new contrastive learning approach in gGAN, we formulate the code-clearing and generation loop as a dual-objective optimization problem, enabling PromSec to notably reduce the number of LLM inferences. As a result, PromSec becomes a cost-effective and practical solution for generating secure and functioning codes.Extensive experiments conducted on Python and Java code datasets confirm that PromSec effectively enhances code security while upholding its intended functionality. Our experiments show that despite the comprehensive application of a state-of-the-art approach, it falls short in addressing all vulnerabilities within the code, whereas PromSec effectively resolves each of them. Moreover, PromSec achieves more than an order-of-magnitude reduction in operational time, number of LLM queries, and security analysis costs. Furthermore, prompts optimized with PromSec for a certain LLM are transferable to other LLMs across programming languages and generalizable to unseen vulnerabilities in training. This study presents an essential step towards improving the trustworthiness of LLMs for secure and functioning code generation, significantly enhancing their large-scale integration in real-world software code development practices.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2266–2280},
numpages = {15},
keywords = {LLMs, code generation, graph generative adversarial networks, secure and functioning codes},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3637528.3671573,
author = {Kuang, Weirui and Qian, Bingchen and Li, Zitao and Chen, Daoyuan and Gao, Dawei and Pan, Xuchen and Xie, Yuexiang and Li, Yaliang and Ding, Bolin and Zhou, Jingren},
title = {FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671573},
doi = {10.1145/3637528.3671573},
abstract = {Large language models (LLMs) have demonstrated great capabilities in various natural language understanding and generation tasks. These pre-trained LLMs can be further improved for specific downstream tasks by fine-tuning. However, the adoption of LLM in real-world applications can be hindered by privacy concerns and the resource-intensive nature of model training and fine-tuning. When multiple entities have similar interested tasks but cannot directly share their local data due to privacy regulations, federated learning (FL) is a mainstream solution to leverage the data of different entities. Besides avoiding direct data sharing, FL can also achieve rigorous data privacy protection, model intelligent property protection, and model customization via composition with different techniques. Despite the aforementioned advantages of FL, fine-tuning LLMs in FL settings still lacks adequate support from the existing frameworks and, therefore, faces challenges in optimizing the consumption of significant communication and computational resources, preparing various data for different tasks, and satisfying diverse information protection demands. In this paper, we discuss these challenges and introduce our package FederatedScope-LLM (FS-LLM) as a main contribution, which consists: (1) We build a complete end-to-end benchmarking pipeline under real-world scenarios, automizing the processes of dataset preprocessing, federated fine-tuning execution or simulation, and performance evaluation; (2) We provide comprehensive and off-the-shelf federated parameter-efficient fine-tuning (PEFT) algorithm implementations and versatile programming interfaces for future extension, enhancing the capabilities of LLMs in FL scenarios with low communication and computation costs, even without accessing the full model; (3) We adopt several accelerating and resource-efficient operators, and provide flexible pluggable sub-routines for interdisciplinary study. We conduct extensive and reproducible experiments to show the effectiveness of FS-LLM and benchmark advanced LLMs with PEFT algorithms in FL. We release FS-LLM at https://github.com/alibaba/FederatedScope/tree/llm.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5260–5271},
numpages = {12},
keywords = {benchmark, federated learning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3597503.3623343,
author = {Deng, Yinlin and Xia, Chunqiu Steven and Yang, Chenyuan and Zhang, Shizhuo Dylan and Yang, Shujing and Zhang, Lingming},
title = {Large Language Models are Edge-Case Generators: Crafting Unusual Programs for Fuzzing Deep Learning Libraries},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623343},
doi = {10.1145/3597503.3623343},
abstract = {Bugs in Deep Learning (DL) libraries may affect almost all downstream DL applications, and it is crucial to ensure the quality of such systems. It is challenging to generate valid input programs for fuzzing DL libraries, since the input programs need to satisfy both the syntax/semantics of the supported languages (e.g., Python) and the tensor/operator constraints for constructing valid computational graphs. Recently, the TitanFuzz work demonstrates that modern Large Language Models (LLMs) can be directly leveraged to implicitly learn all the language and DL computation constraints to generate valid programs for fuzzing DL libraries (and beyond). However, LLMs tend to generate ordinary programs following similar patterns/tokens with typical programs seen in their massive pre-training corpora (e.g., GitHub), while fuzzing favors unusual inputs that cover edge cases or are unlikely to be manually produced.To fill this gap, this paper proposes FuzzGPT, the first approach to priming LLMs to synthesize unusual programs for fuzzing. FuzzGPT is mainly built on the well-known hypothesis that historical bug-triggering programs may include rare/valuable code ingredients important for bug finding. Meanwhile, while traditional techniques leveraging such historical information require intensive human efforts to both design dedicated generators and ensure the syntactic/semantic validity of generated programs, FuzzGPT demonstrates that this process can be fully automated via the intrinsic capabilities of LLMs (including fine-tuning and in-context learning), while being generalizable and applicable to challenging domains. While FuzzGPT can be applied with different LLMs, this paper focuses on the powerful GPT-style models: Codex and CodeGen. Moreover, FuzzGPT also shows the potential of directly leveraging the instruction-following capability of the recent ChatGPT for effective fuzzing. The experimental study on two popular DL libraries (PyTorch and TensorFlow) shows that FuzzGPT can substantially outperform TitanFuzz, detecting 76 bugs, with 49 already confirmed as previously unknown bugs, including 11 high-priority bugs or security vulnerabilities.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {70},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3589334.3645378,
author = {Yan, Yibo and Wen, Haomin and Zhong, Siru and Chen, Wei and Chen, Haodong and Wen, Qingsong and Zimmermann, Roger and Liang, Yuxuan},
title = {UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645378},
doi = {10.1145/3589334.3645378},
abstract = {Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4006–4017},
numpages = {12},
keywords = {language-image pretraining, spatio-temporal data, urban computing},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3627673.3680025,
author = {Huang, Jia-Hong and Yang, Chao-Chun and Shen, Yixian and Pacces, Alessio M. and Kanoulas, Evangelos},
title = {Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680025},
doi = {10.1145/3627673.3680025},
abstract = {The legal landscape encompasses a wide array of lawsuit types, presenting lawyers with challenges in delivering timely and accurate information to clients, particularly concerning critical aspects like potential imprisonment duration or financial repercussions. Compounded by the scarcity of legal experts, there's an urgent need to enhance the efficiency of traditional legal workflows. Recent advances in deep learning, especially Large Language Models (LLMs), offer promising solutions to this challenge. Leveraging LLMs' mathematical reasoning capabilities, we propose a novel approach integrating LLM-based methodologies with specially designed prompts to address precision requirements in legal Artificial Intelligence (LegalAI) applications. The proposed work seeks to bridge the gap between traditional legal practices and modern technological advancements, paving the way for a more accessible, efficient, and equitable legal system. To validate this method, we introduce a curated dataset tailored to precision-oriented LegalAI tasks, serving as a benchmark for evaluating LLM-based approaches. Extensive experimentation confirms the efficacy of our methodology in generating accurate numerical estimates within the legal domain, emphasizing the role of LLMs in streamlining legal processes and meeting the evolving demands of LegalAI. Github: https://github.com/Jhhuangkay/Optimizing-Numerical-Estimation-and-Operational-Efficiency-in-the-Legal-Domain.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4554–4562},
numpages = {9},
keywords = {large language models, precision-oriented legal artificial intelligence, tailored prompt design},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3589334.3645627,
author = {Huang, Xuanwen and Han, Kaiqiao and Yang, Yang and Bao, Dezheng and Tao, Quanjin and Chai, Ziwei and Zhu, Qi},
title = {Can GNN be Good Adapter for LLMs?},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645627},
doi = {10.1145/3589334.3645627},
abstract = {Recently, large language models (LLMs) have demonstrated superior capabilities in understanding and zero-shot learning on textual data, promising significant advances for many text-related domains. In the graph domain, various real-world scenarios also involve textual data, where tasks and node features can be described by text. These text-attributed graphs (TAGs) have broad applications in social media, recommendation systems, etc. Thus, this paper explores how to utilize LLMs to model TAGs. Previous methods for TAG modeling are based on million-scale LMs. When scaled up to billion-scale LLMs, they face huge challenges in computational costs. Additionally, they also ignore the zero-shot inference capabilities of LLMs. Therefore, we propose GraphAdapter, which uses a graph neural network (GNN) as an efficient adapter in collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN adapter introduces only a few trainable parameters and can be trained with low computation costs. The entire framework is trained using auto-regression on node text (next token prediction). Once trained, GraphAdapter can be seamlessly fine-tuned with task-specific prompts for various downstream tasks. Through extensive experiments across multiple real-world TAGs, GraphAdapter based on Llama 2 gains an average improvement of approximately 5% in terms of node classification. Furthermore, GraphAdapter can also adapt to other language models, including RoBERTa, GPT-2. The promising results demonstrate that GNNs can serve as effective adapters for LLMs in TAG modeling.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {893–904},
numpages = {12},
keywords = {graph neural networks, large language model, text-attributed graph},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3613905.3648656,
author = {Zhou, Zhongyi and Jin, Jing and Phadnis, Vrushank and Yuan, Xiuxiu and Jiang, Jun and Qian, Xun and Zhou, Jingtao and Huang, Yiyi and Xu, Zheng and Zhang, Yinda and Wright, Kristen and Mayes, Jason and Sherwood, Mark and Lee, Johnny and Olwal, Alex and Kim, David and Iyengar, Ram and Li, Na and Du, Ruofei},
title = {Experiencing InstructPipe: Building Multi-modal AI Pipelines via Prompting LLMs and Visual Programming},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3648656},
doi = {10.1145/3613905.3648656},
abstract = {Foundational multi-modal models have democratized AI access, yet the construction of complex, customizable machine learning pipelines by novice users remains a grand challenge. This paper demonstrates a visual programming system that allows novices to rapidly prototype multimodal AI pipelines. We first conducted a formative study with 58 contributors and collected 236 proposals of multimodal AI pipelines that served various practical needs. We then distilled our findings into a design matrix of primitive nodes for prototyping multimodal AI visual programming pipelines, and implemented a system with 65 nodes. To support users’ rapid prototyping experience, we built InstructPipe, an AI assistant based on large language models (LLMs) that allows users to generate a pipeline by writing text-based instructions. We believe InstructPipe enhances novice users onboarding experience of visual programming and the controllability of LLMs by offering non-experts a platform to easily update the generation.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {402},
numpages = {5},
keywords = {Deep Learning, Deep Neural Networks, Graph Compiler, Large Language Models, Low-code Development, Node-graph Editor, Visual Analytics, Visual Programming, Visual Prototyping},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3626252.3630799,
author = {Al-Hossami, Erfan and Bunescu, Razvan and Smith, Justin and Teehan, Ryan},
title = {Can Language Models Employ the Socratic Method? Experiments with Code Debugging},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630799},
doi = {10.1145/3626252.3630799},
abstract = {When employing the Socratic method of teaching, instructors guide students toward solving a problem on their own rather than providing the solution directly. While this strategy can substantially improve learning outcomes, it is usually time-consuming and cognitively demanding. Automated Socratic conversational agents can augment human instruction and provide the necessary scale, however their development is hampered by the lack of suitable data for training and evaluation. In this paper, we introduce a manually created dataset of multi-turn Socratic advice that is aimed at helping a novice programmer fix buggy solutions to simple computational problems. The dataset is then used for benchmarking the Socratic debugging abilities of a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and chain of thought prompting of the much larger GPT-4. The code and datasets are made freely available for research at the link below.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {53–59},
numpages = {7},
keywords = {benchmark dataset, debugging, language models, socratic dialogue},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3699538.3699556,
author = {Birillo, Anastasiia and Artser, Elizaveta and Potriasaeva, Anna and Vlasov, Ilya and Dzialets, Katsiaryna and Golubev, Yaroslav and Gerasimov, Igor and Keuning, Hieke and Bryksin, Timofey},
title = {One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699556},
doi = {10.1145/3699538.3699556},
abstract = {Students often struggle with solving programming problems when learning to code, especially when they have to do it online, with one of the most common disadvantages of working online being the lack of personalized help. This help can be provided as next-step hint generation, i.e., showing a student what specific small step they need to do next to get to the correct solution. There are many ways to generate such hints, with large language models (LLMs) being among the most actively studied right now. While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality. In this work, we utilize this idea and propose a novel system to provide both textual and code hints for programming tasks. The pipeline of the proposed approach uses a chain-of-thought prompting technique and consists of three distinct steps: (1) generating subgoals — a list of actions to proceed with the task from the current student’s solution, (2) generating the code to achieve the next subgoal, and (3) generating the text to describe this needed action. During the second step, we apply static analysis to the generated code to control its size and quality. The tool is implemented as a modification to the open-source JetBrains Academy plugin, supporting students in their in-IDE courses. To evaluate our approach, we propose a list of criteria for all steps in our pipeline and conduct two rounds of expert validation. Finally, we evaluate the next-step hints in a classroom with 14 students from two universities. Our results show that both forms of the hints — textual and code — were helpful for the students, and the proposed system helped them to proceed with the coding tasks.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {9},
numpages = {12},
keywords = {Programming Education, in-IDE learning, LLMs, Generative AI, Next-Step Hints},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3638529.3654178,
author = {Morris, Clint and Jurado, Michael and Zutty, Jason},
title = {LLM Guided Evolution - The Automation of Models Advancing Models},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3654178},
doi = {10.1145/3638529.3654178},
abstract = {In the realm of machine learning, traditional model development and automated approaches like AutoML typically rely on layers of abstraction, such as tree-based or Cartesian genetic programming. Our study introduces "Guided Evolution" (GE), a novel framework that diverges from these methods by utilizing Large Language Models (LLMs) to directly modify code. GE leverages LLMs for a more intelligent, supervised evolutionary process, guiding mutations and crossovers. Our unique "Evolution of Thought" (EoT) technique further enhances GE by enabling LLMs to reflect on and learn from the outcomes of previous mutations. This results in a self-sustaining feedback loop that augments decision-making in model evolution. GE maintains genetic diversity, crucial for evolutionary algorithms, by leveraging LLMs' capability to generate diverse responses from expertly crafted prompts and modulate model temperature. This not only accelerates the evolution process but also injects expert like creativity and insight into the process. Our application of GE in evolving the ExquisiteNetV2 model demonstrates its efficacy: the LLM-driven GE autonomously produced variants with improved accuracy, increasing from 92.52% to 93.34%, without compromising model compactness. This underscores the potential of LLMs to accelerate the traditional model design pipeline, enabling models to autonomously evolve and enhance their own designs.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {377–384},
numpages = {8},
keywords = {large language models, automated machine learning, evolutionary algorithms},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{10.1145/3701268.3701273,
author = {Conway, Brian and Nolan, Keith and Quille, Keith},
title = {HCAI Block Model: A competence model for Human Centred Artificial Intelligence at K-12},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701273},
doi = {10.1145/3701268.3701273},
abstract = {Artificial Intelligence (AI) is becoming a common topic within the computing K-12 curricula worldwide. While much of the focus of research is on the use of Generative AI in and for education, AI as a core subject area is still gaining popularity, with much of this research focusing on content and tools that effectively support the teaching of AI. However, as we grow as a field, there is a need currently unmet to provide foundations (in the form of a block model as there exists for programming) to allow researchers to build strong pedagogies and methodologies from, and even a base to design activities and content. Compounding this, as ethics and its relationship to AI in the K-12 classroom grows stronger, there is a further need to provide scaffolding to educators and researchers not only on traditional AI concepts, but also on how they link with ethical knowledge, skills and dispositions. In this paper, the Human Centered Artificial Intelligence (HCAI) Block Model is developed and introduced. This is a competence-based model to guide effective teaching and learning of Human Centered Artificial Intelligence, as well as research in the K-12 space. The HCAI Block model’s foundation is developed/adapted from the programming Block model and has been adapted and developed using two lenses. The first was through the data science lens through interaction with Computational Thinking 2.0 and competency-based learning. The second lens was through a human-centred lens. The outcome was a ground-up K-12 model where traditional and technical AI concepts have been developed from the start, integrating ethical considerations and human-centred approaches.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {22–28},
numpages = {7},
keywords = {Computing Education, Machine Learning, Human-Centered AI, Block Model, Ethics, Computational Thinking 2.0},
location = {
},
series = {HCAIep '24}
}

@article{10.1145/3676507,
author = {Constantinides, Marios and Bogucka, Edyta Paulina and Scepanovic, Sanja and Quercia, Daniele},
title = {Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676507},
doi = {10.1145/3676507},
abstract = {Integrating Artificial Intelligence (AI) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert analysis. We developed a semi-automatic method that leverages Large Language Models (LLMs) to identify AI uses in mobile and wearables, classify their risks based on the EU AI Act, and determine their benefits that align with globally recognized long-term sustainable development goals; a manual validation of our method by two experts in mobile and wearable technologies, a legal and compliance expert, and a cohort of nine individuals with legal backgrounds who were recruited from Prolific, confirmed its accuracy to be over 85%. We uncovered that specific applications of mobile computing hold significant potential in improving well-being, safety, and social equality. However, these promising uses are linked to risks involving sensitive data, vulnerable groups, and automated decision-making. To avoid rejecting these risky yet impactful mobile and wearable uses, we propose a risk assessment checklist for the Mobile HCI community.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {262},
numpages = {28},
keywords = {LLM, mobile, prompt engineering, risk assessment, sustainable development goals, wearables}
}

@inproceedings{10.1145/3652620.3687776,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {Enhancing Software Modeling Learning with AI-Powered Scaffolding},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687776},
doi = {10.1145/3652620.3687776},
abstract = {This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {103–106},
numpages = {4},
keywords = {generative AI, education, software modelling, model-driven software engineering, UML, scaffolding},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3629526.3649130,
author = {Hillston, Jane},
title = {What does Performance Mean for Large Language Models?},
year = {2024},
isbn = {9798400704444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629526.3649130},
doi = {10.1145/3629526.3649130},
abstract = {In the last decade there has been a significant leap in the capability of foundation AI models, largely driven by the introduction and refinement of transformer-based machine learning architectures. The most visible consequence of this has been the explosion of interest and application of large language models such as ChatGPT. This is one exemplar of how a foundation model trained on a huge amount of data can be specialised for particular task, often by a phase of reinforcement learning with human feedback.Within the AI community "performance" of such systems is generally taken to mean how well they respond to their users on characteristics such as accuracy, verifiability, and bias. Performance analysis usually considers both the responsiveness of a system to its user and the efficiency and equity of resource use. These foundation models rely on massive amounts of resource but there appears to have been little work considering how to understand the resource use or the trade-offs that exist between how the system responds to users and the amount of resource used.In this talk I will present initial ideas of what it could mean to develop a framework of performance evaluation for foundation models such as large language models. Such a framework would need to take into consideration the distinct phases of operation for these models, which broadly speaking can be categorised as training, generating and fine-tuning. Evaluating the trade-off between user interests and resource management will require the identification of suitable metrics. Resources in such systems are more than simply compute and storage use, and bandwidth; data and even human resources also play crucial roles in training and fine-tuning. I will discuss all these topics.},
booktitle = {Proceedings of the 15th ACM/SPEC International Conference on Performance Engineering},
pages = {118},
numpages = {1},
keywords = {efficient use of resources, large language models, performance evaluation, user responsiveness},
location = {London, United Kingdom},
series = {ICPE '24}
}

@inproceedings{10.1145/3663741.3664785,
author = {Barbon Junior, Sylvio and Ceravolo, Paolo and Groppe, Sven and Jarrar, Mustafa and Maghool, Samira and S\`{e}des, Florence and Sahri, Soror and Van Keulen, Maurice},
title = {Are Large Language Models the New Interface for Data Pipelines?},
year = {2024},
isbn = {9798400706790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663741.3664785},
doi = {10.1145/3663741.3664785},
abstract = {A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge.},
booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
articleno = {6},
numpages = {6},
keywords = {Automated Machine Learning, Big Data Analytic, Human-Computer Interaction, Knowledge Graphs, Natural Language Understanding, eXplainable Artificial Intelligence},
location = {Santiago, AA, Chile},
series = {BiDEDE '24}
}

@inproceedings{10.1145/3626252.3630880,
author = {Sheard, Judy and Denny, Paul and Hellas, Arto and Leinonen, Juho and Malmi, Lauri and Simon},
title = {Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630880},
doi = {10.1145/3626252.3630880},
abstract = {Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1223–1229},
numpages = {7},
keywords = {ai code generation, generative ai, instructor perceptions, interview study, large language models, llms, programming education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3637528.3672010,
author = {Chen, Nuo and Li, Yuhan and Tang, Jianheng and Li, Jia},
title = {GraphWiz: An Instruction-Following Language Model for Graph Computational Problems},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672010},
doi = {10.1145/3637528.3672010},
abstract = {Large language models (LLMs) have achieved impressive success across various domains, but their capability in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel instruction-tuning dataset aimed at enabling language models to tackle a broad spectrum of graph problems through explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of solving various graph computational problems while generating clear reasoning processes. To further enhance the model's performance and reliability, we integrate the Direct Preference Optimization (DPO) framework within the graph problem-solving context. The improved model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Our study also investigates the relationship between training data volume and model performance, emphasizing the risk of overfitting as data volume increases. Additionally, we explore the transferability of the proposed model across different tasks and datasets, demonstrating its robust zero-shot generalization capability. GraphWiz offers a new blueprint and valuable insights for developing LLMs specialized in graph reasoning and problem-solving.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {353–364},
numpages = {12},
keywords = {graph algorithms, instruction tuning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671485,
author = {Yan, Da and Hamed, Ahmed Abdeen and Chen, Jake Y. and Zaki, Mohammed J.},
title = {23rd International Workshop on Data Mining in Bioinformatics (BIOKDD 2024)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671485},
doi = {10.1145/3637528.3671485},
abstract = {The goal of the 22nd International Workshop on Data Mining in Bioinformatics (BIOKDD 2023) is to encourage KDD researchers to solve the numerous problems and challenges in Bioinformatics using Data Mining technologies. Based on the organizers' expertise and communities, BIOKDD 2023 features the theme "Large-Scale Data-Driven Methods for Bioinformatics". This theme encourages the use of high-performance computing (HPC) to support the training of large machine learning models for problems in Bioinformatics and Computational Biology. The key goal is to accelerate the convergence between Data Mining and Bioinformatics communities to expedite discoveries in basic biology, medicine and healthcare.The goal of the 23rd International Workshop on Data Mining in Bioinformatics (BIOKDD 2024) is to encourage KDD researchers to solve the numerous problems and challenges in Bioinformatics using Data Mining technologies. Based on the organizers' expertise and communities, BIOKDD 2024 features the theme "Advancing Bioinformatics with LLMs and GenAI". This theme encourages the use of large language models and generative artificial intelligence to solve problems in Bioinformatics and Computational Biology. The key goal is to accelerate the convergence between Data Mining and Bioinformatics communities to expedite discoveries in basic biology, medicine and healthcare.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6747–6748},
numpages = {2},
keywords = {AI, bioinformatics, health informatics},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3678585,
author = {Gao, Yi and Xiao, Kaijie and Li, Fu and Xu, Weifeng and Huang, Jiaming and Dong, Wei},
title = {ChatIoT: Zero-code Generation of Trigger-action Based IoT Programs},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678585},
doi = {10.1145/3678585},
abstract = {Trigger-Action Program (TAP) is a simple but powerful format to realize intelligent IoT applications, especially in home automation scenarios. Existing trace-driven approaches and in-situ programming approaches depend on either customized interaction commands or well-labeled datasets, resulting in limited applicable scenarios. In this paper, we propose ChatIoT, a zero-code TAP generation system based on large language models (LLMs). With a novel context-aware compressive prompting scheme, ChatIoT is able to automatically generate TAPs from user requests in a token-efficient manner and deploy them to the TAP runtime. Further, for those TAP requests including unknown sensing abilities, ChatIoT can also generate new AI models with knowledge distillation by multimodal LLMs, with a novel model customization method based on deep reinforcement learning. We implemented ChatIoT and evaluated its performance extensively. Results show that ChatIoT can reduce token consumption by 26.1-84.9% and improve TAP generation accuracy by 4.2-65.5% compared to state-of-the-art approaches in multiple settings. We also conducted a real user study, and ChatIoT can achieve 91.57% TAP generation accuracy.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {103},
numpages = {29},
keywords = {Home automation, Internet of Things, LLMs, Zero-code TAP generation}
}

@inproceedings{10.1145/3691620.3695000,
author = {Sun, Zhihong and Wan, Yao and Li, Jia and Zhang, Hongyu and Jin, Zhi and Li, Ge and Lyu, Chen},
title = {Sifting through the Chaff: On Utilizing Execution Feedback for Ranking the Generated Code Candidates},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695000},
doi = {10.1145/3691620.3695000},
abstract = {Large Language Models (LLMs), such as GPT-4, StarCoder, and Code Llama, are transforming the way developers approach programming by automatically generating code based on given contexts, such as natural language descriptions or incomplete surrounding code. Despite advancements, generating syntactically and semantically correct code remains challenging, especially for complex programming tasks. Existing approaches typically generate multiple candidate solutions using LLMs to increase the likelihood of producing correct code. However, selecting the correct code from these candidates --- a process known as code ranking --- remains a major challenge. Current research on code ranking can be categorized into execution-based and non-execution-based methods. Execution-based methods, although effective, encounter notable limitations, such as scarcity of quality unit tests and security risks. Non-execution-based methods like CodeRanker, which rely solely on classification labels to train a code ranker, struggle to capture subtle errors and provide detailed error insights. Recognizing the strengths and limitations of both approaches, we propose a new method that integrates the advantages of execution-based and non-execution-based techniques. The key insight of our work is that an effective code ranker is expected to truly comprehend the underlying causes of erroneous code, as relying solely on classification labels is insufficient. Inspired by this, this paper puts forward RankEF, an innovative approach for code ranking that leverages execution feedback. RankEF employs multi-task learning to integrate code classification with execution feedback generation. This approach enables the model to understand the reasons behind incorrect code, distinguishing between correct and incorrect solutions without the need to execute the code during the ranking phase. Experiments on three code generation benchmarks---APPS, MBPP, and HumanEval---demonstrate that RankEF significantly outperforms the state-of-the-art CodeRanker, achieving relative improvements of +30.97%, +31.43%, and +19.51% in Pass@1, Pass@2, and Pass@5 on APPS test, respectively.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {229–241},
numpages = {13},
keywords = {code generation, code ranking, execution feedback},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1109/SC41406.2024.00076,
author = {Giordani, Jeremiah and Xu, Ziyang and Colby, Ella and Ning, August and Godala, Bhargav Reddy and Chaturvedi, Ishita and Zhu, Shaowei and Chon, Yebin and Chan, Greg and Tan, Zujun and Collier, Galen and Halverson, Jonathan D. and Deiana, Enrico Armenio and Liang, Jasper and Sossai, Federico and Su, Yian and Patel, Atmn and Pham, Bangyen and Greiner, Nathan and Campanoni, Simone and August, David I.},
title = {Revisiting Computation for Research: Practices and Trends},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00076},
doi = {10.1109/SC41406.2024.00076},
abstract = {In the field of computational science, effectively supporting researchers necessitates a deep understanding of how they utilize computational resources. Building upon a decade-old survey that explored the practices and challenges of research computation, this study aims to bridge the understanding gap between providers of computational resources and researchers who rely on them. This study revisits key survey questions and gathers feedback on open-ended topics from over a hundred interviews. Quantitative analyses of present and past results illuminate the landscape of research computation. Qualitative analyses, including careful use of large language models, highlight trends and challenges with concrete evidence. Given the rapid evolution of computational science, this paper offers a toolkit with methodologies and insights to simplify future research and ensure ongoing examination of the landscape. This study, with its findings and toolkit, guides enhancements to computational systems, deepens understanding of user needs, and streamlines reassessment of the computational landscape.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {70},
numpages = {14},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3626252.3630854,
author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
title = {Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630854},
doi = {10.1145/3626252.3630854},
abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {951–957},
numpages = {7},
keywords = {capstone courses, chatgpt, generative ai, large language models, software engineering education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@proceedings{10.1145/3637528,
title = {KDD '24: Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our pleasure to welcome you to the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining---KDD'2024 in Barcelona, Catalonia. This year's conference continues its tradition of being the premier forum for presentation of research results and experience reports on knowledge discovery, data science, and machine learning. The mission of the conference is to provide the best venue for advancement, education, and adoption of the "science" of knowledge discovery and machine learning from all types of data; to share novel methodologies that fulfill the needs of heterogeneous applications and environments and identify new directions for future research and development. These ideas have the potential to shape and impact our society and environment, becoming particularly important with the emergence of AI in all fields. So, KDD provides researchers and practitioners a unique opportunity to share their perspectives with others interested in various aspects of data science and machine learning.KDD'24 has a program of three keynotes (Sanjeev Arora, Tanya Berger-Wolf and Xihong Lin), one panel on generative AI, 411 research track papers, 151 applied data science (ADS) track papers and eight invited talks, 30 workshops, 34 tutorials (nine of them hands-on), nine special days (one online for India), and three KDD cups. We have introduced two new special days, one in Responsible AI and another in European Data Science given the location of the conference. We also added one extra poster session to have more time for posters presentations. For second time we used Openreview for the research and ADS tracks with the goal to further improve the review quality and facilitate the interaction between reviewers and authors. We hope that you will find this program interesting and thought-provoking and that the conference will provide you with a valuable opportunity to share ideas with other researchers and practitioners from institutions around the world.},
location = {Barcelona, Spain}
}

@inproceedings{10.1145/3653804.3654608,
author = {Qiu, Hongjie and Li, Jinqiang and Gan, Junhao and Zheng, Shuwen and Yan, Liqi},
title = {DroneGPT: Zero-shot Video Question Answering For Drones},
year = {2024},
isbn = {9798400718199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653804.3654608},
doi = {10.1145/3653804.3654608},
abstract = {With the continuous development and popularization of drone technology, drones are widely used in various fields, especially in drone video applications. We propose DroneGPT, a neural-symbolic method that learns VISPROG, which does not require any task-specific training. It leverages the contextual learning ability of large language models to generate and execute modular programs, solving complex and compositional drone vision tasks given natural language instructions. The modules in the program can call several ready-made computer vision models to achieve object detection, or write image processing programs by themselves, and finally connect them to achieve drone video question answering. We believe that DroneGPT can expand the task scope of drones in the video field and further enrich the functions of contemporary drones.},
booktitle = {Proceedings of the International Conference on Computer Vision and Deep Learning},
articleno = {49},
numpages = {6},
keywords = {Grounding DINO, computer vision, drone, question answering, video analysis, visual programing},
location = {Changsha, China},
series = {CVDL '24}
}

@inproceedings{10.1145/3632971.3632976,
author = {Zhou, Jun Yu and Fei, Chun Qing and Zou, Bing Guo},
title = {A Case Study on the Generalization of Chinese Text Classification Methods based on Deep Learning},
year = {2024},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632971.3632976},
doi = {10.1145/3632971.3632976},
abstract = {Abstract. In the past decade, deep learning based methods have taken a dominant position in natural language processing (NLP). For almost all NLP tasks, deep learning based methods far surpassed traditional methods. Especially in the past five years, the development of deep learning methods has been particularly rapid. For example, the pre-training and fine-tuning paradigms represented by BERT have dominated the NLP field, while also driving the development of other fields such as computer vision. Nowadays pre-trained large language models (LLMs) such as GPT-3/ChatGPT further demonstrate the advantages of Transformer based deep learning methods, which can achieve good results across various problems without any specialized training. In spite of the remarkable success, their performances still underperform fine-tuned models in the task of text classification in some scenarios. Nevertheless, the LLMs are good generalist models. The goal we pursue is the deep learning methods with good generalization ability. In the case of limited computing resources and high performance requirements, the fine-tuned models remain the first choice. So how is the generalization ability of the fine-tuned models? In this paper, we explore the generalization of representative Chinese text classification methods based on deep learning. The experimental results indicate that Transformer based methods present good ability of generalization on two significant different Chinese datasets. In the current era of LLMs, this work can assist us in choosing more appropriate solutions for natural language processing tasks.},
booktitle = {Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
pages = {128–132},
numpages = {5},
keywords = {Deep learning, Generalization, Text classification, Text representation, Transformer},
location = {Shanghai, China},
series = {JCRAI '23}
}

@inproceedings{10.1145/3637528.3671465,
author = {Park, Youngsuk and Budhathoki, Kailash and Chen, Liangfu and K\"{u}bler, Jonas M. and Huang, Jiaji and Kleindessner, Matth\"{a}us and Huan, Jun and Cevher, Volkan and Wang, Yida and Karypis, George},
title = {Inference Optimization of Foundation Models on AI Accelerators},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671465},
doi = {10.1145/3637528.3671465},
abstract = {Powerful foundation models, including large language models (LLMs), with Transformer architectures have ushered in a new era of Generative AI across various industries. Industry and research community have witnessed a large number of new applications, based on those foundation models. Such applications include question and answer, customer services, image and video generation, and code completions, among others. However, as the number of model parameters reaches to hundreds of billions, their deployment incurs prohibitive inference costs and high latency in real-world scenarios. As a result, the demand for cost-effective and fast inference using AI accelerators is ever more higher. To this end, our tutorial offers a comprehensive discussion on complementary inference optimization techniques using AI accelerators. Beginning with an overview of basic Transformer architectures and deep learning system frameworks, we deep dive into system optimization techniques for fast and memory-efficient attention computations and discuss how they can be implemented efficiently on AI accelerators. Next, we describe architectural elements that are key for fast transformer inference. Finally, we examine various model compression and fast decoding strategies in the same context.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6605–6615},
numpages = {11},
keywords = {foundation models, inference optimization, llms, transformer},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3662739.3664740,
author = {Zhan, Liuchun and Huang, Changjiang},
title = {Research on Computer Intelligent ChatGPT Natural Language Processing System Based on Scientific Knowledge Graph},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3664740},
doi = {10.1145/3662739.3664740},
abstract = {A synonym mining method is proposed by combining the character vector graph and noise robust learning method. The model uses paired word vectors pre-trained by ChatGPT to enhance entity semantic representation. Classify marks with noise. Then the cross optimal processing is carried out to identify the true and false marks. The two-layer construction system of knowledge extraction and knowledge fusion is constructed to realize the independent construction and answer of software engineering questions. The system effectively improves the efficiency of software project understanding and software reuse.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {47–51},
numpages = {5},
keywords = {ChatGPT, Software knowledge extraction, Natural language processing system, Software knowledge graph},
location = {Ningbo, China},
series = {MIDA '24}
}

@inproceedings{10.1145/3658271.3658320,
author = {Saldanha, Mateus Santos and Digiampietri, Luciano Antonio},
title = {ChatGPT and Bard Performance on the POSCOMP Exam},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658320},
doi = {10.1145/3658271.3658320},
abstract = {Context: Modern chatbots, built upon advanced language models, have achieved remarkable proficiency in answering questions across diverse fields. Problem: Understanding the capabilities and limitations of these chatbots is a significant challenge, particularly as they are integrated into different information systems, including those in education. Solution: In this study, we conducted a quantitative assessment of the ability of two prominent chatbots, ChatGPT and Bard, to solve POSCOMP questions. IS Theory: The IS theory used in this work is Information processing theory. Method: We used a total of 271 questions from the last five POSCOMP exams that did not rely on graphic content as our materials. We presented these questions to the two chatbots in two formats: directly as they appeared in the exam and with additional context. In the latter case, the chatbots were informed that they were answering a multiple-choice question from a computing exam. Summary of Results: On average, chatbots outperformed human exam-takers by more than 20%. Interestingly, both chatbots performed better, in average, without additional context added to the prompt. They exhibited similar performance levels, with a slight advantage observed for ChatGPT. Contributions and Impact in the IS area: The primary contribution to the field involves the exploration of the capabilities and limitations of chatbots in addressing computing-related questions. This information is valuable for individuals developing Information Systems with the assistance of such chatbots or those relying on technologies built upon these capabilities.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {49},
numpages = {10},
keywords = {Bard, ChatBot, ChatGPT, Computer Science Examination, Large Language Model},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@article{10.1145/3664219,
author = {Huang, Jiayang and Huang, Yue and Yip, David and Guljajeva, Varvara},
title = {Ephemera: Language as a Virus - AI-driven Interactive and Immersive Art Installation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3664219},
doi = {10.1145/3664219},
abstract = {In this paper, we introduce the speech-based interactive and immersive installation, Ephemera, as an artistic response to the linguistic taboos encountered in daily communication, prompting audience reflection and thoughts. Within this project, we symbolize the dissemination chain of language through a computational ecosystem. Utilizing the surreal 'virus' as an embodiment of banned words, we employ generative models for visual representation, leverage large language models for communicative agents, and use machine learning for behavioral engines, ultimately simulating a digitally autonomous micro-organism world of forbidden language. We contextualized the speech-to-content generation process to draw the audience's attention to the power and constraints of language. Additionally, we examine AI's comprehension of censored words and ethical considerations. Finally, our artistic project proposes the aphorism "Language as a virus, art as an antibody," offering novel perspectives on language taboos and art-technology intersections.},
journal = {Proc. ACM Comput. Graph. Interact. Tech.},
month = jul,
articleno = {62},
numpages = {8},
keywords = {human-AI interaction, immersive experience, interactive art, language visualization}
}

@inproceedings{10.1145/3664647.3681552,
author = {Gao, Minghe and Chen, Shuang and Pang, Liang and Yao, Yuan and Dang, Jisheng and Zhang, Wenqiao and Li, Juncheng and Tang, Siliang and Zhuang, Yueting and Chua, Tat-Seng},
title = {Fact :Teaching MLLMs with &lt;u&gt;Fa&lt;/u&gt;ithful, &lt;u&gt;C&lt;/u&gt;oncise and &lt;u&gt;T&lt;/u&gt;ransferable Rationales},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681552},
doi = {10.1145/3664647.3681552},
abstract = {The remarkable performance of Multimodal Large Language Models (MLLMs) has demonstrated their proficient understanding capabilities in handling various visual tasks. Nevertheless, the opaque nature of black-box reasoning processes persists as an enigma, rendering them uninterpretable and struggling with hallucination. Their ability to execute intricate reasoning tasks is also constrained, culminating in stagnation of progression. In this work, we introduce Fact, a novel paradigm designed to generate multimodal rationales that are faithful, concise, and transferable for teaching MLLMs. This paradigm utilizes verifiable visual programming to generate executable code guaranteeing faithfulness. Through a series of operations including pruning, merging, and bridging, the rationale enhances its conciseness. Furthermore, we filter rationales that can be transferred to end-to-end paradigms from programming paradigms to guarantee transferability. Empirical evidence from experiments demonstrates the superiority of Fact across models of varying parameter sizes, significantly enhancing their compositional reasoning and generalization ability and reducing hallucinations owing to its high correlation between images and text.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {846–855},
numpages = {10},
keywords = {distillation step-by-step, multimodel chain-of-thought, visual programming},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3685767.3685777,
author = {Abdalla, Hemn Barzan and Awlla, Ardalan Hussein and Kumar, Yulia and Cheraghy, Maryam},
title = {Big Data: Past, Present, and Future Insights},
year = {2024},
isbn = {9798400709609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3685767.3685777},
doi = {10.1145/3685767.3685777},
abstract = {This paper presents a comprehensive analysis of the historical progression, current trends, and prospects of Big Data. It explores the technological advancements that have established Big Data as a critical element of contemporary analytics, its extensive impact across various sectors, and the ethical challenges it poses. Beginning with the early recognition of Big Data's potential in the 2000s, the paper traces the development of foundational technologies such as Hadoop and the subsequent diversification of tools and methods. It delves into the integration of advanced analytics and machine learning, the rise of cloud-based Big Data services, and the transformative effects on sectors including healthcare, finance, agriculture, and education. The study also examines ethical considerations such as privacy, bias, transparency, and regulatory compliance, emphasizing the need for robust governance frameworks. It investigates the potential of emerging technologies like AI, IoT, and quantum computing to enhance Big Data capabilities further. It highlights future directions, including decentralized data ecosystems, advanced analytical techniques, and enhanced data privacy measures. By providing a panoramic view of Big Data's development, this paper aims to showcase its potential to revolutionize decision-making processes, improve operational efficiency, and drive innovation across industries; it underscores the importance of balancing technological innovation with ethical responsibility to ensure positive societal advancement and global progress. To add a novelty to the discussion, an AI agent Big D was created to provide a relevant analysis of trends in Big Data. The agent uses a multimodal ChatGPT-4o Large Language Model (LLM) from OpenAI and provides its review based on uploaded files and LLM knowledge.},
booktitle = {Proceedings of the 2024 Asia Pacific Conference on Computing Technologies, Communications and Networking},
pages = {60–70},
numpages = {11},
location = {Chengdu, China},
series = {CTCNet '24}
}

@inproceedings{10.1145/3704440.3704777,
author = {Chen, Jiaxuan},
title = {Comparative Analysis and Optimization of LoRA Adapter Co-serving for Large Language Models},
year = {2024},
isbn = {9798400713545},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704440.3704777},
doi = {10.1145/3704440.3704777},
abstract = {Large language models (LLMs) are widely deployed across a range of applications, but their efficient use for serving diverse tasks remains a challenge due to the significant resource demands of running numerous specialized models. Parameter-efficient fine-tuning (PEFT) addresses this by allowing models to be adapted using only a small set of additional parameters, leaving the backbone model unchanged.The objective of this research is to develop a scheduling framework for parameter-efficient adapters that allows for the co-serving of both inference and fine-tuning tasks across multiple adapters, while sharing a single backbone model. By harnessing the benefits of parameter-efficient tuning, this approach minimizes the overhead associated with storing, loading, and running multiple task-specific models, thereby improving overall performance.To achieve this, we propose to conduct a comparative analysis of prior works evaluating their performance and resource management strategies in adapter-based serving. Through experiments, we assess the strengths and limitations of each approach, identifying opportunities for more efficient adapter and task management in future systems. This paper presents the problem, discusses the background of this early-stage project, and outlines a research plan for developing an efficient co-serving framework for LLM systems.},
booktitle = {Proceedings of the 25th International Middleware Conference: Demos, Posters and Doctoral Symposium},
pages = {27–28},
numpages = {2},
keywords = {Adapter-based inference, Co-serving adapters, Large language models (LLMs), Scheduling Data transfer},
location = {Hong Kong, Hong Kong},
series = {Middleware '24}
}

@inproceedings{10.1145/3674029.3674041,
author = {Weng, Yan and Lynch, Jayson and Krueger, Elizabeth},
title = {Figuring Figures: An assessment of large language models on different modalities of math word problems},
year = {2024},
isbn = {9798400716379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674029.3674041},
doi = {10.1145/3674029.3674041},
abstract = {This paper presents a new dataset of geometry word problems in three forms: with figures, with code that produces these figures, and purely textual. Having versions of the same question which use different modalities allows for a more direct comparison of the performance of machine learning models on mathematical question answering across different modalities of input. We evaluate several multi-modal large language models and find they consistently perform best on the plain text descriptions and worst on the version with images.},
booktitle = {Proceedings of the 2024 9th International Conference on Machine Learning Technologies},
pages = {74–78},
numpages = {5},
keywords = {Machine Learning, Math QA, Multi-Modal Neural Nets, NLP},
location = {Oslo, Norway},
series = {ICMLT '24}
}

@inproceedings{10.1145/3636555.3636912,
author = {Snyder, Caitlin and Hutchins, Nicole M and Cohn, Clayton and Fonteles, Joyce Horn and Biswas, Gautam},
title = {Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636912},
doi = {10.1145/3636555.3636912},
abstract = {This study introduces a methodology to investigate students’ collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework—specifically, Planning, Enacting, and Reflection—proposed in the literature, applying it to examine students’ collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students’ model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {540–550},
numpages = {11},
keywords = {SRL, STEM, collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1613/jair.1.15278,
author = {Franceschelli, Giorgio and Musolesi, Mirco},
title = {Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges},
year = {2024},
issue_date = {Apr 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {79},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.15278},
doi = {10.1613/jair.1.15278},
abstract = {Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {30}
}

@inproceedings{10.1145/3651890.3672268,
author = {Wu, Duo and Wang, Xianda and Qiao, Yaqi and Wang, Zhi and Jiang, Junchen and Cui, Shuguang and Wang, Fangxin},
title = {NetLLM: Adapting Large Language Models for Networking},
year = {2024},
isbn = {9798400706141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651890.3672268},
doi = {10.1145/3651890.3672268},
abstract = {Many networking tasks now employ deep learning (DL) to solve complex prediction and optimization problems. However, current design philosophy of DL-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (DNNs) for different networking tasks. Besides, DNNs tend to achieve poor generalization performance on unseen data distributions/environments.Motivated by the recent success of large language models (LLMs), this work studies the LLM adaptation for networking to explore a more sustainable design philosophy. With the powerful pre-trained knowledge, the LLM is promising to serve as the foundation model to achieve "one model for all tasks" with even better performance and stronger generalization. In pursuit of this vision, we present NetLLM, the first framework that provides a coherent design to harness the powerful capabilities of LLMs with low efforts to solve networking problems. Specifically, NetLLM empowers the LLM to effectively process multimodal data in networking and efficiently generate task-specific answers. Besides, NetLLM drastically reduces the costs of fine-tuning the LLM to acquire domain knowledge for networking. Across three networking-related use cases - viewport prediction, adaptive bitrate streaming and cluster job scheduling, we showcase that the NetLLM-adapted LLM significantly outperforms state-of-the-art algorithms.},
booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
pages = {661–678},
numpages = {18},
keywords = {deep learning, network optimization, video streaming, job scheduling, large language model adaptation},
location = {Sydney, NSW, Australia},
series = {ACM SIGCOMM '24}
}

@article{10.1145/3661143,
author = {Khanshan, Alireza and Van Gorp, Pieter and Markopoulos, Panos},
title = {Evaluation of Code Generation for Simulating Participant Behavior in Experience Sampling Method by Iterative In-Context Learning of a Large Language Model},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {EICS},
url = {https://doi.org/10.1145/3661143},
doi = {10.1145/3661143},
abstract = {The Experience Sampling Method (ESM) is commonly used to understand behaviors, thoughts, and feelings in the wild by collecting self-reports. Sustaining sufficient response rates, especially in long-running studies remains challenging. To avoid low response rates and dropouts, experimenters rely on their experience, proposed methodologies from earlier studies, trial and error, or the scarcely available participant behavior data from previous ESM protocols. This approach often fails in finding the acceptable study parameters, resulting in redesigning the protocol and repeating the experiment. Research has shown the potential of machine learning to personalize ESM protocols such that ESM prompts are delivered at opportune moments, leading to higher response rates. The corresponding training process is hindered due to the scarcity of open data in the ESM domain, causing a cold start, which could be mitigated by simulating participant behavior. Such simulations provide training data and insights for the experimenters to update their study design choices. Creating this simulation requires behavioral science, psychology, and programming expertise. Large language models (LLMs) have emerged as facilitators for information inquiry and programming, albeit random and occasionally unreliable. We aspire to assess the readiness of LLMs in an ESM use case. We conducted research using GPT-3.5 turbo-16k to tackle an ESM simulation problem. We explored several prompt design alternatives to generate ESM simulation programs, evaluated the output code in terms of semantics and syntax, and interviewed ESM practitioners. We found that engineering LLM-enabled ESM simulations have the potential to facilitate data generation, but they perpetuate trust and reliability challenges.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {255},
numpages = {19},
keywords = {Behavior Simulation, Experience Sampling Method, Large Language Model, Prompt Engineering}
}

@inproceedings{10.1145/3639701.3656308,
author = {Alonso del Barrio, David and Tiel, Max and Gatica-Perez, Daniel},
title = {Human Interest or Conflict? Leveraging LLMs for Automated Framing Analysis in TV Shows},
year = {2024},
isbn = {9798400705038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639701.3656308},
doi = {10.1145/3639701.3656308},
abstract = {In the current media landscape, understanding the framing of information is crucial for critical consumption and informed decision making. Framing analysis is a valuable tool for identifying the underlying perspectives used to present information, and has been applied to a variety of media formats, including television programs. However, manual analysis of framing can be time-consuming and labor-intensive. This is where large language models (LLMs) can play a key role. In this paper, we propose a novel approach to use prompt-engineering to identify the framing of spoken content in television programs. Our findings indicate that prompt-engineering LLMs can be used as a support tool to identify frames, with agreement rates between human and machine reaching up to 43%. As LLMs are still under development, we believe that our approach has the potential to be refined and further improved. The potential of this technology for interactive media applications is vast, including the development of support tools for journalists, educational resources for students of journalism learning about framing and related concepts, and interactive media experiences for audiences.},
booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences},
pages = {157–167},
numpages = {11},
keywords = {LLMs, TV, framing analysis, media, prompt-engineering},
location = {Stockholm, Sweden},
series = {IMX '24}
}

@inproceedings{10.1145/3698587.3701447,
author = {Liu, Zengding and Chen, Chen and Cao, Jiannong and Pan, Minglei and Liu, Jikui and Li, Nan and Miao, Fen and Li, Ye},
title = {Large Language Models for Cuffless Blood Pressure Measurement From Wearable Biosignals},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701447},
doi = {10.1145/3698587.3701447},
abstract = {Large language models (LLMs) have captured significant interest from both academia and industry due to their impressive performance across various textual tasks. However, the potential of LLMs to analyze physiological time-series data remains an emerging research field. Particularly, there is a notable gap in the utilization of LLMs for analyzing wearable biosignals to achieve cuffless blood pressure (BP) measurement, which is critical for the management of cardiovascular diseases. This paper presents the first work to explore the capacity of LLMs to perform cuffless BP estimation based on wearable biosignals. We extracted physiological features from electrocardiogram (ECG) and photoplethysmogram (PPG) signals and designed context-enhanced prompts by combining these features with BP domain knowledge and user information. Subsequently, we adapted LLMs to BP estimation tasks through instruction tuning. To evaluate the proposed approach, we conducted assessments of ten advanced LLMs using a comprehensive public dataset of wearable biosignals from 1,272 participants. The experimental results demonstrate that the optimally fine-tuned LLM significantly surpasses conventional task-specific baselines, achieving an estimation error of 0.00 ± 9.25 mmHg for systolic BP and 1.29 ± 6.37 mmHg for diastolic BP. Notably, the ablation studies highlight the benefits of our context enhancement strategy, leading to an 8.9% reduction in mean absolute error for systolic BP estimation. This paper pioneers the exploration of LLMs for cuffless BP measurement, providing a potential solution to enhance the accuracy of cuffless BP measurement.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {27},
numpages = {11},
keywords = {cuffless blood pressure, instruction tuning, large language models, wearable biosignals},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3675249.3675307,
author = {Yao, Huan and Bao, Wanying and Wu, Hequn},
title = {BabyGAN for Facial Contour Reversion: AI Course Applications Using U-Net Architecture},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675307},
doi = {10.1145/3675249.3675307},
abstract = {BabyGAN is a generative adversarial network model based on the U-net architecture and residual networks, designed for the transformation of adult facial contours into baby facial contours. This model is primarily used in the artificial intelligence practical courses of vocational colleges, focusing on information technology education. A key feature of BabyGAN is its ability to help students deeply understand the logical structure of generative adversarial networks while also fostering their enthusiasm. Compared to other GAN models used in teaching, BabyGAN has the advantage of allowing students to easily construct training sets, enabling immediate use of class-specific datasets in the classroom. The working principle of BabyGAN involves integrating a special keypoint constraint loss function in the generator to produce high-quality baby facial contours, thereby transforming adult facial contours into corresponding high-quality infant facial contours. BabyGAN plays a significant role in the future work scenarios of students. Incorporating the BabyGAN course into AI curricula effectively blends information technology education with students' future career prospects. The application of GANs to meet user needs is a current research hotspot. Introducing students to BabyGAN in a fun and educational setting also aligns with market demands, equipping students with practical skills and the ability to apply these skills in future work contexts.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {324–329},
numpages = {6},
location = {Sanming, China},
series = {ICCMT '24}
}

@article{10.1145/3657282,
author = {Liu, Hou-I and Galindo, Marco and Xie, Hongxia and Wong, Lai-Kuan and Shuai, Hong-Han and Li, Yung-Hui and Cheng, Wen-Huang},
title = {Lightweight Deep Learning for Resource-Constrained Environments: A Survey},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3657282},
doi = {10.1145/3657282},
abstract = {Over the past decade, the dominance of deep learning has prevailed across various domains of artificial intelligence, including natural language processing, computer vision, and biomedical signal processing. While there have been remarkable improvements in model accuracy, deploying these models on lightweight devices, such as mobile phones and microcontrollers, is constrained by limited resources. In this survey, we provide comprehensive design guidance tailored for these devices, detailing the meticulous design of lightweight models, compression methods, and hardware acceleration strategies. The principal goal of this work is to explore methods and concepts for getting around hardware constraints without compromising the model’s accuracy. Additionally, we explore two notable paths for lightweight deep learning in the future: deployment techniques for TinyML and Large Language Models. Although these paths undoubtedly have potential, they also present significant challenges, encouraging research into unexplored areas.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {267},
numpages = {42},
keywords = {Lightweight model, efficient transformer, model compression, quantization, tinyML, large language models}
}

@inproceedings{10.1145/3616855.3635690,
author = {Xie, Yukang and Wang, Chengyu and Yan, Junbing and Zhou, Jiyong and Deng, Feiqi and Huang, Jun},
title = {Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635690},
doi = {10.1145/3616855.3635690},
abstract = {Recently, Large Language Models (LLMs) have achieved amazing zero-shot learning performance over a variety of Natural Language Processing (NLP) tasks, especially for text generative tasks. Yet, the large size of LLMs often leads to the high computational cost of model training and online deployment. In our work, we present ALTER, a system that effectively builds the multi-tAsk Learners with mixTure-of-task-adaptERs upon small language models (with &lt;1B parameters) to address multiple NLP tasks simultaneously, capturing the commonalities and differences between tasks, in order to support domain-specific applications. Specifically, in ALTER, we propose the Mixture-of-Task-Adapters (MTA) module as an extension to the transformer architecture for the underlying model to capture the intra-task and inter-task knowledge. A two-stage training method is further proposed to optimize the collaboration between adapters at a small computational cost. Experimental results over a mixture of NLP tasks show that our proposed MTA architecture and the two-stage training method achieve good performance. Based on ALTER, we have also produced MTA-equipped language models for various domains.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1094–1097},
numpages = {4},
keywords = {language model, multi-task learning, text generation},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3650212.3680334,
author = {Ran, Dezhi and Wang, Hao and Song, Zihe and Wu, Mengzhou and Cao, Yuan and Zhang, Ying and Yang, Wei and Xie, Tao},
title = {Guardian: A Runtime Framework for LLM-Based UI Exploration},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680334},
doi = {10.1145/3650212.3680334},
abstract = {Tests for feature-based UI testing have been indispensable for ensuring the quality of mobile applications (apps for short).        The high manual labor costs to create such tests have led to a strong interest in automated feature-based UI testing, where an approach automatically explores the App under Test (AUT) to find correct sequences of UI events achieving the target test objective, given only a high-level test objective description.        Given that the task of automated feature-based UI testing resembles conventional AI planning problems, large language models (LLMs), known for their effectiveness in AI planning, could be ideal for this task.        However, our study reveals that LLMs struggle with following specific instructions for UI testing and replanning based on new information. This limitation results in reduced effectiveness of LLM-driven solutions for automated feature-based UI testing, despite the use of advanced prompting techniques.                Toward addressing the preceding limitation, we propose Guardian, a runtime system framework to improve the effectiveness of automated feature-based UI testing by offloading computational tasks from LLMs with two major strategies.        First, Guardian refines UI action space that the LLM can plan over, enforcing the instruction following of the LLM by construction.        Second, Guardian deliberately checks whether the gradually enriched information invalidates previous planning by the LLM.        Guardian removes the invalidated UI actions from the UI action space that the LLM can plan over, restores the state of the AUT to the state before the execution of the invalidated UI actions, and prompts the LLM to re-plan with the new UI action space.        We instantiate Guardian with ChatGPT and construct a benchmark named FestiVal with 58 tasks from 23 highly popular apps.        Evaluation results on FestiVal show that Guardian achieves 48.3},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {958–970},
numpages = {13},
keywords = {Android Testing, Large Language Models, Mobile Testing, Runtime System, Sequential Planning, UI Testing},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3626246.3654727,
author = {Chen, Sibei and Liu, Hanbing and Jin, Waiting and Sun, Xiangyu and Feng, Xiaoyao and Fan, Ju and Du, Xiaoyong and Tang, Nan},
title = {ChatPipe: Orchestrating Data Preparation Pipelines by Optimizing Human-ChatGPT Interactions},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3654727},
doi = {10.1145/3626246.3654727},
abstract = {Orchestrating a high-quality data preparation program is essential for successful machine learning (ML), but it is known to be time and effort consuming. Despite the impressive capabilities of large language models like ChatGPT in generating programs by inter- acting with users through natural language prompts, there are still limitations. Specifically, a user must provide specific prompts to iteratively guide ChatGPT in improving data preparation programs, which requires a certain level of expertise in programming, the dataset used and the ML task. Moreover, once a program has been generated, it is non-trivial to revisit a previous version or make changes to the program without starting the process over again. In this paper, we present ChatPipe, a novel system designed to facilitate seamless interaction between users and ChatGPT. Chat- Pipe provides users with effective recommendation on next data preparation operations, and guides ChatGPT to generate program for the operations. Also, ChatPipe enables users to easily roll back to previous versions of the program, which facilitates more efficient experimentation and testing. We have developed a web application for ChatPipe and prepared several real-world ML tasks from Kaggle, which can demonstrate the capabilities of ChatPipe.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {484–487},
numpages = {4},
keywords = {data preparation, human-in-the-loop, reinforcement learning},
location = {Santiago AA, Chile},
series = {SIGMOD '24}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3650212.3680359,
author = {Yin, Xin and Ni, Chao and Wang, Shaohua and Li, Zhenhao and Zeng, Limin and Yang, Xiaohu},
title = {ThinkRepair: Self-Directed Automated Program Repair},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680359},
doi = {10.1145/3650212.3680359},
abstract = {Though many approaches have been proposed for Automated Program Repair (APR) and indeed achieved remarkable performance, they still have limitations in fixing bugs that require analyzing and reasoning about the logic of the buggy program. Recently, large language models (LLMs) instructed by prompt engineering have attracted much attention for their powerful ability to address many kinds of tasks including bug-fixing. However, the quality of the prompt will highly affect the ability of LLMs and manually constructing high-quality prompts is a costly endeavor.
 
 
 
To address this limitation, we propose a self-directed LLM-based automated program repair, ThinkRepair, with two main phases: collection phase and fixing phase. The former phase automatically collects various chains of thoughts that constitute pre-fixed knowledge by instructing LLMs with the Chain-of-Thought (CoT) prompt. The latter phase targets fixing a bug by first selecting examples for few-shot learning and second automatically interacting with LLMs, optionally appending with feedback of testing information.
 
 
 
Evaluations on two widely studied datasets (Defects4J and QuixBugs) by comparing ThinkRepair with 12 SOTA APRs indicate the priority of ThinkRepair in fixing bugs. Notably, ThinkRepair fixes 98 bugs and improves baselines by 27%∼344.4% on Defects4J V1.2. On Defects4J V2.0, ThinkRepair fixes 12∼65 more bugs than the SOTA APRs. Additionally, ThinkRepair also makes a considerable improvement on QuixBugs (31 for Java and 21 for Python at most).},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1274–1286},
numpages = {13},
keywords = {Automated Program Repair, Large Language Model, Prompt Engineering},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1145/3643753,
author = {Wang, Yan and Li, Xiaoning and Nguyen, Tien N. and Wang, Shaohua and Ni, Chao and Ding, Ling},
title = {Natural Is the Best: Model-Agnostic Code Simplification for Pre-trained Large Language Models},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643753},
doi = {10.1145/3643753},
abstract = {Pre-trained Large Language Models (LLM) have achieved remarkable successes in several domains. However, code-oriented LLMs are often heavy in computational complexity, and quadratically with the length of the input code sequence. Toward simplifying the input program of an LLM, the state-of-the-art approach has the strategies to filter the input code tokens based on the attention scores given by the LLM. The decision to simplify the input program should not rely on the attention patterns of an LLM, as these patterns are influenced by both the model architecture and the pre-training dataset. Since the model and dataset are part of the solution domain, not the problem domain where the input program belongs, the outcome may differ when the model is pre-trained on a different dataset. We propose SlimCode, a model-agnostic code simplification solution for LLMs that depends on the nature of input code tokens. As an empirical study on the LLMs including CodeBERT, CodeT5, and GPT-4 for two main tasks: code search and summarization, we reported that 1) the removal ratio of code has a linear-like relation with the saving ratio on training time, 2) the impact of categorized tokens on code simplification can vary significantly, 3) the impact of categorized tokens on code simplification is task-specific but model-agnostic, and 4) the above findings hold for the paradigm–prompt engineering and interactive in-context learning. The empirical results showed that SlimCode can improve the state-of-the-art technique by 9.46% and 5.15% in terms of MRR and BLEU score on code search and summarization, respectively. More importantly, SlimCode is 133 times faster than the state-of-the-art approach. Additionally, SlimCode can reduce the cost of invoking GPT-4 by up to 24% per API query, while still producing comparable results to those with the original code. With this result, we call for a new direction on code-based, model-agnostic code simplification solutions to further empower LLMs.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {27},
numpages = {23},
keywords = {AI4SE, Code Simplification, Machine Learning, Neural Networks, Pre-trained Large Language Models}
}

@inproceedings{10.1145/3657604.3664694,
author = {Calo, Tommaso and Maclellan, Christopher},
title = {Towards Educator-Driven Tutor Authoring: Generative AI Approaches for Creating Intelligent Tutor Interfaces},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664694},
doi = {10.1145/3657604.3664694},
abstract = {Intelligent Tutoring Systems (ITSs) have shown great potential in delivering personalized and adaptive education, but their widespread adoption has been hindered by the need for specialized programming and design skills. Existing approaches overcome the programming limitations with no-code authoring through drag and drop, however they assume that educators possess the necessary skills to design effective and engaging tutor interfaces. To address this assumption we introduce generative AI capabilities to assist educators in creating tutor interfaces that meet their needs while adhering to design principles. Our approach leverages Large Language Models (LLMs) and prompt engineering to generate tutor layout and contents based on high-level requirements provided by educators as inputs. However, to allow them to actively participate in the design process, rather than relying entirely on AI-generated solutions, we allow generation both at the entire interface level and at the individual component level. The former provides educators with a complete interface that can be refined using direct manipulation, while the latter offers the ability to create specific elements to be added to the tutor interface. A small-scale comparison shows the potential of our approach to enhance the efficiency of tutor interface design. Moving forward, we raise critical questions for assisting educators with generative AI capabilities to create personalized, effective, and engaging tutors, ultimately enhancing their adoption.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {305–309},
numpages = {5},
keywords = {human-centered computing, intelligent tutoring systems, intelligent-user-interfaces, ui/ux},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1109/ASE56229.2023.00181,
author = {Huang, Kai and Meng, Xiangxin and Zhang, Jian and Liu, Yang and Wang, Wenjie and Li, Shuhao and Zhang, Yuqing},
title = {An Empirical Study on Fine-Tuning Large Language Models of Code for Automated Program Repair},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00181},
doi = {10.1109/ASE56229.2023.00181},
abstract = {The advent of large language models (LLMs) has opened up new opportunities for automated program repair (APR). In particular, some recent studies have explored how to leverage large language models of code (LLMCs) for program repair tasks and show promising results. However, most of them adopt the zero/few-shot learning paradigm for APR, which directly use LLMCs to generate the possibly correct code given its surrounding context. Though effective, the repair capabilities of LLMCs based on the fine-tuning paradigm have yet to be extensively explored. Also, it remains unknown whether LLMCs have the potential to repair more complicated bugs (e.g., multi-hunk bugs). To fill the gap, in this work, we conduct a comprehensive study on the program repair capability of LLMCs in the fine-tuning paradigm. We select 5 popular LLMCs with representative pre-training architectures, including CodeBERT, GraphCodeBERT, PLBART, CodeT5, and UniXcoder. We consider 3 typical program repair scenarios (i.e., bugs, vulnerabilities, and errors) involving 3 programming languages (i.e., Java, C/C++, and JavaScript). Notably, we take both single-hunk and multi-hunk bugs/vulnerabilities into account. We then fine-tune them on widely-used datasets and compare them with existing state-of-the-art APR tools. We also investigate the impact of different design choices, which include code abstractions, code representations, and model evaluation metrics. Our experimental results show that LLMCs in the fine-tuning paradigm can significantly outperform previous state-of-the-art APR tools. Through in-depth analysis, we provide insights into choosing appropriate strategies to guide LLMCs for better performance. Lastly, we reveal several limitations of LLMCs for APR and make suggestions for future research on LLMC-based APR.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1162–1174},
numpages = {13},
keywords = {automated program repair, large language models of code, neural machine translation, fine-tuning},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3654522.3654596,
author = {Jeong, Hong-Ju and Boo, Hacksung and Bae, Jiseung and Jeon, Mincheol and Huh, Eui-Nam},
title = {An Energy-Efficient Parallelism Scheme for Deep Neural Network Training And Inferencing on Heterogeneous Cloud Resources},
year = {2024},
isbn = {9798400716713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654522.3654596},
doi = {10.1145/3654522.3654596},
abstract = {The emergence of Large Language Models(LLM) and generative AI has led to an explosive increase in computational demands across cloud computing data centers. The growing number of parameters in deep learning models results in significant power consumption problem, leading to the need for cost-effective and eco-friendly data centers. Furthermore, with the advent of multi-cloud environments, deep learning computations, not only for training but also for inference, no longer occur on a single hardware unit but are distributed across various heterogeneous hardware nodes forming clusters. In this paper, we present solutions to these challenges from a parallelism perspective. Considering the characteristics of the models, we implement data parallelism and model parallelism, partitioning models and data across heterogeneous hardware nodes for power-efficient learning and inferencing. To quantify the impact, we measured the power consumption of CPUs, GPUs, and RAM during the experiments, providing insights into the energy efficiency of the proposed partitioning strategies. Furthermore, we conducted a carbon footprint analysis, converting the measured power consumption into equivalent carbon emissions. The study highlights the necessity of partitioning research for energy-efficient learning and inferencing, addressing the identified issues.},
booktitle = {Proceedings of the 2024 9th International Conference on Intelligent Information Technology},
pages = {493–498},
numpages = {6},
keywords = {Carbon footprint, Deep learning, Heterogeneous, Parallelism, Power consumption},
location = {Ho Chi Minh City, Vietnam},
series = {ICIIT '24}
}

@inproceedings{10.1145/3627673.3679821,
author = {Wang, Haoran and Shu, Kai},
title = {Trojan Activation Attack: Red-Teaming Large Language Models using Steering Vectors for Safety-Alignment},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679821},
doi = {10.1145/3627673.3679821},
abstract = {To ensure AI safety, instruction-tuned Large Language Models (LLMs) are specifically trained to ensure alignment, which refers to making models behave in accordance with human intentions. While these models have demonstrated commendable results on various safety benchmarks, the vulnerability of their safety alignment has not been extensively studied. This is particularly troubling given the potential harm that LLMs can inflict. Existing attack methods on LLMs often rely on poisoned training data or the injection of malicious prompts. These approaches compromise the stealthiness and generalizability of the attacks, making them susceptible to detection. Additionally, these models often demand substantial computational resources for implementation, making them less practical for real-world applications. In this work, we study a different attack scenario, called Trojan Activation Attack (TA2), which injects trojan steering vectors into the activation layers of LLMs. These malicious steering vectors can be triggered at inference time to steer the models toward attacker-desired behaviors by manipulating their activations. Our experiment results on four primary alignment tasks show that TA2 is highly effective and adds little or no overhead to attack efficiency. Additionally, we discuss potential countermeasures against such activation attacks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2347–2357},
numpages = {11},
keywords = {activation steering, large language model, trojan attack},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3589334.3645414,
author = {Zhang, Zhen and Zhao, Yuhua and Gao, Hang and Hu, Mengting},
title = {LinkNER: Linking Local Named Entity Recognition Models to Large Language Models using Uncertainty},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645414},
doi = {10.1145/3589334.3645414},
abstract = {Named Entity Recognition (NER) serves as a fundamental task in natural language understanding, bearing direct implications for web content analysis, search engines, and information retrieval systems. Fine-tuned NER models exhibit satisfactory performance on standard NER benchmarks. However, due to limited fine-tuning data and lack of knowledge, it performs poorly on unseen entity recognition. As a result, the usability and reliability of NER models in web-related applications are compromised. Instead, Large Language Models (LLMs) like GPT-4 possess extensive external knowledge, but research indicates that they lack specialty for NER tasks. Furthermore, non-public and large-scale weights make tuning LLMs difficult. To address these challenges, we propose a framework that combines small fine-tuned models with LLMs (LinkNER) and an uncertainty-based linking strategy called RDC that enables fine-tuned models to complement black-box LLMs, achieving better performance. We experiment with both standard NER test sets and noisy social media datasets. LinkNER enhances NER task performance, notably surpassing SOTA models in robustness tests. We also quantitatively analyze the influence of key components like uncertainty estimation methods, LLMs, and in-context learning on diverse NER tasks, offering specific web-related recommendations.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4047–4058},
numpages = {12},
keywords = {information extraction, large language models, robustness, uncertainty estimation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3672393,
author = {Periti, Francesco and Montanelli, Stefano},
title = {Lexical Semantic Change through Large Language Models: a Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3672393},
doi = {10.1145/3672393},
abstract = {Lexical Semantic Change (LSC) is the task of identifying, interpreting, and assessing the possible change over time in the meanings of a target word. Traditionally, LSC has been addressed by linguists and social scientists through manual and time-consuming analyses, which have thus been limited in terms of the volume, genres, and time-frame that can be considered. In recent years, computational approaches based on Natural Language Processing have gained increasing attention to automate LSC as much as possible. Significant advancements have been made by relying on Large Language Models (LLMs), which can handle the multiple usages of the words and better capture the related semantic change. In this article, we survey the approaches based on LLMs for LSC, and we propose a classification framework characterized by three dimensions: meaning representation, time-awareness, and learning modality. The framework is exploited to (i) review the measures for change assessment, (ii) compare the approaches on performance, and (iii) discuss the current issues in terms of scalability, interpretability, and robustness. Open challenges and future research directions about the use of LLMs for LSC are finally outlined.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {282},
numpages = {38},
keywords = {Lexical semantics, lexical semantic change, semantic shift detection, large language models}
}

@inproceedings{10.1145/3626772.3657974,
author = {Geng, Binzong and Huan, Zhaoxin and Zhang, Xiaolu and He, Yong and Zhang, Liang and Yuan, Fajie and Zhou, Jun and Mo, Linjian},
title = {Breaking the Length Barrier: LLM-Enhanced CTR Prediction in Long Textual User Behaviors},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657974},
doi = {10.1145/3626772.3657974},
abstract = {With the rise of large language models (LLMs), recent works have leveraged LLMs to improve the performance of click-through rate (CTR) prediction. However, we argue that a critical obstacle remains in deploying LLMs for practical use: the efficiency of LLMs when processing long textual user behaviors. As user sequences grow longer, the current efficiency of LLMs is inadequate for training on billions of users and items. To break through the efficiency barrier of LLMs, we propose Behavior Aggregated Hierarchical Encoding (BAHE) to enhance the efficiency of LLM-based CTR modeling. Specifically, BAHE proposes a novel hierarchical architecture that decouples the encoding of user behaviors from inter-behavior interactions. Firstly, to prevent computational redundancy from repeated encoding of identical user behaviors, BAHE employs the LLM's pre-trained shallow layers to extract embeddings of the most granular, atomic user behaviors from extensive user sequences and stores them in the offline database. Subsequently, the deeper, trainable layers of the LLM facilitate intricate inter-behavior interactions, thereby generating comprehensive user embeddings. This separation allows the learning of high-level user representations to be independent of low-level behavior encoding, significantly reducing computational complexity. Finally, these refined user embeddings, in conjunction with correspondingly processed item embeddings, are incorporated into the CTR model to compute the CTR scores. Extensive experimental results show that BAHE reduces training time and memory by five times for CTR models using LLMs, especially with longer user sequences. BAHE has been deployed in a real-world system, allowing for daily updates of 50 million CTR data on 8 A100 GPUs, making LLMs practical for industrial CTR prediction.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2311–2315},
numpages = {5},
keywords = {click-through rate prediction, large language models},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3652620.3687802,
author = {Buchmann, Thomas},
title = {Prompting Bidirectional Model Transformations - The Good, The Bad and The Ugly},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687802},
doi = {10.1145/3652620.3687802},
abstract = {This paper investigates the comparative effectiveness of model-to-model transformations generated by an LLM based upon user prompts versus those created with dedicated model transformation languages, using a standard benchmark. The emergence of Generative AI offers a novel approach, allowing developers to specify transformations in natural language rather than learning specialized languages. However, our findings suggest that, in its current state, generative AI does not yet pose a threat to dedicated model transformation languages. While AI-assisted approaches promise to provide flexibility and accessibility, dedicated model transformation languages still offer structured advantages crucial for complex transformations, especially when bidirectionality and incrementality are mandatory requirements. This research contributes to the ongoing discourse on the role of AI in software engineering, highlighting its potential and current limitations in enhancing model transformation processes.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {550–555},
numpages = {6},
keywords = {modeling, LLM, MDE, AI, modeltransformation, Bx},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1145/3643745,
author = {Zan, Daoguang and Yu, Ailun and Shen, Bo and Chen, Bei and Li, Wei and Gong, Yongshun and Chen, Xiaolin and Yao, Yafen and Luo, Weihua and Guan, Bei and Liu, Yan and Wang, Yongji and Wang, Qianxiang and Cui, Lizhen},
title = {DiffCoder: Enhancing Large Language Model on API Invocation via Analogical Code Exercises},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643745},
doi = {10.1145/3643745},
abstract = {The task of code generation aims to generate code solutions based on given programming problems. Recently, code large language models (code LLMs) have shed new light on this task, owing to their formidable code generation capabilities. While these models are powerful, they seldom focus on further improving the accuracy of library-oriented API invocation. Nonetheless, programmers frequently invoke APIs in routine coding tasks. In this paper, we aim to enhance the proficiency of existing code LLMs regarding API invocation by mimicking analogical learning, which is a critical learning strategy for humans to learn through differences among multiple instances. Motivated by this, we propose a simple yet effective approach, namely DiffCoder, which excels in API invocation by effectively training on the differences (diffs) between analogical code exercises. To assess the API invocation capabilities of code LLMs, we conduct experiments on seven existing benchmarks that focus on mono-library API invocation. Additionally, we construct a new benchmark, namely PanNumEval, to evaluate the performance of multi-library API invocation. Extensive experiments on eight benchmarks demonstrate the impressive performance of DiffCoder. Furthermore, we develop a VSCode plugin for DiffCoder, and the results from twelve invited participants further verify the practicality of DiffCoder.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {19},
numpages = {21},
keywords = {Code Generation, Code Library, Instruction Tuning, Large Language Model}
}

@inproceedings{10.1145/3660829.3660845,
author = {Mattis, Toni and Krebs, Eva and Rinard, Martin C. and Hirschfeld, Robert},
title = {Examples out of Thin Air: AI-Generated Dynamic Context to Assist Program Comprehension by Example},
year = {2024},
isbn = {9798400706349},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660829.3660845},
doi = {10.1145/3660829.3660845},
abstract = {Programmers often benefit from the availability of concrete run-time data alongside abstract source code. However, programmers need to manually exercise the program to reach an interesting state or write code that reproducibly executes a functionality with concrete inputs to be able to observe concrete data. This work aims to automate this process by leveraging generative AI. We present a framework and a preliminary Smalltalk-based prototype allowing programmers to obtain and run examples for the currently viewed source code section from a large language model. Our approach demonstrates how locally hosted LLMs can be fine-tuned and used for such a task with reasonable computational effort while minimizing common problems like hallucinations and out-of-date knowledge. The framework has direct applications in example-based live programming, where it can suggest new examples, and in learning settings where novices need to know how to use certain functionality.},
booktitle = {Companion Proceedings of the 8th International Conference on the Art, Science, and Engineering of Programming},
pages = {99–107},
numpages = {9},
keywords = {example-based programming, generative ai, large language models, live programming, smalltalk},
location = {Lund, Sweden},
series = {Programming '24}
}

@inproceedings{10.1145/3643479.3662057,
author = {Liu, Yi-Cheng and Chu, Wei-Ta},
title = {Chart Question Answering based on Modality Conversion and Large Language Models},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662057},
doi = {10.1145/3643479.3662057},
abstract = {A two-stage chart question answering system is proposed in this paper. Chart/plot images are first converted into structured text-based data by a transformer-based conversion model. Based on the structured text data, a large language model (LLM) is employed to answer the given questions to achieve chart-related question answering. Techniques like chain-of-thoughts, self-consistency, and program of thoughts are utilized to prompt the LLM based on the one-shot learning scheme. We also found that, by rephrasing questions several times and asking the LLM, different answers may be obtained. Aggregating these answers gives rise to performance gain. Overall, we show the proposed method is competitive or even better than the state of the arts, with smaller model size and requiring less training data.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {19–24},
numpages = {6},
keywords = {ChartQA, Large language model, PlotQA, Visual question answering},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@inproceedings{10.1145/3651890.3672239,
author = {Cao, Jiamin and Guan, Yu and Qian, Kun and Gao, Jiaqi and Xiao, Wencong and Dong, Jianbo and Fu, Binzhang and Cai, Dennis and Zhai, Ennan},
title = {Crux: GPU-Efficient Communication Scheduling for Deep Learning Training},
year = {2024},
isbn = {9798400706141},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651890.3672239},
doi = {10.1145/3651890.3672239},
abstract = {Deep learning training (DLT), e.g., large language model (LLM) training, has become one of the most important services in multitenant cloud computing. By deeply studying in-production DLT jobs, we observed that communication contention among different DLT jobs seriously influences the overall GPU computation utilization, resulting in the low efficiency of the training cluster. In this paper, we present Crux, a communication scheduler that aims to maximize GPU computation utilization by mitigating the communication contention among DLT jobs. Maximizing GPU computation utilization for DLT, nevertheless, is NP-Complete; thus, we formulate and prove a novel theorem to approach this goal by GPU intensity-aware communication scheduling. Then, we propose an approach that prioritizes the DLT flows with high GPU computation intensity, reducing potential communication contention. Our 96-GPU testbed experiments show that Crux improves 8.3% to 14.8% GPU computation utilization. The large-scale production trace-based simulation further shows that Crux increases GPU computation utilization by up to 23% compared with alternatives including Sincronia, TACCL, and CASSINI.},
booktitle = {Proceedings of the ACM SIGCOMM 2024 Conference},
pages = {1–15},
numpages = {15},
keywords = {communication scheduling, data center network, deep learning},
location = {Sydney, NSW, Australia},
series = {ACM SIGCOMM '24}
}

@inproceedings{10.1145/3625223.3649280,
author = {Morgan, Fearghal and Byrne, John Patrick and Bupathi, Abishek and George, Roshan and Elahi, Adnan and Callaly, Frank and Kelly, Se\'{a}n and O'Loughlin, Declan},
title = {HDLGen-ChatGPT Case Study: RISC-V Processor VHDL and Verilog Model - Testbench and EDA Project Generation},
year = {2024},
isbn = {9798400704109},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625223.3649280},
doi = {10.1145/3625223.3649280},
abstract = {This paper presents the open source HDLGen-ChatGPT application, working in tandem with ChatGPT-3.5, the free online large language model (LLM) chat interface. The tools enable fast digital systems design and test specification capture, and automatic generation of both VHDL and Verilog models, and testbenches, and AMD Vivado and Intel Quartus Electronic Design Automation (EDA) projects. EDA tools check the generated HDL syntax, simulate and synthesise HDL models, and follow the steps to FPGA hardware prototyping. The tools exploit a formal, top-down design and test specification documentation process, domain knowledge, and the flexibility of LLMs, for HDL code generation. Results are included for a hierarchical RV32I RISC-V processor design. Process steps are illustrated for the RISC-V 32 \texttimes{} 32-bit register bank component. The process typically requires only minimal manual HDL capture or editing, and often none at all. URLs to tutorial videos for the complete RISC-V design are provided on the GitHub project repository. The paper evaluates the results and provides HDLGen-ChatGPT and ChatGPT usage recommendations. The tools can be applied in digital systems training programmes, with reduced emphasis on the assessment of HDL model and testbench capture and generation, while maintaining strong emphasis on the assessment of system design, test planning and documentation, HDL simulation verification/debug, and analysis of synthesised netlists.},
booktitle = {Proceedings of the 34th International Workshop on Rapid System Prototyping},
articleno = {11},
numpages = {7},
keywords = {digital systems design, HDLGen-ChatGPT, LLM, ChatGPT, generative AI, design capture, automation, HDL, EDA, FPGA, testbench, VHDL, verilog},
location = {Hamburg, Germany},
series = {RSP '23}
}

@inproceedings{10.1145/3663529.3663829,
author = {Toslali, Mert and Snible, Edward and Chen, Jing and Cha, Alan and Singh, Sandeep and Kalantar, Michael and Parthasarathy, Srinivasan},
title = {AgraBOT: Accelerating Third-Party Security Risk Management in Enterprise Setting through Generative AI},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663829},
doi = {10.1145/3663529.3663829},
abstract = {In the contemporary business landscape, organizations often rely on third-party services for many functions, including IT services, cloud computing, and business processes. To identify potential security risks, organizations conduct rigorous assessments before engaging with third-party vendors, referred to as Third-Party Security Risk Management (TPSRM). Traditionally, TPSRM assessments are executed manually by human experts and involve scrutinizing various third-party documents such as System and Organization Controls Type 2 (SOC 2) reports and reviewing comprehensive questionnaires along with the security policy and procedures of vendors—a process that is time-intensive and inherently lacks scalability. 
 
 
 
AgraBOT, a Retrieval Augmented Generation (RAG) framework, can assist TPSRM assessors by expediting TPSRM assessments and reducing the time required from days to mere minutes. AgraBOT utilizes cutting-edge AI techniques, including information retrieval (IR), large language models (LLMs), multi-stage ranking, prompt engineering, and in-context learning to accurately generate relevant answers from third-party documents to conduct assessments. We evaluate AgraBOT on seven real TPSRM assessments, consisting of 373 question-answer pairs, and attain an F1 score of 0.85.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {74–79},
numpages = {6},
keywords = {AI, Document Understanding, LLM, RAG, TPSRM},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3637528.3671456,
author = {Li, Jia and Sun, Xiangguo and Li, Yuhan and Li, Zhixun and Cheng, Hong and Yu, Jeffrey Xu},
title = {Graph Intelligence with Large Language Models and Prompt Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671456},
doi = {10.1145/3637528.3671456},
abstract = {Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Graph intelligence is rapidly becoming a crucial aspect of understanding and exploiting the intricate interconnections within graph data. Recently, large language models (LLMs) and prompt learning techniques have pushed graph intelligence forward, outperforming traditional Graph Neural Network (GNN) pre-training methods and setting new benchmarks for performance. In this tutorial, we begin by offering a comprehensive review and analysis of existing methods that integrate LLMs with graphs. We introduce existing works based on a novel taxonomy that classifies them into three distinct categories according to the roles of LLMs in graph tasks: as enhancers, predictors, or alignment components. Secondly, we introduce a new learning method that utilizes prompting on graphs, offering substantial potential to enhance graph transfer capabilities across diverse tasks and domains. We discuss existing works on graph prompting within a unified framework and introduce our developed tool for executing a variety of graph prompting tasks. Additionally, we discuss the applications of combining Graphs, LLMs, and prompt learning across various tasks, such as urban computing, recommendation systems, and anomaly detection. This lecture-style tutorial is an extension of our original work published in IJCAI 2024[44] and arXiv[77] with the invitation of KDD24.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6545–6554},
numpages = {10},
keywords = {graph learning, graph prompting, large language model},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3613905.3650792,
author = {Higasa, Taichi and Tanaka, Keitaro and Feng, Qi and Morishima, Shigeo},
title = {Keep Eyes on the Sentence: An Interactive Sentence Simplification System for English Learners Based on Eye Tracking and Large Language Models},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650792},
doi = {10.1145/3613905.3650792},
abstract = {Language learners should read challenging texts regularly. However, using dictionaries or search engines to look up difficult expressions can be time-consuming and distracting. To address this, we have developed a system combining eye tracking with Large Language Models (LLMs) to simplify sentences automatically, allowing learners to focus on the content. The system incorporates user-tailored models that estimate users’ comprehension of sentences using gaze data and sentence information. The system also features user-triggered simplification, resulting from iterative design improvements. We conducted a user study with 17 English learners where they read English text using either our system or a baseline involving online dictionaries and search engines. Our system significantly improved both reading speed and comprehension, especially for complex sentences. The gaze-based simplification improved concentration on the content, allowing for an interruption-free reading experience. It could assist in daily reading practice, particularly for extensive reading focused on large volumes of text at a rapid pace.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {211},
numpages = {7},
keywords = {Eye tracking, human-computer interaction, machine learning, sentence simplification},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3657604.3664664,
author = {Moreau-Pernet, Baptiste and Tian, Yu and Sawaya, Sandra and Foltz, Peter and Cao, Jie and Milne, Brent and Christie, Thomas},
title = {Classifying Tutor Discursive Moves at Scale in Mathematics Classrooms with Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664664},
doi = {10.1145/3657604.3664664},
abstract = {In mathematics tutoring, using appropriate instructional discursive strategies, called "talk moves'', is critical to support student learning. Training tutors in the appropriate use of talk moves is a key component of tutor development programs. However, tutor development at scale is a challenge. Recent research has shown that automatic talk moves classification of tutorial discourse can facilitate large-scale delivery of personalized talk moves feedback. In this paper, we build on this work and share our current progress using large language models to classify talk moves in transcripts of tutoring sessions. We report classification results from fine-tuned models, prompt optimization, and supervised embedding vectors classification. The fine-tuned strategy performed best, yielding better performance (.87 macro and .93 weighted f1 score in predicting expert labels) than the current state-of-the-art RoBERTa model. We discuss trade-offs across methods and models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {361–365},
numpages = {5},
keywords = {discourse analysis, llm classification, math tutor training},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3637528.3672194,
author = {Lin, Xihong},
title = {Empower an End-to-end Scalable and Interpretable Data Science Ecosystem using Statistics, AI and Domain Science},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672194},
doi = {10.1145/3637528.3672194},
abstract = {The data science ecosystem encompasses data fairness, statistical, ML and AI methods and tools, interpretable data analysis and results, and trustworthy decision-making. Rapid advancements in AI have revolutionized data utilization and enabled machines to learn from data more effectively. Statistics, as the science of learning from data while accounting for uncertainty, plays a pivotal role in addressing complex real-world problems and facilitating trustworthy decision-making. In this talk, I will discuss the challenges and opportunities involved in building an end-to-end scalable and interpretable data science ecosystem using the analysis of whole genome sequencing studies and biobanks that integrates statistics, ML/AI, and genomic and health science as an example. Biobanks collect whole genome data, electronic health records and epidemiological data. I will illustrate key points using the analysis of multi-ancestry whole genome sequencing studies and biobanks by discussing a few scalable and interpretable statistical and ML/AI methods, tools and data science resources.Specifically, first, data fairness and diversity is a critical pillar of a trustworthy data science ecosystem. About 85+% of genome wide association study samples in the last 15 years are European, resulting in disparity in genetic research. I will discuss the community effort on improving diversity in genetic studies in the last 10 years. I will present trans-ancestry polygenic risk scores (PRS) using millions of common genetic variants across the genome by leveraging large GWAS sample sizes of European and smaller sample sizes of under-represented populations for predicting disease risk using transfer learning and genetic association summary statistics. The performance of deep learning methods for PRS will also be discussed. Second, scalability in cloud platforms is critical for large scale affordable analysis for multi-ancestry biobanks and whole genome studies. I will discuss improving scalability in cloud-computing using interpretable sparsity via FastSparseGRM.To build an interpretable and powerful end-to-end ecosystem of rare variant analysis of large scale whole genome sequencing studies and biobanks, I will first introduce FAVOR, a multi-faceted variant functional annotation database and portal of all possible 9 billions of variants across the whole genome. I will discuss FAVOR-GPT, a LLM interface of the FAVOR functional annotation database to improve user experience for navigating FAVOR and performing variant functional annotation query and variant functional summary statistics calculations. I will also discuss FAVORannotator which can be used to functionally annotate any whole genome sequencing studies. I will also discuss STAAR and STAAR and STAARpipeline, the WGS rare variant analysis pipeline that boosts the power of WGS rare variant association analysis by dynamically incorporating multi-faceted variant functional annotations. Extension of incorporating single-cell data in WGS analysis will also be discussed. I will also discuss ensemble methods that improve the power of rare variant association tests.Cloud-deployment of these resources and tools in several ecosystems will be presented, such as RAP for the UK biobank, AnVIL for the NHGRI Genome Sequencing Program and All of Us, and BioData Catalyst for the NHLBI Trans-omics Precision Medine Program (TOPMed). This talk aims to ignite proactive and thought-provoking discussions, foster collaboration, and cultivate open-minded approaches to advance scientific discovery.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3–4},
numpages = {2},
keywords = {ai, annotation, biobanks, electronic health records, ensemble methods, gpt, integrative analysis, interpretability, machine learning, scalability, sparsity, statistics, summary statistics, whole genome sequencing studies},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3613904.3642336,
author = {Cuadra, Andrea and Wang, Maria and Stein, Lynn Andrea and Jung, Malte F. and Dell, Nicola and Estrin, Deborah and Landay, James A.},
title = {The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642336},
doi = {10.1145/3613904.3642336},
abstract = {From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {18},
keywords = {AI, Affective Computing, Automation, Autonomous Agents, Chatbots, Conversational Agents, Conversational User Interfaces, Disability, Emotion, Empathy, Ethics, Gender, Health, Human-AI Interaction, Human-Computer Interaction, Identity, LLMs, Marginalization, Mental Health, Natural Language Processing, Personalization, Power and Privilege, Religion, Social Robots, Technological Harm, Ubiquitous Computing, User Experience Design, Values in Design, Voice Assistants, Wellbeing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3643991.3644903,
author = {Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole and Quaranta, Luigi},
title = {Leveraging GPT-like LLMs to Automate Issue Labeling},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644903},
doi = {10.1145/3643991.3644903},
abstract = {Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {469–480},
numpages = {12},
keywords = {LLM, issue labeling, GPT, software maintenance and evolution, labeling unstructured data},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3664647.3681695,
author = {Huang, Rongjie and Wang, Yongqi and Hu, Ruofan and Xu, Xiaoshan and Hong, Zhiqing and Yang, Dongchao and Cheng, Xize and Wang, Zehan and Jiang, Ziyue and Ye, Zhenhui and Liu, Luping and Zheng, Siqi and Zhao, Zhou},
title = {VoiceTuner: Self-Supervised Pre-training and Efficient Fine-tuning For Voice Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681695},
doi = {10.1145/3664647.3681695},
abstract = {Voice large language models (LLMs) cast voice synthesis as a language modeling task in a discrete space, and have demonstrated significant progress to date. Despite the recent success, the current development of voice LLMs in low-resource applications is hampered by data scarcity and high computational cost. In this work, we propose VoiceTuner, with a self-supervised pre-training and efficient fine-tuning approach for low-resource voice generation. Specifically, 1) to mitigate data scarcity, we leverage large-scale unlabeled dataset and pre-train VoiceTuner-SSL without pre-defined applications, which can be fine-tuned in downstream tasks; 2) to further reduce the high training cost in complete fine-tuning, we introduce a multiscale transformer adapter to effectively update only around 1% parameters as a plug-and-play module. Experimental results demonstrate that VoiceTuner-SSL presents strong acoustic continuations, and VoiceTuner achieves state-of-the-art results in rich-resource TTS evaluation compared with competitive baseline models. Low-resource (1h, 10h, 30h) downstream applications including zero-shot TTS, instruction TTS, and singing voice synthesis present VoiceTuner's superior audio quality and style similarity with reduced data requirement and computational cost. Audio samples are available at https://VoiceTuner.github.io},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10630–10639},
numpages = {10},
keywords = {efficient fine-tuning, large language models, speech synthesis},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3650212.3680389,
author = {Eom, Jueon and Jeong, Seyeon and Kwon, Taekyoung},
title = {Fuzzing JavaScript Interpreters with Coverage-Guided Reinforcement Learning for LLM-Based Mutation},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680389},
doi = {10.1145/3650212.3680389},
abstract = {JavaScript interpreters, crucial for modern web browsers, require an effective fuzzing method to identify security-related bugs. However, the strict grammatical requirements for input present significant challenges. Recent efforts to integrate language models for context- aware mutation in fuzzing are promising but lack the necessary coverage guidance to be fully effective. This paper presents a novel technique called CovRL (Coverage-guided Reinforcement Learning) that combines Large Language Models (LLMs) with Reinforcement Learning (RL) from coverage feedback. Our fuzzer, CovRL-Fuzz, integrates coverage feedback directly into the LLM by leveraging the Term Frequency-Inverse Document Frequency (TF-IDF) method to construct a weighted coverage map. This map is key in calculating the fuzzing reward, which is then applied to the LLM-based mutator through reinforcement learning. CovRL-Fuzz, through this approach, enables the generation of test cases that are more likely to discover new coverage areas, thus improving bug detection while minimizing syntax and semantic errors, all without needing extra post-processing. Our evaluation results show that CovRL-Fuzz outperforms the state-of-the-art fuzzers in enhancing code coverage and identifying bugs in JavaScript interpreters: CovRL-Fuzz identified 58 real-world security-related bugs in the latest JavaScript interpreters, including 50 previously unknown bugs and 15 CVEs.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1656–1668},
numpages = {13},
keywords = {coverage, fuzzing, large language model, reinforcement learning},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3630106.3658993,
author = {Mirowski, Piotr and Love, Juliette and Mathewson, Kory and Mohamed, Shakir},
title = {A Robot Walks into a Bar: Can Language Models Serve as Creativity SupportTools for Comedy? An Evaluation of LLMs’ Humour Alignment with Comedians},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658993},
doi = {10.1145/3630106.3658993},
abstract = {We interviewed twenty professional comedians who perform live shows in front of audiences and who use artificial intelligence in their artistic process as part of 3-hour workshops on “AI x Comedy” conducted at the Edinburgh Festival Fringe in August 2023 and online. The workshop consisted of a comedy writing session with large language models (LLMs), a human-computer interaction questionnaire to assess the Creativity Support Index of AI as a writing tool, and a focus group interrogating the comedians’ motivations for and processes of using AI, as well as their ethical concerns about bias, censorship and copyright. Participants noted that existing moderation strategies used in safety filtering and instruction-tuned LLMs reinforced hegemonic viewpoints by erasing minority groups and their perspectives, and qualified this as a form of censorship. At the same time, most participants felt the LLMs did not succeed as a creativity support tool, by producing bland and biased comedy tropes, akin to “cruise ship comedy material from the 1950s, but a bit less racist”. Our work extends scholarship about the subtle difference between, one the one hand, harmful speech, and on the other hand, “offensive” language as a practice of resistance, satire and “punching up”. We also interrogate the global value alignment behind such language models, and discuss the importance of community-based value alignment and data ownership to build AI tools that better suit artists’ needs. Warning: this study may contain offensive language and discusses self-harm.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1622–1636},
numpages = {15},
keywords = {Censorship, Comedy, Creativity, Large Language Models, Offensive speech, Value Alignment},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3672198.3673798,
author = {Guo, Kuo and Chen, Jia and Xu, Qi and Song, Fei and Huang, Xu and Liu, Shang and Qian, Dongsheng and Zhu, Jun and Zhang, Ruyun and Long, Keping},
title = {CollaSFC: An Intelligent Collaborative Approach for In-network SFC Failure Detection in Data Center for AI Computing},
year = {2024},
isbn = {9798400707131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672198.3673798},
doi = {10.1145/3672198.3673798},
abstract = {The successful application cases of Large Language Models (LLMs) and Machine Learning (ML) are driving traditional data centers to transform into intelligent computing data centers characterized by low latency, high bandwidth, high reliability, and zero packet loss. The demand for immense computing and ultra-low latency suggests that in-network computing (INC) may be a viable solution, such as In-network aggregation (INA). INA involves a hierarchical structure of switches and servers to form different Service Function Chains (SFCs) including switches, servers, physical links, and virtual links for accomplishing model training. However, the aggregation of heavy traffic in CTCs tends to a sudden and drastic increase in a specific node, greatly increasing the likelihood of node failure. To detect SFC failure in real time, we propose an in-network SFC failure detection approach based on INC. We introduce digital twins (DT) and propose a collaborative AI framework based on the data plane and control plane to avoid model overfitting. In addition, to reduce the computing consumption, we propose the concept of "multiple SFC chains multiple models" to customize each SFC failure detection model and validate the mechanism on a BMv2-based prototype, which implements a high-accuracy failure detection with minor performance degradation.},
booktitle = {Proceedings of the 2024 SIGCOMM Workshop on Networks for AI Computing},
pages = {41–47},
numpages = {7},
keywords = {Failure Detection, Intelligent Computing Data Center, Service Function Chains},
location = {Sydney, NSW, Australia},
series = {NAIC '24}
}

@article{10.14778/3685800.3685913,
author = {Amer-Yahia, Sihem},
title = {Intelligent Agents for Data Exploration},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685913},
doi = {10.14778/3685800.3685913},
abstract = {Data Exploration is an incremental process that helps users express what they want through a conversation with the data. Reinforcement Learning (RL) is one of the most notable approaches to automate data exploration and several solutions have been proposed. We first summarize some RL solutions that were built for different applications. In this context, various data exploration operators are leveraged including traditional roll-up and drill-down operations and text-based operations. An RL agent is trained to generate the best policy according to a hand-crafted reward function.The benefit of training RL policies for specific data exploration tasks has been demonstrated more than once for exploring finding a needle in a haystack, for serendipitous galaxy exploration, for helping a customer land on a satisfactory product, for helping a conference chair build a program committee in a stepwise fashion, for summarizing large datasets, etc.With the advent of Large Language Models and their ability to reason sequentially, it has become legitimate to ask the question: would LLMs and AI planning outperform an RL policy in data exploration? More specifically, would LLMs help circumvent retraining for new tasks and striking a balance between specificity and generality? This led us to designing LLM-powered approaches that introduce a new way of thinking about data exploration.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4521–4530},
numpages = {10}
}

@inproceedings{10.1145/3658644.3670334,
author = {Sun, Haochen and Li, Jason and Zhang, Hongyang},
title = {zkLLM: Zero Knowledge Proofs for Large Language Models},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670334},
doi = {10.1145/3658644.3670334},
abstract = {The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations.In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zero-knowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy.Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4405–4419},
numpages = {15},
keywords = {large language models, zero-knowledge proofs},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3664647.3680685,
author = {Gu, Zhaopeng and Zhu, Bingke and Zhu, Guibo and Chen, Yingying and Li, Hao and Tang, Ming and Wang, Jinqiao},
title = {FiLo: Zero-Shot Anomaly Detection by Fine-Grained Description and High-Quality Localization},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680685},
doi = {10.1145/3664647.3680685},
abstract = {Zero-shot anomaly detection (ZSAD) methods detect anomalies without prior access to known normal or abnormal samples within target categories. Existing methods typically rely on pretrained multimodal models, computing similarities between manually crafted textual features representing ''normal'' or ''abnormal'' semantics and image patch features to detect anomalies. However, the generic descriptions of ''abnormal'' often fail to precisely match diverse types of anomalies across different object categories. Additionally, computing feature similarities for single patches struggles to pinpoint specific locations of anomalies with various sizes and scales. To address these issues, we propose a novel ZSAD method called FiLo, comprising two components: adaptively learned Fine-Grained Description (FG-Des) and position-enhanced High-Quality Localization (HQ-Loc). FG-Des introduces fine-grained anomaly descriptions for each category using Large Language Models (LLMs) and employs adaptively learned textual templates to enhance the accuracy and interpretability of anomaly detection. HQ-Loc, utilizing Grounding DINO for preliminary localization, position-enhanced text prompts, and Multi-scale Multi-shape Cross-modal Interaction (MMCI) module, facilitates more accurate localization of anomalies of different sizes and shapes. Experimental results on datasets like MVTec and VisA demonstrate that FiLo significantly improves the performance of ZSAD in both detection and localization, achieving state-of-the-art performance with an image-level AUC of 83.9% and a pixel-level AUC of 95.9% on the VisA dataset. Code is available at https://github.com/CASIA-IVA-Lab/FiLo.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2041–2049},
numpages = {9},
keywords = {anomaly detection, vision-language model, zero-shot learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3658644.3690295,
author = {Chen, Guanzhong and Qin, Zhenghan and Yang, Mingxin and Zhou, Yajie and Fan, Tao and Du, Tianyu and Xu, Zenglin},
title = {Unveiling the Vulnerability of Private Fine-Tuning in Split-Based Frameworks for Large Language Models: A Bidirectionally Enhanced Attack},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690295},
doi = {10.1145/3658644.3690295},
abstract = {Recent advancements in pre-trained large language models (LLMs) have significantly influenced various domains. Adapting these models for specific tasks often involves fine-tuning (FT) with private, domain-specific data. However, privacy concerns keep this data undisclosed, and the computational demands for deploying LLMs pose challenges for resource-limited data holders. This has sparked interest in split learning (SL), a Model-as-a-Service (MaaS) paradigm that divides LLMs into smaller segments for distributed training and deployment, transmitting only intermediate activations instead of raw data. SL has garnered substantial interest in both industry and academia as it aims to balance user data privacy, model ownership, and resource challenges in the private fine-tuning of LLMs. Despite its privacy claims, this paper reveals significant vulnerabilities arising from the combination of SL and LLM-FT: the Not-too-far property of fine-tuning and the auto-regressive nature of LLMs. Exploiting these vulnerabilities, we propose Bidirectional Semi-white-box Reconstruction (BiSR), the first data reconstruction attack (DRA) designed to target both the forward and backward propagation processes of SL. BiSR utilizes pre-trained weights as prior knowledge, combining a learning-based attack with a bidirectional optimization-based approach for highly effective data reconstruction. Additionally, it incorporates a Noise-adaptive Mixture of Experts (NaMoE) model to enhance reconstruction performance under perturbation. We conducted systematic experiments on various mainstream LLMs and different setups, empirically demonstrating BiSR's state-of-the-art performance. Furthermore, we thoroughly examined three representative defense mechanisms, showcasing our method's capability to reconstruct private data even in the presence of these defenses.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2904–2918},
numpages = {15},
keywords = {data reconstruction attack, large language models, split learning},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3657242.3658587,
author = {Contreras Aguilar, David and Medina, Fernando and Oyanedel, Mauricio and Salam\'{o}, Maria and S\`{a}nchez-Marr\`{e}, Miquel},
title = {SAMANTHA: A chatbot to assist users in training tasks to prevent workplace hazards},
year = {2024},
isbn = {9798400717871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657242.3658587},
doi = {10.1145/3657242.3658587},
abstract = {In businesses, preventing workplace hazards becomes crucial. In order to limit negative effects on people, society, and the economy, it is crucial for both the organization and its employees to reduce accidents and occupational illnesses. Staff training programs are essential to a company’s preventative system. In this paper, we introduce SAMANTHA, an AI chatbot that helps reduce occupational dangers in the mining industry. Using pre-trained Large Language Models (LLMs), SAMANTHA assists users with training as well as daily work tasks, aiming to help employees in any circumstance to enhance well-being at work. Despite SAMANTHA’s concentration on the mining industry, its framework is sufficiently general to be readily applied to other industries. When SAMANTHA’s learning model is compared to the pre-trained ChatGPT3.5 model, it is clear that the suggested chatbot can accurately respond to users, and the evaluation conducted with real users indicates that they are satisfied with it.},
booktitle = {Proceedings of the XXIV International Conference on Human Computer Interaction},
articleno = {11},
numpages = {8},
keywords = {AI-powered Chatbot, ChatGPT, Large Language Models, Prevention of occupational risks},
location = {A Coru\~{n}a, Spain},
series = {Interacci\'{o}n '24}
}

@inproceedings{10.1145/3660043.3660172,
author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
title = {Research on the Application of AI in Personalized Education},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660172},
doi = {10.1145/3660043.3660172},
abstract = {Smart education uses advanced information technology, combined with educational theories and teaching methods, to achieve automatic, intelligent, and efficient teaching process. Personalized education represents the core content and goal of smart education because traditional classroom or remote teaching can't accurately grasp every student's individual knowledge and understanding of the content being taught. The development of artificial intelligence technology has provided technical support for smart education, particularly for personalized education. Natural language processing models such as chatGPT and knowledge graph technology have made personalized education increasingly practicable. This article describes the technological framework of smart education, its potential applications, and emphasizes the use of AI technology in personalized education. The article covers topic areas, including learning situation analysis, implementing personalized instruction, personalized teaching management.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {723–727},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3700297.3700350,
author = {Lin, Daping and Pu, Xianwei},
title = {Effects of Prompts and Time on the Automated Scoring of English Argumentative Essays by ChatGPT 4},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700350},
doi = {10.1145/3700297.3700350},
abstract = {As deep learning technology in computer science develops, generative artificial intelligence (GenAI) has shown great potential in automated essay scoring (AES). Prompts and time are important factors which may influence the performance of GenAI. The study selected 52 English argumentative essays, designed five different prompts, chooses two different time points, and then utilized ChatGPT 4 to explore the effects of prompts and time on AES by GenAI. Besides, possible reasons for large difference between human and GenAI score were discussed.For different prompts, results show that the one-shot prompt performs better in AES compared with the other four prompts. It provides background information and a scoring example to ChatGPT. The scores generated by it do not significantly differ from the human scores. They significantly and positively correlate with human scores (ρ = 0.424). The exact-plus-adjacent agreement (EPAA) rate for one-shot prompt scores reaches 69.23%. For scores generated at different points in time, results reveal that although there is still a significant difference between scores generated after one week and human scores, the ChatGPT-Human EPAA rate becomes higher and the absolute value of mean score difference is smaller.Based on the analysis of selected essays, the major reason for large GenAI-Human score difference is that ChatGPT evaluates essays from limited perspectives to give its score, while human raters can comprehensively assess the quality of an essay. What's more, ChatGPT cannot keep the same scoring criteria during the rating process.The study aims to help people understand how to interact with GenAI more efficiently and take advantage of GenAI to meet the practical needs.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {302–312},
numpages = {11},
keywords = {English argumentative essays, automated essay scoring, generative artificial intelligence, prompts, time},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3626772.3657655,
author = {Wang, Ben},
title = {GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI collaboration},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657655},
doi = {10.1145/3626772.3657655},
abstract = {The advent of ChatGPT and similar large language models (LLMs) has revolutionized the human-AI interaction and information-seeking process. Leveraging LLMs as an alternative to search engines, users can now access summarized information tailored to their queries, significantly reducing the cognitive load in navigating vast information resources. This shift underscores the potential of LLMs in redefining information access paradigms [1]. Drawing on the foundation of task-focused information retrieval and LLMs' task planning ability, this research extends the scope of LLM capabilities beyond short-term task automation (i.e., smaller-scale and routine tasks that LLM agents can automate with less human intervention) to support users in navigating long-term and significant life tasks. The long-term tasks encompass broader personal life goals or development in aspects like health, finances, education, and professional development, which cannot be fully completed by LLM agents but require significant human involvement.This study introduces the GOLF framework (Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability to assist in significant life decisions through goal orientation and long-term planning. Figure 1 presents the GOLF framework, including a task taxonomy and the process for task management. The GOLF framework envisions the completion of complex tasks as a strategic journey toward a final goal, incorporating a sequence of activities, tasks, and subtasks, adopting the task taxonomy in Figure 1a [2]. Figure 1b illustrates the task process within the GOLF framework, which operates on AutoGen [3], a sophisticated multi-agent system, and involves multiple LLM agents to facilitate user support and workload distribution for achieving long-term goals. The multi-agent system processes the task following steps: Initial Planning, Step Planning, Task Assignment, Multi-Agent Coordination, User Engagement, and Evaluation and Iteration.The methodology encompasses a comprehensive simulation study to test the framework's efficacy, followed by model and human evaluations to develop a dataset benchmark for long-term life tasks, and experiments across different models and settings. By shifting the focus from short-term tasks to the broader spectrum of long-term life goals, this research underscores the transformative potential of LLMs in enhancing human decision-making processes and task management, marking a significant step forward in the evolution of human-AI collaboration.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3072},
numpages = {1},
keywords = {human-ai collaboration, large language model, task},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3660811,
author = {Mai, Yubo and Gao, Zhipeng and Hu, Xing and Bao, Lingfeng and Liu, Yu and Sun, JianLing},
title = {Are Human Rules Necessary? Generating Reusable APIs with CoT Reasoning and In-Context Learning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660811},
doi = {10.1145/3660811},
abstract = {Inspired by the great potential of Large Language Models (LLMs) for solving complex coding tasks, in this paper, we propose a novel approach, named Code2API, to automatically perform APIzation for Stack Overflow code snippets. Code2API does not require additional model training or any manual crafting rules and can be easily deployed on personal computers without relying on other external tools. Specifically, Code2API guides the LLMs through well-designed prompts to generate well-formed APIs for given code snippets. To elicit knowledge and logical reasoning from LLMs, we used chain-of-thought (CoT) reasoning and few-shot in-context learning, which can help the LLMs fully understand the APIzation task and solve it step by step in a manner similar to a developer. Our evaluations show that Code2API achieves a remarkable accuracy in identifying method parameters (65%) and return statements (66%) equivalent to human-generated ones, surpassing the current state-of-the-art approach, APIzator, by 15.0% and 16.5% respectively. Moreover, compared with APIzator, our user study demonstrates that Code2API exhibits superior performance in generating meaningful method names, even surpassing the human-level performance, and developers are more willing to use APIs generated by our approach, highlighting the applicability of our tool in practice. Finally, we successfully extend our framework to the Python dataset, achieving a comparable performance with Java, which verifies the generalizability of our tool.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {104},
numpages = {23},
keywords = {APIs, Chain-of-thought, In-context learning, Large language models, Stack Overflow}
}

@inproceedings{10.1145/3597503.3608134,
author = {Geng, Mingyang and Wang, Shangwen and Dong, Dezun and Wang, Haotian and Li, Ge and Jin, Zhi and Mao, Xiaoguang and Liao, Xiangke},
title = {Large Language Models are Few-Shot Summarizers: Multi-Intent Comment Generation via In-Context Learning},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3608134},
doi = {10.1145/3597503.3608134},
abstract = {Code comment generation aims at generating natural language descriptions for a code snippet to facilitate developers' program comprehension activities. Despite being studied for a long time, a bottleneck for existing approaches is that given a code snippet, they can only generate one comment while developers usually need to know information from diverse perspectives such as what is the functionality of this code snippet and how to use it. To tackle this limitation, this study empirically investigates the feasibility of utilizing large language models (LLMs) to generate comments that can fulfill developers' diverse intents. Our intuition is based on the facts that (1) the code and its pairwise comment are used during the pre-training process of LLMs to build the semantic connection between the natural language and programming language, and (2) comments in the real-world projects, which are collected for the pre-training, usually contain different developers' intents. We thus postulate that the LLMs can already understand the code from different perspectives after the pre-training. Indeed, experiments on two large-scale datasets demonstrate the rationale of our insights: by adopting the in-context learning paradigm and giving adequate prompts to the LLM (e.g., providing it with ten or more examples), the LLM can significantly outperform a state-of-the-art supervised learning approach on generating comments with multiple intents. Results also show that customized strategies for constructing the prompts and post-processing strategies for reranking the results can both boost the LLM's performances, which shed light on future research directions for using LLMs to achieve comment generation.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {39},
numpages = {13},
keywords = {code summarization, large language model, in-context learning},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3674805.3686671,
author = {Liu, Yueyue and Zhang, Hongyu and Li, Zhiqiang and Miao, Yuantian},
title = {Optimizing the Utilization of Large Language Models via Schedule Optimization: An Exploratory Study},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686671},
doi = {10.1145/3674805.3686671},
abstract = {Background: Large Language Models (LLMs) have gained significant attention in machine-learning-as-a-service (MLaaS) offerings. In-context learning (ICL) is a technique that guides LLMs towards accurate query processing by providing additional information. However, longer prompts lead to higher costs of LLM service, creating a performance-cost trade-off. Aims: We aim to investigate the potential of combining schedule optimization with ICL to optimize LLM utilization. Method: We conduct an exploratory study. First, we consider the performance-cost trade-off in LLM utilization as a multi-objective optimization problem, aiming to select the most suitable prompt template for each LLM job to maximize accuracy (the percentage of correctly processed jobs) and minimize invocation cost. Next, we investigate three methods for prompt performance prediction to address the challenge of evaluating the accuracy objective in the fitness function, as the result can only be determined after submitting the job to the LLM. Finally, we apply widely used search-based techniques and evaluate their effectiveness. Results: The results indicate that the machine learning-based technique is an effective approach for prompt performance prediction and fitness function calculation. Schedule optimization can achieve higher accuracy or lower cost by selecting a suitable prompt template for each job, compared to simply submitting all jobs using a single prompt template, e.g., saving costs from 21.33% to 86.92% in our experiments on LLM-based log parsing. However, the performance of the evaluated search-based techniques varies across different instances and metrics, with no single technique consistently outperforming the others. Conclusions: This study demonstrates the potential of combining schedule optimization with ICL to improve the utilization of LLMs. However, there is still ample room for improving the searched-based techniques and prompt performance prediction techniques for more cost-effective LLM utilization.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {84–95},
numpages = {12},
keywords = {Large Language Models, Multi-objective Optimization, Schedule Optimization, Search-based Techniques},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.1145/3660778,
author = {Yang, Zhen and Liu, Fang and Yu, Zhongxing and Keung, Jacky Wai and Li, Jia and Liu, Shuo and Hong, Yifan and Ma, Xiaoxue and Jin, Zhi and Li, Ge},
title = {Exploring and Unleashing the Power of Large Language Models in Automated Code Translation},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660778},
doi = {10.1145/3660778},
abstract = {Code translation tools, namely transpilers, are developed for automatic source-to-source translation. Latest learning-based transpilers have shown impressive enhancement against rule-based counterparts in both translation accuracy and readability, owing to their task-specific pre-training on extensive monolingual corpora. Nevertheless, their current performance still remains unsatisfactory for practical deployment, and the associated training resources are also prohibitively expensive. Large Language Models (LLMs), pre-trained on huge amounts of human-written code/text, have shown remarkable performance in many code intelligence tasks due to their powerful generality, even without task-specific re-training/fine-tuning. Thus, LLMs can potentially circumvent the above limitations, but they have not been exhaustively explored yet. This paper investigates diverse LLMs and learning-based transpilers for automated code translation tasks, finding that: although certain LLMs have outperformed current transpilers, they still have some accuracy issues, where most of the failures are induced by a lack of comprehension of source programs (38.51%), missing clear instructions on I/O types in translation (14.94%), and ignoring discrepancies between source and target programs (41.38%).  Enlightened by the above findings, we further propose UniTrans, a Unified code Translation framework, applicable to various LLMs, for unleashing their power in this field. Specifically, UniTrans first crafts a series of test cases for target programs with the assistance of source programs. Next, it harnesses the above auto-generated test cases to augment the code translation and then evaluate their correctness via execution. Afterward, UniTrans further (iteratively) repairs incorrectly translated programs prompted by test case execution results. Extensive experiments are conducted on six settings of translation datasets between Python, Java, and C++. Three recent LLMs of diverse sizes, including GPT-3.5 and LLaMA-13B/7B, are tested with UniTrans, and all achieve substantial improvements in terms of computational accuracy and exact match accuracy among almost all translation settings, showing the universal effectiveness of UniTrans in practice.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {71},
numpages = {24},
keywords = {Automated Code Translation, Large Language Models, Transformer}
}

@inproceedings{10.1145/3691620.3695014,
author = {Wu, Guangyuan and Cao, Weining and Yao, Yuan and Wei, Hengfeng and Chen, Taolue and Ma, Xiaoxing},
title = {LLM Meets Bounded Model Checking: Neuro-symbolic Loop Invariant Inference},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695014},
doi = {10.1145/3691620.3695014},
abstract = {Loop invariant inference, a key component in program verification, is a challenging task due to the inherent undecidability and complex loop behaviors in practice. Recently, machine learning based techniques have demonstrated impressive performance in generating loop invariants automatically. However, these methods highly rely on the labeled training data, and are intrinsically random and uncertain, leading to unstable performance. In this paper, we investigate a synergy of large language models (LLMs) and bounded model checking (BMC) to address these issues. The key observation is that, although LLMs may not be able to return the correct loop invariant in one response, they usually can provide all individual predicates of the correct loop invariant in multiple responses. To this end, we propose a "query-filter-reassemble" strategy, namely, we first leverage the language generation power of LLMs to produce a set of candidate invariants, where training data is not needed. Then, we employ BMC to identify valid predicates from these candidate invariants, which are assembled to produce new candidate invariants and checked by off-the-shelf SMT solvers. The feedback is incorporated into the prompt for the next round of LLM querying. We expand the existing benchmark of 133 programs to 316 programs, providing a more comprehensive testing ground. Experimental results demonstrate that our approach significantly outperforms the state-of-the-art techniques, successfully generating 309 loop invariants out of 316 cases, whereas the existing baseline methods are only able to tackle 219 programs at best. The code is publicly available at https://github.com/SoftWiser-group/LaM4Inv.git.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {406–417},
numpages = {12},
keywords = {loop invariant, program verification, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.14778/3685800.3685868,
author = {Wang, Mengzhao and Wu, Haotian and Ke, Xiangyu and Gao, Yunjun and Xu, Xiaoliang and Chen, Lu},
title = {An Interactive Multi-Modal Query Answering System with Retrieval-Augmented Large Language Models},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685868},
doi = {10.14778/3685800.3685868},
abstract = {Retrieval-augmented Large Language Models (LLMs) have reshaped traditional query-answering systems, offering unparalleled user experiences. However, existing retrieval techniques often struggle to handle multi-modal query contexts. In this paper, we present an interactive Multi-modal Query Answering (MQA) system, empowered by our newly developed multi-modal retrieval framework and navigation graph index, integrated with cutting-edge LLMs. It comprises five core components: Data Preprocessing, Vector Representation, Index Construction, Query Execution, and Answer Generation, all orchestrated by a dedicated coordinator to ensure smooth data flow from input to answer generation. One notable aspect of MQA is its utilization of contrastive learning to assess the significance of different modalities, facilitating precise measurement of multimodal information similarity. Furthermore, the system achieves efficient retrieval through our advanced navigation graph index, refined using computational pruning techniques. Another highlight of our system is its pluggable processing framework, allowing seamless integration of embedding models, graph indexes, and LLMs. This flexibility provides users diverse options for gaining insights from their multi-modal knowledge base. A preliminary video introduction of MQA is available at https://youtu.be/xvUuo2ZIqWk.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4333–4336},
numpages = {4}
}

@inproceedings{10.1145/3613904.3642080,
author = {Fontana De Vargas, Mauricio and Yu, Christina and Shane, Howard C. and Moffatt, Karyn},
title = {Co-Designing QuickPic: Automated Topic-Specific Communication Boards from Photographs for AAC-Based Language Instruction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642080},
doi = {10.1145/3613904.3642080},
abstract = {Traditional topic-specific communication boards for Augmentative and Alternative Communication (AAC) require manual programming of relevant symbolic vocabulary, which is time-consuming and often impractical even for experienced Speech-Language Pathologists (SLPs). While recent research has demonstrated the potential to automatically generate these boards from photographs using artificial intelligence, there has been no exploration on how to design such tools to support the specific needs of AAC-based language instruction. This paper introduces QuickPic, a mobile AAC application co-designed with SLPs and special educators, aimed at enhancing language learning for non-speaking individuals, such as autistic children. Through a 17-month design process, we uncover the unique design features required to provide timely language support in therapy and special education contexts. We present emerging evidence on the overall satisfaction of SLPs using QuickPic, and on the advantages of large language model-based generation compared to the existing technique for automated vocabulary from photographs for AAC.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {910},
numpages = {16},
keywords = {Augmentative and Alternative Communication, LLM, assistive technology, autism, just-in-time},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3709138,
author = {Yuan, Wei and Yang, Chaoqun and Ye, Guanhua and Chen, Tong and Hung, Nguyen Quoc Viet and Yin, Hongzhi},
title = {FELLAS: Enhancing Federated Sequential Recommendation with LLM as External Services},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3709138},
doi = {10.1145/3709138},
abstract = {Sequential recommendation has been widely studied in the recommendation domain since it can capture users’ temporal preferences and provide more accurate and timely recommendations. To address user privacy concerns, the combination of federated learning and sequential recommender systems (FedSeqRec) has gained growing attention. Unfortunately, the performance of FedSeqRec is still unsatisfactory because the models used in FedSeqRec have to be lightweight to accommodate communication bandwidth and clients’ on-device computational resource constraints. Recently, large language models (LLMs) have exhibited strong transferable and generalized language understanding abilities and therefore, in the NLP area, many downstream tasks now utilize LLMs as a service to achieve superior performance without constructing complex models. Inspired by this successful practice, we propose a generic FedSeqRec framework, FELLAS, which aims to enhance FedSeqRec by utilizing LLMs as an external service.Specifically, FELLAS employs an LLM server to provide both item-level and sequence-level representation assistance. The item-level representation service is queried by the central server to enrich the original ID-based item embedding with textual information, while the sequence-level representation service is accessed by each client. However, invoking the sequence-level representation service requires clients to send sequences to the external LLM server. To safeguard privacy, we implement  (d_{mathcal{X}}) -privacy satisfied sequence perturbation, which protects clients’ sensitive data with guarantees. Additionally, a contrastive learning-based method is designed to transfer knowledge from the noisy sequence representation to clients’ sequential recommendation models. Furthermore, to empirically validate the privacy protection capability of FELLAS, we propose two interacted item inference attacks, considering the threats posed by the LLM server and the central server acting as curious-but-honest adversaries in cooperation. Extensive experiments conducted on three datasets with two widely used sequential recommendation models demonstrate the effectiveness and privacy-preserving capability of FELLAS.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = dec,
keywords = {Recommender System, Federated Learning, Privacy Protection}
}

@inproceedings{10.1145/3643796.3648451,
author = {Zharov, Yaroslav and Khudyakov, Yury and Fedotova, Evgeniia and Grigorenko, Evgeny and Bogomolov, Egor},
title = {Tool-augmented LLMs as a Universal Interface for IDEs},
year = {2024},
isbn = {9798400705809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643796.3648451},
doi = {10.1145/3643796.3648451},
abstract = {Modern-day Integrated Development Environments (IDEs) have come a long way from the early text editing utilities to the complex programs encompassing thousands of functions to help developers. However, with the increasing number of efficiency-enhancing tools incorporated, IDEs gradually became sophisticated software with a steep learning curve. The rise of the Large Language Models (LLMs) capable of both natural language dialogue and code generation leads to a discourse on the obsolescence of the concept of IDE. In this work, we offer a view on the place of the LLMs in the IDEs as the universal interface wrapping the IDE facilities. We envision a model that is able to perform complex actions involving multiple IDE features upon user command, stripping the user experience of the tedious work involved in searching through options and actions. For the practical part of the work, we engage with the works exploring the ability of LLMs to call for external tools to expedite a given task execution. We showcase a proof-of-concept of such a tool.},
booktitle = {Proceedings of the 1st ACM/IEEE Workshop on Integrated Development Environments},
pages = {40–42},
numpages = {3},
keywords = {IDE, LLM, ToolFormer},
location = {Lisbon, Portugal},
series = {IDE '24}
}

@inproceedings{10.1145/3625549.3658687,
author = {Hwang, Sunyeol and Lee, Eungyeong and Oh, Hongseok and Yi, Youngmin},
title = {FASOP: Fast yet Accurate Automated Search for Optimal Parallelization of Transformers on Heterogeneous GPU Clusters},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625549.3658687},
doi = {10.1145/3625549.3658687},
abstract = {Transformer-based large language models have recently shown remarkable performance, but their significantly large parameters require efficient training, which is commonly realized by utilizing both data- and model-parallel deep learning on a GPU cluster. To minimize the training time, the optimal degrees of data and model parallelisms and the optimal model partitioning should be searched. When heterogeneous GPU clusters are used to utilize as many GPUs as possible, it becomes more challenging. In this work, we propose a framework named FASOP that automatically and rapidly finds the (near-)optimal degrees of parallelisms and model partitioning of Transformer-based models on heterogeneous GPU clusters, with an accurate estimation of pipelining latency and communications. Moreover, it can search for optimal cluster configurations that minimize the training time while satisfying the cost of GPU clusters. The proposed model partitioning algorithm in FASOP is three orders of magnitude faster than Dynamic Programming in the state-of-the-art for GPT-2 1.5B on a mixed set of 32 GPUs with A100 and A10, leading to a few seconds instead of several hours. And, FASOP shows only 8.7% mean absolute error in training time estimation for GPT-2 1.5B. With a fast yet accurate search, FASOP achieved up to 1.37\texttimes{} speedup compared to Megatron-LM.},
booktitle = {Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {253–266},
numpages = {14},
keywords = {heterogeneous cluster, distributed deep learning, parallelization strategy, large language model},
location = {Pisa, Italy},
series = {HPDC '24}
}

@inproceedings{10.1145/3613904.3642777,
author = {Taeb, Maryam and Swearngin, Amanda and Schoop, Eldon and Cheng, Ruijia and Jiang, Yue and Nichols, Jeffrey},
title = {AXNav: Replaying Accessibility Tests from Natural Language},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642777},
doi = {10.1145/3613904.3642777},
abstract = {Developers and quality assurance testers often rely on manual testing to test accessibility features throughout the product lifecycle. Unfortunately, manual testing can be tedious, often has an overwhelming scope, and can be difficult to schedule amongst other development milestones. Recently, Large Language Models (LLMs) have been used for a variety of tasks including automation of UIs. However, to our knowledge, no one has yet explored the use of LLMs in controlling assistive technologies for the purposes of supporting accessibility testing. In this paper, we explore the requirements of a natural language based accessibility testing workflow, starting with a formative study. From this we build a system that takes a manual accessibility test instruction in natural language (e.g., “Search for a show in VoiceOver”) as input and uses an LLM combined with pixel-based UI Understanding models to execute the test and produce a chaptered, navigable video. In each video, to help QA testers, we apply heuristics to detect and flag accessibility issues (e.g., Text size not increasing with Large Text enabled, VoiceOver navigation loops). We evaluate this system through a 10-participant user study with accessibility QA professionals who indicated that the tool would be very useful in their current work and performed tests similarly to how they would manually test the features. The study also reveals insights for future work on using LLMs for accessibility testing.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {962},
numpages = {16},
keywords = {Accessibility, Large language models, UI testing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3689217.3690614,
author = {Cong, Tianshuo and Ran, Delong and Liu, Zesen and He, Xinlei and Liu, Jinyuan and Gong, Yichen and Li, Qi and Wang, Anyu and Wang, Xiaoyun},
title = {Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging},
year = {2024},
isbn = {9798400712098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689217.3690614},
doi = {10.1145/3689217.3690614},
abstract = {Model merging is a promising lightweight model empowerment technique that does not rely on expensive computing devices (e.g., GPUs) or require the collection of specific training data. Instead, it involves editing different upstream model parameters to absorb their downstream task capabilities. However, uncertified model merging can infringe upon the Intellectual Property (IP) rights of the original upstream models. In this paper, we conduct the first study on the robustness of IP protection methods under model merging scenarios. Specifically, we investigate two state-of-the-art IP protection techniques: Quantization Watermarking and Instructional Fingerprint, along with various advanced model merging technologies, such as Task Arithmetic, TIES-MERGING, and so on. Experimental results indicate that current Large Language Model (LLM) watermarking techniques cannot survive in the merged models, whereas model fingerprinting techniques can. Our research aims to highlight that model merging should be an indispensable consideration in the robustness assessment of model IP protection techniques, thereby promoting the healthy development of the open-source LLM community.},
booktitle = {Proceedings of the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis},
pages = {69–76},
numpages = {8},
keywords = {intellectual property, large language models, model merging},
location = {Salt Lake City, UT, USA},
series = {LAMPS '24}
}

@inproceedings{10.1145/3627673.3679743,
author = {Wang, Yuhao and Wang, Yichao and Fu, Zichuan and Li, Xiangyang and Wang, Wanyu and Ye, Yuyang and Zhao, Xiangyu and Guo, Huifeng and Tang, Ruiming},
title = {LLM4MSR: An LLM-Enhanced Paradigm for Multi-Scenario Recommendation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679743},
doi = {10.1145/3627673.3679743},
abstract = {As the demand for more personalized recommendation grows and a dramatic boom in commercial scenarios arises, the study on multi-scenario recommendation (MSR) has attracted much attention, which uses the data from all scenarios to simultaneously improve their recommendation performance. However, existing methods tend to integrate insufficient scenario knowledge and neglect learning personalized cross-scenario preferences, thus leading to sub-optimal performance. Meanwhile, though large language model (LLM) has shown great capability of reasoning and capturing semantic information, the high inference latency and high computation cost of tuning hinder its implementation in industrial recommender systems. To fill these gaps, we propose an LLM-enhanced paradigm LLM4MSR in this work. Specifically, we first leverage LLM to uncover multi-level knowledge from the designed scenario- and user-level prompt without fine-tuning the LLM, then adopt hierarchical meta networks to generate multi-level meta layers to explicitly improve the scenario-aware and personalized recommendation capability. Our experiments on KuaiSAR-small, KuaiSAR, and Amazon datasets validate significant advantages of LLM4MSR: (i) the effectiveness and compatibility with different multi-scenario backbone models, (ii) high efficiency and deployability on industrial recommender systems, and (iii) improved interpretability. The implemented code and data is available to ease reproduction.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2472–2481},
numpages = {10},
keywords = {click-through rate prediction, large language model, multi-domain, multi-scenario recommendation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3639476.3639777,
author = {Mishra, Shyamal and Chatterjee, Preetha},
title = {Exploring ChatGPT for Toxicity Detection in GitHub},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639777},
doi = {10.1145/3639476.3639777},
abstract = {Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {6–10},
numpages = {5},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

@inproceedings{10.1145/3626772.3657722,
author = {Liu, Qidong and Wu, Xian and Zhao, Xiangyu and Zhu, Yuanshao and Xu, Derong and Tian, Feng and Zheng, Yefeng},
title = {When MOE Meets LLMs: Parameter Efficient Fine-tuning for Multi-task Medical Applications},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657722},
doi = {10.1145/3626772.3657722},
abstract = {The recent surge in Large Language Models (LLMs) has garnered significant attention across numerous fields. Fine-tuning is often required to fit general LLMs for a specific domain, like the web-based healthcare system. However, two problems arise during fine-tuning LLMs for medical applications. One is the task variety problem, which involves distinct tasks in real-world medical scenarios. The variety often leads to sub-optimal fine-tuning for data imbalance and seesaw problems. Besides, the large amount of parameters in LLMs leads to huge time and computation consumption by fine-tuning. To address these two problems, we propose a novel parameter efficient fine-tuning framework for multi-task medical applications, dubbed as MOELoRA. The designed framework aims to absorb both the benefits of mixture-of-expert (MOE) for multi-task learning and low-rank adaptation (LoRA) for parameter efficient fine-tuning. For unifying MOE and LoRA, we devise multiple experts as the trainable parameters, where each expert consists of a pair of low-rank matrices to retain the small size of trainable parameters. Then, a task-motivated gate function for all MOELoRA layers is proposed, which can control the contributions of each expert and produce distinct parameters for various tasks. We conduct experiments on a multi-task medical dataset, indicating MOELoRA outperforms the existing parameter efficient fine-tuning methods. The code is available online.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1104–1114},
numpages = {11},
keywords = {large language model, medical application, multi-task learning},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3637528.3671865,
author = {Ling, Zhenqing and Chen, Daoyuan and Yao, Liuyi and Li, Yaliang and Shen, Ying},
title = {On the Convergence of Zeroth-Order Federated Tuning for Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671865},
doi = {10.1145/3637528.3671865},
abstract = {The confluence of Federated Learning (FL) and Large Language Models (LLMs) is ushering in a new era in privacy-preserving natural language processing. However, the intensive memory requirements for fine-tuning LLMs pose significant challenges, especially when deploying on clients with limited computational resources. To circumvent this, we explore the novel integration of Memory-efficient Zeroth-Order Optimization within a federated setting, a synergy we term as FedMeZO. Our study is the first to examine the theoretical underpinnings of FedMeZO in the context of LLMs, tackling key questions regarding the influence of large parameter spaces on optimization behavior, the establishment of convergence properties, and the identification of critical parameters for convergence to inform personalized federated strategies. Our extensive empirical evidence supports the theory, showing that FedMeZO not only converges faster than traditional first-order methods such as FedAvg but also significantly reduces GPU memory usage during training to levels comparable to those during inference. Moreover, the proposed personalized FL strategy that is built upon the theoretical insights to customize the client-wise learning rate can effectively accelerate loss reduction. We hope our work can help to bridge theoretical and practical aspects of federated fine-tuning for LLMs, thereby stimulating further advancements and research in this area.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1827–1838},
numpages = {12},
keywords = {convergence analysis, federated learning, large language models, zeroth-order optimization},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3589334.3648145,
author = {Cao, Rui and Lee, Roy Ka-Wei and Jiang, Jing},
title = {Modularized Networks for Few-shot Hateful Meme Detection},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648145},
doi = {10.1145/3589334.3648145},
abstract = {In this paper, we address the challenge of detecting hateful memes in the low-resource setting where only a few labeled examples are available. Our approach leverages the compositionality of Low-rank adaptation (LoRA), a widely used parameter-efficient tuning technique. We commence by fine-tuning large language models (LLMs) with LoRA on selected tasks pertinent to hateful meme detection, thereby generating a suite of LoRA modules. These modules are capable of essential reasoning skills for hateful meme detection. We then use the few available annotated samples to train a module composer, which assigns weights to the LoRA modules based on their relevance. The model's learnable parameters are directly proportional to the number of LoRA modules. This modularized network, underpinned by LLMs and augmented with LoRA modules, exhibits enhanced generalization in the context of hateful meme detection. Our evaluation spans three datasets designed for hateful meme detection in a few-shot learning context. The proposed method demonstrates superior performance to traditional in-context learning, which is also more computationally intensive during inference.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4575–4584},
numpages = {10},
keywords = {few-shot learning, hateful content, multimodal memes, parameter-efficient tuning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3643692.3648261,
author = {Baxter, Hunter and Huang, Yu and Leach, Kevin},
title = {Genetic Improvement for DNN Security},
year = {2024},
isbn = {9798400705731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643692.3648261},
doi = {10.1145/3643692.3648261},
abstract = {Genetic improvement (GI) in Deep Neural Networks (DNNs) has traditionally enhanced neural architecture and trained DNN parameters. Recently, GI has supported large language models by optimizing DNN operator scheduling on accelerator clusters. However, with the rise of adversarial AI, particularly model extraction attacks, there is an unexplored potential for GI in fortifying Machine Learning as a Service (MLaaS) models. We suggest a novel application of GI --- not to improve model performance, but to diversify operator parallelism for the purpose of a moving target defense against model extraction attacks. We discuss an application of GI to create a DNN model defense strategy that uses probabilistic isolation, offering unique benefits not present in current DNN defense systems.},
booktitle = {Proceedings of the 13th ACM/IEEE International Workshop on Genetic Improvement},
pages = {11–12},
numpages = {2},
keywords = {computer security, genetic improvement},
location = {Lisbon, Portugal},
series = {GI '24}
}

@inproceedings{10.1145/3664647.3689178,
author = {Wang, Xin and Zhou, Yuwei and Chen, Hong and Zhu, Wenwu},
title = {Curriculum Learning for Multimedia in the Era of Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3689178},
doi = {10.1145/3664647.3689178},
abstract = {This tutorial focuses on curriculum learning (CL), an important topic in machine learning, which gains an increasing amount of attention in the research community. CL is a learning paradigm that enables machines to learn from easy data to hard data, imitating the meaningful procedure of human learning with curricula. As an easy-to-use plug-in, CL has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision, natural language processing, reinforcement learning, etc. In particular, CL can also play an important role in multimedia applications. Therefore, it is essential to introduce CL to more scholars and researchers in the machine learning and multimedia community. However, there have been no tutorials on CL for multimedia so far, motivating the organization of this tutorial at ACM Multimedia 2024. To give a comprehensive tutorial on CL for multimedia, we plan to organize it from the following aspects: (1) theories, (2) approaches, (3) applications, (4) tools, and (5) future directions. First, we introduce the motivations, theories, and insights behind CL. Second, we advocate novel, high-quality approaches, as well as innovative solutions to the challenging problems in CL. Then we present the applications of CL in various scenarios, especially multimedia, followed by some relevant tools. In the end, we discuss open questions and future directions in the era of large language models. We believe this topic is at the core of the scope of ACM Multimedia and is attractive to the audience interested in machine learning and multimedia from both academia and industry.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11296–11297},
numpages = {2},
keywords = {curriculum learning, large language models, machine learning library and tool, machine learning paradigm, training strategy},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3649217.3653595,
author = {Cucuiat, Veronica and Waite, Jane},
title = {Feedback Literacy: Holistic Analysis of Secondary Educators' Views of LLM Explanations of Program Error Messages},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653595},
doi = {10.1145/3649217.3653595},
abstract = {The implications of using large language model (LLM) tools for learning to program at secondary school level are largely unknown, and yet there is pressure for teachers to engage with these. To start addressing this gap, we investigated: RQ1: What are secondary educators' views on the potential classroom use of LLM program error message explanations? RQ2: In what ways can a feedback literacy perspective support the analysis of educators' views of potential classroom use of LLM program error message explanations? The responses of eight expert secondary school educators were gathered during a semi-structured, activity-based interview and qualitatively analysed. Fifteen themes were derived from their commentary, of which ten corresponded to enhanced program error message (PEM) guidelines. Yet, all themes correlated to feedback literacy theory, providing a more holistic view. The analysis revealed that educators preferred LLM explanations to guide and develop understanding rather than tell, that students should be supported to make judgements and action LLM-generated feedback. Combining PEM guideline and feedback literacy findings, we suggest augmented IDEs should be designed with educators and students in mind, and teacher professional development (PD) is needed. Research is needed to compare our findings with a wider range of educators and investigate what feedback literacy means for resource design, PD, and classroom practice in secondary and undergraduate contexts.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {192–198},
numpages = {7},
keywords = {AI, IDE, K-12 education, ML, feedback literacy},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3635059.3635104,
author = {Karanikolas, Nikitas and Manga, Eirini and Samaridi, Nikoletta and Tousidou, Eleni and Vassilakopoulos, Michael},
title = {Large Language Models versus Natural Language Understanding and Generation},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635104},
doi = {10.1145/3635059.3635104},
abstract = {In recent years, the process humans adopt to learn a foreign language has moved from the strict "Grammar –Translation" method, which is based mainly on grammar and syntax rules, to more innovative processes, resulting to the more modern "Communicative approach". As its name states, this approach focuses on the coherent communication with native speakers and the cultivation of oral skills, without taking into consideration, at least at the first stages, the rules that govern the language. The same trend seems to have been applied to the way machinery can be "educated" to comprehend and reproduce the unfamiliar, human language. The "rule based" Natural Language Generation (NLG) and Natural Language Understanding (NLU) algorithms, on one hand, and the "text based" Large Language Models (LLMs), on the other, are two, analogous to the two human foreign language learning processes, subareas of Natural Language Processing (NLP). This paper presents these two alternative approaches, LLMs (a technology having surfaced as an influential catalyst of NLP, during last years) on the one hand and NLG/NLU on the other, highlighting their applications, their technologies, their capabilities, their differences, their strengths and weaknesses and the challenges they present, contributing to a deeper comprehension of the evolving landscape of Artificial Intelligence and human-computer communication.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {278–290},
numpages = {13},
keywords = {Large Language Models, Natural Language Generation, Natural Language Processing, Natural Language Understanding},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3641525.3663629,
author = {Bhaskar, Adhithya and Stodden, Victoria},
title = {Reproscreener: Leveraging LLMs for Assessing Computational Reproducibility of Machine Learning Pipelines},
year = {2024},
isbn = {9798400705304},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641525.3663629},
doi = {10.1145/3641525.3663629},
abstract = {The increasing reliance on machine learning models in scientific research and day-to-day applications – and the near-opacity of their associated computational methods – creates a widely recognized need to enable others to verify results coming from Machine Learning Pipelines. In this work we use an empirical approach to build on efforts to define and deploy structured publication standards that allow machine learning research to be automatically assessed and verified, enabling greater reliability and trust in results. To automate the assessment of a set of publication standards for Machine Learning Pipelines we developed Reproscreener; a novel, open-source software tool (see https://reproscreener.org/). We benchmark Reproscreener’s automatic reproducibility assessment against a novel manually labeled “gold standard” dataset of machine learning arXiv preprints. Our empirical evaluation has a dual goal: to assess Reproscreener’s performance; and to uncover gaps and opportunities in current reproducibility standards. We develop reproducibility assessment metrics we called the Repo Metrics to provide a novel overall assessment of the re-executability potential of the Machine Learning Pipeline, called the ReproScore. We used two approaches to the automatic identification of reproducibility metrics, keywords and LLM tools, and found the reproducibility metric evaluation performance of Large Language Model (LLM) tools superior to keyword associations.},
booktitle = {Proceedings of the 2nd ACM Conference on Reproducibility and Replicability},
pages = {101–109},
numpages = {9},
keywords = {Computational Reproducibility, CyberInfrastructure, Machine Learning, Open Code, Open Data, ReproScore, Reproducibility Policy, Reproscreener},
location = {Rennes, France},
series = {ACM REP '24}
}

@inproceedings{10.1145/3656019.3676895,
author = {Dutta, Akash and Jannesari, Ali},
title = {MIREncoder: Multi-modal IR-based Pretrained Embeddings for Performance Optimizations},
year = {2024},
isbn = {9798400706318},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656019.3676895},
doi = {10.1145/3656019.3676895},
abstract = {One of the primary areas of interest in High Performance Computing is the improvement of performance of parallel workloads. Nowadays, compilable source code-based optimization tasks that employ deep learning often exploit LLVM Intermediate Representations (IRs) for extracting features from source code. Most such works target specific tasks, or are designed with a pre-defined set of heuristics. So far, pre-trained models are rare in this domain, but the possibilities have been widely discussed. Especially approaches mimicking large-language models (LLMs) have been proposed. But these have prohibitively large training costs. In this paper, we propose MIREncoder, a Multi-modal IR-based Auto-Encoder that can be pre-trained to generate a learned embedding space to be used for downstream tasks by machine learning-based approaches. A multi-modal approach enables us to better extract features from compilable programs. It allows us to better model code syntax, semantics and structure. For code-based performance optimizations, these features are very important while making optimization decisions. A pre-trained model/embedding implicitly enables the usage of transfer learning, and helps move away from task-specific trained models. Additionally, a pre-trained model used for downstream performance optimization should itself have reduced overhead, and be easily usable. These considerations have led us to propose a modeling approach that i) understands code semantics and structure, ii) enables use of transfer learning, and iii) is small and simple enough to be easily re-purposed or reused even with low resource availability. Our evaluations will show that our proposed approach can outperform the state of the art while reducing overhead.},
booktitle = {Proceedings of the 2024 International Conference on Parallel Architectures and Compilation Techniques},
pages = {156–167},
numpages = {12},
keywords = {Auto-tuning, GNN, LLVM, Multi-modal Modeling, Performance Optimization, Pre-training},
location = {Long Beach, CA, USA},
series = {PACT '24}
}

@article{10.1145/3654992,
author = {Wu, Yang and Wan, Yao and Zhang, Hongyu and Sui, Yulei and Wei, Wucai and Zhao, Wei and Xu, Guandong and Jin, Hai},
title = {Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654992},
doi = {10.1145/3654992},
abstract = {The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {115},
numpages = {28},
keywords = {code generation, data analysis, data visualization, exploratory study, large language models, natural language processing}
}

@inproceedings{10.1145/3703847.3703872,
author = {Zhao, Zhenping and Gao, Yong and Sun, Congfei and Wang, Jing and Zhou, Lanjun and Xu, Hongji},
title = {Application of large models in wearable device-based cardiovascular risk monitoring},
year = {2024},
isbn = {9798400709746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703847.3703872},
doi = {10.1145/3703847.3703872},
abstract = {Text matching method was used to identify the corresponding Framingham risk factors from each cardiovascular disease examination report, and the corresponding risk coefficient given by the Framingham heart risk score scale was used as the Framingham risk coefficient. Words similar to each Framingham risk factor were collected as similar risk factors, and the self-attention agency model was used to find corresponding similar risk factors from each cardiovascular disease examination report, and the corresponding similar risk coefficient was given. Text semantic analysis method was used to find out the risk factors from each cardiovascular disease examination report, and the corresponding risk coefficients were calculated. The three types of risk factors were identified and the basic information of patients were spliced and integrated to generate the initial risk analysis report, and the medical large language model was used to adjust the initial risk analysis report through the fine-tuning of prompt words, and the final risk analysis report was generated.},
booktitle = {Proceedings of the 2024 International Conference on Smart Healthcare and Wearable Intelligent Devices},
pages = {144–150},
numpages = {7},
keywords = {Medical model, Risk factors, cardiovascular disease},
location = {
},
series = {SHWID '24}
}

@inproceedings{10.1145/3689932.3694758,
author = {Roa, Camila and Mahbub, Maria and Srinivasan, Sudarshan and Begoli, Edmon and Sadovnik, Amir},
title = {Semantic Stealth: Crafting Covert Adversarial Patches for Sentiment Classifiers Using Large Language Models},
year = {2024},
isbn = {9798400712289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689932.3694758},
doi = {10.1145/3689932.3694758},
abstract = {Deep learning models have been shown to be vulnerable to adversarial attacks, in which perturbations to their inputs cause the model to produce incorrect predictions. As opposed to adversarial attacks in computer vision, where small changes introduced to pixel values can drastically alter a model's output while remaining imperceptible to humans, text-based attacks are difficult to conceal due to the discrete nature of tokens. Consequently, unconstrained gradient-based attacks often produce adversarial examples that lack semantic meaning, rendering them detectable through visual inspection or perplexity filters. In contrast to methods that rely on gradient-based optimization in the embedding space, we propose an approach that leverages a Large Language Model's ability to generate grammatically correct and semantically meaningful text to craft adversarial patches that seamlessly blend in with the original input text. These patches can be used to alter the behavior of a target model, such as a text classifier. Since our approach does not rely on gradient backpropagation, it only requires access to the target model's confidence scores, making it a grey-box attack. We demonstrate the feasibility of our approach using open-source LLMs, including Intel's Neural Chat, Llama2, and Mistral-Instruct, to generate adversarial patches capable of altering the predictions of a distilBERT model fine-tuned on the IMDB reviews dataset for sentiment classification.},
booktitle = {Proceedings of the 2024 Workshop on Artificial Intelligence and Security},
pages = {42–52},
numpages = {11},
keywords = {adversarial attack, adversarial patches, large language model, sentiment classification, transformer-based model},
location = {Salt Lake City, UT, USA},
series = {AISec '24}
}

@article{10.14778/3696435.3696440,
author = {Li, Zhaodonghui and Yuan, Haitao and Wang, Huiming and Cong, Gao and Bing, Lidong},
title = {LLM-R2: A Large Language Model Enhanced Rule-Based Rewrite System for Boosting Query Efficiency},
year = {2024},
issue_date = {September 2024},
publisher = {VLDB Endowment},
volume = {18},
number = {1},
issn = {2150-8097},
url = {https://doi.org/10.14778/3696435.3696440},
doi = {10.14778/3696435.3696440},
abstract = {Query rewrite, which aims to improve query efficiency by altering an SQL query's structure without changing its result, has been an important research problem. In order to maintain equivalence between the rewritten query and the original one during rewriting, traditional query rewrite methods always rewrite the queries following certain rewrite rules. However, some problems still remain. First, existing methods of finding the optimal choice or sequence of rewrite rules are still limited and the process always costs a lot of resources. Methods involving discovering new rewrite rules typically require complicated proofs of structural logic or extensive user interactions. Second, current query rewrite methods usually rely highly on DBMS cost estimators which are often not accurate. In this paper, we address these problems by proposing a novel query rewrite method named LLM-R2, which leverages a large language model (LLM) to recommend rewrite rules for a database rewrite system. To further enhance the inference ability of the LLM in recommending rewrite rules, we train a contrastive model using a curriculum-based approach to learn query representations and select effective query demonstrations for the LLM. Experimental results show that our method significantly improves the query execution efficiency and outperforms the baseline methods. In addition, our method exhibits high robustness across different datasets.},
journal = {Proc. VLDB Endow.},
month = sep,
pages = {53–65},
numpages = {13}
}

@article{10.5555/3722479.3722527,
author = {Anem, Sai Sravya and Amiruzzaman, Md and Bhuiyan, Ashik Ahmed},
title = {Studying Financial Data with Macroeconomic Factors Using Machine Learning},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {This paper focuses on the prediction of stock indices through machine learning, focusing on macroeconomic factors and market sentiment generation. It centers on major US stock index funds, notably the S&amp;P 500, and their correlation with key economic indicators like GDP, unemployment, CPI, money supply, and retail sales. Utilizing economic data from diverse sources such as the Federal Reserve, NASDAQ, and news websites, the study cleans and transforms datasets to estimate quarterly fund returns. Employing tree-based algorithms, particularly XGBoost, enables accurate predictions. Moreover, the paper evaluates index forecast performance across various market cycles and geopolitical events. It also uses traditional NLP methods and large language models to explore market sentiment generation, offering comprehensive insights. In essence, this paper sheds light on the predictive power of macroeconomic factors on stock indices and the nuances of market sentiment analysis, leveraging both conventional and advanced techniques.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {151–163},
numpages = {13}
}

@inproceedings{10.1145/3701625.3701659,
author = {Guerino, Lucca Renato and Kuroishi, Pedro Henrique and Paiva, Ana Cristina Ramada and Vincenzi, Auri Marcelo Rizzo},
title = {Static and Dynamic Comparison of Mutation Testing Tools for Python},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701659},
doi = {10.1145/3701625.3701659},
abstract = {Context: Mutation testing is a rigorous approach for assessing the quality of test suites by injecting faults (i.e., mutants) into software under test. Tools, such as CosmicRay and Mutpy, are examples of Mutation Testing tools for Python software programs. Problem: With different Python mutation testing tools, comparative analysis is lacking to evaluate their effectiveness in different usage scenarios. Furthermore, the evolution of these tools makes continuous evaluation of their functionalities and characteristics necessary. Method: In this work, we evaluate (statically and dynamically) four Python mutation testing tools, namely CosmicRay, MutPy, MutMut, and Mutatest. In static evaluation, we introduce a comparison framework, adapted from one previously applied to Java tools, and collected information from tool documentation and developer surveys. For dynamic evaluation, we use tests built based on those produced by Pynguin, which are improved through the application of Large Language Models (LLMs) and manual analyses. Then, the adequate test suites were cross-tested among different tools to evaluate their effectiveness in killing mutants each other. Results: Our findings reveal that CosmicRay offers superior functionalities and customization options for mutant generation compared to its counterparts. Although CosmicRay’s performance was slightly lower than MutPy in the dynamic tests, its recent updates and active community support highlight its potential for future enhancements. Cross-examination of the test suites further shows that mutation scores varied narrowly among tools, with a slight emphasis on MutPy as the most effective mutant fault model.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {199–209},
numpages = {11},
keywords = {Software Testing, Experimental Software Engineering, Automated Test Generation, Coverage Testing, Mutation Testing, Testing Tools, Python Mutation Tools},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3589335.3641257,
author = {Wang, Xin and Zhou, Yuwei and Chen, Hong and Zhu, Wenwu},
title = {Curriculum Learning: Theories, Approaches, Applications, Tools, and Future Directions in the Era of Large Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641257},
doi = {10.1145/3589335.3641257},
abstract = {This tutorial focuses on curriculum learning (CL), an important topic in machine learning, which gains an increasing amount of attention in the research community. CL is a learning paradigm that enables machines to learn from easy data to hard data, imitating the meaningful procedure of human learning with curricula. As an easy-to-use plug-in, CL has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision, natural language processing, data mining, reinforcement learning, etc. Therefore, it is essential introducing CL to more scholars and researchers in the machine learning community. However, there have been no tutorials on CL so far, motivating the organization of our tutorial on CL at WWW 2024. To give a comprehensive tutorial on CL, we plan to organize it from the following aspects: (1) theories, (2) approaches, (3) applications, (4) tools and (5) future directions. First, we introduce the motivations, theories and insights behind CL. Second, we advocate novel, high-quality approaches, as well as innovative solutions to the challenging problems in CL. Then we present the applications of CL in various scenarios, followed by some relevant tools. In the end, we discuss open questions and the future direction in the era of large language models. We believe this topic is at the core of the scope of WWW and is attractive to the audience interested in machine learning from both academia and industry.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1306–1310},
numpages = {5},
keywords = {curriculum learning, large language models, machine learning library and tool, machine learning paradigm, training strategy},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3597503.3623342,
author = {Yang, Aidan Z. H. and Le Goues, Claire and Martins, Ruben and Hellendoorn, Vincent},
title = {Large Language Models for Test-Free Fault Localization},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623342},
doi = {10.1145/3597503.3623342},
abstract = {Fault Localization (FL) aims to automatically localize buggy lines of code, a key first step in many manual and automatic debugging tasks. Previous FL techniques assume the provision of input tests, and often require extensive program analysis, program instrumentation, or data preprocessing. Prior work on deep learning for APR struggles to learn from small datasets and produces limited results on real-world programs. Inspired by the ability of large language models (LLMs) of code to adapt to new tasks based on very few examples, we investigate the applicability of LLMs to line level fault localization. Specifically, we propose to overcome the left-to-right nature of LLMs by fine-tuning a small set of bidirectional adapter layers on top of the representations learned by LLMs to produce LLMAO, the first language model based fault localization approach that locates buggy lines of code without any test coverage information. We fine-tune LLMs with 350 million, 6 billion, and 16 billion parameters on small, manually curated corpora of buggy programs such as the Defects4J corpus. We observe that our technique achieves substantially more confidence in fault localization when built on the larger models, with bug localization performance scaling consistently with the LLM size. Our empirical evaluation shows that LLMAO improves the Top-1 results over the state-of-the-art machine learning fault localization (MLFL) baselines by 2.3%--54.4%, and Top-5 results by 14.4%-35.6%. LLMAO is also the first FL technique trained using a language model architecture that can detect security vulnerabilities down to the code line level.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {17},
numpages = {12},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3698038.3698523,
author = {Patke, Archit and Reddy, Dhemath and Jha, Saurabh and Qiu, Haoran and Pinto, Christian and Narayanaswami, Chandra and Kalbarczyk, Zbigniew and Iyer, Ravishankar},
title = {Queue Management for SLO-Oriented Large Language Model Serving},
year = {2024},
isbn = {9798400712869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698038.3698523},
doi = {10.1145/3698038.3698523},
abstract = {Large language model (LLM) serving is becoming an increasingly critical workload for cloud providers. Existing LLM serving systems focus on interactive requests, such as chatbots and coding assistants, with tight latency SLO requirements. However, when such systems execute batch requests that have relaxed SLOs along with interactive requests, it leads to poor multiplexing and inefficient resource utilization. To address these challenges, we propose QLM, a queue management system for LLM serving. QLM maintains batch and interactive requests across different models and SLOs in a request queue. Optimal ordering of the request queue is critical to maintain SLOs while ensuring high resource utilization. To generate this optimal ordering, QLM uses a Request Waiting Time (RWT) Estimator that estimates the waiting times for requests in the request queue. These estimates are used by a global scheduler to orchestrate LLM Serving Operations (LSOs) such as request pulling, request eviction, load balancing, and model swapping. Evaluation on heterogeneous GPU devices and models with real-world LLM serving dataset shows that QLM improves SLO attainment by 40-90% and throughput by 20-400% while maintaining or improving device utilization compared to other state-of-the-art LLM serving systems. QLM's evaluation is based on the production requirements of a cloud provider. QLM is publicly available at https://www.github.com/QLM-project/QLM.},
booktitle = {Proceedings of the 2024 ACM Symposium on Cloud Computing},
pages = {18–35},
numpages = {18},
keywords = {large language models, machine learning inference, queuing},
location = {Redmond, WA, USA},
series = {SoCC '24}
}

@inproceedings{10.1145/3677052.3698647,
author = {Gopal, Achintya},
title = {NeuralFactors: A Novel Factor Learning Approach to Generative Modeling of Equities},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698647},
doi = {10.1145/3677052.3698647},
abstract = {The use of machine learning for statistical modeling (and thus, generative modeling) has grown in popularity with the proliferation of time series models, text-to-image models, and especially large language models. Fundamentally, the goal of classical factor modeling is statistical modeling of stock returns, and in this work, we explore using deep generative modeling to enhance classical factor models. Prior work has explored the use of deep generative models in order to model hundreds of stocks, leading to accurate risk forecasting and alpha portfolio construction; however, that specific model does not allow for easy factor modeling interpretation in that the factor exposures cannot be deduced. In this work, we introduce NeuralFactors, a novel machine-learning based approach to factor analysis where a neural network outputs factor exposures and factor returns, trained using the same methodology as variational autoencoders. We show that this model outperforms prior approaches both in terms of log-likelihood performance and computational efficiency. Further, we show that this method is competitive to prior work in generating realistic synthetic data, covariance estimation, risk analysis (e.g., value at risk, or VaR, of portfolios), and portfolio optimization. Finally, due to the connection to classical factor analysis, we analyze how the factors our model learns cluster together and show that the factor exposures could be used for embedding stocks.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {99–107},
numpages = {9},
keywords = {Generative Modeling, Portfolio Optimization, Risk Forecasting, Statistical Factors, Stock Returns, Variational Autoencoders},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@proceedings{10.1145/3689094,
title = {SUMAC '24: Proceedings of the 6th workshop on the analySis, Understanding and proMotion of heritAge Contents},
year = {2024},
isbn = {9798400712050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to SUMAC 2024, the 6th edition of the ACM workshop on analySis, Understanding and proMotion of heritAge Contents. The workshop focuses on analyzing, processing and valorizing all types of data related to cultural heritage, including tangible and intangible heritage. As stated by UNESCO, cultural heritage provides societies with a wealth of resources inherited from the past, created in the present for the benefit of future generations. The massive digitization of historical analogue resources and production of born-digital documents provide us with large volumes of varied multimedia heritage data (images, maps, text, video, 3D objects, multi-sensor data, etc.), which represent a rich heritage that can be exploited in a wide variety of fields, from research in social sciences and computational humanities to land use and territorial policies, including urban modeling, digital simulation, archaeology, tourism, education, culture preservation, creative media and entertainment. In terms of research in computer science, artificial intelligence and digital humanities, they address challenging problems related to the diversity, specificity or volume of the media, the veracity of the data, and different user needs with respect to engaging with this rich material and the extraction of value out of the data. These challenges are reflected in the corresponding sub-fields of machine learning, signal processing, multi-modal techniques and human-machine interaction, with special focus on:Analysis of historical data,Content understanding and pattern recognition,Linking and recommendation of multi-modal digital heritage,Human-machine interaction for big data analysis and visualization,Generative modeling of cultural heritage.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3658644.3691374,
author = {Xue, Di and Zhao, Gang and Fan, Zhongqi and Li, Wei and Xu, Yahong and Liu, Zhen and Liu, Yin and Yuan, Zhongliang},
title = {Poster: An Exploration of Large Language Models in Malicious Source Code Detection},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691374},
doi = {10.1145/3658644.3691374},
abstract = {Embedding malicious code within the software supply chain has become a significant concern in the information technology field. Current methods for detecting malicious code, based on signatures, behavior analysis, and traditional machine learning models, lack result interpretability. This study proposes a novel malicious code detection framework, Mal-LLM, which leverages the cost advantages of traditional machine learning models and the interpretability of LLMs. Initially, traditional machine learning models filter vast amounts of malicious source code in the software supply chain. Subsequently, LLMs analyze and interpret the filtered malicious source code using a customized prompt template incorporating role-playing and chain-of-thought techniques. The feasibility of the Mal-LLM framework is validated through extensive experimental analyses, examining the ambiguity and redundancy of the LLM in the framework, the significance of ''experience'' and ''malicious'' prompts, and exploring methods to reduce the cost of using LLMs from an enterprise perspective.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {4940–4942},
numpages = {3},
keywords = {llms, malicious code detection, prompt engineering, software supply chain},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3626253.3635404,
author = {Howard-Sarin, Brij},
title = {The Future of the Error Message: Comparing Large Language Models and Novice Programmer Effectiveness in Fixing Errors},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635404},
doi = {10.1145/3626253.3635404},
abstract = {Research on enhancing error message presentation is of great interest to teachers and developers alike because improving Integrated Development Environments (IDEs) increases early student retention and efficiency at all levels with more effective developing tools. This study aims to compare GPT-4 and novice programmer accuracy in fixing errors to assess the viability of Large Language Models as an error message enhancement tool. First, a random sample of 100,000 sessions from all users of BlueJ 5, an IDE for novice programmers, was analyzed to determine the time it took programmers to resolve coding errors. Subsequently, for each of the five most common errors, GPT-4 was given 20 randomly-selected snippets of code from Blackbox mini, a curated subset of Blackbox with source code attached, and prompted to explain and fix the errors. This study replicated prior research that proposed a Zipf-Mandelbrot Distribution of error message frequency; the five most common errors comprised 45% of all error messages. In comparing GPT-4 and novices, it was found that humans fix code at higher rates, but GPT-4 provided completely correct explanations for error messages 96% of the time. This study concludes that GPT-4 functions best as a tool to explain error messages in an interactive format, rather than as a tool to produce correct code on its own. In conclusion, GPT-4 would be best utilized to enhance the classroom experience as a chat assistant to reduce time spent on syntactical errors, leading to improved productivity and better novice retention.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {BlueJ, GPT-4, IDEs, blackbox, error message enhancement, error messages, large language models, novice programmers},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3638884.3638961,
author = {Liu, Wenjing and Zhang, Suxiang and Sun, Yang and Sheng, Xing and Wu, Zhidong},
title = {New Energy Power Domain Question-Method Extraction And Soft Clustering},
year = {2024},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638884.3638961},
doi = {10.1145/3638884.3638961},
abstract = {In recent years, as the field of new energy power has gradually become a research hotspot, there are more and more research results related to new energy power. This paper first proposes to Fine-tune the Chinese LLaMA large language model to realize the extraction of research questions and methods in new energy power results. The fine-tuning dataset is constructed by the combination of rule template and gpt-3.5 enhancement, which avoids the costly and time-consuming problem caused by manual construction. The fine-tuning method adopts LoRA high-efficiency fine-tuning to save computing resources; Then, F1 value is used as the evaluation index to compare the extraction effect of the model under different fine-tuning datasets. The results show that the model has a good extraction effect on the research questions and method terms when training the dataset constructed by the combination of rule template and gpt-3.5 enhancement. Finally, according to the extracted research question phrases, BTM(Biterm Topic Model) is used to study the distribution of topic words, and soft clustering of research question phrases is carried out according to the obtained topic words, so as to realize the correlation between the research results and professional terms, which provides the foundation for the future establishment of the knowledge graph and knowledge base of new energy power.CCS CONCEPTS • Theory of computation • Theory and algorithms for application domains • Unsupervised learning and clustering},
booktitle = {Proceedings of the 2023 9th International Conference on Communication and Information Processing},
pages = {484–491},
numpages = {8},
keywords = {Biterm Topic Model, Chinese LLaMA Fine-Tuning, Soft clustering, Terminology extraction},
location = {Lingshui, China},
series = {ICCIP '23}
}

@inproceedings{10.1145/3664647.3681584,
author = {Guo, Xuechen and Chai, Wenhao and Li, Shi-Yan and Wang, Gaoang},
title = {LLaVA-Ultra: Large Chinese Language and Vision Assistant for Ultrasound},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681584},
doi = {10.1145/3664647.3681584},
abstract = {Multimodal Large Language Model (MLLM) has recently garnered attention as a prominent research focus. By harnessing powerful LLM, it facilitates a transition of conversational generative AI from unimodal text to performing multimodal tasks. This boom begins to significantly impact medical field. However, general visual language model (VLM) lacks sophisticated comprehension for medical visual question answering (Med-VQA). Even models specifically tailored for medical domain tend to produce vague answers with weak visual relevance. In this paper, we propose a fine-grained adaptive VLM architecture for Chinese medical visual conversations through parameter-efficient tuning. Specifically, we devise a fusion module with fine-grained vision encoders to achieve enhancement for subtle medical visual semantics. Then we note data redundancy common to medical scenes is ignored in most prior works. In cases of a single text paired with multiple figures, we utilize weighted scoring with knowledge distillation to adaptively screen valid images mirroring text descriptions. For execution, we leverage a large-scale multimodal Chinese ultrasound dataset obtained from the hospital. We create instruction-following data based on text from professional doctors, which ensures effective tuning. With enhanced model and quality data, our Large Chinese Language and Vision Assistant for Ultra sound (LLaVA-Ultra) shows strong capability and robustness to medical scenarios. On three Med-VQA datasets, LLaVA-Ultra surpasses previous state-of-the-art models on various metrics.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8845–8854},
numpages = {10},
keywords = {medical instruction tuning, multimodal large language model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3643795.3648395,
author = {Pister, Kaiser and Paul, Dhruba Jyoti and Joshi, Ishan and Brophy, Patrick},
title = {PromptSet: A Programmer's Prompting Dataset},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648395},
doi = {10.1145/3643795.3648395},
abstract = {The rise of capabilities expressed by large language models has been quickly followed by the integration of the same complex systems into application level logic. Algorithms, programs, systems, and companies are built around structured prompting to black box models where the majority of the design and implementation lies in capturing and quantifying the `agent mode'. The standard way to shape a closed language model is to prime it for a specific task with a tailored prompt, often initially handwritten by a human. The textual prompts co-evolve with the codebase, taking shape over the course of project life as artifacts which must be reviewed and maintained, just as the traditional code files might be. Unlike traditional code, we find that prompts do not receive effective static testing and linting to prevent runtime issues. In this work, we present a novel dataset called PromptSet, with more than 61,000 unique developer prompts used in open source Python programs. We perform analysis on this dataset and introduce the notion of a static linter for prompts. Released with this publication is a HuggingFace dataset and a Github repository to recreate collection and processing efforts, both under the name pisterlabs/promptset.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {62–69},
numpages = {8},
keywords = {prompt management, large language models, dataset, information systems, ethnography, taxonomy},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3605098.3635964,
author = {De Oliveira, Aillkeen Bezerra and Baptista, Claudio de Souza and Firmino, Anderson Almeida and De Paiva, Anselmo Cardoso},
title = {A Large Language Model Approach to Detect Hate Speech in Political Discourse Using Multiple Language Corpora},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635964},
doi = {10.1145/3605098.3635964},
abstract = {In this era of unprecedented digital connectivity and interactions, the issue of hate speech has become a focal point in societal discussions. The rise of digital communication platforms has fundamentally transformed how hate speech spreads. Online social media and messaging apps have rapidly disseminated hate speech, exacerbated by the internet's anonymity. Computational technology has emerged as a valuable tool for identifying and mitigating hate speech on social media. In this work, we employed five distinct corpora representing the English, Italian, Filipino, German, and Turkish languages. We propose employing a Large Language Model (GPT-3) enhanced with Cross-Lingual Learning to improve hate speech detection in English and Italian. Our investigation employs a strategy, namely JL/CL+, which combines two strategies: Joint Learning (JL) and Cascade Learning (CL). Even using data with lexical disparities, our findings demonstrate substantial success, yielding an F1-score of 96.58% for English and 92.05% for Italian languages.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1461–1468},
numpages = {8},
keywords = {hate speech, large language model, cross-lingual learning, machine learning, natural language processing},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3620665.3640423,
author = {Guo, Cong and Zhang, Rui and Xu, Jiale and Leng, Jingwen and Liu, Zihan and Huang, Ziyu and Guo, Minyi and Wu, Hao and Zhao, Shouren and Zhao, Junping and Zhang, Ke},
title = {GMLake: Efficient and Transparent GPU Memory Defragmentation for Large-scale DNN Training with Virtual Memory Stitching},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640423},
doi = {10.1145/3620665.3640423},
abstract = {Large-scale deep neural networks (DNNs), such as large language models (LLMs), have revolutionized the artificial intelligence (AI) field and become increasingly popular. However, training or fine-tuning such models requires substantial computational power and resources, where the memory capacity of a single acceleration device like a GPU is one of the most important bottlenecks. Owing to the prohibitively large overhead (e.g., 10\texttimes{}) of GPUs' native memory allocator, DNN frameworks like PyTorch and TensorFlow adopt a caching allocator that maintains a memory pool with a splitting mechanism for fast memory (de)allocation. Unfortunately, the caching allocator's efficiency degrades quickly for popular memory reduction techniques such as re-computation, offloading, distributed training, and low-rank adaptation. The primary reason is that those memory reduction techniques introduce frequent and irregular memory (de)allocation requests, leading to severe fragmentation problems for the splitting-based caching allocator. To mitigate this fragmentation problem, we propose a novel memory allocation framework based on low-level GPU virtual memory management called GPU memory lake (GMLake). GMLake employs a novel virtual memory stitching (VMS) mechanism, which can fuse or combine non-contiguous memory blocks with a virtual memory address mapping. GMLake can reduce average of 9.2 GB (up to 25 GB) GPU memory usage and 15% (up to 33%) fragmentation among eight LLM models on GPU A100 with 80 GB memory. GMLake is completely transparent to the DNN models and memory reduction techniques and ensures the seamless execution of resource-intensive deep-learning tasks. We have open-sourced GMLake at https://github.com/intelligent-machine-learning/glake/tree/main/GMLake.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {450–466},
numpages = {17},
keywords = {memory defragmentation, GPU, deep learning, virtual memory stitching},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@article{10.1145/3696450,
author = {Huang, Kai and Xu, Zhengzi and Yang, Su and Sun, Hongyu and Li, Xuejun and Yan, Zheng and Zhang, Yuqing},
title = {Evolving Paradigms in Automated Program Repair: Taxonomy, Challenges, and Opportunities},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3696450},
doi = {10.1145/3696450},
abstract = {With the rapid development and large-scale popularity of program software, modern society increasingly relies on software systems. However, the problems exposed by software have also come to the fore. The software bug has become an important factor troubling developers. In this context, Automated Program Repair (APR) techniques have emerged, aiming to automatically fix software bug problems and reduce manual debugging work. In particular, benefiting from the advances in deep learning, numerous learning-based APR techniques have emerged in recent years, which also bring new opportunities for APR research. To give researchers a quick overview of APR techniques’ complete development and future opportunities, we review the evolution of APR techniques and discuss in depth the latest advances in APR research. In this article, the development of APR techniques is introduced in terms of four different patch generation schemes: search-based, constraint-based, template-based, and learning-based. Moreover, we propose a uniform set of criteria to review and compare each APR tool and then discuss the current state of APR development. Finally, we analyze current challenges and future directions, especially highlighting the critical opportunities that large language models bring to APR research.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {36},
numpages = {43},
keywords = {Automated program repair}
}

@inproceedings{10.1145/3674805.3686664,
author = {Hu, Gang and Zeng, Xiaoqin and Yu, Wanlong and Peng, Min and Yuan, Mengting and Duan, Liang},
title = {Unsupervised and Supervised Co-learning for Comment-based Codebase Refining and its Application in Code Search},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686664},
doi = {10.1145/3674805.3686664},
abstract = {&nbsp;Background: Code pre-training and large language models are heavily dependent on data quality. These models require a vast, high-quality corpus matching text descriptions with codes to establish semantic correlations between natural and programming languages. Unlike NLP tasks, code comment heavily relies on specialized programming knowledge and is often limited in quantity and variety. Thus, most widely available open-source datasets are established with compromise and noise from platforms, such as StackOverflow, where code snippets are often incomplete. This may lead to significant errors when deploying the trained models in real-world applications. &nbsp;Aims: Comments as a substitute for queries are used to build code search datasets from GitHub. While comments describe code functionality and details, they often contain noise and differ from queries. Thus, our research focuses on improving the syntactic and semantic quality of code comments. &nbsp;Method: We propose a comment-based data refinement framework CoCoRF 1 via an unsupervised and supervised co-learning technique. It applies manually defined rules for syntax filtering and constructs a bootstrap query corpus via the WTFF algorithm for training the TVAE model for further semantic filtering. &nbsp;Results: Our study shows that CoCoRF achieves high efficiency with less computational resource, and outperforms comparison models in DeepCS code search task. &nbsp;Conclusions: Our findings indicate that the CoCoRF framework significantly improves the performance of code search tasks by enhancing the quality of code datasets.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {1–12},
numpages = {12},
keywords = {Code Search, CodeSearchNet Cleaning, Comment-Code dataset, Self-attention Mechanism},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3691620.3694997,
author = {Lu, Jiawei and Wang, Haoye and Liu, Zhongxin and Liang, Keyu and Bao, Lingfeng and Yang, Xiaohu},
title = {Instructive Code Retriever: Learn from Large Language Model's Feedback for Code Intelligence Tasks},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694997},
doi = {10.1145/3691620.3694997},
abstract = {Recent studies proposed to leverage large language models (LLMs) with In-Context Learning (ICL) to handle code intelligence tasks without fine-tuning. ICL employs task instructions and a set of examples as demonstrations to guide the model in generating accurate answers without updating its parameters. While ICL has proven effective for code intelligence tasks, its performance heavily relies on the selected examples. Previous work has achieved some success in using BM25 to retrieve examples for code intelligence tasks. However, existing approaches lack the ability to understand the semantic and structural information of queries, resulting in less helpful demonstrations. Moreover, they do not adapt well to the complex and dynamic nature of user queries in diverse domains. In this paper, we introduce a novel approach named Instructive Code Retriever (ICR), which is designed to retrieve examples that enhance model inference across various code intelligence tasks and datasets. We enable ICR to learn the semantic and structural information of the corpus by a tree-based loss function. To better understand the correlation between queries and examples, we incorporate the feedback from LLMs to guide the training of the retriever. Experimental results demonstrate that our retriever significantly outperforms state-of-the-art approaches. We evaluate our model's effectiveness on various tasks, i.e., code summarization, program synthesis, and bug fixing. Compared to previous state-of-the-art algorithms, our method achieved improvements of 50.0% and 90.0% in terms of BLEU-4 for two code summarization datasets, 74.6% CodeBLEU on program synthesis dataset, and increases of 3.6 and 3.2 BLEU-4 on two bug fixing datasets.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {191–203},
numpages = {13},
keywords = {software engineering, large language models, in-context learning},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3650212.3680355,
author = {Zhang, Cen and Zheng, Yaowen and Bai, Mingqiang and Li, Yeting and Ma, Wei and Xie, Xiaofei and Li, Yuekang and Sun, Limin and Liu, Yang},
title = {How Effective Are They? Exploring Large Language Model Based Fuzz Driver Generation},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680355},
doi = {10.1145/3650212.3680355},
abstract = {Fuzz drivers are essential for library API fuzzing. However, automatically generating fuzz drivers is a complex task, as it demands the creation of high-quality, correct, and robust API usage code. An LLM-based (Large Language Model) approach for generating fuzz drivers is a promising area of research. Unlike traditional program analysis-based generators, this text-based approach is more generalized and capable of harnessing a variety of API usage information, resulting in code that is friendly for human readers. However, there is still a lack of understanding regarding the fundamental issues on this direction, such as its effectiveness and potential challenges.
 

 
To bridge this gap, we conducted the first in-depth study targeting the important issues of using LLMs to generate effective fuzz drivers. Our study features a curated dataset with 86 fuzz driver generation questions from 30 widely-used C projects. Six prompting strategies are designed and tested across five state-of-the-art LLMs with five different temperature settings. In total, our study evaluated 736,430 generated fuzz drivers, with 0.85 billion token costs ($8,000+ charged tokens). Additionally, we compared the LLM-generated drivers against those utilized in industry, conducting extensive fuzzing experiments (3.75 CPU-year). Our study uncovered that:
 

 
1) While LLM-based fuzz driver generation is a promising direction, it still encounters several obstacles towards practical applications;
 
2) LLMs face difficulties in generating effective fuzz drivers for APIs with intricate specifics. Three featured design choices of prompt strategies can be beneficial: issuing repeat queries, querying with examples, and employing an iterative querying process;
 
3) While LLM-generated drivers can yield fuzzing outcomes that are on par with those used in the industry, there are substantial opportunities for enhancement, such as extending contained API usage, or integrating semantic oracles to facilitate logical bug detection.
 

 
Our insights have been implemented to improve the OSS-Fuzz-Gen project, facilitating practical fuzz driver generation in industry.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1223–1235},
numpages = {13},
keywords = {Fuzz Driver Generation, Fuzz Testing, Large Language Model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.5555/3715638.3715656,
author = {Roll, James},
title = {AI as a Learning Tool for Introductory Programming},
year = {2024},
issue_date = {September 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {4},
issn = {1937-4771},
abstract = {The goal of this assignment is to introduce introductory programming students to using generative AI tools like Claude and ChatGPT to help them in learning introductory programming. Students are shown how they can use AI tools to help explain basic programming concepts, decode cryptic error messages, explain why a program isn't working, and find syntax errors in and suggest fixes. Students are also encouraged to avoid using AI Tools to fully write programs at this point in their education, and introduced to the limitations generative AI tools for programming. This version of the assignment was written for an introductory Java programming course, but could easily be adapted to other programming languages.},
journal = {J. Comput. Sci. Coll.},
month = sep,
pages = {45},
numpages = {1}
}

@article{10.1145/3611018,
author = {Maas, Martin and Andersen, David G. and Isard, Michael and Javanmard, Mohammad Mahdi and McKinley, Kathryn S. and Raffel, Colin},
title = {Combining Machine Learning and Lifetime-Based Resource Management for Memory Allocation and Beyond},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {4},
issn = {0001-0782},
url = {https://doi.org/10.1145/3611018},
doi = {10.1145/3611018},
abstract = {Memory management is fundamental to the performance of all applications. On modern server architectures, an application's memory allocator needs to balance memory utilization against the ability to use 2MB huge pages, which are crucial for achieving high performance. This paper shows that prior C++ memory allocators are fundamentally limited because optimizing this trade-off depends on the knowledge of object lifetimes, which is information allocators lack.We introduce a two-step approach to attain high memory utilization in huge pages. We first introduce a novel machine-learning approach that predicts the lifetime of freshly allocated objects using the stack trace at the time of allocation and treats stack traces as natural language. We then present a fundamentally new type of memory allocator that exploits (potentially incorrect) object lifetime predictions to achieve high memory utilization at full huge page usage. In contrast to prior memory allocators that organize their heap around size classes and free lists, our allocator organizes the heap based on predicted lifetime classes and adjusts to mispredictions on the fly. We demonstrate experimentally that this learned lifetime-aware memory allocator (LLAMA) reduces fragmentation with huge pages by up to 78%.Our approach gives rise to a new methodology for applying ML in computer systems. In addition, similar space-time bin packing problems abound in computer science and we discuss how this approach has applications beyond memory allocation to a wide range of problems.},
journal = {Commun. ACM},
month = mar,
pages = {87–96},
numpages = {10}
}

@inproceedings{10.1145/3640457.3688140,
author = {Mezentsev, Gleb and Gusak, Danil and Oseledets, Ivan and Frolov, Evgeny},
title = {Scalable Cross-Entropy Loss for Sequential Recommendations with Large Item Catalogs},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688140},
doi = {10.1145/3640457.3688140},
abstract = {Scalability issue plays a crucial role in productionizing modern recommender systems. Even lightweight architectures may suffer from high computational overload due to intermediate calculations, limiting their practicality in real-world applications. Specifically, applying full Cross-Entropy (CE) loss often yields state-of-the-art performance in terms of recommendations quality. Still, it suffers from excessive GPU memory utilization when dealing with large item catalogs. This paper introduces a novel Scalable Cross-Entropy (SCE) loss function in the sequential learning setup. It approximates the CE loss for datasets with large-size catalogs, enhancing both time efficiency and memory usage without compromising recommendations quality. Unlike traditional negative sampling methods, our approach utilizes a selective GPU-efficient computation strategy, focusing on the most informative elements of the catalog, particularly those most likely to be false positives. This is achieved by approximating the softmax distribution over a subset of the model outputs through the maximum inner product search. Experimental results on multiple datasets demonstrate the effectiveness of SCE in reducing peak memory usage by a factor of up to 100 compared to the alternatives, retaining or even exceeding their metrics values. The proposed approach also opens new perspectives for large-scale developments in different domains, such as large language models.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {475–485},
numpages = {11},
keywords = {Sequential recommendation, cross-entropy loss, negative sampling},
location = {Bari, Italy},
series = {RecSys '24}
}

@article{10.1145/3605210,
author = {Dong, Jun},
title = {Natural Language Processing Pretraining Language Model for Computer Intelligent Recognition Technology},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {8},
issn = {2375-4699},
url = {https://doi.org/10.1145/3605210},
doi = {10.1145/3605210},
abstract = {Computer intelligent recognition technology refers to the use of computer vision, Natural Language Processing (NLP), machine learning and other technologies to enable computers to recognize, analyze, understand and answer human language and behavior. The common applications of computer intelligent recognition technology include image recognition, NLP, face recognition, target tracking, and other fields. NLP is a field of computer science, which involves the interaction between computers and natural languages. NLP technology can be used to process, analyze and generate natural language data, such as text, voice and image. Common NLP technology applications include language translation, emotion analysis, text classification, speech recognition and question answering system. Language model is a machine learning model, which uses a large number of text data for training to learn language patterns and relationships in text data. Although the language model has made great progress in the past few years, it still faces some challenges, including: poor semantic understanding, confusion in multilingual processing, slow language processing and other shortcomings. Therefore, in order to optimize these shortcomings, this article would study the pre-training language model based on NLP technology, which aimed at using NLP technology to optimize and improve the performance of the language model, thus optimizing the computer intelligent recognition technology. The model had a higher language understanding ability and more accurate prediction ability. In addition, the model could learn language rules and structures by using a large number of corpus, so as to better understand natural language. Through experiments, it could be known that the data size and total computing time of the traditional Generative Pretrained Transformer-2 (GPT-2) language model were 10 GB and 97 hours respectively. The data size and total computing time of BERT (Bidirectional Encoder Representations from Transformer) were 12 GB and 86 hours respectively. The data size and total computing time of the pre-training language model based on NLP were 18 GB and 71 hours respectively. Obviously, the pre-training language model based on NLP had a larger data size and shorter computing time. The experimental results showed that the NLP technology could better optimize the language model and effectively improve its various capabilities. This article opened up a new development direction for computer intelligent recognition technology and provided excellent technical support for the development of language models.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {110},
numpages = {12},
keywords = {Natural Language Processing, Computer Intelligent Recognition Technology, Pre-trained Language Model, Computer Vision, Machine Learning}
}

@inproceedings{10.1145/3664647.3688992,
author = {Jin, Yizhang and Li, Jian and Zhang, Jiangning and Hu, Jianlong and Gan, Zhenye and Tan, Xin and Liu, Yong and Wang, Yabiao and Wang, Chengjie and Ma, Lizhuang},
title = {LLaVA-VSD: Large Language-and-Vision Assistant for Visual Spatial Description},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3688992},
doi = {10.1145/3664647.3688992},
abstract = {Visual Spatial Description (VSD) aims to generate texts that describe the spatial relationships between objects within images. Traditional visual spatial relationship classification (VSRC) methods typically output the spatial relationship between two objects in an image, often neglecting world knowledge and lacking general language capabilities. In this paper, we propose a Large Language-and-Vision Assistant for Visual Spatial Description, named LLaVA-VSD, which is designed for the classification, description, and open-ended description of visual spatial relationships. Specifically, the model first constructs a visual spatial instruction-following dataset using given figure-caption pairs for the three tasks. It then employs LoRA to fine-tune a Large Language and Vision Assistant for VSD, which has 13 billion parameters and supports high-resolution images. Finally, a large language model is used to refine the generated sentences, enhancing their diversity and accuracy. LLaVA-VSD demonstrates excellent multimodal conversational capabilities and can follow open-ended instructions to assist with inquiries about object relationships in images.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11420–11425},
numpages = {6},
keywords = {fine-tuning, instruction tuning, llm, multimodal, prompt engineering, visual spatial description},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3689736,
author = {Yang, Chenyuan and Deng, Yinlin and Lu, Runyu and Yao, Jiayi and Liu, Jiawei and Jabbarvand, Reyhaneh and Zhang, Lingming},
title = {WhiteFox: White-Box Compiler Fuzzing Empowered by Large Language Models},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689736},
doi = {10.1145/3689736},
abstract = {Compiler correctness is crucial, as miscompilation can falsify program behaviors, leading to serious consequences over the software supply chain. In the literature, fuzzing has been extensively studied to uncover compiler defects. However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates test programs without sufficient understanding of internal compiler behaviors. As such, they often fail to construct test programs to exercise intricate optimizations. Meanwhile, traditional white-box techniques, such as symbolic execution, are computationally inapplicable to the giant codebase of compiler systems. Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and even have achieved state-of-the-art performance in black-box fuzzing. Nonetheless, guiding LLMs with compiler source-code information remains a missing piece of research in compiler testing.
 
 
 
 
 
 
 

 
 
 
 
 
 
 
To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization, with a spotlight on detecting deep logic bugs in the emerging deep learning (DL) compilers. WhiteFox adopts a multi-agent framework: (i) an LLM-based analysis agent examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) an LLM-based generation agent produces test programs based on the summarized requirements. Additionally, optimization-triggering tests are also used as feedback to further enhance the test generation prompt on the fly. Our evaluation on the three most popular DL compilers (i.e., PyTorch Inductor, TensorFlow-XLA, and TensorFlow Lite) shows that WhiteFox can generate high-quality test programs to exercise deep optimizations requiring intricate conditions, practicing up to 8 times more optimizations than state-of-the-art fuzzers. To date, WhiteFox has found in total 101 bugs for the compilers under test, with 92 confirmed as previously unknown and 70 already fixed. Notably, WhiteFox has been recently acknowledged by the PyTorch team, and is in the process of being incorporated into its development workflow. Finally, beyond DL compilers, WhiteFox can also be adapted for compilers in different domains, such as LLVM, where WhiteFox has already found multiple bugs.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {296},
numpages = {27},
keywords = {Code Analysis, Fuzzing, Large Language Models, White-box Testing}
}

@inproceedings{10.1145/3613905.3636316,
author = {Jiang, Yue and Lu, Yuwen and Knearem, Tiffany and Kliman-Silver, Clara E and Lutteroth, Christof and Li, Toby Jia-Jun and Nichols, Jeffrey and Stuerzlinger, Wolfgang},
title = {Computational Methodologies for Understanding, Automating, and Evaluating User Interfaces},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636316},
doi = {10.1145/3613905.3636316},
abstract = {Building on the success of the first two workshops on user interfaces (UIs) at CHI 2022 and CHI 2023, this workshop aims to advance the research field by further exploring current research trends, such as applying large language models and visual language models. Previous work has explored computational approaches to understanding and adapting UIs using constraint-based optimization models and machine learning-based data-driven approaches. In addition to further delving into these established UI research areas, we aim to trigger the exploration into the application of the latest advancements in general-purpose large language and vision-language models within the UI domain. We will encourage participants to explore novel methods for understanding, automating, and evaluating UIs. The proposed workshop seeks to bring together academic researchers and industry practitioners interested in computational approaches for UIs to discuss the needs and opportunities for future user interface algorithms, models, and applications.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {462},
numpages = {7},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3644815.3644948,
author = {Rasool, Zafaryab and Barnett, Scott and Willie, David and Kurniawan, Stefanus and Balugo, Sherwin and Thudumu, Srikanth and Abdelrazek, Mohamed},
title = {LLMs for Test Input Generation for Semantic Applications},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644948},
doi = {10.1145/3644815.3644948},
abstract = {Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {160–165},
numpages = {6},
keywords = {large language model, query evaluation, question answering, semantic cache, test input generation},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1109/ASE56229.2023.00047,
author = {Xia, Chunqiu Steven and Ding, Yifeng and Zhang, Lingming},
title = {The Plastic Surgery Hypothesis in the Era of Large Language Models},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00047},
doi = {10.1109/ASE56229.2023.00047},
abstract = {Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients. However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored. In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs? Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning (training on the buggy project) and prompting (directly providing valuable code ingredients as hints to the LLM). To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy (via information retrieval and static analysis) for more powerful APR. While traditional APR techniques require intensive manual efforts in both generating patches based on the plastic surgery hypothesis and guaranteeing patch validity, our approach is fully automated and general. Moreover, while it is very challenging to manually design heuristics/patterns for effectively leveraging the hypothesis, due to the power of LLMs in code vectorization/understanding, even partial/imprecise project-specific information can still guide LLMs in generating correct patches! Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming baseline techniques by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {522–534},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@article{10.1145/3699773,
author = {Gao, Yang and Zhang, Wenbo and Ren, Junbin and Zheng, Ruihao and Jin, Yingcheng and Wu, Di and Shu, Lin and Xu, Xiangmin and Jin, Zhanpeng},
title = {PressInPose: Integrating Pressure and Inertial Sensors for Full-Body Pose Estimation in Activities},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699773},
doi = {10.1145/3699773},
abstract = {The accurate assessment of human body posture through wearable technology has significant implications for sports science, clinical diagnostics, rehabilitation, and VR interaction. Traditional methods often require complex setups or are limited by the environment's constraints. In response to these challenges, this paper presents an innovative approach to human posture estimation under complex motion scenarios through the development of an advanced shoe insole embedded with pressure sensors and an Inertial Measurement Unit (IMU). Coupled with a single wrist-mounted IMU, our system facilitates a comprehensive analysis of human biomechanics by integrating physical kinematics modeling based on pressure data with a multi-region human posture estimation network. To enhance the robustness of our system model, we employed large language models to generate virtual human motion sequences. These sequences were utilized to create synthetic IMU data for data augmentation purposes, addressing the challenge of limited real-world data availability and variability. Our approach uniquely combines physical modeling with data-driven techniques to improve the accuracy and reliability of posture estimation. Experimental results demonstrate that our integrated system significantly advances wearable technology for motion analysis. The Mean Per Joint Position Error (MPJPE) was reduced to 7.75 cm, highlighting the effectiveness of our multi-modal modeling and virtual data augmentation in refining posture estimation.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {197},
numpages = {28},
keywords = {IMU, body pose estimation, pressure sensing, smart shoe}
}

@inproceedings{10.1145/3627673.3679581,
author = {Tang, Zuoli and Huan, Zhaoxin and Li, Zihao and Hu, Shirui and Zhang, Xiaolu and Zhou, Jun and Zou, Lixin and Li, Chenliang},
title = {TEXT CAN BE FAIR: Mitigating Popularity Bias with PLMs by Learning Relative Preference},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679581},
doi = {10.1145/3627673.3679581},
abstract = {Recently, the item textual information has been exploited with pre-trained language models (PLMs) to enrich the representations of tail items. The underlying idea is to align the hot items and tail items in terms of the external semantic knowledge covered by the PLM. However, it is non-trivial to eliminate the popularity bias by exploiting the textual semantics. One major obstacle is that the model supervision still counts on the sparse yet binary user behaviors. In the preliminary investigation, we discover that text-based recommendations also suffer from the popularity bias.To this end, we propose a novel self-distillation framework based on a pre-trained language model, named Staple. The proposed Staple consists of two main components: ranker model and recommender model, which are both instantiated as a PLM towards exploiting the item textual semantics. Motivated by the recent success of reinforcement learning with human feedback (RLHF), the proposed Staple aims to recover the relative preference by learning a fair ranker model that can successfully distinguish the preference levels for uninteracted items. Specifically, analogous to the training of large language models (LLMs), we introduce a pre-training and a fair supervised fine-tuning with a decoupled layer to build the ranker model. Then, similar to RLHF for LLM training, we utilize the relative preference information estimated by the ranker over candidate items to complement the learning of the recommender model. We show that this RLHF process can be reformed as an efficient distillation learning process. We conduct extensive experiments on three real-world datasets. In addition to the performance metrics, we employ two additional metrics to measure fairness and debiased performance. The experiments show that our method can significantly improve the item exposure fairness of recommendation and mitigate popularity bias, while also improving the recommendation performance. The source code is available at https://github.com/WHUIR/STAPLE.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2240–2249},
numpages = {10},
keywords = {popularity bias, sequential recommendation, text-based recommendation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3664646.3665664,
author = {Vijayvergiya, Manushree and Salawa, Ma\l{}gorzata and Budiseli\'{c}, Ivan and Zheng, Dan and Lamblin, Pascal and Ivankovi\'{c}, Marko and Carin, Juanjo and Lewko, Mateusz and Andonov, Jovan and Petrovi\'{c}, Goran and Tarlow, Daniel and Maniatis, Petros and Just, Ren\'{e}},
title = {AI-Assisted Assessment of Coding Practices in Modern Code Review},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3665664},
doi = {10.1145/3664646.3665664},
abstract = {Modern code review is a process in which an incremental code contribution made by a code author is reviewed by one or more peers before it is committed to the version control system. An important element of modern code review is verifying that code contributions adhere to best practices. While some of these best practices can be automatically verified, verifying others is commonly left to human reviewers. This paper reports on the development, deployment, and evaluation of AutoCommenter, a system backed by a large language model that automatically learns and enforces coding best practices. We implemented AutoCommenter for four programming languages (C++, Java, Python, and Go) and evaluated its performance and adoption in a large industrial setting. Our evaluation shows that an end-to-end system for learning and enforcing coding best practices is feasible and has a positive impact on the developer workflow. Additionally, this paper reports on the challenges associated with deploying such a system to tens of thousands of developers and the corresponding lessons learned.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {85–93},
numpages = {9},
keywords = {Artificial Intelligence, Code Review, Coding Best Practices},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@article{10.1145/3643762,
author = {Wadhwa, Nalin and Pradhan, Jui and Sonwane, Atharv and Sahu, Surya Prakash and Natarajan, Nagarajan and Kanade, Aditya and Parthasarathy, Suresh and Rajamani, Sriram},
title = {CORE: Resolving Code Quality Issues using LLMs},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643762},
doi = {10.1145/3643762},
abstract = {As software projects progress, quality of code assumes paramount importance as it affects reliability, maintainability and security of software. For this reason, static analysis tools are used in developer workflows to flag code quality issues. However, developers need to spend extra efforts to revise their code to improve code quality based on the tool findings. In this work, we investigate the use of (instruction-following) large language models (LLMs) to assist developers in revising code to resolve code quality issues.    We present a tool, CORE (short for COde REvisions), architected using a pair of LLMs organized as a duo comprised of a proposer and a ranker. Providers of static analysis tools recommend ways to mitigate the tool warnings and developers follow them to revise their code. The proposer LLM of CORE takes the same set of recommendations and applies them to generate candidate code revisions. The candidates which pass the static quality checks are retained. However, the LLM may introduce subtle, unintended functionality changes which may go un-detected by the static analysis. The ranker LLM evaluates the changes made by the proposer using a rubric that closely follows the acceptance criteria that a developer would enforce. CORE uses the scores assigned by the ranker LLM to rank the candidate revisions before presenting them to the developer.    We conduct a variety of experiments on two public benchmarks to show the ability of CORE:  (1) to generate code revisions acceptable to both static analysis tools and human reviewers (the latter evaluated with user study on a subset of the Python benchmark),  (2) to reduce human review efforts by detecting and eliminating revisions with unintended changes,  (3) to readily work across multiple languages (Python and Java), static analysis tools (CodeQL and SonarQube) and quality checks (52 and 10 checks, respectively),  and  (4) to achieve fix rate comparable to a rule-based automated program repair tool but with much smaller engineering efforts (on the Java benchmark).  CORE could revise 59.2% Python files (across 52 quality checks) so that they pass scrutiny by both a tool and a human reviewer. The ranker LLM reduced false positives by 25.8% in these cases. CORE produced revisions that passed the static analysis tool in 76.8% Java files (across 10 quality checks) comparable to 78.3% of a specialized program repair tool, with significantly much less engineering efforts. We release code, data, and supplementary material publicly at http://aka.ms/COREMSRI.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {36},
numpages = {23},
keywords = {Code quality, LLMs, code revision, static analysis}
}

@article{10.1109/TASLP.2024.3490373,
author = {Li, Ren and Xiao, Qiao and Yang, Jianxi and Zhang, Luyi and Chen, Yu},
title = {MRC-PASCL: A Few-Shot Machine Reading Comprehension Approach via Post-Training and Answer Span-Oriented Contrastive Learning},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3490373},
doi = {10.1109/TASLP.2024.3490373},
abstract = {The rapid development of pre-trained language models (PLMs) has significantly enhanced the performance of machine reading comprehension (MRC). Nevertheless, the traditional fine-tuning approaches necessitate extensive labeled data. MRC remains a challenging task in the few-shot settings or low-resource scenarios. This study proposes a novel few-shot MRC approach via post-training and answer span-oriented contrastive learning, termed MRC-PASCL. Specifically, in the post-training module, a novel noun-entity-aware data selection and generation strategy is proposed according to characteristics of MRC task and data, focusing on masking nouns and named entities in the context. In terms of fine-tuning, the proposed answer span-oriented contrastive learning manner selects spans around the golden answers as negative examples, and performs multi-task learning together with the standard MRC answer prediction task. Experimental results show that MRC-PASCL outperforms the PLMs-based baseline models and the 7B and 13B large language models (LLMs) cross most MRQA 2019 datasets. Further analyses show that our approach achieves better inference efficiency with lower computational resource requirement. The analysis results also indicate that the proposed method can better adapt to the domain-specific scenarios.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4838–4849},
numpages = {12}
}

@article{10.1145/3672458,
author = {Huang, Qing and Luo, Zhiwen and Xing, Zhenchang and Zeng, Jinshan and Chen, Jieshan and Xu, Xiwei and Chen, Yong},
title = {Revealing the Unseen: AI Chain on LLMs for Predicting Implicit Dataflows to Generate Dataflow Graphs in Dynamically Typed Code},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3672458},
doi = {10.1145/3672458},
abstract = {Dataflow graphs (DFGs) capture definitions (defs) and uses across program blocks, which is a fundamental program representation for program analysis, testing and maintenance. However, dynamically typed programming languages like Python present implicit dataflow issues that make it challenging to determine def-use flow information at compile time. Static analysis methods like Soot and WALA are inadequate for handling these issues, and manually enumerating comprehensive heuristic rules is impractical. Large pre-trained language models (LLMs) offer a potential solution, as they have powerful language understanding and pattern matching abilities, allowing them to predict implicit dataflow by analyzing code context and relationships between variables, functions, and statements in code. We propose leveraging LLMs’ in-context learning ability to learn implicit rules and patterns from code representation and contextual information to solve implicit dataflow problems. To further enhance the accuracy of LLMs, we design a five-step chain of thought (CoT) and break it down into an Artificial Intelligence (AI) chain, with each step corresponding to a separate AI unit to generate accurate DFGs for Python code. Our approach’s performance is thoroughly assessed, demonstrating the effectiveness of each AI unit in the AI Chain. Compared to static analysis, our method achieves 82% higher def coverage and 58% higher use coverage in DFG generation on implicit dataflow. We also prove the indispensability of each unit in the AI Chain. Overall, our approach offers a promising direction for building software engineering tools by utilizing foundation models, eliminating significant engineering and maintenance effort, but focusing on identifying problems for AI to solve.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {183},
numpages = {29},
keywords = {Dataflow graph, AI chain, Large Language Models}
}

@article{10.5555/3715622.3715633,
author = {Zuo, Fei and Tompkins, Cody and Qian, Gang and Rhee, Junghwan and Qu, Xianshan and Yang, Bokai},
title = {ChatGPT as an Assembly Language Interpreter for Computing Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {Assembly language is a low-level programming language useful for a number of important computing areas, such as hardware and embedded systems programming, computer architecture, reverse engineering, and malware analysis. In recent years, generative AI, enhanced by GPT technology, has been widely adopted in the IT industry as well as computing education. However, little work has been done to investigate the applicability of GPT to teaching assembly language. In this paper, we fill in the gap by providing an empirical study of GPT's ability to interpret assembly instructions. In particular, we manually evaluated GPT-4's per-instruction explanations of code segments for four different computer architectures, namely x86, x86-64, ARM, and AArch64. Our study shows that, while inconsistencies and rare errors do exist, GPT's interpretations are highly accurate in general, demonstrating a great potential for such tools to be applied in pedagogical practices for tutoring assembly language.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {73–82},
numpages = {10}
}

@inproceedings{10.1145/3650212.3680397,
author = {Yu, Zeliang and Wen, Ming and Guo, Xiaochen and Jin, Hai},
title = {Maltracker: A Fine-Grained NPM Malware Tracker Copiloted by LLM-Enhanced Dataset},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680397},
doi = {10.1145/3650212.3680397},
abstract = {As the largest package registry, Node Package Manager (NPM) has become the prime target for various supply chain attacks recently and has been flooded with numerous malicious packages, posing significant security risks to end-users. Learning-based methods have demonstrated promising performance with good adaptability to various types of attacks. However, they suffer from two main limitations. First, they often utilize metadata features or coarse-grained code features extracted at the package level while overlooking complex code semantics. Second, the dataset used to train the model often suffers from a lack of variety both in quantity and diversity, and thus cannot detect significant types of attacks.
 
 
 

 
 
 
To address these problems, we introduce Maltracker, a learningbased NPM malware tracker based on fine-grained features empowered by LLM-enhanced dataset. First, Maltracker constructs precise call graphs to extract suspicious functions that are reachable to a pre-defined set of sensitive APIs, and then utilizes community detection algorithm to identify suspicious code gadgets based on program dependency graph, from which fine-grained features are then extracted. To address the second limitation, we extend the dataset using advanced large language models (LLM) to translate malicious functions from other languages (e.g., C/C++, Python, and Go) into JavaScript. Evaluations shows that Maltracker can achieve an improvement of about 12.6% in terms of F1-score at the package level and 31.0% at the function level compared with the SOTA learning-based methods. Moreover, the key components of 𝑀𝑎𝑙𝑡𝑟𝑎𝑐𝑘𝑒𝑟 all contribute to the effectiveness of its performance. Finally, Maltracker has also detected 230 new malicious packages in NPM and received 61 thanks letters, among which some contain new malicious behaviors that cannot be detected by existing tools.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1759–1771},
numpages = {13},
keywords = {Code Translation, Large Language Model, Malware Detection},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1109/TASLP.2024.3485485,
author = {Xue, Jinlong and Deng, Yayue and Gao, Yingming and Li, Ya},
title = {Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3485485},
doi = {10.1109/TASLP.2024.3485485},
abstract = {Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of generation tasks. Text-to-Audio (TTA), a burgeoning generation application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resources. Furthermore, the text encoder serves as a critical bridge between text and audio, since it acts as an instruction for the diffusion model to generate coherent content. Previous studies in T2I recognize the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lacking in prior TTA works. Through comprehensive ablation studies and innovative cross-attention map visualizations, we provide insightful assessments, being the first to reveal the internal mechanisms in the TTA field and intuitively explain how different text encoders influence the diffusion process. Our findings reveal Auffusion's superior capability in generating audios that accurately match textual descriptions, which is further demonstrated in several related tasks, such as audio style transfer, inpainting, and other manipulations.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4700–4712},
numpages = {13}
}

@inproceedings{10.1145/3620666.3651380,
author = {Heo, Guseul and Lee, Sangyeop and Cho, Jaehong and Choi, Hyunmin and Lee, Sanghyeon and Ham, Hyungkyu and Kim, Gwangsun and Mahajan, Divya and Park, Jongse},
title = {NeuPIMs: NPU-PIM Heterogeneous Acceleration for Batched LLM Inferencing},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3651380},
doi = {10.1145/3620666.3651380},
abstract = {Modern transformer-based Large Language Models (LLMs) are constructed with a series of decoder blocks. Each block comprises three key components: (1) QKV generation, (2) multi-head attention, and (3) feed-forward networks. In batched processing, QKV generation and feed-forward networks involve compute-intensive matrix-matrix multiplications (GEMM), while multi-head attention requires bandwidth-heavy matrix-vector multiplications (GEMV). Machine learning accelerators like TPUs or NPUs are proficient in handling GEMM but are less efficient for GEMV computations. Conversely, Processing-in-Memory (PIM) technology is tailored for efficient GEMV computation, while it lacks the computational power to handle GEMM effectively.Inspired by this insight, we propose NeuPIMs, a heterogeneous acceleration system that jointly exploits a conventional GEMM-focused NPU and GEMV-optimized PIM devices. The main challenge in efficiently integrating NPU and PIM lies in enabling concurrent operations on both platforms, each addressing a specific kernel type. First, existing PIMs typically operate in a "blocked" mode, allowing only either NPU or PIM to be active at any given time. Second, the inherent dependencies between GEMM and GEMV in LLMs restrict their parallel processing. To tackle these challenges, NeuPIMs is equipped with dual row buffers in each bank, facilitating the simultaneous management of memory read/write operations and PIM commands. Further, NeuPIMs employs a runtime sub-batch interleaving technique to maximize concurrent execution, leveraging batch parallelism to allow two independent sub-batches to be pipelined within a single NeuPIMs device. Our evaluation demonstrates that compared to GPU-only, NPU-only, and a na\"{\i}ve NPU+PIM integrated acceleration approaches, NeuPIMs achieves 3\texttimes{}, 2.4\texttimes{} and 1.6\texttimes{} throughput improvement, respectively.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {722–737},
numpages = {16},
keywords = {processing-in-memory (PIM), neural processing unit (NPU), heterogeneous system, large language model (LLM), inference serving, transformer-based generative model (GPT)},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1145/3589335.3651582,
author = {Tania, Nishat Ara and Masud, Md Rayhanul and Rokon, Md Omar Faruk and Zhang, Qian and Faloutsos, Michalis},
title = {Who is Creating Malware Repositories on GitHub and Why?},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651582},
doi = {10.1145/3589335.3651582},
abstract = {Recent studies have found thousands of malware source code repositories on GitHub. For the first time, we propose to understand the origins and motivations behind the creation of such malware repositories. For that, we collect and profile the authors of malware repositories using a three-fold systematic approach. First, we identify 14K users in GitHub who have authored at least one malware repository. Second, we leverage a pretrained large language model (LLM) to estimate the likelihood of malicious intent of these authors. This innovative approach led us to categorize 3339 as Malicious, 3354 as Likely Malicious, and 7574 as Benign authors. Further, to validate the accuracy and reliability of our classification, we conduct a manual review of 200 randomly selected authors. Third, our analysis provides insights into the authors' profiles and motivations. We find that Malicious authors often have sparse profiles and focus on creating and spreading malware, while Benign authors typically have complete profiles with a focus on cybersecurity research and education. Likely Malicious authors show varying levels of engagement and ambiguous intentions. We see our study as a key step towards understanding the ecosystem of malware authorship on GitHub.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {955–958},
numpages = {4},
keywords = {classification, github, hacker, llm, malware, repository, user},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3689218.3689221,
author = {Kong, Xiangxing and Li, Yangyang and Fan, Manyi and Shi, Jiayi and Wei, Lingxiang and Qu, Shaojie},
title = {Automated Knowledge Mining and Knowledge Graph Reasoning for Aircraft Engine Maintenance},
year = {2024},
isbn = {9798400718250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689218.3689221},
doi = {10.1145/3689218.3689221},
abstract = {The maintenance process for aircraft engines is fraught with significant challenges due to their inherent complexity. Large Language Models excel in general Natural Language Processing tasks, yet they lack domain-specific knowledge, thereby compromising their performance in specialized areas. The varied descriptions of engine faults also render traditional text matching algorithms unsuitable for this maintenance domain. In this paper, we construct a knowledge graph integrated with fault diagnosis reasoning ability with knowledge mined from aircraft engine maintenance data. Firstly, we propose the Knowledge Mining and Knowledge Graph Reasoning framework for aircraft engine maintenance data knowledge mining and aircraft engine fault diagnosis. Secondly, we utilize prompt with in-context learning to mitigate the issue of the model lacking expertise in the field of aircraft engine maintenance. Finally, we adopt a sentence similarity calculation method based on BERT, which enables more effective processing of semantic information. We apply our method to Aircraft Engine Fault dataset which is collected from maintenance records of civil aircraft engine since 2007 to 2015, and experimental results demonstrate the effectiveness of our knowledge mining method and aircraft engine fault reasoning algorithm.},
booktitle = {Proceedings of the 2024 6th International Conference on Pattern Recognition and Intelligent Systems},
pages = {35–40},
numpages = {6},
keywords = {aircraft engine maintenance, knowledge graph reasoning, large language model},
location = {Hong Kong, Hong Kong},
series = {PRIS '24}
}

@article{10.1145/3659601,
author = {Wang, Yufei and Zeng, Wenting and Liu, Changzhen and Ye, Zhuohan and Sun, Jiawei and Ji, Junxiang and Jiang, Zhihan and Yan, Xianyi and Wu, Yongyi and Wang, Yigao and Yang, Dingqi and Wang, Leye and Zhang, Daqing and Wang, Cheng and Chen, Longbiao},
title = {CrowdBot: An Open-Environment Robot Management System for On-Campus Services},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659601},
doi = {10.1145/3659601},
abstract = {In contemporary campus environments, the provision of timely and efficient services is increasingly challenging due to limitations in accessibility and the complexity and openness of the environment. Existing service robots, while operational, often struggle with adaptability and dynamic task management, leading to inefficiencies. To overcome these limitations, we introduce CrowdBot, a robot management system that enhances service in campus environments. Our system leverages a hierarchical reinforcement learning-based cloud-edge hybrid scheduling framework (REDIS), for efficient online streaming task assignment and dynamic action scheduling. To verify the REDIS framework, we have developed a digital twin simulation platform, which integrates large language models and hot-swapping technology. This facilitates seamless human-robot interaction, efficient task allocation, and cost-effective execution through the reuse of robot equipment. Our comprehensive simulations corroborate the system's remarkable efficacy, demonstrating significant improvements with a 24.46% reduction in task completion times, a 9.37% decrease in travel distances, and up to a 3% savings in power usage. Additionally, the system achieves a 7.95% increase in the number of tasks completed and a 9.49% reduction in response time. Real-world case studies further affirm CrowdBot's capability to adeptly execute tasks and judiciously recycle resources, thereby offering a smart and viable solution for the streamlined management of campus services.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {80},
numpages = {27},
keywords = {crowdsensing, dynamic task schedule, equipment-swappable robots, online streaming task assignment, reinforcement learning, robot management}
}

@article{10.1145/3664606,
author = {Ma, Wei and Liu, Shangqing and Zhao, Mengjie and Xie, Xiaofei and Wang, Wenhang and Hu, Qiang and Zhang, Jie and Liu, Yang},
title = {Unveiling Code Pre-Trained Models: Investigating Syntax and Semantics Capacities},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {7},
issn = {1049-331X},
url = {https://doi.org/10.1145/3664606},
doi = {10.1145/3664606},
abstract = {Code models have made significant advancements in code intelligence by encoding knowledge about programming languages. While previous studies have explored the capabilities of these models in learning code syntax, there has been limited investigation on their ability to understand code semantics. Additionally, existing analyses assume that the number of edges between nodes at the abstract syntax tree&nbsp;(AST) is related to syntax distance, and also often require transforming the high-dimensional space of deep learning models to a low-dimensional one, which may introduce inaccuracies. To study how code models represent code syntax and semantics, we conduct a comprehensive analysis of seven code models, including four representative code pre-trained models (CodeBERT, GraphCodeBERT, CodeT5, and UnixCoder) and three large language models (LLMs) (StarCoder, CodeLlama and CodeT5+). We design four probing tasks to assess the models’ capacities in learning both code syntax and semantics. These probing tasks reconstruct code syntax and semantics structures (AST, control dependence graph (CDG), data dependence graph (DDG), and control flow graph (CFG)) in the representation space. These structures are core concepts for code understanding. We also investigate the syntax token role in each token representation and the long dependency between the code tokens. Additionally, we analyze the distribution of attention weights related to code semantic structures. Through extensive analysis, our findings highlight the strengths and limitations of different code models in learning code syntax and semantics. The results demonstrate that these models excel in learning code syntax, successfully capturing the syntax relationships between tokens and the syntax roles of individual tokens. However, their performance in encoding code semantics varies. CodeT5 and CodeBERT demonstrate proficiency in capturing control and data dependencies, whereas UnixCoder shows weaker performance in this aspect. We do not observe LLMs generally performing much better than pre-trained models. The shallow layers of LLMs perform better than their deep layers. The investigation of attention weights reveals that different attention heads play distinct roles in encoding code semantics. Our research findings emphasize the need for further enhancements in code models to better learn code semantics. This study contributes to the understanding of code models’ abilities in syntax and semantics analysis. Our findings provide guidance for future improvements in code models, facilitating their effective application in various code-related tasks.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = aug,
articleno = {169},
numpages = {29},
keywords = {Code model analysis, syntax and semantic encoding}
}

@inproceedings{10.1145/3627673.3680117,
author = {Xu, Anbang and Yu, Tan and Du, Min and Gundecha, Pritam and Guo, Yufan and Zhu, Xinliang and Wang, May and Li, Ping and Chen, Xinyun},
title = {Generative AI and Retrieval-Augmented Generation (RAG) Systems for Enterprise},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680117},
doi = {10.1145/3627673.3680117},
abstract = {This workshop introduces generative AI applications for enterprise, with a focus on retrieval-augmented generation (RAG) systems. Generative AI is a field of artificial intelligence that can create new content and solve complex problems. RAG systems are a novel generative AI technique that combines information retrieval with text generation to generate rich and diverse responses. RAG systems can leverage enterprise data, which is often specific, structured, and dynamic, to provide customized solutions for various domains. However, enterprise data also poses challenges such as scalability, security, and data quality. This workshop convenes researchers and practitioners to explore RAG and other generative AI systems in real-world enterprise scenarios, fostering knowledge exchange, collaboration, and identification of future directions. Relevant to the CIKM community, the workshop intersects with core areas of data science and machine learning, offering potential benefits across various domains.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5599–5602},
numpages = {4},
keywords = {enterprise application, generation, rag, retrieval},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3648471,
author = {Wang, Jiajia and Huang, Jimmy Xiangji and Tu, Xinhui and Wang, Junmei and Huang, Angela Jennifer and Laskar, Md Tahmid Rahman and Bhuiyan, Amran},
title = {Utilizing BERT for Information Retrieval: Survey, Applications, Resources, and Challenges},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3648471},
doi = {10.1145/3648471},
abstract = {Recent years have witnessed a substantial increase in the use of deep learning to solve various natural language processing (NLP) problems. Early deep learning models were constrained by their sequential or unidirectional nature, such that they struggled to capture the contextual relationships across text inputs. The introduction of bidirectional encoder representations from transformers (BERT) leads to a robust encoder for the transformer model that can understand the broader context and deliver state-of-the-art performance across various NLP tasks. This has inspired researchers and practitioners to apply BERT to practical problems, such as information retrieval (IR). A survey that focuses on a comprehensive analysis of prevalent approaches that apply pretrained transformer encoders like BERT to IR can thus be useful for academia and the industry. In light of this, we revisit a variety of BERT-based methods in this survey, cover a wide range of techniques of IR, and group them into six high-level categories: (i) handling long documents, (ii) integrating semantic information, (iii) balancing effectiveness and efficiency, (iv) predicting the weights of terms, (v) query expansion, and (vi) document expansion. We also provide links to resources, including datasets and toolkits, for BERT-based IR systems. Additionally, we highlight the advantages of employing encoder-based BERT models in contrast to recent large language models like ChatGPT, which are decoder-based and demand extensive computational resources. Finally, we summarize the comprehensive outcomes of the survey and suggest directions for future research in the area.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {185},
numpages = {33},
keywords = {BERT, information retrieval, natural language processing, artificial intelligence}
}

@inproceedings{10.1145/3700906.3701004,
author = {He, Qinyuan and Du, Nanxin and Yu, Huapeng and Yang, Xiaozhuo},
title = {Adaptive Deep Learning Algorithm Design for Diverse Inertial Navigation Systems},
year = {2024},
isbn = {9798400707032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700906.3701004},
doi = {10.1145/3700906.3701004},
abstract = {This paper aims to study the design of deep learning adaptive algorithms for different types of inertial navigation systems. Underwater inertial navigation plays a crucial role in fields such as ocean exploration, but improving its accuracy faces challenges, and combined navigation methods are often adopted. Deep learning is widely applied in inertial navigation, which can be used for sensor data processing, positioning, attitude estimation, and can also be combined with other navigation technologies. Based on previous research, this paper delves into the characteristics of different inertial navigation devices, combines with large language models, and proposes an LLM-based adaptive parameter selection expert system. This system can select appropriate deep learning network parameters based on parameters such as the material, accuracy, and service life of the inertial navigation device to ensure the matching between the model and the inertial navigation device. The network design is divided into a displacement prediction module and a heading angle prediction module, and different targeted designs are adopted. The experiment was conducted in the Yellow Sea, equipped with strapdown fiber optic inertial navigation systems and strapdown laser inertial navigation systems, and targeted training was carried out according to the characteristics of the two sets of systems. The fiber optic inertial navigation system has an earlier factory time and a large data scale; the laser inertial navigation system has a recent factory time and high accuracy. The experimental results show that the error is significantly suppressed after adopting the deep learning algorithm, and it is feasible to use the expert system to drive the setting of targeted parameters, which has the value of promotion and research.},
booktitle = {Proceedings of the International Conference on Image Processing, Machine Learning and Pattern Recognition},
pages = {609–615},
numpages = {7},
keywords = {AUV, Deep learning, Underwater navigation},
location = {
},
series = {IPMLP '24}
}

@inproceedings{10.1145/3632634.3655852,
author = {Aladi, Clement Chimezie},
title = {IT Higher Education Teachers and Trust in AI-Enabled Ed-Tech: Implications for Adoption of AI in Higher Education},
year = {2024},
isbn = {9798400704772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632634.3655852},
doi = {10.1145/3632634.3655852},
abstract = {The integration of Artificial Intelligence (AI) in higher education encounters a myriad of inhibiting factors, notably the conspicuous absence of transparency, reliability issues, and ethical concerns. This problem has substantially impeded the assimilation of generative AI-enabled Educational Technology (Ed-Tech) within the higher education domain, unlike other fields such as finance, health, and management. The prevailing sentiment among higher education practitioners remains wavering, with differing opinions on whether to permit AI comprehensively, impose complete restrictions, or allow minimal integration into academic courses. This pilot study endeavors to elucidate the nuanced determinants influencing cognitive trust of Information Technology (IT) Higher Education instructors in AI-enabled educational Technology. The implications of this trust, or lack thereof, on the broader adoption of AI in higher education, constitute a focal point of investigation in this scholarly investigation.},
booktitle = {Proceedings of the 2024 Computers and People Research Conference},
articleno = {19},
numpages = {16},
keywords = {AI-enabled, EdTech, Educational Technology, Higher Education, Keywords: AI, Trust},
location = {Murfreesboro, TN, USA},
series = {SIGMIS-CPR '24}
}

@inproceedings{10.1145/3678726.3678745,
author = {Wu, Chih-Hung and Liou, Guang-Mei},
title = {ARCS Model for Exploring the Enhancement of Learning Motivation and Engagement through AIGC Technology in Computer Graphics Courses},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678745},
doi = {10.1145/3678726.3678745},
abstract = {The purpose of this study is to apply the Keller ARCS Motivation Model theory to the "Computer Graphics" course. In the learning process of computer graphics courses, generating images using generative AI and then modifying them is employed to arouse students' interest and enhance their learning engagement. The aim of this research is to analyze the interest generated by the course through experimental results of curriculum design. Most students show a high level of interest in the integration of generative AI into the course, while a very small minority express dislike for generating images in this manner. The findings confirm that integrating generative AI into computer graphics courses can increase student interest in learning.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {51–59},
numpages = {9},
keywords = {AIGC, ARCS, Learning Interest},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3658321.3658367,
author = {Santos, Patricia de Oliveira and Figueiredo, Allan Chamon and Nuno Moura, Pedro and Diirr, Bruna and Alvim, Adriana C. F. and Santos, Rodrigo Pereira Dos},
title = {How Do Information Technology Professionals Use Generative Artificial Intelligence?},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658321.3658367},
doi = {10.1145/3658321.3658367},
abstract = {Context: The emergence of generative Artificial Intelligence (AI) and, more recently, the dissemination of Copilot, ChatGPT-3 and similar tools have broadened the discussion about the possibility of using generative AI tools in many professional segments such as health, education, and technological area. Problem: Although some studies explore the potential of generative AI tools to assist Information Technology (IT) professionals in executing specific tasks, they do not delve into the professionals’ characteristics or collect information about multiple generative AI tools usage. Solution: Considering the possibilities brought by generative AI, this study aims to shed light on the perception of IT professionals about generative AI tools and characterize these professionals’ profiles. IS Theory: This research is based on the Technology Acceptance Model. Method: A survey research was carried out with IT professionals so as to identify how these professionals are using generative AI and gather information about these professionals’ profiles. Results: Results show that 70,5% (43 out of 61) of the respondents use some generative AI tool, the majority of whom are software development professionals, and, despite the problems faced when using these tools, 86% of these professionals recommend using them. Contribution: In this study the profile of the IT professionals using generative AI was identified, it was then possible to evaluate the acceptance of such tools among these professionals and identify the main reasons why some of them are not yet using generative AI.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {56},
numpages = {9},
keywords = {Generative AI, IT Professional, Survey},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3637528.3671466,
author = {Deng, Songgaojun and de Rijke, Maarten and Ning, Yue},
title = {Advances in Human Event Modeling: From Graph Neural Networks to Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671466},
doi = {10.1145/3637528.3671466},
abstract = {Human events such as hospital visits, protests, and epidemic outbreaks directly affect individuals, communities, and societies. These events are often influenced by factors such as economics, politics, and public policies of our society. The abundance of online data sources such as social networks, official news articles, and personal blogs chronicle societal events, facilitating the development of AI models for social science, public health care, and decision making. Human event modeling generally comprises both the forecasting stage, which estimates future events based on historical data, and interpretation, which seeks to identify influential factors of such events to understand their causative attributes. Recent achievements, fueled by deep learning and the availability of public data, have significantly advanced the field of human event modeling.This survey offers a systematic overview of deep learning technologies for forecasting and interpreting human events, with a primary focus on political events. We first introduce the existing challenges and background in this domain. We then present the problem formulation of event forecasting and interpretation. We investigate recent achievements in graph neural networks, owing to the prevalence of relational data and the efficacy of graph learning models. We also discuss the latest studies that utilize large language models for event reasoning. Lastly, we provide summaries of data resources, open challenges, and future research directions in the study of human event modeling.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6459–6469},
numpages = {11},
keywords = {event forecasting, graph neural networks, language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3709364,
author = {Min, Do June and P\'{e}rez-Rosas, Ver\'{o}nica and Resnicow, Kenneth and Mihalcea, Rada},
title = {Evaluating Language Models for Assessing Counselor Reflections},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709364},
doi = {10.1145/3709364},
abstract = {Reflective listening is a fundamental communication skill in behavioral health counseling. It enables counselors to demonstrate an understanding of and empathy for clients’ experiences and concerns. Training to acquire and refine reflective listening skills is essential for counseling proficiency. Yet, it faces significant barriers, notably the need for specialized and timely feedback to improve counseling skills. In this work, we evaluate and compare several computational models, including transformer-based architectures, for their ability to assess the quality of counselors’ reflective listening skills. We explore a spectrum of neural-based models, ranging from compact, specialized RoBERTa models to advanced large-scale language models such as Flan, Mistral, and GPT-3.5, to score psychotherapy reflections. We introduce a psychotherapy dataset that encompasses three basic levels of reflective listening skills. Through comparative experiments, we show that a finetuned small RoBERTa model with a custom learning objective (Prompt-Aware margIn Ranking (PAIR)) effectively provides constructive feedback to counselors in training. This study also highlights the potential of machine learning in enhancing the training process for motivational interviewing (MI) by offering scalable and effective feedback alternatives for counseling training.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = dec,
keywords = {Motivational Interviewing, Computational Counseling, Reflective Listening, Large Language Modeling}
}

@inproceedings{10.1145/3628516.3659399,
author = {Hu, Zihui and Hou, Hanchao and Ni, Shiguang},
title = {Grow with Your AI Buddy: Designing an LLMs-based Conversational Agent for the Measurement and Cultivation of Children's Mental Resilience},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628516.3659399},
doi = {10.1145/3628516.3659399},
abstract = {Psychological resilience refers to an individual's ability to adapt to adversity and stress. Education on psychological resilience during childhood can contribute to future mental health and well-being, such as reducing anxiety and depression [1] [2]. However, traditional psychosocial resilience training faces challenges with accessibility, heavily constrained by cost and spatiotemporal limitations. Recently, emerging large language models (LLMs) have demonstrated exceptional capabilities in conversational tasks, indicating new prospects for cultivating children's psychological resilience. In our work, 1) we conducted qualitative interviews with 10 Chinese children (aged 8-12) and their parents to understand their needs and current conditions; 2) based on the interview results and theories of psychological resilience, we summarized three pathways for developing children's psychological resilience using conversational agents (CAs) and identified six key challenges for designing child-centered CAs; 3) we designed and developed a web prototype using optimized LLMs (see Figure 1), which integrates personal and social support factors, to measure and foster children's psychological resilience through conversations; and 4) we invited 48 child volunteers in user testing and designed three sets of experiments to evaluate the effectiveness of system interventions, the effectiveness of measurements, and overall acceptability. Results indicate that the intervention tasks actively promoted psychological resilience in adolescents. Intelligent measurement scores were effectively consistent with traditional scales in objective scoring, while subjective evaluations, such as appeal and fun, significantly exceeded traditional scale scores.Through our practice, we show the potential of CAs in enhancing children's mental health and presented a reference application case. Moreover, we have unearthed notable future research issues, including challenges in designing psychologically educational CAs that are persistently attractive to children, combining real-life support factors with CAs, and ethical concerns regarding safety and privacy.},
booktitle = {Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
pages = {811–817},
numpages = {7},
location = {Delft, Netherlands},
series = {IDC '24}
}

@inproceedings{10.1145/3703187.3703238,
author = {Chen, Qianyu},
title = {Research on Inference and Training Acceleration of Large Language Model},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703238},
doi = {10.1145/3703187.3703238},
abstract = {Large language models have become an important research direction in the field of deep learning, and have received extensive attention from academia and industry. These models excel in natural language processing tasks, significantly improving the performance of downstream tasks. However, due to the large scale of the model, high-performance computing resources are required for deployment, and the latency problem in the inference process also limits its practical use in some industrial applications. Therefore, how to optimize these models to improve their practical application effect is still an urgent problem to be solved. In this work, by optimising the model architecture, introducing sparsity techniques, using quantisation methods and adopting distributed training strategies, we have achieved a substantial reduction in the computational overhead and memory requirements of large-scale language models, while simultaneously improving the inference speed and training efficiency. Firstly, the model architecture was optimised in order to reduce redundant calculations and enhance the parameter efficiency of the model, particularly in the design of the self-attention mechanism and the feedforward network layer. Secondly, the incorporation of sparsity technology has the potential to reduce the number of parameters and the amount of computation without a significant impact on the model's performance. This is achieved through the utilisation of sparse matrix multiplication and pruning techniques, which serve to minimise unnecessary computation. Furthermore, the quantization method markedly diminishes the memory footprint and bandwidth requirements by transforming the model weights and activation functions from high-precision floating-point numbers to low-precision representations, thereby enhancing the computational efficiency of the model. In the training process, a distributed training strategy was employed, utilising a combination of data parallelism and model parallelism to optimise the use of computing resources across multiple machines, thereby significantly reducing the training time. The results of the experimental analysis demonstrate that these methods can markedly enhance the speed of both inference and training, while concurrently reducing the consumption of resources, whilst maintaining the performance of the model.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {303–307},
numpages = {5},
keywords = {Distributed training, Inference acceleration, Large language model, Sparse matrix multiplication},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3699538.3699546,
author = {Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\"{o}ppe, Christian and de Jong, Imke and Sosnovsky, Sergey},
title = {Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699546},
doi = {10.1145/3699538.3699546},
abstract = {Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {14},
numpages = {12},
keywords = {Generative AI, Large Language Models, Computing Education, Programming Courses},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3664647.3680827,
author = {Chen, Haodong and Huang, Haojian and Dong, Junhao and Zheng, Mingzhe and Shao, Dian},
title = {FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680827},
doi = {10.1145/3664647.3680827},
abstract = {Dynamic Facial Expression Recognition (DFER) is crucial for understanding human behavior. However, current methods exhibit limited performance mainly due to the insufficient utilization of facial dynamics, and the ambiguity of expression semantics, etc. To this end, we propose a novel framework, named Multi-modal Fine-grained CLIP for DFER with AdaptERs (FineCLIPER), incorporating the following novel designs: 1) To better distinguish between similar facial expressions, we extend the class labels to textual descriptions from both positive and negative aspects, and obtain supervision by calculating the cross-modal similarity based on the CLIP model; 2) Our FineCLIPER adopts a hierarchical manner to effectively mine useful cues from DFE videos. Specifically, besides directly embedding video frames as input (low semantic level), we propose to extract the face segmentation masks and landmarks based on each frame (middle semantic level) and utilize the Multi-modal Large Language Model (MLLM) to further generate detailed descriptions of facial changes across frames with designed prompts (high semantic level). Additionally, we also adopt Parameter-Efficient Fine-Tuning (PEFT) to enable efficient adaptation of large pre-trained models (i.e., CLIP) for this task. Our FineCLIPER achieves SOTA performance on the DFEW, FERV39k, and MAFW datasets in both supervised and zero-shot settings with few tunable parameters. Project page: https://haroldchen19.github.io/FineCLIPER-Page/},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2301–2310},
numpages = {10},
keywords = {contrastive learning, dynamic facial expression recognition, model adaptation, multi-modal, parameter-efficient transfer learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3659211.3659227,
author = {Han, Yang},
title = {Advancing Text Analytics: Instruction Fine-Tuning of QianWen-7B for Sentiment Classification},
year = {2024},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659211.3659227},
doi = {10.1145/3659211.3659227},
abstract = {The complexity of financial systems and the subtleties of market behavior necessitate sophisticated tools for sentiment analysis. This study presents a fine-tuned QianWen-7B [1] model, a large pre-trained language model, tailored for financial text sentiment classification. Utilizing instruction fine-tuning, we have adapted the model to classify texts into three categories: positive, neutral, and negative. Our dataset comprises 2,879 neutral, 1,362 positive, and 604 negative samples from texts. The model was trained using a fine-tuning framework called QLora [2], with a quantization level of 4 and Lora rank of 8, optimizing for both memory usage and computational efficiency. We employed the Adam optimizer with a learning rate of 5e-5, a batch size of 4, and gradient accumulation to address hardware limitations. The fine-tuned Qwen-7B model achieved an accuracy of 0.8227, outperforming the Deberta-V3-base and Deberta-V3-large models, which underscores the effectiveness of our approach. Our findings illustrate the potential of using large language models with instruction fine-tuning for enhanced text sentiment analysis, paving the way for more informed investment decisions and robust market regulation. The discussion highlights the model's superior performance, challenges in dataset representativeness and class imbalance, and the importance of model interpretability in decision-making. It also points to future enhancements that could further improve the model's applicability and relevance in the rapidly changing financial sector.},
booktitle = {Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
pages = {90–93},
numpages = {4},
location = {Zhengzhou, China},
series = {BDEIM '23}
}

@inproceedings{10.1145/3649158.3657043,
author = {Kundu, Ashish},
title = {AI/ML, Graphs and Access Control: Towards Holistic Identity and Access Management},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657043},
doi = {10.1145/3649158.3657043},
abstract = {Vulnerabilities in identity and access management (IAM) are one of the most common reasons for data breaches leading to adversarial impacts on security, privacy and compliance postures. Account breaches, incorrectly designed access control policies, weaknesses in authentication and credential management, vulnerable session management are some of the several security issues that lead to eventual compromise of the crown jewels leading to data breaches. The lifecycles of subjects and their identities, of objects and re- sources, and of the permissions and authorization policies are in- tertwined in a complex manner for each specific scenario. Often subjects, objects and permissions often are hard to be defined or isolated from each other, especially in the context of machine learn-ing. The evolution of these entities, and how their provenance is analyzed often is essential not only for forensic analysis of a breach but also should be a proactive ongoing process.  In order to manage the security issues and risks thereof, holistic end-to-end identity and access management in a secure and privacy- preserving manner is the need of yesterday, today and of the future. In the past couple of decades, we have encountered this problem time and again in various contexts in the settings of academic and industry research and in development/deployment of products, services and processes.  Three elements are the key ingredients in order to address this problem in a holistic manner: (1) graphs, (2) machine learning, and (3) decentralized computing (i.e., web3, blockchains). Further, with the advent of generative AI and large language models, the question arises about what problems they can help solve, or they can excerbate further, or what new challenges they can introduce. In this talk, I plan to delve into a discussion of the following: (a) the holistic and end-to-end nature of IAM, (b) the interplay between these three elements - graphs, machine learning, Web3 as well as generative AI, and how they can help, and (c) the research challenges that need to be addressed in order to reduce the security, privacy and compliance risks in identity and access management.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {1},
numpages = {1},
keywords = {access control, generative ai, identity, machine learning},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@inproceedings{10.1145/3629527.3651419,
author = {Niewenhuis, Dante and Talluri, Sacheendra and Iosup, Alexandru and De Matteis, Tiziano},
title = {FootPrinter: Quantifying Data Center Carbon Footprint},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629527.3651419},
doi = {10.1145/3629527.3651419},
abstract = {Data centers have become an increasingly significant contributor to the global carbon footprint. In 2021, the global data center industry was responsible for around 1% of the worldwide greenhouse gas emissions. With more resource-intensive workloads, such as Large Language Models, gaining popularity, this percentage is expected to increase further. Therefore, it is crucial for data center service providers to become aware of and accountable for the sustainability impact of their design and operational choices. However, reducing the carbon footprint of data centers has been a challenging process due to the lack of comprehensive metrics, carbon-aware design tools, and guidelines for carbon-aware optimization. In this work, we propose FootPrinter, a first-of-its-kind tool that supports data center designers and operators in assessing the environmental impact of their data center. FootPrinter uses coarse-grained operational data, grid energy mix information, and discrete event simulation to determine the data center's operational carbon footprint and evaluate the impact of infrastructural or operational changes. FootPrinter can simulate days of operations of a regional data center on a commodity laptop in a few seconds, returning the estimated footprint with marginal error. By making this project open source, we hope to engage the community in the development of methodologies and tools for systematically assessing and exploring the sustainability of data centers.},
booktitle = {Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
pages = {189–195},
numpages = {7},
keywords = {carbon emission, carbon footprint, data center, simulation},
location = {London, United Kingdom},
series = {ICPE '24 Companion}
}

@inproceedings{10.1145/3597503.3623345,
author = {Steenhoek, Benjamin and Gao, Hongyang and Le, Wei},
title = {Dataflow Analysis-Inspired Deep Learning for Efficient Vulnerability Detection},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623345},
doi = {10.1145/3597503.3623345},
abstract = {Deep learning-based vulnerability detection has shown great performance and, in some studies, outperformed static analysis tools. However, the highest-performing approaches use token-based transformer models, which are not the most efficient to capture code semantics required for vulnerability detection. Classical program analysis techniques such as dataflow analysis can detect many types of bugs based on their root causes. In this paper, we propose to combine such causal-based vulnerability detection algorithms with deep learning, aiming to achieve more efficient and effective vulnerability detection. Specifically, we designed DeepDFA, a dataflow analysis-inspired graph learning framework and an embedding technique that enables graph learning to simulate dataflow computation. We show that DeepDFA is both performant and efficient. DeepDFA outperformed all non-transformer baselines. It was trained in 9 minutes, 75x faster than the highest-performing baseline model. When using only 50+ vulnerable and several hundreds of total examples as training data, the model retained the same performance as 100% of the dataset. DeepDFA also generalized to real-world vulnerabilities in DbgBench; it detected 8.7 out of 17 vulnerabilities on average across folds and was able to distinguish between patched and buggy versions, while the highest-performing baseline models did not detect any vulnerabilities. By combining DeepDFA with a large language model, we surpassed the state-of-the-art vulnerability detection performance on the Big-Vul dataset with 96.46 F1 score, 97.82 precision, and 95.14 recall. Our replication package is located at https://doi.org/10.6084/m9.figshare.21225413.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {16},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3650203.3663331,
author = {Woisetschl\"{a}ger, Herbert and Erben, Alexander and Wang, Shiqiang and Mayer, Ruben and Jacobsen, Hans-Arno},
title = {Federated Fine-Tuning of LLMs on the Very Edge: The Good, the Bad, the Ugly},
year = {2024},
isbn = {9798400706110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650203.3663331},
doi = {10.1145/3650203.3663331},
abstract = {With the emergence of AI regulations, such as the EU AI Act, requirements for simple data lineage, enforcement of low data bias, and energy efficiency have become a priority for everyone offering AI services. Being pre-trained on versatile and a vast amount of data, large language models and foundation models (FMs) offer a good basis for building high-quality deep learning pipelines. Fine-tuning can further improve model performance on a specific downstream task, which requires orders of magnitude less data than pre-training. Often, access to high-quality and low-bias data for model fine-tuning is limited due to technical or regulatory requirements. Federated learning (FL), as a distributed and privacy-preserving technique, offers a well-suited approach to significantly expanding data access for model fine-tuning. Yet, this data is often located on the network edge, where energy, computational, and communication resources are significantly more limited than in data centers.In our paper, we conduct an end-to-end evaluation for fine-tuning the FLAN-T5 FM family on the network edge. We study energy efficiency potentials throughout FL systems - on clients, in communication, and on the server. Our analysis introduces energy efficiency as a real-time metric to assess the computational efficiency of an FL system. We show the stark need for further improvements in communication efficiency when working with FMs and demonstrate the importance of adaptive FL optimizers for FM training.},
booktitle = {Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning},
pages = {39–50},
numpages = {12},
location = {Santiago, AA, Chile},
series = {DEEM '24}
}

@inproceedings{10.1145/3677619.3678092,
author = {Bahr, Tobias and Manzocco, Mario and Schuster, Dennis},
title = {Differentiated Tasks by ChatGPT for Secondary Computer Science Education: Useful or not?},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678092},
doi = {10.1145/3677619.3678092},
abstract = {In recent years, there has been a growing interest in exploring the capabilities of AI chatbots, such as ChatGPT. Studies have investigated diverse applications, including the response of AI chatbots to undergraduate exam questions and the generation of student exercises for programming. However, the question remains if AI chatbots provide adequate results for K-12 CS in different application scenarios. AI chatbots are increasingly integrated into K-12 education by both students and teachers. In this context, a tool using didactical parameters was created to differentiate tasks with ChatGPT-4 in an ongoing project. Preliminary findings from this work in progress reveal that teachers see a benefit using the tool. Future directions for using the tool are discussed.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {34},
numpages = {2},
keywords = {AI chatbots, ChatGPT, Computer Science Education, Expert rating, K-12},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@inproceedings{10.1145/3639478.3647634,
author = {Wang, Xinchen and Hu, Ruida and Gao, Cuiyun and Wen, Xin-Cheng and Chen, Yujia and Liao, Qing},
title = {ReposVul: A Repository-Level High-Quality Vulnerability Dataset},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3647634},
doi = {10.1145/3639478.3647634},
abstract = {Open-Source Software (OSS) vulnerabilities bring great challenges to the software security and pose potential risks to our society. Enormous efforts have been devoted into automated vulnerability detection, among which deep learning (DL)-based approaches have proven to be the most effective. However, the performance of the DL-based approaches generally relies on the quantity and quality of labeled data, and the current labeled data present the following limitations: (1) Tangled Patches: Developers may submit code changes unrelated to vulnerability fixes within patches, leading to tangled patches. (2) Lacking Inter-procedural Vulnerabilities: The existing vulnerability datasets typically contain function-level and file-level vulnerabilities, ignoring the relations between functions, thus rendering the approaches unable to detect the inter-procedural vulnerabilities. (3) Outdated Patches: The existing datasets usually contain outdated patches, which may bias the model during training.To address the above limitations, in this paper, we propose an automated data collection framework and construct the first repository-level high-quality vulnerability dataset named ReposVul. The proposed framework mainly contains three modules: (1) A vulnerability untangling module, aiming at distinguishing vulnerability-fixing related code changes from tangled patches, in which the Large Language Models (LLMs) and static analysis tools are jointly employed. (2) A multi-granularity dependency extraction module, aiming at capturing the inter-procedural call relationships of vulnerabilities, in which we construct multiple-granularity information for each vulnerability patch, including repository-level, file-level, function-level, and line-level. (3) A trace-based filtering module, aiming at filtering the outdated patches, which leverages the file path trace-based filter and commit time trace-based filter to construct an up-to-date dataset.The constructed repository-level ReposVul encompasses 6,134 CVE entries representing 236 CWE types across 1,491 projects and four programming languages. Thorough data analysis and manual checking demonstrate that ReposVul is high in quality and alleviates the problems of tangled and outdated patches in previous vulnerability datasets.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {472–483},
numpages = {12},
keywords = {open-source software, software vulnerability datasets, data quality},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1109/ASE56229.2023.00040,
author = {Jiang, Ziyou and Shi, Lin and Yang, Guowei and Wang, Qing},
title = {SCPatcher: Mining Crowd Security Discussions to Enrich Secure Coding Practices},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00040},
doi = {10.1109/ASE56229.2023.00040},
abstract = {Secure coding practices (SCPs) have been proposed to guide software developers to write code securely to prevent potential security vulnerabilities. Yet, they are typically one-sentence principles without detailed specifications, e.g., "Properly free allocated memory upon the completion of functions and at all exit points.", which makes them difficult to follow in practice, especially for software developers who are not yet experienced in secure programming. To address this problem, this paper proposes SCPatcher, an automated approach to enrich secure coding practices by mining crowd security discussions on online knowledge-sharing platforms, such as Stack Overflow. In particular, for each security post, SCPatcher first extracts the area of coding examples and coding explanations with a fix-prompt tuned Large Language Model (LLM) via Prompt Learning. Then, it hierarchically slices the lengthy code into coding examples and summarizes the coding explanations with the areas. Finally, SCPatcher matches the CWE and Public SCP, integrating them with extracted coding examples and explanations to form the SCP specifications, which are the wild SCPs with details, proposed by the developers. To evaluate the performance of SCPatcher, we conduct experiments on 3,907 security posts from Stack Overflow. The experimental results show that SCPatcher outperforms all baselines in extracting the coding examples with 2.73% MLine on average, as well as coding explanations with 3.97% F1 on average. Moreover, we apply SCPatcher on 447 new security posts to further evaluate its practicality, and the extracted SCP specifications enrich the public SCPs with 3,074 lines of code and 1,967 sentences.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {358–370},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@proceedings{10.1145/3657604,
title = {L@S '24: Proceedings of the Eleventh ACM Conference on Learning @ Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the Proceedings of the Eleventh Annual ACM Conference on Learning at Scale, L@S 2024, held July 18-20, 2024 at Georgia Tech in Atlanta, Georgia, USA.The Learning at Scale conference was created by the Association for Computing Machinery (ACM), inspired by the emergence of Massive Open Online Courses (MOOCs) and the accompanying shift in thinking about education. During the last few years, new opportunities for scaling up learning have emerged, like hybrid learning environments combining online and face-to-face, and informal learning enabled by all sorts of platforms (e.g., gamified language learning, citizen science communities, and collaborative programming communities). In the recent two years, the unprecedented development of generative AI has brought profound opportunities to scale the teaching and learning experiences, with the goal of enhancing learning for the increasingly diverse group of learners in both formal and informal contexts. L@S has evolved along with these emergent massive learning scenarios and opportunities and is today one of the most prominent venues for discussion of the highest quality of research on how learning and teaching can be transformed at scale, in diverse learning environments.The theme of L@S 2024 is Scaling Learning in the Age of AI. Rapid advances in AI have created new opportunities but also challenges for the Learning@Scale community. The advances in generative AI show potential to enhance pedagogical practices and the efficacy of learning at scale. This has led to an unprecedented level of interest in employing generative AI for scaling tutoring and feedback. The prevalence of such tools calls for new practices and understanding on how AI-based methods should be designed and developed to enhance the experiences and outcomes of teachers and learners.Learning@Scale 2024 solicits empirical and theoretical papers on, but not limited to, the following topics (in no particular order): 1) Instruction at scale: studies that examine how teachers and educators scale their instructions, what aspects of instruction could be scaled effectively, and which of these instructional strategies are the most effective for learning. 2) Interventions at scale: studies that examine the effects of interventions on student learning and performance when implemented at scale. We welcome studies that use both qualitative and quantitative methods. 3) The use of generative AI to scale learning: studies that investigate stakeholders' experiences with generative AI, students' and teachers' interactions with generative AI, and the potentials and limitations of using generative AI in education. 4) Systems and tools to support learning at scale: research that designs and develops systems and tools to support learning at scale. For example, this involves scaling learning through web-based systems, MOOCs, visualization, intelligent tutoring systems, gamification, immersive techniques (AR/VR/MR), mobile technologies, tangible interfaces, and various other technologies. 5) The evaluation of existing learning at scale systems and online learning environments using but not limited to the above-mentioned technologies. 6) Methods and algorithms that model learner behavior: research that contributes methods, algorithms, and pipelines that process large student data to enhance learning at scale. 7) Scaling learning in informal contexts: studies that explore how people take advantage of online environments to pursue their interests informally. 8) Review and synthesis of existing literature related to learning at scale. 9) Empirical studies and interventions that address equity, trust, algorithmic transparency and explainability, fairness and bias when using AI in education. 10) Research that addresses accessibility in learning at scale contexts. 11) Design and deployment of learning at scale systems for learners from underrepresented groups.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3640543.3645198,
author = {Qian, Crystal and Wexler, James},
title = {Take It, Leave It, or Fix It: Measuring Productivity and Trust in Human-AI Collaboration},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645198},
doi = {10.1145/3640543.3645198},
abstract = {Although recent developments in generative AI have greatly enhanced the capabilities of conversational agents such as Google’s Bard or OpenAI’s ChatGPT, it’s unclear whether the usage of these agents aids users across various contexts. To better understand how access to conversational AI affects productivity and trust, we conducted a mixed-methods, task-based user study, observing 76 software engineers (N=76) as they completed a programming exam with and without access to Bard. Effects on performance, efficiency, satisfaction, and trust vary depending on user expertise, question type (open-ended "solve" questions vs. definitive "search" questions), and measurement type (demonstrated vs. self-reported). Our findings include evidence of automation complacency, increased reliance on the AI over the course of the task, and increased performance for novices on “solve”-type questions when using the AI. We discuss common behaviors, design recommendations, and impact considerations to improve collaborations with conversational AI.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {370–384},
numpages = {15},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3650212.3652140,
author = {Ouyang, Yicheng and Yang, Jun and Zhang, Lingming},
title = {Benchmarking Automated Program Repair: An Extensive Study on Both Real-World and Artificial Bugs},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652140},
doi = {10.1145/3650212.3652140},
abstract = {As bugs are inevitable and prevalent in real-world programs, many Automated Program Repair (APR) techniques have been proposed to generate patches for them. However, due to the lack of a standard for evaluating APR techniques, prior works tend to use different settings and benchmarks in evaluation, threatening the trustworthiness of the evaluation results. Additionally, they typically only adopt plausibility and genuineness as evaluation metrics, which may potentially mask some underlying issues in APR techniques. To overcome these issues, in this paper, we conduct an extensive and multi-dimensional evaluation of nine learning-based and three traditional state-of-the-art APR techniques under the same environment and settings. We employ the widely studied Defects4J V2.0.0 benchmark and a newly constructed large-scale mutation-based benchmark named MuBench, derived from Defects4J and including 1,700 artificial bugs generated by various mutators, to uncover potential limitations in these APR techniques. We also apply multi-dimensional metrics, including compilability/plausibility/genuineness metrics, as well as SYE (SYntactic Equivalence) and TCE (Trivial Compiler Equivalence) metrics, to thoroughly analyze the 1,814,652 generated patches. This paper presents noteworthy findings from the extensive evaluation: Firstly, Large Language Model (LLM) based APR demonstrates less susceptibility to overfitting on the Defects4J V1.2.0 dataset and fixes the most number of bugs. Secondly, the study suggests a promising future for combining traditional and learning-based APR techniques, as they exhibit complementary advantages in fixing different types of bugs. Additionally, this work highlights the necessity for further enhancing patch compilability of learning-based APR techniques, despite the presence of various existing strategies attempting to improve it. The study also reveals other guidelines for enhancing APR techniques, including the need for handling unresolvable symbol compilability issues and reducing duplicate/no-op patch generation. Finally, our study uncovers seven implementation issues in the studied techniques, with five of them confirmed and fixed by the corresponding authors.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {440–452},
numpages = {13},
keywords = {Empirical assessment, Mutation testing, Program repair},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1109/ASE56229.2023.00109,
author = {Gao, Shuzheng and Wen, Xin-Cheng and Gao, Cuiyun and Wang, Wenxuan and Zhang, Hongyu and Lyu, Michael R.},
title = {What Makes Good In-Context Demonstrations for Code Intelligence Tasks with LLMs?},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00109},
doi = {10.1109/ASE56229.2023.00109},
abstract = {Pre-trained models of source code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning (ICL). ICL employs task instructions and a few examples as demonstrations, and then inputs the demonstrations to the language models for making predictions. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of ICL heavily relies on the quality of demonstrations, e.g., the selected examples. It is important to systematically investigate how to construct a good demonstration for code-related tasks. In this paper, we empirically explore the impact of three key factors on the performance of ICL in code intelligence tasks: the selection, order, and number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including code summarization, bug fixing, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of ICL in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We also show that a carefully-designed demonstration based on our findings can lead to substantial improvements over widely-used demonstration construction methods, e.g., improving BLEU-4, EM, and EM by at least 9.90%, 175.96%, and 50.81% on code summarization, bug fixing, and program synthesis, respectively.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {761–773},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3632620.3671112,
author = {Skripchuk, James and Bacher, John and Price, Thomas},
title = {An Investigation of the Drivers of Novice Programmers' Intentions to Use Web Search and GenAI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671112},
doi = {10.1145/3632620.3671112},
abstract = {External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web resources such as tutorial websites and Q&amp;A forums. With the rise of Generative AI (GenAI), there has been increasing concern and research about how external resources should be used in the classroom. However, little work has directly contrasted student beliefs and perceptions of web resources with GenAI, has grounded these beliefs in prior psychological theory, and has investigated how demographic factors and student backgrounds influence these beliefs and intentions. We administered a vignette-style survey across two courses required for a CS major at an R1 University, a freshman (n = 152) and senior capstone course (n = 44). Students responded to likert questions aiming to measure behavioral factors related to these tools, such as intention to use, perceived attitudes, peer perceptions, and their own perceived tool competency. We primarily investigate the results of an introductory course, finding that novices have a wide range of opinions on both resources, but overall find them slightly useful and have a tendency to prefer web-search. We compare this with seniors, who have more positive perceptions of these tools, and discuss possible reasons and implications for this difference. We constructed two path models to investigate which factors strongly influence novices’ intention to use resources and find the primary factor to be their general attitudes in how these tools will result in a positive or negative outcome (e.g. perceived benefits, justifiability). We also measure the effects of student background on intention to use these resources. Finally, we discuss implications and suggestions on how instructors can use this information to approach, address, and influence resource usage in their classrooms.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {487–501},
numpages = {15},
keywords = {CS Education, GenAI, Help-seeking, student perspectives, web-search},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3631700.3664900,
author = {Portaz, Miguel and Manjarres, Angeles and Santos, Olga C.},
title = {Harmonizing Ethical Principles: Feedback Generation Approaches in Modeling Human Factors for Assisted Psychomotor Systems},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3664900},
doi = {10.1145/3631700.3664900},
abstract = {As the demand for personalized and adaptive learning experiences increase, there is a urgent need for providing effective feedback mechanisms within critical systems, such as in psychomotor learning systems. This proposal introduces an approach for the integration of retrieval-augmented generation tools to provide comprehensive and insightful feedback to users. By combining the strengths of retrieval-based techniques and generative models, these tools offer the potential to enhance learning outcomes by delivering tailored feedback that is both informative and engaging. The proposal also emphasises the importance of incorporating explainability and transparency concepts. Following the hybrid intelligence paradigm it is possible to ensure that the feedback provided by these tools is not only accurate but also understandable to humans. This approach fosters trust and promotes a deeper understanding of the psychomotor learning process, empowering users and facilitators to make informed decisions about the psychomotor learning path. The hybrid intelligence paradigm, which combines the strengths of both human and artificial intelligence, plays a crucial role in the deployment of these solutions. By taking advantage of the cognitive capabilities of human experts alongside the computational power of artificial intelligence algorithms, it is possible to offer personalised feedback that takes into account both technical accuracy and pedagogical effectiveness. Through these collaborative efforts it is also possible to create learning environments that are inclusive, adaptable, and beneficial to lifelong learning. In conclusion, this proposal introduces retrieval-augmented generation tools for providing feedback in psychomotor learning systems, which represents a significant step towards in its personalization, and whose ethical implications align with the new regulations on the implementation of intelligent technologies in critical systems.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {380–385},
numpages = {6},
keywords = {Collaborative Learning, Ethics, Human-Centered, Hybrid Intelligence, Intelligent Psychomotor Systems, Retrieval Augmented Generation, XAI},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3694715.3695969,
author = {Ge, Hao and Fu, Fangcheng and Li, Haoyang and Wang, Xuanyu and Lin, Sheng and Wang, Yujie and Nie, Xiaonan and Zhang, Hailin and Miao, Xupeng and Cui, Bin},
title = {Enabling Parallelism Hot Switching for Efficient Training of Large Language Models},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695969},
doi = {10.1145/3694715.3695969},
abstract = {Training of large-scale deep learning models necessitates parallelizing the model and data across numerous devices, and the choice of parallelism strategy substantially depends on the training workloads such as memory consumption, computation cost, and communication cost. Current approaches generally assume uniform training workloads across samples in a given task. Thus, existing systems are designed to adopt a static parallelism strategy throughout one training process. Nevertheless, when training models with sequence inputs, this assumption fails due to the sequence length variation across samples. Consequently, training with a static parallelism strategy would result in sub-optimal performance.In this paper, we first reveal the under-explored fact that the optimal parallelism strategy varies even for the sequences within a single mini-batch. Motivated by this, we present HotSPa, a novel system that adopts multiple parallelism strategies for efficient training with sequence inputs. To be specific, given a mini-batch of training sequences, HotSPa partitions them into multiple groups and applies different parallelism strategies to process each group individually. To enable the hot switching between strategies, HotSPa transfers model parameters and accumulated gradients among the devices on the fly. Significant solutions are proposed with the hope of seamless and rapid parallelism hot switching. Firstly, we design a graph compiler, which generates distributed computation graphs for different parallelism strategies simultaneously, and orchestrates them to share a single model storage backbone. Secondly, we develop a simple yet effective hot switch planner, which heuristically deduces communication plans to accelerate the transition of model partitioning given any pairs of strategies. Extensive experiments on large language model training demonstrate that HotSPa can be up to 2.99\texttimes{} faster than Megatron-LM and DeepSpeed that utilize static parallelism strategies. Source code is available: https://github.com/PKU-DAIR/Hetu.},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {178–194},
numpages = {17},
keywords = {distributed training, large language model, parallelism strategy},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@article{10.5555/3717781.3717799,
author = {Tok, Bulut and Dogan, Gulustan},
title = {Advisor SeaHawk: An Academic Advisor Chatbot for MSCSIS Students at UNCW},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {This paper introduces Advisor SeaHawk, an advanced academic advisor chatbot for students at the University of North Carolina Wilmington (UNCW), specifically tailored for MSCSIS (Master of Science Computer and Information Science) students. Using OpenAI's GPT-4o model, Advisor SeaHawk provides personalized academic advising, including course recommendations, prerequisite checks, and detailed academic plans. The development process involves converting PDF academic records into structured JSON data, extracting student information using regular expressions, and integrating CSV-based course information. By leveraging natural language processing, Advisor SeaHawk interacts with students in a friendly manner, effectively simulating a human advisor. This chatbot aims to provide an accessible, efficient, and tailored advising experience for college students. We have not tested Advisor Seahawk yet on real student data.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {138–148},
numpages = {11}
}

@inproceedings{10.1145/3627673.3679226,
author = {Peng, Jinfeng and Cui, Hanghai and Shen, Derong and Kou, Yue and Nie, Tiezheng and Guo, Tianlong},
title = {GARF: A Self-supervised Data Cleaning System with SeqGAN},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679226},
doi = {10.1145/3627673.3679226},
abstract = {High-quality data is essential for data science and machine learning applications, but unfortunately, real-world data often contains significant amounts of errors, such as typos, missing values, and data inconsistencies. Despite all the efforts in cleaning data using either logical or learning-based methods, in practice, data cleaning still requires high human cost, for either manually providing data repairing rules or preparing labeled datasets for training machine learning models. In this paper, we introduce GARF, a novel data cleaning system based on sequence generative adversarial networks (SeqGAN). One key information GARF tries to learn is data repair rules. To automatically extracts data repair rules from dirty data, GARF employs a SeqGAN to capture the dependency relationships, and converts the information learned by machine to interpretable data repair rules for humans. Additionally, considering that both generated rules and data may not be fully trusted, GARF provides a co-cleaning process to iteratively update inaccurate rules and repair dirty data until there is no tuple violating rules. We have implemented and deployed GARF as an open-sourced system, and demonstrated its usability on data cleaning in real-world scenarios.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5260–5264},
numpages = {5},
keywords = {data cleaning, generative adversarial network, rule generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3649165.3690111,
author = {Poitras, Eric and Crane, Brent and Siegel, Angela},
title = {Generative AI in Introductory Programming Instruction: Examining the Assistance Dilemma with LLM-Based Code Generators},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690111},
doi = {10.1145/3649165.3690111},
abstract = {Problem decomposition is an important skill in programming, allowing learners to break down complex tasks into manageable subgoals. However, translating these subgoals into executable code poses a significant challenge for novice programmers. In this study conducted in an introductory programming course, learners received instruction in stepwise refinement and integration of AI-generated code within their assignments. Throughout the course, learners were permitted to rely on AI code generators, following opportunities to receive feedback on their ability to read and write code without AI assistance.  Our findings show that learners frequently relied on AI-generated code when working on assignments outside the classroom, but that the frequency of reliance varied from one assignment to another. The reliance on AI-generated code was not correlated with the learners' year in their degree, nor whether they were enrolled in a CS degree or not. Instead, it was associated with their prior knowledge, as learners who were less proficient in reading and writing code were more likely to seek AI assistance.  AI tools were primarily used to translate subgoals into code, fix errors, and explain algorithmic concepts. Few learners encountered difficulties in understanding or integrating AI generated code into their solutions. Overall, learner performance in meeting assignment requirements was relatively high, regardless of their prior knowledge or reliance on AI code generators. We conclude that leveraging the capabilities of generative AI can effectively bridge the gap between problem-solving and implementation, enabling learners to engage in skills that might otherwise be beyond their reach.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {186–192},
numpages = {7},
keywords = {ai coding assistants, ai-assisted pair programming, chatgpt, generative ai, gpt-3.5, introductory programming, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@proceedings{10.1145/3616855,
title = {WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 17th ACM International Conference on Web Search and Data Mining - WSDM 2024. WSDM is one of the premier conferences in the fields of web search and data mining, with a dynamic and growing community from academia and industry. After two years of virtual conferences and in-person conferences in Singapore, the 2024 edition is an in-person conference with virtual elements. We hope you enjoy the conference at the "Centro Internacional de Congresos de Yucatan (CIC)" in Merida from March 4 to March 8, 2024.We are excited to kick off the program with a dynamic mix of Tutorials and Industry Day. Our seven tutorials will cover a broad range of search and data mining topics. Industry Day will provide valuable insights from leaders at major technology companies. The core technical program continues WSDM's tradition of a single-track format, featuring 109 thought-provoking papers from both academic and industry experts. We're honored to have inspiring keynote speakers each day: Nicolas Christin (CMU), Elizabeth Reid (Google), and Saiph Savage (Civic A.I. Lab). Additionally, 17 interactive demonstrations will showcase the latest prototypes and systems. The final day offers a stimulating Doctoral Consortium and six engaging workshops on topics including integrity in social networks, large language model for society, psychology-informed information access system, interactive and scalable information retrieval system and machine learning on graphs. WSDM 2024 proudly presents WSDM day on information retrieval and Web in the region. WSDM Cup Day highlights finalists' presentations addressing challenges in Conversational Multi-Doc QA. This diverse and stimulating program promises to be an enriching experience for all!.},
location = {Merida, Mexico}
}

@inproceedings{10.1145/3597503.3639184,
author = {Chow, Yiu Wai and Di Grazia, Luca and Pradel, Michael},
title = {PyTy: Repairing Static Type Errors in Python},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639184},
doi = {10.1145/3597503.3639184},
abstract = {Gradual typing enables developers to annotate types of their own choosing, offering a flexible middle ground between no type annotations and a fully statically typed language. As more and more code bases get type-annotated, static type checkers detect an increasingly large number of type errors. Unfortunately, fixing these errors requires manual effort, hampering the adoption of gradual typing in practice. This paper presents PyTy, an automated program repair approach targeted at statically detectable type errors in Python. The problem of repairing type errors deserves specific attention because it exposes particular repair patterns, offers a warning message with hints about where and how to apply a fix, and because gradual type checking serves as an automatic way to validate fixes. We addresses this problem through three contributions: (i) an empirical study that investigates how developers fix Python type errors, showing a diverse set of fixing strategies with some recurring patterns; (ii) an approach to automatically extract type error fixes, which enables us to create a dataset of 2,766 error-fix pairs from 176 GitHub repositories, named PyTyDefects; (iii) the first learning-based repair technique for fixing type errors in Python. Motivated by the relative data scarcity of the problem, the neural model at the core of PyTy is trained via cross-lingual transfer learning. Our evaluation shows that PyTy offers fixes for ten frequent categories of type errors, successfully addressing 85.4% of 281 real-world errors. This effectiveness outperforms state-of-the-art large language models asked to repair type errors (by 2.1x) and complements a previous technique aimed at type errors that manifest at runtime. Finally, 20 out of 30 pull requests with PyTy-suggested fixes have been merged by developers, showing the usefulness of PyTy in practice.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {87},
numpages = {13},
keywords = {automatic program repair, type annotation, transfer learning},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3675812.3675843,
author = {Zhang, Wenting and Zhang, Qiaorong and Cai, Mingming and Wang, Dongqing and Zheng, Yafeng},
title = {Navigating the Application Challenges of ChatGPT in Education: Promoting Responsible Use and Minimizing Mental Risks},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675843},
doi = {10.1145/3675812.3675843},
abstract = {With the wide application of artificial intelligence, especially generative AI like ChatGPT, the era of significant transformation in education has quietly arrived. This article first explores the current applications of ChatGPT in logical learning, language learning, as well as personalized and effective teaching. It then deeply analyzes the challenges brought by the application of ChatGPT in education from three aspects: digital ethics, psychological risks for teachers and students, and educational governance. Based on its potential risks and challenges, effective measures and suggestions are proposed, including improving information literacy education, fully utilizing human-computer collaboration, and establishing clear regulations for the use of ChatGPT. These measures aim to ensure that ChatGPT can maximize its application value in the field of education while minimizing the mental risks.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {23–28},
numpages = {6},
keywords = {Application Challenges, ChatGPT, Mental Risks},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3630106.3658936,
author = {Staufer, Dimitri and Pallas, Frank and Berendt, Bettina},
title = {Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization Tool for Mitigating the Risk of Whistleblower Re-Identification},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658936},
doi = {10.1145/3630106.3658936},
abstract = {Whistleblowing is essential for ensuring transparency and accountability in both public and private sectors. However, (potential) whistleblowers often fear or face retaliation, even when reporting anonymously. The specific content of their disclosures and their distinct writing style may re-identify them as the source. Legal measures, such as the EU Whistleblower Directive, are limited in their scope and effectiveness. Therefore, computational methods to prevent re-identification are important complementary tools for encouraging whistleblowers to come forward. However, current text sanitization tools follow a one-size-fits-all approach and take an overly limited view of anonymity. They aim to mitigate identification risk by replacing typical high-risk words (such as person names and other labels of named entities) and combinations thereof with placeholders. Such an approach, however, is inadequate for the whistleblowing scenario since it neglects further re-identification potential in textual features, including the whistleblower’s writing style. Therefore, we propose, implement, and evaluate a novel classification and mitigation strategy for rewriting texts that involves the whistleblower in the assessment of the risk and utility. Our prototypical tool semi-automatically evaluates risk at the word/term level and applies risk-adapted anonymization techniques to produce a grammatically disjointed yet appropriately sanitized text. We then use a Large Language Model (LLM) that we fine-tuned for paraphrasing to render this text coherent and style-neutral. We evaluate our tool’s effectiveness using court cases from the European Court of Human Rights (ECHR) and excerpts from a real-world whistleblower testimony and measure the protection against authorship attribution attacks and utility loss statistically using the popular IMDb62 movie reviews dataset, which consists of 62 individuals. Our method can significantly reduce authorship attribution accuracy from 98.81% to 31.22%, while preserving up to 73.1% of the original content’s semantics, as measured by the established cosine similarity of sentence embeddings.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {733–745},
numpages = {13},
keywords = {Authorship Obfuscation, Fine-tuning Language Models, LLM-based Rephrasing, Text Sanitization, Whistleblower Anonymity},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3643916.3644434,
author = {Li, Jiliang and Zhang, Yifan and Karas, Zachary and McMillan, Collin and Leach, Kevin and Huang, Yu},
title = {Do Machines and Humans Focus on Similar Code? Exploring Explainability of Large Language Models in Code Summarization},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644434},
doi = {10.1145/3643916.3644434},
abstract = {Recent language models have demonstrated proficiency in summarizing source code. However, as in many other domains of machine learning, language models of code lack sufficient explainability --- informally, we lack a formulaic or intuitive understanding of what and how models learn from code. Explainability of language models can be partially provided if, as the models learn to produce higher-quality code summaries, they also align in deeming the same code parts important as those identified by human programmers. In this paper, we report negative results from our investigation of explainability of language models in code summarization through the lens of human comprehension. We measure human focus on code using eye-tracking metrics such as fixation counts and duration in code summarization tasks. To approximate language model focus, we employ a state-of-the-art model-agnostic, black-box, perturbation-based approach, SHAP (SHapley Additive exPlanations), to identify which code tokens influence that generation of summaries. Using these settings, we find no statistically significant relationship between language models' focus and human programmers' attention. Furthermore, alignment between model and human foci in this setting does not seem to dictate the quality of the LLM-generated summaries. Our study highlights an inability to align human focus with SHAP-based model focus measures. This result calls for future investigation of multiple open questions for explainable language models for code summarization and software engineering tasks in general, including the training mechanisms of language models for code, whether there is an alignment between human and model attention on code, whether human attention can improve the development of language models, and what other model focus measures are appropriate for improving explainability.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {47–51},
numpages = {5},
keywords = {neural code summarization, language models, explainable AI, SHAP, human attention, eye-tracking},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3626252.3630958,
author = {Cambaz, Doga and Zhang, Xiaoling},
title = {Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630958},
doi = {10.1145/3626252.3630958},
abstract = {The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {artificial intelligence in education, code generation models, large language models, programming education, systematic review},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3631657,
author = {Akram, Bita and Leinonen, Juho and Norouzi, Narges and Prather, James and Zhang, Lisa},
title = {AI in Computing Education from Research to Practice},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3631657},
doi = {10.1145/3626253.3631657},
abstract = {The panel comprises a diverse set of Computing educators working on AI in education. The panelists will address four areas of AI in Computing education: 1) AI for introductory CS classrooms, 2) Investigating opportunities presented by LLMs, 3) LLM-based tool development, and 4) Ethics and inclusion in AI curriculum. The panel will share experiences and discuss opportunities and challenges in AI education with the community.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {artificial intelligence, computing education, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3589334.3645604,
author = {Wu, Qitian and Nie, Fan and Yang, Chenxiao and Bao, Tianyi and Yan, Junchi},
title = {Graph Out-of-Distribution Generalization via Causal Intervention},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645604},
doi = {10.1145/3589334.3645604},
abstract = {Out-of-distribution (OOD) generalization has gained increasing attentions for learning on graphs, as graph neural networks (GNNs) often exhibit performance degradation with distribution shifts. The challenge is that distribution shifts on graphs involve intricate interconnections between nodes, and the environment labels are often absent in data. In this paper, we adopt a bottom-up data-generative perspective and reveal a key observation through causal analysis: the crux of GNNs' failure in OOD generalization lies in the latent confounding bias from the environment. The latter misguides the model to leverage environment-sensitive correlations between ego-graph features and target nodes' labels, resulting in undesirable generalization on new unseen nodes. Built upon this analysis, we introduce a conceptually simple yet principled approach for training robust GNNs under node-level distribution shifts, without prior knowledge of environment labels. Our method resorts to a new learning objective derived from causal inference that coordinates an environment estimator and a mixture-of-expert GNN predictor. The new approach can counteract the confounding bias in training data and facilitate learning generalizable predictive relations. Extensive experiment demonstrates that our model can effectively enhance generalization with various types of distribution shifts and yield up to 27.4% accuracy improvement over state-of-the-arts on graph OOD generalization benchmarks.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {850–860},
numpages = {11},
keywords = {causal inference, distribution shifts, graph neural networks, graph representation learning, out-of-distribution generalization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3699538.3699580,
author = {Kiesler, Natalie and Scholz, Ingo and Albrecht, Jens and Stappert, Friedhelm and Wienkop, Uwe},
title = {Novice Learners of Programming and Generative AI - Prior Knowledge Matters},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699580},
doi = {10.1145/3699538.3699580},
abstract = {With the broad availability of Generative AI (GenAI), introductory programming education is starting to change. At Nuremberg Tech, we observed the doubling of failure rates to approximately 50% in the first semester course “Procedural Programming” across students of all study programs. Due to these exam results in winter 2023/24, we conducted a pilot study to gather students’ use of GenAI tools, their exam results, and prior programming education and experience. The results imply significant differences of students’ use of GenAI tools depending on their prior programming education. We will therefore extend the investigation in winter term 2024/25.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {51},
numpages = {2},
keywords = {GenAI, student success, programming education, introductory programming, use pattern},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1109/ASE56229.2023.00031,
author = {Peng, Yun and Wang, Chaozheng and Wang, Wenxuan and Gao, Cuiyun and Lyu, Michael R.},
title = {Generative Type Inference for Python},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00031},
doi = {10.1109/ASE56229.2023.00031},
abstract = {Python is a popular dynamic programming language, evidenced by its ranking as the second most commonly used language on GitHub. However, its dynamic type system can lead to potential type errors, leading researchers to explore automatic type inference approaches for Python programs. Existing type inference approaches can be generally grouped into three categories, i.e., rule-based, supervised, and cloze-style approaches. The rule-based type inference approaches can ensure the accuracy of predicted variable types, but they suffer from low coverage problems caused by dynamic features and external calls. Supervised type inference approaches, while feature-agnostic and able to mitigate the low coverage problem, require large, high-quality annotated datasets and are limited to pre-defined types. As zero-shot approaches, the cloze-style approaches reformulate the type inference problem into a fill-in-the-blank problem by leveraging the general knowledge in powerful pre-trained code models. However, their performance is limited since they ignore the domain knowledge from static typing rules which reflect the inference logic. What is more, their predictions are not interpretable, hindering developers' understanding and verification of the results.This paper introduces TypeGen, a few-shot generative type inference approach that incorporates static domain knowledge from static analysis. TypeGen creates chain-of-thought (COT) prompts by translating the type inference steps of static analysis into prompts based on the type dependency graphs (TDGs), enabling language models to learn from how static analysis infers types. By combining COT prompts with code slices and type hints, TypeGen constructs example prompts from human annotations. TypeGen only requires very few annotated examples to teach language models to generate similar COT prompts via in-context learning. Moreover, TypeGen enhances the interpretability of results through the use of the input-explanation-output strategy, which generates both explanations and type predictions in COT prompts. Experiments show that TypeGen outperforms the best baseline Type4Py by 10.0% for argument type prediction and 22.5% in return value type prediction in terms of top-1 Exact Match by using only five examples. Furthermore, TypeGen achieves substantial improvements of 27% to 84% compared to the zero-shot performance of large language models with parameter sizes ranging from 1.3B to 175B in terms of top-1 Exact Match.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {988–999},
numpages = {12},
keywords = {type inference, chain-of-thought, generative model},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3657604.3664701,
author = {Popescu, Diana M. and Joyner, David A.},
title = {ChatGPT's Performance on Problem Sets in an At-Scale Introductory Computer Science Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664701},
doi = {10.1145/3657604.3664701},
abstract = {This work in progress paper examines the impact of LLMs such as ChatGPT in a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform, focusing on its strengths and limitations in solving coding assignments. The study reveals ChatGPT's proficiency in some areas while highlighting challenges in pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. In order to discourage over-reliance on AI assistance from students while preserving scalability, the paper proposes strategies to enhance the difficulty of coding assignments by adding more creative elements in their structure. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {486–490},
numpages = {5},
keywords = {applied computing, artificial intelligence, e-learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3657604.3662046,
author = {Chen, Binglin and Lewis, Colleen M. and West, Matthew and Zilles, Craig},
title = {Plagiarism in the Age of Generative AI: Cheating Method Change and Learning Loss in an Intro to CS Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662046},
doi = {10.1145/3657604.3662046},
abstract = {Background: ChatGPT became widespread in early 2023 and enabled the broader public to use powerful generative AI, creating a new means for students to complete course assessments.  Purpose: In this paper, we explored the degree to which generative AI impacted the frequency and nature of cheating in a large introductory programming course. We also estimate the learning impact of students choosing to submit plagiarized work rather than their own work.  Methods: We identified a collection of markers that we believe are indicative of plagiarism in this course. We compare the estimated prevalence of cheating in the semesters before and during which ChatGPT became widely available. We use linear regression to estimate the impact of students' patterns of cheating on their final exam performance. Findings: The patterns associated with these plagiarism markers suggest that the quantity of plagiarism increased with the advent of generative AI, and we see evidence of a shift from online plagiarism hubs (e.g., Chegg, CourseHero) to ChatGPT. In addition, we observe statistically significant learning losses proportional to the amount of presumed plagiarism, but there is no statistical difference on the proportionality between semesters.  Implications: Our findings suggest that unproctored exams become increasingly insecure and care needs to be taken to ensure the validity of summative assessments. More importantly, our results suggest that generative AI can be detrimental to students' learning. It seems necessary for educators to reduce the benefit of students using generative AI for counterproductive purposes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {75–85},
numpages = {11},
keywords = {cheating, cs 1, generative ai, llm, plagiarism detection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3649165.3690094,
author = {Ma, Iris and Krone-Martins, Alberto and Videira Lopes, Cristina},
title = {Integrating AI Tutors in a Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690094},
doi = {10.1145/3649165.3690094},
abstract = {RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions.  RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98% of the time. Among the students who used AI tutors, 78% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {130–136},
numpages = {7},
keywords = {education, large language models, llms, software engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626772.3657816,
author = {Zivic, Pablo and Vazquez, Hernan and S\'{a}nchez, Jorge},
title = {Scaling Sequential Recommendation Models with Transformers},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657816},
doi = {10.1145/3626772.3657816},
abstract = {Modeling user preferences has been mainly addressed by looking at users' interaction history with the different elements available in the system. Tailoring content to individual preferences based on historical data is the main goal of sequential recommendation. The nature of the problem, as well as the good performance observed across various domains, has motivated the use of the transformer architecture, which has proven effective in leveraging increasingly larger amounts of training data when accompanied by an increase in the number of model parameters. This scaling behavior has brought a great deal of attention, as it provides valuable guidance in the design and training of even larger models. Taking inspiration from the scaling laws observed in training large language models, we explore similar principles for sequential recommendation. Addressing scalability in this context requires special considerations as some particularities of the problem depart from the language modeling case. These particularities originate in the nature of the content catalogs, which are significantly larger than the vocabularies used for language and might change over time. In our case, we start from a well-known transformer-based model from the literature and make two crucial modifications. First, we pivot from the traditional representation of catalog items as trainable embeddings to representations computed with a trainable feature extractor, making the parameter count independent of the number of items in the catalog. Second, we propose a contrastive learning formulation that provides us with a better representation of the catalog diversity. We demonstrate that, under this setting, we can train our models effectively on increasingly larger datasets under a common experimental setup. We use the full Amazon Product Data dataset, which has only been partially explored in other studies, and reveal scaling behaviors similar to those found in language models. Compute-optimal training is possible but requires a careful analysis of the compute-performance trade-offs specific to the application. We also show that performance scaling translates to downstream tasks by fine-tuning larger pre-trained models on smaller task-specific domains. Our approach and findings provide a strategic roadmap for model training and deployment in real high-dimensional preference spaces, facilitating better training and inference efficiency. We hope this paper bridges the gap between the potential of transformers and the intrinsic complexities of high-dimensional sequential recommendation in real-world recommender systems. Code and models can be found at https://github.com/mercadolibre/srt.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1567–1577},
numpages = {11},
keywords = {scaling laws, sequential recommendation, transfer learning, transformers},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3650400.3650606,
author = {Xing, Kongduo},
title = {Design and implementation of digital training evaluation management system based on AI's generative AI technology},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650606},
doi = {10.1145/3650400.3650606},
abstract = {With the advancement of information technology, traditional offline training is gradually giving way to online digital training. The conventional online digital training evaluation management system entails manual data collection followed by the utilization of these gathered data for training effectiveness assessment. This entire process is intricate and can introduce potential biases. To address these challenges, we have developed a digital training management system rooted in AI's generative AI technology. This innovative system employs both the fuzzy comprehensive evaluation method and the artificial intelligence evaluation method to assess the quality and effectiveness indexes of digital training. Furthermore, it is designed on the foundation of deep learning algorithms, creating an AI-driven digital training evaluation management system. To ensure the security and privacy of the system, extensive simulation experiments have been conducted. These experiments help control the deviation values of evaluation results, ultimately guaranteeing the fairness of outcomes generated by the evaluation system.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1222–1226},
numpages = {5},
location = {Xiamen, China},
series = {EITCE '23}
}

@article{10.5555/3717781.3717788,
author = {Works, Karen E.},
title = {Three Phase - Adversarial Search - Tile Games},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {With the advent of chatGPT and Copilot I find that students are not delving deep enough into the implementation of search approaches. To combat this, I decided to implement a three-phase adversarial search project. After lectures on adversarial search approaches and implementation examples, students are given code to a user versus user basic tile game. They are informed of the three phases of the assignment with the goal of encouraging students to understand that they are expected to be able to read and understand an adversarial search logic. In the first phase, all students use the user versus user basic tile game to implement a computer versus user basic tile game app that utilizes an adversarial search. In the second phase, students create and implement their own computer versus user basic tile game app by changing the rules on how the tile game is won and what a valid move is. In the third phase, students are given a timed 10 minute quiz where they are given code for a tile game and the rules for how the game is won and valid moves. The students must identify if the adversarial search is properly implemented and if not then what logic is not correct.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {29–32},
numpages = {4}
}

@inproceedings{10.1145/3631802.3631848,
author = {Deriba, Fitsum Gizachew and Sanusi, Ismaila Temitayo and Sunday, Amos Oyelere},
title = {Enhancing Computer Programming Education using ChatGPT- A Mini Review},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631848},
doi = {10.1145/3631802.3631848},
abstract = {This paper aims to provide insights into how ChatGPT enhances computer programming education by synthesizing existing studies using rapid review. We analysed 13 articles published in 2023, where studies focused on different aspects of basic programming education. The results indicate that 21% of these studies demonstrate that ChatGPT served as a tool for code explanation and handling complex topics. However, 36% show that ChatGPT had difficulty answering non-text-based and code-related questions, revealing reliability and accuracy issues with these tools. Another 36% of the studies showed that blindly over-reliance on ChatGPT affected critical thinking, student creativity, and problem-solving skills in programming education. 46% of the studies indicated the need to provide clear guidelines and employ plagiarism-detection tools to instruct students effectively. We suggest that educators should adopt diverse approaches to integrating ChatGPT as an educational tool while highlighting ethical considerations and model limitations.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {45},
numpages = {2},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3689535.3689537,
author = {Stone, Irene},
title = {Investigating the Use of ChatGPT to Support the Learning of Python Programming Among Upper Secondary School Students: A Design-Based Research Study},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689537},
doi = {10.1145/3689535.3689537},
abstract = {This study investigates how ChatGPT can be used to support the learning of Python programming among upper second-level students in an Irish classroom. It addresses critical gaps in the literature, such as the lack of research at secondary level, the need for human-centered studies conducted over time, and the absence of guidelines for integrating ChatGPT into introductory programming education. Employing a design-based research methodology, this study aims to understand student engagement with ChatGPT and investigates how to support their use of prompts when learning to program. The research involves students as co-creators alongside their teacher, who is also the researcher, in developing a pedagogical framework that integrates ChatGPT into Python programming education.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {11},
numpages = {1},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, design-based research, generative AI, human-centered, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3626253.3635595,
author = {Hamerski, Patti C.},
title = {Generative AI as a Resource for Creativity in Computational Physics},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635595},
doi = {10.1145/3626253.3635595},
abstract = {Generative artificial intelligence (gen-AI) has become ubiquitous in daily life, including classroom environments where students are using it to assist them on their coursework. Given the widespread use of this tool and the lack of knowledge over how it can support learning, there is a need for educators to have a framework for using it in the classroom and teaching their students usage strategies that are beneficial for learning. One pathway forward is through creativity, a process crucial for learning and also connected to the act of using gen-AI. This poster demonstrates the results of a study designed to provide an in-depth view on how creativity intersects with gen-AI usage in a computational physics course. In the course, students learn about computing tools during group-based, open-ended computational physics activities. Students are often tasked with using gen-AI to explore and help make decisions. The findings demonstrate a connection between using gen-AI and engaging in creative processes, and the implications point to strategies for supporting student usage of gen-AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1666–1667},
numpages = {2},
keywords = {computational science, creativity, curriculum design, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3669754.3669806,
author = {Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan},
title = {Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669806},
doi = {10.1145/3669754.3669806},
abstract = {Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {339–344},
numpages = {6},
keywords = {ChatGPT, PLS-SEM, education, generative AI, programming},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inproceedings{10.1145/3639474.3640059,
author = {Fwa, Hua Leong},
title = {Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640059},
doi = {10.1145/3639474.3640059},
abstract = {Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {233–241},
numpages = {9},
keywords = {LLM, ChatGPT, misconception, programming, errors, cluster, prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3649217.3653558,
author = {Pang, Ashley and Vahid, Frank},
title = {ChatGPT and Cheat Detection in CS1 Using a Program Autograding System},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653558},
doi = {10.1145/3649217.3653558},
abstract = {We experimented with ChatGPT's ability to write programs in a CS1 class, and the ability of a popular tool to auto-detect ChatGPT-written programs. We found ChatGPT was proficient at generating correct programs from a mere copy-paste of the English programming assignment specifications. However, running ChatGPT for 10 programming assignments and acting as 20 different students, and using zyBook's APEX beta tool for academic integrity, we found: (1) ChatGPT-generated programs tend to use a programming style departing from the style taught in the textbook or by the instructor, and these "style anomalies" were automatically detected. (2) Although ChatGPT may for the same assignment generate a few different program solutions for different students, ChatGPT often generates highly-similar programs for different students, so if enough students in a class (e.g., 5 or more) use ChatGPT, their programs will likely be flagged by a similarity checker. (3) If students are required to do all programming in the autograder's IDE, then a student using ChatGPT ends up showing very little time relative to classmates, which is automatically flagged. (4) Manually, we observed that if a student consistently uses ChatGPT to submit programs, the programming style may vary across programs, something normal students don't do; automation of style inconsistency detection was recently added to APEX. In short, while there will no doubt be an arms race between AI-generated programs and automatic detection of AI-generated programs, currently students using ChatGPT for multiple CS1 programs can be detected by automated tools such as zyBooks' APEX.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {367–373},
numpages = {7},
keywords = {CS1, ChatGPT, academic integrity, cheat detection, large language models, plagiarism, similarity checking, style anomalies},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653602,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {Guidelines for the Evolving Role of Generative AI in Introductory Programming Based on Emerging Practice},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653602},
doi = {10.1145/3649217.3653602},
abstract = {In the rapidly evolving Generative AI (GenAI) landscape, source code and natural language are being mixed and used in new ways. This presents opportunities for rethinking teaching practice in Introductory Programming (CS1) courses that includes, but goes beyond, assessment. In this paper we examine the reasons why and how instructors who are early adopters of GenAI are using it in their teaching, and why others are not. We also explore the changes and adaptations that are currently being made to practice. This is achieved by synthesizing insights from several recent studies that have collected primary data from introductory programming instructors who are teaching with, considering teaching with, or actively not teaching with GenAI.Due to the fast pace of GenAI development and adoption, the fixed-pace and cyclical nature of education, and the relatively slow pace of research (including ethical approvals) and publication cycles, research with primary data from instructors is only being published relatively recently. In computing education, there is not yet enough published research with primary data from CS1 instructors to warrant a systematic literature review, although in the next year this will likely be possible. Based on an analysis of the nascent research that has been published, we propose emerging and flexible guidelines on how CS1 instructors could adapt their practice based on what others have done so far. These guidelines highlight important factors to consider when integrating GenAI in CS1 courses, which for many is only beginning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {10–16},
numpages = {7},
keywords = {CS1, LLM, artificial intelligence, automated/assisted code generation, chatgpt, computing education, copilot, generative AI, introductory programming, k-12, large language model, machine learning, novice programmer, school},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649165.3690125,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Prather, James and Leinonen, Juho and Luxton-Reilly, Andrew and MacNeil, Stephen},
title = {Integrating Natural Language Prompting Tasks in Introductory Programming Courses},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690125},
doi = {10.1145/3649165.3690125},
abstract = {Introductory programming courses often emphasize mastering syntax and basic constructs before progressing to more complex and interesting programs. This bottom-up approach can be frustrating for novices, shifting the focus away from problem solving and potentially making computing less appealing to a broad range of students. The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module. The first requires students to solve computational problems by writing natural language prompts, emphasizing problem-solving over syntax. The second involves students crafting prompts to generate code equivalent to provided fragments, to foster an understanding of the relationship between prompts and code. Most of the students in the course had reported finding programming difficult to learn, often citing frustrations with syntax and debugging. We found that self-reported difficulty with learning programming had a strong inverse relationship with performance on traditional programming assessments such as tests and projects, as expected. However, performance on the natural language tasks was less strongly related to self-reported difficulty, suggesting they may target different skills. Learning how to communicate with AI coding models is becoming an important skill, and natural language prompting tasks may appeal to a broad range of students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {88–94},
numpages = {7},
keywords = {cs1, eipe, explain in plain english, introductory programming, llm, natural language prompting, prompt engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3670653.3677507,
author = {Kubullek, Ann-Kathrin and Kuma\c{c}, Nadire and Dogang\"{u}n, Ayseg\"{u}l},
title = {Understanding the Adoption of ChatGPT in Higher Education: A Comparative Study with Insights from STEM and Business Students},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3677507},
doi = {10.1145/3670653.3677507},
abstract = {Since ChatGPT’s introduction, generative artificial intelligence (AI) has significantly influenced the media, technological innovation, and educational discourse. Its increasing importance, especially in academia, necessitates a detailed examination of the impact of AI on higher education, particularly on how it changes teaching and learning processes. This study therefore looks at the factors affecting students’ attitudes towards AI technologies in the university setting, with a particular focus on the differences between business and STEM programmes. Using a mixed methods approach, the study combines surveys and interviews to collect data on students’ perceptions, attitudes and experiences with generative AI technology in academia. The data collected is analysed both quantitatively and qualitatively to reveal significant trends and insights into the adoption and use of generative AI tools in the university environment. The main objective of the study is to shed light on the determinants that determine the varying degrees of AI adoption in different academic disciplines. The findings have the potential to inform the implementation of educational technology and assist in the development of strategies for the effective integration of generative AI tools to meet the different needs and preferences of students in a range of academic contexts.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {684–689},
numpages = {6},
keywords = {ChatGPT, STEM degree programs, academic disciplines, acceptance of AI, business degree programs, generative AI adoption, higher education, students},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@inproceedings{10.1145/3640544.3645234,
author = {George, Samuel D and Dewan, Prasun},
title = {NotebookGPT – Facilitating and Monitoring Explicit Lightweight Student GPT Help Requests During Programming Exercises},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645234},
doi = {10.1145/3640544.3645234},
abstract = {The success of GPT with coding tasks has made it important to consider the impact of GPT and similar models on teaching programming. Students’ use of GPT to solve programming problems can hinder their learning. However, they might also get significant benefits such as quality feedback on programming style, explanations of how a given piece of code works, help with debugging code, and the ability to see valuable alternatives to their code solutions. We propose a new design for interacting with GPT called Mediated GPT with the goals of (a) providing students with access to GPT but allowing instructors to programmatically modify responses to prevent hindrances to student learning and combat common GPT response concerns, (b) helping students generate and learn to create effective prompts to GPT, and (c) tracking how students use GPT to get help on programming exercises. We demonstrate a first-pass implementation of this design called NotebookGPT.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {62–65},
numpages = {4},
keywords = {ChatGPT, Computer programming, GPT, Intelligent tutoring systems, Learning at scale},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3613904.3642773,
author = {Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi},
title = {CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642773},
doi = {10.1145/3613904.3642773},
abstract = {Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {650},
numpages = {20},
keywords = {AI assistants, AI tutoring, class deployment, design guidelines, educational technology, generative AI, intelligent tutoring systems, large language models, programming education},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3579168.3632724,
author = {Ho, Shuyuan Mary and Liu, Yue},
title = {Genie Breaks the Bottle: Ethics in Artificial Intelligence Adoption: ChatGPT; The Beginning and the End of Human Wisdom},
year = {2024},
isbn = {9798400700941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579168.3632724},
doi = {10.1145/3579168.3632724},
abstract = {ChatGPT, developed by OpenAI, has attracted significant attention from early adopters. While this generative artificial intelligence (AI) system can be somewhat intuitive, such technology can also be disruptive in domains that require creativity (e.g., computer coding, system development and education), information authenticity (e.g., news agencies) and precision (e.g., manufacturing, clinical decision making). This study urges scholars in the fields of human-computer interaction and information system to reexamine technology adoption to better understand the criticality and ethics of AI and ChatGPT with regards to social change and social impact.},
booktitle = {Proceedings of the 2023 Computers and People Research Conference},
articleno = {6},
numpages = {4},
keywords = {Artificial intelligence, ChatGPT, deepfakes, generative adversarial networks, information ethics, social change},
location = {Pomona, CA, USA},
series = {SIGMIS-CPR '23}
}

@inproceedings{10.1145/3636243.3636248,
author = {Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen},
title = {The Effects of Generative AI on Computing Students’ Help-Seeking Preferences},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636248},
doi = {10.1145/3636243.3636248},
abstract = {Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {39–48},
numpages = {10},
keywords = {ChatGPT, Generative AI, computing education, help-seeking},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3675812.3675877,
author = {Huang, Lei and Liu, Xiyu and Xie, Chunqiu and Zhu, Wenjuan},
title = {Investigating Factors Influencing University Students' Use of intelligent Audio Reading Platform for Reading and Learning},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675877},
doi = {10.1145/3675812.3675877},
abstract = {In recent years, with the rapid development of information technology and advances in smart technologies, the modes of reading have become more diversified. It is now possible not only to read books with one's eyes but also to "listen" to them, offering the better reading experience. University students need to constantly absorb information and knowledge from the outside world, which means that they need an efficient and easy way to read and learn, and the use of intelligent audio reading platform can fulfill this need. Therefore, in order to propose strategies to promote university students' use of intelligent audio reading platforms for reading and learning, this study employs a questionnaire survey to investigate the factors influencing university students' behavioral intention to use audio reading platform for reading and learning. A sample of 236 university students was analyzed using the Partial Least Squares Structural Equation Modelling technique (PLS-SEM). Results showed that perceived usefulness, perceived ease of use, and social influence have a significant positive influence on the behavioral intention of university students to use audio reading platform for reading and learning, while perceived cost and perceived enjoyment have no significant influence on the behavioral intention. Based on these results, this study proposes strategies for university teachers, intelligent audio reading platform developers and operators to promote university students’ use of intelligent audio reading platform for reading and learning. For university teachers, they can promote the adoption of audio reading by guiding students to use audio reading platforms for learning. For developers of an intelligent audio reading platform, based on generative AI, they can enhance reading and learning experience for university students by optimizing personalized recommendation functions and offering diverse reading preferences, such as pronunciation styles and speeds. For operators of intelligent audio reading platforms, they can ensure high-quality content, stable network connections, and reasonable pricing strategies to enhance university students’ reading and learning experience.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {131–137},
numpages = {7},
keywords = {Intelligent audio reading platform, influencing factors, university students},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3660853.3660915,
author = {Karaca, Mehmet F.},
title = {Is Artificial Intelligence able to Produce Content Appropriate for Education Level? A Review on ChatGPT and Gemini},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660915},
doi = {10.1145/3660853.3660915},
abstract = {This study examined 120 Turkish stories written for primary, secondary, high school, and undergraduate education levels by ChatGPT-3.5, ChatGPT-4, and Gemini1.5 Pro. The data was processed by software created with Natural Language Processing methods in mind. The general characteristics, quantitative characteristics, and readability of the stories were all reviewed within the scope of the study. Using the Ate\c{s}man and Bezirci-Y\i{}lmaz formulas, which are widely used for Turkish texts, the readability of the stories was calculated. As a result of the analysis, it was determined that AI is able to produce distinct stories, and it generates cohesive stories by utilizing subjects and themes that are suitable for a specific educational audience. When the average readabilities are taken into account, it has been found that ChatGPT-3.5 generates better stories suited for the education level based on the Ate\c{s}man formula and Gemini based on the Bezirci-Y\i{}lmaz formula, and the difficulty level of ChatGPT-3.5 stories rises in tandem with education level in both formulas. Also, the stories at the undergraduate level were found to be the hardest to read and with primary schools having the easiest readability. When the number of stories at readability levels is taken into account, it has been found that GPT-3.5 and ChatGPT-4 in the Ate\c{s}man formula and ChatGPT-3.5, ChatGPT-4, and Gemini in the Bezirci-Y\i{}lmaz formula generate appropriate stories for the education level; the levels range from easy to difficult as the education level increases. Additionally, it has been found that the number of stories included is gradually increasing. It was concluded that AIs produced stories above their educational level; while ChatGPT-3.5 and Gemini were more successful in story production, the Bezirci-Y\i{}lmaz formula was better in determining readability.},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {208–213},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Gemini, Natural Language Processing, Readability},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

@inproceedings{10.1145/3631802.3631807,
author = {Jeuring, Johan and Groot, Roel and Keuning, Hieke},
title = {What Skills Do You Need When Developing Software Using ChatGPT? (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631807},
doi = {10.1145/3631802.3631807},
abstract = {Since the release of LLM-based tools such as GitHub Copilot and ChatGPT the media and popular scientific literature, but also journals such as the Communications of the ACM, have been flooded with opinions how these tools will change programming. The opinions range from “machines will program themselves”, to “AI does not help programmers”. Of course, these statements are meant to to stir up a discussion, and should be taken with a grain of salt, but we argue that such unfounded statements are potentially harmful. Instead, we propose to investigate which skills are required to develop software using LLM-based tools. In this paper we report on an experiment in which we explore if Computational Thinking (CT) skills predict the ability to develop software using LLM-based tools. Our results show that the ability to develop software using LLM-based tools can indeed be predicted by the score on a CT assessment. There are many limitations to our experiment, and this paper is also a call to discuss how to approach, preferably experimentally, the question of which skills are required to develop software using LLM-based tools. We propose to rephrase this question to include by what kind of people/programmers, to develop what kind of software using what kind of LLM-based tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {38},
numpages = {6},
keywords = {ChatGPT, Computational thinking skills, LLM-based tools, Software development skills},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3626252.3630951,
author = {Vahid, Frank and Pang, Ashley and Denzler, Benjamin},
title = {Towards Comprehensive Metrics for Programming Cheat Detection},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630951},
doi = {10.1145/3626252.3630951},
abstract = {Automated assistance for detecting cheating on programs has long been investigated by CS educators, especially with the rise of "homework help" websites over the past decade, and recently with AI tools like ChatGPT. The main detection approach has long been flagging similar submission pairs. Modern cheating, like hiring contractors or using ChatGPT, may not yield such similarity. And, cases based on similarity alone may be weak. Thus, over the past several years, building on logs from an online program auto-grader (zyBooks), we developed additional "cheating concern metrics": points rate, style anomalies, style inconsistencies, IP address anomalies, code replacements, and initial copying. Most are defined not only for one programming assignment but also across a set of assignments. The metrics can help catch more kinds of cheating, provide more compelling evidence of cheating, reduce false cheating accusations based on similarity alone, and help instructors focus their limited cheat-detection time on the most egregious cases. We describe the techniques, and our experiences (via our own Python scripts and a commercial tool) for several terms, showing benefits of having more metrics than just similarity. Of 30 cheating cases over 3 terms and 300 students, most were based on metrics beyond similarity, all students admitted, none later contested, and time per student was only 1-2 hours (far less than previously). Our goal is to prevent cheating in the first place, by reducing opportunity via strong detection tools, as part of a multi-faceted approach to having students truly learn and stay out of trouble.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1361–1367},
numpages = {7},
keywords = {ai, cheating, cs1, homework, plagiarism, programming assignments},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3690113,
author = {Kasinidou, Maria and Kleanthous, Styliani and Otterbacher, Jahna},
title = {"We have to learn to work with such systems": Students' Perceptions of ChatGPT After a Short Educational Intervention on NLP},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690113},
doi = {10.1145/3649165.3690113},
abstract = {Natural Language Processing (NLP) is a critical area of AI that is increasingly integrated into everyday life. The public regularly engages with systems such as Siri, Alexa, and more recently, ChatGPT, yet few understand how these systems work. In this paper, we examine how students perceive NLP technologies after completing a unit on NLP within an AI course designed for non-CS majors. We further present our students' perspectives on the banning of ChatGPT in Italy, where the course was delivered. The NLP unit featured a lecture, an interactive session, and a practical assignment wherein students developed a smart assistant responsive to textual commands. Students, after creating their smart assistants, highlighted challenges such as inadequate training datasets and natural language ambiguity. Opinions on ChatGPT's ban varied, with privacy concerns prevailing. However, a consensus emerged in favor of educational efforts to raise awareness about technology limitations, advocating understanding over outright bans in anticipation of their inevitable integration into daily life.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {74–80},
numpages = {7},
keywords = {artificial intelligence, chatgpt, large language models, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3670013.3670058,
author = {Torrato, Janette B. and Pillar, Genevieve A. and Robledo, Dave Arthur R. and Aguja, Socorro E. and Prudente, Maricar S.},
title = {Knowledge, Attitudes, and Practices on ChatGPT:Perspectives from Students and Teachers of De La Salle Santiago Zobel School},
year = {2024},
isbn = {9798400717062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670013.3670058},
doi = {10.1145/3670013.3670058},
abstract = {Abstract. Chat Generative Pre-trained Transformer (ChatGPT) is an artificial intelligence (AI) system that is gaining popularity among students and teachers. However, in the basic education level, the use of ChatGPT is still an ongoing discussion, particularly on how to regulate its use. This study endeavors to describe the perspectives of teachers and students about ChatGPT in terms of their knowledge, attitudes, and practices to better appreciate its role in advancing teaching and learning. This descriptive survey involved a total of (N=187) respondents, including students from Grade 6 (n=70), Grade 10 (n=38), and Grade 12 (n=18) and teachers (n=61). The newly developed 39-item Knowledge, Attitudes, Practices on ChatGPT Questionnaire (KAP-CQ39) with a Cronbach α = 0.91 was used as the primary instrument in understanding and leveraging the academic potential of this AI system. Open-ended questions on the advantages and disadvantages of using ChatGPT are also included in the questionnaire. KAP-CQ39 was administered online using Google Forms. Data culled from the survey was analyzed using an online open-source program referred to as Jeffreys's Amazing Statistics Program (JASP). Results revealed no significant difference in perspectives between teachers (mean=11.88) and students (mean=11.46) knowledge on ChatGPT F (2,169) =2.66, p=0.104. Similarly, attitudes towards the educational use of ChatGPT showed that both teachers and students hold positive attitudes. Demographic factors contributing to the differences in teachers’ perspectives on the educational use of ChatGPT were sex, years of teaching experience, and specialization. For the students, the demographic factors did not contribute to the differences in their perspectives. Generally, in terms of practices, responses provided valuable insights into how ChatGPT can be better designed and implemented for teaching and learning. Thus, policy implications were drawn relative to the efficient use of ChatGPT.},
booktitle = {Proceedings of the 2024 15th International Conference on E-Education, E-Business, E-Management and E-Learning},
pages = {107–116},
numpages = {10},
location = {Fukuoka-shi, Japan},
series = {IC4E '24}
}

@inproceedings{10.1145/3626253.3635398,
author = {Mousa, Raneem Emad and Veilleux, Nanette},
title = {Is ChatGPT the Academic Catalyst We've all been Waiting For?},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635398},
doi = {10.1145/3626253.3635398},
abstract = {The excitement around ChatGPT 3.5 underscores its potential to transform various fields in education, including STEM. However, we must approach these claims cautiously. While AI can enhance STEM education, there are ethical concerns and potential inaccuracies linked to unsupervised automated responses. To comprehensively evaluate ChatGPT's influence on STEM, we conducted a controlled experiment that involved answering a question set in mathematics and CS in a time-limited session. To avoid bias, we recruited four groups of math and CS students with similar abilities -each group comprised five students. Two groups utilized ChatGPT, while the other two did not. Students who used ChatGPT were tasked with explaining how and where they employed the tool. Conversely, students who did not use ChatGPT were asked to showcase their problem-solving process. We analyzed the responses from these four groups, alongside the analysis of ChatGPT conversations for those who employed ChatGPT. Performance, confidence level, and completion time of each participant were recorded. Experts in mathematics and CS were then consulted to review participant responses. These experts were subsequently interviewed to gain deeper insights and draw conclusive findings. Our findings show that students who didn't use ChatGPT in Mathematics scored better than those who did, Specifically, ChatGPT provided the correct working process but yielded a wrong final answer due to arithmetic mistakes. Similarly, in programming, ChatGPT led to less elegant code. Our findings provide valuable insights into the benefits and challenges of AI integration in these fields, helping educators and students to adapt to AI advancements.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1885},
numpages = {1},
keywords = {ai, chatgpt, education, stem},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3674805.3690753,
author = {d'Aloisio, Giordano and Fortz, Sophie and Hanna, Carol and Fortunato, Daniel and Bensoussan, Avner and Mendiluze Usandizaga, E\~{n}aut and Sarro, Federica},
title = {Exploring LLM-Driven Explanations for Quantum Algorithms},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690753},
doi = {10.1145/3674805.3690753},
abstract = {Background: Quantum computing is a rapidly growing new programming paradigm that brings significant changes to the design and implementation of algorithms. Understanding quantum algorithms requires knowledge of physics and mathematics, which can be challenging for software developers. Aims: In this work, we provide a first analysis of how LLMs can support developers’ understanding of quantum code. Method: We empirically analyse and compare the quality of explanations provided by three widely adopted LLMs (Gpt3.5, Llama2, and Tinyllama) using two different human-written prompt styles for seven state-of-the-art quantum algorithms. We also analyse how consistent LLM explanations are over multiple rounds and how LLMs can improve existing descriptions of quantum algorithms. Results: Llama2 provides the highest quality explanations from scratch, while Gpt3.5 emerged as the LLM best suited to improve existing explanations. In addition, we show that adding a small amount of context to the prompt significantly improves the quality of explanations. Finally, we observe how explanations are qualitatively and syntactically consistent over multiple rounds. Conclusions: This work highlights promising results, and opens challenges for future research in the field of LLMs for quantum code explanation. Future work includes refining the methods through prompt optimisation and parsing of quantum code explanations, as well as carrying out a systematic assessment of the quality of explanations.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {475–481},
numpages = {7},
keywords = {Code Explainability., Large Language Models, Quantum Computing},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3689535.3689553,
author = {Stone, Irene},
title = {Exploring Human-Centered Approaches in Generative AI and Introductory Programming Research: A Scoping Review},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689553},
doi = {10.1145/3689535.3689553},
abstract = {Recent advancements in generative artificial intelligence are poised to reshape introductory programming education, challenging conventional teaching methodologies. This paper presents a scoping review that explores the current understanding of integrating generative artificial intelligence tools in the learning of introductory programming. Through an analysis of 28 selected studies, this review provides a snapshot of the landscape in mid-2024, presenting benefits, concerns, and recommendations surrounding the use of generative artificial intelligence within programming education. It finds insufficient guidance on how to implement recommended pedagogical strategies, limited consideration of student perceptions and experiences, and a predominance of short study time frames. Additionally, there is a significant research gap in second-level education, particularly in the United Kingdom and Ireland. The paper discusses how these gaps signal a need for more human-centered approaches in the current research. The paper concludes with recommendations for future research, aiming to inspire further inquiry and advance the understanding of generative artificial intelligence’s role in programming education from a human-centered perspective.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {4},
numpages = {7},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, code generation, generative AI, human-centered, learner perspectives, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3649217.3653621,
author = {Margulieux, Lauren E. and Prather, James and Reeves, Brent N. and Becker, Brett A. and Cetin Uzun, Gozde and Loksa, Dastyni and Leinonen, Juho and Denny, Paul},
title = {Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653621},
doi = {10.1145/3649217.3653621},
abstract = {We explored how undergraduate introductory programming students naturalistically used generative AI to solve programming problems. We focused on the relationship between their use of AI to their self-regulation strategies, self-efficacy, and fear of failure in programming. In this repeated-measures, mixed-methods research, we examined students' patterns of using generative AI with qualitative student reflections and their self-regulation, self-efficacy, and fear of failure with quantitative instruments at multiple times throughout the semester. We also explored the relationships among these variables to learner characteristics, perceived usefulness of AI, and performance. Overall, our results suggest that student factors affect their baseline use of AI. In particular, students with higher self-efficacy, lower fear of failure, or higher prior grades tended to use AI less or later in the problem-solving process and rated it as less useful than others. Interestingly, we found no relationship between students' self-regulation strategies and their use of AI. Students who used AI less or later in problem-solving also had higher grades in the course, but this is most likely due to prior characteristics as our data do not suggest that this is a causal relationship.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {276–282},
numpages = {7},
keywords = {CS1, LLMs, artificial intelligence, copilot, fear of failure, generative ai, introductory programming, large language models, metacognition, self-efficacy, self-regulated learning, self-regulation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1109/TCBB.2024.3477592,
author = {Zhao, Dengwei and Zhou, Jingyuan and Tu, Shikui and Xu, Lei},
title = {&lt;italic&gt;De Novo&lt;/italic&gt; Drug Design by Multi-Objective Path Consistency Learning With Beam A&lt;sup&gt;*&lt;/sup&gt; Search},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3477592},
doi = {10.1109/TCBB.2024.3477592},
abstract = {Generating high-quality and drug-like molecules from scratch within the expansive chemical space presents a significant challenge in the field of drug discovery. In prior research, value-based reinforcement learning algorithms have been employed to generate molecules with multiple desired properties iteratively. The immediate reward was defined as the evaluation of intermediate-state molecules at each step, and the learning objective would be maximizing the expected cumulative evaluation scores for all molecules along the generative path. However, this definition of the reward was misleading, as in reality, the optimization target should be the evaluation score of only the final generated molecule. Furthermore, in previous works, randomness was introduced into the decision-making process, enabling the generation of diverse molecules but no longer pursuing the maximum future rewards. In this paper, immediate reward is defined as the improvement achieved through the modification of the molecule to maximize the evaluation score of the final generated molecule exclusively. Originating from the A&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$^*$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;*&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq3-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; search, path consistency (PC), i.e., &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$f$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq4-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; values on one optimal path should be identical, is employed as the objective function in the update of the &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$f$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq5-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; value estimator to train a multi-objective &lt;italic&gt;de novo&lt;/italic&gt; drug designer. By incorporating the &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$f$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq6-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; value into the decision-making process of beam search, the DrugBA&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$^*$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;*&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq7-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; algorithm is proposed to enable the large-scale generation of molecules that exhibit both high quality and diversity. Experimental results demonstrate a substantial enhancement over the state-of-the-art algorithm QADD in multiple molecular properties of the generated molecules.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = oct,
pages = {2459–2470},
numpages = {12}
}

@inproceedings{10.1145/3699538.3699591,
author = {Keuning, Hieke and Luxton-Reilly, Andrew and Ott, Claudia and Petersen, Andrew and Kiesler, Natalie},
title = {Goodbye Hello World - Research Questions for a Future CS1 Curriculum},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699591},
doi = {10.1145/3699538.3699591},
abstract = {Generative AI (GenAI) is currently capable of generating correct code for introductory level programming problems, and its performance is improving. We believe that this capability can be leveraged to improve student motivation, broaden students’ understanding of software development, and engage them in more authentic learning. We defined a set of assumptions about GenAI’s future capabilities (e.g., the ability to generate small pieces of code and to compose these pieces of code via user prompts) and engaged in a backcasting exercise to identify what else is needed to develop a CS1 course that places GenAI in a central role. Undertaking this thought experiment immediately revealed that aspects of the software development process usually reserved for later in the curriculum, such as requirements elicitation and design, could be introduced earlier in the process. With GenAI tools bearing the load of generating correct code snippets, students could focus on higher-level software design and construction skills and practice them in an authentic environment. Our thought experiment identified a set of questions that need to be addressed for such a course to actually exist, including questions about student preparation, and the ability of students to decompose problems effectively and to resolve problems that arise when integrating pieces of code. We also identified questions related to the design of a GenAI centered course, such as the impact on student motivation of using GenAI instead of engaging directly with code, the extent to which social learning theories apply to interactions with GenAI, and how existing pedagogies can integrate GenAI tools.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {27},
numpages = {2},
keywords = {Computing education, CS1, Generative AI, Mastery Learning, LLMs},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3649217.3653608,
author = {Pankiewicz, Maciej and Baker, Ryan S.},
title = {Navigating Compiler Errors with AI Assistance - A Study of GPT Hints in an Introductory Programming Course},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653608},
doi = {10.1145/3649217.3653608},
abstract = {We examined the efficacy of AI-assisted learning in an introductory programming course at the university level by using a GPT-4 model to generate personalized hints for compiler errors within a platform for automated assessment of programming assignments. The control group had no access to GPT hints. In the experimental condition GPT hints were provided when a compiler error was detected, for the first half of the problems in each module. For the latter half of the module, hints were disabled. Students highly rated the usefulness of GPT hints. In affect surveys, the experimental group reported significantly higher levels of focus and lower levels of confrustion (confusion and frustration) than the control group. For the six most commonly occurring error types we observed mixed results in terms of performance when access to GPT hints was enabled for the experimental group. However, in the absence of GPT hints, the experimental group's performance surpassed the control group for five out of the six error types.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {94–100},
numpages = {7},
keywords = {GPT, LLM, automated assessment, large language models, programming education},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626252.3630832,
author = {Sakzad, Amin and Paul, David and Sheard, Judithe and Brankovic, Ljiljana and Skerritt, Matthew P. and Li, Nan and Minagar, Sepehr and Simon and Billingsley, William},
title = {Diverging assessments: What, Why, and Experiences},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630832},
doi = {10.1145/3626252.3630832},
abstract = {In this experience paper, we introduce the concept of 'diverging assessments', process-based assessments designed so that they become unique for each student while all students see a common skeleton. We present experiences with diverging assessments in the contexts of computer networks, operating systems, ethical hacking, and software development. All the given examples allow the use of generative-AI-based tools, are authentic, and are designed to generate learning opportunities that foster students' meta-cognition. Finally, we reflect upon these experiences in five different courses across four universities, showing how diverging assessments enhance students' learning while respecting academic integrity.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1161–1167},
numpages = {7},
keywords = {assessment-as-learning, authentic assessment, diverging assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3715622.3715630,
author = {Lindoo, Ed and Lotfy, Mohamed},
title = {Generative AI and its Impact on the CS Classroom and Programmers},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {As the integration of generative artificial intelligence (AI) in educational settings becomes more widespread, students, teachers, and educational institutions face the challenge of utilizing these technologies in a responsible manner. The responsible use of generative AI can help CS and IT students develop critical thinking, enhance their learning experience, facilitate the learning process, can assist in understanding code concepts, programming skills, and/or enhancing the programming knowledge. The aim of this investigation is on how students might utilize, and potentially abuse, generative AI. In this paper we provide examples of how generative AI can be used to generate code modules. We discuss the use of generative AI in programming classes as well as its impact on the future of programming and programmers.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {35–50},
numpages = {16}
}

@inproceedings{10.1145/3626252.3630875,
author = {Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki},
title = {Improved Program Repair Methods using Refactoring with GPT Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630875},
doi = {10.1145/3626252.3630875},
abstract = {Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {569–575},
numpages = {7},
keywords = {generative ai, program repair, programming assignment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630761,
author = {Mason, Raina and Simon and Becker, Brett A. and Crick, Tom and Davenport, James H.},
title = {A Global Survey of Introductory Programming Courses},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630761},
doi = {10.1145/3626252.3630761},
abstract = {We present results of an in-depth survey of nearly 100 introductory programming (CS1) instructors in 18 countries spanning six continents. Although CS1 is well studied, relatively few broadly-scoped studies have been conducted, and none prior have exceeded regional scale. In addition, CS1 is a notoriously fickle and often changing course, and many might find it beneficial to know what other instructors are doing across the globe; perhaps more so as we continue to understand the impact of the COVID-19 pandemic on computing education and as the effects of Generative AI take hold. Expanding upon several surveys conducted in Australasia, the UK, and Ireland, this survey facilitates a direct comparison of global trends in CS1. The survey goes beyond environmental factors such as languages used, and examines why CS1 instructors teach what they do, in the ways they do. In total the survey spans 84 institutions and 91 courses in which a total of over 40,000 students are enrolled.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {799–805},
numpages = {7},
keywords = {covid-19, cs 1, cs-1, cs1, global, instructors, introductory programming, novice programmers, programming languages, survey, teaching languages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3689535.3689538,
author = {Sentance, Sue and Watson, Steven and Addo, Salomey Afua and Shi, Shengpeng and Waite, Jane and Yu, Bo},
title = {Developing Computing Teacher Guidance on GenAI},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689538},
doi = {10.1145/3689535.3689538},
abstract = {Generative AI (GenAI) is becoming widely available for use in schools by teachers and students. While many educators appreciate the potential benefits of GenAI for enhancing learning, there are also significant concerns about authorship, authenticity, plagiarism, ethics, biases, and the broader implications of their use in education. For computing teachers in schools, these issues can be even more acute. In this project, we established a working group of practising computing teachers to bring together a range of views and experiences. Initial results of the project led to a booklet for computing teachers on how to use GenAI, illustrating the effectiveness of teacher-researcher partnerships in developing resources for school use. This project will be followed by further work on computing teachers’ actual experience of GenAI in practice.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {12},
numpages = {1},
keywords = {AI education, K-12 education, generative AI, teachers},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3675812.3675871,
author = {Zhong, Xuanyan and Xin, Haiyang and Li, Wenfeng and Zhan, Zehui and Cheng, May-hung},
title = {The Design and application of RAG-based conversational agents for collaborative problem solving},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675871},
doi = {10.1145/3675812.3675871},
abstract = {Dialogue is the basis of collaborative problem solving, and the development of generative artificial intelligence has made dialogue no longer limited to human-to-human, and human-computer dialogue has gradually become an important way for people to solve problems. At the same time, with the change of the subject of collaborative problem solving, the cultivation of collaborative problem-solving skill urgently needs to explore a new path. In this regard, more and more studies have begun to apply conversational agents in collaborative problem-solving activities, digging deeper into the effects of time on students in conversational agents. However, there is no clear answer to the question of how conversational agents can be better integrated into a collaborative environment for all to assist people in the collaborative problem-solving process and improve performance. In this study, we constructed a conceptual model of human-computer collaboration in order to improve students' learning performance. Based on this model, we integrated Retrieval-Augmented Generative and GPT to construct a conversational agent, and the results of the study showed that the Retrieval-Augmented Generative Agent for Collaborative Problem Solving constructed in this study can effectively promote students' collaborative problem-solving performance.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {62–68},
numpages = {7},
keywords = {Collaborative problem solving, Conversational agent, GPT},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3640544.3645231,
author = {George, Samuel D and Huang, Tao and Robinson, Chandler and Schell, Gabriel and Shan, Wei and Zhao, Ziqian and Zhou, Zeqi and Dewan, Prasun},
title = {Assistant Dashboard Plus – Enhancing an Existing Instructor Dashboard with Difficulty Detection and GPT-based Code Clustering},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645231},
doi = {10.1145/3640544.3645231},
abstract = {As interest in programming as a major grows, instructors must accommodate more students in their programming courses. One particularly challenging aspect of this growth is providing quality assistance to students during in-class and out-of-class programming exercises. Prior work proposes using instructor dashboards to help instructors combat these challenges. Further, the introduction of ChatGPT represents an exciting avenue to assist instructors with programming exercises but needs a delivery method for this assistance. We propose a revision of a current instructor dashboard Assistant Dashboard Plus that extends an existing dashboard with two new features: (a) identifying students in difficulty so that instructors can effectively assist them, and (b) providing instructors with pedagogically relevant groupings of students’ exercise solutions with similar implementations so that instructors can provide overlapping code style feedback to students within the same group. For difficulty detection, it uses a state-of-the-art algorithm for which a visualization has not been created. For code clustering, it uses GPT. We present a first-pass implementation of this dashboard.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {54–57},
numpages = {4},
keywords = {ChatGPT, Computer programming, Dashboards, GPT, Learning at scale},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3675417.3675543,
author = {Chen, Yajuan and She, Shengxiang and Sun, Yan},
title = {Is AI-generated content better? A study based on Ant Forest Game content recommendation},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675543},
doi = {10.1145/3675417.3675543},
abstract = {As we entered the 21st century, with the development of computers and mobile internet, research in Artificial Intelligence has made significant advancements. Artificial Intelligence (AI) is a field of science and engineering focused on enabling computers to perform tasks that typically require human intelligence. It encompasses various subfields such as machine learning, expert systems, natural language processing, and computer vision. In 2022, OpenAI released a new chatbot model named ChatGPT, which can understand human language and generate text like a human. Its robust data capabilities have attracted the attention of experts in various fields. However, the public's perception and attitude towards AI technology and ChatGPT are also crucial. Therefore, in this study, we used an online experiment and employed different groups of ChatGPT-generated content recommendation and real-person-generated content recommendation as experimental manipulation conditions. From the user perception perspective, we aimed to explore the differences between user perceptions of content recommendation provided by Artificial Intelligence (ChatGPT) and those provided by real-person. We also investigated whether the perception of AI-generated (ChatGPT) content recommendation had an impact on users' subsequent intention to support Ant Forest Game. The results show significant differences in perceived content quality between AI-generated (ChatGPT) Ant Forest Game content recommendation and real-person-generated content recommendation. Additionally, in terms of subsequent support intention for Ant Forest Game, there were also significant differences between AI-generated (ChatGPT) Ant Forest Game content recommendation and real-person generated Ant Forest Game content recommendation. Ant Forest Game content recommendation was found to significantly enhance Ant Forest Game support intention. Participants exhibited higher perceived content quality and greater support intention for AI-generated (ChatGPT) Ant Forest Game content recommendation. This study explores the psychological mechanisms involved in human-computer interaction, contributing to research in the field of Artificial Intelligence. Compared to a real human person's recommendation, people tend to prefer ChatGPT's recommendation, showing that people exhibit similar social behaviors and emotional responses when interacting with generative AI (ChatGPT) as they do with real humans. These findings are significant for the development and improvement of Artificial Intelligence.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {749–755},
numpages = {7},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3660650.3660656,
author = {Bird, William},
title = {Faceless Adversary, Feckless Colleague: The Many Sides of ChatGPT},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660656},
doi = {10.1145/3660650.3660656},
abstract = {Although CS educators have studied the potential of generative AI for years, the release of ChatGPT in late 2022 sparked a wave of uncertainty and anxiety. With students arriving at university already experienced with using ChatGPT for work across the academic spectrum, educators were under pressure to somehow address the presence of this new resource in their classroom. This article describes both the “climate of fear” surrounding ChatGPT’s impacts on education and an attempt by the authors to induct ChatGPT as a colleague instead of an adversary. While creating a video series where we used ChatGPT to generate practice exercises for CS1 and CS2, we found it to be patient, charismatic and friendly, but also sometimes obstinate, misinformed, stubborn and confused; in other words, it was surprisingly human.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {14},
numpages = {6},
keywords = {CS education, generative AI, teaching tools},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3626253.3635522,
author = {Ruiz, Pati and Rangel, Alessandra and Coenraad, Merijke},
title = {Using Generative AI to Support PK-12 Teaching and Learning: Developing Sample Lessons and More},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635522},
doi = {10.1145/3626253.3635522},
abstract = {North Salem Central School District (North Salem) has worked with researchers as part of a larger Research Practice Partnership (RPP) to design and implement an inclusive PK-12 computing pathway in their district. This poster describes how teachers used Generative AI (GenAI) tools in three areas: (1) the development of sample computational thinking (CT) lesson plans; (2) initial brainstorming; and (3) professional learning.As North Salem reflected on their use of GenAI tools, they named two AI tools specifically: OpenAI's ChatGPT-4 and Bing's Image Creator. Teachers also describe ethical dilemmas that they faced when integrating GenAI tools as well as other concerns that will be described below. This work builds on the growing literature on the use of Generative AI tools to support the day-to-day work of teachers.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1800–1801},
numpages = {2},
keywords = {K-12 computer science education, ducational equity, formative assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691620.3695470,
author = {Cao, Jialun and Chen, Zhiyong and Wu, Jiarong and Cheung, Shing-Chi and Xu, Chang},
title = {JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695470},
doi = {10.1145/3691620.3695470},
abstract = {Code generation benchmarks such as HumanEval are widely adopted to evaluate LLMs' capabilities. However, after consolidating the latest 24 benchmarks, we noticed three significant imbalances. First, imbalanced programming language. 95.8% of benchmarks involve Python, while only 5 benchmarks involve Java, resulting in an insufficient understanding of LLMs' capability to generate Java code. Second, imbalanced code granularity. Function-/statement-level benchmarks account for over 83.3% of benchmarks. Only a mere handful extends to class-/project-levels, and all are limited to Python. Third, lacking advanced features. Existing benchmarks primarily assess basic coding skills (e.g., variables, operators, and control structures), while overlooking advanced Object-Oriented Programming (OOP) features (i.e., encapsulation, inheritance, and polymorphism). Considering the prevalence of these advanced features in real-world Java project development, constructing benchmarks to test LLMs on handling OOP features is necessary.To fill these gaps, we propose JavaBench, a project-level Java benchmark that exercises OOP features. It comprises four Java projects with 389 methods in 106 Java classes. The test coverage is up to 92%, and JavaBench is attested by 282 undergraduate students, reaching a 90.93/100 average score (i.e., pass rate against the test suite), ensuring the quality of documentation, code skeleton, and tests. To better evaluate LLM's capability against JavaBench, we introduce a systematic evaluation design covering three context settings and five synthesis strategies at two granularities using three hierarchical metrics. Our extensive experiment yields several interesting findings. First, we noticed that regarding project-level Java programming, LLMs are far behind undergraduate students (no project can be correctly completed by any studied LLMs, and at most 48.24% Pass@5 in a more relaxed evaluation). Second, using method signature as prompt context may strike an ideal balance for project-level code generation. JavaBench is publicly available at https://github.com/java-bench/JavaBench. We also release a leaderboard and invite model developers to participate and test their models against JavaBench at https://java-bench.github.io/leaderboard.html.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {870–882},
numpages = {13},
keywords = {large language model, program synthesis, object-oriented programming},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3649217.3653607,
author = {Rivera, Elijah and Steinmaurer, Alexander and Fisler, Kathi and Krishnamurthi, Shriram},
title = {Iterative Student Program Planning using Transformer-Driven Feedback},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653607},
doi = {10.1145/3649217.3653607},
abstract = {Problem planning is a fundamental programming skill, and aids students in decomposing tasks into manageable subtasks. While feedback on plans is beneficial for beginners, providing this in a scalable and timely way is an enormous challenge in large courses.Recent advances in LLMs raise the prospect of helping here. We utilize LLMs to generate code based on students' plans, and evaluate the code against expert-defined test suites. Students receive feedback on their plans and can refine them.In this report, we share our experience with the design and implementation of this workflow. This tool was used by 544 students in a CS1 course at an Austrian university. We developed a codebook to evaluate their plans and manually applied it to a sample. We show that LLMs can play a valuable role here. However, we also highlight numerous cautionary aspects of using LLMs in this context, many of which will not be addressed merely by having more powerful models (and indeed may be exacerbated by it).},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {45–51},
numpages = {7},
keywords = {automated feedback, llms, program planning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635618,
author = {Garcia, Leiny and Ojeda-Ramirez, Santiago and Warschauer, Mark},
title = {Restorying with AI Art among Latinx Elementary Students},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635618},
doi = {10.1145/3626253.3635618},
abstract = {The Latinx community is underrepresented in tech-oriented fields, which aligns with the lack of culturally relevant learning experiences in CS for Latinx youth, hindering their ability to conceptualize technology as a tool for transformation and vehicle for cultural expression. This study takes on a restorying approach at the elementary level, where 9 fourth-grade students engaged in focus group discussions over three days to generate prompts for a generative AI art. Through the lens of restorying, the prompts had students conceptualize a future with a focus on their Mexican-American heritage, local community, and technology. The study revealed that students associated their heritage with symbolic representations such as food and music, and characterized the community as a commercialized space while also emphasizing locations conducive to family-oriented activities. As a result, technology in community spaces was associated with consumerism. However, when envisioning a futuristic, transformed community, they made deeper connections between the role of technology in the community, making intricate connections between community improvements and technology-based solutions. This underscores the need for computing education to dedicate time for young learners to reflect on the role technology has on their current culture and community to make deeper connections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1648–1649},
numpages = {2},
keywords = {ai literacy, elementary school, heritage, latinx, restorying},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3699863,
author = {Bailey, Cynthia},
title = {Artificial Intelligence Policy: What Computing Educators and Students Should Know},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3699863},
doi = {10.1145/3649165.3699863},
abstract = {Catalyzed by the release of ChatGPT by OpenAI in November 2022, policymakers worldwide have launched a surge of activity surrounding artificial intelligence (AI). The legal and policy frameworks emerging from this concentrated period of attention may shape AI governance for decades to come. This keynote will examine the implications of these global AI policy debates for computing educators and their students.  Drawing on the speaker's dual experience as a computing educator and AI policy adviser within the United States Senate, this presentation will explore the developing threads of AI policy that educators should integrate into their curricula to prepare students for an evolving socio-technical landscape.  The talk will present an overview of significant AI policy developments, including the European Union's AI Act, the over 120 AI-related bills currently pending in the United States Congress, and the United Arab Emirates' launch of a state-of-the-art open-source AI model. These examples will be contextualized within the history of how the current active regulatory stance diverges from prior approaches to technologies like the internet and social media, and consider the potential implications of this shift.  Equally important to understanding how AI policy is evolving is understanding why. Many legislative efforts are driven by concerns about AI's potential to exacerbate societal harms, such as election misinformation, cybersecurity threats, nonconsensual sexual imagery, weapons development, data privacy violations, intellectual property appropriation, labor market disruptions, and algorithmic biases. Coupled with these concerns is a widespread skepticism toward the tech industry's capacity for responsible self-governance. This context underscores the need for computing educators to engage students on issues of policy, ethics, and justice throughout the curriculum, to cultivate future professionals who can earn public trust and who appreciate the role of governments in establishing balance between innovation and safety guardrails.  Finally, the talk will offer reflections on the experience of serving as a technical adviser to policymakers, and advocate for computing educators to consider public service engagement on AI policy as a compelling career trajectory for themselves and their students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {1–2},
numpages = {2},
keywords = {ai, artificial intelligence, ethics, government, policy, social impact},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3708973.3708979,
author = {Lux, Mathias},
title = {Procedural Content Generation - The Open Source Success Story of Wave Function Collapse},
year = {2024},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
url = {https://doi.org/10.1145/3708973.3708979},
doi = {10.1145/3708973.3708979},
abstract = {With OpenAI's Dall-E, Midjourney, and Adobe Firefly, computer-generated visual content has hit the mass market. Machine learning-based algorithms can now create, and re-mix multimedia content based on huge corpora of images and videos and relieve creative professionals of tedious work. While this has gained much momentum lately, procedurally generated content (PCG) has been around for quite some time already. Especially in video game development, randomized levels, behavior, aesthetics, and even narratives increase replayability and engage the audience longer. Prominent examples are Minecraft and Diablo, where the game world is randomly generated, and Borderlands, where in-game items are generated on the fly. PCG is applied on multiple levels with different purposes, like generating terrain, weather, road and transport networks, house layouts, puzzles, textures, and mazes, just to name a few. Hedrikx et al. [1] give a comprehensive overview of the topic.In a typical scenario, a mix of algorithms is employed to create content on the fly. Generative grammar algorithms are often employed for vegetation, fractal noise is used to generate terrain and clouds, and simulation is used to create road networks or to erode terrain further. Lately, deep learning-based approaches have become available. The most notable example is AI Dungeon [2], where users converse with GPT in a text adventure. However, large neural networks require significant computational power and are hard to explain and constrain, so procedural content generation tends to use less complex algorithms, where game designers can give hard constraints to influence the outcome.},
journal = {SIGMultimedia Rec.},
month = dec,
articleno = {6},
numpages = {1}
}

@inproceedings{10.1145/3649217.3653626,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley and Salloum, Mariam},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653626},
doi = {10.1145/3649217.3653626},
abstract = {Student cheating on at-home programming assignments is a well- known problem. A key contributor is externally-obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally-obtained solutions often use coding styles that depart from a class' style, which we call "style anomalies," such as using untaught or advanced constructs like pointers or ternary operators, or having different indenting or brace usage from the class style. We developed a tool to auto-count style anomalies. For six labs across four terms in 2021-2022, and 50 sampled students per lab, we found 18% of submissions on average had unusually-high style anomaly counts. Importantly, 8% of submissions on average had a high style anomaly count but were not flagged by a similarity checker, meaning 8% of submissions are suspicious but might have been missed if using similarity checking alone. We repeated a similar analysis for Spring 2023 when generative AI (ChatGPT) was gaining popularity, and the numbers rose to 26% and 18%, respectively. Detailed investigations by instructors led to a majority (but not all) high style anomaly submissions being deemed cheating. Even for high-similarity submissions, counting style anomalies can help instructors focus investigations on the most-likely cheating cases, and can strengthen cases sent to student conduct offices. With the rise of externally-obtained solutions from websites, contractors, and generative AI, counting style anomalies may become an increasingly important complement to similarity checking; in fact, it is now the primary cheat-detection tool in our CS1 at a large state university, with similarity secondary.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {381–387},
numpages = {7},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649405.3659534,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Virginia and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {How Instructors Incorporate Generative AI into Teaching Computing},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659534},
doi = {10.1145/3649405.3659534},
abstract = {Generative AI (GenAI) has seen great advancements in the past two years and the conversation around adoption is increasing. Widely available GenAI tools are disrupting classroom practices as they can write and explain code with minimal student prompting. While most acknowledge that there is no way to stop students from using such tools, a consensus has yet to form on how students should use them if they choose to do so. At the same time, researchers have begun to introduce new pedagogical tools that integrate GenAI into computing curricula. These new tools offer students personalized help or attempt to teach prompting skills without undercutting code comprehension. This working group aims to detail the current landscape of education-focused GenAI tools and teaching approaches, present gaps where new tools or approaches could appear, identify good practice-examples, and provide a guide for instructors to utilize GenAI as they continue to adapt to this new era.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {771–772},
numpages = {2},
keywords = {artificial intelligence, generative AI, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3691720.3691768,
author = {Shan, Qiang},
title = {Design and application of a web front-end development course training platform based on generative artificial intelligence and low code development},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691768},
doi = {10.1145/3691720.3691768},
abstract = {With the rapid development of artificial intelligence technology, generative artificial intelligence has shown strong application potential in various fields, and low code development has become a popular choice for quickly building application systems due to its efficient and easy-to-use characteristics. With the continuous updates and iterations of web front-end development technology, how to improve learners' practical abilities and development efficiency has become an important issue in the field of vocational education. Therefore, we have designed an innovative web front-end development course training platform that combines the automation generation ability of generative artificial intelligence and the fast construction advantage of low code development. In platform design, we fully utilize the automated generation capability of generative artificial intelligence to achieve intelligent generation and layout optimization of front-end page elements. At the same time, with the help of the visual programming interface and component-based development methods of low code development platforms, the front-end development process is simplified, the technical threshold is lowered, and students can focus more on the implementation of business logic and creative expression.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {287–291},
numpages = {5},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3649217.3653596,
author = {Apiola, Mikko and Vartiainen, Henriikka and Tedre, Matti},
title = {First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653596},
doi = {10.1145/3649217.3653596},
abstract = {Generative AI is a recent breakthrough in AI. While it has become a hot topic in computing education research (CER), much of the recent research has focused on e.g. issues of plagiarism or academic integrity. One problem spot with Generative AI is its susceptibility to various kinds of algorithmic bias. In this study, we collected data from an introductory computing course, where students experimented with text-to-image generative models and reflected on their generated image sets, in terms of biases, related harms, and possible fixes. Data were collected in Fall 2023 (pilot data in Fall 2022). Data included reports from 163 students. The results show (1) a variety of bias types observed by students related to gender, ethnicity, age, as well as a variety of bias types not observed by students, (2) two major types of attributions for the source of bias: bias caused by biases in the society and bias caused by data or algorithms, and (3) a number of potential harms associated with the biases, as well as attributions of those harms in specific contexts and use cases.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {485–491},
numpages = {7},
keywords = {bias, critical computing education, generative ai, social injustice},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689535.3689543,
author = {Addo, Salomey Afua and Sentance, Sue},
title = {Exploring Computing Teachers' Readiness to Teach AI in Secondary Schools},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689543},
doi = {10.1145/3689535.3689543},
abstract = {Artificial intelligence (AI) is significantly impacting how we live, and the increased capabilities of generative AI applications have positioned AI firmly in the public domain. There is a growing interest in what AI might look like as a subject within the K-12 curriculum, whilst research on teachers’ readiness for teaching AI is as yet limited. This paper describes a qualitative study investigating teachers’ readiness to teach AI in secondary education. The interview study involved eight computing teachers with varying teaching experiences. We used reflexive thematic analysis for themes development. Findings suggest several indicators of teachers’ readiness, including attitudes, prior AI experience, professional development, and access to quality resources. This paper contributes to ongoing debates about how to best support teachers to be ready to teach AI effectively at the school level.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {17},
numpages = {1},
keywords = {K-12 education, artificial intelligence, computing education, teacher readiness},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3664475.3664553,
author = {Rao, Anyi and Xiangli, Yuanbo and Guo, Yuwei and Tang, Mia and Meng, Chenlin and Agrawala, Maneesh},
title = {Generative Models for Visual Content Editing and Creation},
year = {2024},
isbn = {9798400706837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664475.3664553},
doi = {10.1145/3664475.3664553},
abstract = {Welcome to the SIGGRAPH 2024 Course on Generative Models for Visual Content Editing and Creation! In this course, you will embark on an exciting journey into the realm of generative models and their groundbreaking applications in computer graphics. Over the duration of this course, you will gain a comprehensive understanding of generative models and diffusion models, explore fundamental machine learning and deep learning techniques, and discover cutting-edge applications for high-fidelity image synthesis, video generation, 3D content creation, and more. Here's what you can expect to learn:},
booktitle = {ACM SIGGRAPH 2024 Courses},
articleno = {13},
numpages = {6},
location = {Denver, CO, USA},
series = {SIGGRAPH Courses '24}
}

@article{10.1145/3689040,
author = {Bomba, Federico and Men\'{e}ndez-Blanco, Mar\'{\i}a and Grigis, Paolo and Cremaschi, Michele and De Angeli, Antonella},
title = {The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3689040},
doi = {10.1145/3689040},
abstract = {The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of entangled authorship to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {75},
numpages = {23},
keywords = {Agency, Agential Realism, Large Language Models, AI and Art, Creative AI, Hallucination}
}

@inproceedings{10.1145/3660853.3660863,
author = {McGowan, Aidan and Anderson, Neil and Smith, Christopher},
title = {The use of ChatGPT to generate Summative Feedback in Programming Assessments that is Consistent, Prompt, without Bias and Scalable},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660863},
doi = {10.1145/3660853.3660863},
abstract = {ABSTRACTThis paper explores the automated integration of ChatGPT into the feedback process for a large-scale and complex university programming assignment. It aims to explore the feasibility of using ChatGPT to facilitate prompt, efficient, and valued feedback to students. The study presents case studies illustrating the use of the ChatGPT API in generating feedback through an automated tool (AutoFeed) developed by the researchers. The findings report on the advantages as well as the limitations of employing Prompt Engineering for this purpose.},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {39–43},
numpages = {5},
keywords = {ChatGPT, Gen Ai, Programming,university,lab,feedback},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

@inproceedings{10.1145/3673791.3698402,
author = {Kurohashi, Sadao},
title = {From Data Platforms to Knowledge Infrastructure},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698402},
doi = {10.1145/3673791.3698402},
abstract = {Modern society is facing pressing issues, including environmental challenges, inequality, and regional conflicts. To resolve these complex societal problems, the concept of ''open science'' is essential, as emphasized at last year's G7 meeting. In Japan, starting in 2025, all scientific papers resulting from publicly funded research, along with the associated data, will be required to be immediately accessible through open access.The National Institute of Informatics (NII) has been at the forefront of advancing Japan's academic information infrastructure for many years. In 2017, NII embarked on the development of the NII Research Data Cloud -- a platform for the publication, discovery, and management of academic information -- which became operational in 2021. By 2022, the project evolved into a research data ecosystem, built in collaboration with numerous universities and research institutions. This initiative aims to create a comprehensive environment where papers, data, and computational resources are readily accessible across all fields of research.Recognizing the significant impact of generative AI on society and the need for a hub in Japan where large-scale language models (LLMs) can be developed and studied, NII spearheaded the formation of the LLM-jp study group (https://llm-jp.nii.ac.jp/en/) in May 2023. The group, founded on principles of openness, began with approximately 30 researchers specializing in natural language processing and has since grown to over 1,800 participants from industry, government, and academia.In April 2024, NII further advanced this initiative by establishing the LLM R&amp;D Center. By September 2024, the center had developed and released the world's largest fully open LLM, featuring 172 billion parameters -- on a scale similar to GPT-3.5. The center's ongoing work also focuses on ensuring the reliability and transparency of these models. To address the complex societal challenges mentioned above, it is crucial not only to deepen academic research but also to foster collaboration across various disciplines, creating new cross-disciplinary knowledge. LLMs can play a pivotal role in these processes by interpreting data, interconnecting and systematizing knowledge, and laying the groundwork for a robust knowledge infrastructure.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {114},
numpages = {1},
keywords = {generative ai, knowledge infrastructure, large language models (llms), llm-jp, open science},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3663649.3664375,
author = {Yang, Jun and Gilad, Amir and Hu, Yihao and Meng, Hanze and Miao, Zhengjie and Roy, Sudeepa and Stephens-Martinez, Kristin},
title = {What Teaching Databases Taught Us about Researching Databases: Extended Talk Abstract},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664375},
doi = {10.1145/3663649.3664375},
abstract = {Declarative querying is a cornerstone of the success and longevity of database systems, yet it is challenging for novice learners accustomed to different coding paradigms. The transition is further hampered by a lack of query debugging tools compared to the plethora available for programming languages. The paper samples several systems that we build at Duke University to help students learn and debug database queries. These systems have not only helped scale up teaching and improve learning, but also inspired interesting research on databases. Furthermore, with the rise of generative AI, we argue that there is a heightened need for skills in scrutinizing and debugging AI-generated queries, and we outline several ongoing and future work directions aimed at addressing this challenge.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {1–6},
numpages = {6},
keywords = {Database Education, Query Debugging, Query Verification, Relational Algebra, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3641237.3691673,
author = {Trim, Michelle and Butler, Erin and Suttcliffe, Christina},
title = {Seeing How the Sausage is Made: Data Storytelling as Means and Method in a Computer Science Writing Course},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691673},
doi = {10.1145/3641237.3691673},
abstract = {As data corpus-driven tools and technologies increasingly push users to passively search for an answer, rather than search to understand, we believe that technical and computing disciplinary writing courses have a duty to teach the process of responsible data storytelling. While students can grasp that generative AI makes mistakes, hallucinates, and perpetuates bias, they can need help understanding the antecedent causes of those difficulties. All algorithmically driven decision-making or recommending software have in common a large data set that has been labeled, either by users or by the system itself. The origins of that data and the reasonable applications/deductions and conclusions possible for any given dataset have everything to do with why some tools help and some tools perpetuate harms. By starting at the very beginning and asking students to make sense of data, students can more easily see how purpose and audience impact analysis of any given collection of data. Once those opportunities for rhetorical choice making are known, students become ready to understand the connection between data and complex A.I. systems and some of the ways that bias and other kinds of harm can result if designers are not careful. Combining instruction in a technical coding environment with basic data literacy lessons such as ‘the seven data stories,’ [14] we developed and delivered a three-week writing unit designed around responsible data exploration and storytelling. In this experience report, we provide the assignment we used, and the scaffolded activities we employed to bring students through the process, remarking on what worked well and what we want to improve. We provide attendees with a link to an R-based notebook with a walk-through lesson on data exploration commands, and the rubric used to assess students’ texts, notebooks with code and commentary and results, all existing in a referential context. We provide the survey results of students’ perception of learning from this activity. Early findings demonstrate that students internalized lessons about the non-objective nature of data analysis and of specific responsible data storytelling practices required by anyone seeking to ethically represent answers within and limitations of any dataset.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {217–222},
numpages = {6},
keywords = {Data Visualization, Data storytelling, Pedagogy, Technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3663548.3688531,
author = {Liu, Xinlei and Wu, Kevin and Kulkarni, Minchu and Saugstad, Michael and Rapo, Peyton Anton and Freiburger, Jeremy and Hosseini, Maryam and Li, Chu and Froehlich, Jon E.},
title = {Towards Fine-Grained Sidewalk Accessibility Assessment with Deep Learning: Initial Benchmarks and an Open Dataset},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3688531},
doi = {10.1145/3663548.3688531},
abstract = {We examine the feasibility of using deep learning to infer 33 classes of sidewalk accessibility conditions in pre-cropped streetscape images, including bumpy, brick/cobblestone, cracks, height difference (uplifts), narrow, uneven/slanted, pole, and sign. We present two experiments: first, a comparison between two state-of-the-art computer vision models, Meta’s DINOv2 and OpenAI’s CLIP-ViT, on a cleaned dataset of ∼ 24k images; second, an examination of a larger but noisier crowdsourced dataset (∼ 87k images) on the best performing model from Experiment 1. Though preliminary, Experiment 1 shows that certain sidewalk conditions can be identified with high precision and recall, such as missing tactile warnings on curb ramps and grass grown on sidewalks, while Experiment 2 demonstrates that larger but noisier training data can have a detrimental effect on performance. We contribute an open dataset and classification benchmarks to advance this important area.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {103},
numpages = {12},
keywords = {DINOv2, Sidewalk accessibility, ViT-CLIP, computer vision, human mobility, obstacle detection},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3632620.3671116,
author = {Prather, James and Reeves, Brent N and Leinonen, Juho and MacNeil, Stephen and Randrianasolo, Arisoa S and Becker, Brett A. and Kimmel, Bailey and Wright, Jared and Briggs, Ben},
title = {The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671116},
doi = {10.1145/3632620.3671116},
abstract = {Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {469–486},
numpages = {18},
keywords = {CS1, ChatGPT, Copilot, generative AI, large language models, metacognition},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3649405.3659517,
author = {Glassey, Richard and Baltatzis, Alexander},
title = {Active Repos: Integrating Generative AI Workflows into GitHub},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659517},
doi = {10.1145/3649405.3659517},
abstract = {The aim of this work is to describe a simple and cost effective way to integrate generative AI into GitHub to support course specific scenarios. We are motivated by helping teachers realise their creative AI use cases in spite of technical barriers and also to ensure that students have a blessed and fair way to access AI services without needing to sign-up, prompt or pay. First we will describe a scenario that we have implemented for our own CS1 course, then we will describe the technical requirements for implementation. We finish off with our early thoughts on where these types of scenarios might be heading in terms of supporting computing education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {777–778},
numpages = {2},
keywords = {CS1, GitHub actions, automation, generative AI},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3639856.3639915,
author = {Sundar, Rahul and Gadgil, Shreyash and Satya Sai, Tankala and Reddy, Sathi Sai Krishna and B, Gautam and Mittal, Ishita and Guduguntla, Jyotsna Sree and Pujala, Shanmukesh},
title = {InnoGuideGPT: Integrating conversational interface and command interpretation for navigation robots},
year = {2024},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639856.3639915},
doi = {10.1145/3639856.3639915},
abstract = {Integrating natural language understanding, voice command interpretation and natural language generation for realtime inference is a challenging problem. However, developing a proof of concept is now possible in just a few lines of code which was otherwise unimaginable a few years ago. Thanks to the democratization of LLMs and the availability of high-quality pre-trained models through APIs. It is now possible to quickly build effective use cases by just integrating multiple models without even having to pre-train/fine-tune the models on custom data. This is due to their zero-shot learning ability. Although, there are many recent works in this regard oriented towards software&nbsp;[1, 5], edge implementations and their applications to Robotics are yet to be explored in their entirety&nbsp;[6]. Recently, Koubaa&nbsp;[2] proposed RoboGPT, where a ChatGPT was prompt-tuned for command interpretation and subsequently determining the robot’s actions. In this work, we explore the possibility of integrating a real-time conversational voice interface within a navigation robot. This is achieved using an underlying LLM interface to respond to user queries based on a prior context and additionally interpret voice commands for the robot to navigate. As a proof of concept, we evaluate the effectiveness of the planned workflow using a robot simulation. For simulating a Robot’s environment, there exist various tools but in this work, Gazebo&nbsp;[3] has been adopted to simulate a differential drive robot moving in an indoor environment and Rviz is used for visualization. We utilized the TurtleBot3&nbsp;[4] software packages to implement motion planning and navigation algorithms (see figure 2). For the speech recognition, we use OpenAI’s Whisper API, while for text to speech we use the freely available google text-to-speech python package. We then use OpenAI’s GPT-3.5-turbo API within the Langchain framework for building a context aware conversational interface and an additional command interpretation module under the hood to guide the navigation bot. It is remarkable how there is a significant reduction in development time for proof of concepts through the availability of high-quality models in addition to high-quality outcomes. Once the workflow is validated on Gazebo, the workflow is then implemented onto a NVIDIA Jetson Nano which will be used to send and process the cloud based LLM/speech API requests and responses (see figure 3.},
booktitle = {Proceedings of the Third International Conference on AI-ML Systems},
articleno = {57},
numpages = {3},
keywords = {Command interpretation, Conversational AI, Large language models, Robot navigation, Speech recognition, Speech synthesis},
location = {Bangalore, India},
series = {AIMLSystems '23}
}

@inproceedings{10.1145/3610977.3634950,
author = {Williams, Randi and Ali, Safinah and Alcantara, Ra\'{u}l and Burghleh, Tasneem and Alghowinem, Sharifa and Breazeal, Cynthia},
title = {Doodlebot: An Educational Robot for Creativity and AI Literacy},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634950},
doi = {10.1145/3610977.3634950},
abstract = {Today, Artificial Intelligence (AI) is prevalent in everyday life, with emerging technologies like AI companions, autonomous vehicles, and AI art tools poised to significantly transform the future. The development of AI curricula that shows people how AI works and what they can do with it is a powerful way to prepare everyone, and especially young learners, for an increasingly AI-driven world. Educators often employ robotic toolkits in the classroom to boost engagement and learning. However, these platforms are generally unsuitable for young learners and learners without programming expertise. Moreover, these platforms often serve as either programmable artifacts or pedagogical agents, rarely capitalizing on the opportunity to support students in both capacities. We designed Doodlebot, a mobile social robot for hands-on AI education to address these gaps. Doodlebot is an effective tool for exploring AI with grade school (K-12) students, promoting their understanding of AI concepts such as perception, representation, reasoning and generation. We begin by elaborating Doodlebot's design, highlighting its reliability, user-friendliness, and versatility. Then, we demonstrate Doodlebot's versatility through example curricula about AI character design, autonomous robotics, and generative AI accessible to young learners. Finally, we share the results of a preliminary user study with elementary school youth where we found that the physical Doodlebot platform was as effective and user-friendly as the virtual version. This work offers insights into designing interactive educational robots that can inform future AI curricula and tools.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {772–780},
numpages = {9},
keywords = {collaboration, creativity, education, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3690407.3690563,
author = {Zhou, Jinpeng and Tao, Zhiyong},
title = {Research on Automatic Scoring Algorithm for English Composition Based on Heterogeneous Fusion Network},
year = {2024},
isbn = {9798400710247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690407.3690563},
doi = {10.1145/3690407.3690563},
abstract = {Automatic essay scoring is an innovative method that utilizes computer algorithms and artificial intelligence technology to recognize language features in essays through training models, and to perform automatic essay grading. It has become an important research topic in the field of natural language processing in education. However, essay scoring is essentially a complex task that involves comprehensive evaluation of multiple dimensions such as grammar, semantics, and subject relevance. Current neural network models often struggle to fully capture multiple features of essays, thereby limiting their grading effectiveness. In response to the above challenges, this article proposes a method based on BERT and attention mechanism generative fusion network to automatically score essays, and innovatively uses a feature fusion structure based on conditional layer normalization CLN to fuse the features extracted from the attention and residual network-based CNN-BiLSTM essay automatic scoring model and BERT pre trained language model, and then applies them to automatic essay scoring. Compared with baseline methods and ablation experiments, the average QWK performance on this dataset reached 78.86%. This indicates that the fusion network can effectively integrate the semantic information extracted from different structured networks, resulting in better performance in scoring tasks, verifying the accuracy and effectiveness of the proposed model.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms},
pages = {936–940},
numpages = {5},
keywords = {Attention Mechanism, Automatic Essay Scoring, Generative Fusion, Pre-training Model, Residual Network},
location = {
},
series = {CAIBDA '24}
}

@inproceedings{10.1145/3678726.3678733,
author = {Takeuchi, Miki and Ito, Akinori and Nose, Takashi},
title = {Selection of key sentences from lecture video transcription and its application to feedback to the learner},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678733},
doi = {10.1145/3678726.3678733},
abstract = {The COVID-19 pandemic accelerated the shift to online university lectures. Real-time online lectures offer live interaction, while on-demand video lectures such as MOOCs allow flexibility; however, on-demand video lectures face low student concentration and engagement challenges. Thus, our project aims to develop an interactive agent for on-demand videos, improving student motivation. As a building block of such a system, we develop a method to estimate key sentences from lecture speech. We compared two text summarization methods, the BERTSUM and GPT-based summarization, to select the key sentences. As a result, a combination of GPT-based summarization and BERT-based text selection gave the best results. Moreover, we developed a system that indicates the estimated key sentences to the learners and conducted a subjective evaluation of the system.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {218–223},
numpages = {6},
keywords = {MOOC, Online learning, text summarization},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3627043.3659574,
author = {Manzoor, Ahtsham and Ziegler, Samuel C. and Garcia, Klaus Maria. Pirker and Jannach, Dietmar},
title = {ChatGPT as a Conversational Recommender System: A User-Centric Analysis},
year = {2024},
isbn = {9798400704338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627043.3659574},
doi = {10.1145/3627043.3659574},
abstract = {With the rapid advances in deep learning, we have witnessed a strongly increased interest in conversational recommender systems (CRS). Until recently, however, even the latest generative models exhibited major limitations and they frequently return non-meaningful responses according to previous studies. However, with the latest Generative AI-based dialog systems implemented with Generative Pre-Trained Transformer (GPT) models, a new era has arrived for CRS research. In this work, we study the use of ChatGPT as a movie recommender system. To this purpose, we conducted an online user study involving N=190 participants, who were tasked to evaluate ChatGPT’s responses in a multitude of dialog situations. As a reference point for the analysis, we included a retrieval-based conversational method in the experiment, which was found to be a robust approach in previous research. Our study results indicate that the responses by ChatGPT were perceived to be significantly better than those by the previous system in terms of their meaningfulness. A detailed inspection of the results showed that ChatGPT excelled when providing recommendations, but sometimes missed the context when asked questions about a movie within a longer dialog. A statistical analysis revealed that information adequacy and recommendation accuracy of the responses had the strongest influence on the perceived meaningfulness of the responses. Finally, an additional analysis showed that the human perceptions of meaningfulness correlated only very weakly with computational metrics such as BLEU or ROUGE, emphasizing the importance of involving humans in the evaluation of a CRS.},
booktitle = {Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {267–272},
numpages = {6},
keywords = {Conversational Recommendation, Large Language Models, User Study},
location = {Cagliari, Italy},
series = {UMAP '24}
}

@inproceedings{10.1145/3649409.3691073,
author = {Barendsen, Erik and Lonati, Violetta and Quille, Keith and Altin, Rukiye and Divitini, Monica and Hooshangi, Sara and Karnalim, Oscar and Kiesler, Natalie and Melton, Madison and Suero Montero, Calkin and Morpurgo, Anna},
title = {AI in and for K-12 Informatics Education. Life after Generative AI.},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691073},
doi = {10.1145/3649409.3691073},
abstract = {The use and adoption of Generative AI (GenAI) has revolutionised various sectors, including computing education. However, this narrow focus comes at a cost to the wider AI in and for educational research. This working group aims to explore current trends and explore multiple sources of information to identify areas of AI research in K-12 informatics education that are being underserved but needed in the post-GenAI AI era. Our research focuses on three areas: curriculum, teacher-professional learning and policy. The denouement of this aims to identify trends and shortfalls for AI in and for K-12 informatics education. We will systematically review the current literature to identify themes and emerging trends in AI education at K-12. This will be done under two facets, curricula and teacher-professional learning. In addition, we will conduct interviews and surveys with educators and AI experts. Next, we will examine the current policy (such as the European AI Act, and European Commission guidelines on the use of AI and data in education and training as well as international counterparts). Policies are often developed by both educators and experts in the domain, thus providing a source of topics or areas that may be added to our findings. Finally, by synthesising insights from educators, AI experts, and policymakers, as well as the literature and policy, our working group seeks to highlight possible future trends and shortfalls.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {279–280},
numpages = {2},
keywords = {AI, GenAI, K-12, curricula, generative AI, informatics},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3641235.3664430,
author = {Matsunaga, Harutaka and Miyata, Kazunori},
title = {Emerging Approaches in CG Education Aimed at Enhancing Visual Communication Skills through Reverse Engineering},
year = {2024},
isbn = {9798400705175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641235.3664430},
doi = {10.1145/3641235.3664430},
abstract = {The proposed research applies reverse engineering techniques in the field of computer graphics (CG) production education at Japanese vocational schools. It involves the development of a "Philosophical Observation Decomposition Table" and a "Concept Decomposition Table" to analyze the relationship between words and visuals, along with artistic elements. This methodology is designed to be both educational and enjoyable. Furthermore, the study suggests the utilization of AI technologies, such as ChatGPT, to expand the scope of CG education beyond technical skills, encompassing soft skills like communication and creativity.},
booktitle = {ACM SIGGRAPH 2024 Educator's Forum},
articleno = {5},
numpages = {2},
keywords = {Diversified Needs and Skills, Education-Industry Collaboration, Skill Gap, Sustainable Education Program},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3675417.3675461,
author = {Liu, Shitou and Liang, Zhenjie and Zhang, Ling},
title = {Analyzing Key Influencing Factors of University Teachers45 Use of Generative Artificial Intelligence in a Small-Sample Data Environment},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675461},
doi = {10.1145/3675417.3675461},
abstract = {This study focuses on exploring the key factors influencing the use of generative artificial intelligence (AI) by university teachers in the context of digital education, particularly in the backdrop of human-computer interaction. Considering the challenges posed by small-sample data, we employed various machine learning models such as linear regression, random forest regression, and support vector regression (SVR), and optimized model parameters through grid search and cross-validation techniques. The optimized models exhibited significantly improved performance, with the linear regression model showing a mean squared error (MSE) of 0.1239 and an R² score of 0.6362, indicating its good predictive accuracy and generalization ability on the small-sample dataset. The study results emphasize performance expectations, perceived value, and community influence as primary influencing factors for university teachers' use of generative AI, especially in the context of human-computer interaction. This is crucial for understanding and promoting the acceptance and use of educational technology. This research provides valuable insights for education policymakers and technology developers and offers important methodological guidance for machine learning applications dealing with small-sample data.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {271–279},
numpages = {9},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3654777.3676392,
author = {Gunturu, Aditya and Wen, Yi and Zhang, Nandi and Thundathil, Jarin and Kazi, Rubaiat Habib and Suzuki, Ryo},
title = {Augmented Physics: Creating Interactive and Embedded Physics Simulations from Static Textbook Diagrams},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676392},
doi = {10.1145/3654777.3676392},
abstract = {We introduce Augmented Physics, a machine learning-integrated authoring tool designed for creating embedded interactive physics simulations from static textbook diagrams. Leveraging recent advancements in computer vision, such as Segment Anything and Multi-modal LLMs, our web-based system enables users to semi-automatically extract diagrams from physics textbooks and generate interactive simulations based on the extracted content. These interactive diagrams are seamlessly integrated into scanned textbook pages, facilitating interactive and personalized learning experiences across various physics concepts, such as optics, circuits, and kinematics. Drawing from an elicitation study with seven physics instructors, we explore four key augmentation strategies: 1) augmented experiments, 2) animated diagrams, 3) bi-directional binding, and 4) parameter visualization. We evaluate our system through technical evaluation, a usability study (N=12), and expert interviews (N=12). Study findings suggest that our system can facilitate more engaging and personalized learning experiences in physics education.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {144},
numpages = {12},
keywords = {Augmented Textbook, Authoring Interfaces, Explorable Explanations, Interactive Paper, Physics Education},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@article{10.1145/3698773,
author = {Sun, Jiaqi and Deng, Xianjun and liu, Shenghao and Fan, Xiaoxuan and Huang, Yongling and He, Yuanyuan and Wu, Celimuge and Park, Jong Hyuk},
title = {Contrastive Learning based Speech Spoofing Detection for Multimedia Security in Edge Intelligence},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3698773},
doi = {10.1145/3698773},
abstract = {Artificial intelligence (AI) empowered edge computing has given rise to a new paradigm and effectively facilitated the promotion and development of multimedia applications. The speech assistant is one of the significant services provided by multimedia applications, which aims to offer intelligent interactive experiences between humans and machines. However, malicious attackers may exploit spoofed speeches to deceive speech assistants, posing great challenges to the security of multimedia applications. The limited resources of multimedia terminal devices hinder their ability to effectively load speech spoofing detection models. Furthermore, processing and analyzing speech in the cloud can result in poor real-time performance and potential privacy risks. Existing speech spoofing detection methods rely heavily on annotated data and exhibit poor generalization capabilities for unseen spoofed speeches. To address these challenges, this paper first proposes the Coordinate Attention Network (CA2Net) that consists of coordinate attention blocks and Res2Net blocks. CA2Net can simultaneously extract temporal and spectral speech feature information and represent multi-scale speech features at a granularity level. Besides, a contrastive learning-based speech spoofing detection framework named GEMINI is proposed. GEMINI can be effectively deployed on edge nodes and autonomously learn speech features with strong generalization capabilities. GEMINI first performs data augmentation on speech signals and extracts conventional acoustic features to enhance the feature robustness. Subsequently, GEMINI utilizes the proposed CA2Net to further explore the discriminative speech features. Then, a tensor-based multi-attention comparison model is employed to maximize the consistency between speech contexts. GEMINI continuously updates CA2Net with contrastive learning, which enables CA2Net to effectively represent speech signals and accurately detect spoofed speeches. Extensive experiments on the ASVspoof2019 dataset show that GEMINI reduces the Equal Error Rate and tandem Detection Cost Function by up to 96.75% and 96.35% in the physical access scenario, and by up to 86.62% and 87.71% in the logical access scenario compared to peer methods.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = oct,
keywords = {Edge intelligence, Multimedia applications, Speech spoofing detection, Contrastive learning, Coordinate attention}
}

@inproceedings{10.1145/3626253.3635519,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635519},
doi = {10.1145/3626253.3635519},
abstract = {Student cheating on at-home programming assignments is a well-known problem. A key contributor is externally obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally obtained solutions often use coding styles that depart from a class's style, which we call "style anomalies". Examples of style anomalies include using untaught or advanced constructs like pointers or ternary operators or having different indenting or brace usage from the class style. We developed a tool to automatically count style anomalies in student code submissions. We used this tool to find suspected cheating in student submissions for lab assignments across five terms of CS1. This poster presents our findings: Some student submissions were suspected of cheating due to high style anomaly counts and were not flagged as suspicious by a code similarity checker. With the rise of externally obtained solutions from websites, contractors, and generative AI, style anomalies may become an important complement to similarity checking for detecting cheating.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1624–1625},
numpages = {2},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3650212.3652142,
author = {Liu, Chenyan and Cai, Yufan and Lin, Yun and Huang, Yuhuan and Pei, Yunrui and Jiang, Bo and Yang, Ping and Dong, Jin Song and Mei, Hong},
title = {CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652142},
doi = {10.1145/3650212.3652142},
abstract = {Recent years have seen the development of LLM-based code generation. Compared to generating code in a software project, incremental code edits are empirically observed to be more frequent. The emerging code editing approaches usually formulate the problem as generating an edit based on known relevant prior edits and context. However, practical code edits can be more complicated. First, an editing session can include multiple (ir)relevant edits to the code under edit. Second, the inference of the subsequent edits is non-trivial as the scope of its ripple effect can be the whole project. 
 
 
 
 
 
 
 
In this work, we propose CoEdPilot, an LLM-driven solution to recommend code edits by discriminating the relevant edits, exploring their interactive natures, and estimating its ripple effect in the project. Specifically, CoEdPilot orchestrates multiple neural transformers to identify what and how to edit in the project regarding both edit location and edit content. When a user accomplishes an edit with an optional editing description, an Subsequent Edit Analysis first reports the most relevant files in the project with what types of edits (e.g., keep, insert, and replace) can happen for each line of their code. Next, an Edit-content Generator generates concrete edit options for the lines of code, regarding its relevant prior changes reported by an Edit-dependency Analyzer. Last, both the Subsequent Edit Analysis and the Edit-content Generator capture relevant prior edits as feedback to readjust their recommendations. We train our models by collecting over 180K commits from 471 open-source projects in 5 programming languages. Our extensive experiments show that (1) CoEdPilot can well predict the edits (i.e., predicting edit location with accuracy of 70.8%-85.3%, and the edit content with exact match rate of 41.8% and BLEU4 score of 60.7); (2) CoEdPilot can well boost existing edit generators such as GRACE and CCT5 on exact match rate by 8.57% points and BLEU4 score by 18.08. Last, our user study on 18 participants with 3 editing tasks (1) shows that CoEdPilot can be effective in assisting users to edit code in comparison with Copilot, and (2) sheds light on the future improvement of the tool design. The video demonstration of our tool is available at https://sites.google.com/view/coedpilot/home.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {466–478},
numpages = {13},
keywords = {code edit generation, edit location, interaction, language model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3664647.3681699,
author = {Yiyang, Luo and Lin, Ke and Gu, Chao},
title = {Context-Aware Indoor Point Cloud Object Generation through User Instructions},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681699},
doi = {10.1145/3664647.3681699},
abstract = {Indoor scene modification has emerged as a prominent area within computer vision, particularly for its applications in Augmented Reality (AR) and Virtual Reality (VR). Traditional methods often rely on pre-existing object databases and predetermined object positions, limiting their flexibility and adaptability to new scenarios. In response to this challenge, we present a novel end-to-end multi-modal deep neural network capable of generating point cloud objects seamlessly integrated with their surroundings, driven by textual instructions. Our work proposes a novel approach in scene modification by enabling the creation of new environments with previously unseen object layouts, eliminating the need for pre-stored CAD models. Leveraging Point-E as our generative model, we introduce innovative techniques such as quantized position prediction and Top-K estimation to address the issue of false negatives resulting from ambiguous language descriptions. Furthermore, we conduct comprehensive evaluations to showcase the diversity of generated objects, the efficacy of textual instructions, and the quantitative metrics, affirming the realism and versatility of our model in generating indoor objects. To provide a holistic assessment, we incorporate visual grounding as an additional metric, ensuring the quality and coherence of the scenes produced by our model. Through these advancements, our approach not only advances the state-of-the-art in indoor scene modification but also lays the foundation for future innovations in immersive computing and digital environment creation. The project is available at https://ainnovatelab.github.io/Context-aware-Indoor-PCG.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10182–10190},
numpages = {9},
keywords = {3d point clouds, deep learning, generative model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3597503.3639154,
author = {Asare, Owura and Nagappan, Meiyappan and Asokan, N.},
title = {A User-centered Security Evaluation of Copilot},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639154},
doi = {10.1145/3597503.3639154},
abstract = {Code generation tools driven by artificial intelligence have recently become more popular due to advancements in deep learning and natural language processing that have increased their capabilities. The proliferation of these tools may be a double-edged sword because while they can increase developer productivity by making it easier to write code, research has shown that they can also generate insecure code. In this paper, we perform a user-centered evaluation GitHub's Copilot to better understand its strengths and weaknesses with respect to code security. We conduct a user study where participants solve programming problems (with and without Copilot assistance) that have potentially vulnerable solutions. The main goal of the user study is to determine how the use of Copilot affects participants' security performance. In our set of participants (n=25), we find that access to Copilot accompanies a more secure solution when tackling harder problems. For the easier problem, we observe no effect of Copilot access on the security of solutions. We also observe no disproportionate impact of Copilot use on particular kinds of vulnerabilities. Our results indicate that there are potential security benefits to using Copilot, but more research is warranted on the effects of the use of code generation tools on technically complex problems with security requirements.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {158},
numpages = {11},
keywords = {user study, code generation, copilot, security, software engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3640471.3680462,
author = {ElAgroudy, Passant and Gruenerbl, Agnes and Barbareschi, Giulia and Spilski, Jan and Kunze, Kai and Lachmann, Thomas and Lukowicz, Paul},
title = {mobiCHAI - 1st International Workshop on Mobile Cognition-Altering Technologies (CAT) using Human-Centered AI},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680462},
doi = {10.1145/3640471.3680462},
abstract = {The quest for enhanced cognition has been a driving force behind human advancement, fostering innovation and personal fulfillment. Cognition Altering Technologies (CAT) holds immense promise in elevating the quality of life across diverse domains including education, decision-making, healthcare, and fitness. The current proliferation of Artificial Intelligence (AI), particularly the widespread adoption of Generative AI and foundational models, presents an unprecedented opportunity to prototype new CAT that can augment human capabilities. This workshop aims to unite interdisciplinary research communities to explore the potential of leveraging GenAI and human-centered AI to develop relevant CAT. Taking place at MobileHCI 2024, this one-day workshop invites researchers, practitioners, and designers from fields such as artificial intelligence, ubiquitous computing, human-computer interaction, and social sciences to collaborate and chart the future of cognitive enhancement through technology.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {31},
numpages = {5},
keywords = {Human-Centered AI, Hybrid-Human Artificial Intelligence, augmenting human capabilities, cognitive science, generative AI, shaping cognitive and social behavior, ubiquitous technologies},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1145/3613905.3636272,
author = {Nacke, Lennart E.},
title = {How to Write Better CHI Papers (with AI)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636272},
doi = {10.1145/3613905.3636272},
abstract = {Writing and organizing research papers is a valuable skill that can make or break your academic career. Generative artificial intelligence (AI) tools offer unprecedented opportunities for researchers to improve their skills in writing research papers and conducting literature reviews. In the past six years, my writing course has introduced you to everything you wanted to know about writing papers. However, with the arrival of generative AI, our writing process is changing. So, now I offer the opportunity to learn how to leverage generative AI tools to edit your writing, brainstorm, and help you find citations, so that your papers are easy to read and have impact. It is broken up into three 75-minute online units that will help you structure your paper’s research content and use generative AI as assistive research technology. The goal of the course is to learn how to leverage generative AI to help you write a paper that makes a contribution to the field of human-computer interaction and can be understood by other HCI researchers facilitated by the use of generative AI tools.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {599},
numpages = {4},
keywords = {Clarity, LaTeX, Research Methods, Submission Process, Writing},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3691620.3695537,
author = {Zhao, Jiuang and Yang, Donghao and Zhang, Li and Lian, Xiaoli and Yang, Zitian and Liu, Fang},
title = {Enhancing Automated Program Repair with Solution Design},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695537},
doi = {10.1145/3691620.3695537},
abstract = {Automatic Program Repair (APR) endeavors to autonomously rectify issues within specific projects, which generally encompasses three categories of tasks: bug resolution, new feature development, and feature enhancement. Despite extensive research proposing various methodologies, their efficacy in addressing real issues remains unsatisfactory. It's worth noting that, typically, engineers have design rationales (DR) on solution--- planed solutions and a set of underlying reasons---before they start patching code. In open-source projects, these DRs are frequently captured in issue logs through project management tools like Jira. This raises a compelling question: How can we leverage DR scattered across the issue logs to efficiently enhance APR?To investigate this premise, we introduce DRCodePilot, an approach designed to augment GPT-4-Turbo's APR capabilities by incorporating DR into the prompt instruction. Furthermore, given GPT-4's constraints in fully grasping the broader project context and occasional shortcomings in generating precise identifiers, we have devised a feedback-based self-reflective framework, in which we prompt GPT-4 to reconsider and refine its outputs by referencing a provided patch and suggested identifiers. We have established a benchmark comprising 938 issue-patch pairs sourced from two open-source repositories hosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot achieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is utilized directly. Additionally, the CodeBLEU scores also exhibit promising enhancements. Moreover, our findings reveal that the standalone application of DR can yield promising increase in the full-match ratio across CodeLlama, GPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot initiative heralds a novel human-in-the-loop avenue for advancing the field of APR.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1706–1718},
numpages = {13},
keywords = {design rationale, issue logs, developer discussion, automated program repair},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3704725,
author = {Zhang, Shaobo and Pan, Yimeng and Liu, Qin and Yan, Zheng and Choo, Kim-Kwang Raymond and Wang, Guojun},
title = {Backdoor Attacks and Defenses Targeting Multi-Domain AI Models: A Comprehensive Review},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3704725},
doi = {10.1145/3704725},
abstract = {Since the emergence of security concerns in artificial intelligence (AI), there has been significant attention devoted to the examination of backdoor attacks. Attackers can utilize backdoor attacks to manipulate model predictions, leading to significant potential harm. However, current research on backdoor attacks and defenses in both theoretical and practical fields still has many shortcomings. To systematically analyze these shortcomings and address the lack of comprehensive reviews, this article presents a comprehensive and systematic summary of both backdoor attacks and defenses targeting multi-domain AI models. Simultaneously, based on the design principles and shared characteristics of triggers in different domains and the implementation stages of backdoor defense, this article proposes a new classification method for backdoor attacks and defenses. We use this method to extensively review backdoor attacks in the fields of computer vision and natural language processing, and we also examine the current applications of backdoor attacks in audio recognition, video action recognition, multimodal tasks, time series tasks, generative learning, and reinforcement learning, while critically analyzing the open problems of various backdoor attack techniques and defense strategies. Finally, this article builds upon the analysis of the current state of AI security to further explore potential future research directions for backdoor attacks and defenses.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {87},
numpages = {35},
keywords = {Artificial intelligence security, backdoor attacks, backdoor defenses}
}

@inproceedings{10.1145/3689092.3690042,
author = {Ghosh, Shreya and Cai, Zhixi and Dhall, Abhinav and Kollias, Dimitrios and Goecke, Roland and Gedeon, Tom},
title = {MRAC Track 1: 2nd Workshop on Multimodal, Generative and Responsible Affective Computing},
year = {2024},
isbn = {9798400712036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689092.3690042},
doi = {10.1145/3689092.3690042},
abstract = {With the rapid advancements in multimodal generative technology, Affective Computing research has provoked discussion about the potential consequences of AI systems equipped with emotional intelligence. Affective Computing involves the design, evaluation, and implementation of Emotion AI and related technologies aimed at improving people's lives. Designing a computational model in affective computing requires vast amounts of multimodal data, including RGB images, video, audio, text, and physiological signals. Moreover, Affective Computing research is deeply engaged with ethical considerations at various stages'from training emotionally intelligent models on large-scale human data to deploying these models in specific applications. Fundamentally, the development of any AI system must prioritize its impact on humans, aiming to augment and enhance human abilities rather than replace them, while drawing inspiration from human intelligence in a safe and responsible manner. The MRAC 2024 Track 1 workshop seeks to extend these principles from controlled, small-scale lab environments to real-world, large-scale contexts, emphasizing responsible development. The workshop also aims to highlight the potential implications of generative technology, along with the ethical consequences of its use, to researchers and industry professionals. To the best of our knowledge, this is the first workshop series to comprehensively address the full spectrum of multimodal, generative affective computing from a responsible AI perspective, and this is the second iteration of this workshop. Webpage: https://react-ws.github.io/2024/},
booktitle = {Proceedings of the 2nd International Workshop on Multimodal and Responsible Affective Computing},
pages = {1–6},
numpages = {6},
keywords = {affective computing, generative ai, human computer interaction},
location = {Melbourne VIC, Australia},
series = {MRAC '24}
}

@inproceedings{10.1145/3626253.3635606,
author = {Hou, Xinying and Ericson, Barbara J. and Wang, Xu},
title = {Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635606},
doi = {10.1145/3626253.3635606},
abstract = {Novice programmers need to write basic code as part of the learning process, but they often face difficulties. To assist struggling students, we recently implemented personalized Parsons problems, which are code puzzles where students arrange blocks of code to solve them, as pop-up scaffolding. Students found them to be more engaging and preferred them for learning, instead of simply receiving the correct answer, such as the response they might get from generative AI tools like ChatGPT. However, a drawback of using Parsons problems as scaffolding is that students may be able to put the code blocks in the correct order without fully understanding the rationale of the correct solution. As a result, the learning benefits of scaffolding are compromised. Can we improve the understanding of personalized Parsons scaffolding by providing textual code explanations? In this poster, we propose a design that incorporates multiple levels of textual explanations for the Parsons problems. This design will be used for future technical evaluations and classroom experiments. These experiments will explore the effectiveness of adding textual explanations to Parsons problems to improve instructional benefits.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1686–1687},
numpages = {2},
keywords = {code explanations, code writing, hint, introductory programming, large language models, parsons problems, scaffolding},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3665689.3665753,
author = {Zhao, Long and Song, Huijia and Lin, Zihan and Wen, Zhenguo and Lin, Xiaozhu},
title = {Artificial intelligence design of ProteinA-like peptides},
year = {2024},
isbn = {9798400716645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665689.3665753},
doi = {10.1145/3665689.3665753},
abstract = {There are hundreds of millions of natural proteins in nature, and these natural proteins can play different roles due to their special structure. The first field of AI for Science is the prediction and design of protein structure, and simulating the structure of certain natural proteins has become a popular topic in biopharmaceutical research. The generative adversarial network model in deep learning and a target sequence method were used in the paper to mimic the special structure of natural proteins. We successfully synthesized the ProteinA-like peptide sequence which had a high structural similarity with the natural proteins in its tertiary structure.These synthetic peptide sequences by computer will lay the foundation for the later transcription to become mRNA and to synthesize protein in the laboratory .},
booktitle = {Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing},
pages = {380–384},
numpages = {5},
location = {Beijing, China},
series = {BIC '24}
}

@inproceedings{10.1145/3665065.3665082,
author = {Nokhwal, Sahil and Nokhwal, Suman and Pahune, Saurabh and Chaudhary, Ankit},
title = {Quantum Generative Adversarial Networks: Bridging Classical and Quantum Realms},
year = {2024},
isbn = {9798400717291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665065.3665082},
doi = {10.1145/3665065.3665082},
abstract = {In this pioneering research paper, we present a groundbreaking exploration into the synergistic fusion of classical and quantum computing paradigms within the realm of Generative Adversarial Networks (GANs). Our objective is to seamlessly integrate quantum computational elements into the conventional GAN architecture, thereby unlocking novel pathways for enhanced training processes. Drawing inspiration from the inherent capabilities of quantum bits (qubits), we delve into the incorporation of quantum data representation methodologies within the GAN framework. By capitalizing on the unique quantum features, we aim to accelerate the training process of GANs, offering a fresh perspective on the optimization of generative models. Our investigation deals with theoretical considerations and evaluates the potential quantum advantages that may manifest in terms of training efficiency and generative quality. We confront the challenges inherent in the quantum-classical amalgamation, addressing issues related to quantum hardware constraints, error correction mechanisms, and scalability considerations. This research is positioned at the forefront of quantum-enhanced machine learning, presenting a critical stride towards harnessing the computational power of quantum systems to expedite the training of Generative Adversarial Networks. Through our comprehensive examination of the interface between classical and quantum realms, we aim to uncover transformative insights that will propel the field forward, fostering innovation and advancing the frontier of quantum machine learning.},
booktitle = {Proceedings of the 2024 8th International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {105–109},
numpages = {5},
keywords = {Adversarial Networks (QGANs), Generative Modeling, Quantum Generative, Quantum Machine Learning, Quantum Speedup},
location = {Singapore, Singapore},
series = {ISMSI '24}
}

@inproceedings{10.1145/3643832.3661892,
author = {Jia, Fucheng and Jiang, Shiqi and Cao, Ting and Cui, Wei and Xia, Tianrui and Cao, Xu and Li, Yuanchun and Wang, Qipeng and Zhang, Deyu and Ren, Ju and Liu, Yunxin and Qiu, Lili and Yang, Mao},
title = {Empowering In-Browser Deep Learning Inference on Edge Through Just-In-Time Kernel Optimization},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661892},
doi = {10.1145/3643832.3661892},
abstract = {Web is increasingly becoming the primary platform to deliver AI services onto edge devices, making in-browser deep learning (DL) inference more prominent. Nevertheless, the heterogeneity of edge devices, combined with the underdeveloped state of Web hardware acceleration practices, hinders current in-browser inference from achieving its full performance potential on target devices.To address this issue, this paper presents the pioneering inbrowser inference system, nnJIT, which enables just-in-time (JIT) auto-generation of optimized computing kernels for edge devices. nnJIT is built upon two novel techniques that significantly reduce kernel search and compilation overhead while improving performance firmly: Tensor-Web Compiling Co-Design lowers compiling costs by around 100\texttimes{} through eliminating redundant and ineffective compiling passes; Web-Specific Lite Kernel Optimization Space reduces kernel tuning costs by focusing on Web programming requirements and efficient device resource utilization, pruning the optimization space from millions to only dozens.nnJIT1 is evaluated for modern models, e.g., BART, T5, and Llama 2, on a range of edge devices including laptops and smartphones using different browsers and hardware from ARM, Intel, AMD and Nvidia. The results show that nnJIT can achieve up to 8.2\texttimes{} faster within 30 seconds compared to the existing baselines.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {438–450},
numpages = {13},
keywords = {in-browser deep learning inference, just-in-time kernel optimizations, WebAssembly, WebGPU},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@article{10.1145/3632860,
author = {Patton, Noah and Rahmani, Kia and Missula, Meghana and Biswas, Joydeep and Dillig, I\c{s}\i{}l},
title = {Programming-by-Demonstration for Long-Horizon Robot Tasks},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632860},
doi = {10.1145/3632860},
abstract = {The goal of programmatic Learning from Demonstration (LfD) is to learn a policy in a programming language that can be used to control a robot’s behavior from a set of user demonstrations. This paper presents a new programmatic LfD algorithm that targets long-horizon robot tasks which require synthesizing programs with complex control flow structures, including nested loops with multiple conditionals. Our proposed method first learns a program sketch that captures the target program’s control flow and then completes this sketch using an LLM-guided search procedure that incorporates a novel technique for proving unrealizability of programming-by-demonstration problems. We have implemented our approach in a new tool called PROLEX and present the results of a comprehensive experimental evaluation on 120 benchmarks involving complex tasks and environments. We show that, given a 120 second time limit, PROLEX can find a program consistent with the demonstrations in 80% of the cases. Furthermore, for 81% of the tasks for which a solution is returned, PROLEX is able to find the ground truth program with just one demonstration. In comparison, CVC5, a syntax-guided synthesis tool, is only able to solve 25% of the cases even when given the ground truth program sketch, and an LLM-based approach, GPT-Synth, is unable to solve any of the tasks due to the environment complexity.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {18},
numpages = {34},
keywords = {Abstract Interpretation, Learning from Demonstrations, Program Synthesis}
}

@article{10.1145/3624720,
author = {Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
title = {Computing Education in the Era of Generative AI},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624720},
doi = {10.1145/3624720},
abstract = {Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.},
journal = {Commun. ACM},
month = jan,
pages = {56–67},
numpages = {12}
}

@inproceedings{10.1145/3615979.3664473,
author = {Tourassi, Georgia},
title = {Powering Progress in Leadership Computing in the Era of Generative AI and Energy Constraints},
year = {2024},
isbn = {9798400703638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615979.3664473},
doi = {10.1145/3615979.3664473},
abstract = {The advent of exascale computing has unlocked unprecedented opportunities for scientific discovery and technological advancement. As we push the boundaries of computational power, we find ourselves at the intersection of two critical challenges: harnessing the transformative potential of generative AI and navigating the growing demands on energy consumption. In this presentation I will describe the Oak Ridge National Laboratory’s journey to exascale computing, highlighting the remarkable achievements made possible by the Frontier supercomputing across various scientific domains. I will highlight the intricate interplay between large-scale modeling, simulation, and the growing field of generative AI, showcasing how these technologies can be seamlessly interwoven to tackle complex scientific problems and drive innovation. However, the energy consumption of these cutting-edge systems poses significant challenges that demand our attention and ingenuity. I will discuss the strategies and best practices we are implementing at the Oak Ridge Leadership Computing Facility to manage and optimize energy efficiency, ensuring the sustainability of our computing infrastructure while trying to solve the most pressing scientific and technical challenges facing humanity.},
booktitle = {Proceedings of the 38th ACM SIGSIM Conference on Principles of Advanced Discrete Simulation},
pages = {1},
numpages = {1},
location = {Atlanta, GA, USA},
series = {SIGSIM-PADS '24}
}

@inproceedings{10.1145/3656650.3656663,
author = {Gennari, Rosella and Krik, Soufiane},
title = {Responsible Design of Socio-Technical Solutions with Social Design Students: a Case Study},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656663},
doi = {10.1145/3656650.3656663},
abstract = {Recent research work on digital-well being considers it a matter of personal growth and education. Research in social digital well-being, in particular, invites young generations to consider the role of digital technologies for social well-being. It explored how to engage young generations in building socio-technical prototypes and reflecting on the impact of technology on people. This article fits into this broad line of research. It reports on a case study with social design students with no computing background. It invited them to consider the use of computing technologies in their social-design projects, and to reflect critically on their work. The design was structured with an ad hoc toolkit with various building materials, including cards for reflecting, and physical-computing devices for rapidly prototyping design ideas. The purpose of the toolkit is, on the one hand, to structure and constrain the generative design process and, on the other hand, to allow a certain degree of expressiveness and freedom to participants. The article reports the results of the case study and concludes with a discussion of how to engage non-computing experts in such a process, balancing freedom and guidance.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {50},
numpages = {9},
keywords = {Responsible design, building interaction, end user, interaction design tools, prototyping, social interaction, well being},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3677052.3698622,
author = {Natarajan, Jeevesh and Wang, Wayne and Jiang, Yaqiao and Zhang, Zeqi and Ye, Huanhui and Kuang, Lingxi},
title = {Generative-CNN for Pattern Recognition in Finance},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698622},
doi = {10.1145/3677052.3698622},
abstract = {Convolutional neural networks (CNNs) have achieved considerable success across a spectrum of computer vision tasks, with applications ranging from healthcare to automated driving. Recent literature has also explored its potential utility in trading and risk management within the finance industry. Despite their versatility, CNNs are substantially constrained by their data-hungry nature. The lack of well-labeled image datasets poses a major challenge to the widespread adoption of CNNs in financial machine learning research across academia and industry. To address these concerns, this work presents Generative-CNN, a novel approach that utilizes a generative adversarial network (GAN) to synthetically generate images to enhance the performance of a CNN with applications in trading.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {142–149},
numpages = {8},
keywords = {Candlestick Patterns, Convolutional Neural Networks, Financial Time Series, Generative Adversarial Networks, Image Classification},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3632621.3671415,
author = {Landesman, Rotem},
title = {Teens' Ethical Sensemaking About Emerging Technologies},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671415},
doi = {10.1145/3632621.3671415},
abstract = {Emerging technologies, among them generative AI, are continuously being integrated into the mundane fabric of young people’s lives and routines. Recently, scholars called to expand computing education beyond learning to use and create with technologies to think critically and ethically about their potential impacts as a means to encourage the development of a sense of computational empowerment. My research aims to explore this space and opportunities which encourage ethical thinking with youth - specifically adolescents - on and about generative AI, a recent emerging innovation. This exploration will take inspiration from previous work pointing to the efficacy of practices from the field of Philosophy for Children (P4C) as well as recent work pointing to the potential of eliciting ethical thinking through a critical reflection and making framework, and suggest a novel framework to elicit a sense of computational empowerment as youth grow up in our digital world.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {557–559},
numpages = {3},
keywords = {computing education, ethics in computing, k-12},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3613904.3642239,
author = {Yan, Litao and Hwang, Alyssa and Wu, Zhiyuan and Head, Andrew},
title = {Ivie: Lightweight Anchored Explanations of Just-Generated Code},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642239},
doi = {10.1145/3613904.3642239},
abstract = {Programming assistants have reshaped the experience of programming into one where programmers spend less time writing and more time critically examining code. In this paper, we explore how programming assistants can be extended to accelerate the inspection of generated code. We introduce an extension to the programming assistant called Ivie, or instantly visible in-situ explanations. When using Ivie, a programmer’s generated code is instantly accompanied by explanations positioned just adjacent to the code. Our design was optimized for low-cost invocation and dismissal. Explanations are compact and informative. They describe meaningful expressions, from individual variables to entire blocks of code. We present an implementation of Ivie that forks VS Code, applying a modern LLM for timely segmentation and explanation of generated code. In a lab study, we compared Ivie to a contemporary baseline tool for code understanding. Ivie improved understanding of generated code, and was received by programmers as a highly useful, low distraction complement to the programming assistant.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {140},
numpages = {15},
keywords = {Programming assistants, anchored explanations, brevity, comprehension support, easy dismissal, easy invocation, instructive copilots, label overlays, variable levels of detail},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3643991.3645083,
author = {Das, Joy Krishan and Mondal, Saikat and Roy, Chanchal},
title = {Investigating the Utility of ChatGPT in the Issue Tracking System: An Exploratory Study},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645083},
doi = {10.1145/3643991.3645083},
abstract = {Issue tracking systems serve as the primary tool for incorporating external users and customizing a software project to meet the users' requirements. However, the limited number of contributors and the challenge of identifying the best approach for each issue often impede effective resolution. Recently, an increasing number of developers are turning to AI tools like ChatGPT to enhance problem-solving efficiency. While previous studies have demonstrated the potential of ChatGPT in areas such as automatic program repair, debugging, and code generation, there is a lack of study on how developers explicitly utilize ChatGPT to resolve issues in their tracking system. Hence, this study aims to examine the interaction between ChatGPT and developers to analyze their prevalent activities and provide a resolution. In addition, we assess the code reliability by confirming if the code produced by ChatGPT was integrated into the project's codebase using the clone detection tool NiCad. Our investigation reveals that developers mainly use ChatGPT for brainstorming solutions but often opt to write their code instead of using ChatGPT-generated code, possibly due to concerns over the generation of "hallucinated" code, as highlighted in the literature.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {217–221},
numpages = {5},
keywords = {ChatGPT, issue tracking, NiCad, code clone},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3665463.3678859,
author = {Kleinman, Erica and Seif El-Nasr, Magy and Pfau, Johannes and Kriglstein, Simone and Wallner, G\"{u}nter and Melhart, David and Yannakakis, Georgios N. and Zhu, Jichen and Watson, Benjamin and Harteveld, Casper},
title = {Ethics and Transparency in Game Data},
year = {2024},
isbn = {9798400706929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665463.3678859},
doi = {10.1145/3665463.3678859},
abstract = {While existing work has discussed ethics and fairness in relation to data generally, and a small number of papers have raised the same issues within games specifically, work on addressing fairness and ethical issues with game data collection and usage is still rare. With game AI, LLM integration, data analytics, and machine learning on the rise, a new dimension to the responsible and ethical treatment of data opens up, comprising factors unique to video games. Our goal for this workshop is, thus, to bring together researchers and professionals working in the spaces of game human–computer interaction (HCI), game data and AI, and ethics in both games and AI to discuss and identify interdisciplinary research opportunities and devise potential solutions to existing problems.},
booktitle = {Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play},
pages = {466–470},
numpages = {5},
keywords = {AI, Machine Learning, ethics, game AI, game data, transparency},
location = {Tampere, Finland},
series = {CHI PLAY Companion '24}
}

@inproceedings{10.1145/3620666.3655589,
author = {Vahdat, Amin},
title = {Societal infrastructure in the age of Artificial General Intelligence},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3655589},
doi = {10.1145/3620666.3655589},
abstract = {Today, we are at an inflection point in computing where emerging Generative AI services are placing unprecedented demand for compute while the existing architectural patterns for improving efficiency have stalled. In this talk, we will discuss the likely needs of the next generation of computing infrastructure and use recent examples at Google from networks to accelerators to servers to illustrate the challenges and opportunities ahead. Taken together, we chart a course where computing must be increasingly specialized and co-optimized with algorithms and software, all while fundamentally focusing on security and sustainability.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {1},
numpages = {1},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1109/CGO57630.2024.10444873,
author = {Jangda, Abhinav and Maleki, Saeed and Dehnavi, Maryam Mehri and Musuvathi, Madan and Saarikivi, Olli},
title = {A Framework for Fine-Grained Synchronization of Dependent GPU Kernels},
year = {2024},
isbn = {9798350395099},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CGO57630.2024.10444873},
doi = {10.1109/CGO57630.2024.10444873},
abstract = {Machine Learning (ML) models execute several parallel computations including Generalized Matrix Multiplication, Convolution, Dropout, etc. These computations are commonly executed on Graphics Processing Units (GPUs), by dividing the computation into independent processing blocks, known as tiles. Since the number of tiles are usually higher than the execution units of a GPU, tiles are executed on all execution units in one or more waves. However, the number of tiles is not always a multiple of the number of execution units. Thus, tiles executed in the final wave can under-utilize the GPU.To address this issue, we present cuSync, a framework for synchronizing dependent kernels using a user-defined finegrained synchronization policy to improve the GPU utilization. cuSync synchronizes tiles instead of kernels, which allows executing independent tiles of dependent kernels concurrently. We also present a compiler to generate diverse fine-grained synchronization policies based on dependencies between kernels. Our experiments found that synchronizing CUDA kernels using cuSync reduces the inference times of four popular ML models: MegatronLM GPT-3 by up to 15%, LLaMA by up to 14%, ResNet-38 by up to 22%, and VGG-19 by up to 16% over several batch sizes.},
booktitle = {Proceedings of the 2024 IEEE/ACM International Symposium on Code Generation and Optimization},
pages = {93–105},
numpages = {13},
keywords = {CUDA, GPU, generalized matrix multiplication, convolution, fine-grained synchronization, machine learning},
location = {Edinburgh, United Kingdom},
series = {CGO '24}
}

@article{10.1145/3628599,
author = {Kim, Seok Young and Lee, Jaewook and Paik, Yoonah and Kim, Chang Hyun and Lee, Won Jun and Kim, Seon Wook},
title = {Optimal Model Partitioning with Low-Overhead Profiling on the PIM-based Platform for Deep Learning Inference},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/3628599},
doi = {10.1145/3628599},
abstract = {Recently Processing-in-Memory (PIM) has become a promising solution to achieve energy-efficient computation in data-intensive applications by placing computation near or inside the memory. In most Deep Learning (DL) frameworks, a user manually partitions a model’s computational graph (CG) onto the computing devices by considering the devices’ capability and the data transfer. The Deep Neural Network (DNN) models become increasingly complex for improving accuracy; thus, it is exceptionally challenging to partition the execution to achieve the best performance, especially on a PIM-based platform requiring frequent offloading of large amounts of data. This article proposes two novel algorithms for DL inference to resolve the challenge: low-overhead profiling and optimal model partitioning. First, we reconstruct CG by considering the devices’ capability to represent all the possible scheduling paths. Second, we develop a profiling algorithm to find the required minimum profiling paths to measure all the node and edge costs of the reconstructed CG. Finally, we devise the model partitioning algorithm to get the optimal minimum execution time using the dynamic programming technique with the profiled data. We evaluated our work by executing the BERT, RoBERTa, and GPT-2 models on the ARM multicores with the PIM-modeled FPGA platform with various sequence lengths. For three computing devices in the platform, i.e., CPU serial/parallel and PIM executions, we could find all the costs only in four profile runs, three for node costs and one for edge costs. Also, our model partitioning algorithm achieved the highest performance in all the experiments over the execution with manually assigned device priority and the state-of-the-art greedy approach.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = feb,
articleno = {28},
numpages = {22},
keywords = {PIM-based execution, optimal scheduling, profiling, computational graph}
}

@inproceedings{10.1145/3673277.3673352,
author = {Jiao, Fangyu and Yu, Bei and Chen, Lang and Chen, Dunkui},
title = {A Bibliometric Analysis of Papers on Generative Adversarial Networks},
year = {2024},
isbn = {9798400716959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673277.3673352},
doi = {10.1145/3673277.3673352},
abstract = {Generative Adversarial Network (GAN) is a powerful generative model based on deep learning. At present, it is widely used in computer vision, natural language processing, semi-supervised learning and other fields, and has achieved remarkable results. This paper adopts the bibliometric analysis method, and uses InCites and VOSviewer tools to quantitatively study and visualize the papers of generative adversarial networks. Through the analysis and comparison of countries, institutions, and researchers, a comprehensive portrait of the academic achievements in the field of GAN is portrayed: GAN research reached a peak in 2021; Deep learning, Super-Resolution, Face Recognition, Image Enhancement, Speech Recognition, Object Tracking, Intrusion Detection are hotspots; China and the United States have published the most papers; Chinese institutions lack both international and corporate cooperation, and Chinese researchers need more innovative research on theories.},
booktitle = {Proceedings of the 2024 3rd International Conference on Cryptography, Network Security and Communication Technology},
pages = {434–439},
numpages = {6},
location = {Harbin, China},
series = {CNSCT '24}
}

@inproceedings{10.1145/3677619.3678114,
author = {Marx, Erik and Witt, Clemens and Leonhardt, Thiemo},
title = {Identifying Secondary School Students' Misconceptions about Machine Learning: An Interview Study},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678114},
doi = {10.1145/3677619.3678114},
abstract = {Since students are familiar with machine learning (ML)-based applications in their everyday lives, they already construct mental models of how these systems work. This can result in misconceptions that influence the learning of correct ML concepts. Therefore, this study investigates the misconceptions students hold about the functionality of ML-based applications. To this end, we conducted semi-structured interviews with five students, focusing on their understanding of facial recognition and ChatGPT. The interviews were analyzed using an inductively developed code system and qualitative content analysis. This process identified six key misconceptions held by students: “Programmed Behavior,” “Exactness,” “Data Storage,” “Continuous Learning,” “User-trained Model,” and “Autonomous Data Acquisition”. These misconceptions include the notion that AI learns continuously during application, or that training data is saved and reused later. This paper presents the identified misconceptions and discusses their implication for the design and evaluation of effective learning activities in the context of ML.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {6},
numpages = {10},
keywords = {artificial intelligence, interview study, machine learning, mental models, misconceptions, qualitative research, students conceptions},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@inproceedings{10.1145/3644815.3644982,
author = {Ronanki, Krishna and Cabrero-Daniel, Beatriz and Berger, Christian},
title = {Prompt Smells: An Omen for Undesirable Generative AI Outputs},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644982},
doi = {10.1145/3644815.3644982},
abstract = {Recent trends in the world of Generative Artificial Intelligence (GenAI) focus on developing deep learning (DL)-based models capable of learning structures and temporal patterns from supplied training data to generate content in different formats like text, images, or sound. GenAI models have been widely used in various applications, including creating stories, illustrations, poems, articles, computer code, music compositions, and videos [5, 11].},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {286–287},
numpages = {2},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3638530.3654348,
author = {Baeta, Francisco and Correia, Jo\~{a}o and Martins, Tiago and Machado, Penousal},
title = {Exploring Evolutionary Generators within Generative Adversarial Networks},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3654348},
doi = {10.1145/3638530.3654348},
abstract = {Since their introduction, Generative Adversarial Networks (GANs) have represented the bulk of approaches used in image generation. Before GANs, such approaches used Machine Learning (ML) exclusively to tackle the training problems inherent to GANs. However, in recent years, evolutionary approaches have been making a comeback, not only across the field of ML but in generative modelling specifically. Successes in GPU-accelerated Genetic Programming (GP) led to the introduction of the TGPGAN framework, which used GP as a replacement for the deep convolutional network conventionally used as a GAN generator. In this paper, we delve further into the generative capabilities of evolutionary computation within adversarial models and extend the study performed in TGPGAN to analyse other evolutionary approaches. Similarly to TGPGAN, the presented approaches replace the generator component of a Deep Convolutional GAN (DCGAN): one with a line-drawing Genetic Algorithm (GA) and another with a Compositional Pattern Producing Network (CPPN). Our comparison of generative performance shows that the GA used manages to perform competitively with the original framework. More importantly, this work showcases the viability of other evolutionary approaches other than GP for the purpose of image generation.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {251–254},
numpages = {4},
keywords = {evolutionary computation, genetic programming, generative adversarial networks, TGPGAN},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3688868.3689206,
author = {Laga, Hamid},
title = {Statistical 3D and 4D Shape Analysis: Theory and Applications in the Era of Generative AI},
year = {2024},
isbn = {9798400711954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688868.3689206},
doi = {10.1145/3688868.3689206},
abstract = {The need for 3D and 4D (i.e., 3D + time) shape analysis arises in many branches of science ranging from anatomy, bioinformatics, medicine, and biology to computer graphics, multimedia, and virtual and augmented reality. In fact, shape is an essential property of natural and man-made 3D objects. It deforms over time as a result of many internal and external factors. For instance, anatomical organs such as bones, kidneys, and subcortical structures in the brain deform due to natural growth or disease progression; human faces deform as a consequence of talking, executing facial expressions, and aging. Similarly, human body actions and motions such as walking, jumping, and grasping are the result of the deformation, over time, of the human body shape. The ability to understand and model (1) the typical shape and deformation patterns of a class of 3D objects, and (2) the variability of these shapes and deformations within and across object classes has many applications. For example, in medical diagnosis and biological growth modeling, one is interested in measuring the intensity of pain from facial deformations, and in distinguishing between normal growth and disease progression using the shape of the body and its deformation over time. In computer vision and graphics, the ability to statistically model such spatiotemporal variability can be used to summarize collections of 3D objects and their animation, and simulate animations and motions. Similar to 3D morphable models, these tools can also be used in a generative model for synthesizing large corpora of labeled longitudinal 3D shape data, e.g., 4D faces, virtual humans, and various objects. In this talk, I will share the research undertaken by my group and collaborators in the area of statistical analysis and modelling of static (i.e., 3D) and dynamic (i.e., 4D) shapes. I will first highlight the importance of this topic for various applications ranging from biology and medicine to computer graphics and virtual/augmented reality. I will then structure my talk into three parts. The first one focuses on 3D shapes that bend, stretch, and change in topology. I will introduce our mathematical framework, termed Square Normal Fields (SRNF) [6, 10-12, 15], which provides (1) an efficient representation of 3D shapes, (2) an elastic metric for quantifying shape differences between objects, (3) mechanisms for computing correspondences and geodesics between such shapes, and (4) methods for characterizing populations of 3D shapes using generative models. I will consider both shapes that bend and stretch [6, 10-12, 15] but also those that change their structure and topology [18-22]. The second part of the talk will focus on 4D shapes, i.e., 3D shapes that move and deform as the result of normal growth or disease progression [9, 14]. I will summarize the latest solutions we developed for the statistical analysis of the spatio-temporal variability in such 4D shape data and highlight their applications in various fields. The third part of this talk will focus on the role statistical 3D and 4D shape models played and have to play in the era of Deep Learning and Generative AI. I will particularly highlight their importance and the role they played in advancing the field of 3D and 4D reconstruction and generation from images, videos, and text [1-5, 7, 8, 13, 16, 17]. I will conclude the talk by sharing insights into potential future developments in and applications of statistical 3D and 4D shape models.},
booktitle = {Proceedings of the 1st International Workshop on Multimedia Computing for Health and Medicine},
pages = {5–6},
numpages = {2},
keywords = {differential geometry, elastic shape analysis, generative ai, geometry, spatio-temporal shape analysis, topology, tree-shaped objects},
location = {Melbourne VIC, Australia},
series = {MCHM'24}
}

@article{10.1145/3663759,
author = {Paproki, Anthony and Salvado, Olivier and Fookes, Clinton},
title = {Synthetic Data for Deep Learning in Computer Vision &amp; Medical Imaging: A Means to Reduce Data Bias},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3663759},
doi = {10.1145/3663759},
abstract = {Deep-learning (DL) performs well in computer-vision and medical-imaging automated decision-making applications. A bottleneck of DL stems from the large amount of labelled data required to train accurate models that generalise well. Data scarcity and imbalance are common problems in imaging applications that can lead DL models towards biased decision making. A solution to this problem is synthetic data. Synthetic data is an inexpensive substitute to real data for improved accuracy and generalisability of DL models. This survey reviews the recent methods published in relation to the creation and use of synthetic data for computer-vision and medical-imaging DL applications. The focus will be on applications that utilised synthetic data to improve DL models by either incorporating an increased diversity of data that is difficult to obtain in real life, or by reducing a bias caused by class imbalance. Computer-graphics software and generative networks are the most popular data generation techniques encountered in the literature. We highlight their suitability for typical computer-vision and medical-imaging applications, and present promising avenues for research to overcome their computational and theoretical limitations.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {271},
numpages = {37},
keywords = {Synthetic data, machine learning, generative adversarial network, deep learning}
}

@inproceedings{10.1145/3636534.3694734,
author = {Peng, Ruo and Wu, Chenye},
title = {CCCG: Self-supervised Color Constancy with Collaborative Generative Network},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3694734},
doi = {10.1145/3636534.3694734},
abstract = {Color constancy provides stable color features for high-level computer vision tasks such as target recognition and autonomous driving. Existing deep learning-based color constancy algorithms using convolutional neural networks remove the illumination and obtain images under standard illumination. However, these methods suffer from insufficient training data and poor robustness in complex scenes. To address these issues, we propose a new paradigm: self-supervised color constancy with a collaborative generative network (CCCG). CCCG transforms the illumination estimation problem into a generation problem, reducing the solution space and enhancing algorithm robustness in complex scenes. Additionally, CCCG employs a self-supervised network structure, reducing dependence on light source label data. CCCG comprises two network structures: the Filter Network (FN) and the Illumination Network (IN). FN extracts features from the image and generates an image under standard illumination. IN incorporates the extracted physical light source information into the output results of FN and verifies the generated image. Experimental results on the Gehler-Shi and NUS-8 datasets show that CCCG outperforms current color constancy methods across various evaluation metrics and can be applied to other computer vision tasks requiring color constancy preprocessing.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {2055–2060},
numpages = {6},
keywords = {color constancy, self-supervised, collaborative generative, image restoration},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@article{10.1145/3689636,
author = {Constantin, Mihai Gabriel and Stanciu, Dan-Cristian and \c{S}tefan, Liviu-Daniel and Dogariu, Mihai and Mih\u{a}ilescu, Dan and Ciobanu, George and Bergeron, Matt and Liu, Winston and Belov, Konstantin and Radu, Octavian and Ionescu, Bogdan},
title = {Exploring Generative Adversarial Networks for Augmenting Network Intrusion Detection Tasks},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3689636},
doi = {10.1145/3689636},
abstract = {The advent of generative networks and their adoption in numerous domains and communities have led to a wave of innovation and breakthroughs in AI and machine learning. Generative Adversarial Networks (GANs) have expanded the scope of what is possible with machine learning, allowing for new applications in areas such as computer vision, natural language processing, and creative AI. GANs, in particular, have been used for a wide range of tasks, including image and video generation, data augmentation, style transfer, and anomaly detection. They have also been used for medical imaging and drug discovery, where they can generate synthetic data to augment small datasets, reduce the need for expensive experiments, and lower the number of real patients that must be included in medical trials. Given these developments, we propose using the power of GANs to create and augment flow-based network traffic datasets. We evaluate a series of GAN architectures, including Wasserstein, conditional, energy-based, gradient penalty, and LSTM-GANs. We evaluate their performance on a set of flow-based network traffic data collected from 16 subjects who used their computers for home, work, and study purposes. The performance of these GAN architectures is described according to metrics that involve networking principles, data distribution among a collection of flows, and temporal data distribution. Given the tendency of network intrusion detection datasets to have a very imbalanced data distribution, i.e., a large number of samples in the “normal traffic” category and a comparatively low number of samples assigned to the “intrusion” categories, we test our GANs by augmenting the intrusion data and checking whether this helps intrusion detection neural networks in their task. We publish the resulting UPBFlow dataset and code on GitHub.1},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = dec,
articleno = {16},
numpages = {19},
keywords = {generative networks, network traffic, network flow}
}

@inproceedings{10.1145/3660515.3661329,
author = {Gaspar-Figueiredo, Daniel and Fern\'{a}ndez-Diego, Marta and Nuredini, Ruben and Abrahao, Silvia and Insfran, Emilio},
title = {Reinforcement Learning-Based Framework for the Intelligent Adaptation of User Interfaces},
year = {2024},
isbn = {9798400706516},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660515.3661329},
doi = {10.1145/3660515.3661329},
abstract = {Adapting the user interface (UI) of software systems to meet the needs and preferences of users is a complex task. The main challenge is to provide the appropriate adaptations at the appropriate time to offer value to end-users. Recent advances in Machine Learning (ML) techniques may provide effective means to support the adaptation process. In this paper, we instantiate a reference framework for Intelligent User Interface Adaptation by using Reinforcement Learning (RL) as the ML component to adapt user interfaces and ultimately improving the overall User Experience (UX). By using RL, the system is able to learn from past adaptations to improve the decision-making capabilities. Moreover, assessing the success of such adaptations remains a challenge. To overcome this issue, we propose to use predictive Human-Computer Interaction (HCI) models to evaluate the outcome of each action (i.e., adaptations) performed by the RL agent. In addition, we present an implementation of the instantiated framework, which is an extension of OpenAI Gym, that serves as a toolkit for developing and comparing RL algorithms. This Gym environment is highly configurable and extensible to other UI adaptation contexts. The evaluation results show that our RL-based framework can successfully train RL agents able to learn how to adapt UIs in a specific context to maximize the user engagement by using an HCI model as rewards predictor.},
booktitle = {Companion Proceedings of the 16th ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {40–48},
numpages = {9},
keywords = {Adaptive User Interfaces, Human-Computer Interaction, Reinforcement Learning},
location = {Cagliari, Italy},
series = {EICS '24 Companion}
}

@article{10.1145/3686990,
author = {Fang, Zihan and Huang, Yu},
title = {"Math is a pain!": Understanding challenges and needs of the Machine Learning community on Stack Overflow},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686990},
doi = {10.1145/3686990},
abstract = {Stack Overflow (SO) is a widely recognized online question-and-answer platform for programming, which has also fostered a substantial community dedicated to machine learning (ML), providing a space for both novices and experts to exchange ideas and find solutions to ML-related problems. However, as a relative minority of this online programming platform, research has demonstrated lower engagement in the ML community, but it remains largely unexplored to understand what hinders the engagement and contribution from ML users' perspectives. This paper presents an empirical study based on 22 hours of semi-structured interviews and 131 survey responses with users on SO and reveals the key factors that may lead to the lower response rate and extended waiting time for ML questions on SO, which includes the unique quality requirement for posting ML questions, the discrepancy between time invested and benefits gained, the dispersed nature of the ML community across various platforms and the desired improvement for SO. Moreover, the qualitative study reveals a declining friendliness in SO's culture over time; the subsequent quantitative study corroborates that newcomers frequently encounter stress when posting and answering ML questions, even though this stress diminishes with increased experience. Additionally, we also explored the potential influence of generative AI tools (e.g., ChatGPT) on online question-and-answer platforms, specifically focusing on ML Q&amp;A. We hope the results of this study can pave the way for enhancing the experience of ML users on online platforms, ultimately facilitating improved knowledge exchange and collaboration within the ML domain.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {451},
numpages = {35},
keywords = {chatgpt, machine learning, stack overflow}
}

@inproceedings{10.1145/3589335.3641306,
author = {Mao, Haitao and Zhao, Jianan and He, Xiaoxin and Chen, Zhikai and Huang, Qian and Zhu, Zhaocheng and Tang, Jian and Bronstein, Micheal and Bresson, Xavier and Hooi, Bryan and Zhang, Haiyang and Tang, Xianfeng and Chen, Luo and Tang, Jiliang},
title = {The 1st International Workshop on Graph Foundation Models (GFM)},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641306},
doi = {10.1145/3589335.3641306},
abstract = {Foundation models such as GPT-4 for natural language processing (NLP), Flamingo for computer vision (CV), have set new benchmarks in AI by delivering state-of-the-art results across various tasks with minimal task-specific data. Despite their success, the application of these models to the graph domain is challenging due to the relational nature of graph-structured data. To address this gap, we propose the Graph Foundation Model (GFM) Workshop, the first workshop for GFMs, dedicated to exploring the adaptation and development of foundation models specifically designed for graph data. The GFM workshop focuses on two critical questions: (1) How can the underlying capabilities of existing foundation models be effectively applied to graph data? (2) What foundational principles should guide the creation of models tailored to the graph domain? Through a curated set of panel sections, keynote talks, and paper presentations, our workshop intends to catalyze innovative approaches and theoretical frameworks for Graph Foundation Models (GFMs). We target a broad audience, encompassing researchers, practitioners, and students, and aim to lay the groundwork for the next wave of breakthroughs in integrating graph data with foundation models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1789–1792},
numpages = {4},
keywords = {data mining, foundation model, graph machine learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3689491,
title = {SPLASH Companion '24: Companion Proceedings of the 2024 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
year = {2024},
isbn = {9798400712142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is my great pleasure to welcome you to the 39th ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, being held in the vibrant city of Pasadena, California, from October 20th to October 25th, 2024. Nestled in beautiful southern California, Pasadena offers a unique blend of innovation, culture, and charm, providing the perfect backdrop for this year’s SPLASH conference.SPLASH 2024 continues to be a premier forum for discussing all aspects of software development. This year’s program is as diverse and dynamic as ever, featuring the OOPSLA conference, Onward! Papers and Onward! Essays, SPLASH-E, and our popular student-focused events including the Doctoral Symposium, Student Research Competition, and Programming Language Mentoring Workshop. We are also excited to host a revival of REBASE, a day of talks and discussion to connect industry and academia. Additionally, attendees will have the opportunity to engage with an exciting collection of co-hosted conferences, the Static Analysis Symposium (SAS), International Conference on Generative Programming: Concepts &amp; Experiences (GPCE), and Software Language Engineering (SLE). SPLASH 2024 is also proud to host ten exciting workshops: HATRA, IWACO, JENSFEST, LIVE, NSAD, PAINT, ProLaLa, UNSOUND, VIVEKFEST, and VMIL.},
location = {Pasadena, CA, USA}
}

@inproceedings{10.1145/3613905.3643977,
author = {Elagroudy, Passant and Li, Jie and V\"{a}\"{a}n\"{a}nen, Kaisa and Lukowicz, Paul and Ishii, Hiroshi and Mackay, Wendy E. and Churchill, Elizabeth F and Peters, Anicia and Oulasvirta, Antti and Prada, Rui and Diening, Alexandra and Barbareschi, Giulia and Gruenerbl, Agnes and Kawaguchi, Midori and El Ali, Abdallah and Draxler, Fiona and Welsch, Robin and Schmidt, Albrecht},
title = {Transforming HCI Research Cycles using Generative AI and “Large Whatever Models” (LWMs)},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3643977},
doi = {10.1145/3613905.3643977},
abstract = {This Special Interest Group (SIG) explores the transformative impact of Generative Artificial Intelligence (GenAI) on Human-Computer Interaction (HCI) research processes. The theme here is to answer “question zero”: when to use and when to refrain from using AI tools during the research cycle? The discussion is guided by five research phases commonly used in HCI: research planning, prototyping, data collection, analysis and synthesis, and dissemination and communication. We investigate how GenAI accelerates project cycles, enhances reproducibility, and influences inclusivity in research. We also address the challenging ethical considerations about the ownership of generated content. Our goal is to build a community of HCI enthusiasts to harness the early advantages of the recent groundbreaking technology and foresee challenges arising from its prevalence in the scientific community.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {5},
keywords = {ChatGPT, Generative AI, HCI research, Large Language Models, Large Multimodal Models, research processes, science},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3664647.3680591,
author = {Zhang, Feifei and Qu, Sijia and Shi, Fan and Xu, Changsheng},
title = {Overcoming the Pitfalls of Vision-Language Model for Image-Text Retrieval},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680591},
doi = {10.1145/3664647.3680591},
abstract = {This work tackles the persistent challenge of image-text retrieval, a key problem at the intersection of computer vision and natural language processing. Despite significant advancements facilitated by large-scale Contrastive Language-Image Pretraining (CLIP) models, we found that existing methods fall short in bridging the fine-grained semantic gap between visual and textual representations. To address the above pitfalls, we propose a model called Local and Generative-driven Modality Gap Correction (LG-MGC), which devotes to simultaneously enhancing representation learning and alleviating the modality gap in cross-modal retrieval. The proposed model consists of two main components: a local-driven semantic completion module, which complements specific local context information that is overlooked by traditional models within global features, and a generative-driven semantic translation module, which leverages generated features as a bridge to mitigate modality gap. Our model not only tackles the granularity of semantic correspondence and improves the performance of existing methods without requiring additional trainable parameters, but is also designed to be plug-and-play, allowing for easy integration into existing retrieval models without altering their architectures. Extensive experiments demonstrate the effectiveness of LG-MGC by achieving consistent state-of-the-art performance over strong baselines.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2350–2359},
numpages = {10},
keywords = {clip, computer vision, image-text retrieval},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3672758.3672763,
author = {Peng, Li and Fu, Bihan},
title = {Development and Research of Generative Animation Based on AIGC},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672758.3672763},
doi = {10.1145/3672758.3672763},
abstract = {AIGC is the automatic generation of relevant content from a large number of models and databases based on the input of relevant instructions. This paper mainly discusses the development of artificial intelligence generation technology in animation in the form of images. With the rapid development of artificial intelligence technology, generative animation content has become an important way of animation production and production in modern society. Artificial intelligence-based generative animation is taking up an increasing proportion of the film, game, advertising and other industries, AIGC has been rapidly developed by virtue of its lower production cost and higher production efficiency, which constantly impacts the development of the animation industry and attracts the widespread attention of animation creators. This paper analyses the Generative Adversarial Network and Diffusion Model through the deep learning principle of AIGC technology, and explores the important impact of AIGC technology on the form of generative animation. Using computer discipline thinking to analyse the type of AIGC model for animation creation, and according to the model simulation results of AIGC technology used in generative animation production of technology, market aspects of its development prospects are summarised.},
booktitle = {Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {22–28},
numpages = {7},
location = {Xi' an, China},
series = {CAICE '24}
}

@inproceedings{10.1145/3643834.3661581,
author = {Chen, Qiaoyi and Liu, Siyu and Huang, Kaihui and Wang, Xingbo and Ma, Xiaojuan and Zhu, Junkai and Peng, Zhenhui},
title = {RetAssist: Facilitating Vocabulary Learners with Generative Images in Story Retelling Practices},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661581},
doi = {10.1145/3643834.3661581},
abstract = {Reading and repeatedly retelling a short story is a common and effective approach to learning the meanings and usages of target words. However, learners often struggle with comprehending, recalling, and retelling the story contexts of these target words. Inspired by the Cognitive Theory of Multimedia Learning, we propose a computational workflow to generate relevant images paired with stories. Based on the workflow, we work with learners and teachers to iteratively design an interactive vocabulary learning system named RetAssist. It can generate sentence-level images of a story to facilitate the understanding and recall of the target words in the story retelling practices. Our within-subjects study (N=24) shows that compared to a baseline system without generative images, RetAssist significantly improves learners’ fluency in expressing with target words. Participants also feel that RetAssist eases their learning workload and is more useful. We discuss insights into leveraging text-to-image generative models to support learning tasks.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2019–2036},
numpages = {18},
keywords = {Vocabulary learning, image generation, story retelling},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3649165.3703622,
author = {Alshaigy, Bedour and Grande, Virginia and Kiesler, Natalie and Settle, Amber},
title = {How Do You Solve A Problem Like Recruitment? On The Hiring and Retention of Computing Academics},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3703622},
doi = {10.1145/3649165.3703622},
abstract = {This paper critically examines persistent inequities in existing computing faculty hiring and retention practices, which gravely impact computing educators from marginalized groups. Throughout these processes, applicants fight against multiple systemic barriers, including but not limited to, biased job ads and discriminatory interview practices. The increasing use of generative AI tools to aid in tasks connected to the hiring process, such as writing recommendation letters, exacerbates these biases. The inequities persist despite global initiatives and legal mandates and serve as a direct contradiction to widespread institutional commitments to diversity and inclusion. By building on literature and the lived experiences of the SIGCSE community represented in a recent Technical Symposium session, we raise concerns about the different stages of this process, highlighting the importance of clear expectations and adequate support. The paper concludes with a call to align hiring practices with inclusive institutional values, requiring the academic community to reflect on and revise hiring policies for a more equitable future. It is of paramount importance to address the role of these practices in the erosion of marginalized communities from the computing education community, a marginalization that occurs in many different contexts and negatively impacts everyone involved.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {263–266},
numpages = {4},
keywords = {CS academics, recruitment, retention},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3656156.3665122,
author = {Toka, Mert},
title = {Crafting the Computational: Artistic Production, Generative Systems, and Digital Fabrication},
year = {2024},
isbn = {9798400706325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656156.3665122},
doi = {10.1145/3656156.3665122},
abstract = {Digital artists use generative systems for negotiating agency and control with autonomous processes that display emergent and self-organizing behavior. Practitioners have started using these systems in material fabrication for rich sensory opportunities; however, translating digital generative designs into the physical involves significant knowledge of programming, complex workflows, physical constraints, and material properties. I aim to develop computational systems bridging generative art methods with digital fabrication techniques to support artistic practices. I seek to develop digital generative workflows that account for the complexities of real-world materials through collaborations with professional practitioners. My thesis contributes practice-based research into evolutionary algorithms for real-time digital form generation, a manual-computational workflow for artistic production that moves between digital and material pipelines, and a collaborative practice-driven software development methodology for digital fabrication. These contributions inform my next project aiming to bridge the gap between digital and physical workflows, bringing computational generative design closer to material fabrication.},
booktitle = {Companion Publication of the 2024 ACM Designing Interactive Systems Conference},
pages = {24–29},
numpages = {6},
keywords = {Artificial Life, Artistic Practice, Computational Design, Fabrication and Material Workflows, Generative Systems},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24 Companion}
}

@article{10.1145/3688569,
author = {Wang, Anqi and Dong, Jiahua and Lee, Lik-Hang and Shen, Jiachuan and Hui, Pan},
title = {A Survey on Deep Learning for Design and Generation of Virtual Architecture},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3688569},
doi = {10.1145/3688569},
abstract = {Three-dimensional (3D) shape generation techniques leveraging deep learning have garnered significant interest from both computer vision and architectural design communities, promising to enrich the content in the virtual environment. However, research on virtual architectural design remains limited, particularly regarding designer-AI collaboration and deep learning-assisted design. In our survey, we reviewed 149 related articles (81.2% of articles published between 2019 and 2023) covering architectural design, 3D shape techniques, and virtual environments. Through scrutinizing the literature, we first identify the principles of virtual architecture and illuminate its current production challenges, including datasets, multimodality, design intuition, and generative frameworks. We then introduce the latest approaches to designing and generating virtual buildings leveraging 3D shape generation and summarize four characteristics of various approaches to virtual architecture. Based on our analysis, we expound on four research agendas, including agency, communication, user consideration, and integrating tools. Additionally, we highlight four important enablers of ubiquitous interaction with immersive systems in deep learning-assisted architectural generation. Our work contributes to fostering understanding between designers and deep learning techniques, broadening access to designer-AI collaboration. We advocate for interdisciplinary efforts to address this timely research topic, facilitating content designing and generation in the virtual environment.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {29},
numpages = {41},
keywords = {AI-assisted architectural design, 3D shape generation, virtual architecture, designer-AI collaboration, AIGC}
}

@inproceedings{10.1145/3628096.3629079,
author = {Sharma, Sumita and White, Edward and Kinnula, Marianne and Iivari, Netta and Monga, Charu},
title = {Age against the machine: Exploring ethical AI design and use by, with, and for children},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3629079},
doi = {10.1145/3628096.3629079},
abstract = {As AI-based applications permeate our everyday lives, their impact on children and their futures requires critically examination. While several global and national policy frameworks on Children and AI are being developed, there is still little discussion with children on the limitations, inherent biases, and lack of diversity in current design and development of AI-based applications. Further, as ethical aspects with regards to AI design and use come to the forefront, AI literacy for children becomes imperative. As part of our projects, we have been exploring approaches towards critical AI literacy for children – from hands-on design and making workshops reimagining the future of schooling, to activities with generative AI. We also conduct workshops with Child-Computer Interaction (CCI) experts, and those interested in CCI, to evaluate and extend our methods repertoire through our researchers’ toolbox for the future workshop series in India, Finland, and Denmark (https://interact.oulu.fi/researcherstoolbox). As a part of this workshop series, we propose a workshop at the AfriCHI 2023 conference welcoming conference participants interested critical AI literacy, children and AI, speculative and critical design, and ethical AI.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {313–315},
numpages = {3},
keywords = {Children and Artificial Intelligence, Design Fiction, Ethics, Inclusion},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@inproceedings{10.1145/3664647.3680896,
author = {Pan, Qihe and Zhao, Zhen and Wang, Zicheng and Long, Sifan and Wu, Yiming and Ji, Wei and Liang, Haoran and Liang, Ronghua},
title = {Towards Small Object Editing: A Benchmark Dataset and A Training-Free Approach},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680896},
doi = {10.1145/3664647.3680896},
abstract = {A plethora of text-guided image editing methods has recently been developed by leveraging the impressive capabilities of large-scale diffusion-based generative models especially Stable Diffusion. Despite the success of diffusion models in producing high-quality images, their application to small object generation has been limited due to difficulties in aligning cross-modal attention maps between text and these objects. Our approach offers a training-free method that significantly mitigates this alignment issue with local and global attention guidance, enhancing the model's ability to accurately render small objects in accordance with textual descriptions. We detail the methodology in our approach, emphasizing its divergence from traditional generation techniques and highlighting its advantages. What's more important is that we also provide SOEBench (Small Object Editing), a standardized benchmark for quantitatively evaluating text-based small object generation collected from MSCOCO[22] and OpenImage[18]. Preliminary results demonstrate the effectiveness of our method, showing marked improvements in the fidelity and accuracy of small object generation compared to existing models. This advancement not only contributes to the field of AI and computer vision but also opens up new possibilities for applications in various industries where precise image generation is critical.We will release our dataset on our project page: https://soebench.github.io/},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3257–3265},
numpages = {9},
keywords = {benchmark, cross-attention guidance, small object editing},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3633458,
author = {Liang, Tung-Che and Chang, Yi-Chen and Zhong, Zhanwei and Bigdeli, Yaas and Ho, Tsung-Yi and Chakrabarty, Krishnendu and Fair, Richard},
title = {Dynamic Adaptation Using Deep Reinforcement Learning for Digital Microfluidic Biochips},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1084-4309},
url = {https://doi.org/10.1145/3633458},
doi = {10.1145/3633458},
abstract = {We describe an exciting new application domain for deep reinforcement learning (RL): droplet routing on digital microfluidic biochips (DMFBs). A DMFB consists of a two-dimensional electrode array, and it manipulates droplets of liquid to automatically execute biochemical protocols for clinical chemistry. However, a major problem with DMFBs is that electrodes can degrade over time. The transportation of droplet transportation over these degraded electrodes can fail, thereby adversely impacting the integrity of the bioassay outcome. We demonstrated that the formulation of droplet transportation as an RL problem enables the training of deep neural network policies that can adapt to the underlying health conditions of electrodes and ensure reliable fluidic operations. We describe an RL-based droplet routing solution that can be used for various sizes of DMFBs. We highlight the reliable execution of an epigenetic bioassay with the RL droplet router on a fabricated DMFB. We show that the use of the RL approach on a simple micro-computer (Raspberry Pi 4) leads to acceptable performance for time-critical bioassays. We present a simulation environment based on the OpenAI Gym Interface for RL-guided droplet routing problems on DMFBs. We present results on our study of electrode degradation using fabricated DMFBs. The study supports the degradation model used in the simulator.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = jan,
articleno = {24},
numpages = {24},
keywords = {Biochips, Biological system modeling, Real-time systems, Reinforcement learning}
}

@inproceedings{10.1145/3652037.3663942,
author = {Joaa, AFM Mohimenul and Majumder, Prattoy and Sadeque, Farig},
title = {Curious Learner: A Neuro-Symbolic Approach for Function Execution via Natural Language},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663942},
doi = {10.1145/3652037.3663942},
abstract = {Generative models possess immense potential, but their ability to perform complex calculations is limited by the need to memorize vast amounts of data, leading to computational inefficiencies. Leveraging tools like the Arithmetic Logic Unit using symbolic functions offers a more efficient alternative, enabling faster responses, smaller model sizes, and improved accuracy. We propose a neuro-symbolic generative model to empower natural language models with task execution abilities by integrating functional programming principles. Experiments on our scoped four translation tasks using 98 mathematical functions demonstrated rapid convergence and minimal training time requirements. The model achieved an average accuracy, BLEU score, and perplexity score of 0.85, 0.84, and 5.9, respectively, after training on a T4 GPU for several hours. This neuro-symbolic Language Model shows significant potential for various applications, such as NLP-based command line tools, customer service automation, service discovery automation, project code automation, and natural language-based operating systems.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {392–399},
numpages = {8},
keywords = {Curious Learner, Customer Service Automation, Foundational Model, Generative Model, Large Language Model Architecture, Natural Language Processing, Neuro-Symbolic Programming, Service Discovery Automation, Task Executor, Transformer},
location = {Crete, Greece},
series = {PETRA '24}
}

@article{10.5555/3722479.3722530,
author = {Kollapally, Navya Martin and Geller, James and Morreale, Patricia and Kwak, Daehan},
title = {An Ontology for Social Determinants of Education (SDoEd) Based on Human-AI Collaborative Approach},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The use of computational ontologies is well-established in the field of Medical Informatics. The topic of Social Determinants of Health (SDoH) has also received extensive attention. Work at the intersection of ontologies and SDoH has been published. However, a standardized framework for Social Determinants of Education (SDoEd) is lacking. In this paper, we are closing the gap by introducing an SDoEd ontology for creating a precise conceptualization of the interplay between life circumstances of students and their possible educational achievements. The ontology was developed utilizing suggestions from ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The first version of developed ontology was evaluated by human experts in the field of education and validated using standard ontology evaluation software. This version of the SDoEd ontology contains 231 domain concepts, 10 object properties, and 24 data properties.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {191–203},
numpages = {13}
}

@inproceedings{10.1145/3627703.3650088,
author = {Chen, Bing-Jyue and Waiwitlikhit, Suppakit and Stoica, Ion and Kang, Daniel},
title = {ZKML: An Optimizing System for ML Inference in Zero-Knowledge Proofs},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627703.3650088},
doi = {10.1145/3627703.3650088},
abstract = {Machine learning (ML) is increasingly used behind closed systems and APIs to make important decisions. For example, social media uses ML-based recommendation algorithms to decide what to show users, and millions of people pay to use ChatGPT for information every day. Because ML is deployed behind these closed systems, there are increasing calls for transparency, such as releasing model weights. However, these service providers have legitimate reasons not to release this information, including for privacy and trade secrets. To bridge this gap, recent work has proposed using zero-knowledge proofs (specifically a form called ZK-SNARKs) for certifying computation with private models but has only been applied to unrealistically small models.In this work, we present the first framework, ZKML, to produce ZK-SNARKs for realistic ML models, including state-of-the-art vision models, a distilled GPT-2, and the ML model powering Twitter's recommendations. We accomplish this by designing an optimizing compiler from TensorFlow to circuits in the halo2 ZK-SNARK proving system. There are many equivalent ways to implement the same operations within ZK-SNARK circuits, and these design choices can affect performance by 24\texttimes{}. To efficiently compile ML models, ZKML contains two parts: gadgets (efficient constraints for low-level operations) and an optimizer to decide how to lay out the gadgets within a circuit. Combined, these optimizations enable proving on a wider range of models, faster proving, faster verification, and smaller proofs compared to prior work.},
booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
pages = {560–574},
numpages = {15},
location = {Athens, Greece},
series = {EuroSys '24}
}

@inproceedings{10.1145/3675888.3676033,
author = {Pramod, Dhanya and Patil, Kanchan Pranay},
title = {Generative AI for Elderly Well-being through the Computer as Social Actor Paradigm},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676033},
doi = {10.1145/3675888.3676033},
abstract = {Artificial intelligence and machine learning (AI/ML) technologies like generative AI solutions are proliferating in the real-world healthcare sector. The purpose of this research is to investigate social norms, expectations, and standards of the elderly population for improving trust relationships while interacting with generative AI. The study is based on the CASA paradigm to gain a better understanding of the trust dynamics in human-computer communication to improve the adoption of GAI for elders' health and well-being. We validated the conceptual model with empirical data from 287 elderly users collected through an online and offline survey tool. Quantitative responses received were analysed using structural equation modeling. The study highlights how multimodal interaction, empathy, personalization, augmentation, bias stereotyping, and privacy and security affect the extent to which elderly consumers perceive GAI as trustworthy. Findings indicate that multimodal interaction, personalization, augmentation, and bias stereotyping significantly influenced the trust relationship between the elderly population and GAI. However, empathy privacy, and security were found to be insignificant in trust relationships. Further trust relationships significantly impacted GAI usage. The research provides strong theoretical and practical implications as all the stakeholders like healthcare professionals, patients/users, caregivers, and technology developers can be involved in building applications that cater to diverse needs and promote positive social interactions that can enhance GAI trust and usage.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {65–72},
numpages = {8},
location = {Noida, India},
series = {IC3-2024}
}

@article{10.1145/3631430,
author = {Rahman, Wasifur and Abdelkader, Abdelrahman and Lee, Sangwu and Yang, Phillip and Islam, Md Saiful and Adnan, Tariq and Hasan, Masum and Wagner, Ellen and Park, Sooyong and Dorsey, E. Ray and Schwartz, Catherine and Jaffe, Karen and Hoque, Ehsan},
title = {A User-Centered Framework to Empower People with Parkinson's Disease},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631430},
doi = {10.1145/3631430},
abstract = {We present a user-centric validation of a teleneurology platform, assessing its effectiveness in conveying screening information, facilitating user queries, and offering resources to enhance user empowerment. This validation process is implemented in the setting of Parkinson's disease (PD), in collaboration with a neurology department of a major medical center in the USA. Our intention is that with this platform, anyone globally with a webcam and microphone-equipped computer can carry out a series of speech, motor, and facial mimicry tasks. Our validation method demonstrates to users a mock PD risk assessment and provides access to relevant resources, including a chatbot driven by GPT, locations of local neurologists, and actionable and scientifically-backed PD prevention and management recommendations. We share findings from 91 participants (48 with PD, 43 without) aimed at evaluating the user experience and collecting feedback. Our framework was rated positively by 80.85% (standard deviation ± 8.92%) of the participants, and it achieved an above-average 70.42 (standard deviation ± 13.85) System-Usability-Scale (SUS) score. We also conducted a thematic analysis of open-ended feedback to further inform our future work. When given the option to ask any questions to the chatbot, participants typically asked for information about neurologists, screening results, and the community support group. We also provide a roadmap of how the knowledge generated in this paper can be generalized to screening frameworks for other diseases through designing appropriate recording environments, appropriate tasks, and tailored user-interfaces.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {175},
numpages = {29},
keywords = {End-to-end framework, Framework Evaluation, Parkinson's Disease}
}

@article{10.1145/3701701.3701703,
author = {Zhang, Qiyang and Xu, Mengwei},
title = {Benchmarking Mobile Deep Learning Software},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {3},
issn = {2375-0529},
url = {https://doi.org/10.1145/3701701.3701703},
doi = {10.1145/3701701.3701703},
abstract = {Deploying deep learning (DL) on mobile devices has become increasingly prevalent. DL software libraries are crucial for efficient on-device inference, alongside algorithms and hardware. However, there has been limited understanding on the performance of modern DL libraries. We fill this gap by benchmarking 6 popular DL libraries and 15 diverse models across 10 mobile devices, which reveal an unsatisfactory landscape of mobile DL: their performance is highly disparate and fragmented across different models and hardware, and the impacts often surpass algorithm or hardware optimizations, such as model quantization and GPU/NPU-based computing. Finally, we provide practical implications for stakeholders in the DL library ecosystem, and envision a more ambitious picture of future mobile AI landscape in the LLM era.},
journal = {GetMobile: Mobile Comp. and Comm.},
month = oct,
pages = {5–8},
numpages = {4}
}

@inproceedings{10.1145/3698038.3698510,
author = {Yang, Yanning and Du, Dong and Song, Haitao and Xia, Yubin},
title = {On-demand and Parallel Checkpoint/Restore for GPU Applications},
year = {2024},
isbn = {9798400712869},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698038.3698510},
doi = {10.1145/3698038.3698510},
abstract = {Leveraging serverless computing for cloud-based machine learning services is on the rise, promising cost-efficiency and flexibility are crucial for ML applications relying on high-performance GPUs and substantial memory. However, despite modern serverless platforms handling diverse devices like GPUs seamlessly on a pay-as-you-go basis, a longstanding challenge remains: startup latency, a well-studied issue when serverless is CPU-centric. For example, initializing GPU apps with minor GPU models, like MobileNet, demands several seconds. For more intricate models such as GPT-2, startup latency can escalate to around 10 seconds, vastly overshadowing the short computation time for GPU-based inference. Prior solutions tailored for CPU serverless setups, like fork() and Checkpoint/Restore, cannot be directly and effectively applied due to differences between CPUs and GPUs.This paper presents gCROP (GPU Checkpoint/Restore made On-demand and Parallel), the first GPU runtime that achieves &lt;100ms startup latency for GPU apps with up to 774 million parameters (3.1GB GPT-2-Large model). The key insight behind gCROP is to selectively restore essential states on demand and in parallel during boot from a prepared checkpoint image. To this end, gCROP first introduces a global service, GPU Restore Server, which can break the existing barrier between restore stages and achieve parallel restore. Besides, gCROP leverages both CPU and GPU page faults, and can on-demand restore both CPU and GPU data with profile-guided order to mitigate costs caused by faults. Moreover, gCROP designs a multi-checkpoint mechanism to increase the common contents among checkpoint images and utilizes deduplication to reduce storage costs. Implementation and evaluations on AMD GPUs show significant improvement in startup latency, 6.4x-24.7x compared with booting from scratch and 3.9x-23.5x over the state-of-the-art method (CRIU).},
booktitle = {Proceedings of the 2024 ACM Symposium on Cloud Computing},
pages = {415–433},
numpages = {19},
keywords = {Checkpoint and Restore, Cloud Computing, GPUs, Startup Latency},
location = {Redmond, WA, USA},
series = {SoCC '24}
}

@inproceedings{10.1145/3650203.3663328,
author = {Dai, Timothy and Peters, Austin and Gelbach, Jonah B. and Engstrom, David Freeman and Kang, Daniel},
title = {tailwiz: Empowering Domain Experts with Easy-to-Use, Task-Specific Natural Language Processing Models},
year = {2024},
isbn = {9798400706110},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650203.3663328},
doi = {10.1145/3650203.3663328},
abstract = {Experts outside the field of machine learning (ML) are interested in using ML techniques to analyze their textual data, but they are inhibited by a lack of convenient natural language processing (NLP) tools. To address this issue, we present tailwiz, an easy-to-use Python tool, powered by supervised fine-tuning of NLP models. tailwiz caters to domain experts by abstracting away technical ML knowledge and running conveniently on personal computers, the preferred mode of computation among domain experts. We show that tailwiz outperforms domain experts' current textual analysis techniques on a majority of real-world tasks, up to a 384.8% F1 increase (46.18% absolute increase). tailwiz consistently outperforms GPT-3.5-Turbo on such tasks, showing the need for fine-tuned NLP models to perform domain-specific tasks that meet the analytical demands of domain experts.},
booktitle = {Proceedings of the Eighth Workshop on Data Management for End-to-End Machine Learning},
pages = {12–22},
numpages = {11},
location = {Santiago, AA, Chile},
series = {DEEM '24}
}

@inproceedings{10.1145/3675094.3678989,
author = {Janaka, Nuwan},
title = {Towards Intelligent Wearable Assistants},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678989},
doi = {10.1145/3675094.3678989},
abstract = {This summary outlines my research toward developing intelligent wearable assistants that provide personalized, context-aware computing assistance. Previous work explored information presentation using smart glasses, socially-aware interactions, and applications for learning, communication, and documentation. Current research aims to develop tools for interaction research, including data collection, multimodal evaluation metrics, and a platform for creating context-aware AI assistants. Future goals include extending assistants to physical spaces via telepresence, optimizing learning with generative AI, and investigating collaborative human-AI learning. Ultimately, this research seeks to redefine how humans receive seamless support through proactive, intelligent wearable assistants that comprehend users and environments, augmenting capabilities while reducing reliance on manual labor.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {618–621},
numpages = {4},
keywords = {ai assistance, augmented reality, context-aware system, hmd, interactions, interruptions, mr, notifications, smart glasses, wearable, xr},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@article{10.1145/3674500,
author = {De Sousa Ribeiro, Fabio and Duarte, Kevin and Everett, Miles and Leontidis, Georgios and Shah, Mubarak},
title = {Object-centric Learning with Capsule Networks: A Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3674500},
doi = {10.1145/3674500},
abstract = {Capsule networks emerged as a promising alternative to convolutional neural networks for learning object-centric representations. The idea is to explicitly model part-whole hierarchies by using groups of neurons called capsules to encode visual entities, then learn the relationships between these entities dynamically from data. However, a major hurdle for capsule network research has been the lack of a reliable point of reference for understanding their foundational ideas and motivations. This survey provides a comprehensive and critical overview of capsule networks, which aims to serve as a main point of reference going forward. To that end, we introduce the fundamental concepts and motivations behind capsule networks, such as equivariant inference. We then cover various technical advances in capsule routing algorithms as well as alternative geometric and generative formulations. We provide a detailed explanation of how capsule networks relate to the attention mechanism in Transformers and uncover non-trivial conceptual similarities between them in the context of object-centric representation learning. We also review the extensive applications of capsule networks in computer vision, video and motion, graph representation learning, natural language processing, medical imaging, and many others. To conclude, we provide an in-depth discussion highlighting promising directions for future work.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {291},
numpages = {291},
keywords = {Deep learning, capsule networks, deep neural networks, convolutional neural networks, transformers, routing-by-agreement, self-attention, representation learning, object-centric learning, generative models, computer vision}
}

@inproceedings{10.1145/3625549.3658685,
author = {Maurya, Avinash and Underwood, Robert and Rafique, M. Mustafa and Cappello, Franck and Nicolae, Bogdan},
title = {DataStates-LLM: Lazy Asynchronous Checkpointing for Large Language Models},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625549.3658685},
doi = {10.1145/3625549.3658685},
abstract = {LLMs have seen rapid adoption in all domains. They need to be trained on high-end high-performance computing (HPC) infrastructures and ingest massive amounts of input data. Unsurprisingly, at such a large scale, unexpected events (e.g., failures of components, instability of the software, undesirable learning patterns, etc.), are frequent and typically impact the training in a negative fashion. Thus, LLMs need to be checkpointed frequently so that they can be rolled back to a stable state and subsequently fine-tuned. However, given the large sizes of LLMs, a straightforward checkpointing solution that directly writes the model parameters and optimizer state to persistent storage (e.g., a parallel file system), incurs significant I/O overheads. To address this challenge, in this paper we study how to reduce the I/O overheads for enabling fast and scalable checkpointing for LLMs that can be applied at high frequency (up to the granularity of individual iterations) without significant impact on the training process. Specifically, we introduce a lazy asynchronous multi-level approach that takes advantage of the fact that the tensors making up the model and optimizer state shards remain immutable for extended periods of time, which makes it possible to copy their content in the background with minimal interference during the training process. We evaluate our approach at scales of up to 180 GPUs using different model sizes, parallelism settings, and checkpointing frequencies. The results show up to 48\texttimes{} faster checkpointing and 2.2\texttimes{} faster end-to-end training runtime compared with the state-of-art checkpointing approaches.},
booktitle = {Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {227–239},
numpages = {13},
keywords = {LLMs and transformers, scalable checkpointing, asynchronous multilevel checkpointing},
location = {Pisa, Italy},
series = {HPDC '24}
}

@inproceedings{10.1145/3673805.3673831,
author = {Geurts, Eva and Luyten, Kris},
title = {Anthropomorphic User Interfaces: Past, Present and Future of Anthropomorphic Aspects for Sustainable Digital Interface Design},
year = {2024},
isbn = {9798400718243},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673805.3673831},
doi = {10.1145/3673805.3673831},
abstract = {Interactions with computing systems and conversational services like ChatGPT are now integral to daily life. Surprisingly, user interfaces, the gateways to these systems, largely lack hedonic aspects. There is little attempt to intentionally make communication through user interfaces more like communication with humans. Anthropomorphic user interfaces, which integrate human-like attributes, can make interactions more pleasant and intuitive by allowing users to perceive and interact with interfaces as social actors. This enhances user experience, reduces the learning curve, and boosts adaption rates, but also holds the potential to make interfaces more sustainable, as they rely on familiar human interaction patterns. However, there is little consensus on how to build such interfaces. We conducted an extensive literature review on existing anthropomorphic user interfaces for software systems (past) to map and connect existing definitions and interpretations in an overarching taxonomy (present). The taxonomy and an accompanying web tool provide designers with a reference framework for analyzing and dissecting existing anthropomorphic user interfaces and designing new ones (future).},
booktitle = {Proceedings of the European Conference on Cognitive Ergonomics 2024},
articleno = {31},
numpages = {7},
keywords = {Anthropomorphism, Human-like interfaces, Taxonomy, User interface design},
location = {Paris, France},
series = {ECCE '24}
}

@inproceedings{10.1145/3673038.3673084,
author = {Li, Yinlong and Zhang, Hao and Cheng, Siyao and Liu, Jie},
title = {Federated Edge Learning with Blurred or Pseudo Data Sharing},
year = {2024},
isbn = {9798400717932},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673038.3673084},
doi = {10.1145/3673038.3673084},
abstract = {Edge servers and mobile devices are often assigned a large number of computing tasks. However, the data involved in computing tasks is often sensitive in terms of privacy. Our initial proposal is a federated edge learning strategy based on real-world scenarios, which combines blurred data or pseudo shared data. Federated learning is used to train device models with the aim of protecting privacy while enabling mobile devices to more effectively utilize data for decision-making. In the case of limited energy on mobile devices, we propose a federated edge learning algorithm with blurred data sharing. This algorithm can generate more accurate models by uploading partially blurred data. In order to further improve model accuracy and protect privacy of mobile devices, we propose a federated edge learning algorithm with pseudo data sharing based on dataset distillation and generative adversarial networks (GANs) in scenarios with relatively sufficient energy. The experimental results on several traditional datasets show that our proposed algorithms outperform traditional algorithms in terms of accuracy and energy consumption.},
booktitle = {Proceedings of the 53rd International Conference on Parallel Processing},
pages = {981–990},
numpages = {10},
keywords = {blurred data sharing, dataset distillation, energy optimization, federated edge learning},
location = {Gotland, Sweden},
series = {ICPP '24}
}

@article{10.5555/3665464.3665466,
author = {Juhnke, Kevin},
title = {Perspectives on Technology's Impact on Financial Services and the Future Workforce},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {A variety of experiences over a 30+ year career in the computing field at Principal Financial provides for a life-long journey with many fascinating insights. Mr. Juhnke will focus his thoughts on:• Business and market challenges in Financial Services and their impact on an organization's Technology Strategies• The impact key maturing and emerging technologies have on the Financial Services industry including...- Cloud Advancements- Generative AI- Blockchain- "Citizen" DevelopmentHe will conclude his thoughts with perspectives on areas where educators can help position students to be more marketable and impactful in financial services tech jobs after graduation.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {18–19},
numpages = {2}
}

@inproceedings{10.1145/3627673.3679122,
author = {Zhang, Bo-Wen and Yan, Yan and Li, Lin and Liu, Guang},
title = {InfinityMath: A Scalable Instruction Tuning Dataset in Programmatic Mathematical Reasoning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679122},
doi = {10.1145/3627673.3679122},
abstract = {Recent advancements in Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT) methods have greatly enhanced language models' mathematical reasoning capabilities, facilitating their integration into instruction tuning datasets with LLMs. However, existing methods for large-scale dataset creation require substantial seed data and high computational costs for data synthesis, posing significant challenges for scalability. We introduce InfinityMATH, a scalable instruction tuning dataset for programmatic mathematical reasoning. The construction pipeline emphasizes decoupling numbers from mathematical problems to synthesize number-independent programs, enabling efficient and flexible scaling while minimizing dependency on specific numerical values. Fine-tuning experiments with open-source language and code models, such as Llama2 and CodeLlama, demonstrate the practical benefits of InfinityMATH. These fine-tuned models, showed significant relative improvements on both in-domain and out-of-domain benchmarks, ranging from 184.7% to 514.3% on average. Additionally, these models exhibited high robustness on the GSM8K+ and MATH+ benchmarks, which are enhanced version of test sets with simply the number variations. InfinityMATH ensures that models are more versatile and effective across a broader range of mathematical problems. The data is available at https://huggingface.co/datasets/flagopen/InfinityMATH.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5405–5409},
numpages = {5},
keywords = {data augmentation, data synthesis, decoupled numeric dependencies, logical inconsistencies, programmatic mathematical reasoning},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3665869,
author = {Jia, Zhen and Zhang, Zhang and Wang, Liang and Tan, Tieniu},
title = {Human Image Generation: A Comprehensive Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3665869},
doi = {10.1145/3665869},
abstract = {Image and video synthesis has become a blooming topic in computer vision and machine learning communities along with the developments of deep generative models, due to its great academic and application value. Many researchers have been devoted to synthesizing high-fidelity human images as one of the most commonly seen object categories in daily lives, where a large number of studies are performed based on various models, task settings, and applications. Thus, it is necessary to give a comprehensive overview on these variant methods on human image generation. In this article, we divide human image generation techniques into three paradigms, i.e., data-driven methods, knowledge-guided methods, and hybrid methods. For each paradigm, the most representative models and the corresponding variants are presented, where the advantages and characteristics of different methods are summarized in terms of model architectures. The main public human image datasets and evaluation metrics in the literature are also summarized. Furthermore, due to the wide application potential, the typical downstream usages of synthesized human images are covered. Finally, the challenges and potential opportunities of human image generation are discussed to shed light on future research.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {279},
numpages = {39},
keywords = {Human image generation, human image rendering, person image generation, deep generative model, 3D human body model}
}

@article{10.1145/3656409,
author = {Huot, Mathieu and Ghavami, Matin and Lew, Alexander K. and Schaechtle, Ulrich and Freer, Cameron E. and Shelby, Zane and Rinard, Martin C. and Saad, Feras A. and Mansinghka, Vikash K.},
title = {GenSQL: A Probabilistic Programming System for Querying Generative Models of Database Tables},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {PLDI},
url = {https://doi.org/10.1145/3656409},
doi = {10.1145/3656409},
abstract = {This article presents GenSQL, a probabilistic programming system for querying probabilistic generative models of database tables. By augmenting SQL with only a few key primitives for querying probabilistic models, GenSQL enables complex Bayesian inference workflows to be concisely implemented. GenSQL’s query planner rests on a unified programmatic interface for interacting with probabilistic models of tabular data, which makes it possible to use models written in a variety of probabilistic programming languages that are tailored to specific workflows. Probabilistic models may be automatically learned via probabilistic program synthesis, hand-designed, or a combination of both. GenSQL is formalized using a novel type system and denotational semantics, which together enable us to establish proofs that precisely characterize its soundness guarantees. We evaluate our system on two case real-world studies—an anomaly detection in clinical trials and conditional synthetic data generation for a virtual wet lab—and show that GenSQL more accurately captures the complexity of the data as compared to common baselines. We also show that the declarative syntax in GenSQL is more concise and less error-prone as compared to several alternatives. Finally, GenSQL delivers a 1.7-6.8x speedup compared to its closest competitor on a representative benchmark set and runs in comparable time to hand-written code, in part due to its reusable optimizations and code specialization.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {179},
numpages = {26},
keywords = {AutoML, Bayesian data analysis, generative modeling, probabilistic programming, query language, semantics and correctness}
}

@article{10.1145/3652610,
author = {Zeng, Jinwei and Zhang, Guozhen and Yuan, Jian and Li, Yong and Jin, Depeng},
title = {Empowering Predictive Modeling by GAN-based Causal Information Learning},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3652610},
doi = {10.1145/3652610},
abstract = {Generally speaking, we can easily specify many causal relationships in the prediction tasks of ubiquitous computing, such as human activity prediction, mobility prediction, and health prediction. However, most of the existing methods in these fields failed to take advantage of this prior causal knowledge. They typically make predictions only based on correlations in the data, which hinders the prediction performance in real-world scenarios, because a distribution shift between training data and testing data generally exists. To fill in this gap, we proposed a Generative Adversarial Network (GAN)-based Causal Information Learning prediction framework, which can effectively leverage causal information to improve the prediction performance of existing ubiquitous computing deep learning models. Specifically, faced with a unique challenge that the treatment variable, referring to the intervention that influences the target in a causal relationship, is generally continuous in ubiquitous computing, the framework employs a representation learning approach with a GAN-based deep learning model. By projecting all variables except the treatment into a latent space, it effectively minimizes confounding bias and leverages the learned latent representation for accurate predictions. In this way, it deals with the continuous treatment challenge, and in the meantime, it can be easily integrated with existing deep learning models to lift their prediction performance in practical scenarios with causal information. Extensive experiments on two large-scale real-world datasets demonstrate its superior performance over multiple state-of-the-art baselines. We also propose an analytical framework together with extensive experiments to empirically show that our framework achieves better performance gain under two conditions: when the distribution differences between the training data and the testing data are more significant and when the treatment effects are larger. Overall, this work suggests that learning causal information is a promising way to improve the prediction performance of ubiquitous computing tasks. We open both our dataset and code1 and call for more research attention in this area.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {54},
numpages = {19},
keywords = {Prediction, predictive modeling, causal information learning, GAN}
}

@inproceedings{10.1111/cgf.15169,
author = {Hu, Lei and Zhang, Zihao and Ye, Yongjing and Xu, Yiwen and Xia, Shihong},
title = {Diffusion-based Human Motion Style Transfer with Semantic Guidance},
year = {2024},
publisher = {Eurographics Association},
address = {Goslar, DEU},
url = {https://doi.org/10.1111/cgf.15169},
doi = {10.1111/cgf.15169},
abstract = {3D Human motion style transfer is a fundamental problem in computer graphic and animation processing. Existing AdaIN-based methods necessitate datasets with balanced style distribution and content/style labels to train the clustered latent space. However, we may encounter a single unseen style example in practical scenarios, but not in sufficient quantity to constitute a style cluster for AdaIN-based methods. Therefore, in this paper, we propose a novel two-stage framework for few-shot style transfer learning based on the diffusion model. Specifically, in the first stage, we pre-train a diffusion-based text-to-motion model as a generative prior so that it can cope with various content motion inputs. In the second stage, based on the single style example, we fine-tune the pre-trained diffusion model in a few-shot manner to make it capable of style transfer. The key idea is regarding the reverse process of diffusion as a motion-style translation process since the motion styles can be viewed as special motion variations. During the fine-tuning for style transfer, a simple yet effective semantic-guided style transfer loss coordinated with style example reconstruction loss is introduced to supervise the style transfer in CLIP semantic space. The qualitative and quantitative evaluations demonstrate that our method can achieve state-of-the-art performance and has practical applications. The source code is available at https://github.com/hlcdyy/diffusion-based-motion-style-transfer.},
booktitle = {Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Computer Animation},
pages = {1–12},
numpages = {12},
location = {Montreal, Quebec, Canada},
series = {SCA '24}
}

@inproceedings{10.1145/3671151.3671184,
author = {Zhang, Qian and Li, Yingying},
title = {Fast-ECGAN: Towards More Efficient GAN Models},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671184},
doi = {10.1145/3671151.3671184},
abstract = {In this study, we introduce a groundbreaking approach by seamlessly integrating the Edge Guided Generative Adversarial Network enhanced with contrastive learning (ECGAN) into the Jittor computational framework, which is further empowered by our innovative Edge-Aware Spatial Encoding (EASE) technique. This novel integration is designed to refine image edge clarity and enrich overall image quality significantly. By harnessing Jittor's state-of-the-art optimization strategies, we are able to amplify the performance and efficiency of ECGAN remarkably. Through rigorous experimental evaluation, our findings clearly demonstrate the superior efficacy of our integrated approach, as evidenced by substantial improvements in both the quality of the generated images and the computational speed. This research contributes profoundly to the advancement of image generation technology, illustrating the immense potential of fusing sophisticated generative adversarial network models with advanced computing frameworks to achieve unprecedented levels of image realism and processing efficiency. This synergy paves the way for new directions in the application of artificial intelligence in image processing and generation.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {176–181},
numpages = {6},
location = {Wuhan, China},
series = {CIBDA '24}
}

@article{10.1145/3636550,
author = {Mellouli, Sehl and Janssen, Marijn and Ojo, Adegboyega},
title = {Introduction to the Issue on Artificial Intelligence in the Public Sector: Risks and Benefits of AI for Governments},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
url = {https://doi.org/10.1145/3636550},
doi = {10.1145/3636550},
abstract = {Artificial Intelligence (AI) is increasingly adopted by public sector organizations to provide better public services and to transform their internal processes. AI is now considered a key enabler for digital innovation and transformation in the public sector. However, AI is still relatively a new research area in the field of digital government. The term, AI, captures a wide range of technologies, techniques, and tools such as machine/deep learning, natural language processing, robotics, computer vision, and more recently Generative AI. While these AI technologies afford different applications and benefits in the government context, they also create social, ethical, and legal challenges. These challenges require solutions combining both technical (e.g., data and algorithmic solutions to minimize bias) and institutional (e.g., governance structures and processes) mechanisms. The special issue is a collection of articles that contribute to a better understanding of the issues associated with AI deployment in different areas of government operations. They cover AI applications in the areas of emergency response, policy analysis, public bids, and citizen participation. The contributions also address the challenge of realizing a legal transparency regime for AI in government and the effect of AI in bureaucratic decision-making.},
journal = {Digit. Gov.: Res. Pract.},
month = mar,
articleno = {1},
numpages = {6},
keywords = {Artificial intelligence, risks, benefits, e-government}
}

@inproceedings{10.1145/3652583.3658597,
author = {Wang, Shiqi and Zhang, Xinfeng},
title = {Compact Visual Data Representation for Multimedia Search and Analytics},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658597},
doi = {10.1145/3652583.3658597},
abstract = {With the exponential growth of multimedia in various forms, the volume of acquired visual data has dramatically increased while their value intensity remains relatively low. This presents significant challenges in multimedia search and analytics. In this tutorial, we aim to introduce recent advances of compact visual data representation techniques that enable efficient, flexible, and reliable multimedia search and analytics. We will explore the shift from traditional visual information representation techniques, such as video coding, to biologically inspired information processing paradigms, like digital retina based coding and representation. We will also discuss the representation of point cloud data and Artificial Intelligence Generated Content (AIGC) data, which are becoming increasingly popular in modern machine vision technologies. Additionally, we will discuss the recent advances in quality assessment technologies for multimedia signals under various novel and challenging scenarios. Finally, we will introduce the recent standardization activities in media coding including Video Coding for Machine (VCM). This tutorial aims to stimulate fruitful discussions, encourage innovative research, and drive advancements in the field of semantic and visual communication, multimedia search, analytics, computing as well as generative AI.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {1326–1327},
numpages = {2},
keywords = {compact visual representation, multimedia, visual analytics},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3691620.3695553,
author = {Du, Yali and Sun, Hui and Li, Ming},
title = {A Joint Learning Model with Variational Interaction for Multilingual Program Translation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695553},
doi = {10.1145/3691620.3695553},
abstract = {Programs implemented in various programming languages form the foundation of software applications. To alleviate the burden of program migration and facilitate the development of software systems, automated program translation across languages has garnered significant attention. Previous approaches primarily focus on pairwise translation paradigms, learning translation between pairs of languages using bilingual parallel data. However, parallel data is difficult to collect for some language pairs, and the distribution of program semantics across languages can shift, posing challenges for pairwise program translation. In this paper, we argue that jointly learning a unified model to translate code across multiple programming languages is superior to separately learning from bilingual parallel data. We propose Variational Interaction for Multilingual Program Translation (VIM-PT), a disentanglement-based generative approach that jointly trains a unified model for multilingual program translation across multiple languages. VIM-PT disentangles code into language-shared and language-specific features, using variational inference and interaction information with a novel lower bound, then achieves program translation through conditional generation. VIM-PT demonstrates four advantages: 1) captures language-shared information more accurately from various implementations and improves the quality of multilingual program translation, 2) mines and leverages the capability of non-parallel data, 3) addresses the distribution shift of program semantics across languages, 4) and serves as a unified model, reducing deployment complexity.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1907–1918},
numpages = {12},
keywords = {program translation, multi-lingual disentanglement, variational interaction, regularization},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3680528.3687634,
author = {Shen, Tianchang and Li, Zhaoshuo and Law, Marc and Atzmon, Matan and Fidler, Sanja and Lucas, James and Gao, Jun and Sharp, Nicholas},
title = {SpaceMesh: A Continuous Representation for Learning Manifold Surface Meshes},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680528.3687634},
doi = {10.1145/3680528.3687634},
abstract = {Meshes are ubiquitous in visual computing and simulation, yet most existing machine learning techniques represent meshes only indirectly, e.g. as the level set of a scalar field or deformation of a template, or as a disordered triangle soup lacking local structure. This work presents a scheme to directly generate manifold, polygonal meshes of complex connectivity as the output of a neural network. Our key innovation is to define a continuous latent connectivity space at each mesh vertex, which implies the discrete mesh. In particular, our vertex embeddings generate cyclic neighbor relationships in a halfedge mesh representation, which gives a guarantee of edge-manifoldness and the ability to represent general polygonal meshes. This representation is well-suited to machine learning and stochastic optimization, without restriction on connectivity or topology. We first explore the basic properties of this representation, then use it to fit distributions of meshes from large datasets. The resulting models generate diverse meshes with tessellation structure learned from the dataset population, with concise details and high-quality mesh elements. In applications, this approach not only yields high-quality outputs from generative models, but also enables directly learning challenging geometry processing tasks such as mesh repair.},
booktitle = {SIGGRAPH Asia 2024 Conference Papers},
articleno = {78},
numpages = {11},
keywords = {Mesh Generation, 3D Machine Learning, Graph Representations},
location = {Tokyo, Japan},
series = {SA '24}
}

@inproceedings{10.1145/3626183.3659967,
author = {Kwok, Jacky and Lohstroh, Marten and Lee, Edward A.},
title = {Efficient Parallel Reinforcement Learning Framework Using the Reactor Model},
year = {2024},
isbn = {9798400704161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626183.3659967},
doi = {10.1145/3626183.3659967},
abstract = {Parallel Reinforcement Learning (RL) frameworks are essential for mapping RL workloads to multiple computational resources, allowing for faster generation of samples, estimation of values, and policy improvement. These computational paradigms require a seamless integration of training, serving, and simulation workloads. Existing frameworks, such as Ray, are not managing this orchestration efficiently, especially in RL tasks that demand intensive input/output and synchronization between actors on a single node. In this study, we have proposed a solution implementing the reactor model, which enforces a set of actors to have a fixed communication pattern. This allows the scheduler to eliminate work needed for synchronization, such as acquiring and releasing locks for each actor or sending and processing coordination-related messages. Our framework, Lingua Franca (LF), a coordination language based on the reactor model, also supports true parallelism in Python and provides a unified interface that allows users to automatically generate dataflow graphs for RL tasks. In comparison to Ray on a single-node multi-core compute platform, LF achieves 1.21x and 11.62x higher simulation throughput in OpenAI Gym and Atari environments, reduces the average training time of synchronized parallel Q-learning by 31.2%, and accelerates multi-agent RL inference by 5.12x.},
booktitle = {Proceedings of the 36th ACM Symposium on Parallelism in Algorithms and Architectures},
pages = {41–51},
numpages = {11},
keywords = {machine learning, model of computation, parallel computing, programming languages, reinforcement learning},
location = {Nantes, France},
series = {SPAA '24}
}

@inproceedings{10.1145/3613904.3642677,
author = {Trajkova, Milka and Long, Duri and Deshpande, Manoj and Knowlton, Andrea and Magerko, Brian},
title = {Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642677},
doi = {10.1145/3613904.3642677},
abstract = {Co-creation in embodied contexts is central to the human experience but is often lacking in our interactions with computers. We seek to develop a better understanding of embodied human co-creativity to inform the human-centered design of machines that can co-create with us. In this paper, we ask: What characterizes dancers’ experiences of embodied dyadic interaction in movement improvisation? To answer this, we ran focus groups with 24 university dance students and conducted a thematic analysis of their responses. We synthesize our findings in an Interconnected Model of Improvisational Dance Inputs, where movement choices are shaped by the interplay between in-the-moment influences between the self, partner, and the environment, a set of generative strategies, and heuristics for a successful collaboration. We present a set of design recommendations for LuminAI, a co-creative AI dance partner. Our contributions can inform the design of AI in embodied co-creative domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {890},
numpages = {22},
keywords = {AI agents, co-creative agents, co-creativity, computational creativity, dance improvisation, movement improvisation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3661638.3661697,
author = {Sun, Zhigang and Wu, Junmin},
title = {MHInfer: A FPGA-accelerated Inference Library Based on Domestic Embedded Systems},
year = {2024},
isbn = {9798400716966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661638.3661697},
doi = {10.1145/3661638.3661697},
abstract = {With the wide application of deep learning and the explosion of generative AI, the efficient implementation of model reasoning has attracted wide attention. How to conduct efficient model reasoning on resource-constrained devices such as mobile phones or embedded development boards has been discussed. In such devices, the performance of conventional general computing devices such as CPUs or GPUs will not be the same as that of supercomputers with massive computing resources, and the use of traditional computing resources of such devices for model reasoning is often not satisfactory in time. In this paper, we introduce a high-performance deep learning inference library, MHInfer. This reasoning library is written in traditional C language, and retains the interface of device acceleration, which is convenient for device acceleration of model reasoning later. In this paper, we deploy the inference library to the Zynq UltraScale+ MPSoC ZCU104 embedded development board, which has a quad-core ARM Cortex-A53 CPU and FPGA acceleration device, and runs an embedded domestic operating system on the ARM CPU. Control the data transmission between the host and the FPGA device. In the test, we will compare the speed of CPU and CPU+FPGA heterogeneous platform on the development board respectively. The results show that when using our high-performance reasoning library, the efficiency of computing on CPU+FPGA heterogeneous platform is greatly improved than that of using only CPU.},
booktitle = {Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security},
pages = {309–313},
numpages = {5},
location = {Mianyang, China},
series = {AISNS '23}
}

@article{10.1145/3643034,
author = {Li, Feifei and Wang, Yuanbin and Beyan, Oya and Sch\"{o}neck, Mirjam and Caldeira, Liliana Lourenco},
title = {Voxel-Wise Medical Image Generalization for Eliminating Distribution Shift},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {7},
issn = {1556-4681},
url = {https://doi.org/10.1145/3643034},
doi = {10.1145/3643034},
abstract = {Currently, the medical field is witnessing an increase in the use of machine learning techniques. Supervised learning methods adopted in classification, prediction, and segmentation tasks for medical images always experience decreased performance when the training and testing datasets do not follow the independent and identically distributed assumption. These distribution shift situations seriously influence machine learning applications’ robustness, fairness, and trustworthiness in the medical domain. Hence, in this article, we adopt the CycleGAN (generative adversarial network) method to cycle train the computed tomography data from different scanners/manufacturers. It aims to eliminate the distribution shift from diverse data terminals based on our previous work [14]. However, due to the model collapse problem and generative mechanisms of the GAN-based model, the images we generated contained serious artifacts. To remove the boundary marks and artifacts, we adopt score-based diffusion generative models to refine the images voxel-wisely. This innovative combination of two generative models enhances the quality of data providers while maintaining significant features. Meanwhile, we use five paired patients’ medical images to deal with the evaluation experiments with structural similarity index measure metrics and the segmentation model’s performance comparison. We conclude that CycleGAN can be utilized as an efficient data augmentation technique rather than a distribution-shift-eliminating method. In contrast, the denoising diffusion the denoising diffusion model is more suitable for dealing with the distribution shift problem aroused by the different terminal modules. The limitation of generative methods applied in medical images is the difficulty in obtaining large and diverse datasets that accurately capture the complexity of biological structure and variability. In our following research, we plan to assess the initial and generated datasets to explore more possibilities to overcome the above limitation. We will also incorporate the generative methods into the federated learning architecture, which can maintain their advantages and resolve the distribution shift issue on a larger scale.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jun,
articleno = {167},
numpages = {16},
keywords = {Data fairness, machine learning, CycleGAN, score-based generative model, model robustness}
}

@inproceedings{10.1145/3665314.3670814,
author = {Dhingra, Pratyush and Doppa, Jana and Pande, Partha Pratim},
title = {HeTraX: Energy Efficient 3D Heterogeneous Manycore Architecture for Transformer Acceleration},
year = {2024},
isbn = {9798400706882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665314.3670814},
doi = {10.1145/3665314.3670814},
abstract = {Transformers have revolutionized deep learning and generative modeling to enable unprecedented advancements in natural language processing tasks and beyond. However, designing hardware accelerators for executing transformer models is challenging due to the wide variety of computing kernels involved in the transformer architecture. Existing accelerators are either inadequate to accelerate end-to-end transformer models or suffer notable thermal limitations. In this paper, we propose the design of a three-dimensional heterogeneous architecture referred to as HeTraX specifically optimized to accelerate end-to-end transformer models. HeTraX employs hardware resources aligned with the computational kernels of transformers and optimizes both performance and energy. Experimental results show that HeTraX outperforms existing state-of-the-art by up to 5.6x in speedup and improves EDP by 14.5x while ensuring thermally feasibility.},
booktitle = {Proceedings of the 29th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {1–6},
numpages = {6},
keywords = {transformer, heterogeneity, accelerator, thermal-aware, PIM},
location = {Newport Beach, CA, USA},
series = {ISLPED '24}
}

@inproceedings{10.5555/3643142.3643387,
author = {Kang, Jaewoong and Kim, Young and Imran, Muhammad Mu'az and Jung, Gi-sun and Kim, Yun Bae},
title = {Generating Population Synthesis Using a Diffusion Model},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {Owing to the increase in computing power, large-scale agent-based modeling (ABM) has been increasingly used in various fields. However, a complete and detailed individual population is challenging to obtain because of confidentiality concerns. Thus, modelers must adopt population synthesis to emulate the joint distribution of individual-level attributes of the actual population in the region of interest. Traditional population synthesis methods often exhibit issues regarding scalability and sampling zero. Therefore, this paper presents the use of a deep generative model called the denoising diffusion probabilistic model to generate new samples. Our proposed method uses the characteristics of deep generative model of generation from noise to generate a synthetic population, including sampling zero. In the experimental results, the standardized root mean squared error of our proposed model performed 2.130, which outperformed 2.381 of the deep learning-based population synthesis method, VAE, and 7.620 of the traditional population synthesis method, MCMC.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2944–2955},
numpages = {12},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3664647.3681539,
author = {Jia, Zhijun and Xue, Huaying and Peng, Xiulian and Lu, Yan},
title = {Convert and Speak: Zero-shot Accent Conversion with Minimum Supervision},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681539},
doi = {10.1145/3664647.3681539},
abstract = {Low resource of parallel data is the key challenge of accent conversion(AC) problem in which both the pronunciation units and prosody pattern need to be converted. We propose a two-stage generative framework "convert-and-speak" in which the conversion is only operated on the semantic token level and the speech is synthesized conditioned on the converted semantic token with a speech generative model in target accent domain. The decoupling design enables the "speaking" module to use massive amount of target accent speech and relieves the parallel data required for the "conversion" module. Conversion with the bridge of semantic token also relieves the requirement for the data with text transcriptions and unlocks the usage of language pre-training technology to further efficiently reduce the need of parallel accent speech data. To reduce the complexity and latency of "speaking", a single-stage AR generative model is designed to achieve good quality as well as lower computation cost. Experiments on Indian-English to general American-English conversion show that the proposed framework achieves state-of-the-art performance in accent similarity, speech quality, and speaker maintenance with only 15 minutes of weakly parallel data which is not constrained to the same speaker. Extensive experimentation with diverse accent types suggests that this framework possesses a high degree of adaptability, making it readily scalable to accommodate other accents with low-resource data. Audio samples are available at https://www.microsoft.com/en-us/research/project/convert-and-speak-zero-shot-accent-conversion-with-minimumsupervision/.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4446–4454},
numpages = {9},
keywords = {accent conversion, generative model, speech synthesis},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1109/TCBB.2024.3480088,
author = {Su, Fangfang and Teng, Chong and Li, Fei and Li, Bobo and Zhou, Jun and Ji, Donghong},
title = {Generative Biomedical Event Extraction With Constrained Decoding Strategy},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3480088},
doi = {10.1109/TCBB.2024.3480088},
abstract = {Currently, biomedical event extraction has received considerable attention in various fields, including natural language processing, bioinformatics, and computational biomedicine. This has led to the emergence of numerous machine learning and deep learning models that have been proposed and applied to tackle this complex task. While existing models typically adopt an extraction-based approach, which requires breaking down the extraction of biomedical events into multiple subtasks for sequential processing, making it prone to cascading errors. This paper presents a novel approach by constructing a biomedical event generation model based on the framework of the pre-trained language model &lt;italic&gt;T5&lt;/italic&gt;. We employ a sequence-to-sequence generation paradigm to obtain events, the model utilizes constrained decoding algorithm to guide sequence generation, and a curriculum learning algorithm for efficient model learning. To demonstrate the effectiveness of our model, we evaluate it on two public benchmark datasets, Genia 2011 and Genia 2013. Our model achieves superior performance, illustrating the effectiveness of generative modeling of biomedical events.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = oct,
pages = {2471–2484},
numpages = {14}
}

@article{10.1145/3640811,
author = {N., Thenmoezhi and B., Perumal and A., Lakshmi},
title = {Multi-view Image Fusion Using Ensemble Deep Learning Algorithm For MRI And CT Images},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {2375-4699},
url = {https://doi.org/10.1145/3640811},
doi = {10.1145/3640811},
abstract = {Medical image fusions are crucial elements in image-based health care diagnostics or therapies and generic applications of computer visions. However, the majority of existing methods suffer from noise distortion that affects the overall output. When pictures are distorted by noises, classical fusion techniques perform badly. Hence, fusion techniques that properly maintain information comprehensively from multiple faulty pictures need to be created. This work presents Enhanced Lion Swarm Optimization (ESLO) with Ensemble Deep Learning (EDL) to address the aforementioned issues. The primary steps in this study include image fusions, segmentation, noise reduction, feature extraction, picture classification, and feature selection. Adaptive Median Filters are first used for noise removal in sequence to enhance image quality by eliminating noises. The MRIs and CT images are then segmented using the Region Growing–based k-Means Clustering (RKMC) algorithm to separate the images into their component regions or objects. Images in black and white are divided into image. In the white image, the RKMC algorithm successfully considered the earlier tumour probability. The next step is feature extraction, which is accomplished by using the Modified Principal Component Analysis (MPCA) to draw out the most informative aspects of the images. Then the ELSO algorithm is applied for optimal feature selection, which is computed by best fitness values. After that, multi-view image fusions of multi modal images derive lower-, middle-, and higher-level image contents. It is done by using Deep Convolution Neural Network (DCNN) and the Tissue-Aware Conditional Generative Adversarial Network (TAcGAN) algorithm, which fuses the multi-view features and relevant image features, and it is used for real-time applications. ELSO +EDL algorithm gives better results in terms of accuracy, Peak Signal-To-Noise Ratio (PSNR), and lower Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) when compared to other existing algorithms.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = mar,
articleno = {40},
numpages = {24},
keywords = {Multi-view image fusions, Magnetic Resonance Imaging (MRI) images, Computed Tomography (CT) images, Enhanced Lion Swarm Optimization (ELSO), Ensemble Deep Learning (EDL) algorithm}
}

@inproceedings{10.1145/3631700.3665234,
author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
title = {Towards Zero-shot Knowledge Graph building: Automated Schema Inference},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665234},
doi = {10.1145/3631700.3665234},
abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {467–473},
numpages = {7},
keywords = {Large Language Models, Named Entity Recognition, Ontology Learning},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3674225.3674326,
author = {Niu, Yuzhe and Liu, Li and Sha, Feng and Li, Lin},
title = {Optimized dependency-aware task offloading and resource allocation via multi-stage Imitation Learning in mobile edge computing},
year = {2024},
isbn = {9798400716638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674225.3674326},
doi = {10.1145/3674225.3674326},
abstract = {In the realm of mobile edge computing, the energy consumption and stability of offloading can be significantly influenced by random task arrivals and constraints imposed by task dependencies. To address this challenge, this study proposes a Multi-stage Generative Adversarial Imitation Learning (Multi-stage GAIL) algorithm. This algorithm engages in multi-stage continuous optimization to handle the offloading and allocation processes of dependent tasks. By integrating a simulation system, the algorithm effectively disentangles dependency relationships and generates a queue of tasks ready for execution. It obtains the optimal decision in multiple stages, effectively addressing the impact of the random task arrivals and dependency constraints on task offloading and allocation. Consequently, it leads to enhancements in system performance compared to the baseline algorithm.},
booktitle = {Proceedings of the 2024 International Conference on Power Electronics and Artificial Intelligence},
pages = {560–565},
numpages = {6},
location = {Xiamen, China},
series = {PEAI '24}
}

@article{10.1145/3652854,
author = {Yang, Hao and Wu, Xian and Qiu, Zhaopeng and Zheng, Yefeng and Chen, Xu},
title = {Distributional Fairness-aware Recommendation},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3652854},
doi = {10.1145/3652854},
abstract = {Fairness has been gradually recognized as a significant problem in the recommendation domain. Previous models usually achieve fairness by reducing the average performance gap between different user groups. However, the average performance may not sufficiently represent all the characteristics of the performances in a user group. Thus, equivalent average performance may not mean the recommender model is fair, for example, the variance of the performances can be different. To alleviate this problem, in this article, we define a novel type of fairness, where we require that the performance distributions across different user groups should be similar. We prove that with the same performance distribution, the numerical characteristics of the group performance, including the expectation, variance, and any higher-order moment, are also the same. To achieve distributional fairness, we propose a generative and adversarial training framework. Specifically, we regard the recommender model as the generator to compute the performance for each user in different groups, and then we deploy a discriminator to judge which group the performance is drawn from. By iteratively optimizing the generator and the discriminator, we can theoretically prove that the optimal generator (the recommender model) can indeed lead to the equivalent performance distributions. To smooth the adversarial training process, we propose a novel dual curriculum learning strategy for optimal scheduling of training samples. Additionally, we tailor our framework to better suit top-N recommendation tasks by incorporating softened ranking metrics as measures of performance discrepancies. We conduct extensive experiments based on real-world datasets to demonstrate the effectiveness of our model.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
articleno = {131},
numpages = {28},
keywords = {Distributional fairness, adversarial training, recommender system}
}

@inproceedings{10.1109/ASE56229.2023.00155,
author = {Dong, Jinhao and Zhu, Qihao and Sun, Zeyu and Lou, Yiling and Hao, Dan},
title = {Merge Conflict Resolution: Classification or Generation?},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00155},
doi = {10.1109/ASE56229.2023.00155},
abstract = {Collaborative development is critical to improve the productivity. Multiple contributors work simultaneously on the same project and might make changes to the same code locations. This can cause conflicts and require manual intervention from developers to resolve them. To alleviate the human efforts of manual conflict resolution, researchers have proposed various automatic techniques. More recently, deep learning models have been adopted to solve this problem and achieved state-of-the-art performance. However, these techniques leverage classification to combine the existing elements of input. The classification-based models cannot generate new tokens or produce flexible combinations, and have a wrong hypothesis that fine-grained conflicts of one single coarse-grained conflict are independent.In this work, we propose to generate the resolutions of merge conflicts from a totally new perspective, that is, generation, and we present a conflict resolution technique, MergeGen. First, we design a structural and fine-grained conflict-aware representation for the merge conflicts. Then, we propose to leverage an encoder-decoder-based generative model to process the designed conflict representation and generate the resolutions auto-regressively. We further perform a comprehensive study to evaluate the effectiveness of MergeGen. The quantitative results show that MergeGen outperforms the state-of-the-art (SOTA) techniques from both precision and accuracy. Our evaluation on multiple programming languages verifies the good generalization ability of MergeGen. In addition, the ablation study shows that the major component of our technique makes a positive contribution to the performance of MergeGen, and the granularity analysis reveals the high tolerance of MergeGen to coarse-grained conflicts. Moreover, the analysis on generating new tokens further proves the advance of generative models.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1652–1663},
numpages = {12},
keywords = {merge conflict resolution, generative models, conflict representation},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@article{10.1145/3639466,
author = {Wang, Tingting and Tang, Tao and Cai, Zhen and Fang, Kai and Tian, Jinyu and Li, Jianqing and Wang, Wei and Xia, Feng},
title = {Federated Learning-based Information Leakage Risk Detection for Secure Medical Internet of Things},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1533-5399},
url = {https://doi.org/10.1145/3639466},
doi = {10.1145/3639466},
abstract = {The Medical Internet of Things (MIoT) requires extreme information and communication security, particularly for remote consultation systems. MIoT’s integration of physical and computational components creates a seamless network of medical devices providing high-quality care via continuous monitoring and treatment. However, traditional security methods such as cryptography cannot prevent privacy compromise and information leakage caused by security breaches. To solve this issue, this paper proposes a novel Federated Learning Intrusion Detection System (FLIDS). FLIDS combines Generative Adversarial Network (GAN) and Federated Learning (FL) to detect cyber attacks like Denial of Service (DoS), data modification, and data injection using machine learning. FLIDS shows exceptional performance with over 99% detection accuracy and 1% False Positive Rate (FPR). It saves bandwidth by transmitting 3.8 times fewer bytes compared to central data collection. These results prove FLIDS’ effectiveness in detecting and mitigating security threats in Medical Cyber-Physical Systems (MCPS). The paper recommends scaling up FLIDS to use computing resources from multiple mobile devices for better intrusion detection accuracy and efficiency while reducing the burden on individual devices in MIoT.},
note = {Just Accepted},
journal = {ACM Trans. Internet Technol.},
month = jan,
keywords = {Patient Data., False Positive Rate, Training Accuracy, Dataset Construction, Discriminator Network, Data Leakage, GAN-based Privacy Protection, Medical Internet of Things, Intrusion Detection System, Federated Learning}
}

@inproceedings{10.1145/3703187.3703207,
author = {Chen, Shuang and Chen, Huan and Lu, Yajun},
title = {Investigating the role of artificial intelligence in immersive visual design: A case study in Nanjing},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703207},
doi = {10.1145/3703187.3703207},
abstract = {In the 21st century, the rapid development of computers and the Internet has facilitated the deep integration of art and technology, leading to the vigorous rise of new media art and making immersive experiences a new trend in the cultural and creative industries. This research uses Nanjing, a representative example of urban culture, as a backdrop to explore immersive visual image design and examine the impact of integrating technology and art on the cultural and creative industries. First, deep learning algorithms, including Convolutional Neural Networks (CNNs), are employed to automatically analyze Nanjing's urban culture and extract visual elements, such as mountains, water, cities, and forests, with local characteristics. Next, Generative Adversarial Networks (GANs) are used to generate and optimize the extracted visual elements, organizing them in a systematic manner to enhance the artistic and scientific qualities of the images. Additionally, a highly interactive imaging system is designed by combining ToughDesigner (TD) software with Kinect sensing equipment. Finally, an immersive visual exhibition space is constructed using light and shadow projection technology to showcase Nanjing's urban culture and shape the city's image. This research aims to provide a reference for the future development of new media art, promote the deeper integration of technology and art, and enhance the public's cultural experience and perception of artworks.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {115–120},
numpages = {6},
keywords = {Artificial intelligence, Immersive visual image, Interactive virtual simulation, Nanjing city culture},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3620665.3640366,
author = {Ansel, Jason and Yang, Edward and He, Horace and Gimelshein, Natalia and Jain, Animesh and Voznesensky, Michael and Bao, Bin and Bell, Peter and Berard, David and Burovski, Evgeni and Chauhan, Geeta and Chourdia, Anjali and Constable, Will and Desmaison, Alban and DeVito, Zachary and Ellison, Elias and Feng, Will and Gong, Jiong and Gschwind, Michael and Hirsh, Brian and Huang, Sherlock and Kalambarkar, Kshiteej and Kirsch, Laurent and Lazos, Michael and Lezcano, Mario and Liang, Yanbo and Liang, Jason and Lu, Yinghai and Luk, C. K. and Maher, Bert and Pan, Yunjie and Puhrsch, Christian and Reso, Matthias and Saroufim, Mark and Siraichi, Marcos Yukio and Suk, Helen and Zhang, Shunting and Suo, Michael and Tillet, Phil and Zhao, Xu and Wang, Eikan and Zhou, Keren and Zou, Richard and Wang, Xiaodong and Mathews, Ajit and Wen, William and Chanan, Gregory and Wu, Peng and Chintala, Soumith},
title = {PyTorch 2: Faster Machine Learning Through Dynamic Python Bytecode Transformation and Graph Compilation},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620665.3640366},
doi = {10.1145/3620665.3640366},
abstract = {This paper introduces two extensions to the popular PyTorch machine learning framework, TorchDynamo and TorchInductor, which implement the torch.compile feature released in PyTorch 2. TorchDynamo is a Python-level just-in-time (JIT) compiler that enables graph compilation in PyTorch programs without sacrificing the flexibility of Python. It achieves this by dynamically modifying Python bytecode before execution and extracting sequences of PyTorch operations into an FX graph, which is then JIT compiled using one of many extensible backends. TorchInductor is the default compiler backend for TorchDynamo, which translates PyTorch programs into OpenAI's Triton for GPUs and C++ for CPUs. Results show that TorchDynamo is able to capture graphs more robustly than prior approaches while adding minimal overhead, and TorchInductor is able to provide a 2.27\texttimes{} inference and 1.41\texttimes{} training geometric mean speedup on an NVIDIA A100 GPU across 180+ real-world models, which outperforms six other compilers. These extensions provide a new way to apply optimizations through compilers in eager mode frameworks like PyTorch.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {929–947},
numpages = {19},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@article{10.1145/3686155,
author = {Niu, Yunfang and Wu, Lingxiang and Zhang, Yufeng and Zhu, Yousong and Zhu, Guibo and Wang, Jinqiao},
title = {Multi-Model Style-Aware Diffusion Learning for Semantic Image Synthesis},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {11},
issn = {1551-6857},
url = {https://doi.org/10.1145/3686155},
doi = {10.1145/3686155},
abstract = {Semantic image synthesis aims to generate images from given semantic layouts, which is a challenging task that requires training models to capture the relationship between layouts and images. Previous works are usually based on Generative Adversarial Networks (GAN) or autoregressive (AR) models. However, the GAN model's training process is unstable, and the AR model’s performance is seriously affected by the independent image encoder and the unidirectional generation bias. Due to the above limitations, these methods tend to synthesize unrealistic, poorly aligned images and only consider single-style image generation. In this paper, we propose a Multi-model Style-aware Diffusion Learning (MSDL) framework for semantic image synthesis, including a training module and a sampling module. In the training module, a layout-to-image model is introduced to transfer the learned knowledge from a model pretrained with massive weak correlated text-image pairs data, making the training process more efficient. In the sampling module, we designed a map-guidance technique and creatively designed a multi-model style-guidance strategy for creating images in multiple styles, e.g., oil painting, Disney Cartoon, and pixel style. We evaluate our method on Cityscapes, ADE20K, and COCO-Stuff, making visual comparisons and computing with multiple metrics such as FID, LPIPS, etc. Experimental results demonstrate that our model is highly competitive, especially in terms of fidelity and diversity.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = nov,
articleno = {348},
numpages = {21},
keywords = {Semantic image synthesis, diffusion model, pretrained model}
}

@inproceedings{10.1145/3687488.3687506,
author = {Duan, Mingzhe and Nazri, Ali Ahmad},
title = {System design of vehicle road crack identification},
year = {2024},
isbn = {9798400709937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687488.3687506},
doi = {10.1145/3687488.3687506},
abstract = {In order to solve the problems of low efficiency and low accuracy of traditional manual detection of road cracks, this paper proposes a vehicle-mounted road crack recognition system based on machine vision and deep learning. It mainly includes three parts: pavement collection and sample set preparation, crack identification model training and crack detection. First, the road surface images are collected through the dual cameras on the vehicle, and image stitching and image enhancement techniques are used for preprocessing to reduce the effects of lighting, vibration, etc. The real road images are combined with the generative adversarial network (GAN) to expand and enrich the sample library, so as to build the customized sample set required for this project. Then, the U-Net convolutional neural network can exclude the non-road parts such as the front vehicle and green belt in the image, and only retain the road surface image, and the model is trained by the YOLOv8 target detection algorithm to obtain the road surface crack recognition model. Finally, the system can detect road surface cracks during vehicle driving, and accurately locate the crack position through the vehicle-mounted satellite positioning system, providing a scientific basis for road maintenance and quality assessment. The system not only improves detection efficiency, but also helps optimize the scheduling of road maintenance resources, and has significant social and economic value.},
booktitle = {Proceedings of the 2024 4th International Conference on Control and Intelligent Robotics},
pages = {104–108},
numpages = {5},
keywords = {Design, Generative Adversarial Network, Image preprocessing, Road crack},
location = {
},
series = {ICCIR '24}
}

@article{10.5555/3722479.3722491,
author = {Hegde, Vageesh and Bolar, Supreetha},
title = {Unveiling the Nexus: AI, Environmental Impact, and Cost},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {As we move into 2024, the global landscape is experiencing a significant increase in the adoption of artificial intelligence (AI), which is revolutionizing industries and societies. AI, powered by machine learning (ML) and other advanced programming techniques, represents non-human intelligence capable of learning from large datasets. This transformative technology presents unparalleled opportunities, but also significant challenges, particularly with regards to its environmental impact and economic feasibility. This paper explores the two sides of AI development: Generative AI requires a lot of processing power, leading to high energy consumption and substantial CO2 emissions, affecting its cost-effectiveness and environmental impact. It meticulously examines the complex components contributing to the operational costs of AI models, including computational resources, data storage, energy consumption, and infrastructure requirements. It rigorously analyzes factors influencing these costs, such as model complexity, data volume, and technological infrastructure, to provide a comprehensive framework for cost analysis in AI. Furthermore, the paper explores methodologies for evaluating and quantifying these operational costs, which are essential for calculating return on investment (ROI) in AI initiatives. Real-world case studies illustrate the practical applications of AI, comparing different models to determine their cost-effectiveness and ROI. The paper discusses emerging trends in AI development focused on reducing environmental impact, including green AI initiatives and energy-efficient strategies. It concludes with insights into future research directions, advocating for advancements in cost analysis methodologies and sustainable AI practices to promote responsible AI innovation. In summary, his paper offers a comprehensive analysis of the economic and environmental aspects of AI deployment, providing valuable insights for stakeholders navigating the complexities of AI implementation in a rapidly evolving technological landscape.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {37–38},
numpages = {2}
}

@inproceedings{10.1145/3638530.3661481,
author = {Yang, Tianxing and Ye, Huigen and Xu, Hua},
title = {Learning to Generate Scalable MILP Instances},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3661481},
doi = {10.1145/3638530.3661481},
abstract = {Large-scale Mixed-Integer Linear Programming (MILP) problems have been efficiently addressed using Machine Learning (ML)-based frameworks, especially ML-based evolutionary optimization frameworks to obtain high-quality solutions. When addressing real-world MILP problems, ML-based evolutionary optimization frameworks often face challenges in acquiring sufficient instances that belong to the same category. This underscores the need for generators that can autonomously produce MILP problems from existing instances. This paper introduces MILPGen, a novel generative framework for autonomous MILP instance generation. Our key contribution lies in the two-stage problem generation in MILPGen: 1) Node Splitting and Merging, which splits the bipartite graph and tries to reconstruct it; 2) Scalable Problem Construction, which concatenates tree structures to get larger problems. We demonstrate that the instances generated by MILPGen are highly similar to the original problem instances and can effectively enhance the solution effect of the ML-based evolutionary optimization frameworks. Further experiments show that the scaled-up generated instances still retain the problem's structural properties, validating the proposed framework's effectiveness.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {159–162},
numpages = {4},
keywords = {mixed-integer linear programming, optimization, unsupervised learning, benchmarking},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@article{10.1613/jair.1.14258,
author = {Ganguly, Ankush and Jain, Sanjana and Watchareeruetai, Ukrit},
title = {Amortized Variational Inference: A Systematic Review},
year = {2024},
issue_date = {Jan 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {78},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.14258},
doi = {10.1613/jair.1.14258},
abstract = {The core principle of Variational Inference (VI) is to convert the statistical inference problem of computing complex posterior probability densities into a tractable optimization problem. This property enables VI to be faster than several sampling-based techniques. However, the traditional VI algorithm is not scalable to large data sets and is unable to readily infer out-of-bounds data points without re-running the optimization process. Recent developments in the field, like stochastic-, black box-, and amortized-VI, have helped address these issues. Generative modeling tasks nowadays widely make use of amortized VI for its efficiency and scalability, as it utilizes a parameterized function to learn the approximate posterior density parameters. In this paper, we review the mathematical foundations of various VI techniques to form the basis for understanding amortized VI. Additionally, we provide an overview of the recent trends that address several issues of amortized VI, such as the amortization gap, generalization issues, inconsistent representation learning, and posterior collapse. Finally, we analyze alternate divergence measures that improve VI optimization.},
journal = {J. Artif. Int. Res.},
month = jan,
numpages = {49}
}

@inproceedings{10.1145/3694715.3695978,
author = {Padmanabha Iyer, Anand and Guan, Mingyu and Dai, Yinwei and Pan, Rui and Gandhi, Swapnil and Netravali, Ravi},
title = {Improving DNN Inference Throughput Using Practical, Per-Input Compute Adaptation},
year = {2024},
isbn = {9798400712517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694715.3695978},
doi = {10.1145/3694715.3695978},
abstract = {Machine learning inference platforms continue to face high request rates and strict latency constraints. Existing solutions largely focus on compressing models to substantially lower compute costs (and time) with mild accuracy degradations. This paper explores an alternate (but complementary) technique that trades off accuracy and resource costs on a perinput granularity: early exit models, which selectively allow certain inputs to exit a model from an intermediate layer. Though intuitive, early exits face fundamental deployment challenges, largely owing to the effects that exiting inputs have on batch size (and resource utilization) throughout model execution. We present E3, the first system that makes early exit models practical for realistic inference deployments. Our key insight is to split and replicate blocks of layers in models in a manner that maintains a constant batch size throughout execution, all the while accounting for resource requirements and communication overheads. Evaluations with NLP and vision models show that E3 can deliver up to 1.74\texttimes{} improvement in goodput (for a fixed cost) or 1.78\texttimes{} reduction in cost (for a fixed goodput). Additionally, E3's goodput wins generalize to autoregressive LLMs (2.8--3.8\texttimes{}) and compressed models (1.67\texttimes{}).},
booktitle = {Proceedings of the ACM SIGOPS 30th Symposium on Operating Systems Principles},
pages = {624–639},
numpages = {16},
location = {Austin, TX, USA},
series = {SOSP '24}
}

@inproceedings{10.1145/3637528.3671785,
author = {Shen, Xu and Wang, Yili and Zhou, Kaixiong and Pan, Shirui and Wang, Xin},
title = {Optimizing OOD Detection in Molecular Graphs: A Novel Approach with Diffusion Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671785},
doi = {10.1145/3637528.3671785},
abstract = {Despite the recent progress of molecular representation learning, its effectiveness is assumed on the close-world assumptions that training and testing graphs are from identical distribution. The open-world test dataset is often mixed with out-of-distribution (OOD) samples, where the deployed models will struggle to make accurate predictions. The misleading estimations of molecules' properties in drug screening or design can result in the tremendous waste of wet-lab resources and delay the discovery of novel therapies. Traditional detection methods need to trade off OOD detection and in-distribution (ID) classification performance since they share the same representation learning model. In this work, we propose to detect OOD molecules by adopting an auxiliary diffusion model-based framework, which compares similarities between input molecules and reconstructed graphs. Due to the generative bias towards reconstructing ID training samples, the similarity scores of OOD molecules will be much lower to facilitate detection. Although it is conceptually simple, extending this vanilla framework to practical detection applications is still limited by two significant challenges. First, the popular similarity metrics based on Euclidian distance fail to consider the complex graph structure. Second, the generative model involving iterative denoising steps is notoriously time-consuming especially when it runs on the enormous pool of drugs. To address these challenges, our research pioneers an approach of Prototypical Graph Reconstruction for Molecular OOd Detection, dubbed as PGR-MOOD. Specifically, PGR-MOOD hinges on three innovations: i) An effective metric to comprehensively quantify the matching degree of input and reconstructed molecules according to their discrete edges and continuous node features; ii) A creative graph generator to construct a list of prototypical graphs that are in line with ID distribution but away from OOD one; iii) An efficient and scalable OOD detector to compare the similarity between test samples and pre-constructed prototypical graphs and omit the generative process on every new molecule. Extensive experiments on ten benchmark datasets and six baselines are conducted to demonstrate our superiority: PGR-MOOD achieves more than 8% of average improvement in terms of detection AUC and AUPR accompanied by the reduced cost of testing time and memory consumption. The anonymous code is in: https://github.com/se7esx/PGR-MOOD.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2640–2650},
numpages = {11},
keywords = {diffusion models, molecular graphs, out-of-distribution detection},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3655030,
author = {Roy, Arunava and Dasgupta, Dipankar},
title = {DRD-GAN: A Novel Distributed Conditional Wasserstein Deep Convolutional Relativistic Discriminator GAN with Improved Convergence},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3655030},
doi = {10.1145/3655030},
abstract = {Generative Adversarial Network (GAN) exhibited significant capabilities in many applications including image enhancement and manipulation, language translation, generating images/videos from text, creating art and music, and so on. However, training GANs using large datasets remains highly computationally intensive for most of the standalone systems. Additionally, standalone GANs often exhibit poor synchronization between their generator and discriminator with unstable training, poor convergence along with a large number of mode collapses and vanishing/exploding gradients. Standalone GANs also failed to learn in a decentralized environment, where the data are distributed among several client machines. Some researchers have lately used the most prevalent decentralized setting available today, called Federated Learning (FL) to develop distributed-GAN strategies as the possible solutions, although their implementations mostly failed to address the above issues mainly because of the training instability within the distributed components, which eventually leads to the poor synchronization among the generators and discriminators scattered over several machines.In this work, we developed a computationally inexpensive Wasserstein conditional Distributed Relativistic Discriminator-GAN (DRD-GAN) to alleviate the above issues. DRD-GAN stabilizes its training (with non-convex losses) by keeping a global generator in the central server and relativistic discriminators in the local clients (one discriminator per client) and uses Wasserstein-1 for computing local and global losses. It eventually avoids mode collapses, vanishing/exploding gradients (both in the presence of iid and non-iid samples) and helps DRD-GAN to produce high-quality fake images. Apart from that, the sheer unavailability of a capable conditional distributed-GAN model has become another motivation behind the current work. Essentially, we revisited the FL paradigms, locating one discriminator per client and a generator in the central server that aggregates the updates coming from multiple discriminators. Relativistic discriminators in the clients are trained on both iid and non-iid private data. We presented a detailed mathematical formulation of DRD-GAN and empirically evaluated our claims using CIFAR-10, MNIST, EuroSAT, and CelebA datasets.},
journal = {ACM Trans. Probab. Mach. Learn.},
month = dec,
articleno = {6},
numpages = {34},
keywords = {Federated learning (FL), distributed-GANs (D-GANs), FL-GANs, standalone GANs, distance metrics}
}

@inproceedings{10.1145/3649476.3660360,
author = {Yang, Junhuan and Sheng, Yi and Zhang, Yuzhou and Wang, Hanchen and Lin, Youzuo and Yang, Lei},
title = {Enhanced AI for Science using Diffusion-based Generative AI - A Case Study on Ultrasound Computing Tomography},
year = {2024},
isbn = {9798400706059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649476.3660360},
doi = {10.1145/3649476.3660360},
abstract = {Ultrasound computed tomography (USCT) is an emerging imaging modality that holds great promise for breast imaging. Full-waveform inversion (FWI)-based image reconstruction methods leverage accurate wave physics to generate high spatial resolution quantitative images of the breast tissue’s acoustic properties, such as speed of sound, from USCT measurement data. However, the significant computational demand for FWI reconstruction poses a considerable challenge to its widespread adoption in clinical settings. Data-driven machine learning approaches offer a faster and more efficient means of translating waveform data into images. Yet, the effectiveness of machine learning methods is constrained by the diversity and quality of the training data. Given the heterogeneous distribution of breast tissue characteristics, such as fat content and size, the performance of machine learning varies across different sizes. This variability is problematic, particularly in medical diagnostics, where precision is crucial. In response to the limited data in certain categories, we propose utilizing generative AI to augment data samples, thereby enhancing FWI’s performance on limited-sample data and addressing issues of AI fairness.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2024},
pages = {754–759},
numpages = {6},
location = {Clearwater, FL, USA},
series = {GLSVLSI '24}
}

@inproceedings{10.1145/3634737.3657015,
author = {Kumar, Abhinav and Aguilera, Miguel A. Guirao and Tourani, Reza and Misra, Satyajayant},
title = {A Generative Framework for Low-Cost Result Validation of Machine Learning-as-a-Service Inference},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3657015},
doi = {10.1145/3634737.3657015},
abstract = {The growing popularity of Machine Learning (ML) has led to its deployment in various sensitive domains, which has resulted in significant research focused on ML security and privacy. However, in some applications, such as Augmented/Virtual Reality, integrity verification of the outsourced ML tasks is more critical-a facet that has not received much attention. Existing solutions, such as multi-party computation and proof-based systems, impose significant computation overhead, which makes them unfit for real-time applications. We propose Fides, a novel framework for real-time integrity validation of ML-as-a-Service (MLaaS) inference. Fides features a novel and efficient distillation technique-Greedy Distillation Transfer Learning-that dynamically distills and fine-tunes a space and compute-efficient verification model for verifying the corresponding service model while running inside a trusted execution environment. Fides features a client-side attack detection model that uses statistical analysis and divergence measurements to identify, with a high likelihood, if the service model is under attack. Fides also offers a re-classification functionality that predicts the original class whenever an attack is identified. We devised a generative adversarial network framework for training the attack detection and re-classification models. The evaluation shows that Fides achieves an accuracy of up to 98% for attack detection and 94% for re-classification.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1246–1260},
numpages = {15},
keywords = {verifiable computing, result verification, trusted execution environment, machine learning as a service, edge computing},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

@inproceedings{10.1145/3627673.3679973,
author = {Li, Zhe and Xu, Ronghui and Hu, Jilin and Peng, Zhong and Lu, Xi and Guo, Chenjuan and Yang, Bin},
title = {Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679973},
doi = {10.1145/3627673.3679973},
abstract = {Significant wave height (SWH) is a vital metric in marine science, and accurate SWH estimation is crucial for various applications, e.g., marine energy development, fishery, early warning systems for potential risks, etc. Traditional SWH estimation methods that are based on numerical models and physical theories are hindered by computational inefficiencies. Recently, machine learning has emerged as an appealing alternative to improve accuracy and reduce computational time. However, due to limited observational technology and high costs, the scarcity of real-world data restricts the potential of machine learning models. To overcome these limitations, we propose an ocean SWH estimation framework, namely Orca. Specifically, Orca enhances the limited spatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporal aware encoding module. By segmenting the limited buoy observational data temporally, encoding the buoys' locations spatially, and designing prompt templates, Orca capitalizes on the robust generalization ability of LLMs to estimate significant wave height effectively with limited data. Experimental results on the Gulf of Mexico demonstrate that Orca achieves state-of-the-art performance in SWH estimation.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3892–3896},
numpages = {5},
keywords = {large language model, prompt fine-tuning, significant wave height},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3641584.3641644,
author = {Zhao, Xin and Kong, Weiwei},
title = {Zero-shot Image Caption Enhancement using Large-Scale Language Models},
year = {2024},
isbn = {9798400707674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641584.3641644},
doi = {10.1145/3641584.3641644},
abstract = {Large-scale language models (LLMs) have demonstrated impressive zero-shot learning generalization capabilities for new language tasks. However, applying LLMs to the image captioning problem still poses challenges. This is primarily due to the modality gap between image captioning and LLMs. Existing methods address the modality gap by training language and visual models end-to-end, but this approach incurs significant computational costs. To address this challenge, we propose a novel approach that combines multiple caption generation and fusion of image captions, providing cues for decoupling the modalities and tasks of image captioning from LLMs without the need for end-to-end training. Specifically, we generate multiple captions, relevant questions, and their answers for each image. Then, using prompt templates, we input this information into a large-scale pre-trained language model to generate captions. This approach offers several benefits: Flexibility: It allows for the flexible use of various LLMs to perform the image captioning task. Cost Efficiency: By avoiding end-to-end training, significantly reduces the computational costs of zero-shot learning with LLMs. Performance Improvement: Our proposed method outperforms previous approaches, demonstrating enhanced performance in generating image captions. By adopting this approach, we aim to bridge the gap between LLMs and the image captioning task, providing a cost-effective solution that achieves improved performance without the need for resource-intensive end-to-end training.},
booktitle = {Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition},
pages = {409–414},
numpages = {6},
location = {Xiamen, China},
series = {AIPR '23}
}

@inproceedings{10.1145/3686540.3686552,
author = {Wang, Yubo and Zhang, Yujia},
title = {Enhancing Cognitive Recall in Dementia Patients: Integrating Generative AI with Virtual Reality for Behavioral and Memory Rehabilitation},
year = {2024},
isbn = {9798400718069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686540.3686552},
doi = {10.1145/3686540.3686552},
abstract = {In this Project, we developed a cognitive rehabilitation program for dementia patients, leveraging generative AI and virtual reality (VR) to evoke personal memories [4]. Integrating Open AI, DreamStudio, and Unity, our system allows patients to input descriptions, generating visual memories in a VR environment [5]. In trials, 85% of AI-generated images matched patients' expectations, although some inaccuracies arose from AI generalizations. Further validation with dementia patients is needed to assess memory recovery impacts. This novel approach modernizes Cognitive Stimulation Therapy (CST), traditionally reliant on non-visual exercises, by incorporating AI and VR to enhance memory recall and visual-spatial skills.While the world is developing more and more into Artificial Intelligence (AI) and Virtual Reality (VR), our program successfully coordinates them to help stimulate dementia patients’ brains and perform the memory recall and visual spatial aspects of CST.},
booktitle = {Proceedings of the 2024 6th International Conference on Big-Data Service and Intelligent Computation},
pages = {86–91},
numpages = {6},
keywords = {AI, Firebase, VR},
location = {Hong Kong, Hong Kong},
series = {BDSIC '24}
}

@article{10.1145/3652207,
author = {Li, Haipeng and Jiang, Hai and Luo, Ao and Tan, Ping and Fan, Haoqiang and Zeng, Bing and Liu, Shuaicheng},
title = {DMHomo: Learning Homography with Diffusion Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3652207},
doi = {10.1145/3652207},
abstract = {Supervised homography estimation methods face a challenge due to the lack of adequate labeled training data. To address this issue, we propose DMHomo, a diffusion model-based framework for supervised homography learning. This framework generates image pairs with accurate labels, realistic image content, and realistic interval motion, ensuring that they satisfy adequate pairs. We utilize unlabeled image pairs with pseudo labels such as homography and dominant plane masks, computed from existing methods, to train a diffusion model that generates a supervised training dataset. To further enhance performance, we introduce a new probabilistic mask loss, which identifies outlier regions through supervised training, and an iterative mechanism to optimize the generative and homography models successively. Our experimental results demonstrate that DMHomo effectively overcomes the scarcity of qualified datasets in supervised homography learning and improves generalization to real-world scenes. The code and dataset are available at GitHub ().},
journal = {ACM Trans. Graph.},
month = apr,
articleno = {30},
numpages = {16},
keywords = {Homography, diffusion models, image alignment, datasets}
}

@inproceedings{10.1145/3661167.3661200,
author = {Mastropaolo, Antonio and Nardone, Vittoria and Bavota, Gabriele and Di Penta, Massimiliano},
title = {How the Training Procedure Impacts the Performance of Deep Learning-based Vulnerability Patching},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661200},
doi = {10.1145/3661167.3661200},
abstract = {Generative deep learning (DL) models have been successfully adopted for vulnerability patching. However, such models require the availability of a large dataset of patches to learn from. To overcome this issue, researchers have proposed to start from models pre-trained with general knowledge, either on the programming language or on similar tasks such as bug fixing. Despite the efforts in the area of automated vulnerability patching, there is a lack of systematic studies on how these different training procedures impact the performance of DL models for such a task. This paper provides a manyfold contribution to bridge this gap, by (i) comparing existing solutions of self-supervised and supervised pre-training for vulnerability patching; and (ii) for the first time, experimenting with different kinds of prompt-tuning for this task. The study required to train/test 23 DL models. We found that a supervised pre-training focused on bug-fixing, while expensive in terms of data collection, substantially improves DL-based vulnerability patching. When applying prompt-tuning on top of this supervised pre-trained model, there is no significant gain in performance. Instead, prompt-tuning is an effective and cheap solution to substantially boost the performance of self-supervised pre-trained models, i.e., those not relying on the bug-fixing pre-training.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {150–159},
numpages = {10},
keywords = {Machine Learning on Code, Pre-Trained Models, Prompt Tuning, Software Vulnerability Repair},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3680528.3687581,
author = {Hwang, Jisung and Sung, Minhyuk},
title = {Occupancy-Based Dual Contouring},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680528.3687581},
doi = {10.1145/3680528.3687581},
abstract = {We introduce a dual contouring method that provides state-of-the-art performance for occupancy functions while achieving computation times of a few seconds. Our method is learning-free and carefully designed to maximize the use of GPU parallelization. The recent surge of implicit neural representations has led to significant attention to occupancy fields, resulting in a wide range of 3D reconstruction and generation methods based on them. However, the outputs of such methods have been underestimated due to the bottleneck in converting the resulting occupancy function to a mesh. Marching Cubes tends to produce staircase-like artifacts, and most subsequent works focusing on exploiting signed distance functions as input also yield suboptimal results for occupancy functions. Based on Manifold Dual Contouring (MDC), we propose Occupancy-Based Dual Contouring (ODC), which mainly modifies the computation of grid edge points (1D points) and grid cell points (3D points) to not use any distance information. We introduce auxiliary 2D points that are used to compute local surface normals along with the 1D points, helping identify 3D points via the quadric error function. To search the 1D, 2D, and 3D points, we develop fast algorithms that are parallelizable across all grid edges, faces, and cells. Our experiments with several 3D neural generative models and a 3D mesh dataset demonstrate that our method achieves the best fidelity compared to prior works.},
booktitle = {SIGGRAPH Asia 2024 Conference Papers},
articleno = {129},
numpages = {11},
keywords = {Marching Cubes, Dual Contouring, Mesh, Implicit Function, Isosurface},
location = {Tokyo, Japan},
series = {SA '24}
}

@inproceedings{10.1145/3629527.3652910,
author = {Litoiu, Marin},
title = {Closing the Loop: Building Self-Adaptive Software for Continuous Performance Engineering},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629527.3652910},
doi = {10.1145/3629527.3652910},
abstract = {Cloud computing and cloud-native platforms have rendered runtime environments more malleable. Simultaneously, the growing demand for flexible and agile software applications and services has driven the emergence of self-adaptive architectures. These architectures, in turn, facilitate software performance modeling, tuning, optimization, and scaling in a continuous manner, blurring the boundary between development-time and run-time. Self-adaptive software employs feedback loop controllers inspired by control theory or variations of the Monitoring-Analysis-Planning-Acting (MAPE) architecture. Whether implemented in a centralized or decentralized manner, most controllers utilize performance models that are learned or tuned at run-time. This shift implies that software is designed to be observable and controllable during execution, presupposing the co-design of software applications and their runtime controllers.This talk commences with a succinct overview of the evolution of self-adaptive software, accentuating key milestones along the journey. Subsequently, recent advancements in software performance modeling at runtime and the role of learning-enabled performance management during software operation are presented.Two recent works are highlighted: one focusing on constructing robust performance models to sustain continuous operation and deployment of cloud-native software, and the other on utilizing multimodal models for performance anomaly detection. The former supports cloud operations like continuous deployment of co-located applications, migration, consolidation of services, or scaling in response to workloads or interferences. The latter is tailored to support performance anomaly detection, localization, and identification of root causes, facilitating swift remediation of faults using generative AI. The final segment of the talk delves into current challenges in developing self-adaptive systems, presenting insights from a recent survey on the state of self-adaptive software in the industry and the challenges perceived by practitioners.},
booktitle = {Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
pages = {258–259},
numpages = {2},
keywords = {cloud computing, generative ai, machine learning, performance models, self-adaptive software systems, self-optimization, software performance},
location = {London, United Kingdom},
series = {ICPE '24 Companion}
}

@inproceedings{10.1145/3637528.3671937,
author = {Xu, Yongxin and Jiang, Xinke and Chu, Xu and Xiao, Yuzhen and Zhang, Chaohe and Ding, Hongxin and Zhao, Junfeng and Wang, Yasha and Xie, Bing},
title = {ProtoMix: Augmenting Health Status Representation Learning via Prototype-based Mixup},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671937},
doi = {10.1145/3637528.3671937},
abstract = {With the widespread adoption of electronic health records (EHR) data, deep learning techniques have been broadly utilized for various health prediction tasks. Nevertheless, the labeled data scarcity issue restricts the prediction power of these deep models. To enhance the generalization capability of deep learning models when faced with such situations, a common trend is to train generative adversarial networks (GANs) or diffusion models for data augmentation. However, due to limitations in sample size and potential label imbalance issues, these methods are prone to mode collapse problems. This results in the generation of new samples that fail to preserve the subtype structure within EHR data, thereby limiting their practicality in health prediction tasks that generally require detailed patient phenotyping. Aiming at the above problems, we propose a &lt;u&gt;Proto&lt;/u&gt;type-based &lt;u&gt;Mix&lt;/u&gt;up method, dubbed ProtoMix, which combines prior knowledge of intrinsic data features from subtype centroids (i.e., prototypes) to guide the synthesis of new samples. Specifically, ProtoMix employs a prototype-guided mixup training task to shift the decision boundary away from the subtypes. Then, ProtoMix optimizes the sampling weights in different areas of the data manifold via a prototype-guided mixup sampling strategy. Throughout the training process, ProtoMix dynamically expands the training distribution using an adaptive mixing coefficient computation method. Experimental evaluations on three real-world datasets demonstrate the efficacy of ProtoMix.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3633–3644},
numpages = {12},
keywords = {electronic health records, healthcare informatics, labeled data scarcity, representation learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.5555/3635637.3663179,
author = {Pettet, Ava and Zhang, Yunuo and Luo, Baiting and Wray, Kyle and Baier, Hendrik and Laszka, Aron and Dubey, Abhishek and Mukhopadhyay, Ayan},
title = {Decision Making in Non-Stationary Environments with Policy-Augmented Search},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Sequential decision-making is challenging in non-stationary environments, where the environment in which an agent operates can change over time. Policies learned before execution become stale when the environment changes, and relearning takes time and computational effort. Online search, on the other hand, can return sub-optimal actions when there are limitations on allowed runtime. In this paper, we introduce Policy-Augmented Monte Carlo tree search (PA-MCTS), which combines action-value estimates from an out-of-date policy with an online search using an up-to-date model of the environment. We prove several theoretical results about PA-MCTS. We also compare and contrast our approach with AlphaZero, another hybrid planning approach, and Deep Q Learning on several OpenAI Gym environments and show that PA-MCTS outperforms these baselines.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2417–2419},
numpages = {3},
keywords = {mcts, non-stationary environments, sequential decision-making},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3633637.3633702,
author = {Zhao, Feixiang and Zhao, Jianchao and Liu, Mingzhe},
title = {Image Domain Ultra-Sparse View CT Artifact Removal Via Conditional Denoising Diffusion Probability Model},
year = {2024},
isbn = {9798400707988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633637.3633702},
doi = {10.1145/3633637.3633702},
abstract = {X-ray computed tomography (CT) scan is commonly used for pre-diagnosis and is powerful tool for ensuring accurate diagnoses. Its potential radiation damage has raised concerns in recent years. Sparse view CT scan can effectively reduce radiation exposure and improve patient comfort by shorten scanning time. However, the incomplete measurement data obtained from sparse view CT scan can only reconstruct CT images containing a large number of artifacts. To remove these artifacts and achieve a quality similar to full view CT images, numerous deep learning (DL)-based methods have been proposed, generally employing autoencoders or generative adversarial networks (GANs). Due to the high-dimensional sparse nature of artifacts, autoencoders and GANs often fail to model artifacts well. In this work, we employ a novel generative model, the denoising diffusion probability model (DDPM), to directly model full view CT images. We use ultra-sparse view CT images as the condition for generating full view CT images, guiding the reverse process of DDPM to realize artifact removal in ultra-sparse view CT images. Our method is the first to achieve artifact removal in ultra-sparse view CT in the image domain. Experiments on a public dataset demonstrate the superiority of our proposed method over existing methods.},
booktitle = {Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition},
pages = {416–421},
numpages = {6},
keywords = {Artifact removal, Deep learning, Denoising Diffusion Probability Model, Sparse view CT},
location = {Qingdao, China},
series = {ICCPR '23}
}

@inproceedings{10.1145/3691620.3694993,
author = {Dong, Jinhao and Sun, Jun and Lin, Yun and Zhang, Yedi and Ma, Murong and Dong, Jin Song and Hao, Dan},
title = {Revisiting the Conflict-Resolving Problem from a Semantic Perspective},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694993},
doi = {10.1145/3691620.3694993},
abstract = {Collaborative software development significantly enhances development productivity by enabling multiple contributors to work concurrently on different branches. Despite these advantages, such collaboration often increases the likelihood of causing conflicts. Resolving these conflicts brings huge challenges, primarily due to the necessity of comprehending the differences between conflicting versions. Researchers have explored various automatic conflict resolution techniques, including unstructured, structured, and learning-based approaches. However, these techniques are mostly heuristic-based or black-box in nature, which means they do not attempt to solve the root cause of the conflicts, i.e., the existence of different program behaviors exhibited by the conflicting versions.In this work, we propose sMerge, a novel conflict resolution approach based on the semantics of program behaviors. We first give the formal definition of the merge conflict problem as well as the specific conditions under which conflicts happen and the criteria employed to select certain version as the resolution. Based on the definition, we propose to resolve the conflicts from the perspective of program behaviors. In particular, we argue that the key to resolving conflicts is identifying different program behaviors, and thus can be solved through targeted test generation. We conduct an extensive evaluation of sMerge using a comprehensive dataset of conflicts sourced from various projects. Our results show that sMerge can effectively solve the merge problem by employing different test generation techniques, including search-based, GPT-based, and manual testing. We remark that sMerge provides a way to understand the program behavior differences through testing, which not only allows us to solve the merge problem soundly but also enables the detection of incorrect ground truths provided by developers, thereby enhancing the reliability of the merge process.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {141–152},
numpages = {12},
keywords = {behavior-based conflict resolving, targeted test generation},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3664647.3681713,
author = {Liu, Bochao and Wang, Pengju and Guo, Weijia and Li, Yong and Zhuang, Liansheng and Wang, Weiping and Ge, Shiming},
title = {Private Gradient Estimation is Useful for Generative Modeling},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681713},
doi = {10.1145/3664647.3681713},
abstract = {While generative models have proved successful in many domains, they may pose a privacy leakage risk in practical deployment. To address this issue, differentially private generative model learning has emerged as a solution to train private generative models for different downstream tasks. However, existing private generative modeling approaches face significant challenges in generating high-dimensional data due to the inherent complexity involved in modeling such data. In this work, we present a new private generative modeling approach where samples are generated via Hamiltonian dynamics with gradients of the private dataset estimated by a well-trained network. In the approach, we achieve differential privacy by perturbing the projection vectors in the estimation of gradients with sliced score matching. In addition, we enhance the reconstruction ability of the model by incorporating a residual enhancement module during the score matching. For sampling, we perform Hamiltonian dynamics with gradients estimated by the well-trained network, allowing the sampled data close to the private dataset's manifold step by step. In this way, our model is able to generate data with a resolution of 256\texttimes{}256. Extensive experiments and analysis clearly demonstrate the effectiveness and rationality of the proposed approach.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {282–290},
numpages = {9},
keywords = {differential privacy, generative models, gradient estimation},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3626772.3657742,
author = {Hou, Yu and Park, Jin-Duk and Shin, Won-Yong},
title = {Collaborative Filtering Based on Diffusion Models: Unveiling the Potential of High-Order Connectivity},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657742},
doi = {10.1145/3626772.3657742},
abstract = {A recent study has shown that diffusion models are well-suited for modeling the generative process of user--item interactions in recommender systems due to their denoising nature. However, existing diffusion model-based recommender systems do not explicitly leverage high-order connectivities that contain crucial collaborative signals for accurate recommendations. Addressing this gap, we propose textsfCF-Diff, a new diffusion model-based collaborative filtering (CF) method, which is capable of making full use of collaborative signals along with multi-hop neighbors. Specifically, the forward-diffusion process adds random noise to user--item interactions, while the reverse-denoising process accommodates our own learning model, named cross-attention-guided multi-hop autoencoder (CAM-AE ), to gradually recover the original user--item interactions. CAM-AE consists of two core modules: 1) the attention-aided AE module, responsible for precisely learning latent representations of user--item interactions while preserving the model's complexity at manageable levels, and 2) the multi-hop cross-attention module, which judiciously harnesses high-order connectivity information to capture enhanced collaborative signals. Through comprehensive experiments on three real-world datasets, we demonstrate that CF-Diff is (a) Superior: outperforming benchmark recommendation methods, achieving remarkable gains up to 7.29% compared to the best competitor, (b) Theoretically-validated: reducing computations while ensuring that the embeddings generated by our model closely approximate those from the original cross-attention, and (c) Scalable: proving the computational efficiency that scales linearly with the number of users or items.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1360–1369},
numpages = {10},
keywords = {collaborative filtering, cross-attention, diffusion model, high-order connectivity, recommender system},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3616855.3635729,
author = {Lenti, Jacopo},
title = {Learning Opinion Dynamics from Data},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635729},
doi = {10.1145/3616855.3635729},
abstract = {The foundation of my doctoral thesis is the estimation of agent-based models (ABMs) that simulate opinion dynamics using a likelihood-based method. I establish that the principles governing ABMs can be transformed into equivalent probabilistic generative models that facilitate a well-defined likelihood function. Consequently, I have incorporated these models into an automatic differentiation framework, which simplifies the process and improves the efficiency of performing maximum likelihood estimation through gradient descent techniques.  The first work shows that our maximum likelihood approach outperforms the typical simulation-based in the estimation of the parameter of a bounded confidence model (BCM) in different settings. We compared the two approaches in three realistic scenarios of increasing complexity depending on data availability: (i) fully observed opinions and interactions, (ii) partially observed interactions, (iii) observed interactions with noisy proxies of the opinions. The comparison is strikingly unbalanced both in term of computational time and estimation error.  Thanks to the formalism of the Probabilistic Graphical Models, it is possible to stand on probabilistic machine learning tools for treating ABMs. Hence, the proposed scheme opens to a broad range of inference techniques. In particular, my ongoing research generalizes the estimation of opinion dynamics models to avoid the most intriguing step of the derivation of the likelihood. We cast the ABMs into a probabilistic programming framework, where it is possible to apply black-box variational inference (VI) without an explicit definition of the (possibly intractable) likelihood. To show such methodology, we extend the BCM towards the most common rules existing in opinion dynamics literature.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1145–1147},
numpages = {3},
keywords = {agent-based models, opinions dynamics, probabilistic modeling},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3665463.3678830,
author = {von Detten, Maximilian and Pakula, Kevin},
title = {Bogtactics: Enhancing Environmental Awareness Through Serious Gaming},
year = {2024},
isbn = {9798400706929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665463.3678830},
doi = {10.1145/3665463.3678830},
abstract = {Games have the potential to educate about environmental issues through interactivity, employing various elements from non-formal educational components to intentional educational experiences. In this paper, we introduce "Bogtactics," a strategy game developed to highlight the significance of wetlands for our ecosystems, utilizing generative AI for content creation. Developed as part of a Master Study program, "Bogtactics" integrates educational elements seamlessly through interactions and meaningful choices based on real data. The development process included three expert interviews, three paper prototypes, and seven digital prototypes, followed by 10 playtests focusing on players’ experiences. The current state of "Bogtactics" demonstrates its capability to disseminate information and raise awareness about peatlands using diverse learning methods. Initial playtest results indicate promising user experience and gameplay elements, providing valuable feedback for future development.},
booktitle = {Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play},
pages = {398–403},
numpages = {6},
keywords = {AI art, Bogs, Education, Serious Games, Simulation, Strategy Game, Wetlands},
location = {Tampere, Finland},
series = {CHI PLAY Companion '24}
}

@article{10.1145/3640332,
author = {Clun, Donato and Shin, Donghwan and Filieri, Antonio and Bianculli, Domenico},
title = {Rigorous Assessment of Model Inference Accuracy using Language Cardinality},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3640332},
doi = {10.1145/3640332},
abstract = {Models such as finite state automata are widely used to abstract the behavior of software systems by capturing the sequences of events observable during their execution. Nevertheless, models rarely exist in practice and, when they do, get easily outdated; moreover, manually building and maintaining models is costly and error-prone. As a result, a variety of model inference methods that automatically construct models from execution traces have been proposed to address these issues.However, performing a systematic and reliable accuracy assessment of inferred models remains an open problem. Even when a reference model is given, most existing model accuracy assessment methods may return misleading and biased results. This is mainly due to their reliance on statistical estimators over a finite number of randomly generated traces, introducing avoidable uncertainty about the estimation and being sensitive to the parameters of the random trace generative process.This article addresses this problem by developing a systematic approach based on analytic combinatorics that minimizes bias and uncertainty in model accuracy assessment by replacing statistical estimation with deterministic accuracy measures. We experimentally demonstrate the consistency and applicability of our approach by assessing the accuracy of models inferred by state-of-the-art inference tools against reference models from established specification mining benchmarks.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {95},
numpages = {39},
keywords = {Model inference, specification mining, process mining, model assessment, formal specifications, machine learning, software engineering, behavioral comparison, conformance checking, precision, recall}
}

@inproceedings{10.1145/3589334.3645477,
author = {Zeng, Hansi and Luo, Chen and Jin, Bowen and Sarwar, Sheikh Muhammad and Wei, Tianxin and Zamani, Hamed},
title = {Scalable and Effective Generative Information Retrieval},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645477},
doi = {10.1145/3589334.3645477},
abstract = {Recent research has shown that transformer networks can be used as differentiable search indexes by representing each document as a sequence of document ID tokens. These generative retrieval models cast the retrieval problem to a document ID generation problem for each query. Despite their elegant design, existing generative retrieval models only perform well on artificially-constructed and small-scale collections. This paper represents an important milestone in generative retrieval research by showing that generative retrieval models can be trained to perform effectively on large-scale standard retrieval benchmarks. In more detail, we propose RIPOR- an optimization framework for generative retrieval that is designed based on two often-overlooked fundamental design considerations. First, RIPOR introduces a novel prefix-oriented ranking optimization algorithm for accurate estimation of relevance score during sequential document ID generation. Second, RIPOR constructs document IDs based on the relevance associations between queries and documents. Evaluation on MSMARCO and TREC Deep Learning Track reveals that RIPOR surpasses state-of-the-art generative retrieval models by a large margin (e.g., 30.5% MRR improvements on MS MARCO Dev Set).},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1441–1452},
numpages = {12},
keywords = {generative retrieval, neural ranking models, ranking optimization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.14778/3685800.3685916,
author = {Madden, Samuel and Cafarella, Michael and Franklin, Michael and Kraska, Tim},
title = {Databases Unbound: Querying All of the World's Bytes with AI},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685916},
doi = {10.14778/3685800.3685916},
abstract = {Over the past five decades, the relational database model has proven to be a scaleable and adaptable model for querying a variety of structured data, with use cases in analytics, transactions, graphs, streaming and more. However, most of the world's data is unstructured. Thus, despite their success, the reality is that the vast majority of the world's data has remained beyond the reach of relational systems.The rise of deep learning and generative AI offers an opportunity to change this. These models provide a stunning capability to extract semantic understanding from almost any type of document, including text, images, and video, which can extend the reach of databases to all the world's data. In this paper we explore how these new technologies will transform the way we build database management software, creating new that systems that can ingest, store, process, and query all data. Building such systems presents many opportunities and challenges. In this paper we focus on three: scalability, correctness, and reliability, and argue that the declarative programming paradigm that has served relational systems so well offers a path forward in the new world of AI data systems as well. To illustrate this, we describe several examples of such declarative AI systems we have built in document and video processing, and provide a set of research challenges and opportunities to guide research in this exciting area going forward.And lovely apparitions, -dim at first,Then radiant, as the mind arising brightFrom the embrace of beauty (whence the formsOf which these are the phantoms) casts on themThe gathered rays which are reality-Shall visit us the progeny immortalOf Painting, Sculpture, and rapt Poesy,And arts, though unimagined, yet to be;Prometheus Unbound, Percy Bysshe Shelley},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4546–4554},
numpages = {9}
}

@inproceedings{10.1145/3669721.3674555,
author = {Zine el abidine, Hebboul and Tang, Hai-Bin and Wang, Zixiang},
title = {Data-Driven Modeling of Miniature Hall Thrusters: A Machine Learning Approach},
year = {2024},
isbn = {9798400710025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669721.3674555},
doi = {10.1145/3669721.3674555},
abstract = {New data-driven and physics-based modeling approaches have been applied synergistically to advance the design of sub-kilowatt Hall thrusters. An extensive literature database was compiled and cleaned using a custom program to impute missing values resulting from patents and confidentiality restrictions. Generative adversarial networks (GANs) augmented the limited dataset, covering various thruster geometries and operating conditions. A correlation analysis identified the most influential performance parameters, which served as inputs to a surrogate artificial neural network (ANN) model for rapid design prediction. The ANN predictions were closely aligned with conventional linear regression models, thus validating the approach. Numerical simulations of the ANN-generated designs demonstrated accurate performance projections, highlighting the potential of these new machine-learning techniques in the design of electric propulsion systems. This framework synergized data resources, machine learning models, and high-fidelity simulations to realize next-generation, low-power Hall thrusters.},
booktitle = {Proceedings of the 2024 3rd International Symposium on Intelligent Unmanned Systems and Artificial Intelligence},
pages = {216–220},
numpages = {5},
location = {Qingdao, China},
series = {SIUSAI '24}
}

@article{10.1145/3637493,
author = {Yuan, Yuan and Ding, Jingtao and Wang, Huandong and Jin, Depeng},
title = {Generating Daily Activities with Need Dynamics},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3637493},
doi = {10.1145/3637493},
abstract = {Daily activity data recording individuals’ various activities in daily life are widely used in many applications such as activity scheduling, activity recommendation, and policymaking. Though with high value, its accessibility is limited due to high collection costs and potential privacy issues. Therefore, simulating human activities to produce massive high-quality data is of great importance. However, existing solutions, including rule-based methods with simplified behavior assumptions and data-driven methods directly fitting real-world data, both cannot fully qualify for matching reality. In this article, motivated by the classic psychological theory, Maslow’s need theory describing human motivation, we propose a knowledge-driven simulation framework based on generative adversarial imitation learning. Our core idea is to model the evolution of human needs as the underlying mechanism that drives activity generation in the simulation model. Specifically, a hierarchical model structure that disentangles different need levels and the use of neural stochastic differential equations successfully capture the piecewise-continuous characteristics of need dynamics. Extensive experiments demonstrate that our framework outperforms the state-of-the-art baselines regarding data fidelity and utility. We also present the insightful interpretability of the need modeling. Moreover, privacy preservation evaluations validate that the generated data does not leak individual privacy. The code is available at .},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {29},
numpages = {28},
keywords = {Daily activities, generation, need dynamics, GAIL}
}

@inproceedings{10.1145/3637528.3671775,
author = {Wang, Ye and Xun, Jiahao and Hong, Minjie and Zhu, Jieming and Jin, Tao and Lin, Wang and Li, Haoyuan and Li, Linjun and Xia, Yan and Zhao, Zhou and Dong, Zhenhua},
title = {EAGER: Two-Stream Generative Recommender with Behavior-Semantic Collaboration},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671775},
doi = {10.1145/3637528.3671775},
abstract = {Generative retrieval has recently emerged as a promising approach to sequential recommendation, framing candidate item retrieval as an autoregressive sequence generation problem. However, existing generative methods typically focus solely on either behavioral or semantic aspects of item information, neglecting their complementary nature and thus resulting in limited effectiveness. To address this limitation, we introduce EAGER, a novel generative recommendation framework that seamlessly integrates both behavioral and semantic information. Specifically, we identify three key challenges in combining these two types of information: a unified generative architecture capable of handling two feature types, ensuring sufficient and independent learning for each type, and fostering subtle interactions that enhance collaborative information utilization. To achieve these goals, we propose (1) a two-stream generation architecture leveraging a shared encoder and two separate decoders to decode behavior tokens and semantic tokens with a confidence-based ranking strategy; (2) a global contrastive task with summary tokens to achieve discriminative decoding for each type of information; and (3) a semantic-guided transfer task designed to implicitly promote cross-interactions through reconstruction and estimation objectives. We validate the effectiveness of EAGER on four public benchmarks, demonstrating its superior performance compared to existing methods. Our source code will be publicly available on PapersWithCode.com.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3245–3254},
numpages = {10},
keywords = {haoyuan li, jiahao xun, jieming zhu, linjun li, mingjie hong, tao jin, wang lin, yan xia, ye wang, zhenhua dong., zhou zhao},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3664595,
author = {Franceschelli, Giorgio and Musolesi, Mirco},
title = {Creativity and Machine Learning: A Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3664595},
doi = {10.1145/3664595},
abstract = {There is a growing interest in the area of machine learning and creativity. This survey presents an overview of the history and the state of the art of computational creativity theories, key machine learning techniques (including generative deep learning), and corresponding automatic evaluation methods. After presenting a critical discussion of the key contributions in this area, we outline the current research challenges and emerging opportunities in this field.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {283},
numpages = {41},
keywords = {Computational creativity, machine learning, generative deep learning, creativity evaluation methods}
}

@inproceedings{10.1145/3627673.3679959,
author = {Zhang, Hanqi and Chen, Chong and Mei, Lang and Liu, Qi and Mao, Jiaxin},
title = {Mamba Retriever: Utilizing Mamba for Effective and Efficient Dense Retrieval},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679959},
doi = {10.1145/3627673.3679959},
abstract = {In the information retrieval (IR) area, dense retrieval (DR) models use deep learning techniques to encode queries and passages into embedding space to compute their semantic relations. It is important for DR models to balance both efficiency and effectiveness. Pre-trained language models (PLMs), especially Transformer-based PLMs, have been proven to be effective encoders of DR models. However, the self-attention component in Transformer-based PLM results in a computational complexity that grows quadratically with sequence length, and thus exhibits a slow inference speed for long-text retrieval. Some recently proposed non-Transformer PLMs, especially the Mamba architecture PLMs, have demonstrated not only comparable effectiveness to Transformer-based PLMs on generative language tasks but also better efficiency due to linear time scaling in sequence length. This paper implements the Mamba Retriever to explore whether Mamba can serve as an effective and efficient encoder of DR model for IR tasks. We fine-tune the Mamba Retriever on the classic short-text MS MARCO passage ranking dataset and the long-text LoCoV0 dataset. Experimental results show that (1) on the MS MARCO passage ranking dataset and BEIR, the Mamba Retriever achieves comparable or better effectiveness compared to Transformer-based retrieval models, and the effectiveness grows with the size of the Mamba model; (2) on the long-text LoCoV0 dataset, the Mamba Retriever can extend to longer text length than its pre-trained length after fine-tuning on retrieval task, and it has comparable or better effectiveness compared to other long-text retrieval models; (3) the Mamba Retriever has superior inference speed for long-text retrieval. In conclusion, Mamba Retriever is both effective and efficient, making it a practical model, especially for long-text retrieval.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4268–4272},
numpages = {5},
keywords = {information retrieval, pretrained language models, state space model},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.5555/3722577.3722795,
author = {Reshetova, Daria and Bai, Yikun and Wu, Xiugang and \"{O}zg\"{u}r, Ayfer},
title = {Understanding entropic regularization in GANs},
year = {2024},
issue_date = {January 2024},
publisher = {JMLR.org},
volume = {25},
number = {1},
issn = {1532-4435},
abstract = {Generative Adversarial Networks (GANs) are a popular method for learning distributions from data by modeling the target distribution as a function of a known distribution. The function, often referred to as the generator, is optimized to minimize a chosen distance measure between the generated and target distributions. One commonly used measure for this purpose is the Wasserstein distance. However, Wasserstein distance is hard to compute and optimize, and in practice entropic regularization techniques are used to facilitate its computation and improve numerical convergence. The influence of regularization on the learned solution, however, remains not well-understood. In this paper, we study how several popular entropic regularizations of Wasserstein distance impact the solution learned by a Wasserstein GAN in a simple benchmark setting where the generator is linear and the target distribution is high-dimensional Gaussian. We show that entropy regularization of Wasserstein distance promotes sparsification of the solution, while replacing the Wasserstein distance with the Sinkhorn divergence recovers the unregularized solution. The significant benefit of both regularization techniques is that they remove the curse of dimensionality suffered by Wasserstein distance. We show that in both cases the optimal generator can be learned to accuracy ε with O(1/ε2) samples from the target distribution without requiring to constrain the discriminator. We thus conclude that these regularization techniques can improve the quality of the generator learned from empirical data in a way that is applicable for a large class of distributions.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {218},
numpages = {32},
keywords = {generative adversarial networks, Wasserstein GANs, optimal transport, entropic regularization, Sinkhorn divergence}
}

@inproceedings{10.1145/3636534.3690684,
author = {Khalili, Hossein and Park, Seongbin and Li, Vincent and Bright, Brandan and Payani, Ali and Kompella, Ramana Rao and Sehatbakhsh, Nader},
title = {LightPure: Realtime Adversarial Image Purification for Mobile Devices Using Diffusion Models},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690684},
doi = {10.1145/3636534.3690684},
abstract = {Autonomous mobile systems increasingly rely on deep neural networks for perception and decision-making. While effective, these systems are vulnerable to adversarial machine learning attacks where small perturbations in the input could significantly impact the outcome of the system. Common countermeasures include leveraging adversarial training and/or data or network transformation. Although widely used, the main drawback of these countermeasures is that they require full and invasive access to the classifiers, which are typically proprietary. Additionally, the cost of training or retraining is often prohibitively expensive for large models. To tackle this, purification models have recently been proposed. The aim is to incorporate a "purification" layer before classification, thereby eliminating the necessity to modify the classifier. Despite their effectiveness, state-of-the-art purification methods are compute-intensive, rendering them unsuitable for mobile systems where resources are constrained and large latency is not desired.This paper presents a new approach, LightPure, that enhances the purification of adversarial images. It improves the accuracy of the current leading purification methods while also providing notable enhancements in speed and computational efficiency, making it suitable for mobile devices with limited resources. Our approach uses a two-step diffusion and one-shot Generative Adversarial Network (GAN) framework for purification, prioritizing latency without compromising robustness. We propose several new techniques in designing our model to achieve a reasonable balance between classification accuracy and adversarial robustness while maintaining a desired latency. We design and implement a proof-of-concept on a Jetson Nano board and evaluate our method using several attack scenarios and datasets. Our results show that LightPure can outperform existing purification methods by up to 10x in terms of latency while achieving higher accuracy and robustness for various black-, gray-, and white-box attack scenarios. The fusion of speed and robust defense mechanisms positions our method as a significant advancement in the field of adversarial image purification, offering a scalable and effective solution for real-world mobile systems.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1147–1161},
numpages = {15},
keywords = {autonomous mobile system, adversarial machine learning, diffusion models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3603287.3651183,
author = {Stigall, William and Al Hafiz Khan, Md Abdullah and Attota, Dinesh and Nweke, Francis and Pei, Yong},
title = {Large Language Models Performance Comparison of Emotion and Sentiment Classification},
year = {2024},
isbn = {9798400702372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603287.3651183},
doi = {10.1145/3603287.3651183},
abstract = {The increasing application of artificial intelligence in daily life necessitates precise emotion classification for improved user interactions in areas like healthcare, marketing, and customer service. This work explores the development of emotion classification algorithms, focusing on text classification and providing low latency inferencing for seamless application into persistent-state systems. We use a parallel multi-task learning approach, to learn multiple tasks with a single loss function, allowing it to learn representations in both Emotion Classification and Sentiment Analysis simultaneously. We present a detailed analysis of a fine-tuned BERTTiny model EmoBERTTiny for emotion and sentiment classification tasks, comparing its performance against baseline models and state-of-the-art 7B parameter models. EmoBERTTiny is bench-marked against Llama-2-7B-chat and Mistral-7B-Instruct across Accuracy, F1-score, precision-recall curves and inference speed. EmoBERTTiny outperforms pre-trained and state-of-the-art models across all metrics and computational efficiency, achieving 93.14% accuracy in sentiment analysis and 85.48% accuracy on emotion classification. EmoBERTTiny processes a 256 token context window in 8.04ms on average post-tokenization, and 154.23ms on average in total processing speed.},
booktitle = {Proceedings of the 2024 ACM Southeast Conference},
pages = {60–68},
numpages = {9},
keywords = {BERT, Emotion Classification, Large Language Models, Llama, Mistral, Multitask Models, NLP, Sentiment Analysis},
location = {Marietta, GA, USA},
series = {ACMSE '24}
}

@inproceedings{10.1145/3637684.3637712,
author = {Bai, Xiao and Cheng, Ying and Chen, Linjie and Yang, Shuo and Wang, Huamin and Wang, Zhe and Wu, Jiayi and Cao, Guohua},
title = {A Generative Network with Dual-Domain Discriminators for Low-Dose Stationary Sources CT Imaging},
year = {2024},
isbn = {9798400709425},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637684.3637712},
doi = {10.1145/3637684.3637712},
abstract = {Recent development of clinical Computed tomography (CT) technologies has led to research for novel CT systems that allow safer and faster imaging, such as low-dose cardiac CT imaging via stationary CT. However, the complex data acquisition schemes in stationary CT often cause severe artifacts and noise in the resulted images; this calls for the development of a new kind of image reconstruction algorithms. Recent advancements in deep learning have shown remarkable progress in medical image reconstruction, processing, and analysis. In this paper, we propose a generative network with dual-domain discriminators for low-dose CT reconstruction in a stationary CT system. The image-domain discriminator optimizes the generation network by comparing the generated CT images with the reference images, while the sinogram-domain discriminator preserves the structure of the sinograms and suppresses the noise. The network incorporates uncertainty to automatically adjust the weights of a multi-term loss function, eliminating the need for the manual tuning of hyperparameters in the loss function. The results from our numerical experiments demonstrate the effectiveness of our proposed reconstruction algorithm for low-dose imaging in stationary CT.},
booktitle = {Proceedings of the 2023 6th International Conference on Digital Medicine and Image Processing},
pages = {98–102},
numpages = {5},
keywords = {Deep learning, Dual-domain, Image reconstruction, Low-Dose CT, Stationary sources},
location = {Kyoto, Japan},
series = {DMIP '23}
}

@inproceedings{10.1145/3664190.3672514,
author = {Abdullahi, Tassallah and Singh, Ritambhara and Eickhoff, Carsten},
title = {Retrieval Augmented Zero-Shot Text Classification},
year = {2024},
isbn = {9798400706813},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664190.3672514},
doi = {10.1145/3664190.3672514},
abstract = {Zero-shot text learning enables text classifiers to handle unseen classes efficiently, alleviating the need for task-specific training data. A simple approach often relies on comparing embeddings of query (text) to those of potential classes. However, the embeddings of a simple query sometimes lack rich contextual information, which hinders the classification performance. Traditionally, this has been addressed by improving the embedding model with expensive training. We introduce QZero, a novel training-free knowledge augmentation approach that reformulates queries by retrieving supporting categories from Wikipedia to improve zero-shot text classification performance. Our experiments across six diverse datasets demonstrate that QZero enhances performance for state-of-the-art static and contextual embedding models without the need for retraining. Notably, in News and medical topic classification tasks, QZero improves the performance of even the largest OpenAI embedding model by at least 5% and 3%, respectively. Acting as a knowledge amplifier, QZero enables small word embedding models to achieve performance levels comparable to those of larger contextual models, offering the potential for significant computational savings. Additionally, QZero offers meaningful insights that illuminate query context and verify topic relevance, aiding in understanding model predictions. Overall, QZero improves embedding-based zero-shot classifiers while maintaining their simplicity. This makes it particularly valuable for resource-constrained environments and domains with constantly evolving information},
booktitle = {Proceedings of the 2024 ACM SIGIR International Conference on Theory of Information Retrieval},
pages = {195–203},
numpages = {9},
keywords = {query reformulation, retrieval augmented learning, text embeddings, zero-shot text classification},
location = {Washington DC, USA},
series = {ICTIR '24}
}

@article{10.1109/TASLP.2024.3436618,
author = {Chang, Kai-Wei and Wu, Haibin and Wang, Yu-Kai and Wu, Yuan-Kuei and Shen, Hua and Tseng, Wei-Cheng and Kang, Iu-Thing and Li, Shang-Wen and Lee, Hung-Yi},
title = {SpeechPrompt: Prompting Speech Language Models for Speech Processing Tasks},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3436618},
doi = {10.1109/TASLP.2024.3436618},
abstract = {Prompting has become a practical method for utilizing pre-trained language models (LMs). This approach offers several advantages. It allows an LM to adapt to new tasks with minimal training and parameter updates, thus achieving efficiency in both storage and computation. Additionally, prompting modifies only the LM's inputs and harnesses the generative capabilities of language models to address various downstream tasks in a unified manner. This significantly reduces the need for human labor in designing task-specific models. These advantages become even more evident as the number of tasks served by the LM scales up. Motivated by the strengths of prompting, we are the first to explore the potential of prompting speech LMs in the domain of speech processing. Recently, there has been a growing interest in converting speech into discrete units for language modeling. Our pioneer research demonstrates that these quantized speech units are highly versatile within our unified prompting framework. Not only can they serve as class labels, but they also contain rich phonetic information that can be re-synthesized back into speech signals for speech generation tasks. Specifically, we reformulate speech processing tasks into speech-to-unit generation tasks. As a result, we can seamlessly integrate tasks such as speech classification, sequence generation, and speech generation within a single, unified prompting framework. The experiment results show that the prompting method can achieve competitive performance compared to the strong fine-tuning method based on self-supervised learning models with a similar number of trainable parameters. The prompting method also shows promising results in the few-shot setting. Moreover, with the advanced speech LMs coming into the stage, the proposed prompting framework attains great potential.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = aug,
pages = {3730–3744},
numpages = {15}
}

@inproceedings{10.1145/3675094.3677575,
author = {Watanabe, Ko and Tanaka, Seiya and Vargo, Andrew and Kise, Koichi and Dengel, Andreas},
title = {Comparing Web Browsing Behaviors with High and Low Information Literacy: A Case Study for Fact Check Against GPT Generated Fake News},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677575},
doi = {10.1145/3675094.3677575},
abstract = {Generative AI has introduced significant concerns about how people interact with information in society, particularly regarding the potential harm caused by fake news. To address this issue, it is critical to understand how people perceive fake news and how their information literacy can be improved. Our research tackles two key questions: "Can we estimate the level of information literacy from participants' web browsing behavior?", and "What characteristics can be observed when comparing participants with high and low information literacy?". We recruited 20 university students to read and evaluate the veracity of generated news. During this process, participants used web searches to verify the news, with their browsing logs collected using the open-source browser extension TrackThink Camera. The study achieved a 73.8% accuracy in estimating participants' ability to detect fake news based on their web browsing behavior. Notably, we observed that web search time ratio is higher, the number of searches are more, and the average scrolling speed is faster for high information literacy participants.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {9–13},
numpages = {5},
keywords = {fake news, information literacy, machine learning, web browsing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3702250.3702280,
author = {Jaisankar, Vijay and Jayagopi, Dinesh Babu},
title = {Spectrogrand: Computational Creativity Driven Audiovisuals' Generation From Text Prompts},
year = {2025},
isbn = {9798400710759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702250.3702280},
doi = {10.1145/3702250.3702280},
abstract = {We explore the applicability of spectrograms in Deep learning applications and in guiding creative decisions. To this end, we propose Spectrogrand, a novel spectrogram-driven end-to-end Generative AI pipeline creating interesting audiovisuals from text prompts and incorporating lightweight computational creativity metrics. This process involves selecting a music piece to underpin the audiovisual, generating an album cover image for the music, and performing neural style transfer on spectrogram chunks to generate the frames for the audiovisual. To democratise the benefits of this pipeline, we open-source the tool, computational creativity metrics, and associated data&nbsp;1.},
booktitle = {Proceedings of the Fifteenth Indian Conference on Computer Vision Graphics and Image Processing},
articleno = {30},
numpages = {10},
keywords = {Computational creativity, Generative AI, Audiovisual generation, Spectrograms, Computer vision},
location = {
},
series = {ICVGIP '24}
}

@inproceedings{10.1145/3664647.3680936,
author = {Jiang-Lin, Jian-Yu and Huang, Kang-Yang and Lo, Ling and Huang, Yi-Ning and Lin, Terence and Wu, Jhih-Ciang and Shuai, Hong-Han and Cheng, Wen-Huang},
title = {ReCorD: Reasoning and Correcting Diffusion for HOI Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680936},
doi = {10.1145/3664647.3680936},
abstract = {Diffusion models revolutionize image generation by leveraging natural language to guide the creation of multimedia content. Despite significant advancements in such generative models, challenges persist in depicting detailed human-object interactions, especially regarding pose and object placement accuracy. We introduce a training-free method named Reasoning and Correcting Diffusion (ReCorD) to address these challenges. Our model couples Latent Diffusion Models with Visual Language Models to refine the generation process, ensuring precise depictions of HOIs. We propose an interaction-aware reasoning module to improve the interpretation of the interaction, along with an interaction correcting module to refine the output image for more precise HOI generation delicately. Through a meticulous process of pose selection and object positioning, ReCorD achieves superior fidelity in generated images while efficiently reducing computational requirements. We conduct comprehensive experiments on three benchmarks to demonstrate the significant progress in solving text-to-image generation tasks, showcasing ReCorD's ability to render complex interactions accurately by outperforming existing methods in HOI classification score, as well as FID and Verb CLIP-Score. Project website is available at https://alberthkyhky.github.io/ReCorD/.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9465–9474},
numpages = {10},
keywords = {diffusion model, human-object interaction, multimodal image generation, visual language model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1109/ASE56229.2023.00063,
author = {Zhang, Quanjun and Fang, Chunrong and Zhang, Tongke and Yu, Bowen and Sun, Weisong and Chen, Zhenyu},
title = {Gamma: Revisiting Template-based Automated Program Repair via Mask Prediction},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00063},
doi = {10.1109/ASE56229.2023.00063},
abstract = {Automated program repair (APR) aims to fix software bugs without manual debugging efforts and plays a crucial role in software development and maintenance. Template-based APR has been widely investigated and shown promising results. However, it is challenging for template-based APR to select the appropriate donor code, which is an important repair ingredient for generating candidate patches. Inappropriate donor code may cause plausible but incorrect patch generation even with correct fix patterns, limiting the repair performance.In this paper, we aim to revisit template-based APR, and propose Gamma, to directly leverage large pre-trained language models for donor code generation. Our main insight is that instead of retrieving donor code in the local buggy file, we can directly predict the correct code tokens based on the context code snippets and repair patterns by a cloze task. Specifically, (1) Gamma revises a variety of fix templates from state-of-the-art template-based APR techniques (i.e., TBar) and transforms them into mask patterns. (2) Gamma adopts a pre-trained language model to predict the correct code for masked code as a fill-in-the-blank task. Although our idea is general and can be built on various existing pre-trained language models, we have implemented Gamma as a practical APR tool based on the recent UniXcoder model. The experimental results demonstrate that Gamma correctly repairs 82 bugs on Defects4J-v1.2, which achieves 20.59% (14 bugs) and 26.15% (17 bugs) improvement over the previous state-of-the-art template-based approach TBar and learning-based one Recoder. Furthermore, Gamma repairs 45 bugs and 22 bugs from the additional Defects4J-v2.0 and QuixBugs, indicating the generalizability of Gamma in addressing the dataset overfitting issue. We also prove that adopting other pre-trained language models can provide substantial advancement, e.g., CodeBERT-based and ChatGPT-based Gamma is able to fix 80 and 67 bugs on Defects4J-v1.2, indicating the scalability of Gamma. Overall, our study highlights the promising future of adopting pre-trained models to generate correct patches on top of fix patterns in practice.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {535–547},
numpages = {13},
keywords = {automated program repair, fix pattern, pre-trained model, LLM4SE},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3649329.3656232,
author = {Mangalagiri, Prasanth and Qian, Lynn and Zafar, Farrukh and Mosalikanti, Praveen and Chang, Phoebe and Kurian, Arun and Saripalli, Vinay},
title = {CDLS: Constraint Driven Generative AI Framework for Analog Layout Synthesis},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3656232},
doi = {10.1145/3649329.3656232},
abstract = {In advanced process technology nodes, analog circuit performance is intrinsically linked to layout parasitics and layout dependent effects (LDE). In contrast to digital designs, layout generation for analog mixed signal circuits remains predominantly a slow manual task, impeding rapid design convergence. To address this bottleneck, we introduce CDLS - a Constraint Driven Generative AI Framework for Analog Layout Synthesis. CDLS is fundamentally a constraint driven framework that enables analog circuit designers to auto-generate simulation-ready layout. Unlike traditional algorithmic approaches, CDLS uses generative AI and machine learning techniques to generate key design constraints that drive the quality of autogenerated placement and routing. Using CDLS, on average we reduce layout iteration time by 2-3X on industrial designs. By reducing the turn-around-time on layout iterations we estimate a 30% reduction to overall design convergence cycle. We also demonstrate that the quality of results achieved through CDLS is on par with manually drawn layout on state-of-the-art analog designs developed on an Intel sub-10nm process technology node.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {80},
numpages = {6},
keywords = {analog layout synthesis, generative AI, machine learning, placement, routing, analog design convergence},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3634814.3634815,
author = {Qi, Zhixiao and Huang, Yongfeng and Wu, Jinzhu and Li, Songbin},
title = {FoodS and FoodIM: Food-Testing Item Recommendation Models for Two Different Users with Different Usage Abilities},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634815},
doi = {10.1145/3634814.3634815},
abstract = {Recommendation systems should adopt different recommendation strategies for different users' usage abilities. For the question of what testing items are required for a food, we have designed two food-testing item recommendation models, called Food Similarity recommendation (FoodS) and Food Testing Item Matching recommendation (FoodIM). FoodS is suitable for unprofessional users who are not aware of testing items. FoodS processes different attributes by different techniques to calculate the similarity between foods, and directly recommends the testing items of the most similar food as the results. FoodIM is suitable for professional users who are aware of testing items. FoodIM calculates the degree of matching between food and testing items through the two-tower structure, and recommends the testing items that match the food. We use macBERT for embedding in FoodIM and named entity recognition (NER) to enhance the representation of food. To improve inference speed, we use GPT-3 for data augmentation and obtain embedding by contrastive learning instead of macBERT. Our experiments on the food-testing item dataset show that both of our recommendation models outperform state-of-the-art methods.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {1–9},
numpages = {9},
keywords = {Food-testing item, Recommendation, Similarity, Two-tower structure},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

@article{10.1145/3687485,
author = {Ying, Wangyang and Wang, Dongjie and Chen, Haifeng and Fu, Yanjie},
title = {Feature Selection as Deep Sequential Generative Learning},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {1556-4681},
url = {https://doi.org/10.1145/3687485},
doi = {10.1145/3687485},
abstract = {Feature selection aims to identify the most pattern-discriminative feature subset. In prior literature, filter (e.g., backward elimination) and embedded (e.g., LASSO) methods have hyperparameters (e.g., top-k, score thresholding) and tie to specific models, thus, hard to generalize; wrapper methods search a feature subset in a huge discrete space and is computationally costly. To transform the way of feature selection, we regard a selected feature subset as a selection decision token sequence and reformulate feature selection as a deep sequential generative learning task that distills feature knowledge and generates decision sequences. Our method includes three steps: (1) We develop a deep variational transformer model over a joint of sequential reconstruction, variational, and performance evaluator losses. Our model can distill feature selection knowledge and learn a continuous embedding space to map feature selection decision sequences into embedding vectors associated with utility scores. (2) We leverage the trained feature subset utility evaluator as a gradient provider to guide the identification of the optimal feature subset embedding; (3) We decode the optimal feature subset embedding to autoregressively generate the best feature selection decision sequence with autostop. Extensive experimental results show this generative perspective is effective and generic, without large discrete search space and expert-specific hyperparameters. The code is available at .},
journal = {ACM Trans. Knowl. Discov. Data},
month = oct,
articleno = {221},
numpages = {21},
keywords = {Feature selection, automated feature engineering, deep sequential generative model}
}

@inproceedings{10.1145/3637528.3671645,
author = {Ren, Yuxin and Yang, Qiya and Wu, Yichun and Xu, Wei and Wang, Yalong and Zhang, Zhiqiang},
title = {Non-autoregressive Generative Models for Reranking Recommendation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671645},
doi = {10.1145/3637528.3671645},
abstract = {Contemporary recommendation systems are designed to meet users' needs by delivering tailored lists of items that align with their specific demands or interests. In a multi-stage recommendation system, reranking plays a crucial role by modeling the intra-list correlations among items. The key challenge of reranking lies in the exploration of optimal sequences within the combinatorial space of permutations. Recent research proposes a generator-evaluator learning paradigm, where the generator generates multiple feasible sequences and the evaluator picks out the best sequence based on the estimated listwise score. The generator is of vital importance, and generative models are well-suited for the generator function. Current generative models employ an autoregressive strategy for sequence generation. However, deploying autoregressive models in real-time industrial systems is challenging. Firstly, the generator can only generate the target items one by one and hence suffers from slow inference. Secondly, the discrepancy between training and inference brings an error accumulation. Lastly, the left-to-right generation overlooks information from succeeding items, leading to suboptimal performance.To address these issues, we propose a Non-AutoRegressive generative model for reranking Recommendation (NAR4Rec) designed to enhance efficiency and effectiveness. To tackle challenges such as sparse training samples and dynamic candidates, we introduce a matching model. Considering the diverse nature of user feedback, we employ a sequence-level unlikelihood training objective to differentiate feasible sequences from unfeasible ones. Additionally, to overcome the lack of dependency modeling in non-autoregressive models regarding target items, we introduce contrastive decoding to capture correlations among these items. Extensive offline experiments validate the superior performance of NAR4Rec over state-of-the-art reranking methods. Online A/B tests reveal that NAR4Rec significantly enhances the user experience. Furthermore, NAR4Rec has been fully deployed in a popular video app Kuaishou with over 300 million daily active users.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5625–5634},
numpages = {10},
keywords = {generative model, non-autoregressive models, recommender systems},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3663363,
author = {Chen, Shijie and Zhang, Yu and Yang, Qiang},
title = {Multi-Task Learning in Natural Language Processing: An Overview},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3663363},
doi = {10.1145/3663363},
abstract = {Deep learning approaches have achieved great success in the field of Natural Language Processing (NLP). However, directly training deep neural models often suffer from overfitting and data scarcity problems that are pervasive in NLP tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful information of related tasks to achieve simultaneous performance improvement on these tasks, has been used to handle these problems. In this article, we give an overview of the use of MTL in NLP tasks. We first review MTL architectures used in NLP tasks and categorize them into four classes, including parallel architecture, hierarchical architecture, modular architecture, and generative adversarial architecture. Then we present optimization techniques on loss construction, gradient regularization, data sampling, and task scheduling to properly train a multi-task model. After presenting applications of MTL in a variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a conclusion and discuss several possible research directions in this field.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {295},
numpages = {32},
keywords = {Multi-task learning}
}

@article{10.1145/3592762,
author = {Opipari, Anthony and Pavlasek, Jana and Chen, Chao and Wang, Shoutian and Desingh, Karthik and Jenkins, Odest Chadwicke},
title = {DNBP: Differentiable Nonparametric Belief Propagation},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3592762},
doi = {10.1145/3592762},
abstract = {We present a differentiable approach to learn the probabilistic factors used for inference by a nonparametric belief propagation algorithm. Existing nonparametric belief propagation methods rely on domain-specific features encoded in the probabilistic factors of a graphical model. In this work, we replace each crafted factor with a differentiable neural network, enabling the factors to be learned using an efficient optimization routine from labeled data. By combining differentiable neural networks with an efficient belief propagation algorithm, our method learns to maintain a set of marginal posterior samples using end-to-end training. We evaluate our differentiable nonparametric belief propagation (DNBP) method on a set of articulated pose tracking tasks and compare performance with learned baselines. Results from these experiments demonstrate the effectiveness of using learned factors for tracking and suggest the practical advantage over hand-crafted approaches. The project webpage is available at: .Problem statementNonparametric belief propagation (NBP) algorithms are a form of generative probabilistic inference that have proven effective for inference in visual perception tasks such as human pose tracking and articulated object tracking in robotic perception. The adaptability of NBP algorithms to new applications, however, is limited by the need to define hand-crafted functions that describe the distinct statistical relationships in a particular dataset. Current methods that utilize NBP rely on extensive domain knowledge to parameterize these relationships. Reducing the domain knowledge required by NBP methods would enable their use in a broader range of applications.MethodsA method is developed that combines the robustness of generative probabilistic inference with the speed, recall power, and general adaptability of discriminative neural networks. Inspired by differentiable Bayesian filters and the pull message passing for nonparametric belief propagation algorithm, a differentiable nonparametric belief propagation algorithm is proposed that performs end-to-end learning of each probabilistic factor required for graphical model inference.ResultsThe effectiveness of DNBP is demonstrated on two simulated articulated tracking tasks and on a real-world hand pose tracking task in noisy environments. An analysis of the learned probabilistic factors and resulting tracking performance is used to validate the approach.SignificanceThe results show that DNBP can leverage the graph structure to report uncertainty about its estimates while significantly reducing the need for prior domain knowledge required by previous NBP methods. This indicates that DNBP has the potential to be successfully applied to robotic perception tasks, where maintaining a notion of uncertainty throughout the inference is beneficial.},
journal = {ACM / IMS J. Data Sci.},
month = jan,
articleno = {3},
numpages = {24},
keywords = {Belief propagation, bayesian inference, nonparametric inference, robotic perception}
}

@article{10.1145/3659596,
author = {Hong, Zhiqing and Wang, Haotian and Ding, Yi and Wang, Guang and He, Tian and Zhang, Desheng},
title = {SmallMap: Low-cost Community Road Map Sensing with Uncertain Delivery Behavior},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659596},
doi = {10.1145/3659596},
abstract = {Accurate road networks play a crucial role in modern mobile applications such as navigation and last-mile delivery. Most existing studies primarily focus on generating road networks in open areas like main roads and avenues, but little attention has been given to the generation of community road networks in closed areas such as residential areas, which becomes more and more significant due to the growing demand for door-to-door services such as food delivery. This lack of research is primarily attributed to challenges related to sensing data availability and quality. In this paper, we design a novel framework called SmallMap that leverages ubiquitous multi-modal sensing data from last-mile delivery to automatically generate community road networks with low costs. Our SmallMap consists of two key modules: (1) a Trajectory of Interest Detection module enhanced by exploiting multi-modal sensing data collected from the delivery process; and (2) a Dual Spatio-temporal Generative Adversarial Network module that incorporates Trajectory of Interest by unsupervised road network adaptation to generate road networks automatically. To evaluate the effectiveness of SmallMap, we utilize a two-month dataset from one of the largest logistics companies in China. The extensive evaluation results demonstrate that our framework significantly outperforms state-of-the-art baselines, achieving a precision of 90.5%, a recall of 87.5%, and an F1-score of 88.9%, respectively. Moreover, we conduct three case studies in Beijing City for courier workload estimation, Estimated Time of Arrival (ETA) in last-mile delivery, and fine-grained order assignment.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {50},
numpages = {26},
keywords = {Community road network, Crowdsensing, Last-mile delivery, Mobile sensing}
}

@inproceedings{10.1145/3627673.3679770,
author = {Dong, Zhijun and Wu, Likang and Zhang, Kai and Liu, Ye and Zhang, Yanghai and Li, Zhi and Zhao, Hongke and Chen, Enhong},
title = {FZR: Enhancing Knowledge Transfer via Shared Factors Composition in Zero-Shot Relational Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679770},
doi = {10.1145/3627673.3679770},
abstract = {Zero-Shot Relational Learning (ZSRL), strives to predict relations that have not been observed during training, presenting a considerable challenge in terms of model generalization. Existing ZSRL methods usually utilize the prior knowledge of labels (e.g., text description, ontological schema) to enable knowledge transfer by learned features. Nonetheless, these methods remain limited to calculating the surface features exhibited by relations, failing to fully explore their underlying driving factors. This leads to insufficient discrimination between the shared and distinctive inherent components among relations, which consequently impedes the cognitive understanding required for advanced reasoning. In our study, we aim to identify and utilize shared factors that widely exist in the prior knowledge of classes to learn enhanced semantic representations via shared factors composition, and develop our Factor-based ZSRL framework (FZR) with Generative Adversarial Networks (GANs) to bridge inequality between seen and unseen classes. FZR is designed to restructure the semantic space in such a way that it captures the essence of relation formation, thereby facilitating superior knowledge transfer in zero-shot scenarios. We conduct extensive experiments and evaluate our model on real-world datasets, and the results clearly demonstrate the effectiveness of the proposed model in zero-shot relational learning tasks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {497–507},
numpages = {11},
keywords = {generative adversarial networks, knowledge transfer, shared factors, zero-shot relational learning},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3652037.3652076,
author = {Bhat, Rithesh and Jain, Bhanu},
title = {Stock Price Trend Prediction using Emotion Analysis of Financial Headlines with Distilled LLM Model},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3652076},
doi = {10.1145/3652037.3652076},
abstract = {Capturing the volatility of stock prices helps individual traders, stock analysts, and institutions alike increase their returns in the stock market. Financial news headlines have been shown to have a significant effect on stock price mobility. Lately, many financial portals have restricted web scraping of stock prices and other related financial data of companies from their websites. In this study we demonstrate that emotion analysis of financial news headlines alone can be sufficient in predicting stock price movement, even in the absence of any financial data. We propose an approach that eliminates the need for web scraping of financial data. We use API based mechanism to retrieve financial news headlines. In this study we train and subsequently leverage light and computationally fast Distilled LLM Model to gather emotional tone and strength of financial news headlines for companies. We then use this information with several machine learning-based classification algorithms to predict the stock price direction based solely on the emotion analysis of news. We demonstrate that emotion analysis-based attributes of financial news headlines are as accurate in predicting the price direction as running the algorithms with the financial data alone.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {67–73},
numpages = {7},
keywords = {Artifical Neural Network, Artificial intelligence, Distilled LLM., LLM, Random Forest, emotion analysis, logistic regression, machine learning, neural networks, sentiment analysis, stock price direction prediction, trend prediction},
location = {Crete, Greece},
series = {PETRA '24}
}

@article{10.1145/3664215,
author = {Robillard, Ga\"{e}tan and Nika, J\'{e}r\^{o}me},
title = {Critical Climate Machine: A Visual and Musical Exploration of Climate Misinformation through Machine Learning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3664215},
doi = {10.1145/3664215},
abstract = {Critical Climate Machine is a cutting-edge media art installation that critically exposes and quantifies mechanisms of climate change misinformation. Utilizing computational aesthetics across data, imagery, and sound, this work processes real-time data from X (Twitter) through a natural language processing learning model derived from cognitive sciences. It not only renders the statistical aspects of this data visually but also manifests its thermal effects. A unique audio dimension is introduced through dialogues between climate skeptics and climate advocates, processed by the generative machine learning (ML) algorithm Dicy2. These elements collectively shape the installation, each unveiling its distinctive algorithmic aesthetics and technical underpinnings. This paper concentrates on the dual application of ML algorithms: one for dissecting extensive online misinformation streams, and the other for creating climate-related dialogues. This dual approach opens a discussion on the mediation of climate, at the convergence of computational and physical realms. Our aim is to critically examine the role of ML technologies in crafting aesthetic experiences that resonate within scientific discourse and public debate on climate issues.},
journal = {Proc. ACM Comput. Graph. Interact. Tech.},
month = jul,
articleno = {56},
numpages = {11},
keywords = {Twitter, X, aesthetics, classification, climate change, dialogues, generative composition, machine learning, misinformation, music, sculpture, social network, sound, visualization}
}

@article{10.5555/3722577.3722929,
author = {Zhang, Chunming and Gao, Muhong and Jia, Shengji},
title = {DAG-informed structure learning from multi-dimensional point processes},
year = {2024},
issue_date = {January 2024},
publisher = {JMLR.org},
volume = {25},
number = {1},
issn = {1532-4435},
abstract = {Motivated by inferring causal relationships among neurons using ensemble spike train data, this paper introduces a new technique for learning the structure of a directed acyclic graph (DAG) within a large network of events, applicable to diverse multi-dimensional temporal point process (MuTPP) data. At the core of MuTPP lie the conditional intensity functions, for which we construct a generative model parameterized by the graph parameters of a DAG and develop an equality-constrained estimator, departing from exhaustive search-based methods. We present a novel, flexible augmented Lagrangian (Flex-AL) optimization scheme that ensures provable global convergence and computational efficiency gains over the classical AL algorithm. Additionally, we explore causal structure learning by integrating acyclicity-constraints and sparsity-regularization. We demonstrate: (i) in cases without regularization, the incorporation of the acyclicity constraint is essential for ensuring DAG recovery consistency; (ii) with suitable regularization, the DAG-constrained estimator achieves both parameter estimation and DAG reconstruction consistencies similar to the unconstrained counterpart, but significantly enhances empirical performance. Furthermore, simulation studies indicate that our proposed DAG-constrained estimator, when appropriately penalized, yields more accurate graphs compared to unconstrained or unregularized estimators. Finally, we apply the proposed method to two real MuTPP datasets.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {352},
numpages = {56},
keywords = {asymptotic consistency, causal structure, constrained optimization, multivariate counting process, structural Hamming distance}
}

@inproceedings{10.1145/3696409.3700202,
author = {Pilataki, Mary and Mauch, Matthias and Dixon, Simon},
title = {Pitch-aware generative pretraining improves multi-pitch estimation with scarce data},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696409.3700202},
doi = {10.1145/3696409.3700202},
abstract = {We demonstrate that pretrained generative models can learn representations that are useful for multi-pitch estimation. We explore representations extracted from DAC, a state-of-the-art audio compression model [24], which is based on VQ-GAN, an encoder-decoder architecture with vector quantisation. We propose pitch conditioning in the model’s latent space such that the learned embeddings are pitch-aware. To determine whether such representations are suitable for transcription, we use them as input features to train a shallow multi-pitch transcriber. We show that conditioning the encoder with ground truth pitch targets leads to substantially improved transcription results. These improvements hold true even when conditioning on noisy labels generated by an off-the-shelf music transcriber, eliminating the need for annotated data during pretraining. Specifically, pitch conditioning in the pretraining phase yields an absolute average improvement of 14.5% and 12.0% in framewise and notewise F-scores respectively across datasets.&nbsp;Furthermore, we show that our representation learning method facilitates efficient transfer learning since our downstream model’s performance is comparable to recent work even though it is trained on audio of a total duration of only 2 hours per dataset for 20 epochs. The source code of this work is available on Github 1.},
booktitle = {Proceedings of the 6th ACM International Conference on Multimedia in Asia},
articleno = {41},
numpages = {8},
keywords = {Music Transcription, Pitch Estimation, Music Information Retrieval, Audio Compression, Deep Learning},
location = {
},
series = {MMAsia '24}
}

@inproceedings{10.1145/3652988.3673934,
author = {Guichoux, T\'{e}o and Soulier, Laure and Obin, Nicolas and Pelachaud, Catherine},
title = {2D or not 2D: How Does the Dimensionality of Gesture Representation Affect 3D Co-Speech Gesture Generation?},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673934},
doi = {10.1145/3652988.3673934},
abstract = {Co-speech gestures are fundamental for communication. The advent of recent deep learning techniques has facilitated the creation of lifelike, synchronous co-speech gestures for Embodied Conversational Agents. "In-the-wild" datasets, aggregating video content from platforms like YouTube via human pose detection technologies, provide a feasible solution by offering 2D skeletal sequences aligned with speech. Concurrent developments in lifting models enable the conversion of these 2D sequences into 3D gesture databases. However, it is important to note that the 3D poses estimated from the 2D extracted poses are, in essence, approximations of the ground-truth, which remains in the 2D domain. This distinction raises questions about the impact of gesture representation dimensionality on the quality of generated motions. Our study examines the effect of using either 2D or 3D joint coordinates as training data on the performance of speech-to-gesture deep generative models.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {22},
numpages = {4},
keywords = {Co-speech gesture generation, Diffusion Models, Pose Representation, Sequence modeling},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@inproceedings{10.5555/3635637.3663028,
author = {Seo, Sangwon and Unhelkar, Vaibhav},
title = {IDIL: Imitation Learning of Intent-Driven Expert Behavior},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {When faced with accomplishing a task, human experts exhibit intentional behavior. Their unique intents shape their plans and decisions, resulting in experts demonstrating diverse behaviors to accomplish the same task. Due to the uncertainties encountered in the real world and their bounded rationality, experts sometimes adjust their intents, which in turn influences their behaviors during task execution. This paper introduces IDIL, a novel imitation learning algorithm to mimic these diverse intent-driven behaviors of experts. Iteratively, our approach estimates expert intent from heterogeneous demonstrations and then uses it to learn an intent-aware model of their behavior. Unlike contemporary approaches, IDIL is capable of addressing sequential tasks with high-dimensional state representations, while sidestepping the complexities and drawbacks associated with adversarial training (a mainstay of related techniques). Our empirical results suggest that the models generated by IDIL either match or surpass those produced by recent imitation learning benchmarks in metrics of task performance. Moreover, as it creates a generative model, IDIL demonstrates superior performance in intent inference metrics, crucial for human-agent interactions, and aptly captures a broad spectrum of expert behaviors.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {1673–1682},
numpages = {10},
keywords = {hierarchical imitation learning, human modeling, intention prediction},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3663976.3664026,
author = {Li, Jiasheng and Meng, Zaiqiao and Liang, Shangsong},
title = {Towards Deep Generative Backmapping of Coarse-Grained Molecular Systems},
year = {2024},
isbn = {9798400716607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663976.3664026},
doi = {10.1145/3663976.3664026},
abstract = {Coarse-graining (CG) is a widely used technique for simplifying complex molecular systems in molecular dynamics simulations. It involves mapping fine-grained (FG) atoms to several CG beads, which enables the study of larger systems and longer simulation timescales. However, this simplification results in the loss of atomistic details. To address this, a technique reverse to CG named backmapping is designed to recover the FG structures from CG beads. Traditional methods of backmapping yield poor reconstructions and often necessitate computationally costly refinement processes. Recently proposed deep learning approaches have shown promise in directly generating atomistic structures with high accuracy. One of the most advanced models deploys a conditional variational auto-encoder (VAE) to encode the FG uncertainties into an invariant latent space and decode them back to FG geometries via equivariant convolutions. Motivated by the recent advancements of diffusion models, we explore an alternative approach to capture the multimodal distribution of FG structures. In this study, we present CGDiff, an equivariant CG-conditional diffusion model for generative backmapping. It models the underlying distribution by condensing the FG information into geometric diffusion processes. Conditioned on CG beads, our model progressively refines the coordinates of FG atoms through equivariant graph neural networks. We evaluate the performance of CGDiff against baselines by conducting experiments on two public datasets. To further promote research in this field, we additionally provide a demo interactive web service for generative backmapping, available at https://huggingface.co/spaces/jsli47/mlbackmap.},
booktitle = {Proceedings of the 2024 2nd Asia Conference on Computer Vision, Image Processing and Pattern Recognition},
articleno = {41},
numpages = {7},
keywords = {Backmapping, Diffusion Model, Graph Neural Network},
location = {Xiamen, China},
series = {CVIPPR '24}
}

@inproceedings{10.1145/3664647.3685508,
author = {de la Torre-Ortiz, Carlos and Ruotsalo, Tuukka},
title = {Perceptual Visual Similarity from EEG: Prediction and Image Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3685508},
doi = {10.1145/3664647.3685508},
abstract = {Visual similarity estimation plays a fundamental role both in human cognition and multimedia information processing as it is the basis for many applications ranging from image search and recommendation to visual content generation. Existing computational models to assess visual similarity often diverge from human perception as they are typically trained solely on image data without information about how humans perceive image similarity. Here, we present an approach for learning perceptual visual similarity from brain recordings obtained via electroencephalogram (EEG). Our approach establishes a mapping between similarity reflected in the human cognitive system and a latent image representation. We evaluate the approach in two tasks. First, predicting visual distance from EEG data and second, adjusting a latent representation of a generative model to generate new images at a predicted distance from a given source image. Experiments demonstrate that the predicted distances from EEG closely align with the ground truth distances, and images generated using these predicted distances closely resemble the ground truth images. These findings open new possibilities for leveraging signals measured from human cognition to infer similarity as opposed to using only content-based models.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11146–11155},
numpages = {10},
keywords = {eeg, generative modeling, perceptual similarity},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681035,
author = {Zhai, Zhijun and Wang, Zengmao and Long, Xiaoxiao and Zhou, Kaixuan and Du, Bo},
title = {SAT3D: Image-driven Semantic Attribute Transfer in 3D},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681035},
doi = {10.1145/3664647.3681035},
abstract = {GAN-based image editing task aims at manipulating image attributes in the latent space of generative models. Most of the previous 2D and 3D-aware approaches mainly focus on editing attributes in images with ambiguous semantics or regions from a reference image, which fail to achieve photographic semantic attribute transfer, such as the beard from a photo of a man. In this paper, we propose an image-driven Semantic Attribute Transfer method in 3D (SAT3D) by editing semantic attributes from a reference image. For the proposed method, the exploration is conducted in the style space of a pre-trained 3D-aware StyleGAN-based generator by learning the correlations between semantic attributes and style code channels. For guidance, we associate each attribute with a set of phrase-based descriptor groups, and develop a Quantitative Measurement Module (QMM) to quantitatively describe the attribute characteristics in images based on descriptor groups, which leverages the image-text comprehension capability of CLIP. During the training process, the QMM is incorporated into attribute losses to calculate attribute similarity between images, guiding target semantic transferring and irrelevant semantics preserving. We present our 3D-aware attribute transfer results across multiple domains and also conduct comparisons with classical 2D image editing methods, demonstrating the effectiveness and customizability of our SAT3D.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10678–10687},
numpages = {10},
keywords = {3d, attribute transfer, image editing},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3613904.3642287,
author = {Chen, Si and Cheng, Haocong and Situ, Jason and Kirst, Desir\'{e}e and Su, Suzy and Malhotra, Saumya and Angrave, Lawrence and Wang, Qi and Huang, Yun},
title = {Towards Inclusive Video Commenting: Introducing Signmaku for the Deaf and Hard-of-Hearing},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642287},
doi = {10.1145/3613904.3642287},
abstract = {Previous research underscored the potential of danmaku–a text-based commenting feature on videos–in engaging hearing audiences. Yet, for many Deaf and hard-of-hearing (DHH) individuals, American Sign Language (ASL) takes precedence over English. To improve inclusivity, we introduce “Signmaku,” a new commenting mechanism that uses ASL, serving as a sign language counterpart to danmaku. Through a need-finding study (N=12) and a within-subject experiment (N=20), we evaluated three design styles: real human faces, cartoon-like figures, and robotic representations. The results showed that cartoon-like signmaku not only entertained but also encouraged participants to create and share ASL comments, with fewer privacy concerns compared to the other designs. Conversely, the robotic representations faced challenges in accurately depicting hand movements and facial expressions, resulting in higher cognitive demands on users. Signmaku featuring real human faces elicited the lowest cognitive load and was the most comprehensible among all three types. Our findings offered novel design implications for leveraging generative AI to create signmaku comments, enriching co-learning experiences for DHH individuals.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {56},
numpages = {18},
keywords = {DHH, Danmaku, Signmaku, Social Interactions},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3645259.3645277,
author = {Mahara, Arpan and Rishe, Naphtali D.},
title = {Generative Adversarial Model Equipped with Contrastive Learning in Map Synthesis},
year = {2024},
isbn = {9798400708473},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3645259.3645277},
doi = {10.1145/3645259.3645277},
abstract = {In the dynamic field of urban planning and the context of unprecedented natural events, such as hurricanes, the fast generation of accurate maps from satellite imagery is paramount. While several studies have utilized Generative Adversarial Networks (GANs) for map generation from satellite images, the present work introduces a new approach by integrating contrastive learning into the GAN framework for enhanced map synthesis. Our methodology distinctively employs positive sampling by aligning similar features (e.g., roads) in both satellite images and their corresponding map outputs, and contrasts this with negative samples for disparate elements. This approach effectively replaces the conventional cyclic process in GANs with a more streamlined, unidirectional procedure, leading to improvements in both the quality of the synthesized maps and computational efficiency. We show the effectiveness of our proposed model, offering an advancement in map generation for remote sensing applications.},
booktitle = {Proceedings of the 2024 6th International Conference on Image Processing and Machine Vision},
pages = {107–114},
numpages = {8},
keywords = {Anchor, Contrastive Learning, CycleGAN, Generation, Generative Adversarial Networks (GANs), Map, PatchNCE, Satellite Imagery, Synthesis},
location = {Macau, China},
series = {IPMV '24}
}

@inproceedings{10.1145/3664647.3688985,
author = {Wang, Yifan and Wu, Xuecheng and Zhang, Jia and Jing, Mohan and Lu, Keda and Yu, Jun and Su, Wen and Gao, Fang and Liu, Qingsong and Sun, Jianqing and Liang, Jiaen},
title = {Building Robust Video-Level Deepfake Detection via Audio-Visual Local-Global Interactions},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3688985},
doi = {10.1145/3664647.3688985},
abstract = {The continual advancements in Generative Artificial Intelligence have created substantial hurdles for accurate deepfake detection, leading to limitations of currently popular detection methods across content-driven video-level deepfake detection scenarios. In this paper, we present the solutions to the Video-Level Deepfake Detection task. Our empirical findings demonstrate that modeling correlations of audio-visual modalities is important for video-level deepfake detection. Therefore, we introduce the model denoted Audio-Visual Local-Global Neural Network (i.e., AV-LGNN) in which the core design is the proposed AV-LGI Module (Audio-Visual Local-Global Interaction Module). The AV-LGI Module is composed of three stages: Local Intra-Region Interaction, Global Inter-Region Interaction, and Local-Global Interaction, which can better capture detailed information at local-level and efficiently learn the fine-grained correlations of inter-modalities in video deepfake detection under lower computational overheads. We further propose an adaptive modality selection strategy to facilitate model learning. Besides, a variety of data augmentation techniques are incorporated for audio-visual branches to enhance the robustness of the AV-LGNN. The experimental results verify the effectiveness of our model.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {11370–11376},
numpages = {7},
keywords = {audio-viusal learning, deepfake detection, feature interactions},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3627673.3679532,
author = {Zhou, Jianping and Li, Junhao and Zheng, Guanjie and Wang, Xinbing and Zhou, Chenghu},
title = {MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679532},
doi = {10.1145/3627673.3679532},
abstract = {Missing values are prevalent in multivariate time series, compromising the integrity of analyses and degrading the performance of downstream tasks. Consequently, research has focused on multivariate time series imputation, aiming to accurately impute the missing values based on available observations. A key research question is how to ensure imputation consistency, i.e., intra-consistency between observed and imputed values, and inter-consistency between adjacent windows after imputation. However, previous methods rely solely on the inductive bias of the imputation targets to guide the learning process, ignoring imputation consistency and ultimately resulting in poor performance. Diffusion models, known for their powerful generative abilities, prefer to generate consistent results based on available observations. Therefore, we propose a conditional diffusion model for Multivariate Time Series Consistent Imputation (MTSCI). Specifically, MTSCI employs a contrastive complementary mask to generate dual views during the forward noising process. Then, the intra contrastive loss is calculated to ensure intra-consistency between the imputed and observed values. Meanwhile, MTSCI utilizes a mixup mechanism to incorporate conditional information from adjacent windows during the denoising process, facilitating the inter-consistency between imputed samples. Extensive experiments on multiple real-world datasets demonstrate that our method achieves the state-of-the-art performance on multivariate time series imputation task under different missing scenarios. Code is available at https://github.com/JeremyChou28/MTSCI.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3474–3483},
numpages = {10},
keywords = {inter consistency, intra consistency, multivariate time series imputation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3618260.3649777,
author = {Kalai, Adam Tauman and Vempala, Santosh S.},
title = {Calibrated Language Models Must Hallucinate},
year = {2024},
isbn = {9798400703836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3618260.3649777},
doi = {10.1145/3618260.3649777},
abstract = {Recent language models generate false but plausible-sounding text with surprising frequency. Such “hallucinations” are an obstacle to the usability of language-based AI systems and can harm people 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
who rely upon their outputs. This work shows that there is an inherent statistical lower-bound on the rate that pretrained language models hallucinate certain types of facts, having nothing to do with the transformer LM architecture or data quality. For “arbitrary” facts whose veracity cannot be determined from the training data, we show that hallucinations must occur at a certain rate for language models that satisfy a statistical calibration condition appropriate for generative language models. Specifically, if the maximum probability of any fact is bounded, we show that the probability of generating a hallucination is close to the fraction of facts that occur exactly once in the training data (a “Good-Turing” estimate), even assuming ideal training data without errors. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
One conclusion is that models pretrained to be sufficiently good predictors (i.e., calibrated) may require post-training to mitigate hallucinations on the type of arbitrary facts that tend to appear once in the training set. However, our analysis also suggests that there is no statistical reason that pretraining will lead to hallucination on facts that tend to appear more than once in the training data (like references to publications such as articles and books, whose hallucinations have been particularly notable and problematic) or on systematic facts (like arithmetic calculations). Therefore, different architectures and learning algorithms may mitigate these latter 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
types of hallucinations.},
booktitle = {Proceedings of the 56th Annual ACM Symposium on Theory of Computing},
pages = {160–171},
numpages = {12},
keywords = {Calibration, Good-Turing Estimator, Hallucination, Language Models},
location = {Vancouver, BC, Canada},
series = {STOC 2024}
}

@inproceedings{10.1145/3674829.3675358,
author = {Hess-Dunlop, Adam and Kakani, Harshitha and Josephson, Colleen},
title = {Towards Deep Learning for Predicting Microbial Fuel Cell Energy Output},
year = {2024},
isbn = {9798400710483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674829.3675358},
doi = {10.1145/3674829.3675358},
abstract = {Soil microbial fuel cells (SMFCs) are an emerging technology which offer clean and renewable energy in environments where more traditional power sources, such as chemical batteries or solar, are not suitable. With further development, SMFCs show great promise for use in robust and affordable outdoor sensor networks, particularly for farmers. One of the greatest challenges in the development of this technology is understanding and predicting the fluctuations of SMFC energy generation, as the electro-generative process is not yet fully understood. Very little work currently exists attempting to model and predict the relationship between soil conditions and SMFC energy generation, and we are the first to use machine learning to do so. In this paper, we train Long Short Term Memory (LSTM) models to predict the future energy generation of SMFCs across timescales ranging from 3 minutes to 1 hour, with results ranging from 2.33% to 5.71% MAPE for median voltage prediction. For each timescale, we use quantile regression to obtain point estimates and to establish bounds on the uncertainty of these estimates. When comparing the median predicted vs. actual values for the total energy generated during the testing period, the magnitude of prediction errors ranged from 2.29% to 16.05%. To demonstrate the real-world utility of this research, we also simulate how the models could be used in an automated environment where SMFC-powered devices shut down and activate intermittently to preserve charge, with promising initial results. Our deep learning-based prediction and simulation framework would allow a fully automated SMFC-powered device to achieve a median 100+% increase in successful operations, compared to a naive model that schedules operations based on the average voltage generated in the past.},
booktitle = {Proceedings of the 7th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
pages = {330–338},
numpages = {9},
keywords = {Deep Learning, Energy Prediction, Intermittent Computing, Long Short Term Memory (LSTM), Microbial Fuel Cells, Predictive Modeling, Quantile Regression, Soil Microbial Fuel Cells, Time-Series Analysis},
location = {New Delhi, India},
series = {COMPASS '24}
}

@inproceedings{10.1145/3664647.3681193,
author = {Lin, Junyu and Zheng, Yan and Chen, Xinyue and Ren, Yazhou and Pu, Xiaorong and He, Jing},
title = {Cross-view Contrastive Unification Guides Generative Pretraining for Molecular Property Prediction},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681193},
doi = {10.1145/3664647.3681193},
abstract = {Multi-view based molecular properties prediction learning has received widely attention in recent years in terms of its potential for the downstream tasks in the field of drug discovery. However, the consistency of different molecular view representations and the full utilization of complementary information among them in existing multi-view molecular property prediction methods remain to be further explored. Furthermore, most current methods focus on generating global level representations at the graph level with information from different molecular views (e.g., 2D and 3D views) assuming that the information can be corresponded to each other. In fact it is not unusual that for example the conformation change or computational errors may lead to discrepancies between views. To addressing these issues, we propose a new Cross-View contrastive unification guides Generative Molcular pre-trained model, call MolCVG. We first focus on common and private information extraction from 2D graph views and 3D geometric views of molecules, Minimizing the impact of noise in private information on subsequent strategies. To exploit both types of information in a more refined way, we propose a cross-view contrastive unification strategy to learn cross-view global information and guide the reconstruction of masked nodes, thus effectively optimizing global features and local descriptions. Extensive experiments on real-world molecular data sets demonstrate the effectiveness of our approach for molecular property prediction task.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2108–2116},
numpages = {9},
keywords = {molecular property prediction, multi-view learning, self-supervised learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3638529.3654039,
author = {Bishop, Jordan T and Jooste, Jason and Howard, David},
title = {Evolutionary Exploration of Triply Periodic Minimal Surfaces via Quality Diversity},
year = {2024},
isbn = {9798400704949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638529.3654039},
doi = {10.1145/3638529.3654039},
abstract = {Triply Periodic Minimal Surfaces (TPMSs) are a family of mathematical structures that exhibit constant zero mean curvature and 3-dimensional periodicity. They are often used to produce cellular solids with advantageous structural, thermal, and optical properties. Existing applications represent TPMSs as trigonometric approximations of a Fourier series. Due to the mathematical difficulty of determining new exact forms and their approximations, previous work has mostly evaluated metrics based on geometry, manufacturability, and mechanical performance across parameterisations of a small set of known TPMS equations. In this work, we define TPMS-like structures as having low estimated mean curvature, and apply a coupling of Grammatical Evolution and Quality Diversity to generate a diverse set of novel structures of this kind. We additionally explore the effect of being TPMS-like on the manufacturability of evolved structures. Results show that many TPMS-like designs can be found for different combinations of total surface area and Gaussian curvature, and that there is not a strong relationship between how TPMS-like a design is and its manufacturability. Our method serves as a basis for future application of novel TPMS-like structures and exploration of the pairing of evolutionary design with generative approaches from broader machine learning.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1165–1173},
numpages = {9},
keywords = {triply periodic minimal surface, quality diversity, grammatical evolution, evolutionary design, constrained optimisation},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{10.1145/3664647.3681060,
author = {Xu, Bo and Zheng, Junzhe and He, Jiayuan and Sun, Yuxuan and Lin, Hongfei and Zhao, Liang and Xia, Feng},
title = {Generating Multimodal Metaphorical Features for Meme Understanding},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681060},
doi = {10.1145/3664647.3681060},
abstract = {Understanding a meme is a challenging task, due to the metaphorical information contained in the meme that requires intricate interpretation to grasp its intended meaning fully. In previous works, attempts have been made to facilitate computational understanding of memes through introducing human-annotated metaphors as extra input features into machine learning models. However, these approaches mainly focus on formulating linguistic representation of a metaphor (extracted from the texts appearing in memes), while ignoring the connection between the metaphor and corresponding visual features (e.g., objects in meme images). In this paper, we argue that a more comprehensive understanding of memes can only be achieved through a joint modelling of both visual and linguistic features of memes. To this end, we propose an approach to generate Multimodal Metaphorical feature for Meme Classification, named MMMC. MMMC derives visual characteristics from linguistic attributes of metaphorical concepts, which more effectively convey the underlying metaphorical concept, leveraging a text-conditioned generative adversarial network. The linguistic and visual features are then integrated into a set of multimodal metaphorical features for classification purpose. We perform extensive experiments on a benchmark metaphorical meme dataset, MET-Meme. Experimental results show that MMMC significantly outperforms existing baselines on the task of emotion classification and intention detection. Our code and dataset are available at https://github.com/liaolianfoka/MMMC.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {447–455},
numpages = {9},
keywords = {meme understanding, metaphor, multimodal},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3696400,
author = {Sun, Chuanhao and Xu, Kai and Antichi, Gianni and Marina, Mahesh K.},
title = {NetGSR: Towards Efficient and Reliable Network Monitoring with Generative Super Resolution},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT4},
url = {https://doi.org/10.1145/3696400},
doi = {10.1145/3696400},
abstract = {Network monitoring systems are a key building block in today's networks. They all follow a common framework where measurement data from network elements is aggregated at a central collector for network-wide visibility. When designing network monitoring systems, two key properties have to be taken into account: (1) efficiency, to minimize the communication overhead from network elements to the collector; (2) high-fidelity, to faithfully represent the network status. However, in presence of network dynamics, tracking the right operating point to ensure both high fidelity and efficiency is hard and we observe that prior monitoring approaches trade off one for the other. In this paper, we show that it is possible to satisfy both these properties with NetGSR, a new deep learning based solution we introduce that reconstructs the fine-grained behavior of network status at the collector while requiring low resolution measurement data from network elements. This is achieved through a combination of a new custom-tailored conditional deep generative model (DistilGAN), and a new feedback mechanism (Xaminer) based on model uncertainty estimation and denoising that allows the collector to adjust the sampling rate for measurement data from network elements, at run-time. We extensively evaluate NetGSR using three different network scenarios with corresponding real-world network monitoring datasets as well as two downstream use cases. We show that NetGSR can faithfully reconstruct fine-grained network status with 25x greater measurement efficiency than prior approaches while requiring only few ms of inference time at the collector.},
journal = {Proc. ACM Netw.},
month = nov,
articleno = {29},
numpages = {27},
keywords = {deep learning, generative models, uncertainty estimation}
}

@inproceedings{10.1145/3662739.3672304,
author = {Jin, Huijiao and Wang, Fei and Jiang, Lanying and Tian, Meng},
title = {Application of CNN in Visual Image Design: Image Feature Extraction and Processing},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3672304},
doi = {10.1145/3662739.3672304},
abstract = {Abstract: In response to the problems of insufficient personalization and unclear feature extraction in traditional visual image design, this paper studied an image feature extraction and processing method based on CNN (Convolutional Neural Networks). Firstly, the images were preprocessed and enhanced to enhance the generalization ability and feature extraction performance of the CNN model; a lightweight CNN architecture and MobileNet (Mobile Network) were designed to reduce computational complexity and parameters, and the model was optimized through technical means; generative adversarial networks (GANs) were utilized to integrate creative elements and enhance the innovation of advertising design. Through transfer learning, the CNN model was adjusted, and the Adam optimizer and early stop strategy were adopted for model training and optimization. In the experiment of feature extraction accuracy, the accuracy of the model in this paper reached 98.8%, 97.8%, and 98%, and it was also better than the comparison model in the comparative experiment. In the generalization ability test, the model did not overfit and demonstrated good generalization ability; in the processing time test, the architecture used in this paper had a shorter processing time than other architectures; in the survey on the integration effect of creative elements, the attractiveness rating reached 96% of the positive reviews.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {569–573},
numpages = {5},
keywords = {Convolutional Neural Networks, Generative Adversarial Networks, Image Feature Extraction and Processing, Mobile Network, Visual Image Design},
location = {Ningbo, China},
series = {MIDA '24}
}

@article{10.1145/3653712,
author = {Tang, Yubao and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Cheng, Xueqi},
title = {Listwise Generative Retrieval Models via a Sequential Learning Process},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3653712},
doi = {10.1145/3653712},
abstract = {Recently, a novel generative retrieval (GR) paradigm has been proposed, where a single sequence-to-sequence model is learned to directly generate a list of relevant document identifiers (docids) given a query. Existing GR models commonly employ maximum likelihood estimation (MLE) for optimization: This involves maximizing the likelihood of a single relevant docid given an input query, with the assumption that the likelihood for each docid is independent of the other docids in the list. We refer to these models as the pointwise approach in this article. While the pointwise approach has been shown to be effective in the context of GR, it is considered sub-optimal due to its disregard for the fundamental principle that ranking involves making predictions about lists. In this article, we address this limitation by introducing an alternative listwise approach, which empowers the GR model to optimize the relevance at the docid list level. Specifically, we view the generation of a ranked docid list as a sequence learning process: At each step, we learn a subset of parameters that maximizes the corresponding generation likelihood of the ith docid given the (preceding) top i-1 docids. To formalize the sequence learning process, we design a positional conditional probability for GR. To alleviate the potential impact of beam search on the generation quality during inference, we perform relevance calibration on the generation likelihood of model-generated docids according to relevance grades. We conduct extensive experiments on representative binary and multi-graded relevance datasets. Our empirical results demonstrate that our method outperforms state-of-the-art GR baselines in terms of retrieval performance.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
articleno = {133},
numpages = {31},
keywords = {Document retrieval, generative retrieval, listwise approach}
}

@inproceedings{10.1145/3616855.3635807,
author = {Wang, Yuhao and Liu, Ziru and Wang, Yichao and Zhao, Xiangyu and Chen, Bo and Guo, Huifeng and Tang, Ruiming},
title = {Diff-MSR: A Diffusion Model Enhanced Paradigm for Cold-Start Multi-Scenario Recommendation},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635807},
doi = {10.1145/3616855.3635807},
abstract = {With the explosive growth of various commercial scenarios, there is an increasing number of studies on multi-scenario recommendation (MSR) which trains the recommender system with the data from multiple scenarios, aiming to improve the recommendation performance on all these scenarios synchronously. However, due to the large discrepancy in the number of interactions among domains, multi-scenario recommendation models usually suffer from insufficient learning and negative transfer especially on the cold-start scenarios, thus exacerbating the data sparsity issue. To fill this gap, in this work we propose a novel diffusion model enhanced paradigm tailored for the cold-start problem in multi-scenario recommendation in a data-driven generative manner. Specifically, based on all-domain data, we leverage the diffusion model with our newly designed variance schedule and the proposed classifier, which explicitly boosts the recommendation performance on the cold-start scenarios by exploiting the generated high-quality and informative embedding, leveraging the abundance of rich scenarios. Our experiments on Douban and Amazon datasets demonstrate two strengths of the proposed paradigm: (i) its effectiveness with a significant increase of 8.5% and 1% in accuracy on the two datasets, and (ii) its compatibility with various multi-scenario backbone models. The implementation code is available for easy reproduction.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {779–787},
numpages = {9},
keywords = {click-through rate prediction, cold-start, diffusion model, multi-domain, multi-scenario recommendation},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3595916.3626402,
author = {Leng, Yipeng and Huang, Qiangjuan and Wang, Zhiyuan and Liu, Yangyang and Zhang, Haoyu},
title = {DiffuseGAE: Controllable and High-fidelity Image Manipulation from Disentangled Representation},
year = {2024},
isbn = {9798400702051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3595916.3626402},
doi = {10.1145/3595916.3626402},
abstract = {Diffusion probabilistic models (DPMs) have shown remarkable results on various image synthesis tasks such as text-to-image generation and image inpainting. However, compared to other generative methods like VAEs and GANs, DPMs lack a low-dimensional, interpretable, and well-decoupled latent code. Recently, diffusion autoencoders (Diff-AE) were proposed to explore the potential of DPMs for representation learning via autoencoding. Diff-AE provides an accessible latent space that exhibits remarkable interpretability, allowing us to manipulate image attributes based on latent codes from the space. However, previous works are not generic as they only operated on a few limited attributes. To further explore the latent space of Diff-AE and achieve a generic editing pipeline, we proposed a module called Group-supervised AutoEncoder(dubbed GAE) for Diff-AE to achieve better disentanglement on the latent code. Our proposed GAE has trained via an attribute-swap strategy to acquire the latent codes for multi-attribute image manipulation based on examples. We empirically demonstrate that our method enables multiple-attributes manipulation and achieves convincing sample quality and attribute alignments, while significantly reducing computational requirements compared to pixel-based approaches for representational decoupling.},
booktitle = {Proceedings of the 5th ACM International Conference on Multimedia in Asia},
articleno = {30},
numpages = {7},
keywords = {Deep generative models, Image manipulation., Representation learning},
location = {Tainan, Taiwan},
series = {MMAsia '23}
}

@inproceedings{10.1145/3634737.3645006,
author = {Murodova, Nozima and Koo, Hyungjoon},
title = {BinAdapter: Leveraging Continual Learning for Inferring Function Symbol Names in a Binary},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3645006},
doi = {10.1145/3634737.3645006},
abstract = {Binary reverse engineering is crucial to gaining insights into the inner workings of a stripped binary. Yet, it is challenging to read the original semantics from a binary code snippet because of the unavailability of high-level information in the source, such as function names, variable names, and types. Recent advancements in deep learning show the possibility of recovering such vanished information with a well-trained model from a pre-defined dataset. Albeit a static model's notable performance, it can hardly cope with an ever-increasing data stream (e.g., compiled binaries) by nature. The two viable approaches for ceaseless learning are retraining the whole dataset from scratch and fine-tuning a pre-trained model; however, retraining suffers from large computational overheads and fine-tuning from performance degradation (i.e., catastrophic forgetting). Lately, continual learning (CL) tackles the problem of handling incremental data in security domains (e.g., network intrusion detection, malware detection) using reasonable resources while maintaining performance in practice.In this paper, we focus on how CL assists in the improvement of a generative model that predicts a function symbol name from a series of machine instructions. To this end, we introduce BinAdapter, a system that can infer function names from an incremental dataset without performance degradation from an original dataset by leveraging CL techniques. Our major finding shows that incremental tokens in the source (i.e., machine instructions) or the target (i.e., function names) largely affect the overall performance of a CL-enabled model. Accordingly, BinAdapter adopts three built-in approaches: [EQUATION] inserting adapters in case of no incremental tokens in both the source and target, [EQUATION] harnessing multilingual neural machine translation (M-NMT) and fine-tuning the source embeddings with [EQUATION] in case of incremental tokens in the source, and [EQUATION] fine-tuning target embeddings with [EQUATION] in case of incremental tokens in both. To demonstrate the effectiveness of BinAdapter, we evaluate the above three scenarios using incremental datasets with or without a set of new tokens (e.g., unseen machine instructions or function names), spanning across different architectures and optimization levels. Our empirical results show that BinAdapter outperforms the state-of-the-art CL techniques for an F1 of up to 24.3% or a Rouge-l of 21.5% in performance.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1200–1213},
numpages = {14},
keywords = {binary analysis, software security, reverse engineering, continual learning},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

@inproceedings{10.1145/3690063.3690064,
author = {Arshad, Tania and Khan, Muhammad Hassan and Farid, Muhammad Shahid},
title = {An Efficient Framework to Recognize Deepfake Faces using a Light-weight CNN},
year = {2024},
isbn = {9798400716911},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690063.3690064},
doi = {10.1145/3690063.3690064},
abstract = {Deepfakes are synthetically generated images or videos in which a person’s body parts (e.g., face) are replaced with someone else. Such visual content can be used to easily deceive human beings. Hence, it becomes very difficult to distinguish between the real and the bogus content by having a glimpse of the images. Numerous research efforts have been made in this domain to understand how deepfakes work and how they can be distinguished from real images. The existing techniques either exploit the handcrafted features that demand the in-depth knowledge and the expertise of researchers; or fully automatic deep learning techniques which are computationally expensive. With the increase in photo-realistic deepfakes over time, the advancement in the existing detection techniques has become the need of the hour. This paper presents an end-to-end framework for deepfake face image detection. The proposed deep network is based on a simple yet effective Convolutional Neural Network (CNN) for the detection of falseness in the images precisely and efficiently. Usually, these fake visual contents are generated using the Generative Adversarial Network (GAN). The convolution process of the proposed deep network extracts the spatial features that help to trace the effects of GAN on the edges of fake images. The proposed algorithm is evaluated on a large publicly available dataset, and it achieved 95% recognition accuracy. It takes 0.0024 seconds to detect the fakeness in the image.},
booktitle = {Proceedings of the 2024 9th International Conference on Multimedia Systems and Signal Processing (ICMSSP)},
pages = {24–29},
numpages = {6},
keywords = {Deepfakes, Fake images, Generative Adversarial Network, Convolutional Neural Network},
location = {
},
series = {ICMSSP '24}
}

@article{10.5555/3722577.3722775,
author = {Awaya, Naoki and Ma, Li},
title = {Unsupervised tree boosting for learning probability distributions},
year = {2024},
issue_date = {January 2024},
publisher = {JMLR.org},
volume = {25},
number = {1},
issn = {1532-4435},
abstract = {We propose an unsupervised tree boosting algorithm for inferring the underlying sampling distribution of an i.i.d. sample based on fitting additive tree ensembles in a manner analogous to supervised tree boosting. Integral to the algorithm is a new notion of "addition" on probability distributions that leads to a coherent notion of "residualization", i.e., subtracting a probability distribution from an observation to remove the distributional structure from the sampling distribution of the latter. We show that these notions arise naturally for univariate distributions through cumulative distribution function (CDF) transforms and compositions due to several "group-like" properties of univariate CDFs. While the traditional multivariate CDF does not preserve these properties, a new definition of multivariate CDF can restore these properties, thereby allowing the notions of "addition" and "residualization" to be formulated for multivariate settings as well. This then gives rise to the unsupervised boosting algorithm based on forward-stagewise fitting of an additive tree ensemble, which sequentially reduces the Kullback-Leibler divergence from the truth. The algorithm allows analytic evaluation of the fitted density and outputs a generative model that can be readily sampled from. We enhance the algorithm with scale-dependent shrinkage and a two-stage strategy that separately fits the marginals and the copula. The algorithm then performs competitively with state-of-the-art deep-learning approaches in multivariate density estimation on multiple benchmark data sets.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {198},
numpages = {52},
keywords = {generative models, normalizing flows, additive models, density estimation, ensemble methods, recursive partitioning}
}

@inproceedings{10.1145/3637528.3671476,
author = {Bagherjeiran, Abraham and Djuric, Nemanja and Lee, Kuang-Chih and Pang, Linsey and Radosavljevic, Vladan and Rajan, Suju},
title = {AdKDD 2024},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671476},
doi = {10.1145/3637528.3671476},
abstract = {The digital advertising field has always had challenging ML problems, learning from petabytes of data that is highly imbalanced, reactivity times in the milliseconds, and more recently compounded with the complex user's path to purchase across devices, across platforms, and even online/real-world behavior. The AdKDD workshop continues to be a forum for researchers in advertising, during and after KDD. Our website which hosts slides and abstracts receives approximately 2,000 monthly visits and 1,800 active users during the KDD 2021. In surveys during AdKDD 2019 and 2020, over 60% agreed that AdKDD is the reason they attended KDD, and over 90% indicated they would attend next year. The 2024 edition is particularly timely because of the increasing application of Graph-based NN and Generative AI models in advertising. Coupled with privacy-preserving initiatives enforced by GDPR, CCPA the future of computational advertising is at an interesting crossroads. For this edition, we plan to solicit papers that span the spectrum of deep user understanding while remaining privacy-preserving. In addition, we will seek papers that discuss fairness in the context of advertising, to what extent does hyper-personalization work, and whether the ad industry as a whole needs to think through more effective business models such as incrementality. We have hosted several academic and industry luminaries as keynote speakers and have found our invited speaker series hosting expert practitioners to be an audience favorite. We will continue fielding a diverse set of keynote speakers and invited talks for this edition as well. As with past editions, we hope to motivate researchers in this space to think not only about the ML aspects but also to spark conversations about the societal impact of online advertising.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6706–6707},
numpages = {2},
keywords = {ad targeting, computational advertising, user modeling},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3715669.3725868,
author = {Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban},
title = {Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3725868},
doi = {10.1145/3715669.3725868},
abstract = {As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {80},
numpages = {8},
keywords = {Code Summarization, Eye tracking, empirical study, code comprehension, Large Language Models, AI4SE},
location = {
},
series = {ETRA '25}
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3702212.3702214,
author = {Clift, Lee and Petrovska, Olga},
title = {Learning without Limits: Analysing the Usage of Generative AI in a Summative Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702214},
doi = {10.1145/3702212.3702214},
abstract = {This paper explores how Generative AI (GenAI) can be introduced within summative assessment components in software engineering education. We present an example of an assessment which allows learners to use GenAI in a freeform, constructionist manner, as part of a large, software development project. This work is inspired by previously executed AI-focused assessments and surveys, which explicitly indicate that learners on an Applied Software Engineering Degree Apprenticeship Programme want to formally learn how to use GenAI tools when programming and their employers want to see these skills from graduates. The learning outcome of the assignment was for learners to explore a typical developmental pipeline as a solo developer, moving from design to development to finished product. Learners were marked exclusively on their end product and understanding of application components, not the written code itself, resulting in an assessment where the end product and project were prioritised over foundational code (which was adequately assessed in other components). The results show that all learners used GenAI to some extent during their project, and in all cases, they found it beneficial for large programming tasks. Learners were generally able to produce a larger, more comprehensive and more ambitious project, compared to previous years. It is proposed that removing the barrier to GenAI - and demystifying it - can encourage a constructionist approach to its use, and normalise it as a potential tool for programming.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {5–8},
numpages = {4},
keywords = {GenAI, software engineering, education, apprenticeship},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3706599.3720282,
author = {Mhasakar, Manas and Baker-Ramos, Rachel and Carter, Benjamin and Helekahi-Kaiwi, Evyn-Bree and Hester, Josiah},
title = {"I Would Never Trust Anything Western": Kumu (Educator) Perspectives on Use of LLMs for Culturally Revitalizing CS Education in Hawaiian Schools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720282},
doi = {10.1145/3706599.3720282},
abstract = {As large language models (LLMs) become increasingly integrated into educational technology, their potential to assist in developing curricula has gained interest among educators. Despite this growing attention, their applicability in culturally responsive Indigenous educational settings like Hawai‘i’s public schools and Kaiapuni (immersion language) programs, remains understudied. Additionally, ‘undefinedlelo Hawai‘i, the Hawaiian language, as a low-resource language, poses unique challenges and concerns about cultural sensitivity and the reliability of generated content. Through surveys and interviews with kumu (educators), this study explores the perceived benefits and limitations of using LLMs for culturally revitalizing computer science (CS) education in Hawaiian public schools with Kaiapuni programs. Our findings highlight AI’s time-saving advantages while exposing challenges such as cultural misalignment and reliability concerns. We conclude with design recommendations for future AI tools to better align with Hawaiian cultural values and pedagogical practices, towards the broader goal of trustworthy, effective, and culturally grounded AI technologies.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {13},
numpages = {10},
keywords = {Culturally responsive pedagogy, Artificial Intelligence in education, Culturally-relevant CS, Hawaiian Immersion Language Schools, Large Language Models, Human-centered AI, Education technology, Indigenous knowledge, Low-resource languages},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701867,
author = {Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi},
title = {Bridging Novice Programmers and LLMs with Interactivity},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701867},
doi = {10.1145/3641554.3701867},
abstract = {While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1295–1301},
numpages = {7},
keywords = {cs1, generative ai, llms, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3705734,
author = {George, Amrita and Storey, Veda Catherine and Hong, Shuguang},
title = {Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3705734},
doi = {10.1145/3705734},
abstract = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {4},
numpages = {30},
keywords = {ChatGPT, Large language model (LLM), technology self-efficacy, computer anxiety, goal orientation, computer playfulness, social support, technology anchors, generative AI, knowledge anchor, OpenAI, technology anchors, artificial intelligence (AI), achievement theory}
}

@inproceedings{10.5555/3712729.3712987,
author = {Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.},
title = {Understanding Optimal Interactions between Students and a Chatbot during a Programming Task},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3106–3117},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3641555.3705080,
author = {Morales, Jamie and Raman, Preeti},
title = {Prompt-Engineering Strategies for Minimizing Bias in Large Language Model Outputs: Applications in Computing Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705080},
doi = {10.1145/3641555.3705080},
abstract = {As large language models (LLMs) increasingly permeate educational applications, concerns about the perpetuation of bias persist. We present our preliminary work on developing prompt-engineering strategies to mitigate bias in content generated by LLMs in computer science (CS) education. This work investigates both empirical insights into fairness-aware prompt formulation and actionable takeaways for educators. We focus on an initial list of prompting strategies for mitigating bias and explore their impact on educational content generation. Recent research has shown the efficacy of prompt-base debiasing [1] as well as the potential disadvantages of using prompts that have not been mitigated for bias, from user dissatisfaction [2] to unsafe outputs [5, 6]. Additionally, a growing body of empirical work points to the idea that certain properties of in-context examples such as flow [7], illustration [3], and order [4] could either improve or derail LLM performance. Our study leverages these findings in the context of generating educational content. The goal is to promote fairness-aware approaches which can be applied to the automated generation of learning materials and the development of LLM-based educational tools. This work also contributes practical insights on prompt-engineering to the evolving curriculum of Ethics in Artificial Intelligence (AI).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1743},
numpages = {1},
keywords = {bias, education, ethics, generative ai, in-context examples, language model, language technology, llm, nlp, prompt-engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701872,
author = {McDanel, Bradley and Novak, Ed},
title = {Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701872},
doi = {10.1145/3641554.3701872},
abstract = {The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {756–762},
numpages = {7},
keywords = {ai-resistant assignments, assignment design, cs education, llm code generation, programming pedagogy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3722229,
author = {AlOmar, Eman Abdullah},
title = {Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722229},
doi = {10.1145/3722229},
abstract = {Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This article explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This article discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analyses reveal that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like “certainly” regarding bug fixing decisions, and apology phrases such as “apologize” when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {16},
numpages = {36},
keywords = {large language models, education, bugfix, static analysis, code quality}
}

@inproceedings{10.1145/3641554.3701858,
author = {Tran, Minh and Gonzalez-Maldonado, David and Zhou, Elaine and Franklin, Diana},
title = {Can GPT Help? Supporting Teachers to Brainstorm Customized Instructional Scratch Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701858},
doi = {10.1145/3641554.3701858},
abstract = {While many recent studies have explored how large language models can transform computer science instruction from the instructor perspective, they are primarily at the college level. Thus, little is known about using large language models towards curriculum development and teacher supports outside of the college setting. Given the emphasis placed on culturally responsive teaching at the K-8 level and well-documented evidence of insensitive and inaccurate language model outputs from a cultural perspective, it is imperative to perform systematic and principled research before considering their use in this setting.This paper explores the potential of teachers using large language models to brainstorm instructional Scratch projects. Specifically, we use GPT-3 to mimic structured projects from an existing computer science curriculum but situate the generated projects in different contexts/themes. We qualitatively analyze 300 project ideas generated by GPT and find 81% of the generated ideas satisfy our metrics for technical alignment and theme quality. We identify two major weaknesses: code complexity of generated projects and presence of potential insensitive elements that would require human filtering. We conclude that, while not ready as a student-facing solution, teachers could use GPT to effectively brainstorm customized instructional materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1134–1140},
numpages = {7},
keywords = {curriculum customization, k-8, large language models, scratch programming, teacher supports},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705215,
author = {Niousha, Rose and O'Neill, Abigail and Chen, Ethan and Malhotra, Vedansh and Akram, Bita and Norouzi, Narges},
title = {LLM-KCI: Leveraging Large Language Models to Identify Programming Knowledge Components},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705215},
doi = {10.1145/3641555.3705215},
abstract = {Identifying Knowledge Components (KCs) in computer science education improves curriculum design and teaching strategies. We introduce a framework using Large Language Models to identify KCs from programming assignments automatically. Our framework helps educators align assignments with course objectives. GPT-4 identifies relevant KCs well, though there's a low match with expert-generated KCs at the course level. At the problem level, performance is lower, but key KCs are reasonably identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1557–1558},
numpages = {2},
keywords = {cs1, knowledge component, large language model},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705277,
author = {Tsang, Jedidiah and Li, Carol and Park, Su Min and Yan, Lisa},
title = {Using LLMs to Detect the Presence of Learning Outcomes in Submitted Work Within Computing Ethics Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705277},
doi = {10.1145/3641555.3705277},
abstract = {This study investigates how large language models (LLMs) can identify the presence of learning outcomes within student submitted work in a computing ethics course. To do so, we craft a codebook to spot key learning outcomes, such as the usage of critical reasoning and awareness of various social issues. We leverage the GPT-4o and GPT-3.5-turbo LLMs to apply codes onto 8,500 pieces of student submitted work. We then use Cohen's kappa to assess interrater reliability and compare human reviewers' coding to outputs from those models, finding that GPT-4o performed just as well as the agreement between human reviewers. We then use the model outputs to identify specific course readings that students engaged particularly deeply with to better inform our computing ethics instruction.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1641–1642},
numpages = {2},
keywords = {codebook, computing ethics, critical consciousness, large language models, positionality},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3719006,
author = {Ahmed, Iftekhar and Aleti, Aldeida and Cai, Haipeng and Chatzigeorgiou, Alexander and He, Pinjia and Hu, Xing and Pezz\`{e}, Mauro and Poshyvanyk, Denys and Xia, Xin},
title = {Artificial Intelligence for Software Engineering: The Journey So Far and the Road Ahead},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3719006},
doi = {10.1145/3719006},
abstract = {Artificial intelligence and recent advances in deep learning architectures, including transformer networks and large language models, change the way people think and act to solve problems. Software engineering, as an increasingly complex process to design, develop, test, deploy, and maintain large-scale software systems for solving real-world challenges, is profoundly affected by many revolutionary artificial intelligence tools in general and machine learning in particular. In this roadmap for artificial intelligence in software engineering, we highlight the recent deep impact of artificial intelligence on software engineering by discussing successful stories of applications of artificial intelligence to classic and new software development challenges. We identify the new challenges that the software engineering community has to address in the coming years to successfully apply artificial intelligence in software engineering, and we share our research roadmap toward the effective use of artificial intelligence in the software engineering profession, while still protecting fundamental human values.We spotlight three main areas that challenge the research in software engineering: the use of generative artificial intelligence and large language models for engineering large software systems, the need of large and unbiased datasets and benchmarks for training and evaluating deep learning and large language models for software engineering, and the need of a new code of digital ethics to apply artificial intelligence in software engineering.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {119},
numpages = {27},
keywords = {Automated Software Development, Machine Learning, Large Language Models, Artificial Intelligence, Explainable AI, Ethical AI}
}

@inproceedings{10.1145/3723010.3723012,
author = {Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis},
title = {Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723012},
doi = {10.1145/3723010.3723012},
abstract = {The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {161–170},
numpages = {10},
keywords = {software development project course, software engineering education, AI support, AI-based tutoring, experiments},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641555.3704749,
author = {Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang},
title = {Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704749},
doi = {10.1145/3641555.3704749},
abstract = {Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1709–1710},
numpages = {2},
keywords = {AI, curriculum development, large language models, undergraduate education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705076,
author = {Chen, Matt},
title = {Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705076},
doi = {10.1145/3641555.3705076},
abstract = {This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1739},
numpages = {1},
keywords = {custom AI integration, generative AI bots},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713644,
author = {Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia},
title = {Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713644},
doi = {10.1145/3706598.3713644},
abstract = {This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {22},
keywords = {Computer Science Education, LLM, Teachable Agent, Deception, Learning by Teaching, University Students, Longitudinal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3672608.3707736,
author = {Speiser, Sebastian},
title = {Assessing the Real-World Impact of Disagreement Between Human Graders and LLMs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707736},
doi = {10.1145/3672608.3707736},
abstract = {Applying artificial intelligence models to grade student answers is a popular application. Lately Large Language Models (LLMs) have shown promising results. However, the disagreement between human graders and LLMs is often considered too large for practical adoption. In this paper, we investigate the real-world impact of this disagreement on final grades. Instead of focusing on individual answers, we simulate the grading process of an entire exam. We use an unmodified LLM (OpenAI GPT-3.5 Turbo) with one-shot prompting for grading individual answers to short answer questions from computer science courses at a German university. Our main contributions are the evaluation of the real-world impact on examination grades in contrast to correctness of individual student answers, the simulation of grading strategies common in human grading practice, and the discussion of the results in the context of observed inter-rater variabilities among human graders. The findings confirm the natural expectation that the impact of the disagreement is lower for final grades than when looking at individual answers. We quantify this effect and compare it to a grading obtained by simulating a second human grader.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {48–53},
numpages = {6},
keywords = {LLMs, programming education, automated short answer grading},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706599.3720291,
author = {Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh},
title = {Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720291},
doi = {10.1145/3706599.3720291},
abstract = {Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {LLMs, ChatGPT, Teaching Assistant, Data Structures and Algorithms Course, Education},
location = {
},
series = {CHI EA '25}
}

@book{10.1145/3708897,
author = {Giacaman, Nasser and Terragni, Valerio},
title = {Empowering Computing Students with Large Language Models by Developing an Escape Room Game},
year = {2025},
isbn = {9798400714450},
abstract = {In this project, computing students learn to integrate large language models (LLMs) into a software system. Students develop a Java application with a basic graphical user interface (GUI) using JavaFX, gain practical experience with prompt engineering, and learn about the impact of LLM parameters and conversational roles. Students are provided with a Javabased API that connects with OpenAI's GPT model. The project emphasizes teaching students to manage LLM API calls, enhance GUI responsiveness, and improve the user experience all in the context of an AI-powered application. This experience equips them with critical skills in software development and AI application. It prepares them for advanced software development by learning how to create effective LLM prompts to create intelligent and user-friendly applications. We share the experience of using this project and provide guidelines for assessing it in a second-year software engineering undergraduate course, where students' prior programming experience is limited to the prerequisite CS2 course on object-oriented programming. In the case study we present, the project involved developing a riddle-solving escape room, which we called EscAIpe Room.},
numpages = {6}
}

@inproceedings{10.1145/3641555.3705132,
author = {Blasco, I\~{n}aki and Mochetti, Karina},
title = {Assessing the Influence of ChatGPT on Student Outcomes in a Models of Computing Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705132},
doi = {10.1145/3641555.3705132},
abstract = {This study investigates the impact of ChatGPT on student performance in a Models of Computing course, foundational for the computer science major. Analysing data from 11 pre-lecture quizzes across four terms, we found a decline in average quiz scores, particularly in the latest term. The results suggest a correlation between increased reliance on ChatGPT and decreased student performance, especially on challenging questions where the AI frequently struggled. These findings highlight both the benefits and challenges of integrating AI in education. Our ongoing research aims to explore this further across multiple courses, ultimately promoting responsible AI use to enhance learning outcomes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1389–1390},
numpages = {2},
keywords = {computing education, llm, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705250,
author = {Akhmetov, Ildar and Prpa, Mirjana},
title = {Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705250},
doi = {10.1145/3641555.3705250},
abstract = {We present the Requirement Elicitation Tool that leverages Large Language Model (LLM) (gpt-4o-mini) to enable simulated real-world interactions of requirements gathering from three synthetic personas. We demonstrate the use case of Computer Science (CS) students in Database Management Systems leveraging the tool to build a conceptual model and Entity-Relationship (ER) diagrams. Our preliminary findings show the potential of this tool to engage students in discovery process without providing predefined solutions and set the directions for future work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1357–1358},
numpages = {2},
keywords = {AI persona, requirement elicitation, software engineering education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701873,
author = {Thorgeirsson, Sverrir and Ewen, Tracy and Su, Zhendong},
title = {What Can Computer Science Educators Learn From the Failures of Top-Down Pedagogy?},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701873},
doi = {10.1145/3641554.3701873},
abstract = {While educational researchers in various disciplines are grappling with how to develop policies and pedagogical approaches that address the use of generative artificial intelligence, the challenge is particularly complex in computer science education where the new technology is changing the core of the field. In this paper, we take a look at the pedagogy of other subjects with a longer history than computer science and a more extensive body of educational research to collect insights on how this challenge can be met. We begin by drawing from recent neurological research to find domains that share cognitive commonalities with computer programming and then build upon comparisons that others have made to literacy and mathematics education. We then consider how the "reading wars" and "math wars" have shaped these fields, which we see as conflicts between less effective top-down pedagogy and more effective bottom-up pedagogy, and reflect on what would be comparable approaches in teaching computing. We find that approaches that make heavy use of large language models without teaching fundamentals can be compared to the top-down pedagogy of reading and mathematics and are likely to be ineffective on their own. Therefore, we advise against the exclusive use of such approaches with novices. However, we also acknowledge that the social science surrounding computer science education is complex and that effectiveness only tells a part of the story, with other factors such as engagement, motivation and social dynamics also being important.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1127–1133},
numpages = {7},
keywords = {bottom-up pedagogy, computer science education, generative artificial intelligence, large language models, literacy, math wars, phonics, position paper, reading, reading wars, top-down pedagogy, whole language},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3701716.3715199,
author = {Zhang, Yifan and Zhao, Xinkui and Wang, Zuxin and Zhou, Zhengyi and Cheng, Guanjie and Deng, Shuiguang and Yin, Jianwei},
title = {SortingHat: Redefining Operating Systems Education with a Tailored Digital Teaching Assistant},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715199},
doi = {10.1145/3701716.3715199},
abstract = {Operating Systems (OS) courses are among the most challenging in computer science education due to the complexity of internal structures and the diversity of running environments. Traditional teaching methods often fail to address the diverse backgrounds, learning speeds, and practical needs of students. To tackle these challenges, we present SortingHat, a personalized digital teaching assistant tailored specifically for OS education. SortingHat integrates advanced AI technologies, including a retrieval-augmented generation (RAG) framework and multi-agent reinforcement learning (MARL), to deliver adaptive, scalable, and effective educational support. SortingHat features a 3D digital human interface powered by large language models (LLMs) to provide personalized, empathetic, and context-aware guidance. It generates tailored exercises based on each student's learning history and academic performance, reinforcing weak areas and challenging advanced concepts. Additionally, the system incorporates a robust evaluation pipeline that ensures fair, consistent, and unbiased grading of student submissions while delivering personalized, actionable feedback for improvement. By combining personalized guidance, adaptive content creation, and automated assessment, SortingHat transforms OS education into an engaging, immersive, and scalable experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2951–2954},
numpages = {4},
keywords = {digital human, education, large language models, multi agent reinforcement learning, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3641554.3701841,
author = {Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D},
title = {Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701841},
doi = {10.1145/3641554.3701841},
abstract = {Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {chatgpt 3.5, digital accessibility, large language models, llms, project based learning, software engineering, wcag},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701800,
author = {Shah, Anshul and Chernova, Anya and Tomson, Elena and Porter, Leo and Griswold, William G. and Soosai Raj, Adalbert Gerald},
title = {Students' Use of GitHub Copilot for Working with Large Code Bases},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701800},
doi = {10.1145/3641554.3701800},
abstract = {Large language models (LLMs) are already heavily used by professional software engineers. An important skill for new university graduates to possess will be the ability to use such LLMs to effectively navigate and modify a large code base. While much of the prior work related to LLMs in computing education focuses on novice programmers learning to code, less work has focused on how upper-division students use and trust these tools, especially while working with large code bases. In this study, we taught students about various GitHub Copilot features, including Copilot chat, in an upper-division software engineering course and asked students to add a feature to a large code base using Copilot. Our analysis revealed a novel interaction pattern that we call one-shot prompting, in which students ask Copilot to implement the entire feature at once and spend the next few prompts asking Copilot to debug the code or asking Copilot to regenerate its incorrect response. Finally, students reported significantly more trust in the code comprehension features than code generation features of Copilot, perhaps due to the presence of trust affordances in the Copilot chat that are absent in the code generation features. Our study takes the first steps in understanding how upper-division students use Github Copilot so that our instruction can adequately prepare students for a career in software engineering.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1050–1056},
numpages = {7},
keywords = {github copilot, large code bases, program comprehension, trust},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705061,
author = {Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.},
title = {Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705061},
doi = {10.1145/3641555.3705061},
abstract = {The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1735},
numpages = {1},
keywords = {AI, LLMs, artificial intelligence, generative AI, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705074,
author = {Roy, Nimisha and Olufisayo, Omojokun and Horielko, Oleksandr},
title = {Empowering Future Software Engineers: Integrating AI Tools into Advanced CS Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705074},
doi = {10.1145/3641555.3705074},
abstract = {Artificial Intelligence (AI) tools have transformed software development, making it crucial to equip computer science (CS) students with the skills to leverage these technologies. This talk presents an innovative curriculum approach, integrating AI tools into an advanced CS capstone course at a stage where students possess foundational skills in software engineering. This strategic timing ensures students can critically engage with AI, recognizing biases and managing challenges like hallucinations in AI-generated outputs.Before redesigning the curriculum, independent research was conducted to understand the strengths and limitations of various AI tools, such as Lucidchart, Eraser.io for design documentation, and GitHub Copilot, GPT-4, Codeium, Claude, and Gemini for implementation tasks like code generation, code completion, UI design, error handling, and API integration. This research guided the curriculum by shaping assignment design and delivering foundational lectures on prompt engineering to ease the learning curve for students. Experiments during the capstone course included AI-enhanced assignments and projects, where students applied these tools for software design and implementation. Quantitative data-prompt refinement counts, error rates, code accuracy, and qualitative reflections revealed increased confidence in AI tools, enhanced productivity, and greater readiness for industry roles. Despite these benefits, students faced challenges with complex tasks that required iterative refinement and oversight, but they gained skills in managing biases and hallucinations in AI outputs. The curriculum's ''right-left'' approach enables a smooth transition to AI-assisted development, preparing students for the evolving tech landscape. This talk shares key findings, best practices, and insights into balancing manual skills with AI-enhanced learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1747},
numpages = {1},
keywords = {ai-enhanced learning, capstone courses, gen-ai tools in curriculum, iterative prompting., software engineering education, student preparedness},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701829,
author = {Liu, Runda and Chen, Shengqi and Chen, Jiajie and Niu, Songjie and Ma, Yuchun and Tang, Xiaofeng},
title = {Iterative Design of a Teaching Assistant Training Program in Computer Science Using the Agile Method},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701829},
doi = {10.1145/3641554.3701829},
abstract = {Facing soaring enrollment and disruptive educational technologies, computing education increasingly relies on the contributions of teaching assistants (TAs), hence the critical importance of high-quality TA training. However, the design and implementation of TA training in computer science face substantial barriers, such as the lack of experienced TA trainers and the scarcity of relevant training materials.This experience report describes the design and implementation of a peer-led computer science TA training program that began in 2022 and has since undergone three iterations, inspired by the approach of agile software development. The current program consists of 10 sessions, organized to serve TAs in three respective stages of professional development. The iterations involved updating and enrichment of the syllabus, transitioning from lecture-centered to discussion-centered training, and discussions of emerging topics in computing education such as the use of large language models (LLMs). Participant feedback showed that TAs approved the iterative design of the training, while identifying areas for further improvement. We summarize lessons learned from the iterative process, reflect on the role of peer TA trainers, and discuss plans for future iterations.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {680–686},
numpages = {7},
keywords = {agile, ta training, teaching assistant},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705201,
author = {Bejarano, Andres and Dickey, Ethan and Setsma, Rhianna},
title = {Implementing the AI-Lab Framework: Enhancing Introductory Programming Education for CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705201},
doi = {10.1145/3641555.3705201},
abstract = {The advent of generative AI tools presents novel opportunities and challenges in computer science education, particularly in introductory programming courses. This study explores the implementation of AI-Lab, a framework designed to guide students in the effective and ethical use of generative AI, in this case ChatGPT, in academic settings without compromising skill development. Conducted during Spring 2024, our use of the intervention targeted over 500 Computer Science and Data Science majors enrolled in their major-specific Data Structures and Algorithms courses. The AI-Lab framework enabled students to develop both conceptual questions and c++ and Python programs by interacting with ChatGPT and iteratively correcting its errors. Focus groups and post-intervention surveys revealed a generally positive experience. Students appreciated the ability to leverage AI for tasks outside their major, recognizing the value of understanding correct solutions through AI-assisted programming. Moreover, the guided use of generative AI by professors alleviated concerns regarding academic dishonesty, fostering a supportive learning environment. Despite these benefits, students expressed awareness of the potential drawbacks of over-reliance on AI, noting the risk of impeding their professional growth. Nevertheless, they acknowledged the practical utility of AI for non-major related tasks. This study highlights the importance of incorporating structured AI training in curricula to balance skill development and ethical AI usage, offering insights for broader applications in higher education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1383–1384},
numpages = {2},
keywords = {ai lab, ai-assisted programming, ai-lab framework, ethical ai usage, generative ai in education, skill development with ai, structured ai training},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3737313.3737334,
author = {Fernandez, Amanda S. and Patrick, David and Gomez, Mauricio and Cornell, Kimberly A.},
title = {Incorporating LLM Activities into Established CS1 Curriculum: An Experience Report},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Large Language Models (LLMs), including Gemini, CoPilot, and ChatGPT, have experienced significant growth in usage and adoption in recent years. As these models become more sophisticated, particularly in code generation capabilities, educators need to adapt their CS1 courses. In this experience report, we share observations we made while designing and teaching LLM activities for CS1 students at two academic institutions during the spring 2024 term. Drawing on recent research, our activities consist of four short 10-15 minute exercises that guide students in how to properly utilize LLMs within their CS1 coursework. These activities can be easily added to the existing CS1 course curriculum to supplement the existing course materials. Post-activity surveys indicated a positive impact on students' understanding of CS concepts and indicated enthusiasm for learning how to use LLMs safely in programming.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {79–93},
numpages = {15}
}

@inproceedings{10.1145/3641555.3704754,
author = {Bhattacharya, Sambit and Uma, Ravanasamudram and Deb, Debzani},
title = {Integrating Data Science for Social Justice: A Tutorial on Developing Non-Traditional Pathways for Non-CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704754},
doi = {10.1145/3641555.3704754},
abstract = {In response to the growing need for socially responsible computer scientists and data scientists, our team is developing a comprehensive data science certificate program specifically tailored for non-computing majors, with a focus on data science for social justice. This program aims to broaden participation in data science and create non-traditional pathways for diverse student populations. Each course in the program is designed to be accessible to non-computing majors, equipping them with the skills to analyze and address social justice issues through data science. Process Oriented Guided Inquiry Learning (POGIL) is employed as an instructional strategy promoting active learning, and real datasets related to social justice are utilized for hands-on activities and assignments, enhancing practical learning experiences. The courses are taught in a synchronous hybrid format, across multiple universities, accommodating both live online and in-person students.This tutorial will equip educators with the tools to incorporate data science for social justice in their courses. Attendees will have access to materials developed for these courses, enabling them to integrate similar content into their own curricula. A key focus is on recent challenges and opportunities created by generative AI. The presenters will share their experiences, course materials, and strategies for introducing computer science through a social justice lens. Participants will share ideas and strategies, which will be collated and made available in a shared repository. This initiative aims to enable educators to train future generations in data science while addressing social justice issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {certificate program, data science, non-computing majors, social justice},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705125,
author = {Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma},
title = {An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705125},
doi = {10.1145/3641555.3705125},
abstract = {Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1681–1682},
numpages = {2},
keywords = {computer science education, large language model, solo taxonomy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701946,
author = {Li, Nero and Broner, Shahar and Kim, Yubin and Mizuo, Katrina and Sauder, Elijah and To, Claire and Wang, Albert and Gila, Ofek and Shindler, Michael},
title = {Investigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701946},
doi = {10.1145/3641554.3701946},
abstract = {There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs).We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {659–665},
numpages = {7},
keywords = {algorithm design techniques, chatgpt, computational thinking, computer-assisted instruction, data structures, generative ai, gpt-4, gpt-4o, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3737313.3737340,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {163–177},
numpages = {15}
}

@inproceedings{10.1145/3641555.3705282,
author = {\v{R}echt\'{a}\v{c}kov\'{a}, Anna and Maximova, Alexandra and Pitts, Griffin},
title = {Finding Misleading Identifiers in Novice Code Using LLMs},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705282},
doi = {10.1145/3641555.3705282},
abstract = {Clear, well-chosen names for variables and functions significantly enhance code readability and maintainability. In computer science education, teaching students to select appropriate identifiers is a critical task, especially in CS1. This study explores how large language models (LLMs) could assist in teaching this skill. While prior research has explored the use of LLMs in programming education, their precision and consistency in teaching code quality, particularly identifier selection, remains largely unexplored. For this purpose, this study investigated how well different LLMs can detect and report misleading identifiers. In a dataset of 33 code samples, we manually labeled misleading identifiers. On this dataset, we then tested five different LLMs on their ability to detect these misleading identifiers, measuring the overall accuracy, precision, recall, and f-score. Results revealed that the most successful model, GPT-4o, was able to correctly detect most of the manually flagged misleading variable names. However, it also tended to flag issues with variable identifiers in cases where the human evaluators would not, and refined prompting was not able to discourage this behavior.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1595–1596},
numpages = {2},
keywords = {automated feedback, code quality, misleading identifiers, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701785,
author = {Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720240,
author = {Shochcho, Muhtasim Ibteda and Rahman, Mohammad Ashfaq Ur and Rohan, Shadman and Islam, Ashraful and Heickal, Hasnain and Rahman, AKM Mahbubur and Amin, M. Ashraful and Ali, Amin Ahsan},
title = {Improving User Engagement and Learning Outcomes in LLM-Based Python Tutor: A Study of PACE},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720240},
doi = {10.1145/3706599.3720240},
abstract = {Large Language Models (LLMs) are increasingly being adopted for educational applications, but sometimes, limited internet access and budget constraints restrict their accessibility. Small Language Models (SLMs) have emerged as viable alternatives, capable of providing effective tutoring in resource-constrained contexts. This paper introduces PACE (Python AI Companion for Enhanced Engagement), a system leveraging SLMs to deliver step-by-step guidance and adaptive feedback for teaching Python. An evaluation with varying levels of learners showed PACE’s effectiveness, achieving a System Usability Scale (SUS) score of 77.28. While participants were generally satisfied with its clarity and personalized feedback, they identified some areas for improvement, such as loss of context during lengthy conversations. This study examines (1) the PACE system’s effectiveness in programming education according to learners, (2) learners’ trust in PACE versus traditional resources, and (3) design recommendations to enhance engagement and learning outcomes. PACE contributes to advancing cost-effective, scalable programming education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {12},
keywords = {LLM, SLM, PACE, Python, Tutor, Learning, Tutoring, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701810,
author = {Borela, Rodrigo and Liding, Zhixian and McDaniel, Melinda},
title = {Enhancing CS1 Education through Experiential Learning with Robotics Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701810},
doi = {10.1145/3641554.3701810},
abstract = {To address the challenges of generative AI in CS1 education, especially its misuse by students to bypass coding exercises, which undermines their engagement with foundational learning, CS1 curricula are evolving to emphasize higher-level problem-solving and systems thinking. In response, a novel experiential learning initiative grounded in High-Impact Practices was introduced to a CS1 course over the course of 2 semesters, involving 132 students. This initiative utilized robotics lab assignments to enhance computational thinking across various levels of granularity, from individual functional components to overall system behaviors, bridging conceptual understanding with real-world applications. The approach emphasized project-based learning, extended engagement time, and reflective practices to deepen students' understanding of core computing concepts and scaffold knowledge integration. The curriculum featured both individual and team-based lab assignments to build foundational skills followed by collaborative problem-solving. The initiative's impact was assessed against a control group of 427 students who completed traditional web development lab assignments. Evaluation methods included thematic analyses of student reflections, instructor opinion surveys, and statistical analysis of exam performances across the semester. Results revealed a substantial positive effect on self-efficacy and learning outcomes. Students in the experiential learning group reported increased confidence in applying their computing skills to real-world scenarios, heightened engagement, and greater improvements in technical proficiency. Notably, their exam scores demonstrated a statistically significant improvement compared to the control group. These findings highlight the effectiveness of integrating practical, interactive elements into computer science education to meet the demands of a rapidly evolving technological landscape.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {144–150},
numpages = {7},
keywords = {artificial intelligence, collaborative learning, cs1, experiential learning, robotics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701959,
author = {Wu, Ylesia and Zheng, Qirui and Lau, Sam},
title = {How Novices Use Program Visualizations to Understand Code that Manipulates Data Tables},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701959},
doi = {10.1145/3641554.3701959},
abstract = {As data science and artificial intelligence continue to impact society, more and more people are learning how to manipulate data with code. To support these learners, program visualization tools automatically generate diagrams to show how code transforms data, in contrast to tools based on large language models (LLMs) that primarily focus on textual explanations. Although program visualization tools are popular among instructors, do novices find these tools usable and useful for data science programs that often manipulate datasets with many rows? To address this, we evaluate a popular, publicly available tool that generates diagrams for Python pandas code through a randomized, in-lab usability study with 17 data science novices. Despite minimal instruction on how to use the tool, novices found that program visualizations increased their confidence in comprehending and debugging code. In addition, even though the tool sometimes produced diagrams with many visual elements, participant performance on the study tasks was not negatively impacted. These findings suggest design guidelines for program visualization tools to help manage cognitive load for data science novices. To our knowledge, this is the first empirical study that investigates how novices use program visualization tools to understand code that manipulates data tables, and suggests a future where novices can use automatically generated diagrams as a complement to LLM tools for effectively understanding unfamiliar programs in data science.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1267–1273},
numpages = {7},
keywords = {data science education, novice programmers, program visualization tools},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3719287,
author = {Oh, Sunggyeol and Zhao, Jiacheng and Russo, Carson and Bolmer, Michael},
title = {Boosting Diary Study Outcomes with a Fine-Tuned Large Language Model},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719287},
doi = {10.1145/3706599.3719287},
abstract = {This study explores fine-tuned Large Language Models (LLMs) integration into diary studies within the Human-Computer Interaction (HCI) field to enhance data collection and analysis. Leveraging a Mistral 7B model fine-tuned with a curated dataset of over 1,000 diary entries, this research addresses challenges such as participant engagement and data richness. The fine-tuned model offers personalized feedback, facilitating deeper reflection and structured recording while reducing the cognitive load on participants. The DiaryQuest educational platform, enhanced with advanced visualization tools and semantic search capabilities, enables educators to efficiently analyze diary data, extract thematic insights, and provide targeted guidance. Results from user evaluations reveal that the optimized platform improves learning outcomes, teaching efficiency, and overall user experience. By bridging traditional diary methodologies with state-of-the-art LLMs, this study advances HCI education and establishes a scalable framework for applying AI in broader educational and research contexts.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {7},
keywords = {Diary Study, Large Language Model},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3705300,
author = {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu, Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
title = {Distinguishing LLM-Generated from Human-Written Code by Contrastive Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705300},
doi = {10.1145/3705300},
abstract = {Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This article aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550k pairs of human-written and ChatGPT-generated code (i.e., 288k Python code pairs and 222k Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {31},
keywords = {Large Language Model, ChatGPT, AI-generated Code Detection, Contrastive Learning}
}

@inproceedings{10.1145/3641555.3705252,
author = {Tadimalla, Sri Yash and Maher, Mary Lou},
title = {Sociotechnical AI Education Course Design for CS Majors and Non-Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705252},
doi = {10.1145/3641555.3705252},
abstract = {As generative AI increasingly integrates into society and education, the number of institutions implementing AI usage policies and offering introductory AI courses is rising. These introductory AI courses mustn't replicate the "gateway/weed-out" phenomenon observed in introductory computer science courses like CS1 and CS2. Literature in computer science education suggests that interventions such as summer camps, bridge courses, and socio-technical courses have improved the sense of belonging and retention among students from underrepresented groups, thereby broadening participation in computer science. Building on previous work to create a socio-technical curriculum for all ages and education levels, this paper presents a course for teaching introductory AI concepts that adopts a socio-technical approach, complete with weekly activities and content designed for broad access. The course has been taught as a 1-credit general education course, primarily for freshmen and first-year students from various majors, and a 3-credit course for CS majors at all levels.This paper provides a curriculum and resources to teach a socio-technical introductory AI course. This approach is important because it not only democratizes AI education across diverse student backgrounds but also equips all students with the critical socio-technical multidisciplinary perspective necessary to navigate and shape the future ethical landscape of AI technology.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1631–1632},
numpages = {2},
keywords = {AI curriculum, AI education, intro to AI, socio-technical AI literacy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705236,
author = {Chopra, Ryka C. and Chakraborty, Suparna},
title = {RAFIKI: Leveraging Large Language Models to Increase AP Computer Science A Enrollment among Disadvantaged High School Females},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705236},
doi = {10.1145/3641555.3705236},
abstract = {The gender gap in computing persists even after decades of investment in lowering the gap. Evidence suggests that stereotypical attitudes and bias perceptions play a critical role in limiting female participation in STEM, beginning in middle and high school. The gap is exacerbated in developing nations with limited academic counselor support. Therefore, the goal is to provide early targeted counseling. RAFIKI - "friend" in Swahili is a large language model-based web application designed to mimic an academic coach. Using user inputs, it provides customized academic counseling with curated information on STEM and computing pathways. Initial experimental evidence shows that RAFIKI use leads to a significant increase in AP Computer Science A course enrollment, considered a pathway to future computing career, particularly among female high school students.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1417–1418},
numpages = {2},
keywords = {AP CSA, ChatGPT, digital coach, female enrollment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705121,
author = {Harrington, Brian and Alnoor, Ahmad Zubair and Haqiqi, Pedram and Hoseininia, Zahra and Lin, Kai and Lodi, Maliha and Mirza, Asad and Wolfe, Leah and Zhang, Kevin},
title = {A Systematic Literature Mapping of Early Generative AI Research is CS Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705121},
doi = {10.1145/3641555.3705121},
abstract = {The widespread release of generative AI tools has led to a rapid rise in publications evaluating their impact on CS education. While there is no doubt that the area is new and rapidly evolving, it is important to begin to catalogue and map the literature at this early stage. In this work, we systematically search and map 82 papers evaluating the impact of generative AI tools on CS education. We then build a literature map of these papers using the axes of population, use of generative AI, and method of evaluation. This work will serve as both a snapshot of the first generation of generative AI papers in the field, and a road-map for further classification and literature review as the field develops.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1467–1468},
numpages = {2},
keywords = {gen ai, generative ai, large language models, literature map, llm},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705066,
author = {Rahman, Farzana},
title = {Leveraging or Limiting: Strategies and Implications of ChatGPT Use by Undergraduate TAs in Large CS2 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705066},
doi = {10.1145/3641555.3705066},
abstract = {As AI tools like ChatGPT become more prevalent in educational settings, their potential to assist undergraduate teaching assistants (uTAs) in large Computer Science 2 (CS2) courses presents both opportunities and challenges. This work focuses on how ChatGPT can be strategically utilized by uTAs during office hours to enhance student support, particularly in complex topics such as data structures, algorithm development, and object-oriented programming. We explored effective strategies for uTAs to use ChatGPT in ways that promote deeper student understanding without compromising the development of independent problem-solving skills. Key strategies include leveraging ChatGPT for real-time code debugging assistance, offering alternative approaches to solving coding problems, comparing and critiquing self and AI generated documentation, and code reviewing. This work also identifies potential challenges, such as the risk of students or uTAs becoming overly dependent on AI-generated solutions and the possibility of inaccurate or incomplete responses from the AI. Hence, our findings highlight the dual role of ChatGPT as both an asset and a potential hindrance, depending on how it is utilized. To mitigate these risks, we propose a set of best practices that ensure ChatGPT enhances, rather than replaces, the uTA's role as a facilitator of learning. The findings from this research provide valuable insights into how uTAs can integrate AI tools thoughtfully into office hours to offer more effective support, ultimately improving student engagement and learning outcomes in large-scale CS2 courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1745},
numpages = {1},
keywords = {ai tools, cs2, student engagement, ta training, undergraduate teaching assistants},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3723010.3723036,
author = {B\"{o}hm, Karsten},
title = {Towards a Semantic Representation of Framework Recommendations for Curricular Specifications in Higher Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723036},
doi = {10.1145/3723010.3723036},
abstract = {Curricular specifications play an important role in the Higher Education sector and the domain of Computer Science and Software Engineering is characterized by a wide range of education programs with a broad range of topic. Therefore, recommendation frameworks play an important role and their usage is beneficial for a unification of education profiles in a systematic way. This  research is contributing to this development by exploring how a recommendation for the domain of Business Informatics in German speaking countries can be improved by formalizing the recommendations in a semantic model that relies on sophisticated European ontologies in the domain like the European Learning Model (ELM) and related data models. It employs Generative Artificial Intelligence Systems to create semantic models in an experimental way and evaluates the resulting model quality. The results show that a formalization using GenAI has a high potential, but currently also shows deficits in the correctness of the resulting models, requiring human oversight during the model creation.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {154–160},
numpages = {7},
keywords = {Business Informatics, Competence Specification, European Learning Model, Higher Education, Learning Framework, Semantic Web},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641554.3701957,
author = {Basit, Nada and Floryan, Mark and Hott, John R. and Huo, Allen and Le, Jackson and Zheng, Ivan},
title = {ASCI: AI-Smart Classroom Initiative},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701957},
doi = {10.1145/3641554.3701957},
abstract = {The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students who were grouped using the tool were more likely to return to the queue more than twice as often (on average) than those who were not. However, while grouping in office hours has the potential to decrease student wait times, teaching assistants and students tend to favor one-on-one meetings over group meetings. This might be improved in the future with updates to the software, TA training, and incorporation of other supporting tools (e.g., LLM technology). The other, newer, tools will be more thoroughly evaluated in future semesters.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {81–87},
numpages = {7},
keywords = {computer science education, cosine similarity, group formation, office hours},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3737313.3737332,
author = {Chamberlain, Devin and Levine, David B. and Pitcairn, Abigail and Snow, Nicholas and Sweeney, Benjamin},
title = {Large Language Models and Introductory Lab Exercises: Susceptibility, Resistance, and Potential},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Three student personas were created, each representing a way in which current students interact with AI tools such as ChatGPT when completing introductory computer science assignments. Four undergraduate students assumed the role of each of the personas in turn and two semesters worth of current assignments were completed in each persona. The results and experiences were then analyzed to determine aspects of the assignments that made it more (or less) difficult to complete them using the AI tools, with an eye towards whether small changes in phrasing or requirements might result in significant changes in this metric.Three of the main takeaways were that LLMs are more difficult for students to use when assignments 1) consist of many small steps, 2) make use of external code libraries, or 3) involve spatial reasoning.Finally, the student/persona experiences helped to generate a list of opportunities for instructors to proactively include the use of AI tools in current assignments without sacrificing any of the current learning objectives.The initial phase involved labs from one institution and used only one AI tool, but follow-up work involving the use of other tools and labs from other institutions validated those core conclusions. A student survey (as well as other published literature) also validated the choice of personas.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {49–63},
numpages = {15}
}

@inproceedings{10.1145/3716640.3716651,
author = {Qiao, Shuying and Denny, Paul and Giacaman, Nasser},
title = {Oversight in Action: Experiences with Instructor-Moderated LLM Responses in an Online Discussion Forum},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716651},
doi = {10.1145/3716640.3716651},
abstract = {The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {95–104},
numpages = {10},
keywords = {Large language models, LLMs, discussion forums, instructor-in-the-loop, software engineering education, chatbots, computing education},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705183,
author = {Brockenbrough, Allan and Feild, Henry and Salinas, Dominic},
title = {Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705183},
doi = {10.1145/3641555.3705183},
abstract = {In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1401–1402},
numpages = {2},
keywords = {LLM, generative AI, large language model, user story},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3703412.3703434,
author = {Liu, Fengchen and Jung, Jordan and Feinstein, Wei and D'Ambrogia, Jeff and Jung, Gary},
title = {Aggregated Knowledge Model: Enhancing Domain-Specific QA with Fine-Tuned and Retrieval-Augmented Generation Models},
year = {2025},
isbn = {9798400711619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703412.3703434},
doi = {10.1145/3703412.3703434},
abstract = {This paper introduces a novel approach to enhancing closed-domain Question Answering (QA) systems, focusing on the specific needs of the Lawrence Berkeley National Laboratory (LBL) Science Information Technology (ScienceIT) domain. Utilizing a rich dataset derived from the ScienceIT documentation, our study embarks on a detailed comparison of two fine-tuned large language models and five retrieval-augmented generation (RAG) models. Through data processing techniques, we transform the documentation into structured context-question-answer triples, leveraging the latest Large Language Models (AWS Bedrock, GCP PaLM2, Meta LLaMA2, OpenAI GPT-4, Google Gemini-Pro) for data-driven insights. Additionally, we introduce the Aggregated Knowledge Model (AKM), which synthesizes responses from the seven models mentioned above using K-means clustering to select the most representative answers. The evaluation of these models across multiple metrics offers a comprehensive look into their effectiveness and suitability for the LBL ScienceIT environment. The results demonstrate the potential benefits of integrating fine-tuning and retrieval-augmented strategies, highlighting significant performance improvements achieved with the AKM. The insights gained from this study can be applied to develop specialized QA systems tailored to specific domains.},
booktitle = {Proceedings of the 4th International Conference on AI-ML Systems},
articleno = {22},
numpages = {7},
keywords = {Fine-tuning Language Models, Retrieval-Augmented Generation, Closed-Domain Question Answering, Domain-Specific Information Retrieval, Large Language Models, GCP PaLM, AWS Bedrock, Meta LLaMA, OpenAI GPT, Google Gemini-Pro, High Performance Computing},
location = {
},
series = {AIMLSystems '24}
}

@inproceedings{10.1145/3706468.3706500,
author = {Duan, Zhangqi and Fernandez, Nigel and Hicks, Alexander and Lan, Andrew},
title = {Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706500},
doi = {10.1145/3706468.3706500},
abstract = {Open-ended coding tasks, which ask students to construct programs according to certain specifications, are common in computer science education. Student modeling can be challenging since their open-ended nature means that student code can be diverse. Traditional knowledge tracing (KT) models that only analyze response correctness may not fully capture nuances in student knowledge from student code. In this paper, we introduce Test case-Informed Knowledge Tracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze and predict both open-ended student code and whether the code passes each test case. We augment the existing CodeWorkout dataset with the test cases used for a subset of the open-ended coding questions, and propose a multi-task learning KT method to simultaneously analyze and predict 1) whether a student’s code submission passes each test case and 2) the student’s open-ended code, using a large language model as the backbone. We quantitatively show that these methods outperform existing KT methods for coding that only use the overall score a code submission receives. We also qualitatively demonstrate how test case information, combined with open-ended code, helps us gain fine-grained insights into student knowledge.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {238–248},
numpages = {11},
keywords = {Computer Science Education, Large Language Models, Open-ended Coding Questions, Test Cases},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3702163.3702188,
author = {Schefer-Wenzl, Sigrid and Vogl, Christoph and Peiris, Sahani and Miladinovic, Igor},
title = {Exploring the Adoption of Generative AI Tools in Computer Science Education: A Student Survey},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702188},
doi = {10.1145/3702163.3702188},
abstract = {The integration of generative AI tools into education has the potential to revolutionize learning experiences, particularly in computer science. This paper explores the adoption and utilization of generative AI tools among computer science students at the University of Applied Sciences Campus Vienna in Austria through a comprehensive survey. The study aims to understand the extent to which AI tools like ChatGPT are integrated into students' academic routines, their perceptions of these tools, and the challenges and opportunities they present. The survey results indicate a high level of acceptance and frequent use of AI tools for tasks such as programming, exam preparation, and generating simplified explanations. However, concerns about the accuracy of AI-generated content and the potential impact on critical thinking skills were also highlighted. The findings underscore the need for clear institutional guidelines and ethical considerations in the use of AI tools in education. This paper contributes to the growing body of literature on AI in education and provides insights for educators and policymakers to enhance the responsible integration of AI technologies in computer science curricula.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {173–178},
numpages = {6},
keywords = {Artificial Intelligence, Computer Science Education, Generative AI Tools, Higher Education},
location = {
},
series = {ICETC '24}
}

@article{10.1145/3735129,
author = {Yang, Boyang and Tian, Haoye and Ren, Jiadong and Zhang, Hongyu and Klein, Jacques and Bissyande, Tegawende and Le Goues, Claire and Jin, Shunfu},
title = {MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-Tuning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735129},
doi = {10.1145/3735129},
abstract = {Within the realm of software engineering, specialized tasks on code, such as program repair, present unique challenges, necessitating fine-tuning Large language models&nbsp;(LLMs) to unlock state-of-the-art performance. Fine-tuning approaches proposed in the literature for LLMs on program repair tasks generally overlook the need to reason about the logic behind code changes, beyond syntactic patterns in the data. High-performing fine-tuning experiments also usually come at very high computational costs. With MORepair, we propose a novel perspective on the learning focus of LLM fine-tuning for program repair: we not only adapt the LLM parameters to the syntactic nuances of the task of code transformation (objective ➊), but we also specifically fine-tune the LLM with respect to the logical reason behind the code change in the training data (objective ➋). Such a multi-objective fine-tuning will instruct LLMs to generate high-quality patches.We apply MORepair to fine-tune four open-source LLMs with different sizes and architectures. Experimental results on function-level and repository-level repair benchmarks show that the implemented fine-tuning effectively boosts LLM repair performance by 11.4% to 56.0%. We further show that our fine-tuning strategy yields superior performance compared to the state-of-the-art approaches, including standard fine-tuning, Fine-tune-CoT, and RepairLLaMA.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Program Repair, Fine-tuning, Large Language Model, Open Source}
}

@article{10.1145/3715112,
author = {Betz, Stefanie and Penzenstadler, Birgit},
title = {With Great Power Comes Great Responsibility: The Role of Software Engineers},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715112},
doi = {10.1145/3715112},
abstract = {The landscape of Software Engineering evolves rapidly amidst digital transformation and the ascendancy of AI, leading to profound shifts in the role and responsibilities of Software Engineers. This evolution encompasses both immediate changes, such as the adoption of Large Language Model-based approaches to coding, and deeper shifts driven by the profound societal and environmental impacts of technology. Despite the urgency, there persists a lag in adapting to these evolving roles. This roadmap article proposes 10 research challenges to develop a new generation of Software Engineers equipped to navigate the technical and social complexities as well as ethical considerations inherent in their evolving profession. Furthermore, the challenges target role definition, integration of AI, education transformation, standards evolution, and impact assessment to equip future Software Engineers to skillfully and responsibly handle the obstacles within their transforming discipline.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {136},
numpages = {21},
keywords = {Sustainability, Responsibility, Roles, Ethics}
}

@inproceedings{10.1145/3701047.3701074,
author = {Wei, Xueling},
title = {KPI-based enterprise management decision-making system Artificial Intelligence Generated Content modeling},
year = {2025},
isbn = {9798400711688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701047.3701074},
doi = {10.1145/3701047.3701074},
abstract = {In terms of business decision-making, there are still issues to be resolved regarding the intelligence of key performance indicators. To address this technical problem, from the perspective of Artificial Intelligence Generated Content, modeling methods such as support vector machines, random search, and machine learning for key performance indicators (KPI) in business decision-making systems have been proposed. The system integrates with large language models, driving the generative efficiency and accuracy of KPI data cleaning, feature extraction, and model optimization training. Using MATLAB to conduct predictive simulation experiments on the integrated system, compared to general information systems for KPIs that do not utilize large language models or Artificial Intelligence Generated Content, the volume of reference data for business decision-making based on large language models increased by 93.61 times, and decision-making efficiency improved by 36.59%, indicating that the Artificial Intelligence Generated Content modeling scheme for business decision-making systems based on operational KPIs is feasible.},
booktitle = {Proceedings of the 2024 2nd International Conference on Communication Networks and Machine Learning},
pages = {147–151},
numpages = {5},
keywords = {Artificial Intelligence Generated Content, KPI, business decision-making},
location = {
},
series = {CNML '24}
}

@article{10.1145/3736407,
author = {Weyssow, Martin and Kamanda, Aton and Zhou, Xin and Sahraoui, Houari},
title = {CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3736407},
doi = {10.1145/3736407},
abstract = {Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavor that requires a deep assessment of LLMs’ outputs. Existing methods and benchmarks rely primarily on automated metrics and static analysis tools, which often fail to capture the nuances of user instructions and LLM outputs. To address this gap, we introduce the LLM-as-a-Judge evaluation framework and present CodeUltraFeedback, a comprehensive dataset for assessing and improving LLM alignment with coding preferences. CodeUltraFeedback consists of 10,000 coding instructions, each annotated with four responses generated from a diverse pool of 14 LLMs. These responses are annotated using GPT-3.5 as a judge, with both ranking-based scores and detailed textual feedback across five distinct coding preferences. Our analysis reveals that responses from GPT-3.5 and GPT-4 are consistently rated higher than those from open-weight models, underscoring substantial alignment gaps between closed- and open-weight LLMs. In turn, we explore the usage of CodeUltraFeedback as feedback data to fine-tune and align CodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement learning from AI feedback (RLAIF) with direct preference optimization (DPO). The resulting aligned model achieves an average alignment improvement of 22.7% and 29.7% when evaluated with GPT-3.5 and GPT-4 judges, respectively. Notably, our aligned CodeLlama-7B-Instruct surpasses much larger models, such as CodeLlama-13B and 34B, in alignment with coding preferences. Despite not being explicitly trained for functional correctness, it also achieves a 10.5% and 26.6% relative improvement in Pass@ (1)  and Pass@ (10)  on the HumanEval+ benchmark. Our contributions demonstrate the practical value of preference tuning in code generation and set the stage for further progress in model alignment and RLAIF for automated software engineering.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Large language models, code generation, automated software engineering, reinforcement learning from AI feedback, direct preference optimization, LLM-as-a-Judge}
}

@inproceedings{10.1145/3641555.3705208,
author = {Weber, Jason Lee and Park, Hyunjun and Song, Daniel J. and Apillanes, Jared and Martinez Neda, Barbara and Wong-Ma, Jennifer and Gago-Masague, Sergio},
title = {Investigating Autograder Usage in the Post- Pandemic and LLM Era},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705208},
doi = {10.1145/3641555.3705208},
abstract = {This work investigates the impact of Large Language Models (LLMs) and the COVID-19 pandemic on student behavior with autograder systems in three programming-heavy courses. We examine whether the release of LLMs like ChatGPT and GitHub Copilot, along with post-pandemic effects, has modified student interactions with autograders. Using data from student submissions over five years, totalling over 4,500 students across over 420,000 submissions, we analyze trends in submission behaviors before and after these events. Our methodology involves tracking submission patterns, focusing on timing, frequency, and score.Contrary to expectations, our findings reveal that metrics remain relatively consistent in the post-ChatGPT and post-pandemic era. Despite yearly fluctuations, no significant shift in student behaviors is attributable to these changes. Students continue to rely on a combination of manual debugging and autograder feedback without noticeable changes in their problem-solving approach.These findings highlight the resilience of the educational practices in these courses and suggest that integrating LLMs into mid-level CS curriculum may not necessitate the significant paradigm shift previously envisioned. Future work should extend these analyses to courses with different structures to determine if these results are generalizable. If not, the specific course aspects contributing to our observed ChatGPT and pandemic resilience should be identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1653–1654},
numpages = {2},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3712005,
author = {Gao, Cuiyun and Hu, Xing and Gao, Shan and Xia, Xin and Jin, Zhi},
title = {The Current Challenges of Software Engineering in the Era of Large Language Models},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3712005},
doi = {10.1145/3712005},
abstract = {With the advent of large language models (LLMs) in the AI area, the field of software engineering (SE) has also witnessed a paradigm shift. These models, by leveraging the power of deep learning and massive amounts of data, have demonstrated an unprecedented capacity to understand, generate, and operate programming languages. They can assist developers in completing a broad spectrum of software development activities, encompassing software design, automated programming, and maintenance, which potentially reduces huge human efforts. Integrating LLMs within the SE landscape (LLM4SE) has become a burgeoning trend, necessitating exploring this emergent landscape’s challenges and opportunities.The article aims at revisiting the software development lifecycle (SDLC) under LLMs, and highlighting challenges and opportunities of the new paradigm. The article first summarizes the overall process of LLM4SE, and then elaborates on the current challenges based on a through discussion. The discussion was held among more than 20 participants from academia and industry, specializing in fields such as SE and artificial intelligence. Specifically, we achieve 26 key challenges from seven aspects, including software requirement and design, coding assistance, testing code generation, code review, code maintenance, software vulnerability management, and data, training, and evaluation. We hope the achieved challenges would benefit future research in the LLM4SE field.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {127},
numpages = {30},
keywords = {Large Language Models, Challenges, LLM4SE}
}

@inproceedings{10.1145/3708493.3712691,
author = {Cummins, Chris and Seeker, Volker and Grubisic, Dejan and Roziere, Baptiste and Gehring, Jonas and Synnaeve, Gabriel and Leather, Hugh},
title = {LLM Compiler: Foundation Language Models for Compiler Optimization},
year = {2025},
isbn = {9798400714078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708493.3712691},
doi = {10.1145/3708493.3712691},
abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities across a variety of software engineering and coding tasks. However, their application in the domain of code and compiler optimization remains underexplored. Training LLMs is resource-intensive, requiring substantial GPU hours and extensive data collection, which can be prohibitive. To address this gap, we introduce LLM&nbsp;Compiler, a suite of robust, openly available, pre-trained models specifically designed for compiler tasks. Built on the foundation of Code&nbsp;Llama, LLM&nbsp;Compiler enhances the understanding of compiler intermediate representations (IRs), assembly language, and optimization techniques. The models have been trained on a vast corpus of 546 billion tokens of LLVM-IR and assembly code and have undergone instruction fine-tuning to interpret compiler behavior.    To demonstrate the utility of these research tools, we also present fine-tuned versions of the models with enhanced capabilities in optimizing code size and disassembling from x86_64 and ARM assembly back into LLVM-IR. These achieve 77% of the optimising potential of an autotuning search, and 45% disassembly round trip (14% exact match).    LLM&nbsp;Compiler is released under a bespoke commercial license to allow wide reuse and is available in two sizes: 7 billion and 13 billion parameters. Our aim is to provide scalable, cost-effective foundational models for further research and development in compiler optimization by both academic researchers and industry practitioners. Since we released LLM&nbsp;Compiler the community has quantized, repackaged, and downloaded the models over 250k times.},
booktitle = {Proceedings of the 34th ACM SIGPLAN International Conference on Compiler Construction},
pages = {141–153},
numpages = {13},
keywords = {Code Optimization, Compiler Optimization, LLVM-IR, Large Language Models, Pre-trained Models},
location = {Las Vegas, NV, USA},
series = {CC '25}
}

@inproceedings{10.1145/3716640.3716652,
author = {Edwards, John and Hellas, Arto and Leinonen, Juho},
title = {On the Opportunities of Large Language Models for Programming Process Data},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716652},
doi = {10.1145/3716640.3716652},
abstract = {Computing educators and researchers have long used programming process data to understand how students construct programs and address challenges. Despite its potential, fully automated feedback systems remain underexplored. The emergence of Large Language Models (LLMs) offers new opportunities for analyzing programming data and providing formative feedback. This study explores using LLMs to summarize programming processes and deliver formative feedback. A case study analyzed keystroke-level data from an introductory programming course, processed into code snapshots. Three state-of-the-art LLMs – Claude 3 Opus, GPT-4 Turbo, and LLaMa2 70B Chat – were evaluated for their feedback capabilities. Results show LLMs effectively provide tailored feedback, emphasizing incremental development, algorithmic planning, and code readability. Our findings highlight the potential of combining keystroke data with LLMs to automate formative feedback, showing that the computing education research and practice community is again one step closer to automating formative programming process feedback.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {105–113},
numpages = {9},
keywords = {programming process data, large language models, generative AI, programming process feedback, programming process summarization, keystroke data},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705195,
author = {Marwan, Samiha and Ibrahim, Mohamed and Morrison, Briana},
title = {How Good are Large Language Models at Generating Subgoal Labels?},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705195},
doi = {10.1145/3641555.3705195},
abstract = {The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1541–1542},
numpages = {2},
keywords = {large language models, subgoal labels, subgoals},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716647,
author = {Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto},
title = {LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716647},
doi = {10.1145/3716640.3716647},
abstract = {There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {56–63},
numpages = {8},
keywords = {generative AI, genAI, large language models, LLMs, GPT-4o, prompt engineering, synthetic data, bugs, submissions, data generation},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3708036.3708089,
author = {Feng, Chen and Li, Yifan and Chen, Zhaoda and Guo, Longxing},
title = {The Evolution and Breakthrough of Natural Language Processing: The Revolution from Rules to Deep Learning},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708089},
doi = {10.1145/3708036.3708089},
abstract = {Natural language processing (NLP) is the intersection of computer science and artificial intelligence. It aims to enable computers to understand and generate human natural language. With the development of the Internet and big data, natural language processing has become one of the most popular areas in the AI ​​era. Currently, the rise of large-scale pre-trained language models has greatly promoted progress in this field, making the application of natural language processing more extensive and in-depth. This article first reviews the development history of natural language processing, from early rule-based systems to current deep learning-based models. In particular, the proposal of the Transformer architecture marks a major breakthrough in natural language processing technology. It greatly improves the ability to handle long-distance dependencies through the attention mechanism, and has become the basic model for many NLP tasks. Further, this article explores the significant improvements in performance of large-scale pre-trained models such as GPT and BERT, and how they understand and generate language by learning the subtle laws of language on large amounts of text data. Finally, the perspective is returned to large language models, including the development history, performance and challenges of large models, and the introduction of meditation is proposed to solve the problem of model illusion.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {307–311},
numpages = {5},
keywords = {Large language models, Machine learning, Natural language processing, Neural networks},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3706468.3706529,
author = {Hassany, Mohammad and Brusilovsky, Peter and Savelka, Jaromir and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil and Agarwal, Arav and Hendrawan, Rully Agus},
title = {Generating Effective Distractors for Introductory Programming Challenges: LLMs vs Humans},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706529},
doi = {10.1145/3706468.3706529},
abstract = {As large language models (LLMs) show great promise in generating a wide spectrum of educational materials, robust yet cost-effective assessment of the quality and effectiveness of such materials becomes an important challenge. Traditional approaches, including expert-based quality assessment and student-centered evaluation, are resource-consuming, and do not scale efficiently. In this work, we explored the use of pre-existing student learning data as a promising approach to evaluate LLM-generated learning materials. Specifically, we used a dataset where students were completing the program construction challenges by picking the correct answers among human-authored distractors to evaluate the quality of LLM-generated distractors for the same challenges. The dataset included responses from 1,071 students across 22 classes taught from Fall 2017 to Spring 2023. We evaluated five prominent LLMs (OpenAI-o1, GPT-4, GPT-4o, GPT-4o-mini, and Llama-3.1-8b) across three different prompts to see which combinations result in more effective distractors, i.e., those that are plausible (often picked by students), and potentially based on common misconceptions. Our results suggest that GPT-4o was the most effective model, matching close to 50% of the functional distractors originally authored by humans. At the same time, all of the evaluated LLMs generated many novel distractors, i.e., those that did not match the pre-existing human-authored ones. Our preliminary analysis shows that those appear to be promising. Establishing their effectiveness in real-world classroom settings is left for future work.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {484–493},
numpages = {10},
keywords = {Large Language Models (LLMs), Distractor Generation and Evaluation, Student Learning Data, Introductory Programming, GPT, LLaMA},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641554.3701859,
author = {Gorson Benario, Jamie and Marroquin, Jenn and Chan, Monica M. and Holmes, Ernest D.V. and Mejia, Daniel},
title = {Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701859},
doi = {10.1145/3641554.3701859},
abstract = {Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {395–401},
numpages = {7},
keywords = {cs education, generative ai, llms in cs education, minority serving institutions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3714461,
author = {Weyssow, Martin and Zhou, Xin and Kim, Kisub and Lo, David and Sahraoui, Houari},
title = {Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3714461},
doi = {10.1145/3714461},
abstract = {Large language models (LLMs) demonstrate impressive capabilities to generate accurate code snippets given natural language intents in a zero-shot manner, i.e., without the need for specific fine-tuning. While prior studies have highlighted the advantages of fine-tuning LLMs, this process incurs high computational costs, making it impractical in resource-scarce environments, particularly for models with billions of parameters. To address these challenges, previous research explored in-context learning (ICL) and retrieval-augmented generation (RAG) as strategies to guide the LLM generative process with task-specific prompt examples. However, ICL and RAG introduce inconveniences, such as the need for designing contextually relevant prompts and the absence of learning task-specific parameters, thereby limiting downstream task performance. In this context, we foresee parameter-efficient fine-tuning (PEFT) as a promising approach to efficiently specialize LLMs to task-specific data while maintaining reasonable resource consumption. In this paper, we deliver a comprehensive study of PEFT techniques for LLMs in the context of automated code generation. Our comprehensive investigation of PEFT techniques for LLMs reveals their superiority and potential over ICL and RAG across a diverse set of LLMs and three representative Python code generation datasets: Conala, CodeAlpacaPy, and APPS. Furthermore, our study highlights the potential for tuning larger LLMs and significant reductions in memory usage by combining PEFT with quantization. Therefore, this study opens opportunities for broader applications of PEFT in software engineering scenarios.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
keywords = {code generation, large language models, parameter-efficient fine-tuning, quantization, retrieval-augmented generation, empirical study}
}

@inbook{10.1145/3718491.3718578,
author = {Ji, Shubo and Zhang, Long and Niu, Liyue and Zheng, Qiusheng},
title = {Evaluation of Chinese Sentiment Analysis for Lightweight LLM},
year = {2025},
isbn = {9798400710865},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3718491.3718578},
abstract = {Large language models have demonstrated impressive performance in natural language processing tasks. However, their extensive parameter scale necessitates substantial computational resources and presents various challenges regarding portability and application scenarios, thereby hindering the widespread adoption and utilization of this technology. This study examines domestic large language models characterized by high portability and a smaller parameter scale, particularly focusing on their performance in sentiment analysis tasks. Accordingly, we designed five Chinese sentiment analysis tasks based on seven public datasets, evaluated the tasks using popular lightweight domestic large language models, and compared their capabilities with deep learning models and ChatGPT. The results indicate that the performance of lightweight domestic large language models on Chinese sentiment analysis tasks surpasses that of deep learning models and approaches the performance of ChatGPT. Furthermore, we assessed enhancement techniques such as prompt word engineering and large model fine-tuning, revealing that the enhanced model's parameter count is merely 3.45% of ChatGPT's, while achieving 95.2% of ChatGPT's performance.},
booktitle = {Proceedings of the 4th Asia-Pacific Artificial Intelligence and Big Data Forum},
pages = {528–534},
numpages = {7}
}

@article{10.1145/3734867,
author = {Akli, Amal and Cordy, Maxime and Papadakis, Mike and Le Traon, Yves},
title = {AutoAdapt: On the Application of AutoML for Parameter-Efficient Fine-Tuning of Pre-Trained Code Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3734867},
doi = {10.1145/3734867},
abstract = {Large Language Models (LLMs) have demonstrated their ability to solve tasks across various domains, including software engineering. However, their extensive number of parameters makes full fine-tuning computationally prohibitive. While Parameter-efficient fine-tuning (PEFT) methods, such as adapter fine-tuning, have been proposed to address this issue; yet, they typically employ default configurations that use the same adapter settings across all layers. Concurrently, Automated Machine Learning (AutoML) has demonstrated success in hyperparameter optimization, while Neural Architecture Search (NAS) has proven effective in optimizing neural network architectures. Building on these successes, we introduce AutoAdapt, a novel approach that leverages NAS to automatically discover task-specific, layer-wide adapter configurations, allowing each layer to adopt distinct adapter parameters. AutoAdapt defines a search space tailored for adapter-based fine-tuning and employs an evolutionary algorithm to explore a diverse range of configurations, thereby evaluating the benefits of customizing each layer individually. We evaluate AutoAdapt on well-established software engineering tasks, including vulnerability detection, code clone detection, and code search. Our empirical results demonstrate that AutoAdapt outperforms manually engineered adapter configurations, achieving up to a 5% improvement in F1-score for clone detection and defect detection, and up to a 25% improvement in MRR for code search. Additionally, it surpasses other PEFT techniques, such as Prefix Tuning and LoRA. Furthermore, AutoAdapt is capable of identifying configurations that outperform even full fine-tuning, while training less than 2.5% of the model parameters. A comprehensive analysis reveals that factors such as selective layer adaptation, module selection (e.g., attention versus feed-forward layers), normalization, and dropout significantly influence performance across different tasks. Additionally, our findings suggest the possibility of transferring adapter configurations to similar datasets and tasks, thus simplifying the search for optimal PEFT settings. Our code and data are available for access at: https://github.com/serval-uni-lu/AutoAdapt},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {PEFT, pre-trained code models, Optimization, AutoML, NAS}
}

@article{10.1145/3719351,
author = {Grishina, Anastasiia and Liventsev, Vadim and H\"{a}rm\"{a}, Aki and Moonen, Leon},
title = {Fully Autonomous Programming Using Iterative Multi-Agent Debugging with Large Language Models},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
url = {https://doi.org/10.1145/3719351},
doi = {10.1145/3719351},
abstract = {Program synthesis with Large Language Models (LLMs) suffers from a “near-miss syndrome”: The generated code closely resembles a correct solution but fails unit tests due to minor errors. We address this with a multi-agent framework called Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively applying SEIDR to instruction-tuned LLMs requires determining (a) optimal prompts for LLMs, (b) what ranking algorithm selects the best programs in debugging rounds, and (c) balancing the repair of unsuccessful programs with the generation of new ones. We empirically explore these tradeoffs by comparing replace-focused, repair-focused, and hybrid debug strategies. We also evaluate lexicase and tournament selection to rank candidates in each generation. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms both conventional use of OpenAI Codex without a repair phase and traditional genetic programming approaches. SEIDR outperforms the use of an LLM alone, solving 18 problems in C++ and 20 in Python on PSB2 at least once across experiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the PSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not surpass current state-of-the-art methods on the Python benchmarks, the results on HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average pass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at least once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama 3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in program synthesis with LLMs.},
journal = {ACM Trans. Evol. Learn. Optim.},
month = mar,
articleno = {8},
numpages = {37},
keywords = {automatic programming, large language models, program repair}
}

@article{10.1145/3711000,
author = {Kapania, Shivani and Wang, Ruiyi and Li, Toby Jia-Jun and Li, Tianshi and Shen, Hong},
title = { 'I'm Categorizing LLM as a Productivity Tool': Examining Ethics of LLM Use in HCI Research Practices},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711000},
doi = {10.1145/3711000},
abstract = {Large language models are increasingly applied in real-world scenarios, including research and education. These models, however, come with well-known ethical issues, which may manifest in unexpected ways in human-computer interaction research due to the extensive engagement with human subjects. This paper reports on research practices related to LLM use, drawing on 16 semi-structured interviews and a survey with 50 HCI researchers. We discuss the ways in which LLMs are already being utilized throughout the entire HCI research pipeline, from ideation to system development and paper writing. While researchers described nuanced understandings of ethical issues, they were rarely or only partially able to identify and address those ethical concerns in their own projects. This lack of action and reliance on workarounds was explained through the perceived lack of control and distributed responsibility in the LLM supply chain, the conditional nature of engaging with ethics, and competing priorities. Finally, we reflect on the implications of our findings and present opportunities to shape emerging norms of engaging with large language models in HCI research.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW102},
numpages = {26},
keywords = {hci research, large language models, research ethics, research practices}
}

@article{10.5555/3729857.3729874,
author = {Bandi, Ajay and Blackford, Benjamin and Fellah, Aziz and Linville, Diana and Meyer, Trevor C. and Voss, Robert J.},
title = {Prompting Collaboration: Development of an Multidisciplinary Applied AI Minor Program},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has rapidly transformed industries and research, becoming a driving force for technological innovation and development [1]. As AI continues to grow and change, it is reshaping the way we approach problem-solving, decision-making, and creative processes across various sectors. Northwest Missouri State University is developing a new multidisciplinary AI minor open to all undergraduate students on campus. The program is tailored for students from any discipline who want to explore how AI can be utilized and integrated into their fields such as computer science, humanities, business, sciences, healthcare, agriculture, and education, among others. The curriculum integrates topics such as foundational AI concepts, prompt engineering and writing processes, ethical considerations in AI, AI in the workplace, and a capstone project. This program also promotes interdisciplinary collaboration and emphasizes the ethical use of AI.By the end of the program, students will be able to use AI to enhance efficiency and accuracy in tasks, develop and evaluate effective prompts, apply generative AI tools across various input formats, and assess the ethical considerations of AI in real-world applications. The panel members are experts from diverse fields, including management, humanities, technical writing, and computer science. The panel discusses the development of the AI minor curriculum and explores opportunities to extend the AI curriculum by offering AI certificates for undergraduate and graduate online professional students. By attending this panel, the audience will gain valuable insights into developing comprehensive AI programs, fostering cross-disciplinary innovation, and preparing students to use AI ethically and effectively across diverse fields.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {129–132},
numpages = {4}
}

@inproceedings{10.1145/3672608.3707798,
author = {Ehl, Marco and Ahmadian, Amir Shayan and Gro\ss{}er, Katharina and Elsofi, Duaa Adel Ali and Herrmann, Marc and Specht, Alexander and Schneider, Kurt and J\"{u}rjens, Jan},
title = {Supporting Software Engineers in IT Security and Privacy through Automated Knowledge Discovery},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707798},
doi = {10.1145/3672608.3707798},
abstract = {Security and privacy are increasingly essential concepts in software engineering. New threats and corresponding countermeasures are continuously discovered. Concurrently, projects are becoming more complex and are exposed to a greater number of threats. This presents a significant challenge for software engineers. As a result, security and privacy are often neglected due to a lack of knowledge, limited time, and financial constraints. While systematic literature reviews exist to address the increasing volume of publications, software engineers still require up-to-date knowledge of current threats and measures. This paper presents an automated, time-efficient, and cost-effective method for discovering knowledge from state-of-the-art literature and project artifacts, such as design documents. The presented method utilizes Large Language Models (LLMs) for data extraction and is demonstrated through a prototypical implementation and evaluation. This evaluation involves security and privacy in open-access scientific publications and project documentation from European Union research and development projects. The extracted knowledge is used to populate a quality model that is specifically designed to provide software engineers with information that helps them apply the findings. This quality model offers software engineers valuable, up-to-date insights into security and privacy, bridging the gap between scientific research and practical applications.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1647–1656},
numpages = {10},
keywords = {security, privacy, quality model, knowledge discovery, large language model},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3641554.3701883,
author = {Haji Amin Shirazi, Shirin and Pang, Ashley and Knight, Allan and Salloum, Mariam and Vahid, Frank},
title = {Midterm Exam Outliers Efficiently Highlight Potential Cheaters on Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701883},
doi = {10.1145/3641554.3701883},
abstract = {The ubiquitous use of online tools, contractors and homework sites, has made plagiarism a concerning topic in computer science education. With the introduction of ChatGPT, it poses a threat now more than ever. Many cheating detection tools, such as similarity checkers and style anomaly checkers, help instructors decide whether a student has plagiarized. However, these are not scalable to large classes. Similarity tools can produce high rates of suspected cheating and thus ineffectively use an instructor's time in weeding out the actual cheating cases, especially in the early weeks of CS courses where programs can be small and student solutions can be very similar. We developed a new approach using outlier detection to filter inconsistent performers based on their lab scores throughout the course and their midterm exam scores. Instructors can then manually analyze a manageable amount of students even with large class sizes. We performed our experiment on two large course offerings of CS1 (a total of 177 students) using our algorithm and compared it to a manual analysis performed by an experienced CS1 instructor. The detection approach identified 11 students in the first offering (Winter 2019) and 12 students in the second offering (Spring 2023). With an average precision of 83%, our tool produces a list of concerning students with high precision. This significantly helps teachers efficiently allocate their time and pursue cheating early in the term in order to address and prevent further issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {437–442},
numpages = {6},
keywords = {academic integrity, cs1, plagiarism, programming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705187,
author = {O'Neill, Abby and Smith, Samantha and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges},
title = {From Code to Concepts: Textbook-Driven Knowledge Tracing with LLMs in CS1},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705187},
doi = {10.1145/3641555.3705187},
abstract = {Gauging a student's understanding of course concepts, at an arbitrary point during a course, can be challenging. Standardized exams offer only a snapshot of performance rather than a deep understanding of progress. However, with Large Language Models (LLMs) now deployed at scale in CS1 courses, we can track multiple attempts from each student for every homework problem. This data provides insights into how students learn and deploy concepts over time, presenting a unique opportunity to rethink how we track changes in individual student knowledge. Traditional Knowledge Tracing (KT) methods often lack explainability and are computationally expensive. In contrast, our framework leverages an LLM to identify student progress on labeled, problem-level concepts from a student homework code submission. Our initial results show that the student's knowledge state can be dynamically updated. This knowledge state can then be used to provide more targeted, effective feedback and create tailored study materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1565–1566},
numpages = {2},
keywords = {artificial intelligence/machine learning, cs1/cs2, instructional technologies, programming, tools and tool use},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1613/jair.1.17028,
author = {Karev, Alexey and Xu, Dong},
title = {ConSCompF: Consistency-focused Similarity Comparison Framework for Generative Large Language Models},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17028},
doi = {10.1613/jair.1.17028},
abstract = {Large Language Models (LLM) are one of the most important discoveries in machine learning in recent years. LLM-based artificial intelligence (AI) assistants, such as ChatGPT, have consistently attracted attention from researchers, investors, and the general public, driving the rapid growth of this industry. With dozens of new LLMs released every month, it becomes quite challenging to differentiate between them, thereby creating a demand for new LLM comparison methods.
In this research, the Consistency-focused Similarity Comparison Framework (ConSCompF) for generative large language models is proposed. It compares texts generated by two LLMs and produces a similarity score, indicating the overall degree of similarity between their responses. The main advantage of this framework is that it can operate on a small number of unlabeled data, such as chatbot instruction prompts, and does not require LLM developers to disclose any information about their product.
To evaluate the efficacy of ConSCompF, two experiments aimed at identifying similarities between multiple LLMs are conducted. Additionally, these experiments examine the correlation between the similarity scores generated by ConSCompF and the differences in outputs produced by other benchmarking techniques, such as ROUGE-L. Finally, a series of few-shot LLM comparison experiments is conducted to evaluate the performance of ConSCompF in a few-shot LLM comparison scenario.
The proposed framework can be used for calculating similarity matrices of multiple LLMs, which can be effectively visualized using principal component analysis (PCA). The outputs of ConSCompF may provide useful insights into data that might have been used during LLM training and help detect potential investment fraud attempts.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {23},
keywords = {electronic health records, Medical Information, NLP, EHR, document level, deep learning, machine learning}
}

@inproceedings{10.1145/3717383.3721236,
author = {Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar},
title = {Seventh Workshop on Emerging Software Engineering Education(WESEE 2025)},
year = {2025},
isbn = {9798400714245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717383.3721236},
doi = {10.1145/3717383.3721236},
abstract = {The seventh Workshop on Emerging Software Engineering Education (WESEE) aims to discuss and examine the development of learning environments that are influencing the pedagogical strategies for the education of software engineering courses in institutions, specifically through the adoption of Generative AI (GenAI) tools and techniques. Additionally, the workshop aims to examine how industries are utilizing GenAI tools and technologies for teaching software development methods and how the developers are utilizing the material for self-learning and skill acquisition. The report is an overview of the upcoming seventh edition of WESEE, which will be held on 20th February 2025 at NIT Kurukshetra. The workshop will be held alongside the 18th Innovations in Software Engineering Conference (ISEC 2025).},
booktitle = {Proceedings of the 18th Innovations in Software Engineering Conference},
articleno = {22},
numpages = {3},
location = {
},
series = {ISEC '25}
}

@article{10.5555/3737313.3737323,
author = {Barnard, Jakob and Braught, Grant and Davis, Janet and Holland-Minkley, Amanda and Schmitt, Karl and Tartaro, Andrea},
title = {Reviewing and Revising your Undergraduate CS Major: A Structured Design Process for Creating Distinctive Curricula},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Computer science (CS) programs have a variety of reasons for regularly reviewing and revising the curriculum for their undergraduate major. Some of these stem from the rapid pace of change in the discipline and corresponding changes in industry expectations for CS graduates. This has been most recently seen as departments consider how to adjust to advances in generative AI and respond to new international curricular guidelines in the form of CS2023 [1]. Programs also revise their CS major in response to contextual shifts at their institution, such as changes in the size and makeup of the student body, the resources and staffing of a program, assessment results, or new institutional priorities [6]. A shifting student body may come with changes in prior experience with computing and in the professional goals of the students. For smaller programs, staffing changes often affect the balance of expertise within subareas of CS. New institutional priorities such as enabling more study abroad experiences or embedding internship/service-learning into the curriculum can require majors to adjust to both accommodate and support these priorities.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {32–34},
numpages = {3}
}

@article{10.5555/3737313.3737341,
author = {Morales, Christopher},
title = {The Effectiveness of ChatGPT in Coding Novel Agent Classes for a Predator-Prey Model-Inspired Iterated Prisoner's Dilemma Model},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {I present a variant of the Iterated Prisoner's Dilemma incorporating elements of a predator-prey model, and assess whether the popular large language models (LLMs) ChatGPT-4o and ChatGPT-4o Mini should be recommended for use by pre-introductory-programming simulation and modeling students to help explore novel strategies for success in the model. I find that the LLMs' output is too unreliable to recommend to students for unsupervised use. However, LLMs may still be useful tools when used under the guidance of an instructor.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {178–185},
numpages = {8}
}

@inproceedings{10.1145/3641555.3704765,
author = {Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug},
title = {Teaching with AI (GPT)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704765},
doi = {10.1145/3641555.3704765},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. In this tutorial, we share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's latest APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, collaboratively building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1773},
numpages = {1},
keywords = {AI, AI ethics, ChatGPT, GPT, generative AI, programming, prompt, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3695991,
author = {Dong, Yihong and Ding, Jiazheng and Jiang, Xue and Li, Ge and Li, Zhuo and Jin, Zhi},
title = {CodeScore: Evaluating Code Generation by Learning Code Execution},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {3},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695991},
doi = {10.1145/3695991},
abstract = {A proper code evaluation metric (CEM) profoundly impacts the evolution of code generation, which is an important research field in NLP and software engineering. Prevailing match-based CEMs (e.g., BLEU, Accuracy, and CodeBLEU) suffer from two significant drawbacks. 1. They primarily measure the surface differences between codes without considering their functional equivalence. However, functional equivalence is pivotal in evaluating the effectiveness of code generation, as different codes can perform identical operations. 2. They are predominantly designed for the Ref-only input format. However, code evaluation necessitates versatility in input formats. Aside from Ref-only, there are NL-only and Ref and NL formats, which existing match-based CEMs cannot effectively accommodate. In this article, we propose CodeScore, a large language model (LLM)-based CEM, which estimates the functional correctness of generated code on three input types. To acquire CodeScore, we present UniCE, a unified code generation learning framework, for LLMs to learn code execution (i.e., learning PassRatio and Executability of generated code) with unified input. Extensive experimental results on multiple code evaluation datasets demonstrate that CodeScore absolutely improves up to 58.87% correlation with functional correctness compared to other CEMs, achieves state-of-the-art performance, and effectively handles three input formats.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
articleno = {77},
numpages = {22},
keywords = {Code Evaluation, Code Pre-trained Language Model, Code Generation}
}

@inproceedings{10.1145/3677389.3702596,
author = {Chen, Yinlin and Xie, Zhiwu and Yang, Le},
title = {JCDL 2024 Workshop: Generative AI for Resource Discovery in Libraries},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702596},
doi = {10.1145/3677389.3702596},
abstract = {This workshop delves into the transformative role of Generative AI technologies in digital libraries, emphasizing advancements in resource discovery and user engagement. Participants will explore how cutting-edge large language models such as GPT-4 and Llama are leveraged to deliver highly personalized resource recommendations and improve the efficiency and precision of information retrieval processes. Through showcases of capstone projects developed as part of the AI Incubator Program, hands-on sessions, and collaborative discussions, attendees will gain practical insights into deploying AI-driven solutions that streamline library operations and elevate user experience.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {125},
numpages = {2},
keywords = {generative AI, large language model, retrieval-augmented generation},
location = {Hong Kong, China},
series = {JCDL '24}
}

@inproceedings{10.1145/3722237.3722266,
author = {Yang, Ye and Wen, Xiong and Maidin, Siti Sarah},
title = {Generative AI Tools in Higher Education Emerging Research: A Bibliometric analysis of co-citation and co-word analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722266},
doi = {10.1145/3722237.3722266},
abstract = {Artificial Intelligence (AI) is positively grasped as promising to disrupt the higher education system but it also poses a number of challenges. Although so many studies attempt to explore the matching of the possibility of this growing technology with the higher education system, ample research needs to be conducted to solve the challenges facing the renovation of higher education. With this in mind, our aim of bibliometric studies is to conduct a deep investigation into the increasingly developing scenario of Generative AI tools in higher education. We extracted data from the Web of Science database that is up-to-date till July 2024, comprising 934 relevant articles. Co-citation and co-word analyses revealed three main research clusters: advanced computationable methods, AI application in higher education, and user technology and adoption. The findings illustrated rapid diffusion of generative AI technologies with prominent emphasis on large-language models in pedagogical practices. Other critical themes center around developing AI-facilitated learning interventions, ethical challenges, and usage impact on learning outcomes. The results show that the field is inherently interdisciplinary, using ideas from educational technology, cognitive science, and AI. In addition, a rising trend is noted for the focus on academic honesty and users' involvement with AI devices. The results indicate the important implications of this study for teachers and policymakers alongside contributions to teaching and research that offer a guide to sustainable improvement across education. Future research would benefit from longitudinal studies drawing on an interdisciplinary approach to realize the long-term implications and address complex issues surrounding the integration of AI within universities.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {166–174},
numpages = {9},
keywords = {Generative AI, artificial intelligence, bibliometric, educational technology, higher education},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3641554.3701906,
author = {Hassan, Mohammed and Chen, Yuxuan and Denny, Paul and Zilles, Craig},
title = {On Teaching Novices Computational Thinking by Utilizing Large Language Models Within Assessments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701906},
doi = {10.1145/3641554.3701906},
abstract = {Novice programmers often struggle to develop computational thinking (CT) skills in introductory programming courses. This study investigates the use of Large Language Models (LLMs) to provide scalable, strategy-driven feedback to teach CT. Through think-aloud interviews with 17 students solving code comprehension and writing tasks, we found that LLMs effectively guided decomposition and program development tool usage. Challenges included students seeking direct answers or pasting feedback without considering suggested strategies. We discuss how instructors should integrate LLMs into assessments to support students' learning of CT.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {471–477},
numpages = {7},
keywords = {code comprehension, debuggers, execution, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705178,
author = {Eikmeier, Nicole and Perlmutter, Leah},
title = {Experiences Teaching A Course On Algorithms, Ethics, and Society},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705178},
doi = {10.1145/3641555.3705178},
abstract = {It is essential for CS students to graduate with competence about ethics and societal impacts of technology. We designed and taught a new reading discussion course, at Grinnell College, Algorithms, Ethics, and Society, for advanced undergraduate students who have completed CS1 and CS2. Course topics included Identity in Computing, Tech Ethics, Algorithms Informing Policies, Large Language Models, Networks and Social Media, Health Applications, and Robotics. We encountered some challenges with the discussion format, which we addressed by upholding class norms, employing discussion techniques learned from humanities and social science colleagues, and being open to learn from our mistakes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1449–1450},
numpages = {2},
keywords = {computer science education, computing and society, technology ethics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716657,
author = {Arora, Utkarsh and Garg, Anupam and Gupta, Aryan and Jain, Samyak and Mehta, Ronit and Oberoi, Rupin and Prachi and Raina, Aryaman and Saini, Manav and Sharma, Sachin and Singh, Jaskaran and Tyagi, Sarthak and Kumar, Dhruv},
title = {Analyzing LLM Usage in an Advanced Computing Class in India},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716657},
doi = {10.1145/3716640.3716657},
abstract = {This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys and interviews.Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {154–163},
numpages = {10},
keywords = {Large Language Models, Computing Education, User Study},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701910,
author = {Gonzalez-Maldonado, David and Liu, Jonathan and Franklin, Diana},
title = {Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701910},
doi = {10.1145/3641554.3701910},
abstract = {Though the increased availability of Large Language Models (LLMs) presents significant potential for change in the way students learn to program, the text-based nature of the available tools currently preclude block-based languages from much of that innovation. In an attempt to remedy this, we identify the strengths and weaknesses of using a transpiler to leverage the existing learning in commercially available LLMs and Scratch, a visual block-based programming language.Using only prompt engineering, we evaluate an LLM's performance on two common classroom tasks in a Scratch curriculum. We evaluate the LLM's ability to: 1) Create project solutions that compile and satisfy project requirements and 2) Analyze student projects' completion of project requirements using natural language. In both cases, we find results indicating that prompt-engineering alone is insufficient to reliably produce high-quality results. For projects of medium complexity, the LLM-generated solutions consistently failed to follow correct syntax or, in the few instances with correct syntax, produce correct solutions. When used for auto-grading, we found a correlation between scores assigned by the official Scratch Encore autograder and those generated by the LLM, nevertheless the discrepancies between the 'real' scores and the scores assigned by the LLM remained too great for the tool to be reliable in a classroom setting.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {388–394},
numpages = {7},
keywords = {block based programming, generative ai, k-12, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3672608.3707732,
author = {Raimondi, Bianca and Giallorenzo, Saverio and Gabbrielli, Maurizio},
title = {Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707732},
doi = {10.1145/3672608.3707732},
abstract = {In education, the capability of generating human-like text of Large Language Models (LLMs) inspired work on how they can increase the efficiency of learning and teaching. We study the affordability of these models for educators and students by investigating how LLMs answer multiple-choice questions (MCQs) with respect to hardware constraints and refinement techniques. We explore this space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming Languages (PL)—the MCQ dataset is a contribution of this work, which we make publicly available. Specifically, we dissect how different factors, such as using readily-available material—(parts of) the course's textbook—for fine-tuning and quantisation (to decrease resource usage) can change the accuracy of the responses. The main takeaway is that smaller textbook-based fine-tuned models outperform generic larger ones (whose pre-training requires conspicuous resources), making the usage of LLMs for answering MCQs resource- and material-wise affordable.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {32–39},
numpages = {8},
keywords = {education, large language models, multiple-choice questions, fine-tuning, quantisation},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3717512.3717515,
author = {Anwar, Mubashir and Caesar, Matthew},
title = {Understanding Misunderstandings: Evaluating LLMs on Networking Questions},
year = {2025},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/3717512.3717515},
doi = {10.1145/3717512.3717515},
abstract = {Large Language Models (LLMs) have demonstrated impressive abilities in tackling tasks across numerous domains. The capabilities of LLMs could potentially be applied to various computer networking tasks, including network synthesis, management, debugging, security, and education. However, LLMs can be unreliable: they are prone to reasoning errors and may hallucinate incorrect information. Their effectiveness and limitations in computer networking tasks remain unclear. In this paper, we attempt to understand the capabilities and limitations of LLMs in network applications. We evaluate misunderstandings regarding networking related concepts across 3 LLMs over 500 questions. We assess the reliability, explain-ability, and stability of LLM responses to networking questions. Furthermore, we investigate errors made, analyzing their cause, detectability, effects, and potential mitigation strategies.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = feb,
pages = {14–24},
numpages = {11},
keywords = {characterization study, computer networking, large language models}
}

@inproceedings{10.1145/3641555.3705212,
author = {Baek, Jeonghun and Yamazaki, Tetsuro and Morihata, Akimasa and Mori, Junichiro and Yamakata, Yoko and Taura, Kenjiro and Chiba, Shigeru},
title = {Leveraging LLM for Detecting and Explaining LLM-generated Code in Python Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705212},
doi = {10.1145/3641555.3705212},
abstract = {As large language models (LLMs) have become more advanced, generating code to solve exercises in programming courses has become significantly easier. However, this convenience raises the concern of over-reliance on these tools, potentially hindering students from developing independent coding skills. To address this concern, we introduce an LLM-based detector that not only detects LLM-generated code but also explains the reasons for its judgments. These reasons provide insight into the characteristics of LLM-generated code, enhancing transparency in the detection process. We evaluate the detector in an introductory Python programming course, achieving over 99% accuracy. Additionally, instructors manually reviewed the reasons provided by the detector and verified that 64.7% of reasons for classifying code as LLM-generated were appropriate. These reasons can also serve as feedback, helping students improve their coding skills by understanding the characteristics of expert-level LLM-generated code.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1369–1370},
numpages = {2},
keywords = {detecting and explaining llm-generated code, large language model, llm-based detector, llm-generated code, python programming courses, reasons for judgment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3737885,
author = {Brown, Neil C. C. and Weill-Tessier, Pierre and Leinonen, Juho and Denny, Paul and K\"{o}lling, Michael},
title = {Howzat? Appealing to Expert Judgement for Evaluating Human and AI Next-Step Hints for Novice Programmers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737885},
doi = {10.1145/3737885},
abstract = {Motivation: Students learning to program often reach states where they are stuck and can make no forward progress – but this may be outside the classroom where no instructor is available to help. In this situation, an automatically generated next-step hint can help them make forward progress and support their learning. It is important to know what makes a good hint or a bad hint, and how to generate good hints automatically in novice programming tools, for example using Large Language Models (LLMs).Method and participants: We recruited 44 Java educators from around the world to participate in an online study. We used a set of real student code states as hint-generation scenarios. Participants used a technique known as comparative judgement to rank a set of candidate next-step Java hints, which were generated by Large Language Models (LLMs) and by five human experienced educators. Participants ranked the hints without being told how they were generated. The hints were generated with no explicit detail given to the LLMs/humans on what the target task was. Participants then filled in a survey with follow-up questions. The ranks of the hints were analysed against a set of extracted hint characteristics using a random forest approach.Findings: We found that LLMs had considerable variation in generating high quality next-step hints for programming novices, with GPT-4 outperforming other models tested. When used with a well-designed prompt, GPT-4 outperformed human experts in generating pedagogically valuable hints. A multi-stage prompt was the most effective LLM prompt. According to a fitted random forest model, the two most important factors of a good hint were length (80–160 words being best), and reading level (US grade nine or below being best). Offering alternative approaches to solving the problem was considered bad, and we found no effect of sentiment.Conclusions: Automatic generation of these hints is immediately viable, given that LLMs outperformed humans – even when the students’ task is unknown. Hint length and reading level were more important than several pedagogical features of hints. The fact that it took a group of experts several rounds of experimentation and refinement to design a prompt that achieves this outcome suggests that students on their own are unlikely to be able to produce the same benefit. The prompting task, therefore, should be embedded in an expert-designed tool.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = may,
keywords = {LLMs, AI, Java, Next-step hints, comparative judgement}
}

@inproceedings{10.1145/3723010.3723034,
author = {Mueller, Moritz and List, Corinna and Kipp, Michael},
title = {The Power of Context: An LLM-based Programming Tutor with Focused and Proactive Feedback},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723034},
doi = {10.1145/3723010.3723034},
abstract = {Current research aims to utilize Large Language Models (LLMs) for tutoring beginning programming students efficiently and at scale. Students often struggle to interact effectively with LLMs to obtain meaningful feedback. We introduce an LLM-based Intelligent Tutoring System (ITS) with a structured interface and prompts aligned with Hattie’s feedback model. To provide more focused feedback, we utilize the user interaction history for context. Additionally, we explore the question of proactivity.A user study with 9 participants compared history-based and current-state feedback methods using ChatGPT, showing a preference for history-based feedback in 69% of cases and with higher usefulness ratings (M = 7.57 vs. M = 4.1, p = 0.03 (statistically significant at p &lt; 0.05)). This effect became more pronounced in later learning stages. For proactivity, we collected user data from the study, where participants explicitly requested feedback, and trained a neural network (NN) to predict optimal feedback timing. While the model achieved 97% accuracy on test data, the small sample size (N = 10) and the use of oversampling limit its generalizability. Future work will refine history-based feedback with eye-tracking data and integrate NN-driven proactive behavior to further enhance the effectiveness of LLM-based ITS in programming education.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {1–10},
numpages = {10},
keywords = {CS in higher education, Large Language Models, intelligent tutoring, focused feedback, proactive feedback, neural networks},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641554.3701791,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul},
title = {Evaluating Language Models for Generating and Judging Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701791},
doi = {10.1145/3641554.3701791},
abstract = {The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {624–630},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, generative ai, large language models, llm-as-a-judge, open source, programming feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720203,
author = {Tang, Xiaohang and Wong, Sam and Huynh, Marcus and He, Zicheng and Yang, Yalong and Chen, Yan},
title = {SPHERE: Supporting Personalized Feedback at Scale in Programming Classrooms with Structured Review of Generative AI Outputs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720203},
doi = {10.1145/3706599.3720203},
abstract = {This paper introduces SPHERE, a system that enables instructors to effectively create and review personalized feedback for in-class coding activities. Comprehensive personalized feedback is crucial for programming learning. However, providing such feedback in large programming classrooms poses significant challenges for instructors. While Large Language Models (LLMs) offer potential assistance, how to efficiently ensure the quality of LLM-generated feedback remains an open question. SPHERE guides instructors’ attention to critical students’ issues, empowers them with guided control over LLM-generated feedback, and provides visual scaffolding to facilitate verification of feedback quality. Our between-subject study with 20 participants demonstrates SPHERE’s effectiveness in creating more high-quality feedback while not increasing the time spent on the overall review process compared to a baseline system. This work contributes a synergistic approach to scaling personalized feedback in programming education, addressing the challenges of real-time response, issue prioritization, and large-scale personalization.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {17},
keywords = {Generative AI, Large Language Model, Programming Education at Scale, Feedback, Computing Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705281,
author = {Li, Carol and Park, Su Min and Tsang, Jedidiah and Yan, Lisa},
title = {What Gets Them Talking? Identifying Catalysts for Student Engagement Within a Computing Ethics Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705281},
doi = {10.1145/3641555.3705281},
abstract = {The expansion of undergraduate CS programs brings different forms of student identity, sociotechnical perspectives, and intersectionality into the classroom. These background factors affect student understanding of the world, and, consequently, their work in computing ethic classes. Instructors of computing ethics courses therefore must facilitate topics that are not only pertinent to modern technologies but that are also interesting for students from a range of backgrounds. In this work, we introduce a low-overhead, natural language processing tool that can assist instructors in extracting student talking points from over 600 discussion forum posts in a large-scale undergraduate computing ethics course. When compared to large language model approaches, this n-gram-based scripting tool is more effective in selecting popular quotes and summarizing course discussion. This tool is simple in implementation and can be easily adapted by instructors to prepare for classroom discussion.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {computing ethics, llm-based tool, n-gram-based tool, open pedagogy, student engagement},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701844,
author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
title = {Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701844},
doi = {10.1145/3641554.3701844},
abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1302–1308},
numpages = {7},
keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3708557.3716160,
author = {Dinakar, Karthik and Lieberman, Henry and Wu, Meng-Hsin},
title = {MIND (Mixed-Initiative Next-gen Design): Workshop on Blending Agents and Direct Manipulation for Harnessing LLMs},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716160},
doi = {10.1145/3708557.3716160},
abstract = {Since the 1980s, a key debate in human-centered computing involving machine learning at IUI is between agent-driven systems and direct manipulation. The explosion of Large Language Models (LLMs), particularly auto-regressive as agents serving as chatbots, generative search, and work automation tools, has also brought with it inherent limitations. We posit that efforts to address and alleviate these LLM challenges—hallucinations, unpredictable outputs, lack of transparency, and difficulties in customization—cannot be solved through algorithmic improvements alone but require elevated mixed-initiative interface design at the heart of the IUI community. This workshop aims to bridge the gap between agent-driven automation and direct manipulation by exploring mixed-initiative interaction models that blend the strengths of both paradigms to empower end-users seeking to harness LLMs.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {187–188},
numpages = {2},
keywords = {Direct manipulation, Agents, Human-Centered Design, Mixed-Initiative Interfaces},
location = {
},
series = {IUI '25 Companion}
}

@inbook{10.1145/3677389.3702547,
author = {Ren, Jiayu and Lin, Chenxi and He, Guoxiu},
title = {Divide and Conquer: Prompting Large Language Models to Identify Personalities in Long Social Posts via Chunked Voting},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702547},
abstract = {Predicting user personality from online posts is a critical endeavor in many social science fields. Previous studies have confirmed that large language models (LLMs) often struggle with processing lengthy contexts. To this end, we propose a divide-and-conquer prompting strategy. Initially, the original text is divided into multiple chunks. The LLM is then prompted to estimate the probability of each chunk corresponding to various personality traits, grounded in established definitions. Finally, these estimates are aggregated using a voting mechanism to yield a final personality assessment. Extensive experiments show that our strategy effectively unlocks the potential of LLMs, surpassing direct inference results from GPT-4 on two benchmarks.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {77},
numpages = {3}
}

@inproceedings{10.1145/3716640.3716658,
author = {Feng, Tony Haoran and Luxton-Reilly, Andrew and W\"{u}nsche, Burkhard C and Denny, Paul},
title = {From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716658},
doi = {10.1145/3716640.3716658},
abstract = {Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes.In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {164–171},
numpages = {8},
keywords = {Generative Artificial Intelligence, GenAI, Strategy, Assignments, Metacognition, Assessments},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701953,
author = {Deb, Debzani and Taylor, Greg and Betz, Scott and Maddux, Bao Anh T. and Ebert, C. Edward and Richardson, Flourice W. and Couto, Jeanine Lino S. and Jarrett, Michael S. and Madjd-Sadjadi, Zagros},
title = {Enhancing University Curricula with Integrated AI Ethics Education: A Comprehensive Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701953},
doi = {10.1145/3641554.3701953},
abstract = {As AI technologies become more prevalent, it is crucial for students to develop responsible, ethical, and proactive AI engagement skills. Recent educational initiatives have focused on enhancing CS and engineering students' AI ethics education but have largely overlooked integrating these concepts across other disciplines. This paper presents and assesses a pioneering initiative that integrates AI ethics into university curricula through a collaborative framework between CS and domain educators. We introduced 1-3 week AI ethics modules in seven diverse courses from Art to Chemistry, incorporating case studies and hands-on activities using chat- or image-based Large Language Models (LLMs). Student surveys indicated significant gains in confidence regarding AI ethics discussions, application of principles, and reasoning skills. Our approach advocates for utilizing structured frameworks and faculty collaboration in embedding AI ethics into university curricula, enhancing students' practical skills and ethical understanding across diverse professional settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {248–254},
numpages = {7},
keywords = {ai ethics, computing education, ethics education, inclusive computing curricula and pedagogy, non-majors},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720081,
author = {Patton, Evan W and Kim, David Y and Granquist, Ashley M and Liu, Robin and Scott, Arianna and Zamanova, Jennet and Abelson, Harold},
title = {Aptly: Making Mobile Apps from Natural Language},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720081},
doi = {10.1145/3706599.3720081},
abstract = {This paper introduces Aptly, a platform designed to democratize mobile app development, particularly for young learners. Aptly integrates a Large Language Model (LLM) with App Inventor, enabling users to create apps using their natural language. User’s description is translated into a programming language that corresponds with App Inventor’s visual blocks. A preliminary study with high school students demonstrated the usability and potential of the platform. Prior programming experience influenced how users interact with Aptly. Participants identified areas for improvement and expressed a shift in perspective regarding programming accessibility and AI’s role in creative endeavors.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {73},
numpages = {6},
keywords = {Computational Action, Large Language Model, Block Programming, Mobile Application},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701972,
author = {Ahmed, Umair Z. and Sahai, Shubham and Leong, Ben and Karkare, Amey},
title = {Feasibility Study of Augmenting Teaching Assistants with AI for CS1 Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701972},
doi = {10.1145/3641554.3701972},
abstract = {With the increasing adoption of Large Language Models (LLMs), there are proposals to replace human Teaching Assistants (TAs) with LLM-based AI agents for providing feedback to students. In this paper, we explore a new hybrid model where human TAs receive AI-generated feedback for CS1 programming exercises, which they can then review and modify as needed. We conducted a large-scale randomized intervention with 185 CS1 undergraduate students, comparing the efficacy of this hybrid approach against manual feedback and direct AI-generated feedback.Our initial hypothesis predicted that AI-augmented feedback would improve TA efficiency and increase the accuracy of guidance to students. However, our findings revealed mixed results. Although students perceived improvements in feedback quality, the hybrid model did not consistently translate to better student performance. We also observed complacency among some TAs who over-relied on LLM generated feedback and failed to identify and correct inaccuracies. These results suggest that augmenting human tutors with AI may not always result in improved teaching outcomes, and further research is needed to ensure it is truly effective.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {11–17},
numpages = {7},
keywords = {cs1, gpt, hint, llm, programming, randomized trial, ta},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3696443.3708944,
author = {Lee, Yoon Noh and Yu, Yongseung and Park, Yongjun},
title = {CUrator: An Efficient LLM Execution Engine with Optimized Integration of CUDA Libraries},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708944},
doi = {10.1145/3696443.3708944},
abstract = {Large Language Models (LLMs) have recently emerged as a state-of-the-art learning model with a wide range of applications in diverse computing environments. Among the various computational operations that comprise the LLM, the GEneral Matrix Multiplication (GEMM) operation is the most frequently utilized operation within the LLM. GEMM libraries such as cuBLAS and CUTLASS provide a variety of optimization techniques to achieve optimal GEMM performance in GPU-enabled computing environments. In particular, the CUTLASS open-source library for GPUs within the CUDA programming environment provides users with the capability to optimize templates for high performance. Previous research has demonstrated the effectiveness of CUTLASS-based GEMMs in improving the performance of real-world deep neural networks on various deep learning platforms. However, these studies have not considered different model parameters for modern LLMs nor have they explored the impact of diverse GPU computing environments.                                                                                                                                                                                                This paper presents CUrator, an efficient LLM execution engine that can achieve optimal end-to-end LLM performance using both cuBLAS and CUTLASS libraries on different GPUs for modern LLMs such as BERT, GPT, and Llama. CUrator first generates CUTLASS-/cuBLAS-friendly graph IRs of various LLMs on the TVM framework to maximize mapping coverage. On the CUTLASS mapping path, it performs a comprehensive search for programmable tuning parameters in the CUTLASS library with the objective of deriving optimal kernels for all GEMMs within each LLM. CUrator further introduces two optimization techniques: 1) build-time reduction key initialization support for CUTLASS Split-K GEMMs, and 2) Split-K support for CUTLASS Batch GEMMs. Finally, CUrator selects the best performing mapping path between cuBLAS and CUTLASS paths. The experimental results show that CUrator achieves inference speedups of 1.50\texttimes{} and 4.99\texttimes{}, respectively, for representative LLMs on the A100 GPU in the single and half precision, compared to the baseline. We strongly believe that the CUrator framework can provide the best direction for next-generation tuning frameworks by showing the maximum end-to-end performance of various LLMs on various GPUs.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {209–224},
numpages = {16},
keywords = {Compiler, GEMM, GPU, Large Language Model},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3696673.3723069,
author = {Meda, Kavya Nikhita and Nara, Pavan Subhash Chandrabose and Bozenka, Svoboda and Zormati, Tarek and Turner, Seth and Worley, Wayne and Mitra, Reshmi},
title = {Integrating Prompt Structures Using LLM Embeddings for Cybersecurity Threats},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723069},
doi = {10.1145/3696673.3723069},
abstract = {This paper aims to develop a specialized Large Language Model (LLM) for cybersecurity training, designed to educate users on fundamental cybersecurity concepts. This paper focuses on creating an interactive system where users can ask questions about computer security and receive accurate, informative responses. By addressing cybersecurity as a critical national issue, the LLM empowers individuals and organizations to defend against malicious cyber threats. Our system was developed using Python, utilizing Google Sheets as a database, Gradio for the user interface, and Google Gemini's API for advanced language processing. The implementation followed a test-driven development approach, iterating between coding and testing to ensure functionality and reliability. Key technologies include Mistral's Large 2 model and embedding models for clustering related data. The Retrieval-Augmented Generation (RAG) framework was employed to integrate information retrieval with the LLM, enhancing its accuracy and relevance. Tools such as Google Suite, Colab, and Gradio contributed to creating a robust and user-friendly system. This paper highlights the potential of domain-specific LLMs, offering a practical solution to the growing need for accessible cybersecurity education and fostering awareness to mitigate the risks posed by malicious hackers.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {180–187},
numpages = {8},
keywords = {large language model (LLM), embedding models, retrieval-augmented generation (RAG), information retrieval, cybersecurity education},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3706598.3713274,
author = {Zheng, Chanjin and Yu, Zengyi and Jiang, Yilin and Zhang, Mingzi and Lu, Xunuo and Jin, Jing and Gao, Liteng},
title = {ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713274},
doi = {10.1145/3706598.3713274},
abstract = {Can Multimodal Large Language Models (MLLMs), with capabilities in perception, recognition, understanding, and reasoning, act as independent assistants in art evaluation dialogues? Current MLLM evaluation methods, reliant on subjective human scoring or costly interviews, lack comprehensive scenario coverage. This paper proposes a process-oriented Human-Computer Interaction (HCI) space design for more accurate MLLM assessment and development. This approach aids teachers in efficient art evaluation and records interactions for MLLM capability assessment. We introduce ArtMentor, a comprehensive space integrating a dataset and three systems for optimized MLLM evaluation. It includes 380 sessions from five art teachers across nine critical dimensions. The modular system features entity recognition, review generation, and suggestion generation agents, enabling iterative upgrades. Machine learning and natural language processing ensure reliable evaluations. Results confirm GPT-4o’s effectiveness in assisting teachers in art evaluation dialogues. Our contributions are available at https://artmentor.github.io/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {18},
keywords = {AI-Assisted Artwork Evaluation, GPT-4o, Multimodal Large Language Models, Human-Computer Interaction Dataset Design, Entity Recognition, Multi-Agent for Iterative Upgrades.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3669940.3707215,
author = {Mei, Yixuan and Zhuang, Yonghao and Miao, Xupeng and Yang, Juncheng and Jia, Zhihao and Vinayak, Rashmi},
title = {Helix: Serving Large Language Models over Heterogeneous GPUs and Network via Max-Flow},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707215},
doi = {10.1145/3669940.3707215},
abstract = {This paper introduces Helix, a distributed system for high-throughput, low-latency large language model (LLM) serving in heterogeneous GPU clusters. The key idea behind Helix is to formulate inference computation of LLMs over heterogeneous GPUs and network connections as a max-flow problem on directed, weighted graphs, whose nodes represent GPU instances and edges capture both GPU and network heterogeneity through their capacities. Helix then uses a mixed integer linear programming (MILP) algorithm to discover highly optimized strategies to serve LLMs on heterogeneous GPUs. This approach allows Helix to jointly optimize model placement and request scheduling, two highly entangled tasks in heterogeneous LLM serving. Our evaluation on several heterogeneous clusters ranging from 24 to 42 GPU nodes shows that Helix improves serving throughput by up to 3.3x and reduces prompting and decoding latency by up to 66% and 24%, respectively, compared to existing approaches. Helix is available at https://github.com/Thesys-lab/Helix-ASPLOS25.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {586–602},
numpages = {17},
keywords = {cloud computing, distributed systems, large language model serving, system for ml},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3701716.3715523,
author = {Dey, Prasenjit and Merugu, Srujana and Kaveri, Sivaramakrishnan},
title = {Uncertainty-Aware Fusion: An Ensemble Framework for Mitigating Hallucinations in Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715523},
doi = {10.1145/3701716.3715523},
abstract = {Large Language Models (LLMs) are known to hallucinate and generate non-factual outputs which can undermine user trust. Traditional methods to directly mitigate hallucinations, such as representation editing and contrastive decoding, often require additional training data and involve high implementation complexity. While ensemble-based approaches harness multiple LLMs to tap into the ''wisdom of crowds'', these methods overlook uncertainties in individual model responses. Recent studies reveal that uncertainty estimation can enable LLMs to self-assess the likelihood of generating hallucinations. In this work, we focus on factoid question answering (QA) and observe that LLMs accuracy and self-assessment capabilities vary widely with different models excelling in different scenarios. Leveraging this insight, we propose Uncertainty-Aware Fusion (UAF), an ensemble framework to reduces hallucinations by strategically combining multiple LLM based on their accuracy and self-assessment abilities. Empirical results on several public benchmark datasets show that UAF outperforms state-of-the-art hallucination mitigation methods by 8% in factual accuracy, while either narrowing or surpassing the performance gap with GPT-4.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {947–951},
numpages = {5},
keywords = {ensemble, hallucination detection, large language models, uncertainty},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3715908,
author = {Li, Jia and Tao, Chongyang and Li, Jia and Li, Ge and Jin, Zhi and Zhang, Huangzhao and Fang, Zheng and Liu, Fang},
title = {Large Language Model-Aware In-Context Learning for Code Generation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715908},
doi = {10.1145/3715908},
abstract = {Large Language Models (LLMs) have shown impressive In-Context Learning (ICL) ability in code generation. LLMs take a prompt context consisting of a few demonstration examples and a new requirement as input, and output new programs without any parameter update. Existing studies have found that the performance of ICL-based code generation heavily depends on the quality of demonstration examples and thus arises research on selecting demonstration examples: given a new requirement, a few demonstration examples are selected from a candidate pool, where LLMs are expected to learn the pattern hidden in these selected demonstration examples. Existing approaches are mostly based on heuristics or randomly selecting examples. However, the distribution of randomly selected examples usually varies greatly, making the performance of LLMs less robust. The heuristics retrieve examples by only considering textual similarities of requirements, leading to sub-optimal performance.To fill this gap, we propose a Large language model-Aware selection approach for In-context-Learning-based code generation named LAIL. LAIL uses LLMs themselves to select examples. It requires LLMs themselves to label a candidate example as a positive example or a negative example for a requirement. Positive examples are helpful for LLMs to generate correct programs, while negative examples are trivial and should be ignored. Based on the labeled positive and negative data, LAIL trains a model-aware retriever to learn the preference of LLMs and select demonstration examples that LLMs need. During the inference, given a new requirement, LAIL uses the trained retriever to select a few examples and feed them into LLMs to generate desired programs. We apply LAIL to four widely used LLMs and evaluate it on five code generation datasets. Extensive experiments demonstrate that LAIL outperforms the state-of-the-art (SOTA) baselines by 11.58%, 3.33%, and 5.07% on CodeGen-Multi-16B, 1.32%, 2.29%, and 1.20% on CodeLlama-34B, and achieves 4.38%, 2.85%, and 2.74% improvements on Text-davinci-003 in terms of Pass@1 at MBJP, MBPP, and MBCPP, respectively. In addition to function-level code generation, LAIL improves the performance of LLMs on DevEval, a repository-level code generation dataset, which achieves 10.04%, 8.12%, and 4.63% improvements compared to the SOTA baselines at Pass@1, 3, and 5 on CodeLlama-7B. Human evaluation further verifies that the generated programs of LAIL are superior in correctness, code quality, and maintainability. Besides, LAIL has satisfactory transferability across different LLMs and datasets, where the retriever learned on one LLM (dataset) can be transferred to other LLMs (datasets).},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Code generation, in-context-learning, large language model}
}

@article{10.1145/3704739,
author = {Le, Linh and Tran, Dung},
title = {A Metric-Based Detection System for Large Language Model Texts},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3704739},
doi = {10.1145/3704739},
abstract = {More efforts are being put into improving the capabilities of Large Language Models (LLM) than into dealing with their implications. Current LLMs are able to generate high-quality texts seemingly indistinguishable from those written by human experts. While offering great potential, such breakthroughs also pose new challenges for safe and ethical uses of LLMs in education, science, and a multitude of other areas. Thus, majority of current approaches in LLM text detection are either computationally expensive or need access to the LLMs’ internal computations, both of which hinder their public accessibility. With such motivation, this article presents a novel metric learning paradigm for detection of LLM-generated texts that is able to balance computational costs, accessibility, and performances. Specifically, the detection is based on learning a similarity function between a given text and an equivalent example generated by LLMs that outputs high values for LLM-LLM text pairs and low values for LLM-human text pairs. In terms of architecture, the detection framework includes a pre-trained language model for the text embedding task and a newly designed deep metric model. The metric component can be trained on triplets or pairs of same-context instances to signify the distances between human and LLM texts while reducing that among LLM texts. Next, we develop five datasets totaling more than 95,000 contexts and triplets of responses in which one is from humans and two are from GPT-3.5 TURBO or GPT-4 TURBO for benchmarking. Experiment studies show that our best architectures maintain F1 scores between 0.87 and 0.95 across the tested corpora in multiple experiment settings. The metric framework also demands significantly less time in training and inference compared to RoBERTa, LLaMA 3, Mistral v0.3, and Ghostbuster, while keeping 90% to 150% performance of the best benchmark.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {8},
numpages = {19},
keywords = {LLM text detection, contrastive learning, triplet learning, metric learning}
}

@article{10.1145/3735635,
author = {Zhao, Zixiao and Fard, Fatemeh},
title = {Do Current Language Models Support Code Intelligence for R Programming Language?},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735635},
doi = {10.1145/3735635},
abstract = {Recent advancements in developing Pre-trained Language Models for Code (Code-PLMs) have urged many areas of Software Engineering (SE) and brought breakthrough results for many SE tasks. Though these models have achieved the state-of-the-art performance for SE tasks for many popular programming languages, such as Java and Python, the Scientific Software and its related languages like R programming language have rarely benefited or even been evaluated with the Code-PLMs. Research has shown that R has many differences with other programming languages and requires specific techniques. In this study, we provide the first insights for code intelligence for R. For this purpose, we collect and open source an R dataset, and evaluate Code-PLMs for the two tasks of code summarization and method name prediction using several settings and strategies, including the differences in two R styles, Tidy-verse and Base R. Our results demonstrate that the studied models have experienced varying degrees of performance degradation when processing R programming language code, which is supported by human evaluation. Additionally, not all models show performance improvement in R-specific tasks even after multi-language fine-tuning. The dual syntax paradigms in R significantly impact the models’ performance, particularly in code summarization tasks. Furthermore, the project-specific context inherent in R codebases significantly impacts the performance when attempting cross-project training. Interestingly, even when Large Language Models like CodeLlama and StarCoder2 are used for code generation, the Pass@K ( (K=1,5,10) ) results lags signigicantly behind Python scores. Our research shows that R as a low resource language requires different techniques to collect a high quality data. Specifically separating the two R styles has a great impact on the results and the separate dataset could increase the performance of the models. Our research sheds light on the capabilities of Code-PLMs and opens new research directions for researchers and practitioners for developing code intelligence tools and techniques for R. With R's widespread use and popularity, the results of our study can potentially benefit a large community of R developers, both in research and industry.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Empirical Studies, Code Summarization, Method Name Prediction, R Programming Language, Code Generation in R, R programming Styles (Tidy-verse and Base)}
}

@inproceedings{10.1145/3707292.3707389,
author = {Li, Yanjun and Yang, Ruiting and Guo, Donghao and Song, Yu},
title = {Research on the Construction of Digital Knowledge Graphs Based on Resources of National First-Class Undergraduate Programs},
year = {2025},
isbn = {9798400707308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3707292.3707389},
doi = {10.1145/3707292.3707389},
abstract = {[Purpose/Significance]: The digitalization of education is an essential path to advancing higher education. The construction of knowledge graphs is a key approach to achieving the digitalization and intelligence of education. [Method/Process]: This paper leverages the rich video resources of existing national first-class undergraduate programs and, based on the teaching orientations of different universities, independently designs customized ontologies and extraction principles. These are then integrated into the LLM knowledge graph builder to ensure the hierarchical structure of the overall course framework. The course video content is transformed into text form, and large language models (LLMS) and word segmentation tools are used for core content extraction, text cleaning, and lexical analysis. The structured text is then converted into SPO (Subject-Predicate-Object) triplets database. [Results/Conclusions]: Finally, the database is imported into the LLM knowledge graph builder, which is pre-configured with extraction rules. It will automatically generate the knowledge graph. After the text is imported into the LLM knowledge graph builder, it will be manually checked to ensure it better meets the actual needs of the students. [Innovation/Limitations]: The research team plans to apply the knowledge graph to train a specialized knowledge-based Q&amp;A assistant. This will support students' understanding and self-assessment of knowledge points in an online learning community. Student feedback will be used to improve and enrich the knowledge graph. Compared to existing methods, this approach better aligns with the constantly evolving digital teaching resources available online, offering more comprehensive and higher-level automation.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Intelligent Information Processing},
pages = {353–359},
numpages = {7},
keywords = {Knowledge graph, course resources, intelligent Q&amp;A, ontology construction, personalized learning},
location = {
},
series = {AIIIP '24}
}

@inproceedings{10.1145/3641555.3705175,
author = {Bouamor, Houda and Gongora-Svartzman, Gabriela and Heimann, Larry and Huang, Shihong},
title = {Evaluating GenAI's Effectiveness for Students with Varied Programming Backgrounds in a Software Development Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705175},
doi = {10.1145/3641555.3705175},
abstract = {Using Generative AI (GenAI) tools in education presents both opportunities and challenges to the traditional teaching methods and students' learning experience and outcomes, particularly in technical and programming courses. This experience report evaluates the impact of GenAI tools, specifically ChatGPT and GitHub CoPilot, in leveling the playing field for Information Systems students with varying technical backgrounds in an application design and development course. By integrating these tools into course labs and projects, this study aimed to determine whether they improve the success rates of less technically prepared and struggling students. Data were collected from five sessions of a semester-long course across two campuses, involving 162 students with five parallel sessions across two continents. The analysis of student performance metrics and surveys revealed that GenAI tools significantly helped students complete programming tasks. However, those who were less technically prepared and relied heavily on AI assistance struggled with more complex, transformative tasks, such as closed-book exams. These findings suggest that while GenAI tools can help close gaps in temporary programming skills, they are less effective - and may even exacerbate disparities - in fostering long-term deeper learning and developing transformative knowledge and critical thinking.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1395–1396},
numpages = {2},
keywords = {generative AI, impact of Genai tools in education, information systems education (IS), leveling playfield, programming background, student performance evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3676536.3699507,
author = {Liao, Yuchao and Adegbija, Tosiron and Lysecky, Roman},
title = {Are LLMs Any Good for High-Level Synthesis?},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3699507},
doi = {10.1145/3676536.3699507},
abstract = {The increasing complexity and demand for faster, energy-efficient hardware designs necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores the potential of Large Language Models (LLMs) to streamline or replace the HLS process, leveraging their ability to understand natural language specifications and refactor code. We survey the current research and conduct experiments comparing Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced by LLMs translating C code or natural language specifications. Our evaluation focuses on quantifying the impact on performance, power, and resource utilization, providing an assessment of the efficiency of LLM-based approaches. This study aims to illuminate the role of LLMs in HLS, identifying promising directions for optimized hardware design in applications such as AI acceleration, embedded systems, and high-performance computing.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {29},
numpages = {8},
keywords = {high-level synthesis, hardware accelerator design, electronic design automation, large language models},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@article{10.1145/3736721,
author = {Qin, Ruiyang and Liu, Dancheng and Xu, Chenhui and Yan, Zheyu and Tan, Zhaoxuan and Jia, Zhenge and Nassereldine, Amir and Li, Jiajie and Jiang, Meng and Abbasi, Ahmed and xiong, jinjun and Shi, Yiyu},
title = {Empirical Guidelines for Deploying LLMs onto Resource-constrained Edge Devices},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3736721},
doi = {10.1145/3736721},
abstract = {The scaling laws have become the de facto guidelines for designing large language models (LLMs), but they were studied under the assumption of unlimited computing resources for both training and inference. As LLMs are increasingly used as personalized intelligent assistants, their customization (i.e., learning through fine-tuning) and deployment onto resource-constrained edge devices will become more and more prevalent. An urgent but open question is how a resource-constrained computing environment would affect the design choices for a personalized LLM. We study this problem empirically in this work. In particular, we consider the tradeoffs among a number of key design factors and their intertwined impacts on learning efficiency and accuracy. The factors include the learning methods for LLM customization, the amount of personalized data used for learning customization, the types and sizes of LLMs, the compression methods of LLMs, the amount of time afforded to learn, and the difficulty levels of the target use cases. Through extensive experimentation and benchmarking, we draw a number of surprisingly insightful guidelines for deploying LLMs onto resource-constrained devices. For example, an optimal choice between parameter learning and RAG may vary depending on the difficulty of the downstream task, the longer fine-tuning time does not necessarily help the model, and a compressed LLM may be a better choice than an uncompressed LLM to learn from limited personalized data.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {Do, Not, Us, This, Code, Put, the, Correct, Terms, for, Your, Paper}
}

@article{10.1145/3708529,
author = {Lin, Zhihao and Ma, Wei and Lin, Tao and Zheng, Yaowen and Ge, Jingquan and Wang, Jun and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F. and Liu, Yang and Li, Li},
title = {Open Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708529},
doi = {10.1145/3708529},
abstract = {Large language models (LLMs) have become instrumental in advancing software engineering (SE) tasks, showcasing their efficacy in code understanding and beyond. AI code models have demonstrated their value not only in code generation but also in defect detection, enhancing security measures and improving overall software quality. They are emerging as crucial tools for both software development and maintaining software quality. Like traditional SE tools, open source collaboration is key in realizing the excellent products. However, with AI models, the essential need is in data. The collaboration of these AI-based SE models hinges on maximizing the sources of high-quality data. However, data, especially of high quality, often hold commercial or sensitive value, making them less accessible for open source AI-based SE projects. This reality presents a significant barrier to the development and enhancement of AI-based SE tools within the SE community. Therefore, researchers need to find solutions for enabling open source AI-based SE models to tap into resources by different organizations. Addressing this challenge, our position article investigates one solution to facilitate access to diverse organizational resources for open source AI models, ensuring that privacy and commercial sensitivities are respected. We introduce a governance framework centered on federated learning (FL), designed to foster the joint development and maintenance of open source AI code models while safeguarding data privacy and security. Additionally, we present guidelines for developers on AI-based SE tool collaboration, covering data requirements, model architecture, updating strategies, and version control. Given the significant influence of data characteristics on FL, our research examines the effect of code data heterogeneity on FL performance. We consider six different scenarios of data distributions and include four code models. We also include four most common FL algorithms. Our experimental findings highlight the potential for employing FL in the collaborative development and maintenance of AI-based SE models. We also discuss the key issues to be addressed in the co-construction process and future research directions.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {126},
numpages = {24},
keywords = {Data Privacy, Software Engineering, Open Source Code Model, Federated Learning}
}

@inproceedings{10.1145/3641554.3701974,
author = {P?durean, Victor-Alexandru and Denny, Paul and Singla, Adish},
title = {BugSpotter: Automated Generation of Code Debugging Exercises},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701974},
doi = {10.1145/3641554.3701974},
abstract = {Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {896–902},
numpages = {7},
keywords = {bugspotter, debugging, exercise generation, generative ai, llms, programming education, test cases},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3701716.3718373,
author = {Li, Zhipeng and Wu, Binglin and Zhang, Yingyi and Li, Xianneng and Li, Kai and Chen, Weizhi},
title = {CuSMer: Multimodal Intent Recognition in Customer Service via Data Augment and LLM Merge},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3718373},
doi = {10.1145/3701716.3718373},
abstract = {The increasing complexity of e-commerce customer service (CS) scenarios, driven by rapid product evolution and user base growth, presents unique challenges for intent recognition. Unlike generic user-generated content (UGC), CS-UGC exhibits multimodal complexity (e.g., product inquiries, return requests) that traditional methods struggle to address due to (1) Limited CS domain-specific knowledge, which hampers the ability of large language models (LLMs) to handle multimodal CS data, and (2) The complexity and noise in CS UGC, which undermines the robustness of traditional approaches. In this paper, we propose Customer Service Augmented LLM Merge (CuSMer), a novel framework integrating semi-supervised learning with model merging techniques through dual pipelines: (i) pseudo-labeling → fine-tuning → LLM merging and (ii) image augmentation → fine-tuning → LLM merging. These piplines enhance the robustness of LLMs against noisy, out-of-distribution data while improving their multimodal understanding of CS scenarios. Evaluated on Alibaba's real-world datasets, CuSMer demonstrates superior robustness in noisy environments and enhanced multimodal understanding compared to baseline LLMs. It achieved third place in the first round and first place in the final round in the WWW25 - Competition: Multimodal Dialogue System Intent Recognition Challenge, validating its scalability and effectiveness for industrial CS applications.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {3058–3062},
numpages = {5},
keywords = {e-commerence, model merge, vision language model},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3723010.3723021,
author = {Fischer, David Vincent and Haug, Jim and Schoppel, Paul and Abke, J\"{o}rg and Becker, Matthias and Hagel, Georg},
title = {Evaluation of a Node-based Automatic Short Answer Tool “NodeGrade”},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723021},
doi = {10.1145/3723010.3723021},
abstract = {NodeGrade tries to provide a suitable solution for the problem of time-intensive short answer grading. This research focuses simultaneously on performance, functionality and user experience, which is underlined by a triangulated approach. The evaluation results show comparable performance of NodeGrade on public datasets, even outperforming GPT-4 on the SemEval 2013 Task 7. Matching of NodeGrade’s output with multiple human expert raters reveals some weaknesses regarding cases at the lower and upper boundary. In terms of user experience, the interviewed and observed students recognized both positive facets, like better learning support and helpful feedback, and negative sides, including technical limitations and lack of transparency. Overall, NodeGrade promises high potential for further practical use and testing in the field of software engineering education and automatic short answer grading.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {20–29},
numpages = {10},
keywords = {ASAG, Automatic Short Answer Grading, Short Answer Scoring, AI in Education, Software Engineering Education, Natural Language Processing, Large Language Models},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3722237.3722245,
author = {Fan, Sun and Peng, Lu and Wu, Shaofeng and Yu, Xingmu},
title = {ChatGPT Empowers Higher Education: —Research Topics Hotspots and Quantitative Visual Analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722245},
doi = {10.1145/3722237.3722245},
abstract = {In order to deeply explore the current research hotspots and development trends of ChatGPT generative artificial intelligence in empowering higher education applications, this study conducted a detailed analysis of 178 articles related to ChatGPT+higher education in the knowledge Resource Database. By using software tools such as Power BI, SPSS, and Excel, this study conducted a visual analysis of core authors, research funding, research topics, author institutions, discipline areas, and related indicators in the literature. The aim of the study is to analyze the current status of ChatGPT research in higher education applications and to explore the hot issues surrounding ChatGPT empowerment in higher education.The study points out that current research in higher education in the era of artificial intelligence mainly focuses on introducing ChatGPT, the characteristics and connotations of large language models, and discussing the opportunities, challenges, coping strategies, and digital transformation research they bring. However, there is still a lack of in-depth exploration of the application of ChatGPT and other technologies in education, especially in areas such as personalized learning and precision teaching, the integration of virtual and actual teaching spaces, intelligent teaching facilities and resources, human-computer collaborative teaching methods, and interdisciplinary innovative research methods.We should actively respond to the opportunities and challenges brought by intelligent tools such as ChatGPT to higher education, and comprehensively and deeply explore how to integrate ChatGPT into key areas of digital education, including teaching design, teaching resource development, teaching organization and implementation, teaching evaluation and reflection, learning and personal knowledge management, innovation team building, and enhancing the digital literacy and professional capabilities of teachers and students. In addition, the impact of the application of ChatGPT and other technologies in education on educational equity, and how to ensure that all students can benefit from it through reasonable design and use, should also be of concern. The goal of this study is to further promote and drive the digital transformation of higher education by building a brand new higher education ecosystem based on ChatGPT.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {38–45},
numpages = {8},
keywords = {ChatGPT, Digital transformation, Empowers, higher education, hot topics, human-machine collaborative intelligence, trends, visualization},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3706598.3713819,
author = {J\"{o}rke, Matthew and Sapkota, Shardul and Warkenthien, Lyndsea and Vainio, Niklas and Schmiedmayer, Paul and Brunskill, Emma and Landay, James A.},
title = {GPTCoach: Towards LLM-Based Physical Activity Coaching},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713819},
doi = {10.1145/3706598.3713819},
abstract = {Mobile health applications show promise for scalable physical activity promotion but are often insufficiently personalized. In contrast, health coaching offers highly personalized support but can be prohibitively expensive and inaccessible. This study draws inspiration from health coaching to explore how large language models (LLMs) might address personalization challenges in mobile health. We conduct formative interviews with 12 health professionals and 10 potential coaching recipients to develop design principles for an LLM-based health coach. We then built GPTCoach, a chatbot that implements the onboarding conversation from an evidence-based coaching program, uses conversational strategies from motivational interviewing, and incorporates wearable data to create personalized physical activity plans. In a lab study with 16 participants using three months of historical data, we find promising evidence that GPTCoach gathers rich qualitative information to offer personalized support, with users feeling comfortable sharing concerns. We conclude with implications for future research on LLM-based physical activity support.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {993},
numpages = {46},
keywords = {Physical activity, health coaching, large language models (LLMs), personal informatics, conversational agents},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641554.3701913,
author = {Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh and Tamilselvam, Srikanth},
title = {Design and Evaluation of an AI-Assisted Grading Tool for Introductory Programming Assignments: An Experience Report},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701913},
doi = {10.1145/3641554.3701913},
abstract = {In a typical introductory programming course, grading student-submitted programs involves an autograder which compiles and runs the programs and tests their functionality with predefined test cases, with no attention to the source code. However, in an educational setting, grading based on inspection of the source code is required for two main reasons (1) awarding partial marks to 'partially correct' code that may be failing the testcase check (2) awarding marks (or penalties) based on source code quality or specific criteria that the instructor may have laid out in the problem statement (e.g. 'implement sorting using bubble-sort'). However, grading based on studying the source code can be highly time consuming when the course has a large enrollment. In this paper we present the design and evaluation of an AI Assistant for source code grading, which we have named TA Buddy. TA Buddy is powered by Code Llama, a large language model especially trained for code related tasks, which we fine-tuned using a graded programs dataset. Given a problem statement, student code submissions and a grading rubric, TA Buddy can be asked to generate suggested grades, i.e. ratings for the various rubric criteria, for each submission. The human teaching assistant (TA) can then accept or overrule these grades. We evaluated the TA Buddy-assisted manual grading against 'pure' manual grading and found that the time taken to grade reduced by 24% while maintaining grade agreement in the two cases at 90%.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {805–811},
numpages = {7},
keywords = {ai-assisted grading, cs education, grading, llms, programming assignments, rubric, source code evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3713081.3731746,
author = {Yu, Junji and Shu, Honglin and Fu, Michael and Wang, Dong and Tantithamthavorn, Chakkrit and Kamei, Yasutaka and Chen, Junjie},
title = {A Preliminary Study of Large Language Models for Multilingual Vulnerability Detection},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731746},
doi = {10.1145/3713081.3731746},
abstract = {Deep learning-based approaches, particularly those leveraging pre-trained language models (PLMs), have shown promise in automated software vulnerability detection. However, existing methods are predominantly limited to specific programming languages, restricting their applicability in multilingual settings. Recent advancements in large language models (LLMs) offer language-agnostic capabilities and enhanced semantic understanding, presenting a potential solution to this limitation. While existing studies have explored LLMs for vulnerability detection, their detection performance remains unknown for multilingual vulnerabilities. To address this gap, we conducted a preliminary study to evaluate the effectiveness of PLMs and state-of-the-art LLMs across seven popular programming languages. Our findings reveal that the PLM CodeT5P achieves the best performance in multilingual vulnerability detection, particularly in identifying the most critical vulnerabilities. Based on these results, we further discuss the potential of LLMs in advancing real-world multilingual vulnerability detection. This work represents an initial step toward exploring PLMs and LLMs for cross-language vulnerability detection, offering key insights for future research and practical deployment.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {161–168},
numpages = {8},
keywords = {multilingual vulnerability, vulnerability detection, large language model},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3641555.3705025,
author = {Diaz, Marc and Karp, Dustin and Tuli, Prayuj and Kapoor, Amanpreet},
title = {Edugator: An AI-enabled Tool for Creating and Delivering Interactive Computing Content},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705025},
doi = {10.1145/3641555.3705025},
abstract = {Edugator is a browser-based, AI-enabled tool designed to help instructors of introductory computing courses create and deliver interactive educational content. It streamlines the content authoring process by incorporating generative AI models into both the creation and delivery stages. Instructors can create bespoke interactive computing lessons and programming problems by providing a prompt and a few clicks. They can also author templates and test cases in programming languages such as C++, Java, C, and Python. Additionally, instructors can validate programming problems by running them against an auto-generated solution, allowing them to refine the problems before releasing it to students, preventing misinformation or ambiguity. Students can complete lessons and solve programming problems in a browser-based text editor receiving immediate feedback. They can also interact with a large language model-powered AI chatbot that scaffolds a student on how to approach the problem without giving out solutions. Edugator is built using modern web frameworks and the goal of the tool is to accelerate the adoption of automated assessment tools by minimizing the challenges instructors face with such tools. It also supports Learning Tools Interoperability (LTI), allowing seamless integration with learning management systems (LMS). The demo will provide an overview of Edugator's features, including authoring programming problems and lessons using AI or remixing existing problems obtained from test banks, LTI integration, and AI-chatbot. More information about the tool can be found at https://edugator.app/ and https://github.com/edugatorlabs/resources},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {ai tutor, automated assessment tool, generative ai, introductory programming, learning by doing},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3742939.3742941,
author = {Vardanega, T.},
title = {It Is Time to Care for Ada!},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3742939.3742941},
doi = {10.1145/3742939.3742941},
abstract = {1 A rather strange introductionI confess, I am a voracious book reader, and being (luckily) versed in quite a few tongues, I enjoy reading books frequently (but not always) without needing translation. In fact, I find languages fascinating, for all they say about people's culture, history, and traits.As a student in Computer Science in the late 1980s, I was imbued with Noam Chomsky's linguistic ''generative grammar'' theory. That theory sees specific languages as second-order derivatives of a single universal grammar, innate in the human mind. That theory, with its hierarchy of formal grammars, has laid the foundation for the theory and practice of language compilers. The principal tenet of Chomsky's theory is that grammar precedes language.},
journal = {Ada Lett.},
month = jun,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3669940.3707224,
author = {Tan, Yifan and Tan, Cheng and Mi, Zeyu and Chen, Haibo},
title = {PipeLLM: Fast and Confidential Large Language Model Services with Speculative Pipelined Encryption},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707224},
doi = {10.1145/3669940.3707224},
abstract = {Confidential computing on GPUs, like NVIDIA H100, mitigates the security risks of outsourced Large Language Models (LLMs) by implementing strong isolation and data encryption. Nonetheless, this encryption incurs a significant performance overhead, reaching up to 52.8% and 88.2% throughput drop when serving OPT-30B and OPT-66B, respectively. To address this challenge, we introduce PipeLLM, a user-transparent runtime system. PipeLLM removes the overhead by overlapping the encryption and GPU computation through pipelining-an idea inspired by the CPU instruction pipelining-thereby effectively concealing the latency increase caused by encryption. The primary technical challenge is that, unlike CPUs, the encryption module lacks prior knowledge of the specific data needing encryption until it is requested by the GPUs. To this end, we propose speculative pipelined encryption to predict the data requiring encryption by analyzing the serving patterns of LLMs. Further, we have developed an efficient, low-cost pipeline relinquishing approach for instances of incorrect predictions. Our experiments show that compared with vanilla systems without confidential computing (e.g., vLLM, PEFT, and FlexGen), PipeLLM incurs modest overhead ( &lt; 19.6% in throughput) across various LLM sizes, from 13B to 175B. PipeLLM's source code is available at https://github.com/SJTU-IPADS/PipeLLM.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {843–857},
numpages = {15},
keywords = {confidential virtual machine, large language model, nvidia confidential computing},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inbook{10.1145/3724504.3724622,
author = {Liang, Bohan},
title = {Artificial Intelligence in Language Education: CiteSpace-based Visualisation and Analysis},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724622},
abstract = {Over the past five years, the rapid development of generative artificial intelligence (AI) has led to a significant increase in research on AI in language education. This article uses CiteSpace software to conduct a visual analysis of research related to AI in language education from the SCI and SSCI databases over the past five years. The research results indicate that from 2020 to 2024, the number of papers related to AI in language education has been increasing steadily with the improvement of AI technologies. What's more, China, the United States, South Korea, England, and Saudi Arabia are the leading countries in terms of publication volume. Institutions such as the Chinese University of Hong Kong, Education University of Hong Kong, and Indiana University System (including Indiana University Bloomington), etc. have a significant number of publications, and collaborative publications among institutions are the mainstream. Moreover, the keyword co-occurrence graph shows that students’ English learning, large language models, natural language processing technology and deep learning are the foci of scholars' research. Keyword clustering graph and top terms in each cluster indicate that research in this field primarily focuses on English learning, particularly on speech and writing skills, and the psychological factors, learning effect, and learning strategies in the process of AI-assisted language education have also attracted the attention of scholars. Lastly, computational modeling technologies and mobile-assisted language learning are also topics that scholars have discussed extensively. The application of AI in non-English languages education, emotional factors of students and mobile-assisted language education driven by large language models may become hotspots in the future.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {721–725},
numpages = {5}
}

@inproceedings{10.1145/3708557.3716333,
author = {Mitra, Mukund and Sinha, Yashaswi and Khokhar, Arushi and Jinkala, Sairam and Biswas, Pradipta},
title = {LMD-FISH: Language Model Driven - Framework for Intelligent Scheduling of Heterogenous Systems},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716333},
doi = {10.1145/3708557.3716333},
abstract = {Efficient task scheduling and execution in heterogeneous multi-robot systems remain challenging due to the complexity of interpreting high-level task instructions, coordinating diverse robot capabilities, and validating task outcomes. Traditional logic-based and learning- based approaches often fall short in dynamic and ambiguous environments. Large Language Models (LLMs) offer a promising solution by leveraging their advanced reasoning, contextual understanding, and adaptability to handle complex task dependencies and interpret multimodal inputs. This paper introduces an LLM-driven framework for station identification, task scheduling, and object pick-up validation. The proposed method achieved task scheduling of  (80%) , while object pick-up validation using few-shot prompting demonstrated reliable performance. These findings highlight the potential of LLMs to improve coordination, adaptability, and reliability in multi-robot systems, paving the way for scalable and intelligent automation solutions.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {74–77},
numpages = {4},
keywords = {Human-Robot Interaction, LLM, Scheduling, Heterogeneous robots},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3701716.3715453,
author = {Shi, Haonan and Ouyang, Tu and Wang, An},
title = {Navigating the Designs of Privacy-Preserving Fine-tuning for Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715453},
doi = {10.1145/3701716.3715453},
abstract = {Instruction tuning has proven effective in enhancing Large Language Models' (LLMs) performance on downstream tasks. However, real-world fine-tuning faces inherent conflicts between model providers' intellectual property protection, clients' data privacy requirements, and tuning costs. While recent approaches like split learning and offsite tuning demonstrate promising architectures for privacy-preserving fine-tuning, there is a gap in systematically addressing the multidimensional trade-offs required for diverse real-world deployments. We propose several indicative evaluation metrics to guide design trade-offs for privacy-preserving fine-tuning and a series of example designs, collectively named GuardedTuning; they result from novel combinations of system architectures with adapted privacy-enhancement methods and emerging computation techniques. Each design represents distinct trade-offs across model utility, privacy guarantees, and costs. Experimental results demonstrate that these designs protect against data reconstruction attacks while maintaining competitive fine-tuning performance.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1298–1302},
numpages = {5},
keywords = {data reconstruction attack, large language models, split learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3708359.3712104,
author = {Kazemitabaar, Majeed and Huang, Oliver and Suh, Sangho and Henley, Austin Z and Grossman, Tovi},
title = {Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712104},
doi = {10.1145/3708359.3712104},
abstract = {Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners’ perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {695–714},
numpages = {20},
keywords = {AI-Assisted Programming, Generative AI, Copilot, ChatGPT, Cognitive Engagement Enhancement, AI-Assisted Learning, Cognitive Forcing Functions, Task Decomposition, Learning Outcomes},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3716640.3716656,
author = {Vadaparty, Annapurna and Geng, Francis and Smith, David H and Benario, Jamie Gorson and Zingaro, Daniel and Porter, Leo},
title = {Achievement Goals in CS1-LLM},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716656},
doi = {10.1145/3716640.3716656},
abstract = {Introduction: The emergence and widespread adoption of generative AI (GenAI) chatbots such as ChatGPT, and programming assistants such as GitHub Copilot, have radically redefined the landscape of programming education. This calls for replication of studies and reexamination of findings from pre-GenAI CS contexts to understand the impact on students. Objectives: Achievement Goals are well studied in computing education and can be predictive of student interest and exam performance. The objective in this study is to compare findings from prior achievement goal studies in CS1 courses with new CS1 courses that emphasize the use of human-GenAI collaborative coding. Methods: In a CS1 course that integrates GenAI, we use linear regression to explore the relationship between achievement goals and prior experience on student interest, exam performance, and perceptions of GenAI. Results: As with prior findings in traditional CS1 classes, Mastery goals are correlated with interest in computing. Contradicting prior CS1 findings, normative goals are correlated with exam scores. Normative and mastery goals correlate with students’ perceptions of learning with GenAI. Mastery goals weakly correlate with reading and testing code output from GenAI.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {CS1, CS1-LLM, Copilot, Achievement Goals, Large Language Models},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3702163.3702185,
author = {Arones, Maritza and Chauca, Carmen and Phun-Pat, Yn\'{e}s and Curro-Urbano, Olga and De La Cruz-Arones, Maritza},
title = {Heutagogical Learning and the Use of ChatGPT in the pre-professional practice of university students},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702185},
doi = {10.1145/3702163.3702185},
abstract = {The objective of the study was to establish the relationship between heutagogical learning and the use of chatGPT in the pre-professional practice of university students of the professional career of Educational Sciences in Mathematics and Computer Science at the National University “San Luis Gonzaga”. The Self-Learning Strategies Questionnaire (CETA) was used for university students, which considers six dimensions: Extension Strategies, Collaboration Strategies, Conceptualization Strategies, Planning Strategies, Exam Preparation Strategies and Participation Strategies. The sample was made up of students enrolled in the IX and X semester of the aforementioned professional career. Through univariate correlation analysis and applying Spearman's Rho test (0.587&gt;0.344, p&lt;0.05), a significant correlation between the variables is confirmed, highlighting the importance of the self-directed approach in the training of educators supported in the use from chatGPT. Additionally, specific strategies, such as outreach, collaboration, conceptualization, planning, test preparation, and participation, were found to be related to preprofessional practice success. Consequently, it is recommended to actively promote heutagogical learning and the application of these strategies in the training of educators.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {155–160},
numpages = {6},
keywords = {chatGPT, heutagogical learning, learning strategy and pre-professional practice},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3676536.3697132,
author = {Dang, Dharanidhar and Dash, Priyabrata and Zheng, Luqi and Li, Haitong},
title = {Co-designing 2.5D Silicon Photonic Accelerators for Distributed Transformer at the Edge},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3697132},
doi = {10.1145/3676536.3697132},
abstract = {The efficient execution of attention-based transformers and large language models on traditional CPUs and GPUs presents significant challenges related to performance and energy efficiency. While innovative solutions like ASICs, FPGAs, and ReRAMs have been explored, the field of silicon photonics has emerged as a promising avenue for developing energy-efficient accelerators for deep AI models. Notably, existing endeavors in silicon photonics have predominantly concentrated on inference for deep AI algorithms, leaving a limited number of initiatives focused on creating comprehensive deep learning accelerators capable of real-time training for transformer-like algorithms. This paper utilizes the superior merits of silicon photonics to realize a full-fledged transformer accelerator equipped for both inference and training. Introducing PHOTRAN, an AI analog photonics accelerator, we harness silicon microdisk-based convolution, photonic phase-change memory-based cache, and dense-wavelength-division-multiplexing to achieve energy-efficient and ultrafast transformer acceleration. Through evaluations using a commercial CAD framework on benchmark models, including Vision Transformers and Large Language models, our results showcase the superior performance of PHOTRAN. This work underscores the significant potential of photonic computing for on-chip training of large deep AI models.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {129},
numpages = {9},
keywords = {silicon photonics, transoformer, edge intelligence, energy efficiency},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3696410.3714658,
author = {Ren, Ruiyang and Wang, Yuhao and Zhou, Kun and Zhao, Wayne Xin and Wang, Wenjie and Liu, Jing and Wen, Ji-Rong and Chua, Tat-Seng},
title = {Self-Calibrated Listwise Reranking with Large Language Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714658},
doi = {10.1145/3696410.3714658},
abstract = {Large language models (LLMs), with advanced linguistic capabilities, have been employed in reranking tasks through a sequence-to-sequence approach. In this paradigm, multiple passages are reranked in a listwise manner and a textual reranked permutation is generated. However, due to the limited context window of LLMs, this reranking paradigm requires a sliding window strategy to iteratively handle larger candidate sets. This not only increases computational costs but also restricts the LLM from fully capturing all the comparison information for all candidates. To address these challenges, we propose a novel self-calibrated listwise reranking method, which aims to leverage LLMs to produce global relevance scores for ranking. To achieve it, we first propose the relevance-aware listwise reranking framework, which incorporates explicit list-view relevance scores to improve reranking efficiency and enable global comparison across the entire candidate set. Second, to ensure the comparability of the computed scores, we propose self-calibrated training that uses point-view relevance assessments generated internally by the LLM itself to calibrate the list-view relevance assessments. Extensive experiments and comprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks demonstrate the effectiveness and efficiency of our proposed method.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3692–3701},
numpages = {10},
keywords = {large language models, self-calibration, text reranking},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3735645,
author = {Zhou, Yinghai and Wang, Ziyu and Jiang, Yunxin and Ma, Bingqi and Wang, Rui and Liu, Yuan and Zhao, Yue and Tian, Zhihong},
title = {AEKG4APT: An AI-Enhanced Knowledge Graph for Advanced Persistent Threats with Large Language Model Analysis},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3735645},
doi = {10.1145/3735645},
abstract = {This paper introduces AEKG4APT, an APT Knowledge Graph (KG) enhanced by Large Language Models (LLMs), as a way to deal with the cybersecurity problems caused by Advanced Persistent Threats (APTs). The core of AEKG4APT lies in the combined application of LLMs, Cyber Threat Intelligence (CTI), and KG. The first part of the paper goes into great detail about how the AEKG4APT was constructed, including its ontology schema, data sources, and dataset features. There are also statistics on the AEKG4APT’s nodes, relationships, and key attributes. Secondly, it was shown how to utilize LLMs and public sandboxes for the collection and analysis of CTI Additionally, tests that compare traditional deep learning models to LLM methods show that LLM is both more efficient and more accurate at extracting information. Subsequently, the Decision Making Trial and Evaluation Laboratory - Interpretive Structural Modeling (DEMATEL-ISM) analytical method was introduced to identify and analyse the factors and their interrelationships within the AEKG4APT data, thereby revealing the key dependencies and influence paths within the data structure. Experiments were designed to demonstrate its applications in modeling, computing, and obtaining interpretable computational results on AEKG4APT. In addition, this paper also explores the dynamic expansion capabilities of AEKG4APT, including data expansion, schema expansion, and permanent maintenance strategies, to address the evolving APT threats. Finally, this paper summarizes the competitiveness and application value of AEKG4APT by comparing it with other CTI KGs and platforms in academia and industry, demonstrating its extensive application potential in the field of cybersecurity.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {Advanced Persistent Threat, Large Language Models, Knowledge Graph, Cyber Threat Intelligence, Sandboxes, DEMATEL-ISM}
}

@inproceedings{10.1145/3701716.3717808,
author = {Mondal, Chayan and Pham, Duc-Son and Gupta, Ashu and Tan, Tele and Gedeon, Tom},
title = {Leveraging Prompt Engineering with Lightweight Large Language Models to Label and Extract Clinical Information from Radiology Reports},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717808},
doi = {10.1145/3701716.3717808},
abstract = {Chest X-ray imaging plays a critical role in diagnosing chest diseases, making it a cornerstone in clinical and research domains. Automating disease diagnosis and extracting relevant clinical information from chest X-ray reports have become essential for developing AI-driven healthcare systems. While effective, deep learning models require extensive labelled datasets, making the labelling of diseases from radiology reports crucial. Traditionally, rule-based labelling approaches have been employed, but the emergence of large language models (LLMs) has introduced new possibilities through instruction-based prompt engineering. In this study, we explore various prompt engineering techniques, including in-context learning and prompt chaining, to label multilabel disease reports and extract key clinical findings from radiology reports. We conducted ablation studies on both proprietary LLMs (e.g., GPT-4 Turbo, GPT-3.5 Turbo) and publicly available LLMs (e.g., Llama2-7B, Llama2-13B, Llama3-8B, Llama2-70B), comparing their performance in terms of clinical accuracy, privacy, and computational cost. Our findings demonstrate that well-crafted prompts on publicly available and lightweight LLMs can achieve competitive results compared to larger and/or proprietary models, offering a cost-effective and privacy-preserving solution for clinical applications. These results highlight the potential of leveraging advanced prompt engineering to streamline disease labelling and enhance the quality of automated report generation in radiology.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1616–1625},
numpages = {10},
keywords = {chest x-ray report., generative ai, in-context learning, llm, prompt engineering},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3717835,
author = {Yang, Haomiao and Xue, Dongyun and Wang, Tianyi and Kwak, Jin and Kim, Hyunsung},
title = {FedGPL: Gradient Priority-based Federated Learning Enhancement for In-Vehicle Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3717835},
doi = {10.1145/3717835},
abstract = {The training of Large Language Models (LLMs) for specialized applications like autonomous driving faces significant data privacy challenges. Federated Learning (FL) offers a solution by enabling local data usage while preserving privacy. In this paper, we introduce Gradient Priority-based Federated Learning (FedGPL), a novel strategy to enhance the efficiency of LLM training in autonomous vehicles. FedGPL precomputes gradients on the server to identify critical model layers, allowing vehicles to selectively update these layers with local data. This selective updating reduces computational burden and minimizes the gradient data transmission. Experimental results show that FedGPL achieves comparable accuracy to existing methods while significantly reducing computational and communication costs, making it a promising approach for training advanced language models in autonomous driving.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = feb,
keywords = {Federated Learning, Large Language Models, Data Privacy, Efficient Fine-tuning}
}

@inproceedings{10.1145/3696410.3714744,
author = {Wei, Yongfu and Lin, Yan and Gao, Hongfan and Xu, Ronghui and Yang, Sean Bin and Hu, Jilin},
title = {Path-LLM: A Multi-Modal Path Representation Learning by Aligning and Fusing with Large Language Models},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714744},
doi = {10.1145/3696410.3714744},
abstract = {The advancement of intelligent transportation systems has led to a growing demand for accurate path representations, which are essential for tasks such as travel time estimation, path ranking, and trajectory analysis. However, traditional path representation learning (PRL) methods often focus solely on single-modal road network data, overlooking important physical and regional factors that influence real-world traffic dynamics. To overcome this limitation, we introduce Path-LLM, a multi-modal path representation learning model that integrates large language models (LLMs) into PRL. Our approach leverages LLMs to interpret both topological and textual data, enabling robust multi-modal path representations. To effectively align and merge these modalities, we propose TPalign, a contrastive learning-based pretraining strategy that ensures alignment within the embedding space. We then present TPfusion, a multimodal fusion module that dynamically adjusts the weight of each modality before integration. To further optimize LLM training, we introduce a Two-stage Overlapping Curriculum Learning (TOCL) approach, which progressively increases the complexity of the training data. Finally, we evaluate Path-LLM on three real-world datasets across traditional PRL downstream tasks, achieving up to a 61.84% improvement in path ranking performance on the Xi'an dataset. Additionally, Path-LLM demonstrates superior performance in both few-shot and zero-shot learning scenarios. Our code is available at: https://github.com/decisionintelligence/Path-LLM.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2289–2298},
numpages = {10},
keywords = {contrastive learning, curriculum learning, large language models, path representation learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3712678.3721880,
author = {Wang, Zhijian and Lu, Rongwei and Zhang, Zhiyang and Westphal, Cedric and He, Dongbiao and Jiang, Jingyan},
title = {LLM4Band: Enhancing Reinforcement Learning with Large Language Models for Accurate Bandwidth Estimation},
year = {2025},
isbn = {9798400714696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712678.3721880},
doi = {10.1145/3712678.3721880},
abstract = {Real-time communication (RTC) applications rely on accurate bandwidth estimation to ensure high-quality communication and user experience. Traditional heuristic and reinforcement learning (RL)-based methods often face challenges with the dynamic nature of real-time networks, leading to issues with generalization. Inspired by the success of Large Language Models (LLMs)---which, with billions of parameters pre-trained on massive datasets, have demonstrated exceptional capabilities in semantic representation, adaptability, and transfer learning---we propose LLM4Band, a novel framework that integrates LLMs with offline reinforcement learning to tackle bandwidth estimation in RTC scenarios. By leveraging the powerful feature extraction capabilities of LLMs and combining them with an offline RL algorithm, LLM4Band incorporates a Balanced Replay Buffer and an LLM-based policy network to significantly enhance robustness and adaptability. Extensive experiments demonstrate that LLM4Band surpasses state-of-the-art methods, achieving a 12.35% improvement in estimation accuracy and a 21% enhancement in communication quality.},
booktitle = {Proceedings of the 35th Workshop on Network and Operating System Support for Digital Audio and Video},
pages = {43–49},
numpages = {7},
keywords = {Bandwidth Estimation, Large Language Model, Reinforcement Learning},
location = {Stellenbosch, South Africa},
series = {NOSSDAV '25}
}

@inproceedings{10.1145/3701716.3718377,
author = {Li, Cheng-Te and Ku, Lun-Wei},
title = {The First International Workshop on Large Language Models for Social Media (SocialLLM 2025)},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3718377},
doi = {10.1145/3701716.3718377},
abstract = {The rapid evolution of Large Language Models (LLMs) has profoundly impacted social media, transforming how information is generated, disseminated, and analyzed. With their ability to process vast amounts of data, grasp contextual nuances, and engage in human-like dialogue, LLMs present new opportunities and challenges for understanding online interactions. The SocialLLM 2025 workshop builds on the foundation laid by SocialNLP, expanding the scope to explore the capabilities and implications of LLMs in social media research. This year's workshop at TheWebConf 2025 focuses on three pivotal themes: leveraging LLMs for mental health support, enhancing emotion detection in textual interactions, and improving misinformation detection through active learning. The selected papers illustrate cutting-edge advancements in these areas, demonstrating how LLMs can be fine-tuned for therapeutic dialogue generation, assessed for their emotional intelligence, and optimized for misinformation detection with minimal labeled data. These contributions highlight the growing interdisciplinary nature of LLM research, merging insights from natural language processing, social computing, and artificial intelligence ethics. By bringing together researchers and practitioners from diverse backgrounds, SocialLLM 2025 aims to foster meaningful discussions on the opportunities and risks associated with LLM-driven social media applications. The workshop serves as a platform for exploring novel methodologies, addressing ethical concerns, and shaping future directions for responsible AI deployment in social media environments. Through collaborative efforts, we seek to advance the field and ensure that LLMs contribute positively to the digital ecosystem.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2589–2591},
numpages = {3},
keywords = {chatgpt, deep learning, generative ai, large language models, natural language processing, social media, social networks, text mining},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1613/jair.1.16665,
author = {Fraser, Kathleen C. and Dawkins, Hillary and Kiritchenko, Svetlana},
title = {Detecting AI-Generated Text: Factors Influencing Detectability with Current Methods},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.16665},
doi = {10.1613/jair.1.16665},
abstract = {Large language models (LLMs) have advanced to a point that even humans have difficulty discerning whether a text was generated by another human, or by a computer. However, knowing whether a text was produced by human or artificial intelligence (AI) is important to determining its trustworthiness, and has applications in many domains including detecting fraud and academic dishonesty, as well as combating the spread of misinformation and political propaganda. The task of AI-generated text (AIGT) detection is therefore both very challenging, and highly critical. In this survey, we summarize stateof-the art approaches to AIGT detection, including watermarking, statistical and stylistic analysis, and machine learning classification. We also provide information about existing datasets for this task. Synthesizing the research findings, we aim to provide insight into the salient factors that combine to determine how “detectable” AIGT text is under different scenarios, and to make practical recommendations for future work towards this significant technical and societal challenge.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {46},
keywords = {machine learning, data mining, information extraction, information retrieval, knowledge discovery, programming}
}

@inproceedings{10.1145/3708557.3716361,
author = {Lataifeh, Mohammed and Afyouni, Imad and Shaduly, Zulaiha Afrah Sadakathullah and Abdulkarim, Abulrahman and Ahmed, Naveed},
title = {An Adaptive Multimodal Framework for Designing Intelligent Virtual Agents in Mixed Reality},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716361},
doi = {10.1145/3708557.3716361},
abstract = {Intelligent Virtual Agents (IVA) that exhibit some aspects of human intelligence, including autonomous behavior, communication with humans, and learning capabilities, can benefit several areas of application. This research proposes a novel multimodal framework for the design and development of an IVA in mixed reality (MR) that has advanced speech capabilities from large language models (LLMs) and integrates computer vision to perceive the user’s environment and actions in the real-world context. The scene understanding allows the IVA to navigate in the user’s physical space, demonstrate an understanding of user’s actions and dynamically interact with physical objects. The proposed multimodal approach enables our agent to tailor its assistance and provide adaptive guidance to the users based on the actions they take in a real-world setting. To demonstrate and evaluate the proposed framework, we developed a salad preparation scenario that involves slicing and mixing multiple vegetables to evaluate our agent’s capabilities in assisting the users and utilized the Magic Leap 2 headset for the MR experience.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {133–136},
numpages = {4},
keywords = {Embodied agents, mixed reality, adaptive},
location = {
},
series = {IUI '25 Companion}
}

@article{10.1145/3709154,
author = {Tariq, Amara and Trivedi, Shubham and Urooj, Aisha and Ramasamy, Gokul and Fathizadeh, Sam and Stib, Matthew and Tan, Nelly and Patel, Bhavik and Banerjee, Imon},
title = {Patient-centric Summarization of Radiology Findings Using Two-step Training of Large Language Models},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3709154},
doi = {10.1145/3709154},
abstract = {Education-level or socioeconomic background of patients may dictate their ability to understand medical jargon. Inability to understand primary findings from a radiology report may lead to unnecessary anxiety among patients or missed follow up. We aim to meet this challenge by developing a patient-sensitive summarization model for radiology reports. We selected computed tomography (CT) exams of chest as a use-case and collected 7,000 studies from Mayo Clinic. Summarization model was built on top of the T5 large language model (LLM) as our experiments indicated that its text-to-text transfer architecture was suited for abstractive text summarization, resulting in a model with 0.77B trainable parameters. Noisy ground truth for model training was collected by prompting LLaMA-13B model. We recruited experts (board-certified radiologists) and laymen to manually evaluate model-generated summaries generated by model. Our model rarely missed information as marked by majority opinion of radiologists. Laymen indicated 63% improvement in their understanding by reading model-generated layman summaries. Comparison with zero-shot performance of ChatGPT indicated that the proposed model reduced the rate of hallucination by half and rate of missing important information by fivefold. The proposed model can generate reliable summaries for radiology reports understandable by patients with vastly different levels of medical knowledge.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {21},
numpages = {15},
keywords = {large language models, domain-specific training, chest computed tomography}
}

@article{10.1145/3718096,
author = {Jo, Ashly Ann and Raj, Ebin Deni and Sahoo, Jayakrushna},
title = {Efficiency and Performance Optimization in Large Language Models through IB Fine-Tuning},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3718096},
doi = {10.1145/3718096},
abstract = {In the rapidly evolving field of Natural Language Processing (NLP), optimizing methods for fine-tuning Large Language Models (LLMs) is increasingly critical for improving generalization and performance. Fine-tuning LLMs is challenging due to high costs, overfitting, and difficulty adapting to diverse tasks. These challenges grow as LLMs scale, making traditional fine-tuning methods inefficient and expensive. To address these issues, a novel Information Bottleneck (IB) method for fine-tuning LLMs is proposed, focusing on retaining only the most critical and relevant information in the model’s internal representations. By striking a balance between information compression and predictive relevance, the IB method aims to reduce overfitting and enhance generalization. This approach also integrates reinforcement learning and continual learning to enhance LLM performance further. The proposed framework considers two key metrics: (1) compression effectiveness, which reduces redundancy and improves generalization, and (2) predictive relevance, which ensures high task-specific performance. The proposed scheme achieves scalable fine-tuning across diverse NLP tasks using a lightweight proxy model to enhance computational efficiency. The proposed framework empirical evaluations and ablation studies show that the IB method improves accuracy while significantly reducing computational costs, enabling efficient, interpretable, and adaptable LLM optimization and increasing convergence.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {56},
numpages = {23},
keywords = {Transformer models, BERT, Attention}
}

@inproceedings{10.1145/3696410.3714825,
author = {Shi, Zhengliang and Gao, Shen and Yan, Lingyong and Feng, Yue and Chen, Xiuyi and Chen, Zhumin and Yin, Dawei and Verberne, Suzan and Ren, Zhaochun},
title = {Tool Learning in the Wild: Empowering Language Models as Automatic Tool Agents},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714825},
doi = {10.1145/3696410.3714825},
abstract = {Augmenting large language models (LLMs) with external tools has emerged as a promising approach to extend their utility, enabling them to solve practical tasks. Previous methods manually parse tool documentation and create in-context demonstrations, transforming tools into structured formats for LLMs to use in their step-by-step reasoning. However, this manual process requires domain expertise and struggles to scale to large toolsets. Additionally, these methods rely heavily on ad-hoc inference techniques or special tokens to integrate free-form LLM generation with tool-calling actions, limiting the LLM's flexibility in handling diverse tool specifications and integrating multiple tools.In this work, we propose AutoTools, a framework that enables LLMs to automate the tool-use workflow. Specifically, the LLM automatically transforms tool documentation into callable functions, verifying syntax and runtime correctness. Then, the LLM integrates these functions into executable programs to solve practical tasks, flexibly grounding tool-use actions into its reasoning processes. Extensive experiments on existing and newly collected, more challenging benchmarks illustrate the superiority of our framework. Inspired by these promising results, we further investigate how to improve the expertise of LLMs, especially open-source LLMs with fewer parameters, within AutoTools. Thus, we propose the AutoTools-Learning approach, training the LLMs with three learning tasks on 34k instances of high-quality synthetic data, including documentation understanding, relevance learning, and function programming. Fine-grained results validate the effectiveness of our overall training approach and each individual task. Our methods are an important step towards the use of LLMs for solving real-world tasks with external tools.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {2222–2237},
numpages = {16},
keywords = {instruction tuning, large language models, tool learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3724504.3724605,
author = {Qi, Shanshan and Qiu, Hongye},
title = {Developing and Implementing Teacher-Created AI Tools for Cultural Expression: A Mixed-Methods Study of EFL Students' Learning of Traditional Chinese Culture},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724605},
doi = {10.1145/3724504.3724605},
abstract = {This study focused on the design and application of AI tools developed by teachers to enable EFL students to express themselves in English within the context of traditional Chinese culture. This study uses a sequential explanatory mixed-methods design to illustrate how educators with little programming knowledge can develop customized learning tools through low-code platforms with large language model integration. The study consists of three phases: developing IA Improved Learning tools, implementing AI Improved tools in EFL classrooms, and evaluating their efficiency. Rich quantitative data collected from 33 undergraduate students, as well as qualitative data from semi-structured interviews, also demonstrate a profound improvement in both the ability of students to express cultural understanding as well as critical engagement in a post-course environment. These findings show how AI tools developed by teachers can fill the gap between technical possibility and pedagogical necessity and how these efforts can support culturally sustaining language learning. This study advances scholarship concerning integrating AIs into language education while offering practice and practical insights for educators interested in creating bespoke domain-specific AI learners.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {608–616},
numpages = {9},
keywords = {English as Foreign Language (EFL), Low-code development, Mixed-methods research, Teacher-created AI tools, Technology-enhanced language learning},
location = {
},
series = {ICIEAI '24}
}

@inproceedings{10.1145/3676641.3716249,
author = {Lai, Ruihang and Shao, Junru and Feng, Siyuan and Lyubomirsky, Steven and Hou, Bohan and Lin, Wuwei and Ye, Zihao and Jin, Hongyi and Jin, Yuchen and Liu, Jiawei and Jin, Lesheng and Cai, Yaxing and Jiang, Ziheng and Wu, Yong and Park, Sunghyun and Srivastava, Prakalp and Roesch, Jared and Mowry, Todd C. and Chen, Tianqi},
title = {Relax: Composable Abstractions for End-to-End Dynamic Machine Learning},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716249},
doi = {10.1145/3676641.3716249},
abstract = {Dynamic shape computations have become critical in modern machine learning workloads, especially in emerging large language models. The success of these models has driven the demand for their universal deployment across a diverse set of backend environments. In this paper, we present Relax, a compiler abstraction for optimizing end-to-end dynamic machine learning workloads. Relax introduces a cross-level abstraction that encapsulates computational graphs, loop-level tensor programs, and external library calls in a single representation. Relax also introduces first-class symbolic shape annotations to track dynamic shape computations globally across the program, enabling dynamic shape-aware cross-level optimizations. We build an end-to-end compilation framework using the proposed approach to optimize dynamic shape models. Experimental results on LLMs show that Relax delivers performance competitive with state-of-the-art systems across various GPUs and enables deployment of emerging models to a broader set of emerging environments, including mobile phones, embedded devices, and web browsers.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {998–1013},
numpages = {16},
keywords = {dynamic-shape machine learning, machine learning compiler},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3711403.3711428,
author = {Guo, Peirong and Zhang, Qi and Tian, Chunwei and Xue, Wanli and Feng, Xiaocheng},
title = {Digital Human Techniques for Education Reform},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711428},
doi = {10.1145/3711403.3711428},
abstract = {The rapid evolution of artificial intelligence, big data, and generative AI models has ushered in significant transformations across various sectors, including education. Digital Human Technique, an innovative technology grounded in advanced computer science and artificial intelligence, is reshaping educational paradigms by enabling virtual humans to simulate human behavior, express emotions, and interact with users. This paper explores the application of Digital Human Technique in education reform, focusing on creating immersive, intelligent classroom experiences that foster meaningful interactions between teachers and students. We define Digital Human Technique and delve into its key technical components such as character modeling and rendering, natural language processing, computer vision, and augmented reality technologies. Our methodology involves analyzing the role of educational digital humans created through these technologies, assessing their impact on educational processes, and examining various application scenarios in educational reform. Results indicate that Digital Human Technique significantly enhances the learning experience by enabling personalized teaching, increasing engagement, and fostering emotional connections. Educational digital humans serve as virtual teachers, interactive learning aids, and facilitators of emotional interaction, effectively addressing the challenges of traditional educational methods. They also promote a deeper understanding of complex concepts through simulated environments and interactive digital content.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {173–178},
numpages = {6},
keywords = {Digital Human Techniques, Education Reform},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3722570.3726898,
author = {Srewa, Mahmoud and Zhao, Tianyu and Elmalaki, Salma},
title = {PluralLLM: Pluralistic Alignment in LLMs via Federated Learning},
year = {2025},
isbn = {9798400716096},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722570.3726898},
doi = {10.1145/3722570.3726898},
abstract = {Ensuring Large Language Models (LLMs) align with diverse human preferences while preserving privacy and fairness remains a challenge. Existing methods, such as Reinforcement Learning from Human Feedback (RLHF), rely on centralized data collection, making them computationally expensive and privacy-invasive. We introduce PluralLLM1 a federated learning-based approach that enables multiple user groups to collaboratively train a transformer-based preference predictor without sharing sensitive data, which can also serve as a reward model for aligning LLMs. Our method leverages Federated Averaging (FedAvg) to aggregate preference updates efficiently, achieving 46% faster convergence, a 4% improvement in alignment scores, and nearly the same group fairness measure as in centralized training. Evaluated on a Q/A preference alignment task, PluralLLM demonstrates that federated preference learning offers a scalable and privacy-preserving alternative for aligning LLMs with diverse human values.},
booktitle = {Proceedings of the 3rd International Workshop on Human-Centered Sensing, Modeling, and Intelligent Systems},
pages = {64–69},
numpages = {6},
keywords = {Fairness, Federated Learning, Group Preference Alignment, Large Language Model, Pluralistic Alignment},
location = {Irvine, CA, USA},
series = {HumanSys '25}
}

@inproceedings{10.1145/3672608.3707900,
author = {Zhang, Zhiyong and Liu, Ruyu and Liu, Xiufeng and Zhu, Yunrui and Yang, Yanyan and Wang, Chaochao and Zhang, Jianhua},
title = {PULLM: A Multimodal Framework for Enhanced 3D Point Cloud Upsampling Using Large Language Models},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707900},
doi = {10.1145/3672608.3707900},
abstract = {Point cloud upsampling is a critical task in 3D computer vision, aiming to generate dense and uniformly distributed point sets from sparse inputs. While current self-supervised methods show promise, they often struggle with preserving fine-grained geometric details, especially for highly sparse point clouds. To address these limitations, we propose PointUpsampleLLM (PULLM), a novel multimodal framework that leverages the power of large language models (LLMs) to enhance 3D point cloud upsampling. PULLM integrates a pretrained Point Cloud LLM (PointLLM) with visual features extracted from point clouds, learning a unified representation that captures both geometric and semantic information. At the core of our approach is the Feature Aware Translator (FAT) module, which effectively bridges the modality gap between visual and textual features, enhancing the spatial understanding of the LLM. PULLM generates textual descriptions of point clouds on-the-fly, eliminating the need for large paired datasets. Extensive experiments on the PU1K and PUGAN benchmarks demonstrate that PULLM consistently outperforms state-of-the-art methods, achieving significant improvements in Chamfer Distance, Hausdorff Distance, and Point-to-Plane distance metrics. For instance, on the PUGAN dataset with sparse inputs, PULLM achieves a 56.15% improvement in Chamfer Distance over the best baseline. Our qualitative results further illustrate PULLM's superior ability to preserve fine details and generate high-quality upsampled point clouds across various object types and geometries.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1223–1230},
numpages = {8},
keywords = {point cloud upsampling, large language models (LLMs), multimodal learning, feature aware translator (FAT), 3D computer vision},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706598.3713905,
author = {Zhou, Zhongyi and Jin, Jing and Phadnis, Vrushank and Yuan, Xiuxiu and Jiang, Jun and Qian, Xun and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Zhou, Jingtao and Huang, Yiyi and Xu, Zheng and Zhang, Yinda and Lee, Johnny and Olwal, Alex and Kim, David and Iyengar, Ram and Li, Na and Du, Ruofei},
title = {InstructPipe: Generating Visual Blocks Pipelines with Human Instructions and LLMs},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713905},
doi = {10.1145/3706598.3713905},
abstract = {Visual programming has the potential of providing novice programmers with a low-code experience to build customized processing pipelines. Existing systems typically require users to build pipelines from scratch, implying that novice users are expected to set up and link appropriate nodes from a blank workspace. In this paper, we introduce InstructPipe, an AI assistant for prototyping machine learning (ML) pipelines with text instructions. We contribute two large language model (LLM) modules and a code interpreter as part of our framework. The LLM modules generate pseudocode for a target pipeline, and the interpreter renders the pipeline in the node-graph editor for further human-AI collaboration. Both technical and user evaluation (N=16) shows that InstructPipe empowers users to streamline their ML pipeline workflow, reduce their learning curve, and leverage open-ended commands to spark innovative ideas.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {877},
numpages = {22},
keywords = {Visual Programming; Large Language Models; Visual Prototyping; Node-graph Editor; Graph Compiler; Low-code Development; Deep Neural Networks; Deep Learning; Visual Analytics},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1109/SCW63240.2024.00158,
author = {John, Chelsea Maria and Nassyr, Stepan and Penke, Carolin and Herten, Andreas},
title = {Performance and Power: Systematic Evaluation of AI Workloads on Accelerators with CARAML},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00158},
doi = {10.1109/SCW63240.2024.00158},
abstract = {The rapid advancement of machine learning (ML) technologies has driven the development of specialized hardware accelerators designed to facilitate more efficient model training. This paper introduces the CARAML benchmark suite, which is employed to assess performance and energy consumption during the training of transformer-based large language models and computer vision models on a range of hardware accelerators, including systems from NVIDIA, AMD, and Graphcore. CARAML provides a compact, automated, extensible, and reproducible framework for assessing the performance and energy of ML workloads across various novel hardware architectures. The design and implementation of CARAML, along with a custom power measurement tool called jpwr, are discussed in detail.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {1164–1176},
numpages = {13},
keywords = {AI, Accelerators, Benchmark, Computer Vision, Energy, GPU, IPU, Machine Learning, NLP, Performance Measurement},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.5555/3712729.3712752,
author = {Wu, Yuhang and Wang, Yingfei and Wang, Chu and Zheng, Zeyu},
title = {LLM Enhanced Machine Learning Estimators for Classification},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {Pre-trained large language models (LLM) have emerged as a powerful tool for simulating various scenarios and generating informative output given specific instructions and multimodal input. In this work, we analyze the specific use of LLM to enhance a classical supervised machine learning method for classification problems. We propose a few approaches to integrate LLM into a classical machine learning estimator to further enhance the prediction performance. We examine the performance of the proposed approaches through both standard supervised learning binary classification tasks, and a transfer learning task where the test data observe distribution changes compared to the training data. Numerical experiments using four publicly available datasets are conducted and suggest that using LLM to enhance classical machine learning estimators can provide significant improvement on prediction performance.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {288–298},
numpages = {11},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3676536.3697135,
author = {Firouzi, Farshad and Nakkilla, Sri Sai Rakesh and Fu, Chenghao and Banerjee, Sanmitra and Talukdar, Jonti and Chakrabarty, Krishnendu},
title = {LLM-AID: Leveraging Large Language Models for Rapid Domain-Specific Accelerator Development},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3697135},
doi = {10.1145/3676536.3697135},
abstract = {The challenges posed by the Dark Silicon era, combined with the escalating computational demands of emerging applications, such as Deep Learning (DL), have strained the capabilities of traditional CPUs and GPUs, necessitating the development of Domain-Specific Accelerators (DSAs). Despite offering substantial enhancements in Power, Performance, and Area (PPA), DSAs encounter significant challenges, including the rapid evolution of applications that necessitate the frequent development of new architectures. This, coupled with the expertise-intensive nature of the design process, often leads to reduced flexibility and extended development cycles, ultimately hindering the broader adoption and efficient deployment of DSAs. To address these challenges, this paper introduces LLM-AID, an agile framework that streamlines the DSA design flow by transforming high-level abstract specifications into Hardware Description Language (HDL) code and facilitating backend Computer-Aided Design (CAD) tool operations. By synergistically combining Large Language Models (LLMs), High-Level Synthesis (HLS) tools, design exploration techniques, and symbolic AI, LLM-AID dramatically accelerates design iterations, optimizes hardware performance, and significantly reduces time-to-market. This innovative approach democratizes DSA development, empowering designers to achieve unprecedented productivity while delivering high-quality DSA solutions.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {25},
numpages = {9},
keywords = {domain-specific accelerators (DSAs), high-level synthesis (HLS), computer-aided design (CAD), large language models (LLMs), design exploration},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3701551.3703562,
author = {Wu, Qinyuan and Khan, Mohammad Aflah and Das, Soumi and Nanda, Vedant and Ghosh, Bishwamittra and Kolling, Camila and Speicher, Till and Bindschaedler, Laurent and Gummadi, Krishna and Terzi, Evimaria},
title = {Towards Reliable Latent Knowledge Estimation in LLMs: Zero-Prompt Many-Shot Based Factual Knowledge Extraction},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703562},
doi = {10.1145/3701551.3703562},
abstract = {In this paper, we focus on the challenging task of reliably estimating factual knowledge that is embedded inside large language models (LLMs). To avoid reliability concerns with prior approaches, we propose to eliminate prompt engineering when probing LLMs for factual knowledge. Our approach, called Zero-Prompt Latent Knowledge Estimator (ZP-LKE), leverages the in-context learning ability of LLMs to communicate both the factual knowledge question as well as the expected answer format. Our knowledge estimator is both conceptually simpler (i.e., doesn't depend on meta-linguistic judgments of LLMs) and easier to apply (i.e., is not LLM-specific), and we demonstrate that it can surface more of the latent knowledge embedded in LLMs. We also investigate how different design choices affect the performance of ZP-LKE. Using the proposed estimator, we perform a large-scale evaluation of the factual knowledge of a variety of open-source LLMs, like OPT, Pythia, Llama(2), Mistral, Gemma, etc. over a large set of relations and facts from the Wikidata knowledge base. We observe differences in the factual knowledge between different model families and models of different sizes, that some relations are consistently better known than others but that models differ in the precise facts they know, and differences in the knowledge of base models and their finetuned counterparts. Code available at: https://github.com/QinyuanWu0710/ZeroPrompt_LKE},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {754–763},
numpages = {10},
keywords = {in-context learning, knowledge extraction, large language models},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3641554.3701934,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Becker, Brett A.},
title = {Exploring Student Reactions to LLM-Generated Feedback on Explain in Plain English Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701934},
doi = {10.1145/3641554.3701934},
abstract = {Code reading and comprehension skills are essential for novices learning programming, and explain-in-plain-English tasks (EiPE) are a well-established approach for assessing these skills. However, manual grading of EiPE tasks is time-consuming and this has limited their use in practice. To address this, we explore an approach where students explain code samples to a large language model (LLM) which generates code based on their explanations. This generated code is then evaluated using test suites, and shown to students along with the test results. We are interested in understanding how automated formative feedback from an LLM guides students' subsequent prompts towards solving EiPE tasks. We analyzed 177 unique attempts on four EiPE exercises from 21 students, looking at what kinds of mistakes they made and how they fixed them. We found that when students made mistakes, they identified and corrected them using either a combination of the LLM-generated code and test case results, or they switched from describing the purpose of the code to describing the sample code line-by-line until the LLM-generated code exactly matched the obfuscated sample code. Our findings suggest both optimism and caution with the use of LLMs for unmonitored formative feedback. We identified false positive and negative cases, helpful variable naming, and clues of direct code recitation by students. For most students, this approach represents an efficient way to demonstrate and assess their code comprehension skills. However, we also found evidence of misconceptions being reinforced, suggesting the need for further work to identify and guide students more effectively.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {575–581},
numpages = {7},
keywords = {eipe, explain in plain english, formative feedback, large language models, llm, misconceptions, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3690624.3709277,
author = {He, Yufei and Sui, Yuan and He, Xiaoxin and Hooi, Bryan},
title = {UniGraph: Learning a Unified Cross-Domain Foundation Model for Text-Attributed Graphs},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709277},
doi = {10.1145/3690624.3709277},
abstract = {Foundation models like ChatGPT and GPT-4 have revolutionized artificial intelligence, exhibiting remarkable abilities to generalize across a wide array of tasks and applications beyond their initial training objectives. However, graph learning has predominantly focused on single-graph models, tailored to specific tasks or datasets, lacking the ability to transfer learned knowledge to different domains. This limitation stems from the inherent complexity and diversity of graph structures, along with the different feature and label spaces specific to graph data. In this paper, we recognize text as an effective unifying medium and employ Text-Attributed Graphs (TAGs) to leverage this potential. We present our UniGraph framework, designed to learn a foundation model for TAGs, which is capable of generalizing to unseen graphs and tasks across diverse domains. Unlike single-graph models that use pre-computed node features of varying dimensions as input, our approach leverages textual features for unifying node representations, even for graphs such as molecular graphs that do not naturally have textual features. We propose a novel cascaded architecture of Language Models (LMs) and Graph Neural Networks (GNNs) as backbone networks. Additionally, we propose the first pre-training algorithm specifically designed for large-scale self-supervised learning on TAGs, based on Masked Graph Modeling. We introduce graph instruction tuning using Large Language Models (LLMs) to enable zero-shot prediction ability. Our comprehensive experiments across various graph learning tasks and domains demonstrate the model's effectiveness in self-supervised representation learning on unseen graphs, few-shot in-context transfer, and zero-shot transfer, even surpassing or matching the performance of GNNs that have undergone supervised training on target datasets.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {448–459},
numpages = {12},
keywords = {graph neural networks, graph pre-training, self-supervised learning},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3701716.3715293,
author = {Li, Wenbin and Yao, Di and Zhao, Ruibo and Chen, Wenjie and Xu, Zijie and Luo, Chengxue and Gong, Chang and Jing, Quanliang and Tan, Haining and Bi, Jingping},
title = {STBench: Assessing the Ability of Large Language Models in Spatio-Temporal Analysis},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715293},
doi = {10.1145/3701716.3715293},
abstract = {The rapid evolution of large language models (LLMs) holds promise for reforming the methodology of spatio-temporal data mining. However, current works for evaluating the spatio-temporal understanding capability of LLMs are somewhat limited and biased. These works either fail to incorporate the latest language models or only focus on assessing a specific dimension of spatio-temporal capabilities, making the evaluation not comprehensive. To address this gap, this paper dissects LLMs' capability of spatio-temporal data into four distinct dimensions: knowledge comprehension, spatio-temporal reasoning, accurate computation, and downstream applications. We curate several natural language question-answer tasks for each category and build the benchmark dataset, namely STBench, containing 15 distinct tasks and over 70,000 QA pairs. Moreover, we have assessed the capabilities of 13 LLMs and experimental results reveal that existing LLMs show remarkable performance on knowledge comprehension and spatio-temporal reasoning tasks, with potential for further enhancement on other tasks through in-context learning, chain-of-thought prompting, and fine-tuning. The code and datasets of STBench are released on https://github.com/LwbXc/STBench.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {749–752},
numpages = {4},
keywords = {benchmark, large language models, spatio-temporal data mining},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696443.3708929,
author = {Taneja, Jubi and Laird, Avery and Yan, Cong and Musuvathi, Madan and Lahiri, Shuvendu K.},
title = {LLM-Vectorizer: LLM-Based Verified Loop Vectorizer},
year = {2025},
isbn = {9798400712753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696443.3708929},
doi = {10.1145/3696443.3708929},
abstract = {Vectorization is a powerful optimization technique that significantly boosts the performance of high performance computing applications operating on large data arrays. Despite decades of research on auto-vectorization, compilers frequently miss opportunities to vectorize code. On the other hand, writing vectorized code manually using compiler intrinsics is still a complex, error-prone task that demands deep knowledge of specific architecture and compilers.  In this paper, we evaluate the potential of large-language models (LLMs) to generate vectorized (Single Instruction Multiple Data) code from scalar programs that process individual array elements.   We propose a novel finite-state-machine multi-agents based approach that harnesses LLMs and test-based feedback to generate vectorized code.  Our findings indicate that LLMs are capable of producing high-performance vectorized code with run-time speedup ranging from 1.1x to 9.4x as compared to the state-of-the-art compilers such as Intel Compiler, GCC, and Clang.  To verify the correctness of vectorized code, we use Alive2, a leading bounded translation validation tool for LLVM IR. We describe a few domain-specific techniques to improve the scalability of Alive2 on our benchmark dataset. Overall, our approach is able to verify 38.2% of vectorizations as correct on the TSVC benchmark dataset.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {137–149},
numpages = {13},
keywords = {AI Agents, Large language model, Loop Vectorization, Translation Validation},
location = {Las Vegas, NV, USA},
series = {CGO '25}
}

@inproceedings{10.1145/3641554.3701960,
author = {Sanchez, Edwin Antonio and Zheng, Muwei and Bishop, Matt and Zou, Xukai},
title = {Case Study 2: Mapping between an E-Voting Curriculum and the DHS/NSA CAE Knowledge Units},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701960},
doi = {10.1145/3641554.3701960},
abstract = {To become a DHS/NSA Center of Academic Excellence in Cyber Defense (CAE-CD), academic institutions must satisfy several specific Knowledge Units (KUs). How they achieve this is up to the institutions. In this case study, we follow the methodology of an earlier work to demonstrate how key parts of an electronic voting (E-voting)-oriented cybersecurity curriculum, proposed by Hostler et al. [4] in 2021, maps into the DHS/NSA KUs supporting the CAE-CD designation, from two aspects: E-voting principle based topics, i.e., from theory and a plug-and-play e-voting system's composing components, i.e., from practice. We grouped CAE-CD KUs into those required as prerequisites, closely related, related/supported, and not covered by the E-voting curriculum. Teachers can then choose which KUs they will use and teach using only the parts of the E-voting-oriented curriculum they deem relevant, and in a depth they find appropriate to their educational objectives, while meeting the requirements of the selected KUs. We conclude with a discussion of how LLMs (Large Language Models) and quantum computing might be added to the E-voting-oriented curriculum.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1022–1028},
numpages = {7},
keywords = {cae-cd, cybersecurity curriculum, cybersecurity education, electronic voting system},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3700794.3700817,
author = {Monteiro Santos, Mateus and Barros, Aristoteles and Rodrigues, Luiz and Dermeval, Diego and Primo, Tiago and Ibert, Ig and Isotani, Seiji},
title = {Near Feasibility, Distant Practicality: Empirical Analysis of Deploying and Using LLMs on Resource-Constrained Smartphones},
year = {2025},
isbn = {9798400710414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700794.3700817},
doi = {10.1145/3700794.3700817},
abstract = {Artificial Intelligence (AI) systems, such as Large Language Models (LLMs), have the transformative potential to empower education. However, utilizing such systems often requires technological infrastructure, including computers and internet access, which are unavailable in many underserved regions, particularly in the Global South. Despite these limitations, research indicates that smartphones are increasingly accessible even in these areas, presenting an opportunity to deliver advanced systems like LLMs through resource-constrained devices. Nevertheless, the technical feasibility of deploying and using LLMs on disconnected smartphones remains unexplored to the best of our knowledge. This paper presents an empirical study that developed an LLM-powered mobile application, deployed it on a smartphone, and evaluated its performance in terms of response time, memory usage, and storage utilization based on three lightweight LLMs (Tinyllama, Redpajama, and Qwen2). The results show that the overall response time ranged from one to two minutes, and memory usage varied between three and nearly five GB. While these findings demonstrate the technical feasibility of deploying LLMs on disconnected smartphones, the significant waiting time and memory consumption highlight the challenges of this approach. Therefore, although LLMs can be deployed on resource-constrained devices to provide equitable access to advanced educational technology, there is an urgent need to develop optimized alternatives suitable for underserved educational settings so that exploring LLMs in such context becomes practically feasible.},
booktitle = {Proceedings of the 13th International Conference on Information &amp; Communication Technologies and Development},
pages = {224–235},
numpages = {12},
location = {
},
series = {ICTD '24}
}

@inproceedings{10.1145/3713081.3731731,
author = {Xie, Yuanmin and Xu, Zhenyang and Tian, Yongqiang and Zhou, Min and Zhou, Xintong and Sun, Chengnian},
title = {Kitten: A Simple Yet Effective Baseline for Evaluating LLM-Based Compiler Testing Techniques},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731731},
doi = {10.1145/3713081.3731731},
abstract = {Compiler testing is critical and indispensable to improve the correctness of compilers. Spurred by recent advancements in Large Language Models (LLMs), LLM-based compiler testing techniques such as Fuzz4All, have demonstrated their potential in uncovering real bugs in diverse compilers and reducing the required engineering efforts in designing program generators. Given the continuous evolution of LLMs and the emergence of new LLM-based approaches, establishing robust baselines is crucial for rigorous evaluation and driving future advancements in this promising research direction.To this end, we introduce Kitten, a mutation-based, language-agnostic program generator. Kitten leverages a corpus of seed programs, analogous to the training set for LLMs, and utilizes the target language's syntax, akin to the knowledge learned by LLMs. Furthermore, Kitten's mutation operators can generate diverse test programs, demonstrating a behavior analogous to the ability of LLM inference to generate new code.Our evaluations demonstrate that, using existing compiler test suites as seed programs, Kitten outperforms Fuzz4All in terms of code coverage and bug detection capabilities. Within 24 hours, Kitten achieved 48.3%, 9.9%, and 33.8% higher coverage than Fuzz4All on GCC, LLVM, and Rustc, respectively, while identifying an average of 19.3, 20.3, and 15.7 bugs in these compilers across three runs. Over the course of nine months dedicated to Kitten's development and testing, we identified a total of 328 across the compilers GCC, LLVM, Rustc, Solc, JerryScript, scalac, and slang, of which 310 have been confirmed or fixed. We strongly believe that Kitten serves as an effective baseline, enabling the identification of limitations within existing LLM-based approaches and consequently driving advancements in this promising research direction.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {21–25},
numpages = {5},
keywords = {compiler testing, language-agnostic code generation, benchmarking},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3722405.3722445,
author = {Zhou, Shengpeng and Li, Haojie},
title = {A Personality Detection Model Based on Language Style and Contrastive Learning},
year = {2025},
isbn = {9798400713880},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722405.3722445},
doi = {10.1145/3722405.3722445},
abstract = {Launched based on data up to October 2024, personality detection has become a significant area of recent research in psychology, human-computer interaction, and social media analysis. Yet existing computational psychology frameworks ignore the role of writing style in behavioral prediction tasks. Further, a single pre-trained model is still used in many studies to extract semantic information from texts. To overcome these limitations, we propose a novel personality detection approach, styleSem, which jointly leverages writing style and deep semantics. We first apply large language models (LLMs) to extract 11 different writing style features, then incorporate a number of pre-trained models with contrastive learning to enhance semantic aspects. We perform experiments on two common benchmark datasets, Essays and MyPersonality. On the Essays dataset, the new method showed an improvement of 1.74% on average compared to the current state of art algorithm. On MyPersonality dataset, it obtains average accuracy 2.42% higher than top-performing method.},
booktitle = {Proceedings of the 2024 International Conference on Image Processing, Multimedia Technology and Maching Learning},
pages = {247–252},
numpages = {6},
keywords = {Attention, Contrastive Learning, Personality Detection, Pre-trained Model, Writing Style},
location = {
},
series = {IPMML '24}
}

@inproceedings{10.1145/3698364.3705351,
author = {Lu, Yi-Chen and Kunal, Kishor and Pradipta, Geraldo and Liang, Rongjian and Gandikota, Ravikishore and Ren, Haoxing},
title = {LEGO-Size: LLM-Enhanced GPU-Optimized Signoff-Accurate Differentiable VLSI Gate Sizing in Advanced Nodes},
year = {2025},
isbn = {9798400712937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698364.3705351},
doi = {10.1145/3698364.3705351},
abstract = {On-Chip Variation (OCV)-aware and Path-Based Analysis (PBA) accurate timing optimization achieved by gate sizing (including Vth-assignment) remains a pivotal step in modern signoff. However, in advanced nodes (e.g., 3nm), commercial tools often yield suboptimal results due to the intricate design demands and the vast choices of library cells that require substantial runtime and computational resources for exploration. To address these challenges, we introduce LEGO-Size, a generative framework that harnesses the power of Large Language Models (LLMs) and GPU-accelerated differentiable techniques for efficient gate sizing. LEGO-Size introduces three key innovations. First, it considers timing paths as sequences of tokenized library cells, casting gate sizing prediction as a language modeling task and solving it with self-supervised learning and supervised fine-tuning. Second, it employs a Graph Transformer (GT) with a linear-complexity attention mechanism for netlist encoding, enabling LLMs to make sizing decisions from a global perspective. Third, it integrates a differentiable Static Timing Analysis (STA) engine to refine LLM-predicted gate size probabilities by directly optimizing Total Negative Slack (TNS) through gradient descent. Experimental results on 5 unseen million-gate industrial designs in a commercial 3nm node show that LEGO-Size achieves up to 125x speed up with 37% TNS improvement over an industry-leading commercial signoff tool with minimal power and area overhead.},
booktitle = {Proceedings of the 2025 International Symposium on Physical Design},
pages = {152–162},
numpages = {11},
keywords = {differentiable static timing analysis (sta), generative gate sizing},
location = {Austin, TX, USA},
series = {ISPD '25}
}

@inproceedings{10.1145/3689031.3717489,
author = {Yuan, Haochen and Wang, Yuanqing and Xie, Wenhao and Cheng, Yu and Miao, Ziming and Ma, Lingxiao and Xue, Jilong and Yang, Zhi},
title = {NeuStream: Bridging Deep Learning Serving and Stream Processing},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3717489},
doi = {10.1145/3689031.3717489},
abstract = {Modern Deep Neural Network (DNN) exhibits a pattern where multiple sub-models are executed, guided by control flows such as loops and switch/merge operations. This dynamic nature introduces complexities in batching the requests of such DNNs for efficient execution on GPUs. In this paper, we present NeuStream, a programming model and runtime system for serving deep learning workloads using stream processing. NeuStream decomposes the inference workflow into modules and forms them into a streaming processing system where a request flows through. Based on such abstraction, NeuStream is able to batch requests at fine-grained module granularity. To maximize serving goodput, NeuStream exploits a two-level scheduling approach to decide the best batching requests and resource allocation for each module while satisfying service level objectives (SLOs). Our evaluation of NeuStream on a set of modern DNNs like Large Language Models (LLM) and diffusion models, etc., shows that NeuStream significantly improves goodput compared to state-of-the-art DNN serving systems.},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {671–685},
numpages = {15},
keywords = {Deep Learning Serving, Streaming Processing System, dynamic Neural Networks},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@inproceedings{10.1145/3708468.3715686,
author = {Post, Kevin and Kuchida, Reo and Olapade, Mayowa and Yin, Zhigang and Flores, Huber},
title = {Making Sensing Interactive and Descriptive with LLMs: Context Reasoning from Multi-Sensor Data},
year = {2025},
isbn = {9798400714030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708468.3715686},
doi = {10.1145/3708468.3715686},
abstract = {Sensor-based Human Activity Recognition (HAR) and context inference using ML/DL (machine and deep learning) models classify activities but offer limited insights into user behaviors and experiences. For instance, IMU sensor data classified may identify "running" or "kicking," but miss broader contexts like "executing an offensive jump in a football match." We present ContextLLM[2], a context-driven solution powered by Large Language Models (LLMs) that transforms sparse, abstract sensor data into detailed, meaningful context descriptions. By using the OPPORTUNITY dataset[1], we show how LLMs aggregate insights from multiple sensors to infer rich context, addressing challenges of data sparsity and fragmentation, and enhancing context-aware applications. As shown in Figure 1, by producing these descriptions using natural language, ContextLLM unlocks new possibilities for making sensing more interactive, e.g., through sensing co-pilot apps.},
booktitle = {Proceedings of the 26th International Workshop on Mobile Computing Systems and Applications},
pages = {130},
numpages = {1},
location = {La Quinta, CA, USA},
series = {HotMobile '25}
}

@article{10.1145/3735140,
author = {Sprenkamp, Kilian and Eckhardt, Sven and Zavolokina, Liudmila and Schwabe, Gerhard},
title = {From Information-Seeking to Information-Asking: Designing RefuGPT, a Chatbot for Ukrainian Refugees in Switzerland},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3735140},
doi = {10.1145/3735140},
abstract = {A key challenge for refugees is accessing relevant information about their host country. However, refugees often face disorientation during their information-seeking process. Disorientation is driven by language barriers, a digital divide, high urgency, and an evolving situation, which hinders the refugees’ ability to access information. Addressing the issue of disorientation, we propose an IT artifact, i.e., a chatbot called RefuGPT, designed through a rigorous Design Science Research Methodology. RefuGPT leverages the power of a large language model (LLM), GPT-4 while accessing two distinct sources of information, i.e., official and community-based information utilizing retrieval augmented generation and prompt-based learning (Figure 1). We assess RefuGPT's usefulness and usability through an ex-post evaluation in a naturalistic setting with Ukrainian refugees. Hence, we show that our bi-layered LLM-based chatbot can effectively assist refugees. They thus move from information-seeking to a more effortless information-asking. Based on those insights, we propose design principles as well as practical recommendations for refugee chatbots.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = may,
keywords = {Large Language Model, Refugee Management, Chatbot Design}
}

@inproceedings{10.1145/3704289.3704293,
author = {Duah, James Ewert and Lu, Xin and McGivern, Paul and Jing, Yanguo},
title = {Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704293},
doi = {10.1145/3704289.3704293},
abstract = {The ongoing integration of Generative Artificial Intelligence (GenAI) within higher education (HE) signifies a pivotal shift in pedagogical paradigms, demanding comprehensive theoretical and practical considerations. This paper critically examines the multifaceted adoption of GenAI in HE by reviewing interdisciplinary theoretical frameworks from psychology, computer science, and pedagogy. It highlights the insufficiency of traditional technology acceptance models, which predominantly address cognitive and rational decision-making processes, and advocates for the inclusion of emotional and ethical dimensions often overlooked in existing frameworks. By synthesizing research across various disciplines, this review identifies significant gaps and proposes an integrated theoretical model to effectively understand and guide GenAI adoption. The proposed framework emphasizes the need for robust, empirically supported methodologies that accommodate the complex, dynamic nature of GenAI applications. This paper not only contributes to academic discourse by providing a comprehensive review of existing literature but also sets a foundation for future empirical studies aimed at refining GenAI integration strategies in HE, ensuring they are ethically aligned and educationally effective.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {1–9},
numpages = {9},
keywords = {GenAI, Higher Education, Psychology, Theoretical Frameworks},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3701716.3715868,
author = {Behdin, Kayhan and Dai, Yun and Dexter, Gregory and Gupta, Aman and Mazumder, Rahul and Saha, Ankan and Song, Qingquan and Tang, Shao and Zhu, Sirou and Hsu, Pin-Lun},
title = {Efficient Algorithms for Leveraging LLMs for Generative and Predictive Recommender Systems},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715868},
doi = {10.1145/3701716.3715868},
abstract = {Large language models (LLMs) have taken the world by storm, revolutionizing the use of AI in products. While scaling laws demonstrate that larger models yield better results, making them work in production is hard, often due to latency demands on inference. In this proposed tutorial, we will share optimizations - both algorithmic and systems-related - that help leverage LLMs (both small and large) for recommendation and generative AI use cases at planet scale for the world's largest professional network - LinkedIn. In the first part of the tutorial, we will discuss state-of-the-art (SOTA) model quantization and pruning techniques. This will be in conjunction with a discussion on GPU kernel-level optimizations including minimizing memory copying, effectively utilizing shared memory, optimizing thread scheduling, and maximizing parallel efficiency. We will discuss our own experience with these inventing and leveraging such techniques, while also discussing the latest advancements from other enterprises and the open source world. Our discussions will cover models ranging in size from 1 billion to 100 billion+ parameters. In the second part of the tutorial, we will discuss the latest advancements in the world of LLM knowledge distillation which can result in training very powerful and performant small language models (SLMs). We will also discuss effective instruction tuning and preference alignment techniques that help with improving accuracy and quality of results for generative use cases. Finally, we will discuss actual production use cases that benefit from the aforementioned techniques at planet scale for LinkedIn.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1–4},
numpages = {4},
keywords = {compression, distillation, large language models, pruning, quantization},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706599.3720175,
author = {Wang, Yishu and Zhou, Fangyu and Han, Xiaokang and Yao, Kecheng and Li, Zhuying},
title = {FoodSage: Addressing Recognition Uncertainty in Automated Dietary Monitoring through Human-Robot Dialogue},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720175},
doi = {10.1145/3706599.3720175},
abstract = {This paper presents FoodSage, a robotic dietary monitoring system that addresses meal tracking challenges through human-robot dialogue. Unlike conventional approaches reliant on manual logging or fully automated recognition, FoodSage employs a human-in-the-loop methodology combining computer vision with natural conversation. A mobile robot autonomously navigates to dining locations and captures meal images using an onboard camera for automated food recognition. Recognition uncertainty is resolved by conversational verification, facilitated by a large language model (LLM). Through incremental learning, FoodSage incorporates user feedback to improve recognition and adapt to diverse eating scenarios. A pilot study with four participants demonstrates that FoodSage communicates effectively while achieving accurate food tracking. By functioning as both a food monitor and an eating companion, it reduces the burden of manual input, maintains high accuracy, and enriches the dining experience. This work contributes to dining monitoring by offering a human-in-the loop approach, ultimately supporting healthier eating habits.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {282},
numpages = {7},
keywords = {Human-in-the-loop, Incremental learning, Diet monitoring, LLM},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3708557.3716358,
author = {Li, Lei and Duan, Manni and Wang, Yongheng},
title = {Interactive Visualization of LSST Quantum Graph},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716358},
doi = {10.1145/3708557.3716358},
abstract = {The Vera C. Rubin Observatory’s Legacy Survey of Space and Time (LSST) project generates vast amounts of data managed by its Pipeline System, built upon the Quantum Graph representing data processing tasks. Official visualization tools based on Graphviz have limitations, including size constraints, inflexible layouts, and difficulty in locating nodes. We propose a new visualization approach using the Dify framework to address these issues. Our contributions include: (1) a program to export Quantum Graph instances into Dify’s workflows, storing Quantum Graph node data in Dify’s CODE nodes with pop-up modals; (2) a more reasonable layout algorithm for Dify workflows that represents LSST’s data processing logic; and (3) a navigation agent based on Large Language Models (LLM) that enables users to locate specific nodes through natural language queries. These improvements enhance the understanding and efficiency of Quantum Graph analysis, offering a more interactive and user-friendly visualization experience for LSST users.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {152–154},
numpages = {3},
keywords = {LSST, pipeline system, visualization, Dify, workflow},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3690624.3709424,
author = {Yu, Pengfei and Gu, Jingjing and Shen, Dazhong and Dong, Xin and Liu, Yang and Xiong, Hui},
title = {Instruction Semantics Enhanced Dual-Flow Graph Model for GPU Error Resilience Prediction},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709424},
doi = {10.1145/3690624.3709424},
abstract = {As GPUs are widely deployed in High Performance Computing systems, it is critical to ensure that these systems can perform reliably. To improve system reliability, researchers estimate the error resilience of GPU programs by understanding resilience characteristics or modeling error propagation. However, features indicative of resilience rely on manual extraction from simulations of numerous faults, and error propagation analysis cannot target fine-grained bit-level faults. To address those problems, this paper introduces a novel paradigm, namely InstrDGM, for efficiently predicting GPU error resilience. Specifically, InstrDGM first fine-tunes a large language model using extensive sequences of GPU assembly instructions for extracting the semantic representation of instructions automatically. Meanwhile, we consider the propagation of bit-level faults during instruction execution and data transfer processes, and leverage graph neural networks to capture their distinct error propagation patterns. Then, the fault embeddings extracted from these error propagation patterns are integrated for error resilience prediction. Additionally, this paper releases a new dataset for GPU error resilience assessment, containing 1.2 million fault samples. Finally, extensive experiments show that InstrDGM significantly outperforms existing methods.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2803–2814},
numpages = {12},
keywords = {error resilience, failure prediction, gpu, graph neural network, large language model},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3676536.3676674,
author = {Qin, Ruiyang and Yan, Zheyu and Zeng, Dewen and Jia, Zhenge and Liu, Dancheng and Liu, Jianbo and Abbasi, Ahmed and Zheng, Zhi and Cao, Ningyuan and Ni, Kai and Xiong, Jinjun and Shi, Yiyu},
title = {Robust Implementation of Retrieval-Augmented Generation on Edge-based Computing-in-Memory Architectures},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676674},
doi = {10.1145/3676536.3676674},
abstract = {Large Language Models (LLMs) deployed on edge devices learn through fine-tuning and updating a certain portion of their parameters. Although such learning methods can be optimized to reduce resource utilization, the overall required resources remain a heavy burden on edge devices. Instead, Retrieval-Augmented Generation (RAG), a resource-efficient LLM learning method, can improve the quality of the LLM-generated content without updating model parameters. However, the RAG-based LLM may involve repetitive searches on the profile data in every user-LLM interaction. This search can lead to significant latency along with the accumulation of user data. Conventional efforts to decrease latency result in restricting the size of saved user data, thus reducing the scalability of RAG as user data continuously grows. It remains an open question: how to free RAG from the constraints of latency and scalability on edge devices? In this paper, we propose a novel framework to accelerate RAG via Computing-in-Memory (CiM) architectures. It accelerates matrix multiplications by performing in-situ computation inside the memory while avoiding the expensive data transfer between the computing unit and memory. Our framework, Robust CiM-backed RAG (RoCR), utilizing a novel contrastive learning-based training method and noise-aware training, can enable RAG to efficiently search profile data with CiM. To the best of our knowledge, this is the first work utilizing CiM to accelerate RAG.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {50},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.5555/3709347.3743575,
author = {Deng, Shilong and Wang, Yongzhao and Savani, Rahul},
title = {From Natural Language to Extensive-Form Game Representations},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {We introduce a framework for translating game descriptions in natural language into game-theoretic extensive-form representations, leveraging Large Language Models (LLMs) and in-context learning. We find that a naive application of in-context learning struggles on this problem, in particular with imperfect information. To address this, we introduce GameInterpreter, a two-stage framework with specialized modules to enhance in-context learning, enabling it to divide and conquer the problem effectively. In the first stage, we tackle the challenge of imperfect information by developing a module that identifies information sets and the corresponding partial tree structure. With this information, the second stage leverages in-context learning alongside a self-debugging module to produce a complete extensive-form game tree represented using pygambit, the Python API of a recognized game-theoretic analysis tool called Gambit. Using this python representation enables the automation of tasks such as computing Nash equilibria directly from natural language descriptions. We evaluate the performance of the full framework, as well as its individual components, using various LLMs on games with different levels of strategic complexity. Our experimental results show that the framework significantly outperforms baseline approaches in generating accurate extensive-form games, with each module playing a critical role in its success.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {593–601},
numpages = {9},
keywords = {code generation, extensive-form games, gambit, game translation, large language models},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@article{10.1145/3733601,
author = {Chen, Magi and Wang, Ting-Chi},
title = {HyperPlace: Harnessing a Large Language Model for Efficient Hyperparameter Optimization in GPU-Accelerated VLSI Placement},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3733601},
doi = {10.1145/3733601},
abstract = {While GPU-based placers have demonstrated significant speed advantages over their CPU-based counterparts, hyperparameter tuning remains a bottleneck, often requiring substantial human intervention and expert knowledge. This challenge is particularly critical given the urgent need for rapid time-to-market solutions. Recently, Large Language Models (LLMs) have exhibited remarkable capabilities in zero-shot learning, context understanding, logical reasoning, and answer generation. In this work, we introduce HyperPlace, an innovative paradigm that leverages an off-the-shelf LLM to automate hyperparameter optimization using in-context learning techniques. Our approach transcends single-output black-box optimization methods by incorporating a batch optimization mechanism that evaluates multiple hyperparameter configurations simultaneously across several GPU computing platforms. We validated the effectiveness of our approach in placement quality, measured by Half-Perimeter Wire Length (HPWL), using DREAMPlace 2.0. To further demonstrate the capability of integrating our framework with other placers, we conducted additional experiments using Xplace 2.0. By employing the ISPD2005 benchmarks for our evaluation, HyperPlace enhances the placement tools with up to a 1.66% reduction in HPWL compared to their published results. Additionally, we evaluated HyperPlace on the ISPD2015 benchmarks, which incorporate fence region constraints not present in ISPD2005 benchmarks. Under these more complex constraints, HyperPlace achieves up to a 22.24% reduction in HPWL compared to the default settings of the placement tools, further demonstrating its adaptability across diverse placement scenarios and benchmark suites.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {LLM Agent, Hyperparameter Optimization}
}

@inproceedings{10.1145/3711542.3711575,
author = {Afzal, Anum and Vladika, Juraj and Fazlija, Gentrit and Staradubets, Andrei and Matthes, Florian},
title = {Towards Optimizing a Retrieval Augmented Generation using Large Language Model on Academic Data},
year = {2025},
isbn = {9798400717383},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711542.3711575},
doi = {10.1145/3711542.3711575},
abstract = {Given the growing trend of many organizations integrating Retrieval Augmented Generation (RAG) into their operations, we assess RAG on domain-specific data and test state-of-the-art models across various optimization techniques. We incorporate four optimizations; Multi-Query, Child-Parent-Retriever, Ensemble Retriever, and In-Context-Learning, to enhance the functionality and performance in the academic domain. We focus on data retrieval, specifically targeting various study programs at a large technical university. We additionally introduce a novel evaluation approach, the RAG Confusion Matrix designed to assess the effectiveness of various configurations within the RAG framework. By exploring the integration of both open-source (e.g., Llama2, Mistral) and closed-source (GPT-3.5 and GPT-4) Large Language Models, we offer valuable insights into the application and optimization of RAG frameworks in domain-specific contexts. Our experiments show a significant performance increase when including multi-query in the retrieval phase.},
booktitle = {Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval},
pages = {250–257},
numpages = {8},
keywords = {Retrieval Augmented Generation, Large Language Models, Benchmark},
location = {
},
series = {NLPIR '24}
}

@inproceedings{10.1145/3706468.3706525,
author = {Li, Zaibei and Yamaguchi, Shunpei and Spikol, Daniel},
title = {OpenMMLA: an IoT-based Multimodal Data Collection Toolkit for Learning Analytics},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706525},
doi = {10.1145/3706468.3706525},
abstract = {Multimodal Learning Analytics (MMLA) expands traditional learning analytics into the digital and physical learning environment, using diverse sensors and systems to collect information about education in more real-world environments. Challenges remain in making these technologies practical for capturing data in authentic learning situations. With the advent of readily accessible powerful artificial intelligence that includes multimodal large language models, new opportunities are available. However, few approaches allow access to these technologies, and most systems are developed for specific environments. Recent work has begun to make toolkits with access to collecting data from sensors, processing, and analyzing, yet these tools are challenging to integrate into a system. This paper introduces OpenMMLA, a toolkit approach that provides programming interfaces for harnessing these technologies into an MMLA platform with prebuilt pipelines, including the audio analyzer, indoor positioning, and video frame analyzer, offering multimodal data collection and visualizations and analytics. The paper provides an initial evaluation of the functionalities of the toolkit in data capturing and the implemented pipelines’ performances.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {872–879},
numpages = {8},
keywords = {Multimodal Learning Analytics, Group Work, Internet of Thing, Smart Badges},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706598.3713447,
author = {Falk, Jeanette and Chen, Yiyi and Rafner, Janet and Zhang, Mike and Bjerva, Johannes and Nolte, Alexander},
title = {How Do Hackathons Foster Creativity? Towards Automated Evaluation of Creativity at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713447},
doi = {10.1145/3706598.3713447},
abstract = {Hackathons have become popular collaborative events for accelerating the development of creative ideas and prototypes. There are several case studies showcasing creative outcomes across domains such as industry, education, and research. However, there are no large-scale studies on creativity in hackathons which can advance theory on how hackathon formats lead to creative outcomes. We conducted a computational analysis of 193,353 hackathon projects. By operationalizing creativity through usefulness and novelty, we refined our dataset to 10,363 projects, allowing us to analyze how participant characteristics, collaboration patterns, and hackathon setups influence the development of creative projects. The contribution of our paper is twofold: We identified means for organizers to foster creativity in hackathons. We also explore the use of large language models (LLMs) to augment the evaluation of creative outcomes and discuss challenges and opportunities of doing this, which has implications for creativity research at large.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {23},
keywords = {Hackathons, creativity, human-centered AI, large language models, quantitative methods},
location = {
},
series = {CHI '25}
}

@inbook{10.1145/3724504.3724635,
author = {He, Hao and Gao, Chaobang},
title = {Research on the Application of Artificial Intelligence in Basic Education: A Global Trend Analysis Based on Bibliometrics},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724635},
abstract = {Based on the bibliometric method, this study visually analyzed the application research literature of artificial intelligence (AI) in the domain of basic education in the Web of Science Core Collection from January 1, 2014 to November 1, 2024 with the help of VOSviewer and CiteSpace. A total of 344 valid articles were selected from 588 institutions and 1090 authors in 60 countries. They were published in 126 journals and cited 13855 references from 6922 journals. The study found that the number of papers published in China is the largest, and the quality recognition of papers in the United States is high. The journals with the greatest number of articles were mostly related to educational technology and computational intelligence, and Computers &amp; Education had the greatest number of citations per article. Keyword co-occurrence analysis shows that the study focuses on deep learning and the application of large language models (LLMs) has increased. The timeline analysis shows that the domain research has moved from the stage of data driven and educational technology application exploration to the stage of AI empowerment and personalized education. The co-citation analysis reveals that the interdisciplinary characteristics of educational technology research are obvious, and the literature co-citation network reflects the multi-dimensional application research type of AI in basic education. All in all, the popularity of AI application research in basic education is increasing, the research focus has changed, and generative AI is developing rapidly.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {799–806},
numpages = {8}
}

@inproceedings{10.1145/3721146.3721944,
author = {Silvestre, Pedro F. and Pietzuch, Peter},
title = {Systems Opportunities for LLM Fine-Tuning using Reinforcement Learning},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721944},
doi = {10.1145/3721146.3721944},
abstract = {Reinforcement learning-based fine-tuning (RLFT) has emerged as a crucial workload for enhancing large language models (LLMs). RLFT workflows are challenging, involving nested loops, multiple models, dynamically shaped tensors and interleaving sequential generation and parallel inference tasks. Despite these complexities, current RLFT engines rely on coarse-grained algorithm representations, treating each component as an independently optimized black-box. As a result, RLFT engines suffer from redundant computations, scheduling overhead, inefficient memory management, and missed opportunities for parallelism.We argue that a fine-grained representation is needed to enable holistic optimization for RLFT workloads. Additionally, we demonstrate that existing declarative deep learning engines fail to optimize RLFT workloads end-to-end due to their need for static tensor shapes and loop bounds, leading to excessive peak memory usage and unnecessary computations. Through micro-benchmarks, we quantify these inefficiencies and show that addressing them could enable more efficient and flexible execution. We propose an RLFT system design based on a fine-granularity representation, opening the door to generalizable optimizations, and paving the way for more scalable and efficient RLFT systems.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {90–99},
numpages = {10},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}

@inproceedings{10.1145/3676536.3676766,
author = {Liu, Shiwei and Tao, Guanchen and Zou, Yifei and Chow, Derek and Fan, Zichen and Lei, Kauna and Pan, Bangfei and Sylvester, Dennis and Kielian, Gregory and Saligane, Mehdi},
title = {ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676766},
doi = {10.1145/3676536.3676766},
abstract = {The self-attention mechanism distinguishes transformer-based large language models (LLMs) apart from convolutional and recurrent neural networks. Despite the performance improvement, achieving real-time LLM inference on silicon remains challenging due to the extensive use of Softmax in self-attention. In addition to the non-linearity, the low arithmetic intensity significantly limits processing parallelism, especially when working with longer contexts. To address this challenge, we propose Constant Softmax (ConSmax), a software-hardware co-design that serves as an efficient alternative to Softmax. ConSmax utilizes differentiable normalization parameters to eliminate the need for maximum searching and denominator summation in Softmax. This approach enables extensive parallelization while still executing the essential functions of Softmax. Moreover, a scalable ConSmax hardware design with a bitwidth-split look-up table (LUT) can achieve lossless non-linear operations and support mixed-precision computing. Experimental results show that ConSmax achieves a minuscule power consumption of 0.2mW and an area of 0.0008mm2 at 1250MHz working frequency in 16nm FinFET technology. For open-source contribution, we further implement our design with the OpenROAD toolchain under SkyWater's 130nm CMOS technology. The corresponding power is 2.69mW and the area is 0.007mm2. ConSmax achieves 3.35\texttimes{} power savings and 2.75\texttimes{} area savings in 16nm technology, and 3.15\texttimes{} power savings and 4.14\texttimes{} area savings with the open-source EDA toolchain. In the meantime, it also maintains comparable accuracy on the GPT-2 model and the WikiText103 dataset. The project is available at https://github.com/ReaLLMASIC/ConSmax.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {72},
numpages = {9},
keywords = {LLM, transformer, hardware-software co-design, softmax, consmax},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3703412.3703437,
author = {Paul, Bibek and Bhowmick, Archisman and Mishra, Mayank and Gupta, Sarthak and Singhal, Rekha},
title = {TASCA++ : A multi-agentic tool to scalably accelerate ML pipelines},
year = {2025},
isbn = {9798400711619},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703412.3703437},
doi = {10.1145/3703412.3703437},
abstract = {In the evolving landscape of machine learning (ML) and deep learning (DL), automatic optimization of these pipelines are crucial, especially with growing data volumes.Our tool TASCA&nbsp;[2], an enhanced tool that leverages advanced Large Language Models (LLMs) like GPTNeo3.5/4 to automatically detect and transform performance anti-patterns in ML pipelines without human intervention. Building on our previous work with TASCA&nbsp;[2], TASCA++ extends the capabilities of its predecessor by incorporating new features that improve detection accuracy and transformation efficiency, resulting in much better optimization. Our empirical evaluation on multiple real-world workloads demonstrates significant performance gains. TASCA++ represents a significant step forward in automated ML pipeline optimization, reducing computational overheads and enhancing scalability.},
booktitle = {Proceedings of the 4th International Conference on AI-ML Systems},
articleno = {25},
numpages = {3},
keywords = {Code Acceleration, ML Pipeline, Scalability Bottlenecks, Multi-Agents},
location = {
},
series = {AIMLSystems '24}
}

@inproceedings{10.5555/3709347.3743537,
author = {Banna, Tahsin Tariq and Rahman, Sejuti and Tareq, Mohammad},
title = {Beyond Words: Integrating Personality Traits and Context-Driven Gestures in Human-Robot Interactions},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {As robots become increasingly integrated into human life, personalizing human-robot interactions (HRI) is crucial for improving user acceptance, engagement, and interaction quality. However, personalizing HRI poses a unique challenge due to the diversity of human personality traits. This paper proposes a method that leverages large language models (LLMs) to dynamically tailor robot conversations according to the Big Five (OCEAN) personality traits. Our novelty lies in using user personality traits to shape robots' verbal responses and implementing contextual action generation for gestures. This study addresses two primary research questions: (1) Does adapting robots' verbal responses based on user personality traits improve communication satisfaction? (2) How does the addition of context-appropriate gestures further enhance user satisfaction? We used Goldberg's personality trait measurement scale (1992) to assess 26 participants who engaged in conversations with an LLM-powered Pepper robot on various topics. The quality of these interactions was self-reported using a revised version of Hecht's (1978) conversation satisfaction scale. Three experimental conditions were conducted: (i) Baseline: Standard LLM conversation, (ii) Personality-congruent: LLM-adjusted dialogue based on personality of participants, and (iii) Enhanced interaction: Personality adaptation plus dynamic gestures. For the third condition, we implemented contextually appropriate pre-defined animations and generated novel gestures by computing joint angle values in real time. Statistical analysis using ANOVA revealed significant differences in communication satisfaction across the three conditions (F=13.41, p&lt;.001). Post-hoc analyses using \v{S}id\'{a}k's multiple comparison test showed significant pairwise differences: Condition 2 vs. 1: Δ Δmean 4.42 , p = 0.02; Condition 3 vs. 1: Δ Δmean 8.23, p &lt; 0.01; Condition 3 vs. 2: Δ Δmean 3.80, p = 0.05. These results demonstrate that both personality-congruent interactions and non-verbal gestures significantly enhance communication satisfaction, with the combined approach yielding the highest satisfaction. This approach opens new possibilities for developing socially intelligent robots with applications in healthcare, education, and customer service.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {242–251},
numpages = {10},
keywords = {HRI, LLM, generative actions, personality traits, robotics},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@article{10.1145/3723005,
author = {Zhang, Xinjie and Zhang, Tenggan and Sun, Lei and Zhao, Jinming and Jin, Qin},
title = {Exploring Interpretability in Deep Learning for Affective Computing: A Comprehensive Review},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3723005},
doi = {10.1145/3723005},
abstract = {Deep learning has shown impressive performance in affective computing, but its black-box characteristic limits the model’s interpretability, posing a challenge to further development and application. Compared with objective recognition tasks such as image recognition, emotion perception as a high-level cognition is more subjective, making it particularly important to enhance the interpretability of deep learning in affective computing. In recent years, some interpretability-related works have emerged, but there are few reviews on this topic yet. This paper summarizes the explainable deep learning methods in affective computing from two aspects: first, the application of general explainable deep learning methods in affective computing from the perspectives of model-agnostic and model-specific is introduced; second, emotion-specific interpretability research that combines emotional psychology theories, physiological studies, and human cognition, covering task design, model design, and result analysis methods, is systematically reviewed. There are new explainable deep learning methods for multimodal and large language models in the context of emotion. Finally, we discuss five specific challenges and propose corresponding future directions to provide insights and references for subsequent research on affective computing interpretability.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
keywords = {Affective computing, Explainable methods, Deep learning, Multimodal}
}

@article{10.1145/3728636,
author = {Kim, Gun Il and Hwang, Sunga and Jang, Beakcheol},
title = {Efficient Compressing and Tuning Methods for Large Language Models: A Systematic Literature Review},
year = {2025},
issue_date = {October 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3728636},
doi = {10.1145/3728636},
abstract = {Efficient compression and tuning techniques have become indispensable in addressing the increasing computational and memory demands of large language models (LLMs). While these models have demonstrated exceptional performance across a wide range of natural language processing tasks, their growing size and resource requirements pose significant challenges to accessibility and sustainability. This survey systematically reviews state-of-the-art methods in model compression, including compression techniques such as knowledge distillation, low-rank approximation, parameter pruning, and quantization, as well as tuning techniques such as parameter-efficient fine-tuning and inference optimization. Compression techniques, though well-established in traditional deep learning, require updated methodologies tailored to the scale and dynamics of LLMs. Simultaneously, parameter-efficient fine-tuning, exemplified by techniques like Low-Rank Adaptation (LoRA) and query tuning, emerges as a promising solution for adapting models with minimal resource overhead. This study provides a detailed taxonomy of these methods, examining their practical applications, strengths, and limitations. Critical gaps are identified in scalability, and the integration of compression and tuning strategies, signaling the need for unified frameworks and hybrid approaches to maximize efficiency and performance. By addressing these challenges, this survey aims at guiding researchers toward sustainable, efficient, and accessible LLM development, ensuring their broader applicability across diverse domains while mitigating resource constraints.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {253},
numpages = {39},
keywords = {Large language models, knowledge distillation, low-rank strategy, quantization, parameter pruning, LoRA, PEFT, inference tuning}
}

@inproceedings{10.1145/3641555.3705180,
author = {Brilliantova, Angelina and Butler, Zack and Bez\'{a}kov\'{a}, Ivona},
title = {Exploring ChatGPT as a Qualitative Research Assistant},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705180},
doi = {10.1145/3641555.3705180},
abstract = {In many CS educational research studies, students are surveyed to understand their reactions to a particular pedagogical approach or tool. These surveys, as well as other types of evaluations, often invite students to provide open-ended feedback about their experiences. However, analyzing these comments can prove to be a challenge, especially to CS educators who may not have strong expertise in qualitative research methods. In addition, in a large study, evaluating all of the provided comments can consume a significant amount of researcher time. In this work, we undertook two separate conversations with ChatGPT in which we prompted it to perform qualitative analysis of a set of comments collected in an earlier study. This allowed us to begin to judge how effectively a modern large language model can serve as an assistant in qualitative analysis. We found that with the prompts we used, ChatGPT can reliably build a set of reasonable labels (codes) for a set of comments, but the application of its labels to specific comments may or may not be effective and human researchers still need to use care and their own understanding in interpreting its output.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1397–1398},
numpages = {2},
keywords = {chatgpt, grounded theory, large-language models, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3701716.3715309,
author = {Sun, Qiang and Luo, Yuanyi and Zhang, Wenxiao and Li, Sirui and Li, Jichunyang and Niu, Kai and Kong, Xiangrui and Liu, Wei},
title = {Docs2KG: A Human-LLM Collaborative Approach to Unified Knowledge Graph Construction from Heterogeneous Documents},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715309},
doi = {10.1145/3701716.3715309},
abstract = {Enterprises generate vast amounts of unstructured documents, posing challenges for knowledge extraction and representation. Large language models (LLMs) offer strong potential for processing such data but struggle with factual accuracy and provenance. Knowledge graphs (KGs) provide a structured framework to address these limitations [6], yet constructing high-quality KGs from heterogeneous data remains a challenge. To address this issue, we present Docs2KG, a modular framework to build high-quality KGs from diverse unstructured documents. We first employs state-of-the-art document processing techniques to extract textual content, tabular data, and figures. The extracted information is then unified into a multifaceted KG with three aspects: (1) a Layout KG capturing document structural hierarchies, (2) a Metadata KG preserving document properties, and (3) a Semantic KG representing domain-specific entities and relationships. Docs2KG supports multiple construction paradigms for Semantic KG: ontology-based approaches, hybrid NLP pipelines with LLM verification, LLM-guided ontology generation, and specialized models for named entity recognition, event extraction, and causal relationship identification to enhance semantic coverage and accuracy. A key feature of Docs2KG is its human-in-the-loop verification interface, enabling iterative quality assessment and refinement of the resulting KGs. Docs2KG is openly available at https://docs2kg.ai4wa.com, with the aim of advancing knowledge graph construction research and accelerating enterprise applications through high-quality knowledge graph construction.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {801–804},
numpages = {4},
keywords = {heterogeneous data, knowledge graph, unstructured data},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3702163.3702432,
author = {Zhang, Mengchen and Feng, Xiang},
title = {Automated Annotation of Academic Emotion Intensity in Online Learning Comment Texts: A BWS Method Based on LLMs},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702432},
doi = {10.1145/3702163.3702432},
abstract = {Academic emotions significantly impact learning processes and student performance, with a recent trend towards automated measurement for their types and intensity. However, manual annotation methods for large-scale training data required by modeling face issues of time consumption and high cost. The Best Worst Scaling (BWS) methodology enhances the reliability of intensity annotation, while Large Language Models (LLMs) offer advantages in understanding academic emotions across diverse contexts. Combining the BWS and LLMs in academic emotion intensity annotation, this study aims to address the challenge of data annotation in measuring academic emotion intensity in online learning. We choose three widely recognized LLMs to complete the BWS annotation tasks separately, then calculate the consistency and conduct statistical analysis. Results indicate that the consistency of the three LLMS in identifying emotion intensity in nine academic emotions was above 0.750, with a total of 0.865 in 4569 comment texts. The perception of emotion intensity by the LLMs closely resembles that of human cognition and responds to the context of online learning, enabling them to effectively substitute for humans in performing large-scale annotation tasks.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {317–323},
numpages = {7},
keywords = {Academic Emotion Intensity, Automated Annotation, Best Worst Scaling (BWS), Online Learning},
location = {
},
series = {ICETC '24}
}

@article{10.1145/3705725,
author = {Yang, Yutao and Zhou, Jie and Ding, Xuanwen and Huai, Tianyu and Liu, Shunyu and Chen, Qin and Xie, Yuan and He, Liang},
title = {Recent Advances of Foundation Language Models-based Continual Learning: A Survey},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {5},
issn = {0360-0300},
url = {https://doi.org/10.1145/3705725},
doi = {10.1145/3705725},
abstract = {Recently, foundation language models (LMs) have marked significant achievements in the domains of natural language processing and computer vision. Unlike traditional neural network models, foundation LMs obtain a great ability for transfer learning by acquiring rich common sense knowledge through pre-training on extensive unsupervised datasets with a vast number of parameters. Despite these capabilities, LMs still struggle with catastrophic forgetting, hindering their ability to learn continuously like humans. To address this, continual learning (CL) methodologies have been introduced, allowing LMs to adapt to new tasks while retaining learned knowledge. However, a systematic taxonomy of existing approaches and a comparison of their performance are still lacking. In this article, we delve into a comprehensive review, summarization, and classification of the existing literature on CL-based approaches applied to foundation language models, such as pre-trained language models, large language models, and vision-language models. We divide these studies into offline and online CL, which consist of traditional methods, parameter-efficient-based methods, instruction tuning-based methods and continual pre-training methods. Additionally, we outline the typical datasets and metrics employed in CL research and provide a detailed analysis of the challenges and future work for LMs-based continual learning.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {112},
numpages = {38},
keywords = {Continual learning, foundation language models, pre-trained language models, large language models, vision-language models, survey}
}

@inproceedings{10.1145/3696410.3714965,
author = {Liu, Yan},
title = {The AI Revolution in Time Series: Challenges and Opportunites},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714965},
doi = {10.1145/3696410.3714965},
abstract = {Recent advancements in deep learning and artificial intelligence have driven significant progress in time series modeling and analysis. On one hand, researchers seek breakthroughs in performance on classical tasks such as forecasting, anomaly detection, classification, etc. On the other hand, it is intriguing to explore the potential for answering more complex inference and reasoning tasks from time series. In this keynote, I will examine the pathways toward foundation models for time series and discuss future research directions in this rapidly evolving field.The remarkable success of foundation models in natural language processing - exemplified by Generative Pre-trained Transformers (GPT) - suggests their potential to revolutionize time series analysis. I will introduce our recent efforts along this direction, including TEMPO, a novel framework designed to learn effective time series representations by leveraging two key inductive biases: one is explicit decomposition of trend, seasonal, and residual components, and the second is prompt-based distribution adaptation for diverse time series types.Beyond representation learning, practical applications demands advanced reasoning capabilities with multi-step time series inference task, requiring both compositional reasoning and computational precision. To tackle this challenge, I will discuss TS-reasoner, a program-aided inference agent that integrates large language models (LLMs) with structured execution pipelines, in-context learning, and self-correction mechanisms. I will discuss a new benchmark dataset and evaluation framework to systematically assess multi-step time series reasoning.By bridging deep learning advances with structured reasoning, I will highlight the next frontier in time series research, i.e., developing foundation models that enhance forecasting performance, generative models, and reasoning capabilities from time series across diverse applications.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4},
numpages = {1},
keywords = {foundation models, generative models, multi-step reasoning, time series},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3734523,
author = {Reddy, E Bhawani Eswar and Bhattacharyya, Sutirtha and Sarmah, Ankur and Nongpoh, Fedrick and Maddala, Karthik and Karfa, Chandan},
title = {LHS: LLM Assisted Efficient High-level Synthesis of Deep Learning Tasks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3734523},
doi = {10.1145/3734523},
abstract = {Deep learning tasks, especially those involving complex convolution neural networks (CNNs), are computationally intensive and pose significant challenges when implemented on hardware. Accelerating these tasks is critical for improving performance. High-level Synthesis (HLS) has the potential to automate the efficient hardware accelerator designs directly from high-level C/C++ specification of trained machine learning (ML) models. Traditional HLS tools cannot synthesize certain high-level constructs, which require manual intervention. Many source code optimizations and the selection of pragmas for HLS optimizations are crucial for generating efficient hardware accelerators with HLS. However, both of these tasks are mostly manual efforts. Recently, Large Language Models (LLMs) have shown remarkable capabilities in various generative tasks. In this work, we explore the application of LLMs to remove these manual efforts in adapting HLS for ML accelerator designs. Our framework called LLM-assisted HLS, i.e., LHS, uses LLMs to automate the resolution of synthesis issues, ensuring compatibility with HLS tools. Furthermore, our framework automates the source code modification and optimization selection through pragma insertion steps, which are crucial for optimizing the synthesized design. Our experimental results with LHS demonstrate a significant improvement in latency for deep learning tasks with underlying complex CNN models without much area overhead. Our LHS allows us to achieve up to 2690 \texttimes{} latency improvement. Promisingly, LHS performs better than the state-of-the-art ML accelerator design tool hls4ml in 4 out of 6 cases in the context of latency improvement at the expense of area overhead (i.e., performance to hardware gain). This work highlights the potential of LLMs to assist and accelerate the HLS process, thereby creating more efficient hardware implementation for deep learning models.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {LLM, High-level synthesis, CNN}
}

@inproceedings{10.1145/3701716.3715872,
author = {Pan, Junwei and Zhang, Zhilin and Zhu, Han and Xu, Jian and Jiang, Jie and Zheng, Bo},
title = {Computational Advertising: Recent Advances},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715872},
doi = {10.1145/3701716.3715872},
abstract = {Computational advertising is one of the most successful application scenarios of machine learning and artificial intelligence. This tutorial is designed to review the latest progress of several critical areas in computational advertising: matching, prediction, auction and bidding. Particularly, with the recent advances in generative AI such as large language models, there is a growing interest in further enhancing these areas with these techniques. In this tutorial, we first introduce the recent advances in matching, including its architecture alternatives, model developments, and how it co-evolves with the ad products which distinguishes itself from that in recommendation products. We then review the recent advances in prediction, with a focus on topics such as feature interactions, user interest models, and multi-task/domain learning. We will show how these building bricks constitute large prediction models and LLM-enhanced/LLM-based prediction models. Then, we discuss auction and bidding, a unique area in computational advertising. Both traditional and learning-based auctions will be introduced, followed by their applications in real-world ad products. Given the auction designs, we show how bidding evolves from control-based, to reinforcement learning-based, and most recently to generative AI-based. Our aim is to help the audience grasp the recent developments in computational advertising, as well as to spark inspiration for future research.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {37–40},
numpages = {4},
keywords = {auction, bidding, click-through rate prediction, generative models, matching, recommendation systems},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714723,
author = {Wen, Bao and Gu, Jingjing and Han, Hao and Yu, Pengfei and Liu, Yang},
title = {Instruction Vulnerability Prediction for WebAssembly with Semantic Enhanced Code Property Graph},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714723},
doi = {10.1145/3696410.3714723},
abstract = {WebAssembly (Wasm) is a universal low-level bytecode designed to build modern web systems. Recent studies have shown that technologies such as voltage scaling and RowHammer attacks are expected to increase the likelihood of bit flips, which may cause unacceptable or catastrophic system failures. This raises concerns about the impact of bit flips on Wasm programs, which run as instructions in web systems, and it is an undeveloped topic since the features of Wasm differ from traditional programs. In this paper, we propose a novel paradigm, namely IVPSEG, to understand the error propagation of bit flips within Wasm programs. Specifically, we first use Large Language Models (LLMs) to automatically extract instruction embeddings containing semantic knowledge of each instruction's context. Then, we exploit these embeddings and program structure (control execution and data transfer) to construct a semantic enhanced code property graph, which implicates the potential path of error propagation. Based on this graph, we utilize graph neural networks and attention diffusion to optimize instruction embeddings by capturing different error propagation patterns for instruction vulnerability prediction. In particular, we build a Wasm compilation and fault generation system to simulate bit flips at Wasm runtime. Our experimental results with 14 benchmark programs and test cases show IVPSEG outperforms the state-of-the-art methods in terms of accuracy (average 13.06%ͽ ), F1-score (average 14.93%↑), and model robustness.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4134–4145},
numpages = {12},
keywords = {bit flips, error propagation, instruction vulnerability prediction, webassembly},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3676151.3719373,
author = {Pourali, Alireza and Boukani, Arian and Khazaei, Hamzeh},
title = {PreNeT: Leveraging Computational Features to Predict Deep Neural Network Training Time},
year = {2025},
isbn = {9798400710735},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676151.3719373},
doi = {10.1145/3676151.3719373},
abstract = {Training deep learning models, particularly Transformer-based architectures such as Large Language Models (LLMs), demands substantial computational resources and extended training periods. While optimal configuration and infrastructure selection can significantly reduce associated costs, this optimization requires preliminary analysis tools. This paper introduces PreNeT, a novel predictive framework designed to address this optimization challenge. PreNeT facilitates training optimization by integrating comprehensive computational metrics, including layer-specific parameters, arithmetic operations and memory utilization. A key feature of PreNeT is its capacity to accurately predict training duration on previously unexamined hardware infrastructures, including novel accelerator architectures. This framework employs a sophisticated approach to capture and analyze the distinct characteristics of various neural network layers, thereby enhancing existing prediction methodologies. Through proactive implementation of PreNeT, researchers and practitioners can determine optimal configurations, parameter settings, and hardware specifications to maximize cost-efficiency and minimize training duration. Experimental results demonstrate that PreNeT achieves up to 72% improvement in prediction accuracy compared to contemporary state-of-the-art frameworks.},
booktitle = {Proceedings of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {81–91},
numpages = {11},
keywords = {computational complexity, large language models, training time prediction},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3676641.3716267,
author = {Gu, Yufeng and Khadem, Alireza and Umesh, Sumanth and Liang, Ning and Servot, Xavier and Mutlu, Onur and Iyer, Ravi and Das, Reetuparna},
title = {PIM Is All You Need: A CXL-Enabled GPU-Free System for Large Language Model Inference},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716267},
doi = {10.1145/3676641.3716267},
abstract = {Large Language Model (LLM) inference uses an autoregressive manner to generate one token at a time, which exhibits notably lower operational intensity compared to earlier Machine Learning (ML) models such as encoder-only transformers and Convolutional Neural Networks. At the same time, LLMs possess large parameter sizes and use key-value caches to store context information. Modern LLMs support context windows with up to 1 million tokens to generate versatile text, audio, and video content. A large key-value cache unique to each prompt requires a large memory capacity, limiting the inference batch size. Both low operational intensity and limited batch size necessitate a high memory bandwidth. However, contemporary hardware systems for ML model deployment, such as GPUs and TPUs, are primarily optimized for compute throughput. This mismatch challenges the efficient deployment of advanced LLMs and makes users to pay for expensive compute resources that are poorly utilized for the memory-bound LLM inference tasks.We propose CENT, a CXL-ENabled GPU-Free sysTem for LLM inference, which harnesses CXL memory expansion capabilities to accommodate substantial LLM sizes, and utilizes near-bank processing units to deliver high memory bandwidth, eliminating the need for expensive GPUs. CENT exploits a scalable CXL network to support peer-to-peer and collective communication primitives across CXL devices. We implement various parallelism strategies to distribute LLMs across these devices. Compared to GPU baselines with maximum supported batch sizes and similar average power, CENT achieves 2.3x higher throughput and consumes 2.3x less energy. CENT reduces the Total Cost of Ownership (TCO), generating 5.2x more tokens per dollar than GPUs.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {862–881},
numpages = {20},
keywords = {compute express link, computer architecture, generative artificial intelligence, large language models, processing-in-memory},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3658617.3697645,
author = {Xu, Jiaming and Li, Jinhao and Liu, Jun and Zhou, Hao and Dai, Guohao},
title = {Accelerator for LLM-Enhanced GNN with Product Quantization and Unified Indexing},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697645},
doi = {10.1145/3658617.3697645},
abstract = {To alleviate the vulnerability of graph neural networks (GNNs) on unseen graphs, many works propose to integrate large language models (LLMs) into GNNs, called graph foundation models (GFMs). The LLM-enhanced GNN, a typical integration method of GFMs, has achieved state-of-the-art performance in most graph-related tasks. However, intensive general matrix multiplications (GEMMs) overhead of LLMs poses a significant challenge to end-to-end inference latency. The introduction of LLMs brings 100\texttimes{} more workload than original GNNs, with GEMMs accounting for more than 99%, becoming the bottleneck of end-to-end inference.To tackle the above challenge, we present GFMEngine, an algorithm and hardware co-design accelerator supporting LLM-enhanced GNNs at multiple levels. (1) At the algorithm level, we point out that the computational precision of LLMs has little impact on the end-to-end accuracy, and propose a product-quantization-based (PQ-based) matrix multiplication for LLMs to alleviate the intensive GEMMs in LLMs, reducing more than 70% computation with negligible accuracy loss. (2) At the hardware level, we point out that the implementation of PQ-based matrix multiplication effectively alleviates the intensive GEMMs but results in a substantial increase in dynamic memory access. Coupled with the dynamic memory access inherent in GNNs, we design a unified indexing unit as the hardware support, reducing ~ 30% memory access in end-to-end inference. (3) At the compilation level, we further design an extensible instruction set architecture as the software support, GFM-ISA, for various real-world GFM tasks. We implement GFMEngine with TSMC 28nm process, and extensive experiments show that GFMEngine achieves up to 3.93\texttimes{}, 38.66\texttimes{}, 22.32\texttimes{}, 2.96\texttimes{} speedup and up to 102.52\texttimes{}, 37.82\texttimes{}, 28.37\texttimes{}, 2.56\texttimes{} energy efficiency improvement compared with NVIDIA Tesla A100 and the domain-specific accelerators, SGCN, MEGA, FACT, respectively.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {534–540},
numpages = {7},
location = {Tokyo, Japan},
series = {ASPDAC '25}
}

@inproceedings{10.1145/3713081.3731741,
author = {Mai, Yubo and Gao, Zhipeng and Hu, Xing and Bao, Lingfeng and Chen, Jingyuan and Sun, Jianling},
title = {Code2API: A Tool for Generating Reusable APIs from Stack Overflow Code Snippets},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731741},
doi = {10.1145/3713081.3731741},
abstract = {Nowadays, developers often turn to Stack Overflow for solutions to daily problems, however, these code snippets are partial code that cannot be tested and verified properly. One way to test these code snippets is to transform them into APIs (Application Program Interface) that developers can directly invoked and executed. However, it is often costly and error-prone for developers to manually perform this transformation (referred to as AIPzation task) due to different actions to be taken (e.g., summarizing proper method names, inferring input parameters list and return statements). To help developers quickly reuse code snippets in Stack Overflow, in this paper, we propose Code2API, a Google Chrome extension that uses Large Language Models (LLMs) to automatically perform APIzation of code snippets on Stack Overflow. Code2API guides LLMs through well-designed prompts to generate reusable APIs, using Chain-of-Thought reasoning and few-shot in-context learning to help LLMs understand and solve the APIzation task in a developer-like manner. The evaluation results show that Code2API significantly outperforms the rule-based approach by a large margin. The full paper of this tool has been published in FSE'24 as a research paper [11].Demo video: https://youtu.be/RI-ZpBnNNwQ.Demo website: https://doi.org/10.6084/m9.figshare.24426961.v1.Replication package: https://github.com/qq804020866/Code2API.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {71–75},
numpages = {5},
keywords = {stack overflow, API, large language model, code snippets},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@inproceedings{10.1145/3701716.3715259,
author = {Cai, Leng and He, Junxuan and Li, Yikai and Liang, Junjie and Lin, Yuanping and Quan, Ziming and Zeng, Yawen and Xu, Jin},
title = {RTBAgent: A LLM-based Agent System for Real-Time Bidding},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715259},
doi = {10.1145/3701716.3715259},
abstract = {Real-Time Bidding (RTB) enables advertisers to place competitive bids on impression opportunities instantaneously, striving for cost-effectiveness in a highly competitive landscape. Although RTB has widely benefited from the utilization of technologies such as deep learning and reinforcement learning, the reliability of related methods often encounters challenges due to the discrepancies between online and offline environments and the rapid fluctuations of online bidding. To handle these challenges, RTBAgent is proposed as the first RTB agent system based on large language models (LLMs), which synchronizes real competitive advertising bidding environments and obtains bidding prices through an integrated decision-making process. Specifically, obtaining reasoning ability through LLMs, RTBAgent is further tailored to be more professional for RTB via involved auxiliary modules, i.e., click-through rate estimation model, expert strategy knowledge, and daily reflection. In addition, we propose a two-step decision-making process and multi-memory retrieval mechanism, which enables RTBAgent to review historical decisions and transaction records and subsequently make decisions more adaptive to market changes in real-time bidding. Empirical testing with real advertising datasets demonstrates that RTBAgent significantly enhances profitability. The RTBAgent code will be publicly accessible at: https://github.com/CaiLeng/RTBAgent.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {104–113},
numpages = {10},
keywords = {bid optimization, bidding agents, large language models, real-time bidding},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3676536.3676741,
author = {Zhong, Shuzhang and Liang, Ling and Wang, Yuan and Wang, Runsheng and Huang, Ru and Li, Meng},
title = {AdapMoE: Adaptive Sensitivity-based Expert Gating and Management for Efficient MoE Inference},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676741},
doi = {10.1145/3676536.3676741},
abstract = {Mixture-of-Experts (MoE) models are designed to enhance the efficiency of large language models (LLMs) without proportionally increasing the computational demands. However, their deployment on edge devices still faces significant challenges due to high on-demand loading overheads from managing sparsely activated experts. This paper introduces AdapMoE, an algorithm-system co-design framework for efficient MoE inference. AdapMoE features adaptive expert gating and management to reduce the on-demand loading overheads. We observe the heterogeneity of experts loading across layers and tokens, based on which we propose a sensitivity-based strategy to adjust the number of activated experts dynamically. Meanwhile, we also integrate advanced prefetching and cache management techniques to further reduce the loading latency. Through comprehensive evaluations on various platforms, we demonstrate AdapMoE consistently outperforms existing techniques, reducing the average number of activated experts by 25% and achieving a 1.35\texttimes{} speedup without accuracy degradation. Code is available at: https://github.com/PKU-SEC-Lab/AdapMoE.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {51},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@article{10.1145/3704997,
author = {Renzullo, Joseph and Reiter, Pemma and Weimer, Westley and Forrest, Stephanie},
title = {Automated Program Repair: Emerging Trends Pose and Expose Problems for Benchmarks},
year = {2025},
issue_date = {August 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {8},
issn = {0360-0300},
url = {https://doi.org/10.1145/3704997},
doi = {10.1145/3704997},
abstract = {Machine learning (ML) pervades the field of Automated Program Repair (APR). Algorithms deploy neural machine translation and large language models (LLMs) to generate software patches, among other tasks. But, there are important differences between these applications of ML and earlier work, which complicates the task of ensuring that results are valid and likely to generalize. A challenge is that the most popular APR evaluation benchmarks were not designed with ML techniques in mind. This is especially true for LLMs, whose large and often poorly-disclosed training datasets may include problems on which they are evaluated.This article reviews work in APR published in the field’s top five venues since 2018, emphasizing emerging trends in the field, including the dramatic rise of ML models, including LLMs. ML-based articles are categorized along structural and functional dimensions, and a variety of issues are identified that these new methods raise. Importantly, data leakage and contamination concerns arise from the challenge of validating ML-based APR using existing benchmarks, which were designed before these techniques were popular. We discuss inconsistencies in evaluation design and performance reporting and offer pointers to solutions where they are available. Finally, we highlight promising new directions that the field is already taking.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {208},
numpages = {18},
keywords = {automated program repair, machine learning, benchmarks, patch quality}
}

@inproceedings{10.1145/3701716.3715858,
author = {Zhang, Chuxu and Ding, Kaize and Li, Jundong and Xu, Dongkuan and Wang, Haoyu and Cheng, Derek Zhiyuan and Liu, Huan},
title = {Resource-Efficient Learning for the Web},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715858},
doi = {10.1145/3701716.3715858},
abstract = {Deep learning techniques have demonstrated impressive effectiveness across a wide array of web applications. Notably, graph neural networks (GNNs) and large language models (LLMs) have become essential tools for modeling the extensive graph-structured data and text/language data that populate the web. Despite their success, the advancement of these methods is frequently hampered by resource constraints. Key challenges include the scarcity of labeled data (data-level constraints) and the demand for smaller model sizes suitable for real-world computing environments (model-level constraints). Addressing these issues is crucial for the effective and efficient deployment of models across various real-world web systems and applications, such as social networks, search engines, recommender systems, question answering, and content analysis. Therefore, there is an urgent need to develop innovative and efficient learning techniques that can overcome these resource limitations from both data and model perspectives.In this lecture-style tutorial, we will focus on state-of-the-art approaches in resource-efficient learning, specifically exploring a range of data- and model-efficient methods for GNNs and LLMs, along with their practical applications in web contexts. Our objectives for this tutorial are threefold: (1)to categorize challenges in resource-efficient learning and discuss data and model constraints; (2) to provide a comprehensive review of existing methods and recent advances in resource-efficient learning, particularly concerning GNNs and LLMs; and (3) to highlight open questions and potential future research directions in this rapidly evolving field. Together, these objectives will provide participants with a comprehensive understanding of resource-efficient learning for GNNs and LLMs, its challenges, and its potential for future advancements.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {77–80},
numpages = {4},
keywords = {deep learning, graph neural networks, large language models, resource-efficient learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3733599,
author = {Luo, Wenqiang and Keung, Jacky and Yang, Boyang and Ye, He and Le Goues, Claire and Bissyand\'{e}, Tegawend\'{e} F. and Tian, Haoye and Le, Xuan Bach D.},
title = {When Fine-Tuning LLMs Meets Data Privacy: An Empirical Study of Federated Learning in LLM-Based Program Repair},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3733599},
doi = {10.1145/3733599},
abstract = {Software systems have been evolving rapidly and inevitably introducing bugs at an increasing rate, leading to significant maintenance costs. While large language models (LLMs) have demonstrated remarkable potential in enhancing software development and maintenance practices, particularly in automated program repair (APR), they rely heavily on high-quality code repositories. Most code repositories are proprietary assets that capture the diversity and nuances of real-world industry software practices, which public datasets cannot fully represent. However, obtaining such data from various industries is hindered by data privacy concerns, as companies are reluctant to share their proprietary codebases. There has also been no in-depth investigation of collaborative software development by learning from private and decentralized data while preserving data privacy for program repair.To address the gap, we investigate federated learning as a privacy-preserving method for fine-tuning LLMs on proprietary and decentralized data to boost collaborative software development and maintenance. We use the private industrial dataset TutorCode for fine-tuning and the EvalRepair-Java benchmark for evaluation, and assess whether federated fine-tuning enhances program repair. We then further explore how code heterogeneity (i.e., variations in coding style, complexity, and embedding) and different federated learning algorithms affect bug fixing to provide practical implications for real-world software development collaboration. Our evaluation reveals that federated fine-tuning can significantly enhance program repair, achieving increases of up to 16.67% for Top@10 and 18.44% for Pass@10, even comparable to the bug-fixing capabilities of centralized learning. Moreover, the negligible impact of code heterogeneity implies that industries can effectively collaborate despite diverse data distributions. Different federated algorithms also demonstrate unique strengths across LLMs, suggesting that tailoring the optimization process to specific LLM characteristics can further improve program repair.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Program Repair, Federated Learning, Large Language Models}
}

@inproceedings{10.5555/3709347.3744043,
author = {Zhao, Yunfan and Boehmer, Niclas and Taneja, Aparna and Tambe, Milind},
title = {Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {AI for social impact (AI4SI) offers significant potential for addressing complex societal challenges in areas such as public health, agriculture, education, conservation, and public safety. However, existing AI4SI research is often labor-intensive and resource-demanding, limiting its accessibility and scalability; the standard approach is to design a (base-level) system tailored to a specific AI4SI problem. We propose the development of a novel meta-level multi-agent system designed to accelerate the development of such base-level systems, thereby reducing the computational cost and the burden on social impact domain experts and AI researchers. Leveraging advancements in foundation models and large language models, our proposed approach focuses on resource allocation problems providing help across the full AI4SI pipeline from problem formulation over solution design to impact evaluation. We highlight the ethical considerations and challenges inherent in deploying such systems and emphasize the importance of a human-in-the-loop approach to ensure the responsible and effective application of AI systems.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2901–2907},
numpages = {7},
keywords = {foundation models, multiagent systems, social impact},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3676536.3676781,
author = {Xiong, Chenwei and Liu, Cheng and Li, Huawei and Li, Xiaowei},
title = {HLSPilot: LLM-based High-Level Synthesis},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676781},
doi = {10.1145/3676536.3676781},
abstract = {Large language models (LLMs) have catalyzed an upsurge in automatic code generation, garnering significant attention for register transfer level (RTL) code generation. Despite the potential of RTL code generation with natural language, it remains error-prone and limited to relatively small modules because of the substantial semantic gap between natural language expressions and hardware design intent. In response to the limitations, we propose a methodology that reduces the semantic gaps by utilizing C/C++ for generating hardware designs via High-Level Synthesis (HLS) tools. Basically, we build a set of C-to-HLS optimization strategies catering to various code patterns, such as nested loops and local arrays. Then, we apply these strategies to sequential C/C++ code through in-context learning, which provides the LLMs with exemplary C/C++ to HLS prompts. With this approach, HLS designs can be generated effectively. Since LLMs still face problems in determining the optimized pragma parameters precisely, we have a design space exploration (DSE) tool integrated for pragma parameter tuning. Furthermore, we also employ profiling tools to pinpoint the performance bottlenecks within a program and selectively convert bottleneck components to HLS code for hardware acceleration. By combining the LLM-based profiling, C/C++ to HLS translation, and DSE, we have established HLSPilot---the first LLM-enabled high-level synthesis framework, which can fully automate the high-level application acceleration on hybrid CPU-FPGA architectures. According to our experiments on real-world application benchmarks, HLSPilot achieve comparable performance in general and can even outperform manually crafted counterparts, thereby underscoring the substantial promise of LLM-assisted hardware designs.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {226},
numpages = {9},
keywords = {large language model, high-level synthesis, C-to-HLS, code generation},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3706599.3719675,
author = {Degachi, Chadha and Dhar, Ujjayan and Niforatos, Evangelos and Kortuem, Gerd},
title = {Towards a Domain Expert Evaluation Framework for Conversational Search in Healthcare},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719675},
doi = {10.1145/3706599.3719675},
abstract = {The rise of large language models for client-facing conversational search in healthcare necessitates evaluation frameworks that enable the assessment and comparison of these tools. Most such frameworks centre around the automated calculation of performance-related metrics and benchmarks. Though necessary, this focus fails to account for the human factors that impact the development, use, and adoption of these systems, as well as the factors specific to the healthcare context. Human evaluation frameworks attempt to address these drawbacks, but few such frameworks have been developed so far, and even fewer are those based on expert insight. In this work, we conduct semi-structured interviews with eleven healthcare professionals in health lifestyle care. From these interviews, we contribute a two-part healthcare domain expert evaluation framework, (K) Knowledge and (I) Interaction, which organises seven evaluation metrics. Our results reveal key understudied metrics for evaluation like (I1) Context-Seeking, (I2) Empathy, and (I3) Trustworthiness.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {537},
numpages = {9},
keywords = {human evaluation, large language models, digital health, conversational search},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3722228,
author = {Bodon, Herminio and Kumar, Vishesh and Worsley, Marcelo},
title = {Design Principles for Authentically Embedding Computer Science in Sports},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722228},
doi = {10.1145/3722228},
abstract = {Objectives. Athletics and sports represent a focal part of adolescence for millions of youth around the world. However, opportunities to engage in computer science (CS) learning experiences are less prevalent, particularly among Hispanic and low-income communities. Recently, researchers have explored ways to bridge these, seemingly, disparate disciplines. Much of this prior research centers on the proliferation of sports technologies that support individualistic learning experiences. Additionally, many of these experiences are developed by researchers with limited design contributions from sports practitioners. To extend prior work, this project centers youth athletic identities and the associated cultural contexts of sports to explore ways that computing technologies can enhance and develop youth athletic identities and sports performance. Moreover, this work surfaces ways that athletics can be a generative and fulfilling space to learn about CS.Participants. In summer 2021, we collaborated with basketball coaches to design and implement a computing-enhanced learning experience with a basketball team of Hispanic participants in Puerto Rico. Eleven basketball athletes from a high school in southern Puerto Rico participated in the study. The participants have strong sports identities, as demonstrated by their lifelong engagement with team sports. Conversely, only one 1 of the 11 participants had experienced sports technologies, and none of them had previously participated in computing learning experiences.Study Method. In collaboration with local basketball coaches, we co-designed a learning experience that centers sports identities and practices and adds computing as a way to extend existing sports identities and local sports activities. We present and evaluate this learning experience using a design-based research approach. Participants’ feedback was collected in the form of surveys, designs, and journal entries, and additional data on their experiences were collected via videos and researchers’ field notes. Using a mixed-methods approach, we highlight existing participants’ identities and perceptions as well as their experiences with our design. We complement quantitative analysis of survey responses with case studies.Findings. We find that our design can provide shifts in youth student-athletes’ perceptions of computing. Additionally, hands-on experiences with computing tools enable participants to start practicing CS sensemaking via learning how different computing tools can support their sports performance individually and as a team. Furthermore, we find that the material, ideational, and relational resources made available through camp:bit supported each participant differently, while collectively providing a space for all of them to have meaningful and fulfilling experiences. Finally, we find that this design can foster and support sports team cohesion.Conclusions. We provide in-depth descriptions of our design, the youth’s engagement with it, and how these learning experiences can be further applied in sports spaces. These examples highlight a unique conception of practice-linked computational identities—where learners’ computational identities are grounded in a specific culturally relevant practice, enabling a more culturally sustaining computing learning experience. Finally, our analysis suggests five design principles for designing and conducting computing-supported learning experiences in sports environments. The principles are as follows: (1) Sports Experience: Authentically Support Existing Identities. (2) Team Dynamics: Team Athletes Are Part of a Whole. (3) Individual Pursuits: Supporting Individual Paths. (4) Direct Interactions: Conversations with Materials and Ideas. (5) Interdisciplinary Facilitation Team: Complementary Skills. These design principles can be used by researchers, practitioners, and local stakeholders to implement sport-centric CS learning experiences to extend and enhance the way student-athletes from marginalized communities practice sports, as well as to activate interest and engagement in CS.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {13},
numpages = {42},
keywords = {Sports, Wearable, Identity, Computing, Computer Science Education, Design-Based Research, Participation, Data Science, AI}
}

@inproceedings{10.1145/3710848.3710871,
author = {Frantar, Elias and Castro, Roberto L. and Chen, Jiale and Hoefler, Torsten and Alistarh, Dan},
title = {MARLIN: Mixed-Precision Auto-Regressive Parallel Inference on Large Language Models},
year = {2025},
isbn = {9798400714436},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3710848.3710871},
doi = {10.1145/3710848.3710871},
abstract = {As inference on Large Language Models (LLMs) emerges as an important workload in machine learning applications, model weight quantization has become a standard technique for efficient GPU deployment. Quantization not only reduces model size, but has also been shown to yield substantial speedups for single-user inference, due to reduced memory movement, with low accuracy impact. Yet, it remains a key open question whether speedups are achievable also in batched settings with multiple parallel clients, which are highly relevant for practical serving. It is unclear whether GPU kernels can be designed to remain practically memory-bound, while supporting the substantially increased compute requirements of batched workloads.In this paper, we resolve this question positively by introducing a new design for Mixed-precision Auto-Regressive LINear kernels, called MARLIN. Concretely, given a model whose weights are compressed via quantization to, e.g., 4 bits per element, MARLIN shows that batchsizes up to 16-32 can be practically supported with close to maximum (4\texttimes{}) quantization speedup, and larger batchsizes up to 64-128 with gradually decreasing, but still significant, acceleration. MARLIN accomplishes this via a combination of techniques, such as asynchronous memory access, complex task scheduling and pipelining, and bespoke quantization support. Our experiments show that MARLIN's near-optimal performance on individual LLM layers across different scenarios can also lead to significant end-to-end LLM inference speedups (of up to 2.8\texttimes{}) when integrated with the popular vLLM open-source serving engine. Finally, we show that MARLIN is extensible to further compression techniques, like NVIDIA 2:4 sparsity, leading to additional speedups.},
booktitle = {Proceedings of the 30th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming},
pages = {239–251},
numpages = {13},
keywords = {Batch parallelism, GPU programming, Large language model (LLM) inference},
location = {Las Vegas, NV, USA},
series = {PPoPP '25}
}

@inproceedings{10.1145/3701100.3701162,
author = {Xu, Shulin and Jia, Xiao and Yan, Lei},
title = {Research on carbon footprint in the whole process of LLM based on refined modeling},
year = {2025},
isbn = {9798400718120},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701100.3701162},
doi = {10.1145/3701100.3701162},
abstract = {The rapid development of Large Language Model (LLM) has brought enormous pressure to power supply and environmental protection. It is necessary to model LLM computing power, electricity, and carbon emissions to analyze energy consumption issues and evaluate the impact of LLM. Previous research on implicit carbon mainly centered around calculation, while attention to operational carbon was mainly focused on LLM training and inference, resulting in incomplete and imprecise calculation of carbon footprint. In order to comprehensively simulate the carbon footprint of LLM throughout its lifecycle, we have created an LLM carbon footprint framework. There are two main contributions: firstly, we propose an algorithm that considers the storage and other components in the embodied carbon, thereby evaluating the embodied carbon emissions generated by all components. Secondly, we calculated the operational carbon in stages based on the LLM process and analyzed in detail the carbon emissions generated in each stage, including data processing, model training, model optimization, model deployment, and model inference, to achieve a refined carbon emission assessment. Finally, we briefly analyzed the current challenges and future development directions based on the model. Our modeling provides a theoretical basis for solving the high energy consumption problem of large-scale models in the future.},
booktitle = {Proceedings of the 2024 3rd International Conference on Algorithms, Data Mining, and Information Technology},
pages = {300–303},
numpages = {4},
keywords = {data center, LLM, carbon footprint, embodied carbon, operational carbon},
location = {
},
series = {ADMIT '24}
}

@inproceedings{10.1145/3721146.3721947,
author = {Jain, Kunal and Parayil, Anjaly and Mallick, Ankur and Choukse, Esha and Qin, Xiaoting and Zhang, Jue and Goiri, \'{I}\~{n}igo and Wang, Rujia and Bansal, Chetan and R\"{u}hle, Victor and Kulkarni, Anoop and Kofsky, Steve and Rajmohan, Saravan},
title = {Performance Aware LLM Load Balancer for Mixed Workloads},
year = {2025},
isbn = {9798400715389},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721146.3721947},
doi = {10.1145/3721146.3721947},
abstract = {Large Language Model (LLM) workloads consist of distinct prefill and decode phases, each with unique compute and memory requirements that should be considered when routing input queries across cluster instances. However, existing load-balancing algorithms treat these workloads as monolithic jobs, ignoring the differences between the two phases. This oversight leads to suboptimal query distribution and increased response latency. In our work, we first characterize the factors affecting response latency during LLM inference. We show that balancing inference requests across available LLM instances can improve end-to-end latency more than simply optimizing the instance-level scheduler. Motivated by these findings, we propose a heuristic-guided, reinforcement learning-based router for data-driven, workload-aware scheduling. Our router distributes queries across LLM instances by using a trainable response-length predictor and a novel formulation for estimating the impact of mixing different workloads, achieving over 11% lower end-to-end latency than existing methods on mixed public datasets. Our framework represents a first step toward a holistic optimization framework and serves as a benchmark for deriving optimal load balancing strategies tailored to different reward functions and requirements. Beyond latency, we can extend the proposed framework to optimize for various performance criteria ensuring that the system meets diverse operational objectives.},
booktitle = {Proceedings of the 5th Workshop on Machine Learning and Systems},
pages = {19–30},
numpages = {12},
location = {World Trade Center, Rotterdam, Netherlands},
series = {EuroMLSys '25}
}

@article{10.1145/3736654,
author = {Basnet, Animesh Singh and Ghanem, Mohamed Chahine and Dunsin, Dipo and Kheddar, Hamza and Sowinski-Mydlarz, Wiktor},
title = {Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736654},
doi = {10.1145/3736654},
abstract = {This paper investigates the application of Deep Reinforcement Learning (DRL) for attributing malware to specific Advanced Persistent Threat (APT) groups through detailed behavioural analysis. By analysing over 3,500 malware samples from 12 distinct APT groups, the study utilises sophisticated tools like Cuckoo Sandbox to extract behavioural data, providing a deep insight into the operational patterns of malware. The research demonstrates that the DRL model significantly outperforms traditional machine learning approaches such as SGD, SVC, KNN, MLP, and Decision Tree Classifiers, achieving an impressive test accuracy of 94.12%. It highlights the model's capability to adeptly manage complex, variable, and elusive malware attributes. Furthermore, the paper discusses the considerable computational resources and extensive data dependencies required for deploying these advanced AI models in cybersecurity frameworks. Future research is directed towards enhancing the efficiency of DRL models, expanding the diversity of the datasets, addressing ethical concerns, and leveraging Large Language Models (LLMs) to refine reward mechanisms and optimise the DRL framework. By showcasing the transformative potential of DRL in malware attribution, this research advocates for a responsible and balanced approach to AI integration, with the goal of advancing cybersecurity through more adaptable, accurate, and robust systems.},
note = {Just Accepted},
journal = {Digital Threats},
month = may,
keywords = {Advanced Persistent Threat (APT), Malware Attribution, AI, MDP, Deep Reinforcement Learning (DRL)}
}

@inproceedings{10.1145/3696410.3714529,
author = {Naseem, Usman and Hu, Liang and Zhang, Qi and Wang, Shoujin and Jameel, Shoaib},
title = {DiGrI: Distorted Greedy Approach for Human-Assisted Online Suicide Ideation Detection},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714529},
doi = {10.1145/3696410.3714529},
abstract = {User-generated content on social media platforms provides a valuable resource for developing automated computational methods to detect mental health issues online leading to suicidal thoughts automatically. Although current fully automated methods show promise, they may produce uncertain predictions, leading to flawed conclusions. To address this, we propose a novel model called DiGrI, or Distorted Greedy Approach for Human-Assisted Online Suicide Ideation Detection, which reformulates suicide ideation assessment as a selective, prioritized prediction problem. The model incorporates a novel multi-classifier distorted greedy model that is optimized to operate under various levels of automation and abstains from making uncertain predictions with theoretical guarantees. Our results show that DiGrI outperforms strong comparative models including large language models in detecting mental health issues on a publicly available Reddit dataset. We discuss the empirical and practical implications, including the ethical considerations of using DiGrI for online automatic suicide ideation detection involving humans, if it were to be translated for use in clinical and public health practice.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {5192–5201},
numpages = {10},
keywords = {deep learning, mental health detection, social media analysis, suicide ideation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inbook{10.1145/3658617.3697618,
author = {Huang, Shan and Li, Jinhao and Yu, Zhen and Ye, Jiancai and Xu, Jiaming and Xu, Ningyi and Dai, Guohao},
title = {LLSM: LLM-enhanced Logic Synthesis Model with EDA-guided CoT Prompting, Hybrid Embedding and AIG-tailored Acceleration},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697618},
abstract = {Machine learning-based methods have shown promising results in the field of Electronic Design Automation (EDA) like logic synthesis result prediction, enabling a shift-left in the overall EDA flow. Designers should fully optimize their Register Transfer Level (RTL) designs early because remedying low-quality RTL in downstream synthesis stages is extremely challenging. However, previous works mainly start modeling from the netlist level or layout level and apply Graph Neural Networks (GNNs) to make predictions.RTL captures the logic and scale information of circuits with uniform representation, making it suitable for a unified embedding approach. Since Large Language Models (LLMs) possess the ability to understand text modality, making them a potential method for understanding RTL and performing various EDA tasks. Therefore, we propose LLSM, the first LLM-enhanced logic synthesis model to extract information directly from RTL code. We also propose three novel approaches for LLSM in this paper. (1) EDA-guided Chain-of-Thought (CoT) prompting. We apply LLMs guided by circuit knowledge to summarize, analyze RTL code, and generate text with circuit information. (2) Text-circuit hybrid embedding. We train a small Language Model (LM) to encode the generated circuit information from LLM and fuse the embeddings of text and circuit modalities with weighted summation. (3) AIG-tailored acceleration library. We utilize an ELL2 format with zero padding tailored for And-Inverter-Graph (AIG) circuit representation and fuse the computation and format conversion. We also design a cacheable state strategy to avoid redundant computation for LM. We are the first to work with both LLM and GNN for the prediction of logic synthesis results and conduct extensive experiments on the OpenABC-D dataset. LLSM achieve up to 21.53% and 19.27% loss reduction in delay and area prediction respectively. It also achieves 1.34\texttimes{} and 6296.77\texttimes{} speedup on average compared to PyG implementation and Synopsis Design Compiler, respectively.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {974–980},
numpages = {7}
}

@article{10.1145/3695995,
author = {Huang, Yuekai and Wang, Junjie and Wang, Song and Wei, Moshi and Shi, Lin and Liu, Zhe and Wang, Qing},
title = {Deep API Sequence Generation via Golden Solution Samples and API Seeds},
year = {2025},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {2},
issn = {1049-331X},
url = {https://doi.org/10.1145/3695995},
doi = {10.1145/3695995},
abstract = {Automatic API recommendation can accelerate developers’ programming and has been studied for years. There are two orthogonal lines of approaches for this task, i.e., information retrieval-based (IR-based) approaches and sequence to sequence (seq2seq) model-based approaches. Although these approaches were reported to have remarkable performance, our observation finds two major drawbacks, i.e., IR-based approaches lack the consideration of relations among the recommended APIs, and seq2seq models do not model the API’s semantic meaning. To alleviate the above two problems, we propose APIGens, which is a retrieval-enhanced large language model (LLM)-based API recommendation approach to recommend an API sequence for a natural language query. The approach first retrieves similar programming questions in history based on the input natural language query, and then scores the results based on API documents via a scorer model. Finally, these results are used as samples for few-shot learning of LLM. To reduce the risk of encountering local optima, we also extract API seeds from the retrieved results to increase the search scope during the LLM generation process. The results show that our approach can achieve 48.41% ROUGE@10 on API sequence recommendation and the 82.61% MAP on API set recommendation, largely outperforming the state-of-the-art baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {44},
numpages = {21},
keywords = {API recommendation, deep learning, information retrieval, sequence generation, large language model}
}

@inproceedings{10.1145/3701716.3715222,
author = {Zhao, Gang and Zhang, Ximing and Lu, Chenji and Zhao, Hui and Wu, Tianshu and Wang, Pengjie and Xu, Jian and Zheng, Bo},
title = {Explainable LLM-driven Multi-dimensional Distillation for E-Commerce Relevance Learning},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715222},
doi = {10.1145/3701716.3715222},
abstract = {Effective query-item relevance modeling is pivotal for enhancing user experience and safeguarding user satisfaction in e-commerce search systems. Recently, benefiting from the vast inherent knowledge, Large Language Model (LLM) approach demonstrates strong performance and long-tail generalization ability compared with previous neural-based specialized relevance learning methods. Though promising, current LLM-based method encounters the following inadequacies in practice: Firstly, the relevance modeling process is a black box, making it difficult to clearly understand why LLM can provide the significant improvement or to analyze its relevance judgment errors. This opacity also hinders the reuse of the LLM's rich intrinsic knowledge. Secondly, the massive parameters and computational demands make it challenging to be deployed online. To improve the interpretability of LLM and boost the performance of online relevance models, we propose an Explainable LLM-driven Multi-dimensional Distillation framework for e-commerce relevance learning, which comprises two core components: (1) An Explainable LLM for relevance modeling (ELLM-rele), which decomposes the relevance learning into intermediate steps and models relevance learning as a Chain-of-Thought (CoT) reasoning, thereby enhancing both interpretability and performance of LLM. (2) A Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the knowledge of ELLM-rele to current interaction-based and representation-based student models from both the relevance score distribution and CoT reasoning aspects. Through distilling the probabilistic and CoT reasoning knowledge, MKD improves both the semantic interaction and long-tail generalization abilities of student models. Extensive offline evaluations and online experiments conducted on Taobao search ad scene demonstrate that our proposed ELLM-MD framework significantly enhances e-commerce relevance learning performance and consumer experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {631–640},
numpages = {10},
keywords = {e-commerce, knowledge distillation, large language model, semantic matching},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3689031.3696075,
author = {Sheng, Guangming and Zhang, Chi and Ye, Zilingfeng and Wu, Xibin and Zhang, Wang and Zhang, Ru and Peng, Yanghua and Lin, Haibin and Wu, Chuan},
title = {HybridFlow: A Flexible and Efficient RLHF Framework},
year = {2025},
isbn = {9798400711961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689031.3696075},
doi = {10.1145/3689031.3696075},
abstract = {Reinforcement Learning from Human Feedback (RLHF) is widely used in Large Language Model (LLM) alignment. Traditional RL can be modeled as a dataflow, where each node represents computation of a neural network (NN) and each edge denotes data dependencies between the NNs. RLHF complicates the dataflow by expanding each node into a distributed LLM training or generation program, and each edge into a many-to-many multicast. Traditional RL frameworks execute the dataflow using a single controller to instruct both intra-node computation and inter-node communication, which can be inefficient in RLHF due to large control dispatch overhead for distributed intra-node computation. Existing RLHF systems adopt a multi-controller paradigm, which can be inflexible due to nesting distributed computation and data communication. We propose HybridFlow, which combines single-controller and multi-controller paradigms in a hybrid manner to enable flexible representation and efficient execution of the RLHF data flow. We carefully design a set of hierarchical APIs that decouple and encapsulate computation and data dependencies in the complex RLHF dataflow, allowing efficient operation orchestration to implement RLHF algorithms and flexible mapping of the computation onto various devices. We further design a 3D-HybridEngine for efficient actor model resharding between training and generation phases, with zero memory redundancy and significantly reduced communication overhead. Our experimental results demonstrate 1.53x~20.57\texttimes{} throughput improvement when running various RLHF algorithms using HybridFlow, as compared with state-of-the-art baselines. HybridFlow source code is available at https://github.com/volcengine/verl},
booktitle = {Proceedings of the Twentieth European Conference on Computer Systems},
pages = {1279–1297},
numpages = {19},
keywords = {Distributed systems, Reinforcement Learning from Human Feedback},
location = {Rotterdam, Netherlands},
series = {EuroSys '25}
}

@article{10.1145/3735640,
author = {Tang, Mingxin and Chen, Wei and Wu, Lizhou and Huang, Libo and Zeng, Kun},
title = {ChatDSE: A Zero-Shot Microarchitecture Design Space Explorer Powered by GPT4.0},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1084-4309},
url = {https://doi.org/10.1145/3735640},
doi = {10.1145/3735640},
abstract = {Design Space Exploration (DSE) aims at identifying Pareto optimal synthesis configurations. Previous works require microarchitecture samples with key labels, including power and clock cycles, to train their models. However, as the chip design space expands rapidly, the cost of sampling the design space has significantly increased, due to the growing number of samples and time-consuming Very Large Scale Integration (VLSI) implementation flow. Recent advancements in Large Language Models (LLMs) have demonstrated their remarkable power in zero-shot learning tasks, presenting an innovative strategy for accomplishing DSE. Hence, this article presents ChatDSE, a zero-shot framework for DSE that is powered by the advanced capabilities of the LLM GPT4.0. Firstly, this framework analyzes the nature of the target microarchitecture and generates a corresponding system context to provide the prior knowledge of the microarchitecture. Secondly, a proposed sampling algorithm, PriorDC, identifies the most representative samples with pseudo labels. One of these samples is chosen as a baseline, whose power and clock cycles labels are set as 1, and the remaining sample labels are obtained by chatting with GPT4.0. Finally, ChatDSE engages in a dialogue with GPT4.0 to estimate the power and clock cycles of designs within the space, ultimately identifying the Pareto optimal design set. In the DSE for the RISC-V Berkeley Out-of-Order Machine (BOOM), experimental results show that ChatDSE is capable of identifying optimal designs and accelerates the exploration process by 574 times when compared to the state-of-the-art DSE methodologies.},
note = {Just Accepted},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = may,
keywords = {Design space exploration, Zero-shot, Large language model, Pareto optimization, BOOM microarchitecture}
}

@inbook{10.1145/3676536.3676816,
author = {Yin, Yuxuan and Wang, Yu and Xu, Boxun and Li, Peng},
title = {ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of Large Language Models},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676816},
abstract = {Analog circuit design requires substantial human expertise and involvement, which is a significant roadblock to design productivity. Bayesian Optimization (BO), a popular machine-learning-based optimization strategy, has been leveraged to automate analog design given its applicability across various circuit topologies and technologies. Traditional BO methods employ black-box Gaussian Process surrogate models and optimized labeled data queries to find optimization solutions by trading off between exploration and exploitation. However, the search for the optimal design solution in BO can be expensive from both a computational and data usage point of view, particularly for high-dimensional optimization problems. This paper presents ADO-LLM, the first work integrating large language models (LLMs) with Bayesian Optimization for analog design optimization. ADO-LLM leverages the LLM's ability to infuse domain knowledge to rapidly generate viable design points to remedy BO's inefficiency in finding high-value design areas specifically under the limited design space coverage of the BO's probabilistic surrogate model. In the meantime, sampling of design points evaluated in the iterative BO process provides quality demonstrations for the LLM to generate high-quality design points while leveraging infused broad design knowledge. Furthermore, the diversity brought by BO's exploration enriches the contextual understanding of the LLM and allows it to more broadly search in the design space and prevent repetitive and redundant suggestions. We evaluate the proposed framework on two different types of analog circuits and demonstrate notable improvements in design efficiency and effectiveness.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {81},
numpages = {9}
}

@inproceedings{10.1145/3716640.3716654,
author = {Gutierrez, Sebastian and Hou, Irene and Lee, Jihye and Angelikas, Kenneth and Man, Owen and Mettille, Sophia and Prather, James and Denny, Paul and MacNeil, Stephen},
title = {Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716654},
doi = {10.1145/3716640.3716654},
abstract = {Recent advancements in generative AI systems have raised concerns about academic integrity among educators. Beyond excelling at solving programming problems and text-based multiple-choice questions, recent research has also found that large multimodal models (LMMs) can solve Parsons problems based only on an image. However, such problems are still inherently text-based and rely on the capabilities of the models to convert the images of code blocks to their corresponding text. In this paper, we further investigate the capabilities of LMMs to solve graph and tree data structure problems based only on images. To achieve this, we computationally construct and evaluate a novel benchmark dataset comprising 9,072 samples of diverse graph and tree data structure tasks to assess the performance of the GPT-4o, GPT-4 with Vision (GPT-4V), Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT–4o and Gemini 1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved 87.6% accuracy on tree samples, while Gemini 1.5 Pro, achieved 76.9% accuracy on graph samples. Our findings highlight the influence of structural and visual variations on model performance. This research not only introduces an LMM benchmark to facilitate replication and further exploration but also underscores the potential of LMMs in solving complex computing problems, with important implications for pedagogy and assessment practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {Generative AI, Academic Integrity, Computing Education, Large Multimodal Models, LMMs, Large Language Models, LLMs},
location = {
},
series = {ACE '25}
}

@article{10.1145/3734217,
author = {Niu, Feifei and Li, Chuanyi and Liu, Kui and Xia, Xin and Lo, David},
title = {When Deep Learning Meets Information Retrieval-based Bug Localization: A Survey},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3734217},
doi = {10.1145/3734217},
abstract = {Bug localization is a crucial aspect of software maintenance, running through the entire software lifecycle. Information retrieval-based bug localization (IRBL) identifies buggy code based on bug reports, expediting the bug resolution process for developers. Recent years have witnessed significant achievements in IRBL, propelled by the widespread adoption of deep learning (DL). To provide a comprehensive overview of the current state of the art and delve into key issues, we conduct a survey encompassing 61 IRBL studies leveraging DL. We summarize best practices in each phase of the IRBL workflow, undertake a meta-analysis of prior studies, and suggest future research directions. This exploration aims to guide further advancements in the field, fostering a deeper understanding and refining practices for effective bug localization. Our study suggests that the integration of DL in IRBL enhances the model’s capacity to extract semantic and syntactic information from both bug reports and source code, addressing issues such as lexical gaps, neglect of code structure information, and cold-start problems. Future research avenues for IRBL encompass exploring diversity in programming languages, adopting fine-grained granularity, and focusing on real-world applications. Most importantly, although some studies have started using large language models for IRBL, there is still a need for more in-depth exploration and thorough investigation in this area.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = may,
keywords = {Information Retrieval, Bug Localization, Deep Learning, Survey}
}

@inproceedings{10.1145/3701716.3717558,
author = {Zhang, Chuxu and Ding, Kaize and Li, Jundong and Xu, Dongkuan and Wang, Haoyu and Cheng, Derek Zhiyuan and Liu, Huan},
title = {RelWeb 2025: The International Workshop on Resource-Efficient Learning for the Web},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717558},
doi = {10.1145/3701716.3717558},
abstract = {Deep learning techniques, such as large language models and graph neural networks, have demonstrated impressive effectiveness across various web applications. Despite their success, the advancement of these methods is frequently hampered by different resource constraint challenges. Key challenges include the scarcity of labeled data (data-level constraints), the need for smaller model sizes that fit real-world computing environments (model-level constraints), and the integration of neural network design with system and hardware for energy efficiency (system-level constraints). Tackling these issues is essential for the effective and efficient deployment of models in various real-world web systems and applications, including social networks, search engines, recommender systems, question answering, and content analysis. Therefore, there is an urgent need to develop innovative and efficient learning techniques that can overcome these resource limitations. The proposed international workshop on ''Resource-Efficient Learning for the Web (RelWeb 2025)'' will provide a great venue for academic researchers and industrial practitioners to share challenges, solutions, and future opportunities for resource-efficient learning. Our workshop objectives are threefold: (1) to establish an engaging platform where experts and participants can share their latest research findings and innovative practices in resource-efficient learning; (2) to explore emerging technologies and trends that could shape the future of this field; and (3) to foster a collaborative environment that encourages partnerships and exchanges among participants. Together, we can advance resource-efficient learning and propel future research in this area.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2468–2471},
numpages = {4},
keywords = {deep learning, graph neural networks, large language models, resource-efficient learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3721427,
author = {Huang, Jiahua and Lin, Weiwei and Wu, Wentai and Wang, Yang and Zhong, Haocheng and Wang, Xinhua and Li, Keqin},
title = {On Efficiency, Fairness and Security in AI Accelerator Resource Sharing: A Survey},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3721427},
doi = {10.1145/3721427},
abstract = {The effective and efficient utilization of AI accelerators represents a critical issue for the practitioners engaged in the field of deep learning. Practical evidence from companies such as Alibaba, SenseTime, and Microsoft reveals that the utilization of production GPU clusters in the industry is generally between 25% and 50%. This indicates a significant opportunity for improvement. To this end, AI accelerator resource sharing has emerged as a promising approach to the performance optimization of multi-tenant clusters. This survey covers this line of studies from 2016 to 2024, focusing primarily on system efficiency while also including discussion on fairness, interference, and security in AI accelerator sharing. We revisit the fundamentals and key concepts, followed by a comprehensive review of recent advances in the field. We find that over 70% of the studies focus on efficiency improvement. We also observe that approximately half of the reviewed studies have made their source code publicly available, while fewer than one-third of the studies did not utilize a physical machine for experimentation. Finally, based on the limitations of existing research, we outline several directions for future research concerning the integration of sharing with large language models (LLMs), coordination between schedulers and application-layer metrics, and collaboration among heterogeneous accelerators.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {221},
numpages = {35},
keywords = {AI accelerators, resource sharing, Artificial Intelligence, fairness, security}
}

@inproceedings{10.1145/3704289.3704301,
author = {Chang, Chi In and Choi, Wan Chong and Choi, Iek Chong},
title = {A Systematic Literature Review of the Opportunities and Advantages for AIGC (OpenAI ChatGPT, Copilot, Codex) in Programming Course},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704301},
doi = {10.1145/3704289.3704301},
abstract = {This systematic literature review explored the opportunities and advantages of integrating Artificial Intelligence Generated Content (AIGC) tools like OpenAI's ChatGPT, Copilot, and Codex in programming education. From an initial pool of 1,173 papers, 24 were rigorously selected for detailed analysis. The findings highlighted the dominant use of ChatGPT, particularly versions 3/3.5 and 4, underscoring its effectiveness and accessibility. Python emerged as the most frequently studied language, followed by Java, C, R, and Scala. A notable research gap was identified in block-based programming languages and online/blended learning environments. Key opportunities and advantages identified included enhanced code review, where AIGC tools offer efficient and comprehensive assessments; personalized learning, with ChatGPT providing individualized feedback and improving student comprehension; and increased student engagement and motivation through interactive features. Additionally, AIGC tools significantly improved problem-solving and debugging support, effectively identifying and correcting coding errors. They also supported diverse learning styles by offering varied examples and solutions, facilitated innovative teaching strategies that improved educational outcomes, and reduced teacher workload by automating routine tasks. These insights demonstrated the transformative potential of AIGC tools in revolutionizing programming education.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {29–35},
numpages = {7},
keywords = {Advantages of AIGC, Artificial intelligence generated content, ChatGPT, Codex, Copilot, Opportunities of AIGC, Programming Course, Systematic literature review},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3669940.3707251,
author = {Lv, Cunchi and Shi, Xiao and Lei, Zhengyu and Huang, Jinyue and Tan, Wenting and Zheng, Xiaohui and Zhao, Xiaofang},
title = {Dilu: Enabling GPU Resourcing-on-Demand for Serverless DL Serving via Introspective Elasticity},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707251},
doi = {10.1145/3669940.3707251},
abstract = {Serverless computing, with its ease of management, auto-scaling, and cost-effectiveness, is widely adopted by deep learning (DL) applications. DL workloads, especially with large language models, require substantial GPU resources to ensure QoS. However, it is prone to produce GPU fragments (e.g., 15%-94%) in serverless DL systems due to the dynamicity of workloads and coarse-grained static GPU allocation mechanisms, gradually eroding the profits offered by serverless elasticity. Different from classical serverless systems that only scale horizontally, we present introspective elasticity (IE), a fine-grained and adaptive two-dimensional co-scaling mechanism to support GPU resourcing-on-demand for serverless DL tasks. Based on this insight, we build Dilu, a cross-layer and GPU-based serverless DL system with IE support. First, Dilu provides multi-factor profiling for DL tasks with efficient pruning search methods. Second, Dilu adheres to the resourcing-complementary principles in scheduling to improve GPU utilization with QoS guarantees. Third, Dilu adopts an adaptive 2D co-scaling method to enhance the elasticity of GPU provisioning in real time. Evaluations show that it can dynamically adjust the resourcing of various DL functions with low GPU fragmentation (10%-46% GPU defragmentation), high throughput (up to 1.8\texttimes{} inference and 1.1\texttimes{} training throughput increment) and QoS guarantees (11%-71% violation rate reduction), compared to the SOTA baselines.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {311–325},
numpages = {15},
keywords = {co-scaling, gpu resourcing-on-demand, introspective elasticity, serverless deep learning},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3701716.3715281,
author = {Hu, Xingchen},
title = {Towards Whole Life-Cycle Management of Prefabricated Buildings based on Knowledge-Data Dual Driven Methods},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715281},
doi = {10.1145/3701716.3715281},
abstract = {As an efficient and environmentally friendly construction method, prefabricated buildings have garnered increasing attention compared to traditional buildings in the context of global urbanization and sustainable development. This research addresses the digital transformation challenges in prefabricated buildings by proposing a whole life cycle management framework based on knowledge-data dual-driven methods. First, country-specific, e.g., Australian, prefabricated building standards and construction cases will be collected to build a knowledge foundation model that integrates a knowledge graph with large language models. By aligning formats of building information modelling and digital twins, automated rule checking will be realized during the design phase, alongside safety, schedule, and quality management in construction. Finally, in the operation and maintenance phase, the knowledge base will support conventional deep learning methods in fault detection and diagnosis of photovoltaic systems to enhance the interpretability of the models and provide the repair or maintenance solutions for photovoltaic systems. This PhD research aims to develop a prefabricated building Web-based knowledge base and management framework, establish a standard dataset for knowledge extraction, and ultimately advance the digital transformation and sustainability of prefabricated buildings.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {693–696},
numpages = {4},
keywords = {building information modelling, knowledge graph, large language model, prefabricated buildings, whole life cycle management},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3672608.3707984,
author = {Xia, Yuan and Pingle, Aabha and Sur, Deepayan and Deshmukh, Jyotirmoy and Raghothaman, Mukund and Ravi, Srivatsan},
title = {LLM-guided Predicate Discovery and Data Augmentation for Learning Likely Program Invariants},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707984},
doi = {10.1145/3672608.3707984},
abstract = {Security protocols, protocols to achieve consensus, those for maintaining memory consistency and coherence, distributed ledgers, multi-party computation, and many similar software systems are examples of distributed message-passing based computation. Ensuring correctness of such distributed systems is a challenging problem for many automatic verification approaches. The deductive verification approach for reasoning about such systems involves computing a program invariant, i.e., an expression evaluates to true for every reachable program state. Several approaches for synthesizing invariants are dynamic, i.e., runs of the program and ancillary information such as target safety properties are used to learn an invariant expression. However, most existing approaches invoke a model checker (or a theorem prover) within the synthesis loop, which makes these approaches depend on the scalability of the verification tools. In this paper, we propose a counterexample-guided inductive synthesis approach called RunVS which learns invariant expressions from program runs, but without information such as target safety properties, and without invoking a model checker/theorem prover for validation. The synthesis approach pairs a decision-tree (DT) based method with a data augmentation technique: DT-learning provides an expression that classifies observed states from augmented states that are speculated to be unreachable. Validation of the learned invariant is performed by sampling program runs and states; any run that invalidates the invariant results in counterexamples used to revises the invariant. As there is no formal proof that the learned artifact is a true invariant, we call such an expression a likely invariant. An important user input to synthesis is often the set of predicates that comprise the invariant expression; we use a novel integration with a large language model (LLM) and prompt it to provide likely predicates to be used. We show empirical results of our approach on several distributed protocols implemented in the Promela modeling language.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1721–1729},
numpages = {9},
keywords = {invariant generation, runtime monitoring, distributed systems},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706598.3713190,
author = {Zhang, Guanhua and Ahmed, Mohamed Adel Naguib and Hu, Zhiming and Bulling, Andreas},
title = {SummAct: Uncovering User Intentions Through Interactive Behaviour Summarisation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713190},
doi = {10.1145/3706598.3713190},
abstract = {Recent work has highlighted the potential of modelling interactive behaviour analogously to natural language. We propose interactive behaviour summarisation as a novel computational task and demonstrate its usefulness for automatically uncovering latent user goals while interacting with graphical user interfaces. We introduce SummAct&nbsp;– a novel hierarchical method to summarise low-level input actions into high-level goals to tackle this task. SummAct first identifies sub-goals from user actions using a large language model and in-context learning. In a second step, high-level goals are obtained by fine-tuning the model using a novel UI element weighting mechanism to preserve detailed context information embedded within UI elements during summarisation. Through a series of evaluations, we demonstrate that SummAct significantly outperforms baseline methods across desktop and mobile user interfaces and interactive tasks by up to 21.9%. We further introduce two exciting example use cases enabled by our method: interactive behaviour forecasting and automatic behaviour synonym identification.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {265},
numpages = {17},
keywords = {Interactive behaviour, Goal recognition, Large language model, Next action prediction},
location = {
},
series = {CHI '25}
}

@article{10.1145/3736402,
author = {Meng, Chuan and Arabzadeh, Negar and Askari, Arian and Aliannejadi, Mohammad and de Rijke, Maarten},
title = {Query Performance Prediction using Relevance Judgments Generated by Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3736402},
doi = {10.1145/3736402},
abstract = {Query performance prediction (QPP) aims to estimate the retrieval quality of a search system for a query without human relevance judgments. Previous QPP methods typically return a single scalar value and do not require the predicted values to approximate a specific information retrieval (IR) evaluation measure, leading to certain drawbacks: (i) a single scalar is insufficient to accurately represent different IR evaluation measures, especially when metrics do not highly correlate, and (ii) a single scalar limits the interpretability of QPP methods because solely using a scalar is insufficient to explain QPP results. To address these issues, we propose a QPP framework using automatically generated relevance judgments (QPP-GenRE), which decomposes QPP into independent subtasks of predicting the relevance of each item in a ranked list to a given query. This allows us to predict any IR evaluation measure using the generated relevance judgments as pseudo-labels. This also allows us to interpret predicted IR evaluation measures, and identify, track and rectify errors in generated relevance judgments to improve QPP quality. We predict an item’s relevance by using open-source large language models (LLMs) to ensure scientific reproducibility.We face two main challenges: (i) excessive computational costs of judging an entire corpus for predicting a metric considering recall, and (ii) limited performance in prompting open-source LLMs in a zero-/few-shot manner. To solve the challenges, we devise an approximation strategy to predict an IR measure considering recall and propose to fine-tune open-source LLMs using human-labeled relevance judgments. Experiments on the TREC 2019–2022 deep learning tracks and CAsT-19–20 datasets show that QPP-GenRE achieves state-of-the-art QPP quality for both lexical and neural rankers.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = may,
keywords = {Query performance prediction, Large language models, Relevance judgments, Relevance prediction, Re-ranking, Conversational search}
}

@article{10.1145/3735637,
author = {Li, Meiziniu and Li, Dongze and Liu, Jianmeng and Cao, Jialun and Tian, Yongqiang and Cheung, Shing-Chi},
title = {Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735637},
doi = {10.1145/3735637},
abstract = {Differential testing offers a promising strategy to alleviate the test oracle problem by comparing the test results between alternative implementations. However, existing differential testing techniques for deep learning (DL) libraries are limited by the key challenges of finding alternative implementations (called  (counterparts) ) for a given API and subsequently generating diverse test inputs. To address the two challenges, this paper introduces DLLens, an LLM-enhanced differential testing technique for DL libraries. The first challenge is addressed by an observation that DL libraries are commonly designed to support the computation of a similar set of DL algorithms. Therefore, the counterpart of a given API’s computation could be successfully synthesized through certain composition and adaptation of the APIs from another DL library. DLLens incorporates a novel counterpart synthesis workflow, leveraging a large language model (LLM) to search for valid counterparts for differential testing. To address the second challenge, DLLens incorporates a static analysis technique that extracts the path constraints from the implementations of a given API and its counterpart to guide diverse test input generation. The extraction is facilitated by LLM’s knowledge of the concerned DL library and its upstream libraries. DLLens incorporates validation mechanisms to manage the LLM’s hallucinations in counterpart synthesis and path constraint extraction.We evaluate DLLens on two popular DL libraries, TensorFlow and PyTorch. Our evaluation shows that DLLens synthesizes counterparts for 1.84 times as many APIs as those found by state-of-the-art techniques on these libraries. Moreover, under the same time budget, DLLens covers 7.23% more branches and detects 1.88 times as many bugs as state-of-the-art techniques on 200 randomly sampled APIs. DLLens has successfully detected 71 bugs in recent TensorFlow and PyTorch libraries. Among them, 59 are confirmed by developers, including 46 confirmed as previously unknown bugs, and 10 of these previously unknown bugs have been fixed in the latest version of TensorFlow and PyTorch.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Large Language Model, Differential Testing, Static Analysis, Deep Learning Library Testing}
}

@article{10.1145/3709375,
author = {Mellia, Marco and Steenkiste, Peter and Qazi, Ihsan Ayyub and Tyson, Gareth},
title = {PACMNET V3, N1, March 2025 Editorial},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CoNEXT1},
url = {https://doi.org/10.1145/3709375},
doi = {10.1145/3709375},
abstract = {The Proceedings of the ACM on Networking (PACMNET) series showcases top-tier research in emerging computer networks and their applications. We welcome submissions introducing new technologies, innovative experiments, creative applications of networking technologies, and fresh insights gained through analysis. Supported by the ACM Special Interest Group on Communications and Computer Networks (SIGCOMM), the journal is backed by a distinguished Editorial Board composed of leading researchers in the field. This issue begins the third volume of PACMNET. It features 6 articles, all submitted by the June 2024 deadline when 121 submissions in total were received. Each submission underwent a thorough review process involving over 80 Editors, coordinated by two Associate Editors. In the initial phase, every article received a minimum of three reviews. Following an online discussion, roughly half of the submissions were rejected, while the other half advanced to a second review phase. In this phase, Editors produced at least two additional reviews per article. After further discussion and remote Editors' meeting, 8 articles were given one-shot major revision. The same Editors reviewed the revised version the Authors prepared, and 6 out of 8 articles were finally selected. These 6 articles appear in this issue. Topics include network support for large language models and deep learning, security, and wireless networking. All papers include a thorough set of experiments to validate the proposed solutions. From a methodological perspective, machine learning and artificial intelligence-based solutions are becoming central in developing novel networking solutions.  We want to express our gratitude to all those who contributed to this issue of PACMNET, especially the Authors for submitting their finest work and the Associate Editors for offering valuable feedback in their reviews and engaging in the discussions. Our thanks also go to the SIGCOMM Executive Committee Chair and the CoNEXT Steering Committee members for their continued support and guidance, providing essential suggestions and insights throughout the article selection process.},
journal = {Proc. ACM Netw.},
month = mar,
articleno = {1},
numpages = {1},
keywords = {editorial, networks}
}

@article{10.5555/3729849.3729853,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui and Dodds, Zachary},
title = {Adaptable Metrics to Inform Introductory CS},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {9},
issn = {1937-4771},
abstract = {Metrics have long been used to assess and guide successful software projects. Traditionally these metrics have measured software's professional rather than its educational suitability. This work proposes six adaptable, reproducible pedagogical metrics. With these metrics, we track an Introductory CS course's capstone projects, 2018--2024. The results suggest both year-over-year evolution and a more sudden, LLM-correlated impact on students' relationship with their early computing work. We have begun adapting our curriculum to these signals, and we foresee future refinements and broader applications to metrics-based reproducible curricular assessment.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {34–42},
numpages = {9}
}

@inproceedings{10.1145/3690624.3709421,
author = {Jiang, Yanru and Liang, Siyu and Choi, Junwon},
title = {Synthetic Survey Data Generation and Evaluation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709421},
doi = {10.1145/3690624.3709421},
abstract = {Survey data are common and invaluable in social science research for understanding population processes and supporting policymaking and planning. Depending on the nature and scale, survey data sharing comes with privacy risks, and data collectors and agencies are constrained by disclosure permissions, limiting usage across research groups and institutes. Previous methods for synthetic data generation and deidentification may not entirely prevent information disclosures, or they may sacrifice data quality and granularity.Using a large-scale national voter file at both national and state levels, this paper introduces an end-to-end pipeline to streamline synthetic data generation and evaluation for survey researchers. This study selects four generative approaches based on different statistical assumptions: the regression-based Synthpop, the generative deep learning-based CTGAN and TVAE, and the large language model-based REaLDTabFormer, and compares them to the baseline synthetic minority oversampling technique (SMOTE). We consider three key dimensions of evaluation (utility, fidelity, and privacy) to highlight the strengths and weaknesses of each approach, and systematically evaluate across various datasets and training sizes. The results reveal that Synthpop is optimized for general utility (i.e., fidelity), while TVAE excels in downstream applications (i.e., target-specific utility) but compromises on general utility and potentially risks data overfitting. REaLDTabFormer demonstrates a balanced performance in both general and target-specific utility, whereas CTGAN offers the best privacy protection. We recommend that future researchers select a generative method by considering the trade-offs between performance across various evaluation dimensions, training size, data type, and computational infrastructure.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2292–2302},
numpages = {11},
keywords = {generative data science, generative modeling, machine learning, survey data, synthetic data},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@article{10.1145/3717061,
author = {Yang, Zezhou and Chen, Sirong and Gao, Cuiyun and Li, Zhenhao and Hu, Xing and Liu, Kui and Xia, Xin},
title = {An Empirical Study of Retrieval-Augmented Code Generation: Challenges and Opportunities},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3717061},
doi = {10.1145/3717061},
abstract = {Code generation aims to automatically generate code snippets of specific programming language according to natural language descriptions. The continuous advancements in deep learning, particularly pre-trained models, have empowered the code generation task to achieve remarkable performance. One main challenge of pre-trained models for code generation is the semantic gap between developers’ natural language requirements and source code. To address the issue, prior studies typically adopt a retrieval-augmented framework for the task, where the similar code snippets collected by a retrieval process can be leveraged to help understand the requirements and provide guidance for the generation process. In a retrieval-augmented framework, similar data can be retrieved from the database using a retrieval algorithm, and original input data can be fused with retrieved data by different fusion strategies. However, there is a lack of systematic study on the application of this framework for code generation, including the impact of the final generated results and the specific usage of the framework. In this paper, we choose three popular pre-trained code models, namely CodeGen, UniXcoder, and CodeT5, to assess the impact of the quality and utilization of retrieved code on the retrieval-augmented framework. Our analysis shows that the retrieval-augmented framework is beneficial for improving the performance of the existing pre-trained models. We also provide suggestions on the utilization of the retrieval-augmented code generation framework: BM25 and Sequential Integration Fusion are recommended due to their convenience and superior performance. Sketch Filling Fusion, which extracts a sketch of relevant code, could help the model improve its performance further. Additionally, we conduct experiments to investigate the influence of the retrieval-augmented framework on large language models for code generation, showing the effectiveness of the framework, and we discuss the trade-off between performance improvement and computational costs in each phase within the framework.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {code generation, retrieval-augmented methods, empirical study}
}

@inproceedings{10.1145/3641555.3705037,
author = {Piech, Chris and Sahami, Mehran and Alonso, Yasmine and Liu, Katie and Arifov, Javokhir and Sreenivas, Anjali and Webber, Dan and Zheng, Tina and Nguyen, Ngoc and Mlauzi, Iddah and Woodrow, Juliette},
title = {Infinite Story},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705037},
doi = {10.1145/3641555.3705037},
abstract = {In Infinite Story, students build a choose-your-own-adventure game that integrates generative AI to create a dynamic, interactive "infinite story" experience. The game is powered by nested dictionary (JSON) objects that store pre-existing scenes. Each scene is a nested dictionary, containing user choices, descriptions, and more. Students are challenged to navigate and manipulate these deeply nested data structures, which helps them appreciate the utility and complexity of dictionary objects. When a user ventures into an undefined scene, the program makes an API call to ChatGPT to generate the next scene, allowing the adventure to continue seamlessly. To the best of our knowledge it is one of the first assignments in intro CS that uses ChatGPT. What makes this assignment truly nifty is how it teaches students to leverage generative AI in a creative, meaningful way. By blending generative storytelling with technical skills, students get to see the power of AI in extending their projects beyond predefined boundaries, creating an open-ended, exciting experience. Many students expanded on this assignment for their final projects, creating sophisticated programs like AI-driven Chess and Go games. Using the techniques from this assignment, they leveraged the course's OpenAI integration to build functional AI agents that enhanced gameplay. These projects showcased the flexibility of the assignment, inspiring students to think critically about the creative and practical applications of AI in real-world contexts.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1750},
numpages = {1},
keywords = {API, CS1, JSON, dictionaries, generative AI, nested structures, python, storytelling},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705031,
author = {Diaz, Nicolas and Roy, Saunak and Beltran, Jonathan},
title = {Exploring Undergraduate AI Perceptions: Knowledge, Enthusiasm, and Concerns},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705031},
doi = {10.1145/3641555.3705031},
abstract = {As Artificial Intelligence (AI) develops and grows its presence in society, college students are increasingly interacting with AI and utilizing tools like ChatGPT as part of their education. Particularly in STEM fields, educators themselves are incorporating AI by encouraging its use as an assistive tool for coursework or designing courses that teach about its inner workings. Understanding students' perceptions and knowledge of AI can help educators know whether students will embrace learning in AI-heavy environments, as well as which student concerns they should acknowledge. Our study uses both quantitative and qualitative data from undergraduate CMNS (College of Computer, Mathematical, and Natural Sciences) students at the University of Maryland, College Park to explore students' perceived knowledge, enthusiasm, and concerns over AI. Our data was collected via a survey administered via email to undergraduates and subsequent focus group interviews with these students about their relationship with AI. Survey findings indicated that students were confident in their knowledge of AI and related competencies, as well as enthusiastic about learning and using AI. Students also highly believed in the need for standards and testing for AI systems to curtail risks. There was a positive correlation between perceived knowledge and enthusiasm of AI, but no correlation between knowledge and concerns. In interviews, students' main uses of AI were summarizing information, creating practice problems, and writing assistance. Popular concerns included academic dishonesty, overreliance on AI tools, and fabricated information in outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1753},
numpages = {1},
keywords = {artificial intelligence, generative AI, higher education, learning environments, student perceptions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3689187.3709614,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709614},
doi = {10.1145/3689187.3709614},
abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {300–338},
numpages = {39},
keywords = {artificial intelligence, computing education, genai, generative ai, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641554.3701853,
author = {Filcik, Daniel and Sobiesk, Edward and Matthews, Suzanne J.},
title = {Fostering Creativity: Student-Generative AI Teaming in an Open-Ended CS0 Assignment},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701853},
doi = {10.1145/3641554.3701853},
abstract = {The increasing ubiquity of web-based generative artificial intelligence technologies necessitates that all students experience teaming with such technologies -- exploring their strengths and limitations and learning how to create synergy with them. To aid in this effort, we designed an open-ended generative AI project for the freshmen taking our general-education introduction to computing course. Students were required to team with generative AI to create something beyond what they alone (or the AI alone) could accomplish. Upon completion, students submitted a short written critical analysis documenting their experiences and presented a three-minute demonstration of their project in class. Despite limited course coverage of AI and generative AI prior to this project, we were impressed by the creativity and sophistication of the submitted final products as well as the breadth of generative AI tools explored. Student reflections on the experience illustrated numerous insights into the strengths and limitations of the tools they employed. Our results underscore that students can learn about the benefits and limitations of generative AI in as little as a single assignment and that covering such topics need not require extensive amounts of course time and resources.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {339–345},
numpages = {7},
keywords = {computing education, cs0, final project, freshmen, generative artificial intelligence, human-ai teaming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701942,
author = {Liu, Zifeng and Jiao, Xinyue and Xing, Wanli and Zhu, Wangda},
title = {Detecting AI-Generated Pseudocode in High School Online Programming Courses Using an Explainable Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701942},
doi = {10.1145/3641554.3701942},
abstract = {Despite extensive research on code plagiarism detection in higher education and for programming languages like Java and Python, limited work has focused on K-12 settings, particularly for pseudocode. This study aims to address this gap by building explainable machine learning models for pseudocode plagiarism detection in online programming education. To achieve this, we construct a comprehensive dataset comprising 7,838 pseudocode submissions from 2,578 high school students enrolled in an online programming foundations course, along with 6,300 pseudocode samples generated by three versions of generative pre-trained transformer (GPT) models. Utilizing this dataset, we develop an explainable model to detect AI-generated pseudocode across various assessments. The model not only identifies AI-generated content but also provides insights into its predictions at both the student and problem levels, thus enhancing our understanding of AI-generated pseudocode in K-12 education. Furthermore, we analyzed SHAP values and key features of the model to pinpoint student submissions that closely resemble AI-generated pseudocode. This research offers implications for developing robust educational technologies and methodologies to uphold academic integrity in online programming courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {701–707},
numpages = {7},
keywords = {ai-generated content, explainable ai, gpt model, online programming education, plagiarism detection, pseudocode},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701806,
author = {Kannam, Suhas and Yang, Yuri and Dharm, Aarya and Lin, Kevin},
title = {Code Interviews: Design and Evaluation of a More Authentic Assessment for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701806},
doi = {10.1145/3641554.3701806},
abstract = {Generative artificial intelligence poses new challenges around assessment, increasingly driving introductory programming educators to employ invigilated exams. But exams do not afford more authentic programming experiences that involve planning, implementing, and debugging programs with computer interaction. In this experience report, we describe code interviews: a more authentic assessment method for take-home programming assignments. Through action research, we experimented with the number and type of questions as well as whether interviews were conducted individually or with groups of students. To scale the program, we converted most of our weekly teaching assistant (TA) sections to conduct code interviews on 5 major weekly take-home programming assignments. By triangulating data from 5 sources, we identified 4 themes. Code interviews (1) pushed students to discuss their work, motivating more nuanced but sometimes repetitive insights; (2) enabled peer learning, reducing stress in some ways but increasing stress in other ways; (3) scaled with TA-led sections, replacing familiar practice with an unfamiliar assessment; (4) focused on student contributions, limiting opportunities for TAs to give guidance and feedback. We reflect on the design of code interviews for student experience, academic integrity, and teacher workload.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {554–560},
numpages = {7},
keywords = {authentic assessment, introductory programming, oral exams},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3716167,
author = {Le-Cong, Thanh and Nguyen, Thanh-Dat and Le, Bach and Murray, Toby},
title = {Towards Reliable Evaluation of Neural Program Repair with Natural Robustness Testing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3716167},
doi = {10.1145/3716167},
abstract = {Automated program repair (APR) has recently gained ground, with numerous research efforts being conducted in the area that have been adopted in the industry. One notable class of APR is neural program repair (NPR), which typically employs deep learning techniques that are trained on vast amounts of historical data to fix bugs that have not been seen in the past. To study the true effectiveness of NPR on existing limited datasets, recent work augments the evaluation data by employing semantics-preserving transformations to convert original buggy programs to semantically equivalent ones. Experiments show that NPR techniques are not robust; e.g., NPR cannot repair semantically equivalent counterparts of 20%-35% of bugs that they can repair in the original dataset. However, we found that many of these transformations are unnatural, that are unlikely to occur in real-world scenarios, leading to misleading conclusions about NPR effectiveness and misguide the improvement on unrobust behaviors, which have minimal real-world impact.In this paper, we propose shifting the focus of robustness evaluation for NPR techniques towards naturally occurring data transformations. To accomplish this, we first examine the naturalness of semantic-preserving transformations through a two-stage human study. This study includes: (i) interviews with senior software developers to establish concrete criteria for evaluating the naturalness of these transformations, and (ii) a survey involving 10 developers to assess the naturalness of 1,178 transformations, i.e., pairs of original and transformed programs, applied to 225 real-world bugs. Our findings show that only 60% of these transformations are considered natural, while 20% are considered unnatural, with strong agreement among the annotators. Moreover, the unnaturalness of these transformations significantly impacts both their applicability to benchmarks and the conclusions drawn from robustness testing.Next, we conduct natural robustness tests on NPR techniques to assess their true effectiveness against real-world data variations. Our experimental results reveal a substantial number of prediction changes in NPR techniques, leading to significant reductions in both plausible and correct patch rates when comparing performance on the original and transformed datasets. Furthermore, we observe notable differences in performance improvements between NPR techniques, suggesting potential biases in the evaluation of NPR introduced by limited datasets. Finally, we explore automating the assessment of transformation naturalness by developing a new naturalness metric, namely RNC, using Large Language Models. This metric effectively evaluates naturalness with an AUC of 0.7, offering a promising direction for automating the naturalness assessment of code transformations.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Automated Program Repair, Natural Robustness, Code Naturalness, Code Transformations}
}

@inproceedings{10.1145/3702386.3702392,
author = {Maurat, John Ivan Curbano and Isip, Elsie Villareal and Lumabas, Aileen Gail Regala},
title = {A Comparative Study of Gender Differences in the Utilization and Effectiveness of AI-Assisted Learning Tools in Programming Among University Students},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702392},
doi = {10.1145/3702386.3702392},
abstract = {This comparative study examines gender differences in the use and efficacy of AI-assisted learning tools for programming among university students. A survey-based methodology was used to collect data from a varied sample of students across different academic years, ensuring representation from diverse demographic groups. The study sought to investigate the frequency of AI tool use and students' assessments of their efficacy in learning programming fundamentals. Notably, the findings reveal that students overwhelmingly prefer ChatGPT as the primary AI tool for learning programming concepts, with 312 mentions, making it the most popular and presumably the most useful tool among respondents. Following ChatGPT, Blackbox AI was the second most mentioned, with 74 students highlighting its utility. Gemini, Co-pilot, Assistguru, and Amazon Code Whisperer followed in popularity, with varying levels of student engagement and perceived usefulness. The study also found a substantial positive association (r = 0.296, p &lt; 0.05) between AI tool usage frequency and perceived effectiveness in programming education, indicating the potential benefits of increased interaction with AI tools. Gender disparities in tool preferences were identified, with male students showing a preference for specific instruments over their female counterparts. Despite these differences, there was little variation in the overall perceived efficacy of AI technology between genders. Furthermore, first-year students exhibited the highest frequency of AI tool usage, particularly on a weekly basis, emphasizing the importance of early exposure on usage patterns throughout students' academic careers. These findings underscore the necessity of considering gender preferences and demographics when developing and implementing AI-powered educational systems. The study recommends individualized approaches to enhance inclusivity and effectiveness in programming education, aiming to inform future advancements in educational technology and pedagogy.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {30–34},
numpages = {5},
keywords = {Educational Technology, Gender Differences, Learning Outcomes, Programming, User Preferences},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3723178.3723268,
author = {Sadat Shanto, Shakib and Ahmed, Zishan and Jony, Akinul Islam},
title = {Generative AI for Programming Education: Can ChatGPT Facilitate the Acquisition of Fundamental Programming Skills for Novices?},
year = {2025},
isbn = {9798400713828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723178.3723268},
doi = {10.1145/3723178.3723268},
abstract = {Modern Generative AI (GAI) systems like ChatGPT have sparked much interest in their potential to revolutionize programming education, especially for beginners. However, the existing empirical data regarding the effectiveness of technologies like ChatGPT as autonomous programming tutors is presently limited. The present study investigates the capacity of ChatGPT to facilitate the acquisition of fundamental programming skills for novice programmers without human assistance. This study puts forth a conceptual framework (APEC - Adaptive Programming Education via ChatGPT) that integrates both bottom-up and top-down approaches, incorporating ChatGPT as the principal instructor for the study of programming. An empirical study was undertaken to assess the usefulness of ChatGPT as a tool for teaching novice programmers a new programming language. This empirical study was conducted on 20 undergraduate students. To provide an expert assessment of the quality of the responses, a survey was conducted with three programming experts proficient in Python. The survey findings indicate that ChatGPT is proficient in explaining core principles such as variables, data types, and control statements through conversational exchanges, adopting an intelligent and logical methodology. Nevertheless, certain constraints arise when dealing with increasingly complex topics.},
booktitle = {Proceedings of the 3rd International Conference on Computing Advancements},
pages = {685–692},
numpages = {8},
keywords = {Generative AI, ChatGPT, Programming Education, Educational Technology, Higher Education},
location = {
},
series = {ICCA '24}
}

@inproceedings{10.1145/3706598.3713748,
author = {Ma, Shuai and Wang, Junling and Zhang, Yuanhao and Ma, Xiaojuan and Wang, April Yi},
title = {DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713748},
doi = {10.1145/3706598.3713748},
abstract = {Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners’ decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners’ personalized construction of a step tree through a “learner-LLM co-decomposition” approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox’s impact on cognitive load, identified usage patterns, and analyzed learners’ strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {20},
keywords = {Programming Learning, Self-Paced Learning, Large Language Models, AI for Coding, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1109/DAC56929.2023.10247803,
author = {Jha, Susmit},
title = {Lightning Talk: Trinity - Assured Neuro-Symbolic Model Inspired by Hierarchical Predictive Coding},
year = {2025},
isbn = {9798350323481},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DAC56929.2023.10247803},
doi = {10.1109/DAC56929.2023.10247803},
abstract = {This paper describes the core concepts and challenges in developing Trinity - a high-assurance neuro-symbolic approach to trustworthy and resilient machine learning for applications in open-world, contested, and rapidly-evolving environments. The two central concepts in Trinity are a neuro-symbolic factored world model that identifies entities, activities, and complex events, and the notion of surprise against this world model that is used for self-adaptation and learning, as well as runtime assurance. The world model is not derived purely as a bottom-up inference from sensors treating each observation as independent uncorrelated input; instead, we iteratively interleave bottom-up inference (conditioned on context) with top-down predictions and context identification using a three-layered hierarchical predictive processing (HPP) stack. Thus, the neuro-symbolic inference in Trinity is bidirectional - learning-based bottom-up pull that is uncertainty-driven and reasoning-based symbolic top-down push that is decision-driven. The progressively symbolic higher layers capture a larger context than the bottom layers finally culminating in the highest layer implemented using large language models. Any surprise arising from the mismatch between the top-down prediction and the bottom-up inference is used for the continual adaptation of Trinity. The inference in Trinity produces a factored temporal world model as the result of perception. The predictions are accompanied by a quantitative measure of surprise from the 3-layered HPP stack. This surprise corresponds to the confidence of the model in its current inference. The continuous monitoring and adaptation accompanied by risk analysis make Trinity robust to semantic adversarial perturbations and more efficiently generalizable to novelties. The hierarchical nature of Trinity also enables adaptation of the architecture to the available compute resources.},
booktitle = {Proceedings of the 60th Annual ACM/IEEE Design Automation Conference},
pages = {1–2},
numpages = {2},
keywords = {assurance, machine learning, robust learning, predictive processing},
location = {San Francisco, California, United States},
series = {DAC '23}
}

@inproceedings{10.1145/3727993.3727999,
author = {Wei, Xueling and Lin, Tao},
title = {Artificial Intelligence Generated Content Neural Network Model for Enterprise Management Decision-Making System},
year = {2025},
isbn = {9798400711831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727993.3727999},
doi = {10.1145/3727993.3727999},
abstract = {Research was conducted on Artificial Intelligence Generated Content neural network model solutions for the technical issues of enterprise decision-making systems. The enterprise decision-making system utilizes Artificial Intelligence Generated Content, neural network technology, and algorithms to establish modules for neural network data preprocessing, anomaly detection, predictive analysis, decision support, adaptive machine learning, and visual decision-making models, integrating the generative and controllable aspects of artificial intelligence into the decision-making system. In simulation experiments, this system improved output accuracy by 21.6% compared to general information systems and provided 89.7 times more effective reference data, indicating that the proposed technical solution is feasible.},
booktitle = {Proceedings of the 2024 4th International Conference on Computational Modeling, Simulation and Data Analysis},
pages = {27–32},
numpages = {6},
keywords = {Artificial Intelligence Generated Content, Business management decision-making, neural network model},
location = {
},
series = {CMSDA '24}
}

@inproceedings{10.1145/3672608.3707909,
author = {Zambach, Sine},
title = {AI-Enhanced Learning: Comparing Outcomes in Introductory and Advanced Programming Courses},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707909},
doi = {10.1145/3672608.3707909},
abstract = {Generative AI chatbots have recently transformed education, necessitating new teaching methods for this paradigm. This study compares the impact of generative AI on introductory and advanced programming courses in fall 2023. Advanced students showed better outcomes, while the performance of introductory students remained unchanged or declined. This highlights the need for tailored AI integration strategies based on students' skill levels.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {104–105},
numpages = {2},
keywords = {teaching, higher education, chatbots, generative AI},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3641555.3705051,
author = {Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh},
title = {TA Buddy: AI-Assisted Grading Tool for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705051},
doi = {10.1145/3641555.3705051},
abstract = {In introductory programming courses, autograders typically evaluate student programs by running testcases without inspecting the source code. However, educational grading often requires manual code inspection for two key reasons: (1) to award partial marks for code that may fail test cases but is partially correct, and (2) to assign marks based on code quality or specific criteria set by the instructor, such as requiring a particular algorithm, e.g., bubble sort. Rubric-based subjective grading is beneficial for these reasons, but manual grading for large course enrollments is time consuming. This demo introduces TA Buddy, an AI assistant integrated with IIT Bombay's BodhiTree Evalpro platform, which is designed to streamline grading in introductory programming courses. It is powered by a pre-trained code LLM, which was fine-tuned with a dataset created here at IITB Bombay. Its key benefits include speeding up the grading process with AI-generated suggestions for ratings of the criteria of a grading rubric. Furthermore, it provides feedback with justifications for assigned grades, making it useful for large courses where manual grading is time-consuming. Note that TA-Buddy only suggests grades to TAs, TAs are still required to review the grades and accept or reject them. In that sense, TA-Buddy offers an AI-Assisted grading option to TAs. This hybrid approach reduces grading time by up to 45% while maintaining an average match of 90% (on a sample of six problems) with un-assisted manual grades.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1736},
numpages = {1},
keywords = {ai-assisted grading, cs education, llms, programming assignments, rubric, source code evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3704769,
author = {Sussman, Alan and Prasad, Sushil and Bunde, David P. and Spacco, Jaime and Gannod, Gerald and Crockett, April Renee and Vaidyanathan, Ramachandran},
title = {Modernizing the CS Introductory Sequence with Parallel and Distributed Computing (and some AI)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704769},
doi = {10.1145/3641555.3704769},
abstract = {Parallel and distributed computing (PDC) has become pervasive in all aspects of computing, so it is essential that students include parallelism and distribution in the computational thinking that they apply to problem solving, from the beginning of their computing education. With all computing devices that students use having multiple cores as well as a GPU in many cases, many students' favorite applications use multiple cores and/or distributed processors. However, we are still teaching them to solve problems using only sequential thinking. Why?This hands-on tutorial will demonstrate how easy it is to open students' eyes to exploiting concurrency in problem solving. You will participate in plugged and unplugged activities that will help students to recognize examples of PDC concepts and concurrency in the world around them. We introduce plugged and unplugged curriculum modules that have been successfully integrated in existing computing classes at multiple institutions. We will also discuss recent efforts at integrating AI methods, including LLMs, into introductory classes.A laptop capable of running a C/C++ compiler, a Java virtual environment, and a Python interpreter is needed to fully participate in activities. However, attendees may learn the core concepts without a laptop. The activities and curriculum modules have been used successfully to teach PDC concepts in early computing courses and will be available after the workshop. Participants will receive a stipend of 400 to defray their cost of registration and one-night hotel stay. The CDER center will also have a booth in the exhibition hall for additional support.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1775},
numpages = {1},
keywords = {acm/ieee-cs/aaai computer science curricula, ai, computing education, cs1/ cs2, early computing class, hpc education, undergraduate instruction, pdc education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3702163.3702448,
author = {Domingues, Ines and Rasteiro, Deolinda Maria Lopes Dias},
title = {A Paradigm Shift in Teaching Machine Learning to Sustainable City Management Master Students},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702448},
doi = {10.1145/3702163.3702448},
abstract = {Teaching machine learning (ML) to students with diverse backgrounds, such as those in the Master in Sustainable City Management program, presents unique challenges. Traditional programming-based approaches can be daunting for students unfamiliar with coding. Initially, software tools like RapidMiner, Weka, and Orange Data Mining were employed to simplify the learning process. However, this method often fell short in conveying deep ML concepts, which often resulted in a superficial understanding. With the advent of user-friendly coding aids like ChatGPT, a transition to Python-based instruction was implemented. Additionally, the incorporation of active learning strategies has further enhanced student engagement and understanding. This shift has shown to improve comprehension and practical skills, evidenced by higher median and maximum grades on the evaluation tool, a final project. A multiple linear regression analysis suggested that performance in “Big Data” significantly predicts grades on the Artificial Intelligence module, and the teaching approach has a marginally significant impact. Subjective analysis by the professor, also proved a better grasp of the concepts by the students.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {413–417},
numpages = {5},
keywords = {Machine Learning Education, Python Programming, Sustainable City Management, Active Learning, Code Assistance Tools},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3641555.3705166,
author = {Demirta\c{s}, Mehmet Arif and Zheng, Claire and Cunningham, Kathryn},
title = {Detecting Programming Plans in Open-ended Code Submissions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705166},
doi = {10.1145/3641555.3705166},
abstract = {Open-ended code-writing exercises are commonly used in large-scale introductory programming courses, as they can be autograded against test cases. However, code writing requires many skills at once, from planning out a solution to applying the intricacies of syntax. As autograding only evaluates code correctness, feedback addressing each of these skills separately cannot be provided. In this work, we explore methods to detect which high-level patterns (i.e. programming plans) have been used in a submission, so learners can receive feedback on planning skills even when their code is not completely correct. Our preliminary results show that LLMs with few-shot prompting can detect the use of programming plans in 95% of correct and 86% of partially correct submissions. Incorporating LLMs into grading of open-ended programming exercises can enable more fine-grained feedback to students, even in cases where their code does not compile due to other errors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1435–1436},
numpages = {2},
keywords = {autograding, large language models, programming plans},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713677,
author = {Jiang, Chutian and Fan, Yinan and Xie, Junan and Kuang, Emily and Feng, Baichuan and Zhang, Kaihao and Fan, Mingming},
title = {Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713677},
doi = {10.1145/3706598.3713677},
abstract = {Although remote learning is widely used for delivering and capturing knowledge, it has limitations in teaching hands-on skills that require nuanced instructions and demonstrations of precise actions, such as massage. Furthermore, scheduling conflicts between instructors and learners often limit the availability of real-time feedback, reducing learning efficiency. To address these challenges, we developed a synthesis tool utilizing an LLM-powered Virtual Teaching Assistant (VTA). This tool integrates multimodal instructions that convey precise data, such as stroke patterns and pressure control, while providing real-time feedback for learners and summarizing their performance for instructors. Our case study with instructors and learners demonstrated the effectiveness of these multimodal instructions and the VTA in enhancing massage teaching and learning. We then discuss the tools’ use in other hands-on skills instruction and cognitive process differences in various courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {17},
keywords = {Remote Massage Learning; Multimodal Teaching and Learning; Hands-on Training.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708394.3708455,
author = {Lv, Jiayan and Yao, Jinfang and Zhu, He},
title = {Research on the Cultivation of Teacher Candidates from the Perspective of AI Empowerment with Sentiment analysis},
year = {2025},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708394.3708455},
doi = {10.1145/3708394.3708455},
abstract = {Over the past decade, with the advancement of technology, chatbots have become a hotspot in the field of artificial intelligence (AI) and are widely used in consumer services, education, search engines, marketing, and other fields. Among them, the Chat Generative Pre-Trained Transformer (ChatGPT), composed of language models and optimization techniques, is leading a transformation in human-computer interaction methods. This study selects the social media platforms "REDnote" and "Weibo" as the research field to explore the role and impact of ChatGPT in education and industry ecosystems. This work examines public sentiment regarding the application of AI in educational ecosystems and talent development by analyzing social media discussions. The sentiment analysis conducted using advanced machine learning models, highlights the prevalence of positive emotions toward ChatGPT's role in enhancing teaching and learning experiences. Furthermore, this study introduces an AI-based dynamic talent cultivation model, rooted in the "3H" (Head, Hand, Heart) framework, which emphasizes cognitive skills, practical capabilities, and emotional intelligence.},
booktitle = {Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
pages = {358–364},
numpages = {7},
keywords = {Artificial Intelligence, ChatGPT, Deep Learning, Machine Learning, Normal Education, Social Media, Talent Cultivation, User Experience},
location = {
},
series = {AIFE '24}
}

@inproceedings{10.1145/3641555.3705227,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement Over Just Showing LLM-Powered Solutions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705227},
doi = {10.1145/3641555.3705227},
abstract = {As generative AI products could generate code and assist students with programming learning seamlessly, integrating AI into programming education contexts has driven much attention. However, one emerging concern is that students might get answers without learning from the LLM-generated content. In this work, we deployed the LLM-powered personalized Parsons puzzles as scaffolding to write-code practice in a Python learning classroom (PC condition) and conducted an 80-minute randomized between-subjects study. Both conditions received the same practice problems. The only difference was that when requesting help, the control condition showed students a complete solution (CC condition), simulating the most traditional LLM output. Results indicated that students who received personalized Parsons puzzles as scaffolding engaged in practicing significantly longer than those who received complete solutions when struggling.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1483–1484},
numpages = {2},
keywords = {GPT, LLM, active learning, generative AI, parsons problems},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3704762,
author = {Birillo, Anastasiia and Keuning, Hieke and Migut, Gosia and Dzialets, Katsiaryna and Golubev, Yaroslav},
title = {Creating in-IDE Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704762},
doi = {10.1145/3641555.3704762},
abstract = {The in-IDE learning format represents a novel way of teaching programming to students entirely within an industry-grade IDE, allowing them to learn both the language and the necessary tooling at the same time. In this tutorial, we will teach the audience everything they need to know to create in-IDE courses and analyze how the students are working in them. In the first part of the tutorial, the audience will get to know the JetBrains Academy plugin that allows creating courses for IntelliJ-based IDEs such as IntelliJ IDEA and PyCharm. The participants will develop their own simple courses with theory, programming tasks, and quizzes, as well as employ some LLM-based features like automatic test generation. In the second part, we will learn how to use another plugin to collect code snapshots and the usage of IDE features of students when they are solving the tasks. Finally, the participants will solve tasks in their own course while using the data gathering plugin, and we will show them how to process and analyze the collected data. As the outcome of the tutorial, the audience will know how to create in-IDE courses, track the students' performance and analyze it, and will already have their own simple course and a dataset that can be expanded or used for further research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {In-IDE learning, JetBrains academy, LLMs, MOOCs, activity tracking, course creation, generative AI, programming education, programming exercises},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3685680,
author = {Annapureddy, Ravinithesh and Fornaroli, Alessandro and Gatica-Perez, Daniel},
title = {Generative AI Literacy: Twelve Defining Competencies},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3685680},
doi = {10.1145/3685680},
abstract = {This article introduces a competency-based model for generative artificial intelligence (AI) literacy covering essential skills and knowledge areas necessary to interact with generative AI. The competencies range from foundational AI literacy to prompt engineering and programming skills, including ethical and legal considerations. These 12 competencies offer a framework for individuals, policymakers, government officials, and educators looking to navigate and take advantage of the potential of generative AI responsibly. Embedding these competencies into educational programs and professional training initiatives can equip individuals to become responsible and informed users and creators of generative AI. The competencies follow a logical progression and serve as a roadmap for individuals seeking to become familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {13},
numpages = {21},
keywords = {Generative AI literacy, AI literacy, data literacy, generative AI, prompt engineering, AI competencies, AI skills}
}

@inproceedings{10.1145/3641555.3705266,
author = {Hou, Irene and Nguyen, Hannah Vy and Man, Owen and MacNeil, Stephen},
title = {The Evolving Usage of GenAI by Computing Students},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705266},
doi = {10.1145/3641555.3705266},
abstract = {Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities ( n=95 ). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students ( n=47 ) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% ( n=48 ), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1481–1482},
numpages = {2},
keywords = {chatgpt, computing education, generative ai, help-seeking},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716649,
author = {Prather, James and Reeves, Brent N and Denny, Paul and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Orvalho, Jo\~{a}o and Alipour, Amin and Alfageeh, Ali and Amarouche, Thezyrie and Kimmel, Bailey and Wright, Jared and Blake, Musa and Barbre, Gweneth},
title = {Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716649},
doi = {10.1145/3716640.3716649},
abstract = {Non-native English speakers (NNES) face multiple barriers to learning programming. These barriers can be obvious, such as the fact that programming language syntax and instruction are often in English, or more subtle, such as being afraid to ask for help in a classroom full of native English speakers. However, these barriers are frustrating because many NNES students know more about programming than they can articulate in English. Advances in generative AI (GenAI) have the potential to break down these barriers because state of the art models can support interactions in multiple languages. Moreover, recent work has shown that GenAI can be highly accurate at code generation and explanation. In this paper, we provide the first exploration of NNES students prompting in their native languages (Arabic, Chinese, and Portuguese) to generate code to solve programming problems. Our results show that students are able to successfully use their native language to solve programming problems, but not without some difficulty specifying programming terminology and concepts. We discuss the challenges they faced, the implications for practice in the short term, and how this might transform computing education globally in the long term.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {74–84},
numpages = {11},
keywords = {AI; Artificial Intelligence; Automatic Code Generation; Codex; Copilot; CS1; GenAI; GitHub; GPT; GPT-4; ChatGPT; HCI; Introductory Programming; Large Language Models; LLM; Non-Native English Speakers; Novice Programming; OpenAI; Prompt Problems},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3702163.3702451,
author = {Han, Mengying and Jiang, Rui and Hong, Jon-Chao and Li, Yushun},
title = {Educational Digital Divide: Investigating Teachers'Digital Teaching Competence in Digital Transformation of Education},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702451},
doi = {10.1145/3702163.3702451},
abstract = {Digital teaching has become one of the key approaches in the wave of digital transformation, considering teachers are the key role in digital teaching to achieve educational equity. What is the competence of teachers to cope with digital teaching has rarely been studied, especially with regard to the gender, regional and area differences. To address this gap, this study paid attention to the differences in digital teaching competence of teachers in different gender, regions and areas. A large-scale survey was conducted and 3,732 valid responses were collected (24.2% from rural schools, 31.4% from town schools, and 44.5% from urban schools) among four major regions. The results show that the overall digital teaching competence of teachers is at an intermediate level, with the emergence of the characteristic of “transforming teaching into learning”, but the competence of student-centered learning design, implementation and evaluation needs to be strengthened. What's more, there are significant differences in digital teaching competence among teachers of different genders, regions, and fields, highlighting the digital divide in education among different groups of teachers. Thus, this study provides valuable evidence that can be used to develop flexible, appropriate, and beneficial teacher professional development programs to prepare teachers for the adoption of generative AI in future education.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {429–434},
numpages = {6},
keywords = {Digital Teaching Assessment, Digital Teaching Competencies, Digital Teaching Design, Digital Teaching Implementation},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3641555.3705278,
author = {Jayaraman, Sharanya and Kolarkar, Ameya},
title = {Using Peer Tutoring to Bolster Retention Rates and Student Performance in CS1 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705278},
doi = {10.1145/3641555.3705278},
abstract = {Active Learning approaches have found success in CS1 and CS2 courses, consolidating instructional time on the practical, problem-solving aspects of programming. With the increasing availability of generative Artificial Intelligence Assistants, there is a renewed push to focus on higher-order skills beyond syntax and solving programming problems by matching sample outputs.This poster examines the impact of conceptual explanation-based exercises in introductory programming courses through the implementation of a scaffolded semi-flipped classroom. This method is currently in its third semester as a part of an ongoing, iterative, semi-experimental approach to support student resilience in entrance-level courses. This approach aimed to enhance student engagement, retention, and performance by integrating weekly practice sessions and "group-tutoring" sessions facilitated by peer learning assistants. In these sessions, students were encouraged to articulate their problem-solving strategies and the reasoning behind their solutions, fostering a deeper understanding of programming language paradigms and problem-solving techniques.The findings indicate that this method significantly increased classroom engagement, as students became more active participants in their learning journey. Retention rates improved as students became more confident in understanding and applying programming concepts. Overall, student performance saw a notable rise, with students demonstrating a better grasp of programming paradigms and problem-solving approaches beyond rote memorization and matching sample outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1495–1496},
numpages = {2},
keywords = {active learning, cs1/cs2, peer-based learning, self-assessment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701823,
author = {Ali, Areej and Collier, Aayushi Hingle and Dewan, Umama and McDonald, Nora and Johri, Aditya},
title = {Analysis of Generative AI Policies in Computing Course Syllabi},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701823},
doi = {10.1145/3641554.3701823},
abstract = {Since the release of ChatGPT in 2022, Generative AI (GenAI) is increasingly being used in higher education computing classrooms across the United States. While scholars have looked at overall institutional guidance for the use of GenAI and reports have documented the response from schools in the form of broad guidance to instructors, we do not know what policies and practices instructors are actually adopting and how they are being communicated to students through course syllabi. To study instructors' policy guidance, we collected 98 computing course syllabi from 54 R1 institutions in the U.S. and studied the GenAI policies they adopted and the surrounding discourse. Our analysis shows that 1) most instructions related to GenAI use were as part of the academic integrity policy for the course and 2) most syllabi prohibited or restricted GenAI use, often warning students about the broader implications of using GenAI, e.g. lack of veracity, privacy risks, and hindering learning. Beyond this, there was wide variation in how instructors approached GenAI including a focus on how to cite GenAI use, conceptualizing GenAI as an assistant, often in an anthropomorphic manner, and mentioning specific GenAI tools for use. We discuss the implications of our findings and conclude with current best practices for instructors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {18–24},
numpages = {7},
keywords = {course syllabi, generative ai, policy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3701198,
author = {Wang, Tianjia and Wu, Tong and Liu, Huayi and Brown, Chris and Chen, Yan},
title = {Generative Co-Learners: Enhancing Cognitive and Social Presence of Students in Asynchronous Learning with Generative AI},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701198},
doi = {10.1145/3701198},
abstract = {Cognitive presence and social presence are crucial for a comprehensive learning experience. Despite the flexibility of asynchronous learning environments to accommodate individual schedules, the inherent constraints of asynchronous environments make augmenting cognitive and social presence particularly challenging. Students often face challenges such as a lack of timely feedback and support, an absence of non-verbal cues in communication, and a sense of isolation. To address this challenge, this paper introduces Generative Co-Learners, a system designed to leverage generative AI-powered agents, simulating co-learners supporting multimodal interactions, to improve cognitive and social presence in asynchronous learning environments. We conducted a study involving 12 student participants who used our system to engage with online programming tutorials to assess the system's effectiveness. The results show that by implementing features to support textual and visual communication and simulate an interactive learning environment with generative agents, our system enhances the cognitive and social presence in the asynchronous learning environment. These results suggest the potential to use generative AI to support student learning and transform asynchronous learning into a more inclusive, engaging, and efficacious educational approach.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP19},
numpages = {24},
keywords = {asynchronous learning, cognitive presence, generative AI, multimodal generative agent, social presence}
}

@inproceedings{10.1145/3723498.3723817,
author = {Cox, Daniel and Murray, John and Salter, Anastasia},
title = {Routine, Twisty, and Queer: Pasts and Futures of Games Programming Pedagogy with No and Low Code Tools},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723817},
doi = {10.1145/3723498.3723817},
abstract = {This paper traces a history of platforms targeting no-code and low-code audiences. It connects historical moments addressing accessibility challenges related to computer programming up through the more recent adoption of generative AI in game engines. Across these moments, this paper identifies communities that claimed authoring platforms, establishing their identity by rejecting other, potentially more efficient or expressive options. We argue these community dynamics have shaped the evolution of current game development platforms. By contextualizing current efforts in pedagogy as part of larger shifts in computer programming and game engine practice, we present a better understanding of the origins of platforms targeting no and low code audiences as rooted in earlier pivots in computer programming and community engagement. These “twisty” and often queer adaptations aimed at smaller communities have led to major changes in how game development has evolved for larger audiences. We close on considerations of the uncertain futures and pedagogical implications of AI-generated code and visual scripting, as game engines increasingly serve as the primary interface between creators and their work.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {47},
numpages = {8},
keywords = {Game Programming Pedagogy, Low code, No code},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3722237.3722260,
author = {Wu, Yanan and Zeng, Xiaoping and Lin, Qibei},
title = {Generative AI Integrated Educational Model for User-Centered Design},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722260},
doi = {10.1145/3722237.3722260},
abstract = {The advent of artificial intelligence (AI) has profoundly transformed the educational landscape. Many educators are exploring how AI tools can enhance learning instructional programs. However, there is less focus on how its application within design education—particularly when teaching user-centered design. This study developed an educational model utilizing AI for user-centered design curriculum. Based on design thinking theory, this model integrates ChatGPT and Midjourney into the divergent and convergent design phases to facilitate the workflow. The empirical research showed that educational model can foster students’ creativity and problem-solving skills. The findings highlight the efficacy of AI integration in curricula design and instructional practices.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {129–135},
numpages = {7},
keywords = {Generative AI, design education, design thinking, instructional design, user-centered design},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3706598.3713574,
author = {Ahmadpour, Naseem and Pillai, Ajit G. and Zhang, Wendy Qi and Loke, Lian and Sachathep, Thida and Zhou, Zhaohua and Gough, Phillip},
title = {Ethics Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713574},
doi = {10.1145/3706598.3713574},
abstract = {Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {ethics, ethical sensitivity, education work, educator, reflection, reflexivity, canvas},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3711403.3711445,
author = {Zhou, Yaxin and He, Xiangchun and Jiang, Ruishuang and Zhang, Shaojun and Han, Yuqi and Guo, Xue},
title = {An Exploration of the Impact of Generalized Big Model Programming Educational Applications of Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711445},
doi = {10.1145/3711403.3711445},
abstract = {The application of artificial intelligence in the field of education has gone through several stages, initially using machine learning technology to optimize the teaching process to achieve automation of the "storage and calculation" function. Subsequently, through deep learning technology, the education has been able to realize the "visual and auditory" perceptual function. Nowadays, with the application of generalized big model, the education field is moving towards the cognitive stage of "understanding and creation". The purpose of this paper is to deeply analyze the challenges and dilemmas brought to programming education by the Generalized Big Model of Artificial Intelligence, and put forward the thinking of adjusting the educational objectives and programming content output under the ChatGPT Big Model for specific teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {246–251},
numpages = {6},
keywords = {Big Model, ChatGPT, Programming Education},
location = {
},
series = {ICETM '24}
}

@article{10.1145/3711023,
author = {Neshaei, Seyed Parsa and Tolzin, Antonia and Berkle, Yvonne and Leuchter, Miriam and Leimeister, Jan Marco and Janson, Andreas and Wambsganss, Thiemo},
title = {Leveraging Learner Errors in Digital Argumentation Learning: How ALure Helps Students Learn from their Mistakes and Write Better Arguments},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711023},
doi = {10.1145/3711023},
abstract = {Providing argumentation feedback is considered helpful for students preparing to work in collaborative environments, helping them with writing higher-quality argumentative texts. Domain-independent natural language processing (NLP) methods, such as generative models, can utilize learner errors and fallacies in argumentation learning to help students write better argumentative texts. To test this, we collect design requirements, and then design and implement two different versions of our system called ALure to improve the students' argumentation skills. We test how ALure helps students learn argumentation in a university lecture with 305 students and compare the learning gains of the two versions of ALure with a control group using video tutoring. We find and discuss the differences of learning gains in argument structure and fallacies in both groups after using ALure, as well as the control group. Our results shed light on the applicability of computer-supported systems using recent advances in NLP to help students in learning argumentation as a necessary skill for collaborative working settings.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW125},
numpages = {32},
keywords = {argumentation learning, learning from errors, natural language processing, writing assistants}
}

@inproceedings{10.1145/3706468.3706559,
author = {Li, Tongguang and Nath, Debarshi and Cheng, Yixin and Fan, Yizhou and Li, Xinyu and Rakovi\'{c}, Mladen and Khosravi, Hassan and Swiecki, Zachari and Tsai, Yi-Shan and Ga\v{s}evi\'{c}, Dragan},
title = {Turning Real-Time Analytics into Adaptive Scaffolds for Self-Regulated Learning Using Generative Artificial Intelligence},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706559},
doi = {10.1145/3706468.3706559},
abstract = {In computer-based learning environments (CBLEs), adopting effective self-regulated learning (SRL) strategies requires sophisticated coordination of multiple SRL processes. While various studies have proposed adaptive SRL scaffolds (i.e. real-time advice on adopting effective SRL processes) and embedded them in CBLEs to facilitate learners’ effective use of SRL strategies, two key research gaps remain. First, there is a lack of research on SRL scaffolds that are based on continuous assessment of both learners’ SRL processes and learning conditions (e.g., awareness of learning resources) to provide adaptive support. Second, current analytics-based scaffolding mechanisms lack the scalability needed to effectively address multiple learning conditions. Integration of analytics of SRL with generative artificial intelligence (GenAI) can provide scalable scaffolding for real-time SRL processes and evolving conditions. Yet, empirical studies implementing and evaluating effects of this integration remain scarce. To address these limitations, we conducted a randomized control trial, assigning participants to three groups (control, process only, and process with condition groups) to investigate the effects of using GenAI to turn insights from real-time analytics about students’ SRL processes and conditions into adaptive scaffolds. The results demonstrate that integrating real-time analytics with GenAI in adaptive SRL scaffolds – addressing both SRL processes and dynamic conditions – promotes more metacognitive learning patterns compared to the control and process-only groups. In addition, the learners showed varying levels of compliance with analytics-based GenAI scaffolds, and this was also reflected in how the learners coordinated their SRL processes, particularly in the performance phase of SRL. This study contributes to the literature by designing, implementing, and evaluating the impact of adaptive scaffolds on learners’ SRL processes using real-time analytics with GenAI.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {667–679},
numpages = {13},
keywords = {self-regulated learning, scaffolding compliance, GenAI, scaffolding, learning analytics},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3701716.3715244,
author = {Wang, Tianfu and Zhan, Yi and Lian, Jianxun and Hu, Zhengyu and Yuan, Nicholas Jing and Zhang, Qi and Xie, Xing and Xiong, Hui},
title = {LLM-powered Multi-agent Framework for Goal-oriented Learning in Intelligent Tutoring System},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715244},
doi = {10.1145/3701716.3715244},
abstract = {Intelligent Tutoring Systems (ITSs) have revolutionized education by offering personalized learning experiences. However, as goal-oriented learning, which emphasizes efficiently achieving specific objectives, becomes increasingly important in professional contexts, existing ITSs often struggle to deliver this type of targeted learning experience. In this paper, we propose GenMentor, an LLM-powered multi-agent framework designed to deliver goal-oriented, personalized learning within ITS. GenMentor begins by accurately mapping learners' goals to required skills using a fine-tuned LLM trained on a custom goal-to-skill dataset. After identifying the skill gap, it schedules an efficient learning path using an evolving optimization approach, driven by a comprehensive and dynamic profile of learners' multifaceted status. Additionally, GenMentor tailors learning content with an exploration-drafting-integration mechanism to align with individual learner needs. Extensive automated and human evaluations demonstrate GenMentor's effectiveness in learning guidance and content quality. Furthermore, we have deployed it in practice and also implemented it as an application. Practical human study with professional learners further highlights its effectiveness in goal alignment and resource targeting, leading to enhanced personalization. Supplementary resources are available at ttps://github.com/GeminiLight/gen-mentor.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {510–519},
numpages = {10},
keywords = {intelligent tutoring system, large language model, multi-agent},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3732786,
author = {Wang, Shijie and Huang, Jiani and Chen, Zhikai and Song, Yu and Tang, Wenzhuo and Mao, Haitao and Fan, Wenqi and Liu, Hui and Liu, Xiaorui and Yin, Dawei and Li, Qing},
title = {Graph Machine Learning in the Era of Large Language Models (LLMs)},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3732786},
doi = {10.1145/3732786},
abstract = {Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graphs. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML’s generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph Heterophily and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {Graph Machine Learning, Large Language Models (LLMs), Pre-training and Fine-tuning, Prompting, and Representation Learning}
}

@inproceedings{10.1145/3722237.3722258,
author = {Fang, Wenjie and Luo, Bin},
title = {Application and Impact of Generative Artificial Intelligence Techniques in Education--Citespace-based visualization and analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722258},
doi = {10.1145/3722237.3722258},
abstract = {Recently, generative AI technology has arisen as a trending research agenda in education.  This study makes an review of 260 documents from the CNKI database published from 2020 to 2024. Through the bibliometric and content analysis methods, together with the CiteSpace tool, highlight the trending application of this technology in education, the distribution characteristics of the core authors and institutions' postings, and the clustering analysis of the research hotspots. The results show continued wide adoption of generative AI technology in education in recent years, peaking sharply in 2023. There hasn't been a stable core group of authors within the field, and the collaborative network is relatively sparse. Research hotspots mainly cover artificial intelligence, human-computer collaboration and educational transformation, which indicates the function generative AI technology could have within the digital transformation and quality enhancement of education. This paper additionally shows the actualization of generative AI technology through its presentation of AI tutors and teaching assistants, teaching models reform, and reshaped instructional evaluation systems via case studies. In face of misuse, integrity issues, and ethical concerns arising, there is a need to find a balance in the application of the technology, such that its more proper development can promote rather than replace human subjectivity.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {117–122},
numpages = {6},
keywords = {CiteCpace visual analytic, Educational Application, Generative AI, Human-computer collaboration},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3641555.3705241,
author = {Jindal, Vasu},
title = {SAFARI-P: Swahili-Focused Adaptive Framework for Accelerated Reinforcement in Intelligent Python Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705241},
doi = {10.1145/3641555.3705241},
abstract = {This paper introduces SAFARI-P (Swahili-Focused Adaptive Framework for Accelerated Reinforcement in Intelligent Python Education), an innovative system that integrates Generative Adversarial Networks (GANs) and a Multi-Dimensional Learning Confidence (MDLC) system for Python programming education in Swahili. The framework comprises three key components: (1) an Adversarial Code Generation System (ACGS) for creating culturally relevant code snippets, (2) an MDLC Assessment Module that uses a tripartite confidence matrix system to evaluate concept understanding, problem-solving patterns, and code quality, and (3) a Cultural Context Integration Engine for incorporating local elements. By simultaneously tracking technical proficiency and cultural understanding through confidence matrices, SAFARI-P provides personalized learning paths that ensure students build strong foundational knowledge while maintaining cultural relevance. In a 16-week study conducted across Kenya, Tanzania, and Uganda, this mathematically rigorous approach to confidence tracking led to significant improvements: a 27% increase in Python proficiency (p &lt; 0.001) and a 32.6% improvement in problem-solving efficiency (p &lt; 0.001).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1499–1500},
numpages = {2},
keywords = {adaptive learning, ai in education, cultural computing, culturally relevant computing, generative adversarial networks},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3702386.3702399,
author = {Huang, Hui-Wen and Chang, Jessica (Chieh-Yu)},
title = {Human-AI Interactions in Teacher Education: Examining Social Presence and Friendship},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702399},
doi = {10.1145/3702386.3702399},
abstract = {This study examines the potential of AI chatbots, such as ChatGPT, to establish meaningful human-AI friendships with college students enrolled in teacher education programs. Fifty-nine junior-level elementary education majors participated in a three-week intervention study. Using the framework of social presence theory, this research explores whether generative AI technologies can replicate key qualities of friendship, such as empathy, social support, and trust. The findings reveal that while AI chatbots provide practical benefits and reliable assistance, they fall short in fostering the deep emotional and empathetic connections that are fundamental to human relationships. Notably, some participants expressed trust in AI chatbots, citing their ability to keep users' secrets private. The results suggest that enhancing social presence may improve emotional engagement and trust in human-AI interactions. This study contributes to the understanding of AI's role in offering social and emotional support, particularly in explaining student teachers' behaviors with AI technologies within educational settings.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {64–69},
numpages = {6},
keywords = {Generative AI, emotional support, human-AI Interaction, social presence theory, virtual friends},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3701716.3717661,
author = {Ding, Ning and Tang, Yehui and Fu, Zhongqian and Xu, Chao and Han, Kai and Wang, Yunhe},
title = {GPT4Image: Large Pre-trained Models Help Vision Models Learn Better on Perception Task},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717661},
doi = {10.1145/3701716.3717661},
abstract = {The upsurge in pre-trained large models started by ChatGPT has swept across the entire deep learning community. Such powerful models demonstrate advanced generative ability and multimodal understanding capability, which quickly set new state of the arts on a variety of benchmarks. The pre-trained LLM usually plays the role as a universal AI model that can conduct various tasks like article analysis and image comprehension. However, due to the prohibitively high memory and computational cost of implementing such a large model, the conventional models (such as CNN and ViT) are still essential for many visual perception tasks. In this paper, we propose to enhance the representation ability of ordinary vision models on perception tasks (e.g. image classification) by taking advantage of the off-the-shelf large pre-trained models. We present a new learning framework, dubbed GPT4Image, where the knowledge of the large pre-trained models are extracted to help CNNs and ViTs learn better representations and achieve higher performance. Firstly, we curate a high quality description set by prompting a multimodal LLM to generate descriptions for training images. Then, these detailed descriptions are fed into a pre-trained encoder to extract text embeddings that encodes the rich semantics of images. During training, text embeddings will serve as extra supervising signal and be aligned with image representations learned by vision models. The alignment process helps vision models achieve better performance with the aid of pre-trained LLMs. We conduct extensive experiments to verify the effectiveness of the proposed algorithm on various visual perception tasks for heterogeneous model architectures.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2056–2065},
numpages = {10},
keywords = {computer vision, image classification, multimodal llm},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3702163.3702179,
author = {Mohd A'seri, Muhamad Safwan and Mahmud, Malissa Maria and Yaacob, Yazilimiwati and Ahmad, Rozaini and Nagasundram, Usha and Mustamam, Nur Izzati},
title = {Beyond the Textbook: A Study of ChatGPT Patterns of Use Perceptions and Experiences Among Students in Higher Education},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702179},
doi = {10.1145/3702163.3702179},
abstract = {This study investigates the utilization pattern, perception, and experience of Higher Education Institutes (HEIs) students towards the ChatGPT application in an academic context. It employs a quantitative approach utilizing a questionnaire as the research instrument. The study sample was selected using a simple random sampling method from Sunway University and Sunway College in Kuala Lumpur, Malaysia. The survey participants, enrolled in General Studies Subjects (MPU) during their short semester between September and December 2023, were selected using a simple random sampling method. Out of 150 students who received the survey via Google Forms, 119 provided complete responses suitable for analysis. The research primarily focused on calculating mean scores to assess three key dimensions: its use patterns of ChatGPT, perceptions and experiences among students towards its adoption in educational contexts. A descriptive analysis was conducted to determine student frequency and percentage values for ChatGPT usage. At the same time, mean scores were utilized to evaluate higher education institutes (HEIs) students' perceptions and experiences with the application in an academic context. This descriptive analysis revealed a spectrum of responses that ranged from low to very high levels across these dimensions. The findings of this study offer extensive insight into the current incorporation and perception of ChatGPT within Higher Education Institutions (HEIs), showcasing the diverse range of engagement and acceptance levels among students.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, Experiences, Higher education institutions, Perceptions, Use patterns},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3706468.3706474,
author = {Yin, Stella Xin and Liu, Zhengyuan and Goh, Dion Hoe-Lian and Quek, Choon Lang and Chen, Nancy F.},
title = {Scaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706474},
doi = {10.1145/3706468.3706474},
abstract = {Pair programming is a collaborative activity that enhances students’ computational thinking (CT) skills. Analyzing students’ interactions during pair programming provides valuable insights into effective learning. However, interpreting classroom dialogues is a challenging and complex task. Due to the simultaneous interaction between interlocutors and other ambient noise in collaborative learning contexts, previous work heavily relied on manual transcription and coding, which is labor-intensive and time-consuming. Recent advancements in speech and language processing offer promising opportunities to automate and scale up dialogue analysis. Besides, previous work mainly focused on task-related interactions, with little attention to social interactions. To address these gaps, we conducted a four-week CT course with 26 fifth-grade primary school students. We recorded their discussions, transcribed them with speech processing models, and developed a coding scheme and applied LLMs for annotation. Our AI-driven pipeline effectively analyzed classroom recordings with high accuracy and efficiency. After identifying the dialogue patterns, we investigated the relationships between these patterns and CT performance. Four clusters of dialogue patterns have been identified: Inquiry, Constructive Collaboration, Disengagement, and Disputation. We observed that Inquiry and Constructive Collaboration patterns were positively related to students’ CT skills, while Disengagement and Disputation patterns were associated with lower CT performance. This study contributes to the understanding of how dialogue patterns relate to CT performance and provides implications for both research and educational practice in CT learning.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {47–57},
numpages = {11},
keywords = {Collaborative learning, Computational thinking, Dialogue analysis, Large language models, Pair programming, Speech and language processing},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3676641.3716262,
author = {Xu, Jianxing and Wen, Yuanbo and Liu, Zikang and Xu, Ruibai and Ruan, Tingfeng and Bi, Jun and Zhang, Rui and Huang, Di and Song, Xinkai and Hao, Yifan and Hu, Xing and Du, Zidong and Zhao, Chongqing and Jie, Jiang and Guo, Qi},
title = {Mosaic: Exploiting Instruction-Level Parallelism on Deep Learning Accelerators with iTex Tessellation},
year = {2025},
isbn = {9798400710797},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676641.3716262},
doi = {10.1145/3676641.3716262},
abstract = {Deep learning has achieved great success in numerous application areas at the cost of high computational complexity. To meet the ever-increasing computational demand, commodity hardware platforms (e.g., CPUs and GPUs) offer abundant computing resources including scalar, vector, and tensor units for deep learning that could execute in parallel. However, existing top-down tiling-based deep learning compilers often generate a homogeneous mapping from the given tensor computation task to hardware arithmetic instructions, failing to utilize different computing units simultaneously to achieve higher performance.In this paper, we propose Mosaic, a bottom-up tessellation-based deep learning compiler that directly tessellates the given tensor computation task with varying instructions, forming a heterogeneous instruction-to-task mapping to exploit instruction-level parallelism (ILP) across different computing units. The key that enables such tessellation is the iTex abstraction, which models the relationship between the instruction operations and its semantics with formalized affine functions. Based on the iTex, we propose a heuristic approach to efficiently generate various tessellation plans. Further, we propose the iTex scheduling technique to orchestrate the execution of instructions, reducing potential structural hazards and maximizing the exploitable ILP. Our extensive evaluation shows that Mosaic achieves an average speedup ranging from 1.08\texttimes{} to 1.28\texttimes{} across multiple hardware platforms compared to highly optimized vendor libraries. Mosaic also achieves an average speedup of 1.34\texttimes{} over the best existing baselines on real-world operators extracted from LLMs. More importantly, Mosaic reaches up to 106% of the GPU Tensor Core theoretical peak throughput, demonstrating its effective exploitation of ILP.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
pages = {672–688},
numpages = {17},
keywords = {compiler, deep learning accelerators, instruction-level parallelism (ilp)},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3676536.3676838,
author = {Mandal, Upasana and Shukla, Shubhi and Rastogi, Ayushi and Bhattacharya, Sarani and Mukhopadhyay, Debdeep},
title = {µLAM: A LLM-Powered Assistant for Real-Time Micro-architectural Attack Detection and Mitigation},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676838},
doi = {10.1145/3676536.3676838},
abstract = {The rise of microarchitectural attacks has necessitated robust detection and mitigation strategies to secure computing systems. Traditional tools, such as static and dynamic code analyzers and attack detectors, often fall short due to their reliance on predefined patterns and heuristics that lack the flexibility to adapt to new or evolving attack vectors. In this paper, we introduce for the first time a microarchitecture security assistant, built on OpenAI's GPT-3.5, which we refer to as μLAM. This assistant surpasses conventional tools by not only identifying vulnerable code segments but also providing context-aware mitigations, tailored to specific system specifications and existing security measures. Additionally, μLAM leverages real-time data from dynamic Hardware Performance Counters (HPCs) and system specifications to detect ongoing attacks, offering a level of adaptability and responsiveness that static and dynamic analyzers cannot match.For fine-tuning μLAM, we utilize a comprehensive dataset that includes system configurations, mitigations already in place for different generations of systems, dynamic HPC values, and both vulnerable and non-vulnerable source codes. This rich dataset enables μLAM to harness its advanced LLM natural language processing capabilities to understand and interpret complex code patterns and system behaviors, learning continuously from new data to improve its predictive accuracy and respond effectively in real time to both known and novel threats, making it an indispensable tool against microarchitectural threats. In this paper, we demonstrate the capabilities of μLAM by fine-tuning and testing it on code utilizing well-known cryptographic libraries such as OpenSSL, Libgcrypt, and NaCl, thereby illustrating its effectiveness in securing critical and complex software environments.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {168},
numpages = {9},
keywords = {microarchitecture attacks, attack detection system, LLMs},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3696410.3714543,
author = {Gao, Wen},
title = {Peng Cheng Cloud Brain and Mind Series of Large Model},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714543},
doi = {10.1145/3696410.3714543},
abstract = {As a revolutionary pre-training model, ChatGPT has already had a huge impact on global economic. It is the strong foundation of computing power that enables large models to continuously improve in the process of understanding massive data, resulting in breakthrough innovations. Based on the Peng Cheng Cloud Brain II E-level intelligent computing platform, Peng Cheng Laboratory is training PCL Mind Series of Large Model. Mind is the first fully autonomous, controllable, safe, open-source pre-training foundation model in China, where the performance of the 200 billion parameter base model reaches the international advanced, and the output content conforms to the Chinese core values. Peng Cheng Laboratory is opening up PCL Mind cooperation and work with external partners to continuously build a large model open-source consortium for domestic large model ecosystem. The next generation-Peng Cheng Cloud Brain III will break through key technologies such as high computing power chips, large-scale networking communication, high-performance software stacks, and large-scale parallel training, and support 10,000 chip-level parallel training of trillion-level parameter AI.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3},
numpages = {1},
keywords = {Peng Cheng cloud brain, WWW, keynote},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3706468.3706494,
author = {Jansen, Thorben and Horbach, Andrea and Meyer, Jennifer},
title = {Feedback from Generative AI: Correlates of Student Engagement in Text Revision from 655 Classes from Primary and Secondary School},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706494},
doi = {10.1145/3706468.3706494},
abstract = {Writing is fundamental in knowledge-based societies, and engaging students in text revision through feedback is critical for developing students’ writing skills. Automated feedback offers a promising solution to teachers’ time constraints creating feedback. However, prior research indicates that 20 to 71 percent of students receiving feedback do not engage in any text revision. Despite these concerning figures, students’ non-engagement has not received widespread attention, likely due to fragmented evidence from a few grade levels and writing tasks disconnected from regular teaching. Further, whether the issue persists when generative AI generates the feedback is unclear. The present study investigates what percentage of students behaviorally engage with feedback from generative AI in authentic classroom learning contexts. We analyzed data from an educational technology company, including 655 teacher-generated writing tasks involving 14,236 students across grades 1-12. Our findings show that around half of the students did not revise a single character in the text after receiving feedback. The percentage was similar across grade levels, task types, or feedback characteristics. We discuss the importance of including the percentage of engaged students as an additional metric in feedback research to achieve the goal that no student is left behind.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {831–836},
numpages = {6},
keywords = {student engagement, automated feedback, writing, generative AI},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3676536.3676697,
author = {DiBrita, Nicholas S. and Leeds, Daniel and Huo, Yuqian and Ludmir, Jason and Patel, Tirthak},
title = {ReCon: Reconfiguring Analog Rydberg Atom Quantum Computers for Quantum Generative Adversarial Networks},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676697},
doi = {10.1145/3676536.3676697},
abstract = {Quantum computing has shown theoretical promise of speedup in several machine learning tasks, including generative tasks using generative adversarial networks (GANs). While quantum computers have been implemented with different types of technologies, recently, analog Rydberg atom quantum computers have been demonstrated to have desirable properties such as reconfigurable qubit (quantum bit) positions and multi-qubit operations. To leverage the properties of this technology, we propose ReCon, the first work to implement quantum GANs on analog Rydberg atom quantum computers. Our evaluation using simulations and real-computer executions shows 33% better quality (measured using Frechet Inception Distance (FID)) in generated images than the state-of-the-art technique implemented on superconducting-qubit technology.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {32},
numpages = {9},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@article{10.1145/3742788,
author = {Kang, Yan and Fan, Tao and Gu, Hanlin and Zhang, Xiaojin and Fan, Lixin and Yang, Qiang},
title = {Grounding Foundation Models through Federated Transfer Learning: A General Framework},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3742788},
doi = {10.1145/3742788},
abstract = {Foundation Models (FMs) such as GPT-4 encoded with vast knowledge and powerful emergent abilities have achieved remarkable success in various natural language processing and computer vision tasks. Grounding FMs by adapting them to domain-specific tasks or augmenting them with domain-specific knowledge enables us to exploit the full potential of FMs. However, grounding FMs faces several challenges, stemming primarily from constrained computing resources, data privacy, model heterogeneity, and model ownership. Federated Transfer Learning (FTL), the combination of federated learning and transfer learning, provides promising solutions to address these challenges. Recently, the need for grounding FMs leveraging FTL, coined FTL-FM, has arisen strongly in both academia and industry. Motivated by the strong growth in FTL-FM research and the potential impact of FTL-FM on industrial applications, we propose an FTL-FM framework that formulates problems of grounding FMs in the federated learning setting, construct a detailed taxonomy based on the FTL-FM framework to categorize state-of-the-art FTL-FM works, and comprehensively overview FTL-FM works based on the proposed taxonomy. We also establish correspondence between FTL-FM and conventional phases of adapting FM so that FM practitioners can align their research works with FTL-FM. In addition, we overview advanced efficiency-improving and privacy-preserving techniques because efficiency and privacy are critical concerns in FTL-FM. Last, we discuss opportunities and future research directions of FTL-FM.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jun,
keywords = {Federated Learning, Transfer Learning, Foundation Model, Privacy}
}

@inproceedings{10.1145/3708036.3708151,
author = {Yan, Erkai and Gao, Mengxiao and Tang, Mei},
title = {Analysis and Research on Generative Artificial Intelligence in the Field of International Library and Information Science},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708151},
doi = {10.1145/3708036.3708151},
abstract = {Generative artificial intelligence is an artificial intelligence technology based on deep learning whose core lies in leveraging computer algorithms and training data to generate new, practically valuable content, encompassing text, images, audio, videos, etc. This technology is poised to exert profound impacts on the transformation and development of libraries. Drawing on generative artificial intelligence research publications in the field of international library and information science included in the Scopus database as the data source, this paper employs CiteSpace software and SciVal tools to conduct a visual analysis of literature outputs, core authors, journal sources, and keywords. The results show that generative artificial intelligence research in the international library and information science field is applied primarily in areas such as reference services, information literacy education, and smart libraries. Recommendations are made to promote the application and development of generative artificial intelligence technology in libraries by strengthening technological research and application, boosting data analysis and data sharing, emphasizing information security and privacy protection, promoting cross-boundary integration and ecological development, etc.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {679–686},
numpages = {8},
keywords = {ChatGPT, Generative artificial intelligence, library},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3706599.3719742,
author = {Li, Jinqiao and Neshaei, Seyed Parsa and M\"{u}ller, Livia and Rietsche, Roman and Davis, Richard Lee and Wambsganss, Thiemo},
title = {SpatiaLearn: Exploring XR Learning Environments for Reflective Writing},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719742},
doi = {10.1145/3706599.3719742},
abstract = {Reflective writing promotes deeper learning by enhancing metacognitive awareness and critical thinking, but learners often struggle with structuring their reflections and maintaining focus. Generative AI and advances in spatial computing offer promising solutions. Extended reality (XR) environments create immersive, distraction-free settings, while conversational agents use dialog-based scaffolding guides to structure learners’ thoughts. However, research on combining dialog-based scaffolding with XR for reflective writing remains limited. To address this, we introduce SpatiaLearn, an adaptive XR tool that enhances reflective writing through conversational guidance in both traditional and immersive environments. A within-subjects study (N = 19) compared participants’ performance in traditional laptop and XR environments. Qualitative analysis shows the spatial interface enhances engagement but raises challenges like unfamiliar interactions and health concerns, requiring task adaptation for XR. This study advances the design of immersive tools for reflective writing, highlighting both the opportunities and challenges of spatial interfaces.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {11},
keywords = {Extended Reality (XR), Spatial Computing, Adaptive Education, Conversational Tutoring},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3708557.3716158,
author = {Mokryn, Osnat and Shaer, Orit and Geyer, Werner and Maher, Mary Lou and Weisz, Justin D. and Buschek, Daniel and Chilton, Lydia B},
title = {HAI-GEN 2025: 6th Workshop on Human-AI Co-Creation with Generative Models},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716158},
doi = {10.1145/3708557.3716158},
abstract = {Generative Artificial Intelligence (GAI) models capable of complex tasks are revolutionizing areas previously considered to define humanity, such as creativity, design, and knowledge work. Research reports that Human-GAI co-creation processes can enhance creativity and even foster a sense of empowerment. A key innovation is the intent-based outcome specification, where users define desired results through natural language, sketches, or gestures, thus shifting control from users to AI models. This paradigm enables new forms of co-creation while presenting challenges in creating effective and safe outcome specifications.This workshop aims to investigate the design, implementation, and evaluation of intent-based co-creative experiences that boost human creativity in work, play, and education across text, images, audio, code, and video. Key questions focus on how creativity support can guide generative AI development and how to leverage generative models for positive user experiences. By uniting researchers and practitioners from Human-Computer Interaction (HCI) and AI, the workshop seeks to deepen understanding of human-AI co-creative interactions and explore opportunities and challenges in developing meaningful and safe generative systems.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {179–182},
numpages = {4},
keywords = {Generative modeling, artificial intelligence, generative design, user experience, co-creation, collaboration, creativity},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3702163.3702165,
author = {Gong, Rushi and Jiang, Rui and Guo, Chuanlei and Hu, Wanqing and Li, Yanyan},
title = {Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702165},
doi = {10.1145/3702163.3702165},
abstract = {Students’ emerging roles in computer supported collaborative learning (CSCL) are crucial in revealing what learning characteristics and states students present during their collaborative knowledge construction. Previous researchers have unveiled the fact that pedagogical scaffoldings such as AI chatbots play a pivotal role in students’ role emerging, but with the prevalence of generative AI (GAI), there is also an urgent need to investigate whether GAI chatbots influence students’ emerging roles during the knowledge construction process in collaborative learning. Therefore, this study conducted a quasi-experiment, using an integration of cluster analysis, chi-square test, case analysis, and content analysis to investigate whether and how a GAI chatbot affected students’ emerging roles in their online collaborative knowledge construction. Results demonstrated statistical significance that the GAI chatbot and the traditional static scripts did not have a distinct difference in students’ emerging roles. However, qualitative data showed that the GAI chatbot had an impact on the allocation of roles and that there were perceptual differences in how students with the same roles experienced the writing process and collaborative atmosphere under different support conditions. The study will provide insights into how GAI chatbots can be adapted for future development and application in a collaborative learning context with consideration of students’ roles.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {8–16},
numpages = {9},
keywords = {Computer Supported Collaborative Learning, Generative AI Chatbot, Knowledge Construction, Students’ Roles},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3706598.3714233,
author = {Earle, Sam and Parajuli, Samyak and Banburski-Fahey, Andrzej},
title = {DreamGarden: A Designer Assistant for Growing Games from a Single Prompt},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714233},
doi = {10.1145/3706598.3714233},
abstract = {Coding assistants are increasingly leveraged in game design, both generating code and making high-level plans. To what degree can these tools align with developer workflows, and what new modes of human-computer interaction can emerge from their use? We present DreamGarden, an AI system capable of assisting with the development of diverse game environments in Unreal Engine. At the core of our method is an LLM-driven planner, capable of breaking down a single, high-level prompt—a dream, memory, or imagined scenario provided by a human user—into a hierarchical action plan, which is then distributed across specialized submodules facilitating concrete implementation. This system is presented to the user as a garden of plans and actions, both growing independently and responding to user intervention via seed prompts, pruning, and feedback. Through a user study, we explore design implications of this system, charting courses for future work in semi-autonomous assistants and open-ended simulation design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {57},
numpages = {19},
keywords = {Game design assistants, 3D asset generation, large language models, visual feedback},
location = {
},
series = {CHI '25}
}

@article{10.5555/3711988.3711989,
author = {Tham, Jason},
title = {Teaching UX: Amid the Hype of Generative AI},
year = {2025},
issue_date = {November 2024},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {20},
number = {1},
issn = {1931-3357},
abstract = {I am a faculty member in a technical communication program at a comprehensive research university. Recently, I have been inundated with questions, concerns, and critiques about the rise of augmentation technologies in writing and design processes, particularly generative artificial intelligence (AI) tools that support chat-based text generation and text-to-image production. I'm sure many UX researchers and designers face similar issues in their work. It remains unclear how generative AI should fit into existing workflow or design processes. Common questions include these:• How does AI work? What can it do? Is it free?• Is it cheating if I use AI to produce content?• Who is responsible for the quality of AI-generated content?• To what extent can I outsource my routine work to AI? In other words, what's an acceptable threshold for using AI before it is considered too much?Specific to UX is the value (cost and labor versus gains and effects) of generative AI in the research and design of user-centered products. Students in my UX courses are increasingly worried about the presence of AI and, consequently, the relevance of their developing skill sets in UX. Educators are growing wary about the presence of AI in the context of teaching and learning; many form partially informed decisions on academic policies for AI usage.},
journal = {J. User Exper.},
month = feb,
pages = {1–8},
numpages = {8}
}

@article{10.1145/3712263,
author = {Mameli, Marco and Paolanti, Marina and Mancini, Adriano and Zingaretti, Primo and Pierdicca, Roberto},
title = {RenderGAN: Enhancing Real-time Rendering Efficiency with Deep Learning},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {3},
issn = {1551-6857},
url = {https://doi.org/10.1145/3712263},
doi = {10.1145/3712263},
abstract = {In the domain of computer graphics, achieving high visual quality in real-time rendering remains a formidable challenge due to the inherent time-quality tradeoff. Conventional real-time rendering engines sacrifice visual fidelity for interactive performance, while image generation using path-tracing techniques can be exceedingly time-consuming. In this article, we introduce RenderGAN, a deep learning-based solution designed to address this critical challenge in real-time rendering. RenderGAN uses G-Buffers and information from a real-time rendering engine as inputs to produce output images with exceptional visual fidelity. Its encoder–decoder architecture, trained using the Generative Adversarial Network (GAN) framework with perceptual loss, enhances image realism. To evaluate RenderGAN’s effectiveness, we quantitatively compare the generated images with those of a path-tracing engine, obtaining a remarkable Universal Image Quality Index (UIQI) value of 0.898. RenderGAN’s open source nature fosters collaboration, driving advancements in real-time computer graphics and rendering techniques. By bridging the gap between real-time and path-tracing rendering, RenderGAN opens new horizons for accelerated image generation, inspiring innovation and unlocking the full potential of real-time visual experiences. Project page:},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
articleno = {99},
numpages = {22},
keywords = {Computer Graphics, Deep Learning, Generative Adversarial Networks, RenderGAN}
}

@inproceedings{10.1145/3641555.3705263,
author = {Lee, Irene and Malyn-Smith, Joyce and Kam, Matthew and Miller, Cody and Wang, Miaoxin},
title = {The AI-Enhanced Software Engineer: A Snapshot of the Profession},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705263},
doi = {10.1145/3641555.3705263},
abstract = {Generative AI and other emerging technologies are significantly impacting the work of software engineers. This impact is not re- stricted to programming; rather it has permeated multiple phases in the software development pipeline. As such, it is increasingly important to understand and analyze the changing work of the AI-enabled software developers who work at the cutting edge of AI Integration. This poster shares the ''Profile of the AI-enhanced Software Engineer'' developed in collaboration between Education Development Center (EDC) and Google. The profile describes in detail the work goals and associated tasks; and the skills, knowledge and attributes needed to do that work effectively. The poster will also share a framework for prompting used by skilled AI-enhanced software engineers across a variety of tasks. Though rapid change is predicted for the field, the Profile can inform K-20 CS and AI education efforts as well as workforce development of the current state of the field and stimulate discussion of how best to prepare for and adapt to the future of work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1519–1520},
numpages = {2},
keywords = {ai-enhanced software engineer, attributes, knowledge, skills},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3706641,
author = {Nacke, Lennart E.},
title = {How to write higher-quality CHI papers (with AI research tools)},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706641},
doi = {10.1145/3706599.3706641},
abstract = {Writing high-quality research papers is crucial for advancing your academic career. With the advent of generative artificial intelligence (AI) tools, researchers now have novel ways to improve their writing, literature reviews, and overall paper quality. This course, delivered in person at CHI 2025 in Yokohama, Japan, offers a practical exploration of how to use AI tools effectively throughout the research writing process. Over three interactive 75-minute sessions, participants will learn to apply AI tools to edit their writing, brainstorm ideas, and enhance their paper’s readability and impact. Through hands-on activities and peer discussions, attendees will gain the skills needed to produce high-impact CHI papers that meet publication standards. This course emphasizes using AI to support writing, structuring research, and refining contributions, providing attendees with practical tools and insights to succeed in academic publishing in the field of Human-Computer Interaction.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {816},
numpages = {3},
keywords = {Generative AI, Writing, ChatGPT, Publication, Writing, Submission Process, Research Methods},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3727648.3727765,
author = {Zhang, Kaijie and Wu, Minhui and Chen, Kaihao},
title = {Scaling Down LLaMA 3: Advanced Compression Techniques and Knowledge Distillation for Resource-Efficient Language Models},
year = {2025},
isbn = {9798400712647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727648.3727765},
doi = {10.1145/3727648.3727765},
abstract = {With the widespread application of large-scale language models (LLMs) in natural language processing, traditional Transformer-based models (such as LLaMA 3) face challenges in resource-constrained environments due to their huge parameter size and computational complexity. To improve efficiency, model compression has become an important research direction. This paper proposes an innovative knowledge distillation strategy to distill the LlamaDecoderLayer of LLaMA 3 into a smaller student model TinyDecoder to reduce the computational and storage overhead of the model. TinyDecoder significantly reduces the model size and computational complexity while maintaining good performance by simplifying parameters such as the hidden layer size and the number of attention heads in LlamaDecoderLayer. Experimental results show that the distilled model significantly reduces storage requirements and computational load while still achieving decent performance. The parameter size of the distilled model is about 4.3% of the original model, the throughput speedup ratio is 1.49x - 10.93x, and the perplexity only increases from 3.25 to 7.94. Although the text generation performance of the distilled model has declined, the inference speed and memory usage are significantly improved compared to the original model, which is particularly suitable for resource-constrained environments. Through distillation, the student model effectively learns the core knowledge of the teacher model and performs well on tasks of simple to medium complexity.},
booktitle = {Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {721–725},
numpages = {5},
keywords = {Knowledge Distillation, LLama 3 Optimization, Large Language Models, Model Compression},
location = {
},
series = {CAICE '25}
}

@inproceedings{10.1145/3706598.3713832,
author = {Jain, Yoshee and Demirtas, Mehmet Arif and Cunningham, Kathryn Irene},
title = {PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713832},
doi = {10.1145/3706598.3713832},
abstract = {Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators’ plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors’ efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {21},
keywords = {programming plan, programming pattern, pattern identification, instructor support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706628.3708833,
author = {Mhatre, Kaustubh Manohar and Mulleti, Venkata Guru Prasanth and Bansil, Curt John and Taka, Endri and Arora, Aman},
title = {Performance Analysis of GEMM Workloads on the AMD Versal Platform},
year = {2025},
isbn = {9798400713965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706628.3708833},
doi = {10.1145/3706628.3708833},
abstract = {AMD Versal is a new heterogeneous computing hardware architecture comprised of adaptive intelligence (AI) engines, programmable logic, and a processing system. General Matrix Multiplication (GEMM) is the fundamental building block of modern deep learning (DL) applications such as ChatGPT, and GEMM workloads can be mapped onto Versal in different ways, each with distinct trade-offs. This paper presents a thorough analysis of GEMM workloads of different shapes and sizes, showcasing performance artifacts associated with the AMD Versal architecture. Focusing on the unique aspects of the Versal architecture, multiple research questions related to performance scaling, sensitivity, and efficiency are explored. This paper aims to assist developers in the FPGA community looking to implement GEMM on AMD Versal by providing guidelines and insights for enhancing performance.},
booktitle = {Proceedings of the 2025 ACM/SIGDA International Symposium on Field Programmable Gate Arrays},
pages = {46},
numpages = {1},
keywords = {deep learning, hardware accelerator, heterogeneous architecture, matrix multiply, versal},
location = {Monterey, CA, USA},
series = {FPGA '25}
}

@inproceedings{10.1145/3641555.3705144,
author = {Gupta, Ishita and Bridgman, Maya and Wang, Sierra and Mitchell, John},
title = {Coding Pathfinder: A Platform for Creative, Self-Guided Mastery in Programming},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705144},
doi = {10.1145/3641555.3705144},
abstract = {We present Coding Pathfinder, a platform to help non-programmers learn to code for a specific purpose. This paper explores how we can scaffold generative AI to provide structure and ensure mastery in informal learning settings, introducing a new approach to coding education. In the current iteration of Pathfinder, a user describes the coding task that they are working on. After collecting some details and scoping the project, Pathfinder identifies the skills that the user will master upon successful completion of the project. It then assesses which of the skills our users already has, and designs a personalised learning journey. The guided journey consists of instructions, explanations, tasks and videos. We also incorporate a chat feature so users can ask questions and engage as if they are working with a tutor.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1465–1466},
numpages = {2},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1109/SCW63240.2024.00127,
author = {Xu, Wubiao and Huang, Xin and Meng, Shiman and Zhang, Weiping and Guo, Luanzheng and Sato, Kento},
title = {An Efficient Checkpointing System for Large Machine Learning Model Training},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00127},
doi = {10.1109/SCW63240.2024.00127},
abstract = {Checkpointing is one of the fundamental techniques to resume training while system fails. It has been generally used in various domains, such as high-performance computing (HPC) and machine learning (ML). However, as machine learning models increase in size and complexity rapidly, the cost of checkpointing in ML training became a bottleneck in storage and performance (time). For example, the latest GPT-4 model has massive parameters at the scale of 1.76 trillion. It is highly time and storage consuming to frequently writes the model to checkpoints with more than 1 trillion floating point values to storage. This work aims to understand and attempt to mitigate this problem. First, we characterize the checkpointing interface in a collection of representative large machine learning/language models with respect to storage consumption and performance overhead. Second, we propose the two optimizations: i) A periodic cleaning strategy that periodically cleans up outdated checkpoints to reduce the storage burden; ii) A data staging optimization that coordinates checkpoints between local and shared file systems for performance improvement. The experimental results with GPT-2 variants show that, overall the proposed optimizations significantly reduce the storage consumption to a constant while improves performance by average 2.1\texttimes{} for checkpointing in GPT-2 training.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {896–900},
numpages = {5},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@article{10.1145/3712710,
author = {Santos, Joana Cristo and Tom\'{a}s Pereira Alexandre, Hugo and Seoane Santos, Miriam and Henriques Abreu, Pedro},
title = {The Role of Deep Learning in Medical Image Inpainting: A Systematic Review},
year = {2025},
issue_date = {July 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3712710},
doi = {10.1145/3712710},
abstract = {Image inpainting is a crucial technique in computer vision, particularly for reconstructing corrupted images. In medical imaging, it addresses issues from instrumental errors, artifacts, or human factors. The development of deep learning techniques has revolutionized image inpainting, allowing for the generation of high-level semantic information to ensure structural and textural consistency in restored images. This article presents a comprehensive review of 53 studies on deep image inpainting in medical imaging, analyzing its evolution, impact, and limitations. The findings highlight the significance of deep image inpainting in artifact removal and enhancing the performance of multi-task approaches by localizing and inpainting regions of interest. Furthermore, the study identifies magnetic resonance imaging and computed tomography as the predominant modalities and highlights generative adversarial networks and U-Net as preferred architectures. Future research directions include the development of blind inpainting techniques, the exploration of techniques suitable for 3D/4D images, multiple artifacts, and multi-task applications, and the improvement of architectures.},
journal = {ACM Trans. Comput. Healthcare},
month = may,
articleno = {30},
numpages = {24},
keywords = {Artifact, Deep Learning, Image Inpainting, Medical Imaging, Multi-Task}
}

@article{10.1145/3712303,
author = {Yoon, Hyung-Jin and Holmes, Ryan and Jafarnejadsani, Hamidreza and Voulgaris, Petros},
title = {Real-time Adversarial Image Perturbations for Autonomous Vehicles Using Reinforcement Learning},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
issn = {2378-962X},
url = {https://doi.org/10.1145/3712303},
doi = {10.1145/3712303},
abstract = {The deep neural network (DNN) model for computer vision tasks (object detection and classification) is widely used in autonomous vehicles, such as driverless cars and unmanned aerial vehicles. However, DNN models are shown to be vulnerable to adversarial image perturbations. The generation of adversarial examples against inferences of DNNs has been actively studied recently. The generation typically relies on optimizations taking an entire image frame as the decision variable. Hence, given a new image, the computationally expensive optimization needs to start over as there is no learning between the independent optimizations. Very few approaches have been developed for attacking online image streams while taking into account the underlying physical dynamics of autonomous vehicles, their mission, and the environment. The article presents a multi-level reinforcement learning framework that can effectively generate adversarial perturbations to misguide autonomous vehicles’ missions. In the existing image attack methods against autonomous vehicles, optimization steps are repeated for every image frame. This framework removes the need for fully converged optimization at every frame. Using multi-level reinforcement learning, we integrate a state estimator and a generative adversarial network that generates the adversarial perturbations. Due to the reinforcement learning agent consisting of state estimator, actor, and critic that only uses image streams, the proposed framework can misguide the vehicle to increase the adversary’s reward without knowing the states of the vehicle and the environment. Simulation studies and a robot demonstration are provided to validate the proposed framework’s performance.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = mar,
articleno = {14},
numpages = {24},
keywords = {image attack, object detection, autonomous vehicle, reinforcement learning}
}

@inproceedings{10.1145/3708359.3712147,
author = {Yuan, Jun and Miao, Kevin and Oh, Heyin and Walker, Isaac and Xue, Zhouyang and Katolikyan, Tigran and Cavallo, Marco},
title = {VibE: A Visual Analytics Workflow for Semantic Error Analysis of CVML Models at Subgroup Level},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712147},
doi = {10.1145/3708359.3712147},
abstract = {Effective error analysis is critical for the successful development and deployment of CVML models. One approach to understanding model errors is to summarize the common characteristics of error samples. This can be particularly challenging in tasks that utilize unstructured, complex data such as images, where patterns are not always obvious. Another method is to analyze error distributions across pre-defined categories, which requires analysts to hypothesize about potential error causes in advance. Forming such hypotheses without access to explicit labels or annotations makes it difficult to isolate meaningful subgroups or patterns, however, as analysts must rely on manual inspection, prior expertise, or intuition. This lack of structured guidance can hinder a comprehensive understanding of where models fail. To address these challenges, we introduce VibE, a semantic error analysis workflow designed to identify where and why computer vision and machine learning (CVML) models fail at the subgroup level, even when labels or annotations are unavailable. VibE incorporates several core features to enhance error analysis: semantic subgroup generation, semantic summarization, candidate issue proposals, semantic concept search, and interactive subgroup analysis. By leveraging large foundation models (such as CLIP and GPT-4) alongside visual analytics, VibE enables developers to semantically interpret and analyze CVML model errors. This interactive workflow helps identify errors through subgroup discovery, supports hypothesis generation with auto-generated subgroup summaries and suggested issues, and allows hypothesis validation through semantic concept search and comparative analysis. Through three diverse CVML tasks and in-depth expert interviews, we demonstrate how VibE can assist error understanding and analysis.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1529–1547},
numpages = {19},
keywords = {Semantic Error Analysis, CVML Model Debugging, Foundation Model, Visual Analytics.},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3669940.3707231,
author = {Wang, Zibo and Zhang, Yijia and Wei, Fuchun and Wang, Bingqiang and Liu, Yanlin and Hu, Zhiheng and Zhang, Jingyi and Xu, Xiaoxin and He, Jian and Wang, Xiaoliang and Dou, Wanchun and Chen, Guihai and Tian, Chen},
title = {Using Analytical Performance/Power Model and Fine-Grained DVFS to Enhance AI Accelerator Energy Efficiency},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707231},
doi = {10.1145/3669940.3707231},
abstract = {Recent advancements in deep learning have significantly increased AI processors' energy consumption, which is becoming a critical factor limiting AI development. Dynamic Voltage and Frequency Scaling (DVFS) stands as a key method in power optimization. However, due to the latency of DVFS control in AI processors, previous works typically apply DVFS control at the granularity of a program's entire duration or sub-phases, rather than at the level of AI operators.The advent of millisecond-level DVFS capabilities on the latest Ascend NPU platforms enables us to set frequency individually for single or multiple operators, opening up the opportunity for further enhancing energy efficiency through fine-grained DVFS control. To ensure performance is unaffected in DVFS, our work builds performance and power models for each operator. Through in-depth timeline analysis, we demonstrate that the cycle count of an operator can be modeled as a convex piecewise linear function of frequency, resulting in a performance model with an average error of 1.96%. Moreover, we build power models that incorporate temperature-dependent terms, which enhances the model's precision and results in an average error of 4.62%.Based on our performance and power models as well as the fine-grained DVFS functionality of Ascend NPU, we propose a DVFS strategy that integrates operator classification, preprocessing, and a genetic algorithm-based search. Experiments on applications including GPT-3 training achieve a reduction in AICore (the computing component within the Ascend NPU) power by 13.44% and NPU chip power by 4.95%, while limiting performance degradation to 1.76%.},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {1118–1132},
numpages = {15},
keywords = {ai accelerator, fine-grained dvfs, genetic algorithm, performance model, power model},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@article{10.1145/3710953,
author = {Chen, Si and Cheng, Haocong and Su, Suzy and Patterson, Stephanie and Kushalnagar, Raja and Huang, Yun and Wang, Qi},
title = {Customizing Generated Signs and Voices of AI Avatars: Deaf-Centric Mixed-Reality Design for Deaf-Hearing Communication},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3710953},
doi = {10.1145/3710953},
abstract = {This study investigates innovative interaction designs for communication and collaborative learning between learners of mixed hearing and signing abilities, leveraging advancements in mixed reality technologies like Apple Vision Pro and generative AI for animated avatars. Adopting a participatory design approach, we engaged 15 d/Deaf and hard of hearing (DHH) students to brainstorm ideas for an AI avatar with interpreting ability (sign language to English and English to sign language) that would facilitate their face-to-face communication with hearing peers. Participants envisioned the AI avatars to address some issues with human interpreters, such as lack of availability, and provide affordable options to expensive personalized interpreting services. Our findings indicate a range of preferences for integrating the AI avatars with actual human figures of both DHH and hearing communication partners. The participants highlighted the importance of having control over customizing the AI avatar, such as AI-generated signs, voices, facial expressions, and their synchronization for enhanced emotional display in communication. Based on our findings, we propose a suite of design recommendations that balance respecting sign language norms with adherence to hearing social norms. Our study offers insights into improving the authenticity of generative AI in scenarios involving specific and sometimes unfamiliar social norms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW055},
numpages = {31},
keywords = {american sign language, facial expressions, interpreter, multi-modality, voice generation}
}

@inproceedings{10.5555/3709347.3743578,
author = {Djenouri, Youcef and Belmecheri, Nassim and Michalak, Tomasz and Dubi\'{n}ski, Jan and Belbachir, Ahmed Nabil and Yazidi, Anis},
title = {Learning Graph Representation of Agent Diffusers},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Diffusion-based generative models have significantly advanced text-to-image synthesis, demonstrating impressive text comprehension and zero-shot generalization. These models refine images from random noise based on textual prompts, with initial reliance on text input shifting towards enhanced visual fidelity over time. This transition suggests that static model parameters might not optimally address the distinct phases of generation. We introduce LGR-AD (Learning Graph Representation of Agent Diffusers), a novel multi-agent system designed to improve adaptability in dynamic computer vision tasks. LGR-AD models the generation process as a distributed system of interacting agents, each representing an expert sub-model. These agents dynamically adapt to varying conditions and collaborate through a graph neural network that encodes their relationships and performance metrics. Our approach employs a coordination mechanism based on top-k maximum spanning trees, optimizing the generation process. Each agent's decision-making is guided by a meta-model that minimizes a novel loss function, balancing accuracy and diversity. Theoretical analysis and extensive empirical evaluations show that LGR-AD outperforms traditional diffusion models across various benchmarks, highlighting its potential for scalable and flexible solutions in complex image generation tasks. Code can be found at: https://github.com/YousIA/LGR_AD.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {620–629},
numpages = {10},
keywords = {collaborative frameworks, graph representations of agents, text to image generation},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3708036.3708139,
author = {Su, Xiaowen},
title = {Exploration and Real-time Rendering Optimization Path Using Deep Learning Methods},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708139},
doi = {10.1145/3708036.3708139},
abstract = {With the continuous development of computer graphics, real- time rendering is increasingly being used in multimedia, virtual reality, and game development. How to improve rendering efficiency and quality is an important way to improve rendering effects, but current rendering methods often encounter performance bottlenecks when rendering complex scenes . In response to the above issues, this paper intends to use deep learning methods to study real-time rendering algorithms based on deep learning. This paper intends to use GAN (Generative Adversarial Networks) technology to automatically generate optimal graphics resources from the training model, thereby shortening rendering time, improving rendering quality, modeling rendering data in different scenes, and significantly reducing rendering costs while ensuring rendering effects. This paper can study an adaptive learning and adjustment mechanism that can dynamically adjust rendering parameters in different software and hardware environments to achieve better results. In Scenario 1, the SSIM (Structural Similarity) of the traditional method is 0.80, while the GAN method is improved to 0.88. The research results of this paper can provide new ideas and methods for optimizing real- time rendering technology.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {606–610},
numpages = {5},
keywords = {Deep Learning Methods, GAN Technology, Optimized Paths, Real-time Rendering},
location = {
},
series = {ICCSMT '24}
}

@article{10.1145/3728479,
author = {Mazumdar, Eric and Sastry, S. Shankar and Jordan, Michael I.},
title = {On Finding Local Nash Equilibria (and only Local Nash Equilibria) in Zero-Sum Games},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3728479},
doi = {10.1145/3728479},
abstract = {We propose local symplectic surgery, a two-timescale procedure for finding local Nash equilibria in two-player zero-sum games. We first show that previous gradient-based algorithms cannot guarantee convergence to local Nash equilibria due to the existence of non-Nash stationary points. By taking advantage of the differential structure of the game, we construct an algorithm for which the local Nash equilibria are the only attracting fixed points. Further, we show that the algorithm exhibits no oscillatory behavior in neighborhoods of equilibria and that it has the same per-iteration complexity as other recently proposed algorithms. Furthermore we give convergence rates in structured classes of zero-sum games. We conclude by validating the algorithm on two numerical examples: a toy example with multiple Nash equilibria and a non-Nash equilibrium, and the training of a small generative adversarial network (GAN).Problem statementWe study the problem of computing a (local) Nash equilibrium in non-convex non-concave zero-sum games, i.e., saddle point problems. The majority of work on solving this class of optimization problems makes strong assumptions on the curvature of the underlying functions and consequently the algorithms tend to fail when deployed in unstructured settings like the training of generative adversarial networks.MethodsWe present a new gradient-based algorithm for finding the local Nash equilibria of two-player zero-sum games: local symplectic surgery. Our algorithm makes essential use of the underlying structure of zero-sum games. To derive our algorithm, we work in continuous time-via an ordinary differential equation (ODE)-and our algorithm is obtained via a discretization of the ODE.  While a naive discretization would require a matrix inversion and would be computationally burdensome, our discretization is a two-timescale discretization that avoids matrix inversion entirely and is of a similar computational complexity as that of other gradient-based algorithms.ResultsWe show how-by design- our proposed algorithm overcomes many of the challenges faced by existing methods for computing local Nash equilibria of non-convex non-concave zero-sum games. In particular we
prove that the only stationary points to which the algorithm can converge are local Nash equilibria and further that it cannot exhibit oscillations around equilibrium points-two properties that existing methods fail to guarantee. Furthermore we show numerically  that our algorithm scales gracefully to complex problems like the training of generative adversarial networks and exhibits more stable behavior than existing methods.SignificanceThis paper focuses on the problem of computing solutions to a non-convex non-concave min-max problems that have particular second-order structure: that of a local Nash equilibrium. We show that existing methods for computing saddle points in such games have no guarantees over the types of solutions they converge to-potentially yielding undesired solutions. To overcome this, we propose a new algorithm-local symplectic surgery- which has strong convergence guarantees even in the unstructured settings that often arise in deep learning. Altogether, our insights and algorithms highlight important new problems and present initial solutions to an important problems in an increasingly important subfield of optimization in machine learning.},
note = {Just Accepted},
journal = {ACM / IMS J. Data Sci.},
month = may
}

@article{10.1145/3718487,
author = {Sharma, Harsh and Dhingra, Pratyush and Doppa, Jana and Ogras, Umit and Pande, Partha Pratim},
title = {A Heterogeneous Chiplet Architecture for Accelerating End-to-End Transformer Models},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {3},
issn = {1084-4309},
url = {https://doi.org/10.1145/3718487},
doi = {10.1145/3718487},
abstract = {Transformers have revolutionized deep learning and generative modeling, enabling advancements in natural language processing tasks. However, the size of transformer models is increasing continuously, driven by enhanced capabilities across various deep learning tasks. This trend of ever-increasing model size has given rise to new challenges in terms of memory and compute requirements. Conventional computing platforms, including GPUs, suffer from suboptimal performance due to the memory demands imposed by models with millions/billions of parameters. The emerging chiplet-based platforms provide a new avenue for compute- and data-intensive machine learning applications enabled by a Network-on-Interposer (NoI). However, designing suitable hardware accelerators for executing Transformer inference workloads is challenging due to a wide variety of complex computing kernels in the Transformer architecture. In this article, we leverage chiplet-based heterogeneous integration to design a high-performance and energy-efficient multichiplet platform to accelerate transformer workloads. We demonstrate that the proposed NoI architecture caters to the data access patterns inherent in a transformer model. The optimized placement of the chiplets and the associated NoI links and routers enable superior performance compared to the state-of-the-art hardware accelerators. The proposed NoI-based architecture demonstrates scalability across varying transformer models and improves latency and energy efficiency by up to 11.8\texttimes{} and 2.36\texttimes{}, respectively when compared with the existing state-of-the-art architecture HAIMA.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = apr,
articleno = {41},
numpages = {24},
keywords = {Large manycore systems, machine learning, thermal-aware}
}

@inproceedings{10.1145/3729605.3729646,
author = {Gu, Xiu and Yuan, Tianyi},
title = {An Empirical Study on AI-Driven Text Mining for Graduate Thesis Quality Management in Higher Education},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729646},
doi = {10.1145/3729605.3729646},
abstract = {In recent years, artificial intelligence(AI) technology has developed rapidly and is widely used in various educational scenarios and administrative management in the field of higher education. This paper takes Text-Mining process of blind review comments of master's theses from a university as an example to explore the application effectiveness of AI technology in the quality management of master's thesis. Through empirical research, it provides a case reference for the application of AI in higher education management and a replicable integration program for similar institutions. This study used a three- phase approach to analyse blind review comments, namely independent use of AI (ChatGPT), independent use of traditional text analysis tools (NVIVO), and collaborative analysis combining the two. It was found that despite the significant advantages of AI in terms of processing speed and scale, the AI's output highly depends on the user's prompts and pre-training. Moreover, human intervention was critical to the stability and accuracy of AI's output.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {232–236},
numpages = {5},
keywords = {Artificial intelligence(AI), Blind review comments, Higher education, Thesis quality management},
location = {
},
series = {ICBDIE '25}
}

@article{10.1145/3733106,
author = {Li, Yuxin and Nie, Jiangtian and Li, Shaobo and Jin, Kebing and Tang, Jianhang and Zhang, Yang and Niyato, Dusit},
title = {Intermediary Output Caching for Diffusion Model-Based Text-to-Image GenAI Services in Edge Computing Networks},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1539-9087},
url = {https://doi.org/10.1145/3733106},
doi = {10.1145/3733106},
abstract = {The remarkable advancement of generative artificial intelligence (GenAI) has driven revolutionary applications for text-to-image generation, like Stable Diffusion and Imagen. Especially, the diffusion model can generate stunning images from natural language descriptions by using a reverse continuous denoising process. However, the computation burden of diffusion model-based GenAI services poses a significant hurdle for their practical implementation. In this work, we propose a novel edge computing-assisted GenAI framework to enable efficient GenAI service provision, where the intermediate output generated by diffusion models can be cached on edge servers and reused by various users to improve edge computing resource utilization. Assuming the existence of causally correlated auxiliary information, a long-term caching problem is formulated under intra-time-slot caching constraints by considering various maximally reusable steps of diffusion model-based GenAI tasks and the available caching capacity at edge servers. By leveraging the Lyapunov optimization framework, we transform the time-average caching problem into several deterministic problems for different time slots. We develop a deep reinforcement learning-based caching (DRC) algorithm to obtain caching decisions in each time slot, where a deep neural network (DNN)-based caching action generation module and a model-based evaluation module are designed. Finally, we conduct extensive simulation experiments by comparing the DRC algorithm with benchmark algorithms. The simulation results depict that the proposed DRC algorithm can reduce response time and improve cache hit rates significantly. The code is available at https://gitee.com/pipihinsky/DRC.},
note = {Just Accepted},
journal = {ACM Trans. Embed. Comput. Syst.},
month = apr,
keywords = {GenAI services, diffusion model, intermediary output caching, edge computing}
}

@inproceedings{10.5555/3712729.3712783,
author = {Abhari, Abdolreza},
title = {Towards New Simulation Models for DL-Based Video Streaming in Edge Networks},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {To evaluate novel solutions for edge computing systems, suitable distribution models for simulation are essential. The extensive use of deep learning (DL) in video analytics has altered traffic patterns on edge and cloud servers, necessitating innovative models. Queuing models are used to simulate the performance and stability of edge-enabled systems, particularly video streaming applications. This paper demonstrates that traditional Markovian M/M/s and general distribution G/G/s queuing models must be revamped for accurate simulation. We examined these queuing models by characterizing the real data with discrete and continuous distributions for arrival rates to homogenous servers in AI-based video analytics edge systems. Based on achieved results, traditional methods for finding general distributions are inadequate, and an automation method for finding empirical distribution is needed. Therefore, we introduce a novel approach using a generative adversarial network (WGAN) to generate artificial data to automate the process of estimating empirical distribution for modeling these applications.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {656–665},
numpages = {10},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3690624.3709313,
author = {Zhu, Ruitao and Liu, Yangsu and Chen, Dagui and Ma, Zhenjia and Shi, Chufeng and Zheng, Zhenzhe and Zhang, Jie and Xu, Jian and Zheng, Bo and Wu, Fan},
title = {Contextual Generative Auction with Permutation-level Externalities for Online Advertising},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709313},
doi = {10.1145/3690624.3709313},
abstract = {Online advertising has become a core revenue driver for internet industry, with ad auctions playing a crucial role in ensuring platform revenue and advertiser incentives. Classical auction mechanisms, such as GSP, rely on the independent CTR assumption and fail to account for the interplay among the displayed items, also called as externalities in economics. Recent advancements in learning-based auctions enable the encoding of high-dimensional contextual features. However, existing methods are limited by the ''prediction-before-allocation'' design paradigm, which models set-level externalities within candidate ads and fails to consider the context of the final allocation, leading to suboptimal results. In this work, we introduce Contextual Generative Auction (CGA), a novel framework that incorporates permutation-level externalities in multi-slot ad auctions. Built on the structure of our theoretically derived optimal auction, CGA decouples the optimization of allocation and payment. We construct an autoregressive generative model for allocation, and reformulate incentive compatibility (IC) constraint into minimizing ex-post regret that supports gradient computation, enabling end-to-end learning of the optimal payment rule. Extensive offline and online experiments demonstrate that CGA significantly enhances platform revenue and CTR compared to existing methods, and effectively approximates the optimal auction with nearly maximal revenue and minimal regret.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {2171–2181},
numpages = {11},
keywords = {externalities, generative auction, learning-based auction design},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inbook{10.1145/3658617.3697648,
author = {Ali, Asmer Hamid and Zhang, Fan and Yang, Li and Fan, Deliang},
title = {Learning to Prune and Low-Rank Adaptation for Compact Language Model Deployment},
year = {2025},
isbn = {9798400706356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658617.3697648},
abstract = {Nowadays, parameter-efficient fine-tuning (PEFT) large pre-trained models (LPMs) for downstream task have gained significant popularity, since it could significantly minimize the training computational overhead. The representative work, LoRA [1], learns a low-rank adaptor for a new downstream task, rather than fine-tuning the whole backbone model. However, for inference, the large size of the learned model remains unchanged, leading to in-efficient inference computation. To mitigate this, in this work, we are the first to propose a learning-to-prune methodology specially designed for fine-tuning downstream tasks based on LPMs with low-rank adaptation. Unlike prior low-rank adaptation approaches that only learn the low-rank adaptors for downstream tasks, our method further leverages the Gumbel-Sigmoid tricks to learn a set of trainable binary channel-wise masks that automatically prune the backbone LPMs. Therefore, our method could leverage the benefits of low-rank adaptation to reduce the training parameters size and smaller pruned backbone LPM size for efficient inference computation. Extensive experiments show that the Pruned-RoBbase model with our method achieves an average channel-wise structured pruning ratio of 24.5% across the popular GLUE Benchmark, coupled with an average of 18% inference time speed-up in real NVIDIA A5000 GPU. The Pruned-DistilBERT shows an average of 13% inference time improvement with 17% sparsity. The Pruned-LLaMA-7B model achieves up to 18.2% inference time improvement with 24.5% sparsity, demonstrating the effectiveness of our learnable pruning approach across different models and tasks.},
booktitle = {Proceedings of the 30th Asia and South Pacific Design Automation Conference},
pages = {36–42},
numpages = {7}
}

@article{10.1145/3733597,
author = {Wang, Tairan and Chen, Xiuying and Zhu, Qingqing and Guo, Taicheng and Gao, Shen and Lu, Zhiyong and Gao, Xin and Zhang, Xiangliang},
title = {New Paradigm for Evaluating Scholar Summaries: A Facet-aware Metric and A Meta-evaluation Benchmark},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3733597},
doi = {10.1145/3733597},
abstract = {Evaluation of summary quality is particularly crucial within the scientific domain, because it facilitates efficient knowledge dissemination and automated scientific information retrieval. This paper presents conceptual and experimental analyses of scientific summarization, highlighting the inadequacies of traditional evaluation methods. These methods, including  (n) -gram overlap calculations, embedding comparisons, verification, and QA-based approaches, often fall short in providing explanations, grasping scientific concepts, or identifying key content. Correspondingly, we introduce the Facet-aware Metric (FM), employing LLMs for advanced semantic matching to evaluate summaries based on different facets. The facet granularity is tailored to the structure of scientific abstracts, offering an integrated evaluation approach that is not fragmented, while also providing fine-grained interpretability. Recognizing the absence of an evaluation benchmark in the scientific domain, we curate a Scientific abstract summary evaluation Dataset (ScholarSum) with facet-level annotations. Our findings confirm that FM offers a more logical approach to evaluating scientific summaries. In addition, fine-tuned smaller models can compete with LLMs in scientific contexts, while LLMs have limitations in learning from in-context information in scientific domains. We hope our benchmark inspires better evaluation metrics and future enhancements to LLMs: .},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = may
}

@inproceedings{10.1145/3703619.3706049,
author = {Casas, Llogari and Mitchell, Kenny},
title = {Structured Teaching Prompt Articulation for Generative-AI Role Embodiment with Augmented Mirror Video Displays},
year = {2025},
isbn = {9798400713484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703619.3706049},
doi = {10.1145/3703619.3706049},
abstract = {We present a classroom enhanced with augmented reality video display in which students adopt snapshots of their corresponding virtual personas according to their teacher’s live articulated spoken educational theme, linearly, such as historical figures, famous scientists, cultural icons, and laterally according to archetypal categories such as world dance styles. We define a structure of generative AI prompt guidance to assist teachers with focused specified visual role embodiment stylization. By leveraging role-based immersive embodiment, our proposed approach enriches pedagogical practices that prioritize experiential learning.},
booktitle = {Proceedings of the 19th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {15},
numpages = {7},
keywords = {Artificial Intelligence, Generative AI, Human-Computer Interaction, Virtual Reality},
location = {Nanjing, Guangdong Province, China},
series = {VRCAI '24}
}

@inproceedings{10.1145/3641555.3705242,
author = {Caraco, Serena and Fabros, Melissa and Lojo, Nelson and Fox, Armando},
title = {Scaffolding Collaborative Software Design with Serious Games},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705242},
doi = {10.1145/3641555.3705242},
abstract = {An application's architecture is frequently refactored after deployment to accommodate its users' evolving needs. However, we currently lack a repeatable, consistent method to teach high-level collaborative design skills. Drawing on the serious play framework, we advance an existing analog exercise for scaffolding collaborative design using a new system: the LLM-managed application overview. From an instructor prompt, the system generates an overview detailing an entire application using CRC cards -- common industry design aids that forego any code or implementation detail. Students individually edit the cards to redesign the application's architecture, while the system simulates the effects of these edits by updating emulated code metrics and estimating redesign cost. Returning to their teams, students discuss the cost and complexity of their designs before selecting and refining a single solution. By the activity's end, the students will have practiced all the design skills necessary for a months-long cycle of development, without the students or the instructor manually managing any implementation details.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1405–1406},
numpages = {2},
keywords = {collaborative design, collaborative learning, serious play, teaching software design},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716554.3716615,
author = {Papageorgiou, Elpiniki and Feleki, Anna and Papandrianos, Nikolaos and Apostolopoulos, Ioannis and Papageorgiou, Konstantinos and Papathanasiou, Nikolaos and Apostolopoulos, Dimitrios},
title = {Multimodal Diagnosis using Deep Fuzzy Cognitive Map with Extreme Learning Machine Integrated into a Medical Decision Support System for Coronary Artery Disease and Non-Small Cell Lung Cancer Detection},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716615},
doi = {10.1145/3716554.3716615},
abstract = {Early detection of Coronary Artery Disease (CAD) and Non-Small Cell Lung Cancer (NSCLC) is crucial for improving patient outcomes. In this study, RGB-CNN (Convolutional Neural Network) was implemented, and trained from scratch using Polar Maps for CAD diagnosis and Computed Tomography (CT) images for NSCLC diagnosis. The CNN predictions were then integrated with clinical data into a Fuzzy Cognitive Map (FCM) classifier for each type of diagnosis. Nuclear medicine experts provided linguistic values in the form of fuzzy sets to define the relationships between input and output concepts, which were later converted into interval values. Extreme Learning Machine (ELM) and Genetic Algorithm (GA) were applied to the FCM learning process to refine the interconnections based on expert knowledge. To ensure the robustness of the results, 10-fold cross-validation was employed. The DeepFCM-ELM model demonstrated superior performance, achieving 80.4%±4.97% accuracy for CAD diagnosis, and 91.9%±3.07% for NSCLC diagnosis using CT images. Heatmaps were generated to interpret CNN predictions by highlighting pathological regions. These heatmaps were then used in GPT, along with DeepFCM weights, CNN, and DeepFCM prediction and input clinical values, employing Natural Language Generation to translate DeepFCM results into human-readable language, enhancing the model's overall explainability. All these techniques have been integrated into a Medical Decision Support System (MDSS) designed to effectively manage both medical classification challenges.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {400–406},
numpages = {7},
keywords = {Convolutional neural networks, Coronary artery disease, Medical classification, Non-small cell lung cancer},
location = {
},
series = {PCI '24}
}

@inproceedings{10.1145/3669940.3707219,
author = {Jain, Anirudh and Gupta, Pulkit and Conte, Thomas M.},
title = {RASSM: Residue-based Acceleration of Single Sparse Matrix Computation via Adaptive Tiling},
year = {2025},
isbn = {9798400706981},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669940.3707219},
doi = {10.1145/3669940.3707219},
abstract = {Single-Sparse-Matrix Kernels (SSMKs) such as SpMM, SDDMM, SpMV, and SpTS form the backbone of applications such as data analytics, graph processing, finite-element analysis, machine learning (including GNNs and LLMs), etc. This paper introduces Residue-based Acceleration of Single Sparse Matrix Computation via Adaptive Tiling (RASSM), an input-dependent, adaptive 2-dimensional tiling technique for SSMKs. The adaptation leverages the concept of a residue matrix: a data structure that compactly captures the pattern of non-zeros in the sparse matrix. With residues, we show it is possible to make intelligent decisions on adaptive tile sizes, resulting in increased cache occupancy. Residues allow for optimizations across both spatial and temporal locality.RASSM improves data movement and overall performance as compared to prior techniques. For example, using spatial analysis for SpMM on commodity server CPUs, RASSM has 1.30X speedup over MKL, 1.32X over J-Stream, 1.20X over ASpT, 1.11X over CSF-4 uniform-shape, and 1.10X over CSF-4 uniform-occupancy. RASSM with temporal analysis improves this to 1.36X (vs. MKL), 1.38X (vs. J-Stream), 1.26X (vs. ASpT), 1.17X (vs. CSF-4 uniform-shape), and 1.16X (vs. CSF-4 uniform-occupancy).},
booktitle = {Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 1},
pages = {907–923},
numpages = {17},
keywords = {auto-tiling, caching, multicore, sddmm, sparse computations, sparse matrix, sparse signatures, spmm},
location = {Rotterdam, Netherlands},
series = {ASPLOS '25}
}

@inproceedings{10.1145/3703001.3724386,
author = {Orland, Fabian and Nista, Ludovico and Kocher, Nick and Vanvinckenroye, Joris and Pitsch, Heinz and Terboven, Christian},
title = {Efficient and Scalable AIxeleration of Reactive CFD Solvers Coupled with Deep Learning Inference on Heterogeneous Architectures},
year = {2025},
isbn = {9798400713422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703001.3724386},
doi = {10.1145/3703001.3724386},
abstract = {The convergence of high-performance computing (HPC) and artificial intelligence (AI) is transforming numerical simulations across various scientific domains. In reactive flow simulations, deep learning (DL) techniques, are emerging as promising alternatives to traditional closure models in large eddy simulations (LES). Although a priori investigations –where models are tested on pre-existing datasets – have demonstrated remarkable performance, a posteriori investigations – which assess model behavior within a running simulation – remain crucial to ensuring stability and accuracy. To bridge this gap, seamless integration between computational fluid dynamics (CFD) solvers and widely used DL frameworks, such as PyTorch or TensorFlow is required. However, traditional CFD solvers are highly optimized for CPU execution, whereas DL inference benefits from acceleration on GPUs or other specialized hardware. This architectural mismatch presents a significant challenge in efficiently leveraging modern heterogeneous HPC platforms.To address this issue, we introduce AIxeleratorService, an open-source C++ library designed to enable efficient deployment of DL models within highly parallel CFD solvers running on heterogeneous architectures. Additionally, we present a Fortran ML module that integrates AIxeleratorService, providing users of Fortran-based CFD solvers with a streamlined, end-to-end workflow for incorporating trained DL architectures into their simulations. We validate our approach by coupling AIxeleratorService with our in-house CFD solver, CIAO, and applying it to two LES configurations. In one, a super-resolution generative adversarial network (SRGAN) reconstructs the unresolved Reynolds stresses tensor to correctly account for the momentum energy transport. On the other, a UNet-type architecture computes the source term of the progress variable equation, which is essential for accurately describing the chemical reaction rate and flame propagation in turbulent combustion. To evaluate computational performance and scalability, we benchmark AIxeleratorService against the existing PhyDLL library on a heterogeneous HPC system comprising Intel Sapphire Rapids CPUs and NVIDIA H100 GPUs. Our results demonstrate that AIxeleratorService achieves superior computational efficiency and scalability, highlighting its potential for accelerating large-scale, AI-enhanced reactive flow simulations.},
booktitle = {Proceedings of the 2025 International Conference on High Performance Computing in Asia-Pacific Region Workshops},
pages = {45–57},
numpages = {13},
keywords = {CFD, reactive flows, heterogeneous architectures, coupling, TensorFlow, super-resolution, GAN, UNet, PhyDLL, AIxeleratorService},
location = {
},
series = {HPC Asia '25 Workshops}
}

@inproceedings{10.1109/DAC56929.2023.10248009,
author = {Wang, Zixiao and Shen, Yunheng and Zhao, Wenqian and Bai, Yang and Chen, Guojin and Farnia, Farzan and Yu, Bei},
title = {DiffPattern: Layout Pattern Generation via Discrete Diffusion},
year = {2025},
isbn = {9798350323481},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DAC56929.2023.10248009},
doi = {10.1109/DAC56929.2023.10248009},
abstract = {Deep generative models dominate the existing literature in layout pattern generation. However, leaving the guarantee of legality to an inexplicable neural network could be problematic in several applications. In this paper, we propose DiffPattern to generate reliable layout patterns. DiffPattern introduces a novel diverse topology generation method via a discrete diffusion model with compute-efficiently lossless layout pattern representation. Then a white-box pattern assessment is utilized to generate legal patterns given desired design rules. Our experiments on several benchmark settings show that DiffPattern significantly outperforms existing baselines and is capable of synthesizing reliable layout patterns.},
booktitle = {Proceedings of the 60th Annual ACM/IEEE Design Automation Conference},
pages = {1–6},
numpages = {6},
location = {San Francisco, California, United States},
series = {DAC '23}
}

@inproceedings{10.1145/3703790.3703840,
author = {Shi, Yichen and Zhou, Tianlong and Yin, Peiyuan and Wang, Zhongyu and Mao, Zhaojun and Rao, Weixiong},
title = {Road Network-based Vehicle Trajectory Imputation via Generative Adversarial Network},
year = {2025},
isbn = {9798400712852},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703790.3703840},
doi = {10.1145/3703790.3703840},
abstract = {Dense trajectories are important to many location-based service (LBS) applications, e.g., traffic prediction. Existing works often fail to ensure that imputed vehicle trajectories perfectly align with road networks. The two-stage approach involving first trajectory imputation and next map-matching suffers from high computation cost and may not leverage the inherent relationship between trajectories data and road networks. To address the issue, in this paper, we develop a generative adversarial networks (GAN)-based imputation framework by leveraging road networks to fill missing points, and train the GAN model by policy-based reinforcement learning (RL) for better integrity and accuracy. Our preliminary evaluation on two real datasets demonstrates that our work outperforms state-of-the-art with better effectiveness and efficiency.},
booktitle = {Proceedings of the 14th International Conference on the Internet of Things},
pages = {176–179},
numpages = {4},
location = {
},
series = {IoT '24}
}

@inproceedings{10.1145/3723498.3723843,
author = {Sfikas, Konstantinos and Liapis, Antonios and Yannakakis, Georgios N.},
title = {Diverse Level Generation via Machine Learning of Quality Diversity},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723843},
doi = {10.1145/3723498.3723843},
abstract = {Can we replicate the power of evolutionary algorithms in discovering good and diverse game content via generative machine learning (ML) techniques? This question could subvert current trends in procedural content generation (PCG) and beyond. By learning the behavior of quality-diversity (QD) evolutionary algorithms through ML, we stand to overcome the computational challenges inherent in QD search and ensure that the benefits of QD search are reproduced by efficient generative models. We introduce a novel, end-to-end methodology named Machine Learning of Quality Diversity (MLQD) which is executed in two steps. First, tailored QD evolution creates large and diverse training datasets from the ground up. Second, sophisticated ML architectures such as the Transformer learn the datasets’ underlying distributions, resulting in generative models that can emulate QD search via stochastic inference. We test MLQD on the use-case of generating strategy game map sketches, a task characterized by stringent constraints and a multidimensional feature space. Our findings are promising, demonstrating that the Transformer architecture can capture both the diversity and the quality traits of the training sets, successfully reproducing the behavior of a range of tested QD algorithms. This marks a significant advancement in our quest to automate the creation of high-quality, diverse game content, pushing the boundaries of what is possible in PCG and generative AI at large.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {67},
numpages = {10},
keywords = {Procedural content generation, machine learning, novelty search, quality diversity, strategy maps},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3722573.3727827,
author = {Williams, Nathan B. and Sung, Woong Je and Ramamurthy, Arun and Jin, Hyunjee and Mavris, Dimitri},
title = {From Toy to Target: Investigating Representation Transfer for Reinforcement Learning with Implications for Cyber-Physical Systems},
year = {2025},
isbn = {9798400716041},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722573.3727827},
doi = {10.1145/3722573.3727827},
abstract = {As Cyber-Physical Systems (CPS) become more common and more complex, training reinforcement learning (RL) agents to perform well in these large-scale environments remains both challenging and computationally expensive. This paper proposes the Toy Transfer Method (TTM) as a potential approach for leveraging knowledge acquired in small-scale toy environments to expedite agent learning in larger environments. The key idea is that an RL agent trained in a well-structured toy environment may learn useful representations that can be transferred to a more complex target environment, expediting training and improving agent efficacy. The Toy Transfer Method is evaluated using OpenAI's Taxi environment as a case study, transferring knowledge from a 5x5 grid world to multiple 7x7 grid worlds with a roughly twice as large state space. The results demonstrate that the TTM-enhanced Deep Q-Network (DQN) agent consistently outperforms a baseline DQN agent trained from scratch, achieving faster convergence and higher average rewards. Furthermore, the TTM-enhanced agent often leads to convergence in cases where the baseline agent fails to converge to a successful policy. These results suggest that environment abstraction and transfer learning may be viable strategies for improving RL efficiency in CPS, especially when the toy and target environments are structurally similar.},
booktitle = {Proceedings of the 7th Workshop on Design Automation for CPS and IoT},
articleno = {2},
numpages = {10},
keywords = {Reinforcement Learning, Representation Transfer, Transfer Learning},
location = {Irvine, CA, USA},
series = {DESTION '25}
}

@article{10.1145/3731754,
author = {Zhong, Renyi and Li, Yichen and Kuang, Jinxi and Gu, Wenwei and Huo, Yintong and Lyu, Michael R.},
title = {LogUpdater: Automated Detection and Repair of Specific Defects in Logging Statements},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3731754},
doi = {10.1145/3731754},
abstract = {Developers write logging statements to monitor software runtime behaviors and system state. However, poorly constructed or misleading log messages can inadvertently obfuscate actual program execution patterns, thereby impeding effective software maintenance. Existing research on analyzing issues within logging statements is limited, primarily focusing on detecting a singular type of defect and relying on manual intervention for fixes rather than automated solutions.To address the limitation, we initiate a systematic study that pinpoints four specific types of defects in logging statements (i.e., statement code inconsistency, static dynamic inconsistency, temporal relation inconsistency, and readability issues) through the analysis of real-world log-centric changes. We then propose LogUpdater, a two-stage framework for automatically detecting and updating logging statements for these specific defects. In the offline stage, LogUpdater constructs a similarity-based classifier on a set of synthetic defective logging statements to identify specific defect types. During the online testing phase, this classifier first evaluates logging statements in a given code snippet to determine the necessity and type of improvements required. Then, LogUpdater constructs type-aware prompts from historical logging update changes for an LLM-based recommendation framework to suggest updates addressing these specific defects.We evaluate the effectiveness of LogUpdater on a dataset containing real-world logging changes, a synthetic dataset, and a new real-world project dataset. The results indicate that our approach is highly effective in detecting logging defects, achieving an F1 score of 0.625. Additionally, it exhibits significant improvements in suggesting precise static text and dynamic variables, with enhancements of 48.12% and 24.90%, respectively. Furthermore, LogUpdater achieves a 61.49% success rate in recommending correct updates on new real-world projects. We reported 40 problematic logging statements and their fixes to GitHub via pull requests, resulting in 25 changes confirmed and merged across 11 different projects.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
keywords = {Logging Statement, Logging Practice, Large Language Model}
}

@inproceedings{10.1145/3705754.3705772,
author = {Qu, Zhaoyang},
title = {Research on Anomaly Detection Method for Telecom Services Based on Improved Autoencoder and Generative Adversarial Network},
year = {2025},
isbn = {9798400710193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3705754.3705772},
doi = {10.1145/3705754.3705772},
abstract = {In the telecommunications industry, abnormal data caused by systems or services can lead to customer churn, hindering the development of telecom services. To address the collection and analysis of such abnormal data, our proposed a framework based on Autoencoder (AE) and Conditional Generative Adversarial Network (CGAN). Firstly, multiple service data tables are collected and associated using the Spark to obtain the dataset. Secondly, the autoencoder reconstructs the original data, calculates the reconstruction error, and extracts the potential features of the reduced dimensionality sequence. Then, the generative adversarial network performs anomaly detection and records the reconstruction error. Finally, we adopt the idea of ensemble learning and combine the reconstruction errors of the autoencoder and the adversarial generative network as the anomaly discrimination criterion. Experiments demonstrate that the proposed AE-CGAN performs well in telecommunications data anomaly detection, accurately identifying data anomalies.},
booktitle = {Proceedings of the 2024 2nd International Conference on Electronics, Computers and Communication Technology},
pages = {101–106},
numpages = {6},
keywords = {Anomaly detection, Autoencoder, GAN, Spark,Ensemble learning, Telecom services},
location = {
},
series = {CECCT '24}
}

@inproceedings{10.1145/3715675.3715817,
author = {Artioli, Emanuele and Lorenzi, Daniele and Tashtarian, Farzad and Timmerer, Christian},
title = {Generative AI for Realistic Voice Dubbing Across Languages},
year = {2025},
isbn = {9798400714887},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715675.3715817},
doi = {10.1145/3715675.3715817},
abstract = {The demand for accessible, multilingual video content has grown significantly with the global rise of streaming platforms, social media, and online learning. The traditional solutions for making content accessible across languages include subtitles, even generated ones, as Youtube offers [1], and synthesizing voiceovers, offered for example by the Yandex Browser [2]. Subtitles are cost-effective and reflect the original voice of the speaker, which is often essential for authenticity. However, they require viewers to divide their attention between reading text and watching visuals, which can diminish engagement, especially for highly visual content. Synthesized voiceovers, on the other hand, eliminate this need by providing an auditory translation, but they typically lack the emotional depth and unique vocal characteristics of the original speaker, which can affect the viewing experience and disconnect audiences from the intended pathos of the content.A straightforward solution would involve having the original actor "perform" in every language, thereby preserving the traits that define their character or narration style. However, recording actors in multiple languages is impractical, time-intensive, and expensive, especially for widely distributed media. By leveraging generative AI, we aim to develop a client-side tool, to incorporate in a dedicated video streaming player, that combines the accessibility of multilingual dubbing with the authenticity of the original speaker's performance, effectively allowing a single actor to deliver their voice in any language. To the best of our knowledge, no current streaming system can capture the speaker's unique voice or emotional tone.Our proposed architecture, presented in Figure 1, incorporates several techniques to achieve high-quality, personalized dubbing:(1) Speaker Voice Extraction: We start by analyzing the original audio to extract the speaker's unique vocal characteristics, including their timbre, pitch, and resonance, and separate it from the background sounds. Advanced timbre analysis tools [3] help isolate these features, allowing us to recreate them across languages.(2) Emotion and Intonation Capture: The voice extraction stage is followed by capturing the emotional tone, pitch dynamics, and emphasis that the speaker conveys, leveraging emotion detection techniques commonly used in sentiment analysis [4]. This step ensures that the generated audio in the target language maintains the original affective tone.(3) Transcription and Translation: The audio is then transcribed, and the text is translated into the target language. Current machine translation models, such as OpenAI's Whisper [5] or Google Translate, serve as the basis for accurate, context-sensitive translations.(4) Generative Voice Synthesis: Then, we apply generative voice synthesis, which combines the speaker's timbre, captured emotional cues, and the translated text to produce audio that sounds as if the original speaker is fluently delivering their lines in the new language.(5) Lastly, we reintroduce the background sounds, for a complete and immersive audio experience.This approach presents two major challenges, namely (1) the synchronization between the pacing of spoken sentences and lip movements, and (2) sentences continuity across audio chunks.Addressing the first challenge requires synchronization strategies that maintain immersion by aligning spoken sentences with actors' lip movements, even when synthesized speech durations differ from the original. Yuan et al. [6] observed that languages adjust speaking speed to convey similar messages within comparable timeframes. Building on this insight, our method employs a timing adjustment that dynamically modulates speech speed by up to 40%, preserving both intelligibility and naturalness.As for the second point, in video streaming applications, content is delivered in chunks, which can interrupt sentences mid-stream. Accurate translation in such cases requires access to sentence endings that may span across chunks. Therefore, our player buffers two audio chunks in advance, translating each chunk only when the next is loaded. This approach ensures coherence by accessing full sentence context before synthesis. The player then aligns the translated audio with the original track's pacing, allowing seamless, real-time switching between audio tracks during playback.Compared to State-of-the-Art techniques, our approach offers several contributions. Unlike current solutions [7-9], our pipeline maintains the speaker's emotional tone and vocal style across languages, crucial for impactful storytelling and viewer engagement. Furthermore, it enables creators and actors to connect authentically with global audiences, meeting the demand for natural, personalized multilingual content. Lastly, integrating this pipeline in video streaming enables real-time translation, especially useful for live content, for which the classic dubbing requires interpreters to translate languages on-the-fly.},
booktitle = {Proceedings of the 4th Mile-High Video Conference},
pages = {75–76},
numpages = {2},
keywords = {Audio, Generative AI, HTTP adaptive streaming},
location = {Denver, CO, USA},
series = {MHV '25}
}

@inproceedings{10.1109/SCW63240.2024.00018,
author = {Park, David K. and Ren, Yihui and Kilic, Ozgur O. and Korchuganova, Tatiana and Vatsavai, Sairam Sri and Boudreau, Joseph and Chowdhury, Tasnuva and Feng, Shengyu and Khan, Raees and Kim, Jaehyung and Klasky, Scott and Maeno, Tadashi and Nilsson, Paul and Outschoorn, Verena Ingrid Martinez and Podhorszki, Norbert and Suter, Frederic and Yang, Wei and Yang, Yiming and Yoo, Shinjae and Klimentov, Alexei and Hoisie, Adolfy},
title = {AI Surrogate Model for Distributed Computing Workloads},
year = {2025},
isbn = {9798350355543},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SCW63240.2024.00018},
doi = {10.1109/SCW63240.2024.00018},
abstract = {Large-scale international scientific collaborations, such as ATLAS, Belle II, CMS, and DUNE, generate vast volumes of data. These experiments necessitate substantial computational power for varied tasks, including structured data processing, Monte Carlo simulations, and end-user analysis. Centralized workflow and data management systems are employed to handle these demands, but current decision-making processes for data placement and payload allocation are often heuristic and disjointed. This optimization challenge potentially could be addressed using contemporary machine learning methods, such as reinforcement learning, which, in turn, require access to extensive data and an interactive environment. Instead, we propose a generative surrogate modeling approach to address the lack of training data and concerns about privacy preservation. We have collected and processed real-world job submission records, totaling more than two million jobs through 150 days, and applied four generative models for tabular data---TVAE, CTAGGAN+, SMOTE, and TabDDPM---to these datasets, thoroughly evaluating their performance. Along with measuring the discrepancy among feature-wise distributions separately, we also evaluate pair-wise feature correlations, distance to closest record, and responses to pre-trained models. Our experiments indicate that SMOTE and TabDDPM can generate similar tabular data, almost indistinguishable from the ground truth. Yet, as a non-learning method, SMOTE ranks the lowest in privacy preservation. As a result, we conclude that the probabilistic-diffusion-model-based TabDDPM is the most suitable generative model for managing job record data.},
booktitle = {Proceedings of the SC '24 Workshops of the International Conference on High Performance Computing, Network, Storage, and Analysis},
pages = {79–86},
numpages = {8},
keywords = {AI-based Performance Modeling, Distributed Workflows, High-Performance Computing, Simulation, Surrogate Models},
location = {Atlanta, GA, USA},
series = {SC-W '24}
}

@inproceedings{10.1145/3716550.3722012,
author = {Lu, Pengyuan and Sokolsky, Oleg and Lee, Insup and Ruchkin, Ivan},
title = {Accelerating Neural Policy Repair with Preservation via Stability-Plasticity Interpolation},
year = {2025},
isbn = {9798400714986},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716550.3722012},
doi = {10.1145/3716550.3722012},
abstract = {Neural network (NN) control has been adopted widely in cyberphysical systems (CPS). When an NN-based policy fails a formally specified task, NN repair algorithms can fix it. Recent literature raises the problem of Repair with Preservation (RwP), which requires preserving existing correct behaviors while repairing the incorrect ones; a corresponding solution is given, known as Incremental Simulated Annealing Repair (ISAR). In this paper, we tackle the computational efficiency issue of ISAR, which involves expensive log-barriered objective functions and wastes computational efforts rolling back when a repaired NN breaks correct behaviors. With our analysis, we reduce the RwP problem to a stability-plasticity (S-P) trade-off interpolation problem, which has been studied in continual learning (CL). Then, we propose our method, ISAR with Interpolation (ISAR-I), which majorly improves ISAR. ISAR-I abandons the expensive log barriers and rolls back to allow intermediate policies to compromise correct behaviors for repair. Then, an interpolation of the S-P trade-off between the original NN and the intermediate NN is kicked off in the Bayesian space, searching for a final NN that both repairs and preserves. Case studies in OpenAI Gym mountain car and an unmanned underwater vehicle show that ISAR-I is able to preserve all verified trajectories while repairing 81.7% and 21.3% of the broken ones, respectively, achieving the same performance as ISAR, with runtime cost of only 6.5% and 19.6%, on average. Source code: https://github.com/ericlupy/isar_interpolation},
booktitle = {Proceedings of the ACM/IEEE 16th International Conference on Cyber-Physical Systems (with CPS-IoT Week 2025)},
articleno = {29},
numpages = {12},
keywords = {Control policy repair, continual learning, neural network repair, stability-plasticity trade-off},
location = {Irvine, CA, USA},
series = {ICCPS '25}
}

@inproceedings{10.1145/3712678.3721881,
author = {Artioli, Emanuele and Tashtarian, Farzad and Timmerer, Christian},
title = {End-to-End Learning-based Video Streaming Enhancement Pipeline: A Generative AI Approach},
year = {2025},
isbn = {9798400714696},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712678.3721881},
doi = {10.1145/3712678.3721881},
abstract = {The primary challenge of video streaming is to balance high video quality with smooth playback. Traditional codecs are well tuned for this trade-off, yet their inability to use context means they must encode the entire video data and transmit it to the client. This paper introduces ELVIS (End-to-end Learning-based VIdeo Streaming Enhancement Pipeline), an end-to-end architecture that combines server-side encoding optimizations with client-side generative in-painting to remove and reconstruct redundant video data. Its modular design allows ELVIS to integrate different codecs, in-painting models, and quality metrics, making it adaptable to future innovations. Our results show that current technologies achieve improvements of up to 11 VMAF points over baseline benchmarks, though challenges remain for real-time applications due to computational demands. ELVIS represents a foundational step toward incorporating generative AI into video streaming pipelines, enabling higher quality experiences without increased bandwidth requirements.},
booktitle = {Proceedings of the 35th Workshop on Network and Operating System Support for Digital Audio and Video},
pages = {50–56},
numpages = {7},
keywords = {End-to-end architecture, Generative AI, HTTP adaptive streaming, Quality of Experience},
location = {Stellenbosch, South Africa},
series = {NOSSDAV '25}
}

@inproceedings{10.1145/3706598.3713529,
author = {Page, Rowan and See, Jian Shin},
title = {Creative Reflections on Image-Making with Artificial Intelligence: Interactions with a Provocative 'Camera'},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713529},
doi = {10.1145/3706598.3713529},
abstract = {Cameras are increasingly augmented with computational processing, producing images that blur the line between documenting reality and creative expression. The rise of text-to-image models has redefined the concept of imagery, sparking ethical and philosophical debates. This paper presents the findings of a qualitative study that employed a provocative prototype ‘camera’ – the A(I)Cam – to engage creative practitioners directly in these discussions. Developed using a Research-through-Design (RtD) approach, the tangible prototype generates and instantly prints AI-created images. A(I)Cam facilitated reflection among creative practitioners (N=15) on their experiences with AI-driven tools and the broader implications for their future practices. We examine the shifts in perspective that emerged from engaging with this embodied form of generative AI (genAI), challenging traditional text-based interaction paradigms, and inviting new modes of creative exploration and reflection. In addition, we offer insights from the RtD project, highlighting the integration of genAI tools into the industrial design process.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {543},
numpages = {16},
keywords = {Creative AI, Generative AI, Research through Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3700003.3700028,
author = {Wan, Hao and Zhang, Han and Fan, Zeming},
title = {HelixNet: A Dual-Helix Generative Network for Accurate Completion of Occluded Branch Images in Orchard Environments},
year = {2025},
isbn = {9798400710926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700003.3700028},
doi = {10.1145/3700003.3700028},
abstract = {Intelligent fruit-harvesting robots face significant challenges due to the visual complexity of orchard tree structures. The occlusion of branches by leaves and fruits leads to incomplete branch images, which limits the robot's understanding of its environment structure, thereby reducing harvesting efficiency and compromising operational safety. To tackle this issue, we introduce HelixNet, a novel lightweight dual-helix generative network architecture designed to complete occluded branch regions, restoring their geometric structure. HelixNet features two parallel chains: the Res-chain and the SM-chain. The Res-chain, based on deep residual learning mechanisms, enhances the learning capacity for diverse global features. The SM-chain employs a unique self-attention mechanism, the Swin Dilated Neighborhood Attention Transformer Module, to improve the capture of contextual information within the feature space. Additionally, a newly constructed bilateral fusion mechanism repeatedly integrates and enhances the global features from both chains. HelixNet is trained end-to-end using a generative adversarial network, without relying on prior knowledge. Experimental results show that HelixNet achieves superior completion accuracy and robustness compared to existing techniques, while maintaining low computational costs.},
booktitle = {Proceedings of the 2024 International Conference on Virtual Reality, Image and Signal Processing},
pages = {142–148},
numpages = {7},
keywords = {Computational efficiency, Dual-chain architecture, Generative adversarial network, Image completion},
location = {
},
series = {ICVISP '24}
}

@inproceedings{10.1145/3723936.3724016,
author = {Wang, Li and Liu, Zhaoyu and Gao, Bo and Zhou, Xi and Cai, Majia and Liu, Qi},
title = {Research on Personalized Track and Field Training Programs Based on Advanced Artificial Intelligence Models},
year = {2025},
isbn = {9798400712234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723936.3724016},
doi = {10.1145/3723936.3724016},
abstract = {Modern track and field, which is practiced in many different disciplines but under the cover of individualized training, is based on the particular physical condition and competitive goals of the athlete as well as performance statistics. Conventional methods fail to consider the dynamic variations of athletes since they are mostly based on fixed data and coach-oriented intuitive approach. In order to solve these difficulties, we provide in this work a fresh plan formulation strategy using multimodal fusion techniques and cross-modal learning. The model develops a customized training schedule using the powerful NLP capacity of LLMs by bridging several kinds of data (the physiological signals, motion trajectories, and text input) into a single structure. Against conventional approaches, experimental data show that the suggested approach significantly improves training optimization, planning flexibility and fusion efficiency. Results of this study highlight the revolutionary relevance of AI-based best running practices that can help to improve the accuracy and efficiency of track and field training approaches.},
booktitle = {Proceedings of the 2024 International Conference on Sports Technology and Performance Analysis},
pages = {509–513},
numpages = {5},
keywords = {Artificial Intelligence, Cross-Modal Learning, Personalized Training, Track and Field},
location = {
},
series = {ICSTPA '24}
}

@article{10.1145/3725536.3725540,
author = {Guida, Ciro},
title = {Toward Privacy-Preserving Training of Generative AI Models for Network Traffic Classification},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/3725536.3725540},
doi = {10.1145/3725536.3725540},
abstract = {Synthetic traffic traces are useful for training traffic classifiers in privacy-constrained environments. Generative Artificial Intelligence (GAI) models are blossoming as a solution to avoid the sharing of real data and the lack of datasets. Never the less ,privacy concerns about GAI are often under-estimated. Therefore, an approach to mitigate the data leakage of a GAI is presented in this paper, with a minimum impact on the utility of synthetic traffic traces for downstream applications. For example, training a Machine Learning (ML) traffic classifier on synthetic traffic traces results in an average accuracy loss of no more than 13% concerning training on a real dataset.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = mar,
pages = {6–8},
numpages = {3}
}

@inproceedings{10.1145/3729605.3729633,
author = {Song, Wei and Liu, Yuan},
title = {Real-Time Performance Optimization in Digital Art Animation Stylization Using Self-Supervised Learning},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729633},
doi = {10.1145/3729605.3729633},
abstract = {To address the problems of low computational efficiency and poor real-time performance in the stylization process of digital art animation, a self-supervised learning algorithm is introduced to optimize the performance of the stylization process and improve real-time rendering efficiency. First, a self-supervised learning framework is designed to automatically learn stylized features through a generative model to reduce the reliance on manual labels. Then, a contrastive learning method is used to optimize the model's ability to extract style features, making the stylized results more accurate. Finally, by integrating real-time rendering technology, the real-time performance of stylization processing is further improved, and smooth conversion of dynamic images is achieved. In the impressionist style, the SSIM (Structural Similarity Index Measure) value using contrastive learning is 0.92, which is significantly higher than 0.85 without contrastive learning. The PSNR (Peak Signal-to-Noise Ratio) also increases from 32.1 dB to 35.6 dB, indicating that contrastive learning significantly improves the structural similarity and detail retention capabilities of images. The application of self-supervised learning in digital art animation stylization not only solves the contradiction between efficiency and accuracy, but also provides a new technical route for real-time animation rendering, which has great application prospects.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {155–160},
numpages = {6},
keywords = {animation stylization, digital art, real-time performance optimization, self-supervised learning},
location = {
},
series = {ICBDIE '25}
}

@article{10.1145/3703457,
author = {Roy, Antika and Al Hasan, MD Mahfuz and Ghosh, Shajib and Varshney, Nitin and Julia, Jake and Forghani, Reza and Asadizanjani, Navid},
title = {Applications and Challenges of AI in PCB X-ray Inspection: A Comprehensive Study},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1550-4832},
url = {https://doi.org/10.1145/3703457},
doi = {10.1145/3703457},
abstract = {As printed circuit boards (PCBs) continue to evolve in complexity and miniaturization, the demand for robust and efficient inspection techniques has become paramount in ensuring the quality and reliability of electronic devices. The application of machine learning and deep learning techniques has revolutionized PCB inspection in recent years, enabling the ability to automate and improve numerous elements of the process. In this article, a comprehensive analysis is performed on the applications and challenges of AI, encompassing techniques of deep learning and machine learning, in the domain of PCB X-ray scrutiny. The main focus of this research centers around defect detection, identification of components and layers, deep learning algorithms for image reconstruction, as well as the identification of defects and features in advanced packaging. This study examines the current cutting-edge advancements in each of these areas, closely examining the existing methodologies and technologies employed. Furthermore, it delves into the limitations and challenges inherent in PCB X-ray inspection, such as the unavailability of data, computational demands, and the interpretability of models. In addition, this article offers prospective insights and presents promising avenues like application of generative adversarial networks and deep learning reconstruction methods for future exploration.},
journal = {J. Emerg. Technol. Comput. Syst.},
month = jan,
articleno = {1},
numpages = {28},
keywords = {Deep learning, Convolutional Neural Networks, Synthetic Image Generation, Generative Adversarial Networks, Dimensionality Reduction, Netlist Extraction, Advancedr Packaging, Reconstruction, Iterative Reconstruction}
}

@inproceedings{10.1145/3706598.3713128,
author = {Shi, Danqing and Wang, Yao and Bai, Yunpeng and Bulling, Andreas and Oulasvirta, Antti},
title = {Chartist: Task-driven Eye Movement Control for Chart Reading},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713128},
doi = {10.1145/3706598.3713128},
abstract = {To design data visualizations that are easy to comprehend, we need to understand how people with different interests read them. Computational models of predicting scanpaths on charts could complement empirical studies by offering estimates of user performance inexpensively; however, previous models have been limited to gaze patterns and overlooked the effects of tasks. Here, we contribute Chartist, a computational model that simulates how users move their eyes to extract information from the chart in order to perform analysis tasks, including value retrieval, filtering, and finding extremes. The novel contribution lies in a two-level hierarchical control architecture. At the high level, the model uses LLMs to comprehend the information gained so far and applies this representation to select a goal for the lower-level controllers, which, in turn, move the eyes in accordance with a sampling policy learned via reinforcement learning. The model is capable of predicting human-like task-driven scanpaths across various tasks. It can be applied in fields such as explainable AI, visualization design evaluation, and optimization. While it displays limitations in terms of generalizability and accuracy, it takes modeling in a promising direction, toward understanding human behaviors in interacting with charts.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1167},
numpages = {14},
keywords = {User model; Simulation; Scanpath; Reinforcement learning; LLMs},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3726854.3727279,
author = {Liu, Xutong and Dai, Xiangxiang and Wang, Xuchuang and Hajiesmaili, Mohammad and Lui, John C.S.},
title = {Combinatorial Logistic Bandits},
year = {2025},
isbn = {9798400715938},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3726854.3727279},
doi = {10.1145/3726854.3727279},
abstract = {Combinatorial multi-armed bandit (CMAB) is a fundamental online learning framework that can optimize cumulative rewards in networked systems under uncertainty. Real-world applications like content delivery and channel allocation often feature binary base arm rewards and nonlinear total reward functions. This paper introduces combinatorial logistic bandits (CLogB), a contextual CMAB framework with the base arm reward modeled as a nonlinear logistic function of the context, and the feedback is governed by a general arm-triggering process. We study CLogB with smooth reward functions, covering applications such as online content delivery, online multi-LLM selection, and dynamic channel allocation. Our first algorithm, CLogUCB, uses a variance-agnostic exploration bonus and achieves a regret bound of \~{O}(d√(κ KT)), where d is the feature dimension, κ reflects logistic model nonlinearity, K is the maximum number of triggered arms, and \~{O} ignores logarithmic factors. This improves on prior results by \~{O}(√κ ). We further propose VA-CLogUCB, a variance-adaptive enhancement achieving regret bounds of \~{O}(d√(KT) ) under standard smoothness conditions and \~{O}(d√T ) under stronger variance conditions, removing dependence on K. For time-invariant feature maps, we enhance computational efficiency by avoiding nonconvex optimization while maintaining \~{O}(d√T) regret. Experiments on synthetic and real-world datasets validate the superior performance of our algorithms, demonstrating their effectiveness and scalability for real-world networked systems.},
booktitle = {Abstracts of the 2025 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
pages = {112–114},
numpages = {3},
keywords = {combinatorial multi-armed bandits, logistic model, multi-armed bandits, regret, variance-adaptive},
location = {Stony Brook, NY, USA},
series = {SIGMETRICS '25}
}

@inproceedings{10.1145/3700003.3700031,
author = {Li, Xuandong and Chen, Musheng},
title = {Research on speckle image reconstruction method based on deep learning},
year = {2025},
isbn = {9798400710926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700003.3700031},
doi = {10.1145/3700003.3700031},
abstract = {Optical speckle image reconstruction is crucial in fields such as biomedical imaging, optical coherence tomography, and optical remote sensing. However, speckle images often suffer from noise and scattering, leading to diminished image quality. This paper introduces a deep learning-based approach to enhance the accuracy and quality of reconstructed speckle images. The process begins with the construction of an experimental optical setup using a spatial light modulator to generate the corresponding speckle patterns. A novel network model, named pix2pix, is then developed based on the generative adversarial network (GAN), integrating both generator and discriminator modules. The model is trained using both the collected speckle image data and real data. Extensive experiments have validated the effectiveness of our approach, showing significant improvements in reconstruction accuracy and computational efficiency. The results indicate that, compared to traditional methods, the deep learning-based technique greatly enhances image clarity, effectively reduces noise, and demonstrates superior generalization in image reconstruction.},
booktitle = {Proceedings of the 2024 International Conference on Virtual Reality, Image and Signal Processing},
pages = {160–164},
numpages = {5},
keywords = {Deep learning, Generative adversarial network (GAN), Image reconstruction, Speckle image},
location = {
},
series = {ICVISP '24}
}

@inproceedings{10.1145/3708657.3708714,
author = {Chen, Yu and Dong, Chao and Niu, Kai},
title = {Radio map estimation for Indoor Localization Using Conditional Generative Adversarial Network},
year = {2025},
isbn = {9798400717444},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708657.3708714},
doi = {10.1145/3708657.3708714},
abstract = {Indoor positioning technology is crucial for accurate navigation and monitoring. However, traditional methods are often limited by the labor-intensive and costly process of collecting high-quality fingerprint data, with performance declining when the database is incomplete. To address these challenges, this study introduces a novel approach based on Conditional Generative Adversarial Network (CGAN). By learning the radio frequency (RF) probability distribution from only a few reference points, our method can estimate the probability distribution at various points across the entire area, effectively constructing a comprehensive and accurate radio map (RM). Integrating this RM into a Hidden Markov Model (HMM) framework and applying Sequential Monte Carlo (SMC) filtering technique, we have significantly improved the tracking accuracy of moving targets in indoor environments. Compared to existing methods that rely on interpolation and artificial neural network(ANN) for radio map estimation, the CGAN-based method proposed in this paper has markedly improved indoor positioning accuracy, with an average precision increase of 26% to 33% and an average positioning error reduction to 2.71 meters.},
booktitle = {Proceedings of the 2024 10th International Conference on Communication and Information Processing},
pages = {353–358},
numpages = {6},
keywords = {indoor location, fingerprint, CGAN, RM, HMM, SMC},
location = {
},
series = {ICCIP '24}
}

@inproceedings{10.1145/3704558.3704564,
author = {Yang, Zelin and Yang, Liqing and Hao, Bin and Zhang, Fei},
title = {A Lightweight Restorative Adversarial Network for Detecting Belt Defects},
year = {2025},
isbn = {9798400710681},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704558.3704564},
doi = {10.1145/3704558.3704564},
abstract = {In modern industrial production, conveyor belts are critical to material transport, and their operational safety and efficiency are vital. Timely defect detection can prevent severe accidents and economic losses. This paper presents an intelligent belt defect detection method based on unsupervised learning, combining Generative Adversarial Networks (GAN) with Vector Quantized Variational Autoencoders (VQ-VAE) for efficient automatic detection of conveyor belt defects. During training, simulated defect images are generated using techniques like Perlin noise and color jittering on normal belt images. The VQ-VAE extracts and quantizes high-level semantic information, enabling accurate defect identification and repair. An improved lightweight U-Net structure serves as the pixel discriminator, optimizing computational efficiency and enhancing minor defect detection accuracy. The method achieved an ROC-AUC of 0.997 and a PR-AUC of 0.993 on a self-built belt dataset, with a detection time of 8.42 milliseconds per image, and showed significant improvement over four benchmark unsupervised models on the Mvtec ad dataset.},
booktitle = {Proceedings of the 2024 2nd International Conference on Frontiers of Intelligent Manufacturing and Automation},
pages = {1–6},
numpages = {6},
keywords = {Belt Defect Detection, GAN, Pixel Discriminator, Unsupervised learning, Variational Autoencoder},
location = {
},
series = {CFIMA '24}
}

@article{10.1145/3709003,
author = {Sun, Yujuan and Huang, Xing and Cui, Yanfang and Dong, Junyu and Zhang, Xiaofeng and Yao, Tao},
title = {An Underwater Imaging Generative Adversarial Network by Simulating the Mechanism of Light Propagation in Water},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3709003},
doi = {10.1145/3709003},
abstract = {Since capturing underwater images without degradation is challenging, there are few real image datasets with paired ground truth for underwater image enhancement. In this article, we propose a generative adversarial network (UIGAN) for underwater imaging; the network can convert images and their corresponding depth maps captured in air into images in water. The underwater imaging mechanism relies on many intrinsic parameters in water, which are difficult to estimate without field calibration. As the strong modeling capability of deep neural networks, this article uses the deep learning model to extract parameters from the real underwater environment. Then the proposed UIGAN simulates the light propagation process (direct attenuation, backscattering, and forward scattering) in water by using three modules with different constraints. We can generate a large training dataset with paired images in air and real water environment. The generated UIGAN dataset serves as input to a forward-attention transfer underwater enhancement model (FATUECNN), and it can output the restored images with appearance like those captured in air. The proposed pipeline is verified both qualitatively and quantitatively by extensive experiments and comparison evaluation with the existing state-of-the-art methods. The source code and the pre-trained model are made publicly available.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {31},
numpages = {18},
keywords = {underwater imaging mechanism, deep learning, underwater enhancement}
}

@article{10.1145/3709011,
author = {Gong, Nanxu and Ying, Wangyang and Wang, Dongjie and Fu, Yanjie},
title = {Neuro-Symbolic Embedding for Short and Effective Feature Selection via Autoregressive Generation},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3709011},
doi = {10.1145/3709011},
abstract = {Feature selection aims to identify the optimal feature subset for enhancing downstream models. Effective feature selection can remove redundant features, save computational resources, accelerate the model learning process, and improve the model overall performance. However, existing works are often time-intensive to identify the effective feature subset within high-dimensional feature spaces. Meanwhile, these methods mainly utilize a single downstream task performance as the selection criterion, leading to the selected subsets that are not only redundant but also lack generalizability. To bridge these gaps, we reformulate feature selection through a neuro-symbolic lens and introduce a novel generative framework aimed at identifying short and effective feature subsets. More specifically, we found that feature ID tokens of the selected subset can be formulated as symbols to reflect the intricate correlations among features. Thus, in this framework, we first create a data collector to automatically collect numerous feature selection samples consisting of feature ID tokens, model performance, and the measurement of feature subset redundancy. Building on the collected data, an encoder-decoder-evaluator learning paradigm is developed to preserve the intelligence of feature selection into a continuous embedding space for efficient search. Within the learned embedding space, we leverage a multi-gradient search algorithm to find more robust and generalized embeddings with the objective of improving model performance and reducing feature subset redundancy. These embeddings are then utilized to reconstruct the feature ID tokens for executing the final feature selection. Ultimately, comprehensive experiments and case studies are conducted to validate the effectiveness of the proposed framework. The associated data and code are publicly available ().},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb,
articleno = {37},
numpages = {21},
keywords = {Feature selection, neuro-symbolic generative learning, multi-objective optimization}
}

@article{10.1145/3729226,
author = {Nadiri, Amirhossein and Li, Jing and Faraji, Ali and Abuoda, Ghadeer and Papagelis, Manos},
title = {TrajLearn: Trajectory Prediction Learning using Deep Generative Models},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
issn = {2374-0353},
url = {https://doi.org/10.1145/3729226},
doi = {10.1145/3729226},
abstract = {Trajectory prediction aims to estimate an entity’s future path using its current position and historical movement data, benefiting fields like autonomous navigation, robotics, and human movement analytics. Deep learning approaches have become key in this area, utilizing large-scale trajectory datasets to model movement patterns, but face challenges in managing complex spatial dependencies and adapting to dynamic environments. To address these challenges, we introduce TrajLearn, a novel model for trajectory prediction that leverages generative modeling of higher-order mobility flows based on hexagonal spatial representation. TrajLearn predicts the next k steps by integrating a customized beam search for exploring multiple potential paths while maintaining spatial continuity. We conducted a rigorous evaluation of TrajLearn, benchmarking it against leading state-of-the-art approaches and meaningful baselines. The results indicate that TrajLearn achieves significant performance gains, with improvements of up to ~40% across multiple real-world trajectory datasets. In addition, we evaluated different prediction horizons (i.e., various values of k), conducted resolution sensitivity analysis, and performed ablation studies to assess the impact of key model components. Furthermore, we developed a novel algorithm to generate mixed-resolution maps by hierarchically subdividing hexagonal regions into finer segments within a specified observation area. This approach supports selective detailing, applying finer resolution to areas of interest or high activity (e.g., urban centers) while using coarser resolution for less significant regions (e.g., rural or uninhabited areas), effectively reducing data storage requirements and computational overhead. We promote reproducibility and adaptability by offering complete code, data, and detailed documentation with flexible configuration options for various applications.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = may,
articleno = {12},
numpages = {33},
keywords = {Mobility data analytics, spatial data mining, trajectory prediction, deep generative models}
}

@inproceedings{10.1145/3706890.3707009,
author = {Yang, Wenyi and Guo, Shengjie and Li, Bin and Wu, Huangyuan},
title = {A SFI-Driven Rapid Distribution Alignment for Classification of Small Sample Data: A Case Study in Adrenal Tumor Analysis},
year = {2025},
isbn = {9798400717826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706890.3707009},
doi = {10.1145/3706890.3707009},
abstract = {The disparate distribution of data across medical centers represents a significant challenge to the development of generalized machine learning models. Furthermore, data in the medical field are typically limited and imbalanced, making it more difficult for traditional domain adaptation methods to learn shared knowledge across disparate hospital data sets, further leading to poor generalization ability of the model in the target domain. In this paper, we propose a SFI (Shapley-based Feature Importance) Driven Rapid Distribution Alignment method for classification, aimed at identifying a potential low-dimensional feature space to rapidly align the distribution of the source domain and the target domain on small sample data. First, the feature importance calculated from the Shapely value guides the Conditional Tabular Generative Adversarial Network (CTGAN) algorithm to augment the small sample data and provide a more precise characterization of the data distribution. Then, feature elimination based on Shapely values and harmony are combined to align data distribution from different hospitals. In contrast to existing traditional domain adaptation techniques that solely prioritize reducing discrepancies in feature distributions across diverse domains, our approach additionally considers the significance of features in classification. The effectiveness of our method was finally verified through the classification of adrenal tumors in a small multi-center sample.},
booktitle = {Proceedings of the 2024 5th International Symposium on Artificial Intelligence for Medicine Science},
pages = {695–700},
numpages = {6},
keywords = {Domain adaption, Feature importance driven rapid distribution alignment, Machine learning},
location = {
},
series = {ISAIMS '24}
}

@inproceedings{10.5555/3709347.3743628,
author = {Kalyanakrishnan, Shivaram and Shah, Sheel and Guguloth, Santhosh Kumar},
title = {A View of the Certainty-Equivalence Method for PAC RL as an Application of the Trajectory Tree Method},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Reinforcement learning (RL) enables an agent interacting with an unknown MDP M to optimise its behaviour by observing transitions sampled from M. A natural entity that emerges in the agent's reasoning is M̂ , the maximum likelihood estimate of M based on the observed transitions. The well-known certainty-equivalence method (CEM) dictates that the agent update its behaviour to π̂ , which is an optimal policy for M̂ . Not only is CEM intuitive, it has been shown to enjoy minimax-optimal sample complexity in some regions of the parameter space for PAC RL with a generative model. A seemingly unrelated algorithm is the ''trajectory tree method'' (TTM), originally developed for efficient decision-time planning in large POMDPs. This paper presents a theoretical investigation that stems from the surprising finding that CEM may indeed be viewed as an application of TTM. The qualitative benefits of this view are (1) new and simple proofs of sample complexity upper bounds for CEM, in fact under a (2) weaker assumption on the rewards than is prevalent in the current literature. Our analysis applies to both non-stationary and stationary MDPs. Quantitatively, we obtain (3) improvements in the sample-complexity upper bounds for CEM both for non-stationary and stationary MDPs, in the regime that the ''mistake probability'' δ is small. Additionally, we show (4) a lower bound on the sample complexity for finite-horizon MDPs, which establishes the minimax-optimality of our upper bound for non-stationary MDPs in the small-δ regime.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {1079–1087},
numpages = {9},
keywords = {certainty-equivalence method, lower bound, pac reinforcement learning, sample complexity, trajectory tree method, upper bound},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

