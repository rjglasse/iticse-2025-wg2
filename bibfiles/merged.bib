@inproceedings{10.1145/3649409.3691094,
author = {Feng, Ty and Liu, Sa and Ghosal, Dipak},
title = {CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691094},
doi = {10.1145/3649409.3691094},
abstract = {The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {310–311},
numpages = {2},
keywords = {AI tutor, computer science education, intelligent tutoring systems, large language models, pedagogical appropriateness, question answering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626252.3630789,
author = {Liu, Mengqi and M'Hiri, Faten},
title = {Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630789},
doi = {10.1145/3626252.3630789},
abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {743–749},
numpages = {7},
keywords = {adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653554,
author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
title = {Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653554},
doi = {10.1145/3649217.3653554},
abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {388–393},
numpages = {6},
keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.1145/3688089,
author = {Zhou, Kyrie Zhixuan and Kilhoffer, Zachary and Sanfilippo, Madelyn Rose and Underwood, Ted and Gumusel, Ece and Wei, Mengyi and Choudhry, Abhinav and Xiong, Jinjun},
title = {Ethics, Governance, and User Mental Models for Large Language Models in Computing Education},
year = {2024},
issue_date = {Fall 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1528-4972},
url = {https://doi.org/10.1145/3688089},
doi = {10.1145/3688089},
abstract = {Large language models like ChatGPT are disrupting many industries, including computing education. How should policy evolve to improve learning outcomes?},
journal = {XRDS},
month = oct,
pages = {46–51},
numpages = {6}
}

@inproceedings{10.1145/3626253.3633409,
author = {Hazzan, Orit and Erez, Yael},
title = {Generative AI in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633409},
doi = {10.1145/3626253.3633409},
abstract = {Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1899},
numpages = {1},
keywords = {ai, assessment, computer science education, curriculum design, disruptive technology, generative ai, skills},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630927,
author = {Kirova, Vassilka D. and Ku, Cyril S. and Laracy, Joseph R. and Marlowe, Thomas J.},
title = {Software Engineering Education Must Adapt and Evolve for an LLM Environment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630927},
doi = {10.1145/3626252.3630927},
abstract = {In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {666–672},
numpages = {7},
keywords = {chatgpt, generative ai, large language models (llms), responsible ai, software engineering, software engineering education, software engineering ethics, software ethics},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3722479.3722506,
author = {Liao, Weidong and Guzide, Osman},
title = {Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {62},
numpages = {1}
}

@inproceedings{10.1145/3657604.3664660,
author = {Nguyen, Ha and Stott, Nate and Allan, Vicki},
title = {Comparing Feedback from Large Language Models and Instructors: Teaching Computer Science at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664660},
doi = {10.1145/3657604.3664660},
abstract = {Large language models (LLMs) can provide formative feedback in programming to help students improve the code they have written. We investigate the use of LLMs (GPT-4) to provide formative code feedback in a sophomore-level computer science (CS) course on data structures and algorithms. In three quizzes on recursion, half of the students randomly received GPT-4's feedback, while the other half received feedback from the course instructor. Students resubmitted their code based on the provided feedback. We found that students in the LLM-feedback condition scored higher in resubmissions than those receiving feedback from the instructor. Students perceived the two types of feedback as equally supportive of guiding resubmissions. We discuss the implications of using LLMs to provide formative feedback at scale in CS instruction.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {335–339},
numpages = {5},
keywords = {computer science education, feedback, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.5555/3715622.3715633,
author = {Zuo, Fei and Tompkins, Cody and Qian, Gang and Rhee, Junghwan and Qu, Xianshan and Yang, Bokai},
title = {ChatGPT as an Assembly Language Interpreter for Computing Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {Assembly language is a low-level programming language useful for a number of important computing areas, such as hardware and embedded systems programming, computer architecture, reverse engineering, and malware analysis. In recent years, generative AI, enhanced by GPT technology, has been widely adopted in the IT industry as well as computing education. However, little work has been done to investigate the applicability of GPT to teaching assembly language. In this paper, we fill in the gap by providing an empirical study of GPT's ability to interpret assembly instructions. In particular, we manually evaluated GPT-4's per-instruction explanations of code segments for four different computer architectures, namely x86, x86-64, ARM, and AArch64. Our study shows that, while inconsistencies and rare errors do exist, GPT's interpretations are highly accurate in general, demonstrating a great potential for such tools to be applied in pedagogical practices for tutoring assembly language.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {73–82},
numpages = {10}
}

@inproceedings{10.1145/3626253.3633431,
author = {Shaffer, Cliff and Brusilovsky, Peter and Koedinger, Ken and Price, Thomas and Barnes, Tiffany and Mostafavi, Behrooz},
title = {Ninth SPLICE Workshop on Technology and Data Infrastructure for CS Education Research},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633431},
doi = {10.1145/3626253.3633431},
abstract = {Many SIGCSE attendees are either developing or using online educational tools, and all will benefit from better interoperability among these tools and better analysis of the clickstream data coming from those tools. New tools for analyzing big data leveraged by AI (e.g., deep learning for assessment) in turn improve both content and pedagogy, thus setting up a virtuous cycle fueling learning discoveries and leveraging innovation in AI: Online technologies → big data analysis → better online technologies. This NSF-supported workshop is the latest in a series of SPLICE workshops, and is a continuation of our event at SIGCSE 2023, where the SPLICE-Portal, a dedicated socio-technical research infrastructure for Computing Education Research, was presented. This year, we continue the work with several new SPLICE community working groups, including those on Dashboards, Large Language Models, Parsons Problems, and Smart Learning Content Protocols. We continue to build upon our existing collaborations developed over the course of the project to engage more members of the community in tasks that will advance the project agenda.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1904},
numpages = {1},
keywords = {collaborative tools, computing education research, online technologies},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649409.3691074,
author = {Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany},
title = {Ethical Implications of Gen-AI and LLMs in Computing Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691074},
doi = {10.1145/3649409.3691074},
abstract = {The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {293–294},
numpages = {2},
keywords = {ChatGPT, curriculum design, ethics, generative AI, large language models, responsibility},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3639474.3640061,
author = {Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
title = {AI-Tutoring in Software Engineering Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640061},
doi = {10.1145/3639474.3640061},
abstract = {With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences.In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {309–319},
numpages = {11},
keywords = {programming education, automated programming assessment systems, artificial intelligence, ChatGPT, OpenAI, ChatBots},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@article{10.5555/3715602.3715614,
author = {Rhee, Junghwan and Shrestha, Aakankshya and Qian, Gang and Zuo, Fei and Fu, Jicheng and Park, Myungah and Qu, Xianshan and Mylavarapu, Goutam and Sung, Hong},
title = {An Evaluation on the Impact of Large Language Models on Computer Science Curricula},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {Since their introduction, large language model (LLM) services have been widely used in our society, including the computer science education area. While this technology provides various types of intelligent assistance to users, its capabilities and impact on computer science education regarding students' learning need further study. In this paper, we present our manual assessment of LLM services' ability to solve questions in various course assignments and projects in our computer science curriculum. Based on the result of the study, we provide our observations of the extent of LLM services' impact on different computer science disciplines. Suggestions are summarized and offered to computer science instructors on the possible strategies for dealing with LLMs in current and future computer science curriculum designs.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {70–80},
numpages = {11}
}

@inproceedings{10.1145/3626253.3631657,
author = {Akram, Bita and Leinonen, Juho and Norouzi, Narges and Prather, James and Zhang, Lisa},
title = {AI in Computing Education from Research to Practice},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3631657},
doi = {10.1145/3626253.3631657},
abstract = {The panel comprises a diverse set of Computing educators working on AI in education. The panelists will address four areas of AI in Computing education: 1) AI for introductory CS classrooms, 2) Investigating opportunities presented by LLMs, 3) LLM-based tool development, and 4) Ethics and inclusion in AI curriculum. The panel will share experiences and discuss opportunities and challenges in AI education with the community.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {artificial intelligence, computing education, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635369,
author = {MacNeil, Stephen and Leinonen, Juho and Denny, Paul and Kiesler, Natalie and Hellas, Arto and Prather, James and Becker, Brett A. and Wermelinger, Michel and Reid, Karen},
title = {Discussing the Changing Landscape of Generative AI in Computing Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635369},
doi = {10.1145/3626253.3635369},
abstract = {In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1916},
numpages = {1},
keywords = {academic integrity, assessment, computing education, curriculum, large language models, pedagogy},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653543,
author = {Bassner, Patrick and Frankford, Eduard and Krusche, Stephan},
title = {Iris: An AI-Driven Virtual Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653543},
doi = {10.1145/3649217.3653543},
abstract = {Integrating AI-driven tools in higher education is an emerging area with transformative potential. This paper introduces Iris, a chat-based virtual tutor integrated into the interactive learning platform Artemis that offers personalized, context-aware assistance in large-scale educational settings. Iris supports computer science students by guiding them through programming exercises and is designed to act as a tutor in a didactically meaningful way. Its calibrated assistance avoids revealing complete solutions, offering subtle hints or counter-questions to foster independent problem-solving skills. For each question, it issues multiple prompts in a Chain-of-Thought to GPT-3.5-Turbo. The prompts include a tutor role description and examples of meaningful answers through few-shot learning. Iris employs contextual awareness by accessing the problem statement, student code, and automated feedback to provide tailored advice. An empirical evaluation shows that students perceive Iris as effective because it understands their questions, provides relevant support, and contributes to the learning process. While students consider Iris a valuable tool for programming exercises and homework, they also feel confident solving programming tasks in computer-based exams without Iris. The findings underscore students' appreciation for Iris' immediate and personalized support, though students predominantly view it as a complement to, rather than a replacement for, human tutors. Nevertheless, Iris creates a space for students to ask questions without being judged by others.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {394–400},
numpages = {7},
keywords = {chatgpt, cs1, education technology, generative ai, interactive learning, large language models, programming exercises},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626252.3630803,
author = {Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv},
title = {ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630803},
doi = {10.1145/3626252.3630803},
abstract = {This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {625–631},
numpages = {7},
keywords = {chatgpt, computer science, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3649217.3653570,
author = {Frazier, Matthew and Damevski, Kostadin and Pollock, Lori},
title = {Customizing ChatGPT to Help Computer Science Principles Students Learn Through Conversation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653570},
doi = {10.1145/3649217.3653570},
abstract = {This paper explores leveraging conversational agents, specifically ChatGPT, to enhance the introduction of computing, focused on the Advanced Placement Computer Science Principles (CSP) course in secondary schools. Despite the potential benefits for diverse student audiences, little research has investigated their effectiveness and engagement in this context. We examine the customization of ChatGPT for secondary school CSP students, assessing its impact on exploratory searches for learning CSP concepts. Results from 20 high school students in grades 10-12 (ages 15-18) in a CSP course indicate that students preferred a customized ChatGPT, with its terminology more suitable to secondary school level, examples more understandable, and better connections to personal experiences compared to standard ChatGPT.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {633–639},
numpages = {7},
keywords = {chatgpt, computer science principles, conversational agent, exploratory search},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3636243.3636257,
author = {Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv},
title = {“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636257},
doi = {10.1145/3636243.3636257},
abstract = {Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, User Study},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3660650.3660668,
author = {Rajabi, Parsa},
title = {Experience Report: Adopting AI-Usage Policy in Software Engineering Education},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660668},
doi = {10.1145/3660650.3660668},
abstract = {This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an "AI-usage disclosure" form for coursework submissions. This approach sought to improve AI literacy, ensure academic integrity, and mitigate potential academic misconduct cases. Despite challenges, including adherence to AI disclosures and the evolving definition of AI tools, the policy promoted a more inclusive learning environment and encouraged a deeper understanding of AI’s role and limitations in computer science education. The findings highlight the need for ongoing policy revisions to adapt to technological advancements, emphasizing the pilot as an essential step towards integrating AI responsibly in educational contexts.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {19},
numpages = {2},
keywords = {AI in Education, AI-usage Policy, Academic Integrity, ChatGPT, Software Engineering Education},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3587102.3588815,
author = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@article{10.1145/3674149,
author = {Mendon\c{c}a, Nabor C.},
title = {Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer Science Exam},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {3},
url = {https://doi.org/10.1145/3674149},
doi = {10.1145/3674149},
abstract = {The recent integration of visual capabilities into Large Language Models (LLMs) has the potential to play a pivotal role in science and technology education, where visual elements such as diagrams, charts, and tables are commonly used to improve the learning experience. This study investigates the performance of ChatGPT-4 Vision, OpenAI’s most advanced visual model at the time the study was conducted, on the Bachelor in Computer Science section of Brazil’s 2021 National Undergraduate Exam (ENADE). By presenting the model with the exam’s open and multiple-choice questions in their original image format and allowing for reassessment in response to differing answer keys, we were able to evaluate the model’s reasoning and self-reflecting capabilities in a large-scale academic assessment involving textual and visual content. ChatGPT-4 Vision significantly outperformed the average exam participant, positioning itself within the top 10 best score percentile. While it excelled in questions that incorporated visual elements, it also encountered challenges with question interpretation, logical reasoning, and visual acuity. A positive correlation between the model’s performance in multiple-choice questions and the performance distribution of the human participants suggests multimodal LLMs can provide a useful tool for question testing and refinement. However, the involvement of an independent expert panel to review cases of disagreement between the model and the answer key revealed some poorly constructed questions containing vague or ambiguous statements, calling attention to the critical need for improved question design in future exams. Our findings suggest that while ChatGPT-4 Vision shows promise in multimodal academic evaluations, human oversight remains crucial for verifying the model’s accuracy and ensuring the fairness of high-stakes educational exams. The paper’s research materials are publicly available at .},
journal = {ACM Trans. Comput. Educ.},
month = aug,
articleno = {37},
numpages = {56},
keywords = {Multimodal generative AI, ChatGPT-4 vision, educational assessment, computer science education}
}

@inproceedings{10.1145/3686852.3686864,
author = {Dakshit, Sagnik},
title = {Faculty Perspectives on the Potential of RAG in Computer Science Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686864},
doi = {10.1145/3686852.3686864},
abstract = {The emergence of Large Language Models (LLMs) has significantly impacted the field of Natural Language Processing and has transformed conversational tasks across various domains because of their widespread integration in applications and public access. The discussion surrounding the application of LLMs in education has raised ethical concerns, particularly concerning plagiarism and policy compliance. Despite the prowess of LLMs in conversational tasks, the limitations of reliability and hallucinations exacerbate the need to guardrail conversations, motivating our investigation of RAG in computer science higher education. We developed Retrieval Augmented Generation (RAG) applications for the two tasks of virtual teaching assistants and teaching aids. In our study, we collected the ratings and opinions of faculty members in undergraduate and graduate computer science university courses at various levels, using our personalized RAG systems for each course. This study is the first to gather faculty feedback on the application of LLM-based RAG in education. The investigation revealed that while faculty members acknowledge the potential of RAG systems as virtual teaching assistants and teaching aids, certain barriers and features are suggested for their full-scale deployment. These findings contribute to the ongoing discussion on the integration of advanced language models in educational settings, highlighting the need for careful consideration of ethical implications and the development of appropriate safeguards to ensure responsible and effective implementation.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {19–24},
numpages = {6},
keywords = {Education, Large Language Models, Learning, Neural Networks, Retrieval Augmented Generation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3649217.3653575,
author = {Smith, C. Estelle and Shiekh, Kylee and Cooreman, Hayden and Rahman, Sharfi and Zhu, Yifei and Siam, Md Kamrul and Ivanitskiy, Michael and Ahmed, Ahmed M. and Hallinan, Michael and Grisak, Alexander and Fierro, Gabe},
title = {Early Adoption of Generative Artificial Intelligence in Computing Education: Emergent Student Use Cases and Perspectives in 2023},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653575},
doi = {10.1145/3649217.3653575},
abstract = {Because of the rapid development and increasing public availability of Generative Artificial Intelligence (GenAI) models and tools, educational institutions and educators must immediately reckon with the impact of students using GenAI. There is limited prior research on computing students' use and perceptions of GenAI. In anticipation of future advances and evolutions of GenAI, we capture a snapshot of student attitudes towards and uses of yet emerging GenAI, in a period of time before university policies had reacted to these technologies. We surveyed all computer science majors in a small engineering-focused R1 university in order to: (1) capture a baseline assessment of how GenAI has been immediately adopted by aspiring computer scientists; (2) describe computing students' GenAI-related needs and concerns for their education and careers; and (3) discuss GenAI influences on CS pedagogy, curriculum, culture, and policy. We present an exploratory qualitative analysis of this data and discuss the impact of our findings on the emerging conversation around GenAI and education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {3–9},
numpages = {7},
keywords = {ai literacy, code generator, education, generative artificial intelligence, image generator, interactive tutoring, large language model, policy, student experience, survey},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3587102.3588773,
author = {Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James},
title = {Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588773},
doi = {10.1145/3587102.3588773},
abstract = {Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {3–4},
numpages = {2},
keywords = {ai, artificial intelligence, chatgpt, computer programming, computer science education, computing education, copilot, deep learning, generative ai, large language models, llm, machine learning},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3568812.3603453,
author = {Tran, Minh},
title = {Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603453},
doi = {10.1145/3568812.3603453},
abstract = {The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {110–112},
numpages = {3},
keywords = {culturally responsive pedagogy, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3626253.3635511,
author = {Bhalerao, Rasika},
title = {My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635511},
doi = {10.1145/3626253.3635511},
abstract = {Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code "better" rather than cheat. These results are intended to be a starting point to spark discussion on the adoption of new technologies in introductory computer science courses. The authors themselves will continue teaching courses with the policy that students should interact with an LLM the way they interact with a person: students are encouraged to discuss and collaborate with it, but copying code from it is considered plagiarism.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1574–1575},
numpages = {2},
keywords = {AI, assignments, plagiarism, students},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3677619.3678092,
author = {Bahr, Tobias and Manzocco, Mario and Schuster, Dennis},
title = {Differentiated Tasks by ChatGPT for Secondary Computer Science Education: Useful or not?},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678092},
doi = {10.1145/3677619.3678092},
abstract = {In recent years, there has been a growing interest in exploring the capabilities of AI chatbots, such as ChatGPT. Studies have investigated diverse applications, including the response of AI chatbots to undergraduate exam questions and the generation of student exercises for programming. However, the question remains if AI chatbots provide adequate results for K-12 CS in different application scenarios. AI chatbots are increasingly integrated into K-12 education by both students and teachers. In this context, a tool using didactical parameters was created to differentiate tasks with ChatGPT-4 in an ongoing project. Preliminary findings from this work in progress reveal that teachers see a benefit using the tool. Future directions for using the tool are discussed.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {34},
numpages = {2},
keywords = {AI chatbots, ChatGPT, Computer Science Education, Expert rating, K-12},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@inproceedings{10.1145/3605468.3605471,
author = {Vo, Gia Minh and Pancratz, Nils},
title = {AI Education in German K-10 Computer Science Curricula},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3605471},
doi = {10.1145/3605468.3605471},
abstract = {The growing importance of artificial intelligence (AI) in our daily lives leads to an increasing demand for AI in learning, teaching, and education. Recent developments, such as ChatGPT, have further pushed the significance of AI, garnering media attention and prompting politicians to require stakeholders in education to place a stronger emphasis on AI education in schools. As a result, a growing number of computer science (CS) curricula are expanding to include the topic of AI. This paper aims to contribute to the understanding of AI in K-10 education in Germany by analyzing CS curricula for lower secondary school education across the 16 federal states of Germany. The results indicate that AI-related content is inconsistently addressed in the CS curricula of various federal states, with a noticeable absence of standardized AI competencies for K-10 education. In several federal states, AI-related content is only implicitly addressed from a socio-cultural perspective. To ensure up-to-date education, it is essential to include mandatory AI content in K-10 CS curricula. These contents should be considered holistically by taking into account the technological, socio-cultural, and user-oriented perspectives, in accordance with the Dagstuhl Triangle.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {15},
numpages = {4},
keywords = {K-10 education, artificial intelligence, computer science education, curriculum analysis},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3649409.3691090,
author = {Folajimi, Yetunde},
title = {From GPT to BERT: Benchmarking Large Language Models for Automated Quiz Generation},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691090},
doi = {10.1145/3649409.3691090},
abstract = {This study evaluates the effectiveness of four leading large language models (LLMs), GPT-3, GPT-4, GPT-4o, and BERT, in generating quiz questions for Java and Python programming courses. We aim to recognize how LLMs can effectively produce educationally valuable questions that meet specific pedagogical criteria, including technical precision, relevance to course objectives, linguistic clarity, and pedagogical appropriateness. Each model was prompted to generate 200 Java and 200 Python quiz questions, totaling 1600 unique questions. These questions are currently being evaluated based on both quantitative and qualitative assessments by a team of computer science educators. Preliminary findings suggest that GPT-4 outperforms BERT in terms of technical precision. Further analysis is ongoing to assess the performance of the models in generating contextually appropriate and educationally useful questions, offering insights into their potential integration into computer science curricula. This work seeks to contribute to the broader discourse on the utility of LLMs in educational settings, specifically within the scope of automated content creation to enhance teaching and assessment methodologies in computer science education.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {312–313},
numpages = {2},
keywords = {automated assessment, computer science education, formative assessment, large language models, personalized quizzes, quiz questions generation},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3661167.3661269,
author = {Harman, Mark},
title = {The Role of Software Measurement in Assured LLM-Based Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661269},
doi = {10.1145/3661167.3661269},
abstract = {Assured Large Language Model Software Engineering (Assured LLMSE) addresses the twin challenges: 1. Ensuring LLM-generated code does not regress the properties of the original code 2. Quantifying the improvement over the original archived by the improve code in a verifiable and measurable way. In so doing, the Assured LLMSE approach tackles the problem of LLMs’ tendency to hallucinate, as well as providing confidence that generated code improves an existing code base. Software testing and measurement play critical roles in this improvement process: testing is the guard against regression, while measurement provides the quantifiable assurance of improvement. Assured LLMSE takes its inspiration from previous work on genetic improvement, for which software measurement also plays a central role. In this keynote we outline the Assured LLMSE approach, highlighting the role of software measurement in the provision of quantifiable, verifiable assurances for code that originates from LLM–based inference. This paper is an outline of the content of the keynote by Mark Harman at the 28th International Conference on Evaluation and Assessment in Software Engineering.  This is joint work with Nadia Alshahwan, Andrea Aquino, Jubin Chheda, Anastasia Finegenova, Inna Harper, Mitya Lyubarskiy, Neil Maiden, Alexander Mols, Shubho Sengupta, Rotem Tal, Alexandru Marginean, and Eddy Wang.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {4},
numpages = {1},
keywords = {Automated Code Generation, CodeLlama, Genetic Improvement (GI), Large Language Models (LLMs), Llama, Search Based Software Engineering (SBSE)},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3663530.3665020,
author = {Dong, Liming and Lu, Qinghua and Zhu, Liming},
title = {A Pilot Study in Surveying Data Challenges of Automatic Software Engineering Tasks},
year = {2024},
isbn = {9798400706721},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663530.3665020},
doi = {10.1145/3663530.3665020},
abstract = {The surge in automatic SE research aims to boost development efficiency and quality while reducing costs. However, challenges such as limited real-world project data and inadequate data conditions constrain the effectiveness of these methods. To systematically understand these challenges, our pilot study reviews prevalent data challenges across various SE tasks. Despite these challenges, thanks to the advances of large language model offers promising performance on SE tasks. 
 
Overall, this pilot survey focused on provide a quick retrospective review on SE data challenges and introduce practical LLM solutions from the SE community to mitigate these challenges.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering and AI for Data Quality in Cyber-Physical Systems/Internet of Things},
pages = {6–11},
numpages = {6},
keywords = {Automatic Software Engineering, Data Challenge, LLM, Pilot Survey},
location = {Porto de Galinhas, Brazil},
series = {SEA4DQ 2024}
}

@inproceedings{10.1145/3626253.3635427,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635427},
doi = {10.1145/3626253.3635427},
abstract = {CS50.ai is an AI-based educational tool developed and integrated into CS50 at Harvard University using large language models (LLMs), supporting both in-person and online learners. CS50.ai encapsulates a variety of AI-based tools designed to enhance students' learning by approximating a 1:1 teacher-to-student ratio. We showcase: "Explain Highlighted Code," a Visual Studio (VS) Code extension that provides just-in-time explanations of code snippets; style50, a VS Code extension that offers formatting suggestions and explanations thereof; and our "CS50 Duck," an AI-based chatbot for course-related questions, implemented both as a VS Code extension and as a standalone web application. We also demonstrate the integration of our tools into Ed, the course's discussion forum. This demo will illustrate the functionality and effectiveness of these tools as well as the pedagogical "guardrails" that we put in place to ensure secure and fair usage of these tools, while sharing insights from our own experience therewith this past summer and fall.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1927},
numpages = {1},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3636517.3636522,
author = {Crandall, Aaron S. and Sprint, Gina and Fischer, Bryan},
title = {Generative Pre-Trained Transformer (GPT) Models as a Code Review Feedback Tool in Computer Science Programs},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {Undergraduate computer science and software engineering students benefit significantly from in-depth reviews of their code early and often in their courses. Performing these reviews is time-consuming for teaching assistants and professors to complete, consequently impacting the timeliness and consistency of the provided feedback. When code feedback is not delivered close to the time of authorship, the utility of the review for students is diminished. Prior work with Automatic Static Analysis Tools has shown promise at using artificial intelligence to automate code reviews, with some success integrating them into classroom environments. To leverage new advances in Generative Pre-Trained Transformer (GPT) models, this work reports on an Automatic Review Tool (ART) to provide timely, automatically generated code reviews. ART was evaluated in a second-semester computer science course by integrating ART into the course's Github-based assignment submission system. A cohort of student volunteers (N = 74) read the ART reviews and provided feedback using a survey spanning two of their course assignments. The results of this pilot study show that students perceived ART was successful at detecting defects and offering style-based suggestions, and students were receptive to receiving future automated reviews of their work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {38–47},
numpages = {10}
}

@article{10.5555/3636988.3636989,
author = {Conrad, Susan and Dimitoglou, George and Flinn, Michael B. and Morgan, Jacob and Gupta, Pranshu and Mengistu, Zelalem},
title = {Current Challenges in Computing Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {Discussion about topics related to current issues in computing science education focusing on three themes: "That AI thing...", "Post-Pandemic Strategies," and "Partnerships."The first theme attempts to address the benefits, challenges, and practical applications of integrating Generative AI technologies, such as ChatGPT, Bard, and CoPilot, into educational settings. Exploration of academic honesty and intellectual property and strategies for how these AI tools can be utilized in classrooms, labs, student projects, assignments, academic programs, and even preparing students for future job opportunities.The second theme revolves around post-pandemic approaches and initiatives to explore aimed at re-engaging students in both classroom activities and extracurricular pursuits. Exploration of strategies to enhance undergraduate and graduate student participation in internships, research opportunities, and the unique challenges and characteristics of job hunting in the current educational and economic landscape.The third theme highlights the significance of forging partnerships between educational institutions and industry stakeholders. Exploring campus ideas and efforts to establish and strengthen relationships with industry partners. Discussion on collaborative projects, research initiatives, mentorship programs, and ways to bridge the gap between academia and industry to benefit both students and the workforce.The final theme is open-ended, encouraging attendees to contemplate additional questions that may initiate reflection on emerging trends, pedagogical challenges, technological advancements, and any other critical issues that computing science educators should address to stay effective and responsive in their roles.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {16–17},
numpages = {2}
}

@inproceedings{10.1145/3626252.3630938,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630938},
doi = {10.1145/3626252.3630938},
abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {750–756},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3660788,
author = {Khojah, Ranim and Mohamad, Mazen and Leitner, Philipp and de Oliveira Neto, Francisco Gomes},
title = {Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660788},
doi = {10.1145/3660788},
abstract = {Large Language Models (LLMs) are frequently discussed in academia and the general public as support tools for virtually any use case that relies on the production of text, including software engineering. Currently, there is much debate, but little empirical evidence, regarding the practical usefulness of LLM-based tools such as ChatGPT for engineers in industry. We conduct an observational study of 24 professional software engineers who have been using ChatGPT over a period of one week in their jobs, and qualitatively analyse their dialogues with the chatbot as well as their overall experience (as captured by an exit survey). We find that rather than expecting ChatGPT to generate ready-to-use software artifacts (e.g., code), practitioners more often use ChatGPT to receive guidance on how to solve their tasks or learn about a topic in more abstract terms. We also propose a theoretical framework for how the (i) purpose of the interaction, (ii) internal factors (e.g., the user's personality), and (iii) external factors (e.g., company policy) together shape the experience (in terms of perceived usefulness and trust). We envision that our framework can be used by future research to further the academic discussion on LLM usage by software engineering practitioners, and to serve as a reference point for the design of future empirical LLM research in this domain.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {81},
numpages = {22},
keywords = {Chatbots, Large Language Models (LLMs), Software Development Bots}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@article{10.1145/3624720,
author = {Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
title = {Computing Education in the Era of Generative AI},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624720},
doi = {10.1145/3624720},
abstract = {Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.},
journal = {Commun. ACM},
month = jan,
pages = {56–67},
numpages = {12}
}

@inproceedings{10.1145/3610969.3610982,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {No More Pencils No More Books: Capabilities of Generative AI on Irish and UK Computer Science School Leaving Examinations},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610982},
doi = {10.1145/3610969.3610982},
abstract = {We investigate the capabilities of ChatGPT (GPT-4) on second-level (high-school) computer science examinations: the UK A-Level and Irish Leaving Certificate. Both are national, government-set / approved, and centrally assessed examinations. We also evaluate performance differences in exams made publicly available before and after the ChatGPT knowledge cutoff date, and investigate what types of question ChatGPT struggles with. We find that ChatGPT is capable of achieving very high marks on both exams and that the performance difference before and after the knowledge cutoff date are minimal. We also observe that ChatGPT struggles with questions involving symbols or images, which can be mitigated when in-text information ‘fills in the gaps’. Additionally, GPT-4 performance can be negatively impacted when an initial inaccurate answer leads to further inaccuracies in subsequent parts of the same question. Finally, the element of choice on the Leaving Certificate is a significant advantage in achieving a high grade. Notably, there are minimal occurrences of hallucinations in answers and few errors in solutions not involving images. These results reveal several strengths and weaknesses of these exams in terms of how generative AI performs on them and have implications for exam design, the construction of marking schemes, and could also shift the focus of what is examined and how.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {2},
numpages = {7},
keywords = {second-level, school, high school, examinations, UK, Leaving Certificate, LCCS, K-12, Ireland, Generative AI, GPT-4, ChatGPT, Artificial Intelligence, A-Level},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3613372.3614189,
author = {Albonico, Michel and Varela, Paulo J\'{u}nior},
title = {A Report on the Use of ChatGPT in Software Engineering and Systems Analysis Courses},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614189},
doi = {10.1145/3613372.3614189},
abstract = {ChatGPT is a natural language model that works as a virtual chat assistant. It has the potential to be used for fostering classroom discussions and addressing student needs when the professor is not accessible. Although it is still early to assess the impact of ChatGPT and similar technologies, there is a considerable discussion on social media and blogs regarding the aspirations and opportunities of utilizing ChatGPT in the software industry and education. The main perception is that ChatGPT can serve as a support tool but should not completely replace interpersonal interaction, as face-to-face dialogue remains crucial for the development of interpersonal skills and a deeper understanding of concepts. This article reports a recent classroom experience in the subjects of Software Engineering and Systems Analysis, while also analyzing ChatGPT’s responses to student inquiries.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {303–311},
numpages = {9},
keywords = {ChatGPT, Software Engineering, Student Support, System Analysis},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3657604.3662036,
author = {Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan},
title = {Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662036},
doi = {10.1145/3657604.3662036},
abstract = {The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the "CodeTutor group" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the "control group"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {63–74},
numpages = {12},
keywords = {field study, large language models, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3613944.3613946,
author = {Qureshi, Basit},
title = {ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings},
year = {2023},
isbn = {9798400700415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613944.3613946},
doi = {10.1145/3613944.3613946},
abstract = {The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.},
booktitle = {Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies},
pages = {7–13},
numpages = {7},
keywords = {Academic assessment, ChatGPT, Data Structures and Algorithms, programming concepts},
location = {Portsmouth, United Kingdom},
series = {ICSLT '23}
}

@inproceedings{10.1145/3587103.3594206,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Caspersen, Michael E. and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {Transformed by Transformers: Navigating the AI Coding Revolution for Computing Education: An ITiCSE Working Group Conducted by Humans},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594206},
doi = {10.1145/3587103.3594206},
abstract = {The recent advent of highly accurate and scalable large language models (LLMs) has taken the world by storm. From art to essays to computer code, LLMs are producing novel content that until recently was thought only humans could produce. Recent work in computing education has sought to understand the capabilities of LLMs for solving tasks such as writing code, explaining code, creating novel coding assignments, interpreting programming error messages, and more. However, these technologies continue to evolve at an astonishing rate leaving educators little time to adapt. This working group seeks to document the state-of-the-art for code generation LLMs, detail current opportunities and challenges related to their use, and present actionable approaches to integrating them into computing curricula.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {561–562},
numpages = {2},
keywords = {AI, CS1, GPT, GitHub, LLM, artificial intelligence, code generation, codex, computer programming, copilot, large language models, novice programming, openAI, pedagogical practices},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

@inproceedings{10.1145/3626252.3630854,
author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
title = {Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630854},
doi = {10.1145/3626252.3630854},
abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {951–957},
numpages = {7},
keywords = {capstone courses, chatgpt, generative ai, large language models, software engineering education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3665464.3665476,
author = {Alrifai, Rad},
title = {Using Generative AI to Design Programming Assignments in Introduction to Computer Science},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Programming stands as an essential requisite in computer science education. Recognizing the challenges students face in learning programming effectively, the proposed assignment aims to integrate generative artificial intelligence (AI) tools to teach students introductory programming constructs. Generative AI has gained an increasing popularity in recent years. Several available Generative AI implementations can now help students learn programming essentials and debugging skills.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {103–106},
numpages = {4}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\"{a}, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {tutoring, student perceptions, generative AI, education, discussion forum, chatbots, artificial intelligence, ChatGPT},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@inproceedings{10.1145/3649217.3653594,
author = {Azaiz, Imen and Kiesler, Natalie and Strickroth, Sven},
title = {Feedback-Generation for Programming Exercises With GPT-4},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653594},
doi = {10.1145/3649217.3653594},
abstract = {Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material. Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements. For example, the output is more structured and consistent. GPT-4 Turbo can also accurately identify invalid casing in student programs' output. In some cases, the feedback also includes the output of the student program. At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed. The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {31–37},
numpages = {7},
keywords = {GPT-4 turbo, LLMs, assessment, benchmarking, formative feedback, introductory programming, large language models, personalized feedback},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.5555/3637036.3637049,
author = {Mehta, Jean and Becker, Brett A. and Hsin, Wen-Jung and Hummel, Joe and Kerney, Bill and Krupp, Brian},
title = {The Influence of Generative AI on Pedagogy and Assessment in Computing Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {4},
issn = {1937-4771},
abstract = {Student access to Generative AI tools stands to alter the way we teach as well as the way we assess our student's learning. ChatGPT has only been available for a few months, but already instructors are concerned about its wide use and implications. Love it? Hate it? Embed it in your course? Ban its use? Will this change not just how we teach but what we teach, when we teach it and even who we teach? Most of us have been wrestling with these questions, and more. Panelists will speak of how they altered their pedagogy, and the results, in both in-person and online courses.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {99},
numpages = {1}
}

@inproceedings{10.1145/3689535.3689554,
author = {Santos, Eddie Antonio and Becker, Brett A.},
title = {Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689554},
doi = {10.1145/3689535.3689554},
abstract = {The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {5},
numpages = {7},
keywords = {AI, C, CS1, GPT-4, GenAI, Generative AI, LLMs, PEM, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3657604.3664701,
author = {Popescu, Diana M. and Joyner, David A.},
title = {ChatGPT's Performance on Problem Sets in an At-Scale Introductory Computer Science Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664701},
doi = {10.1145/3657604.3664701},
abstract = {This work in progress paper examines the impact of LLMs such as ChatGPT in a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform, focusing on its strengths and limitations in solving coding assignments. The study reveals ChatGPT's proficiency in some areas while highlighting challenges in pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. In order to discourage over-reliance on AI assistance from students while preserving scalability, the paper proposes strategies to enhance the difficulty of coding assignments by adding more creative elements in their structure. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {486–490},
numpages = {5},
keywords = {applied computing, artificial intelligence, e-learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3680533.3697064,
author = {Feng, Tony Haoran and Denny, Paul and W\"{u}nsche, Burkhard C. and Luxton-Reilly, Andrew and Whalley, Jacqueline},
title = {An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697064},
doi = {10.1145/3680533.3697064},
abstract = {CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {5},
numpages = {8},
keywords = {Large Language Models, LLMs, Large Multimodal Models, LMMs, Visual Language Models, VLMs, Generative Artificial Intelligence, GenAI, GPT-4, GPT-4o, Visual Perception, Geometric Reasoning, Computer Graphics, Computing Education, Evaluation, Assessment},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3664646.3664765,
author = {Dvivedi, Shubhang Shekhar and Vijay, Vyshnav and Pujari, Sai Leela Rahul and Lodh, Shoumik and Kumar, Dhruv},
title = {A Comparative Analysis of Large Language Models for Code Documentation Generation},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3664765},
doi = {10.1145/3664646.3664765},
abstract = {This paper presents a comprehensive comparative analysis of Large Language Models (LLMs) for generation of code documentation. Code documentation is an essential part of the software writing process. The paper evaluates models such as GPT-3.5, GPT-4, Bard, Llama2, and StarChat on various parameters like Accuracy, Completeness, Relevance, Understandability, Readability and Time Taken for different levels of code documentation. Our evaluation employs a checklist-based system to minimize subjectivity, providing a more objective assessment. We find that, barring StarChat, all LLMs consistently outperform the original documentation. Notably, closed-source models GPT-3.5, GPT-4, and Bard exhibit superior performance across various parameters compared to open-source/source-available LLMs, namely Llama 2 and StarChat. Considering the time taken for generation, GPT-4 demonstrated the longest duration by a significant margin, followed by Llama2, Bard, with GPT-3.5 and StarChat having comparable generation times. Additionally, file level documentation had a considerably worse performance across all parameters (except for time taken) as compared to inline and function level documentation.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {65–73},
numpages = {9},
keywords = {Code documentation, Large Language Models},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630960,
author = {Nguyen, Ha and Allan, Vicki},
title = {Using GPT-4 to Provide Tiered, Formative Code Feedback},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630960},
doi = {10.1145/3626252.3630960},
abstract = {Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {958–964},
numpages = {7},
keywords = {computer science education, feedback, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3639474.3640052,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640052},
doi = {10.1145/3639474.3640052},
abstract = {Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {162–169},
numpages = {8},
keywords = {programming assignments, teaching, object-oriented programming, object-oriented design, OOP best practices, large language models, GPT-3, GPT-4, bard},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3641237.3691673,
author = {Trim, Michelle and Butler, Erin and Suttcliffe, Christina},
title = {Seeing How the Sausage is Made: Data Storytelling as Means and Method in a Computer Science Writing Course},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691673},
doi = {10.1145/3641237.3691673},
abstract = {As data corpus-driven tools and technologies increasingly push users to passively search for an answer, rather than search to understand, we believe that technical and computing disciplinary writing courses have a duty to teach the process of responsible data storytelling. While students can grasp that generative AI makes mistakes, hallucinates, and perpetuates bias, they can need help understanding the antecedent causes of those difficulties. All algorithmically driven decision-making or recommending software have in common a large data set that has been labeled, either by users or by the system itself. The origins of that data and the reasonable applications/deductions and conclusions possible for any given dataset have everything to do with why some tools help and some tools perpetuate harms. By starting at the very beginning and asking students to make sense of data, students can more easily see how purpose and audience impact analysis of any given collection of data. Once those opportunities for rhetorical choice making are known, students become ready to understand the connection between data and complex A.I. systems and some of the ways that bias and other kinds of harm can result if designers are not careful. Combining instruction in a technical coding environment with basic data literacy lessons such as ‘the seven data stories,’ [14] we developed and delivered a three-week writing unit designed around responsible data exploration and storytelling. In this experience report, we provide the assignment we used, and the scaffolded activities we employed to bring students through the process, remarking on what worked well and what we want to improve. We provide attendees with a link to an R-based notebook with a walk-through lesson on data exploration commands, and the rubric used to assess students’ texts, notebooks with code and commentary and results, all existing in a referential context. We provide the survey results of students’ perception of learning from this activity. Early findings demonstrate that students internalized lessons about the non-objective nature of data analysis and of specific responsible data storytelling practices required by anyone seeking to ethically represent answers within and limitations of any dataset.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {217–222},
numpages = {6},
keywords = {Data Visualization, Data storytelling, Pedagogy, Technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3657604.3662040,
author = {Gabbay, Hagit and Cohen, Anat},
title = {Combining LLM-Generated and Test-Based Feedback in a MOOC for Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662040},
doi = {10.1145/3657604.3662040},
abstract = {In large-scale programming courses, providing learners with immediate and effective feedback is a significant challenge. This study explores the potential of Large Language Models (LLMs) to generate feedback on code assignments and to address the gaps in Automated Test-based Feedback (ATF) tools commonly employed in programming courses. We applied dedicated metrics in a Massive Open Online Course (MOOC) on programming to assess the correctness of feedback generated by two models, GPT-3.5-turbo and GPT-4, using a reliable ATF as a benchmark. The findings point to effective error detection, yet the feedback is often inaccurate, with GPT-4 outperforming GPT-3.5-turbo. We used insights gained from the prompt practices to develop Gipy, an application for submitting course assignments and obtaining LLM-generated feedback. Learners participating in a field experiment perceived the feedback provided by Gipy as moderately valuable, while at the same time recognizing its potential to complement ATF. Given the learners' critique and their awareness of the limitations of LLM-generated feedback, the studied implementation may be able to take advantage of the best of both ATF and LLMs as feedback resources. Further research is needed to assess the impact of LLM-generated feedback on learning outcomes and explore the capabilities of more advanced models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {177–187},
numpages = {11},
keywords = {MOOC for programming, automated feedback, generative AI, large language models (LLMs), programming education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3649409.3691086,
author = {Velez, Xavier},
title = {Understanding Algorithmic Problem Solving using LLMs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691086},
doi = {10.1145/3649409.3691086},
abstract = {With the rapid advancement of Large Language Models (LLMs) many instructors for Computer Science courses have begun to opt to allow students to use them as an additional educational resource but often warn that the output may be unreliable. Recent research on LLMs has demonstrated their ability to interpret commands in natural language and produce code in a variety of programming languages. However, it is not clear how well LLMs fair in tackling more complex problem set ups, like those typically seen in Algorithms courses in which students are provided natural language descriptions of an ambiguous problem and use what they learn to map the problem to an algorithmic solution. In this paper, we explore use of LLMs, such as OpenAI's GPT-4o, as tools for assisting students with complex Computer Science curricula, such as algorithmic problem solving. We specifically aim to see if using prompt refinement techniques, LLMs are capable of taking a problem statement in plain English and performing the following tasks: providing both a natural language description and code solution in the Python programming language, producing an analytical argument for the solutions correctness, and finally providing runtime analysis for the produced solution. Our experiments show that GPT-4o is well suited to solving problems like LeetCode 75 that have been seen during training, and prompt-refinement helps with those that have not been seen.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {327–328},
numpages = {2},
keywords = {GPT-4o, algorithms, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3636243.3636256,
author = {Doughty, Jacob and Wan, Zipiao and Bompelli, Anishka and Qayum, Jubahed and Wang, Taozhi and Zhang, Juran and Zheng, Yujia and Doyle, Aidan and Sridhar, Pragnya and Agarwal, Arav and Bogart, Christopher and Keylor, Eric and Kultur, Can and Savelka, Jaromir and Sakr, Majd},
title = {A Comparative Study of AI-Generated (GPT-4) and Human-crafted MCQs in Programming Education},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636256},
doi = {10.1145/3636243.3636256},
abstract = {There is a constant need for educators to develop and maintain effective up-to-date assessments. While there is a growing body of research in computing education on utilizing large language models&nbsp;(LLMs) in generation and engagement with coding exercises, the use of LLMs for generating programming MCQs has not been extensively explored. We analyzed the capability of GPT-4 to produce multiple-choice questions (MCQs) aligned with specific learning objectives (LOs) from Python programming classes in higher education. Specifically, we developed an LLM-powered (GPT-4) system for generation of MCQs from high-level course context and module-level LOs. We evaluated 651 LLM-generated and 449 human-crafted MCQs aligned to 246 LOs from 6 Python courses. We found that GPT-4 was capable of producing MCQs with clear language, a single correct choice, and high-quality distractors. We also observed that the generated MCQs appeared to be well-aligned with the LOs. Our findings can be leveraged by educators wishing to take advantage of the state-of-the-art generative models to support MCQ authoring efforts.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {114–123},
numpages = {10},
keywords = {Assessments, Automated Content Generation, Automatic Generation, GPT-4, LLMs, LOs, Large Language Models, Learning Objectives, MCQs, Multiple-choice Questions},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3639474.3640058,
author = {Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
title = {Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640058},
doi = {10.1145/3639474.3640058},
abstract = {Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {221–232},
numpages = {12},
keywords = {QLCs, large language models, artificial intelligence, introductory programming, program comprehension},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3632620.3671097,
author = {Ali, Murtaza and Rao, Prerna and Mai, Yifan and Xie, Benjamin},
title = {Using Benchmarking Infrastructure to Evaluate LLM Performance on CS Concept Inventories: Challenges, Opportunities, and Critiques},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671097},
doi = {10.1145/3632620.3671097},
abstract = {BACKGROUND AND CONTEXT. The pace of advancement of large language models (LLMs) motivates the use of existing infrastructure to automate the evaluation of LLM performance on computing education tasks. Concept inventories are well suited for evaluation because of their careful design and prior validity evidence. OBJECTIVES. Our research explores the feasibility of using an automated benchmarking framework to evaluate computer science (CS) concept inventories. We explore three primary objectives: evaluation of LLM performance on the SCS1 and BDSI concept inventories; informal expert panel review of items which had variations between LLM and expected student performance; and description of challenges with using benchmarking infrastructure as a methodological innovation. METHOD. We used the Holistic Evaluation of Language Models (HELM) framework to evaluate the SCS1 and BDSI against 10 LLMS with zero-shot and few-shot in-context learning: GPT (3.5, 4.0), Claude (1.3, 2.0, 2.1), Llama (7B, 13B, 70B), Mistral v0.1 7B, and Mixtral 8x7B. We used psychometric data from prior studies to measure knowledge levels for each LLM run. We then conducted an informal expert review to qualitatively explore how question design, CS content knowledge, and LLM design may explain differences between LLM and expected student performances. FINDINGS. Our quantitative analysis found that most LLM response patterns reflected a below average introductory computing student with the SCS1 and did not fit the psychometric 2PL model for the BDSI. Our qualitative analysis identified that LLMs performed well on code infill questions, but poorly on nested conditionals, runtime analysis, and longer questions. We also identified several methodological challenges related to item security, translation, the structure when using HELM. IMPLICATIONS. We consider the feasibility of using automated benchmarking as a methodology to support more reproducible, replicable, and rigorous investigations to understand the intersection of LLM capabilities, computing concepts, and assessment design. We also consider connections between psychometric approaches and LLM evaluations to inform the design of computing assessments that are more resilient to LLM advancements.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {452–468},
numpages = {17},
keywords = {benchmarking, computing education, concept inventories, large language models, psychometrics},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {Software Engineering Education, Oral Examinations, Examination Formats, ChatGPT},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@inproceedings{10.1145/3568812.3603476,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Cambronero, Jos\'{e} and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603476},
doi = {10.1145/3568812.3603476},
abstract = {Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {41–42},
numpages = {2},
keywords = {ChatGPT, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649165.3690101,
author = {Hellas, Arto and Leinonen, Juho and Lepp\"{a}nen, Leo},
title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690101},
doi = {10.1145/3649165.3690101},
abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {46–52},
numpages = {7},
keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3643795.3648389,
author = {Dingle, Adam and Krulis, Martin},
title = {Tackling Students' Coding Assignments with LLMs},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648389},
doi = {10.1145/3643795.3648389},
abstract = {State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {94–101},
numpages = {8},
keywords = {LLM, large language model, coding, programming, student assignment, teaching},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3636243.3636245,
author = {Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636245},
doi = {10.1145/3636243.3636245},
abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {11–18},
numpages = {8},
keywords = {bug detection, computing education, generative AI, large language models, programming errors},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3626253.3635403,
author = {Li, Yi and Zhang, Riteng and Qu, Danni and Marques Samary, Ma\'{\i}ra},
title = {Mining Students' Mastery Levels from CS Placement Tests via LLMs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635403},
doi = {10.1145/3626253.3635403},
abstract = {In higher education, introductory Computer Science (CS) programs offer a range of foundational courses. These encompass not only the standard CS1 and CS2 courses but may also include more specialized options like CS0 and CS1.5. In order to appropriately assign students to the suitable introductory courses, many institutions utilize placement tests, which assess students' pre-existing knowledge and skills. While most institutions rely on accuracy alone to make these determinations, there is often additional information concealed within the completed tests. This paper delves into the potential of Large Language Models (LLMs) to uncover this hidden information, particularly in gaining insights into how students perform in different concepts. Moreover, our framework has the flexibility to accommodate variations in curricula across different institutions, providing additional analytical perspectives. Initially, we built a concept inventory (CI) using the concepts covered in an institution's CS0, CS1, and CS2 curricula. Next, an LLM, specifically GPT 3.5, was applied to associate each question in the placement test with one or more concepts in the CI. Finally, the results of the placement tests were scrutinized, allowing the calculation of mastery levels in each concept for individual students. These mastery levels enable institutions to gauge a student's prior knowledge across various concepts simply by using a CS placement test. Additionally, we presented a case study demonstrating the application of this framework to 267 existing placement test results at Boston College.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1883},
numpages = {1},
keywords = {concept inventory, introductory computer science courses, large language models, placement test},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3568812.3603474,
author = {Singla, Adish},
title = {Evaluating ChatGPT and GPT-4 for Visual Programming},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603474},
doi = {10.1145/3568812.3603474},
abstract = {Generative AI has the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. In particular, this potential lies in the advanced capabilities of state-of-the-art deep generative and large language models such as OpenAI’s Codex&nbsp;[7], ChatGPT&nbsp;[11], and GPT-4&nbsp;[12]. In our work, we seek to investigate the capabilities of these models in visual programming domains popularly used for K-8 programming education, including domains like Scratch&nbsp;[17], Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5], and Karel&nbsp;[13]. Recent works have shown us sparks of advanced capabilities of such models for various education scenarios in introductory Python programming&nbsp;[2, 14, 18, 20]. In fact, a study in 2022 had ranked Codex in the top quartile w.r.t students in a large Python programming course&nbsp;[8]. However, all these works consider only text-based Python programming and leave open the question of how well these models would perform for visual programming. The main research question is: Do state-of-the-art neural generative models show advanced capabilities for visual programming on par with their capabilities on text-based Python programming?In our work, we evaluate these models for visual programming based on the following three settings designed to capture various generative and problem-solving capabilities: We conduct our evaluation based on 10 representative tasks from two visual programming domains: Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5] and Intro to Programming with Karel course by CodeHS.com&nbsp;[3, 13]. As illustrative examples, Figures&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3 show the output of GPT-4 in three settings for Maze18 task. We will provide the detailed analysis and prompts used in a longer version of this poster. Our preliminary results for ChatGPT (based on GPT-3.5) and GPT-4 show that these models perform poorly and produce incorrect output the majority of the time. These results highlight that state-of-the-art neural generative models like GPT-4 still struggle to combine spatial, logical, and programming skills crucial for visual programming. As the next step, it would be important to curate novel benchmarks that the research community can use to evaluate improvements in future versions of these models for visual programming.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {14–15},
numpages = {2},
keywords = {ChatGPT, block-based visual programming, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3626253.3635380,
author = {Veilleux, Nanette and Bates, Rebecca and Goldsmith, Judy and Summet, Valerie},
title = {Mentoring, AI, and the End of Affirmative Action: Connecting with SIGCSE Reads},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635380},
doi = {10.1145/3626253.3635380},
abstract = {This Birds of a Feather will begin with a high-level overview of the SIGCSE Reads 2024 books and then quickly move to discussion about mentoring students in the era of large language models and ChatGPT, including how students may value the curriculum differently, how learning outcomes may change, and how we can support students and alumni/ae as they work with rapidly changing job and learning expectations. We expect that many of the sessions at SIGCSE will address the radical shifts in learning outcomes and curricular changes due to LLMs. We will not focus on the particulars of these changes, but rather on mentoring in this time with Sister Resisters: Mentoring Black Women on Campus by Janie Victoria Ward and Tracy L. Robinson-Wood as a resource. How do we guide our students through the curriculum upheaval triggered by shifting learning outcomes? How do we help them prepare for the new instantiation of computer science?  This BOF is the primary session for SIGCSE Reads. We encourage discussion of this year's fiction works The Lifecycle of Software Objects by Ted Chiang and "Dolly" by Elizabeth Bear, as well as past Reads, throughout the conference.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1922},
numpages = {1},
keywords = {computing education, diversity in computing, mentoring, science fiction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635408,
author = {Xiang, Lili},
title = {SQL Query Evaluation with Large Language Model and Abstract Syntax Trees},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635408},
doi = {10.1145/3626253.3635408},
abstract = {SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from "good" to "unacceptable". The experimental results demonstrate that we can enhance the grading efficiency by applying these approaches and illustrate the ability of utilizing LLM to classify the assessed SQL statements more accurately. In addition, this research contributes to Computer Science (CS) education by integrating these approaches into our team's automated SQL statement assessment tool, improving the learning experience and evaluation process.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1890},
numpages = {1},
keywords = {abstract syntax trees, auto-grader, cs education, large language model, sql},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630897,
author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
title = {Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630897},
doi = {10.1145/3626252.3630897},
abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {618–624},
numpages = {7},
keywords = {introductory programming, large language models, non-native english speakers, problem generation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3639474.3640076,
author = {Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
title = {Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640076},
doi = {10.1145/3639474.3640076},
abstract = {Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey.With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {331–341},
numpages = {11},
keywords = {CS education, CS1, generative AI, ChatGPT, OOP},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3568813.3600139,
author = {Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\"{a}\"{a}, Lilja and Sorva, Juha},
title = {Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600139},
doi = {10.1145/3568813.3600139},
abstract = {Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {93–105},
numpages = {13},
keywords = {CS1, GPT, OpenAI Codex, automatic feedback, help seeking, introductory programming education, large language models, student questions},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649405.3659504,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen},
title = {Analyzing Students' Preferences for LLM-Generated Analogies},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659504},
doi = {10.1145/3649405.3659504},
abstract = {Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {812},
numpages = {1},
keywords = {analogies, computer science education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3699538.3699581,
author = {Vassar, Alexandra and Renzella, Jake and Ross, Emily and Taylor, Andrew},
title = {Fine-Tuning Large Language Models for Better Programming Error Explanations},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699581},
doi = {10.1145/3699538.3699581},
abstract = {This paper investigates supervised fine-tuning of large language models (LLMs) to improve their pedagogical alignment in computing education, addressing concerns that LLMs may hinder learning outcomes. The project utilised a proprietary dataset of 2,500 high quality question/answer pairs from programming course forums, and explores two research questions: the suitability of university course forums in contributing to fine-tuning datasets, and how supervised fine-tuning can improve LLMs’ alignment with educational principles such as constructivism. Initial findings suggest benefits in pedagogical alignment of LLMs, with deeper evaluations required.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {26},
numpages = {2},
keywords = {Programming Error Messages, CS1, AI in CS1, AI in Education, Generative AI, LLM},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3626253.3635601,
author = {Dehbozorgi, Nasrin and Kunuku, Mourya T.},
title = {An LLM-based Reflection Analysis Tool for Identifying and Addressing Challenging Topics},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635601},
doi = {10.1145/3626253.3635601},
abstract = {Traditional evaluation of students' learning primarily relies on assessing learning outcomes through either summative or formative assessment methods. In these approaches, the primary emphasis is on the students' learning outcome, rather than the learning process. However, assessing the learning process is as important since it allows providing timely feedback which can directly impact students' learning outcomes. One of the known approaches to getting information about the learning process is the use of formative reflection tools, which also help students in developing their meta-cognitive skills. One effective method for formative reflection is the Minute Paper technique which asks students two concise questions after each class session: what they have learned and what challenges they have encountered. While Minute Papers encourage brief responses, the analysis process can become time-consuming as the number of students and class sessions grows. To address this challenge, in this study, we propose a Large Language Model (LLM)-based reflection analysis tool designed to assess the challenging topics students encounter during each class session. This tool suggests additional learning modules for students to study based on the frequency of the challenging topics. To achieve this, the model utilizes a local repository of lecture materials to create query contexts, which are then input into the LLM as prompts. Students are given access to these recommended resources for further learning, and they are encouraged to provide feedback after completing these modules. These data-driven recommended learning resources serve as continuous content delivery channels to foster a deeper understanding of the subjects at hand.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1618–1619},
numpages = {2},
keywords = {automated reflection analysis, chatgpt, cs education, large language models (llm), learning outcome, natural language processing (nlp)},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3722479.3722526,
author = {Xie, Jingnan},
title = {Improving Introductory Java Programming Education Through ChatGPT},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The realm of introductory computer science (CS) education is swiftly changing, as educators actively pursue inventive strategies to captivate and empower students. This manuscript introduces a fresh methodology for teaching CS1 or CS2 courses, concentrating specifically on the fundamental principles of Java programming. Harnessing the capabilities of ChatGPT, an AI language model, we delve into how integrating conversational AI into the classroom milieu can foster a more dynamic and tailored learning journey. By furnishing a platform for students to pose inquiries, seek elucidation, and promptly receive feedback, ChatGPT functions as a virtual mentor, complementing conventional teaching methodologies. We scrutinize the potential repercussions of this approach on student learning outcomes (SLOs) and juxtapose it with traditional classroom paradigms. Furthermore, we deliberate on the ramifications of employing AI in education and its contribution to molding the trajectory of introductory programming courses.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {140–150},
numpages = {11}
}

@inproceedings{10.1145/3615886.3627745,
author = {Mooney, Peter and Cui, Wencong and Guan, Boyuan and Juh\'{a}sz, Levente},
title = {Towards Understanding the Geospatial Skills of ChatGPT: Taking a Geographic Information Systems (GIS) Exam},
year = {2023},
isbn = {9798400703485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615886.3627745},
doi = {10.1145/3615886.3627745},
abstract = {This paper examines the performance of ChatGPT, a large language model (LLM), in a geographic information systems (GIS) exam. As LLMs like ChatGPT become increasingly prevalent in various domains, including education, it is important to understand their capabilities and limitations in specialized subject areas such as GIS. Human learning of spatial concepts significantly differs from LLM training methodologies. Therefore, this study aims to assess ChatGPT's performance and ability to grasp geospatial concepts by challenging it with a real GIS exam. By analyzing ChatGPT's responses and evaluating its understanding of GIS principles, we gain insights into the potential applications and challenges of LLMs in spatially-oriented fields. We conduct our evaluation with two models, GPT-3.5 and GPT-4, to understand whether general improvements of an LLM translate to improvements in answering questions related to the spatial domain. We find that both GPT variants can pass a balanced, introductory GIS exam, scoring 63.3% (GPT-3.5) and 88.3% (GPT-4), which correspond to grades D and B+ respectively in standard US letter grading scale. In addition, we also identify specific questions and topics where the LLMs struggle to grasp spatial concepts, highlighting the challenges in teaching such topics to these models. Finally, we assess ChatGPT's performance in specific aspects of GIS, including spatial analysis, basic concepts of mapping, and data management. This granular analysis provides further insights into the strengths and weaknesses of ChatGPT's GIS literacy. This research contributes to the ongoing dialogue on the integration of AI models in education and can provide guidance for educators, researchers, and practitioners seeking to leverage LLMs in GIS. By focusing on specific questions or concepts that pose difficulties for the LLM, this study addresses the nuances of teaching spatial concepts to AI models and offers potential avenues for improvement in spatial literacy within future iterations of LLMs.},
booktitle = {Proceedings of the 6th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {85–94},
numpages = {10},
keywords = {geospatial, foundation model, education, Large Language Models, Generative AI, GIS, ChatGPT},
location = {Hamburg, Germany},
series = {GeoAI '23}
}

@inproceedings{10.1145/3643991.3644926,
author = {Idialu, Oseremen Joy and Mathews, Noble Saji and Maipradit, Rungroj and Atlee, Joanne M. and Nagappan, Mei},
title = {Whodunit: Classifying Code as Human Authored or GPT-4 Generated - A case study on CodeChef problems},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644926},
doi = {10.1145/3643991.3644926},
abstract = {Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT, built on large language models like GPT-4, are revolutionizing how programming tasks are performed, raising questions about whether code is authored by generative AI models. Such questions are of particular interest to educators, who worry that these tools enable a new form of academic dishonesty, in which students submit AI-generated code as their work. Our research explores the viability of using code stylometry and machine learning to distinguish between GPT-4 generated and human-authored code. Our dataset comprises human-authored solutions from CodeChef and AI-authored solutions generated by GPT-4. Our classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A variant of our classifier that excludes gameable features (e.g., empty lines, whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We also evaluated our classifier on the difficulty of the programming problem and found that there was almost no difference between easier and intermediate problems, and the classifier performed only slightly worse on harder problems. Our study shows that code stylometry is a promising approach for distinguishing between GPT-4 generated code and human-authored code.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {394–406},
numpages = {13},
keywords = {code stylometry, ChatGPT, AI code, GPT-4 generated code, authorship profiling, software engineering},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3626253.3635624,
author = {Fan, Aysa X. and Hendrawan, Rully A. and Shi, Yang and Ma, Qianou},
title = {Enhancing Code Tracing Question Generation with Refined Prompts in Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635624},
doi = {10.1145/3626253.3635624},
abstract = {This study refines Large Language Models (LLMs) prompts to enhance the generation of code tracing questions, where the new expert-guided prompts consider features identified from prior research. Expert evaluations compared new LLM-generated questions against previously preferred ones, revealing improved quality in aspects like complexity and concept coverage. While providing insights into effective question generation and affirming LLMs' potential in educational content creation, the study also contributes an expert-evaluated question dataset to the computing education community. However, generating high-quality reverse tracing questions remains a nuanced challenge, indicating a need for further LLM prompting refinement.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1640–1641},
numpages = {2},
keywords = {computer science education, large language model, programming education, tracing question},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653612,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653612},
doi = {10.1145/3649217.3653612},
abstract = {Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {52–58},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, code llama, generative ai, gpt-4, large language models, llm-as-a-judge, llms, open source, programming feedback, zephyr},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3545947.3569630,
author = {MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami},
title = {Automatically Generating CS Learning Materials with Large Language Models},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3569630},
doi = {10.1145/3545947.3569630},
abstract = {Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1176},
numpages = {1},
keywords = {code generation, computer science education, copilot, explanations, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3632620.3671103,
author = {Logacheva, Evanfiya and Hellas, Arto and Prather, James and Sarsa, Sami and Leinonen, Juho},
title = {Evaluating Contextually Personalized Programming Exercises Created with Generative AI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671103},
doi = {10.1145/3632620.3671103},
abstract = {Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students’ interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners’ situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students’ interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {95–113},
numpages = {19},
keywords = {automatic exercise generation, context personalization, generative AI, large language models},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3644815.3644969,
author = {Bur\'{e}gio, Vanilson and Pereira, Iverson and Cabral, Henrique},
title = {Innovating Translation: Lessons Learned from BWX Generative Language Engine},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644969},
doi = {10.1145/3644815.3644969},
abstract = {The integration of Translation Management Systems (TMS) and Large Language Models (LLMs) has revolutionized the translation landscape, offering nuanced and culturally sensitive translations. This paper explores the lessons learned from developing the BWX Generative Language Engine, an award-winning Generative AI tool for translation, which exemplifies the application of generative AI in translation management. Lessons include the transformative impact of AI, the accelerated delivery of beta features with LLMs, and the strategic integration of enabling technologies. Additionally, insights are drawn from strategic testing for optimal model routing, caching mechanisms, fallbacks, and the importance of security and data policy awareness.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {98–99},
numpages = {2},
keywords = {generative AI, translation management systems, large language models, software engineering},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3691620.3695537,
author = {Zhao, Jiuang and Yang, Donghao and Zhang, Li and Lian, Xiaoli and Yang, Zitian and Liu, Fang},
title = {Enhancing Automated Program Repair with Solution Design},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695537},
doi = {10.1145/3691620.3695537},
abstract = {Automatic Program Repair (APR) endeavors to autonomously rectify issues within specific projects, which generally encompasses three categories of tasks: bug resolution, new feature development, and feature enhancement. Despite extensive research proposing various methodologies, their efficacy in addressing real issues remains unsatisfactory. It's worth noting that, typically, engineers have design rationales (DR) on solution--- planed solutions and a set of underlying reasons---before they start patching code. In open-source projects, these DRs are frequently captured in issue logs through project management tools like Jira. This raises a compelling question: How can we leverage DR scattered across the issue logs to efficiently enhance APR?To investigate this premise, we introduce DRCodePilot, an approach designed to augment GPT-4-Turbo's APR capabilities by incorporating DR into the prompt instruction. Furthermore, given GPT-4's constraints in fully grasping the broader project context and occasional shortcomings in generating precise identifiers, we have devised a feedback-based self-reflective framework, in which we prompt GPT-4 to reconsider and refine its outputs by referencing a provided patch and suggested identifiers. We have established a benchmark comprising 938 issue-patch pairs sourced from two open-source repositories hosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot achieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is utilized directly. Additionally, the CodeBLEU scores also exhibit promising enhancements. Moreover, our findings reveal that the standalone application of DR can yield promising increase in the full-match ratio across CodeLlama, GPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot initiative heralds a novel human-in-the-loop avenue for advancing the field of APR.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1706–1718},
numpages = {13},
keywords = {design rationale, issue logs, developer discussion, automated program repair},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3626252.3630937,
author = {Grover, Shuchi},
title = {Teaching AI to K-12 Learners: Lessons, Issues, and Guidance},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630937},
doi = {10.1145/3626252.3630937},
abstract = {There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12 "big ideas" framework and employ a plurality of pedagogies.This paper provides a sense for the current state of the field, shares lessons learned from early K-12 AI education as well as CS education efforts that can be leveraged, highlights issues that must be addressed in designing for teaching AI in K-12, and provides guidance for future K-12 AI education efforts and tackle what to many feels like "the next new thing".},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {422–428},
numpages = {7},
keywords = {artificial intelligence, k-12 ai education, k-12 cs education, machine learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3689535.3689546,
author = {Andrei, Oana and Sojtory, Zoltan},
title = {LLM-aided Pair Programming for Algorithm Tracing},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689546},
doi = {10.1145/3689535.3689546},
abstract = {The recent widespread popularity of generative AI models has inspired the development of large-language model (LLM) based tools for educational purposes. We explore the impact of LLM-based tools on pair programming for algorithm tracing with the aim of addressing challenges inherent to pair programming. We designed and developed a GPT-4 based tool, TraceCompanion, that acts as students’ pair programming partner for algorithm tracing. We describe insights gained from running a pilot study to investigate students’ interactions with the tool and their initial perceptions.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {20},
numpages = {1},
keywords = {algorithm tracing, large language models, pair programming},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3626253.3635542,
author = {Smith, David H. and Zilles, Craig},
title = {Evaluating Large Language Model Code Generation as an Autograding Mechanism for "Explain in Plain English" Questions},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635542},
doi = {10.1145/3626253.3635542},
abstract = {The ability of students to ''Explain in Plain English'' (EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1824–1825},
numpages = {2},
keywords = {autograding, eipe, gpt-4, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3661167.3661202,
author = {De Vito, Gabriele},
title = {Assessing healthcare software built using IoT and LLM technologies},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661202},
doi = {10.1145/3661167.3661202},
abstract = {In the fast-paced world of healthcare technology, combining IoT devices with large language models (LLMs) offers a promising path to transform Clinical Decision-Support Systems (CDSS). This Ph.D. project is designed to tap into IoT’s extensive data collection ability and LLMs’ superior natural language processing skills. It aims to improve clinical decision-making and patient care through a sophisticated DSS that utilizes both technologies’ strengths. The project delves into the software engineering challenges and methodologies required to build an effective DSS. It investigates how to smoothly evaluate and integrate IoT and LLMs into healthcare environments, tackling significant issues like data complexity, privacy concerns, and the necessity for high accuracy in medical settings. It underscores the critical role of thorough evaluation and assessment in developing healthcare technologies.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {476–481},
numpages = {6},
keywords = {Clinical Decision Support System, Healthcare Software Assessment, Large Language Models},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3636555.3636846,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, Jos\'{e} and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636846},
doi = {10.1145/3636555.3636846},
abstract = {Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {12–23},
numpages = {12},
keywords = {ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

@inproceedings{10.1145/3649165.3690116,
author = {Golesteanu, Matei A. and Vowinkel, Garrett B. and Dougherty, Ryan E.},
title = {Can ChatGPT pass a Theory of Computing Course?},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690116},
doi = {10.1145/3649165.3690116},
abstract = {Large Language Models (LLMs) have had considerable difficulty when prompted with mathematical and formal questions, especially those within theory of computing (ToC) courses. In this paper, we detail two experiments regarding our own ToC course and the ChatGPT LLM. For the first, we evaluated ChatGPT's ability to pass our own ToC course's exams. For the second, we created a database of sample ToC questions and responses to accommodate other ToC offerings' choices for topics and structure. We scored each of ChatGPT's outputs on these questions. Overall, we determined that ChatGPT can pass our ToC course, and is adequate at understanding common formal definitions and answering "simple''-style questions, e.g., true/false and multiple choice. However, ChatGPT often makes nonsensical claims in open-ended responses, such as proofs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {33–38},
numpages = {6},
keywords = {automata theory, chatgpt, computer science education, formal languages, large language model, theoretical computer science},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3587102.3588852,
author = {Balse, Rishabh and Valaboju, Bharath and Singhal, Shreya and Warriem, Jayakrishnan Madathil and Prasad, Prajish},
title = {Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588852},
doi = {10.1145/3587102.3588852},
abstract = {Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course.We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {292–298},
numpages = {7},
keywords = {GPT-3, evaluation, feedback, large language models (LLM), python programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.5555/3715602.3715619,
author = {Hong, Alexander and Hong, Gongbing},
title = {The Effectiveness of Coding LLMs and the Challenges in Teaching CS1/2: A Case Study},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {This paper presents a case study that evaluates the effectiveness of coding Large Language Models (LLMs) in introductory computer science courses at the university level. The study assesses six different AI-powered code generators. The evaluation focuses on the accuracy of these AI code generators in solving ten programming problems from a set of problems that instructors at Duke University can assign to students for weekly completion. The results demonstrate the effectiveness of coding LLMs in solving these problems.Based on the findings, the paper discusses the challenges faced by the computer science education community and potential strategies to address them. The advent of coding LLMs poses significant challenges to traditional teaching and learning methods in computer science. These challenges include the need for strategies to mitigate any negative impact of LLMs on the learning process. At the same time, these code LLMs also offer tremendous opportunities for enhancing teaching and learning.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {122–131},
numpages = {10}
}

@inproceedings{10.1145/3617650.3624947,
author = {Sane, Aamod and Albuquerque, Melwina and Gupta, Madhav and Valadi, Jayaraman},
title = {ChatGPT Didn't Take Me Very Far, Did It?},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624947},
doi = {10.1145/3617650.3624947},
abstract = {The effect of ChatGPT (CG) on teachers, assessment and other matters have been discussed in many works, but no one appears to have studied how students are actually using it. We study how students use CG for coursework, a semester long project, and summer internships. We discover that from a student's perspective, CG responses fall into three classes: it is immediately helpful, it needs user help, or it leads to unhelpful frustration. We are developing a classification of these uses as a prelude to understanding how CG can contribute to improving student learning outcomes.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {204},
numpages = {1},
keywords = {learning technologies, large language models, LLM, ChatGPT, CS education},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3626253.3635404,
author = {Howard-Sarin, Brij},
title = {The Future of the Error Message: Comparing Large Language Models and Novice Programmer Effectiveness in Fixing Errors},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635404},
doi = {10.1145/3626253.3635404},
abstract = {Research on enhancing error message presentation is of great interest to teachers and developers alike because improving Integrated Development Environments (IDEs) increases early student retention and efficiency at all levels with more effective developing tools. This study aims to compare GPT-4 and novice programmer accuracy in fixing errors to assess the viability of Large Language Models as an error message enhancement tool. First, a random sample of 100,000 sessions from all users of BlueJ 5, an IDE for novice programmers, was analyzed to determine the time it took programmers to resolve coding errors. Subsequently, for each of the five most common errors, GPT-4 was given 20 randomly-selected snippets of code from Blackbox mini, a curated subset of Blackbox with source code attached, and prompted to explain and fix the errors. This study replicated prior research that proposed a Zipf-Mandelbrot Distribution of error message frequency; the five most common errors comprised 45% of all error messages. In comparing GPT-4 and novices, it was found that humans fix code at higher rates, but GPT-4 provided completely correct explanations for error messages 96% of the time. This study concludes that GPT-4 functions best as a tool to explain error messages in an interactive format, rather than as a tool to produce correct code on its own. In conclusion, GPT-4 would be best utilized to enhance the classroom experience as a chat assistant to reduce time spent on syntactical errors, leading to improved productivity and better novice retention.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {BlueJ, GPT-4, IDEs, blackbox, error message enhancement, error messages, large language models, novice programmers},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3568813.3600142,
author = {Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
title = {Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600142},
doi = {10.1145/3568813.3600142},
abstract = {This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {78–92},
numpages = {15},
keywords = {AI code generation, AlphaCode, ChatGPT, Codex, GPT, GitHub Copilot, MCQ, Multiple-choice question answering, Python course, coding exercises, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649409.3691092,
author = {de Miranda, Fabio and Ferrao, Rafael Corsi and Soler, Diego Pavan and Vieira Graglia, Marcelo Augusto},
title = {LLM-based Individual Contribution Summarization in Software Projects},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691092},
doi = {10.1145/3649409.3691092},
abstract = {This work in progress is about preliminary results in using a Large Language Model (LLM) to summarize individual student contributions in open-ended software projects. Projects for industry clients are good real-world learning opportunities. Though, if the scope is open and defined based on external clients' needs, each group's project will look unique, what makes a challenge for grading and regular feedback. Distributed code version control systems such as Git and resources such as Git classroom help, but it is still burdensome to have professors and TAs looking at the repositories with a frequency that enables useful, timely feedback for the students. We prototyped a method of summarizing each student's contributions to a project's Git repository using an LLM, indicating how to preprocess and break down repository data in order to get better responses from the system. Each student's contributions were extracted using Pydriller. This technique was tested during a 3-week full-time software development sprint in a class of 28 students. Preliminary results indicate a general agreement of students and faculty with the synthesized summaries and an increase in students' awareness of individual responsibilities within the teams and an improvement in engagement among less active members.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {307–308},
numpages = {2},
keywords = {project assessment, software engineering education, teamwork},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3657604.3664665,
author = {Koutcheme, Charles and Hellas, Arto},
title = {Propagating Large Language Models Programming Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664665},
doi = {10.1145/3657604.3664665},
abstract = {Large language models (LLMs) such as GPT-4 have emerged as promising tools for providing programming feedback. However, effective deployment of LLMs in massive classes and Massive Open Online Courses (MOOCs) raises financial concerns, calling for methods to minimize the number of calls to the APIs and systems serving such powerful models. In this article, we revisit the problem of 'propagating feedback' within the contemporary landscape of LLMs. Specifically, we explore feedback propagation as a way to reduce the cost of leveraging LLMs for providing programming feedback at scale. Our study investigates the effectiveness of this approach in the context of students requiring next-step hints for Python programming problems, presenting initial results that support the viability of the approach. We discuss our findings' implications and suggest directions for future research in optimizing feedback mechanisms for large-scale educational environments.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {366–370},
numpages = {5},
keywords = {computer science education, large language models, programming feedback},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3634737.3659433,
author = {Jiang, Fengqing and Xu, Zhangchen and Niu, Luyao and Wang, Boxin and Jia, Jinyuan and Li, Bo and Poovendran, Radha},
title = {POSTER: Identifying and Mitigating Vulnerabilities in LLM-Integrated Applications},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3659433},
doi = {10.1145/3634737.3659433},
abstract = {Compared with the traditional usage of large language models (LLMs) where users directly send queries to an LLM, LLM-integrated applications serve as middleware to refine users' queries with domain-specific knowledge to better inform LLMs and enhance the responses. However, LLM-integrated applications also introduce new attack surfaces. This work considers a setup where the user and LLM interact via an application in the middle. We focus on the interactions that begin with user's queries and end with LLM-integrated application returning responses to the queries, powered by LLMs at the service backend. We identify potential high-risk vulnerabilities in this setting that can originate from the malicious application developer or from an outsider threat initiator that can control the database access, manipulate and poison high-risk data for the user. Successful exploits of the identified vulnerabilities result in the users receiving responses tailored to the intent of a threat initiator. We assess such threats against LLM-integrated applications empowered by GPT-3.5 and GPT-4. Our experiments show that the threats can effectively bypass the restrictions and moderation policies of OpenAI, resulting in users exposing to the risk of bias, toxic content, privacy, and disinformation. We develop a lightweight, threat-agnostic defense to mitigate insider and outsider threats. Our evaluations demonstrate the efficacy of our defense.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {1949–1951},
numpages = {3},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

@inproceedings{10.1145/3657604.3664663,
author = {Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris},
title = {DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664663},
doi = {10.1145/3657604.3664663},
abstract = {Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {351–355},
numpages = {5},
keywords = {computer science education, generative ai, software development life cycle, software engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3660650.3660656,
author = {Bird, William},
title = {Faceless Adversary, Feckless Colleague: The Many Sides of ChatGPT},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660656},
doi = {10.1145/3660650.3660656},
abstract = {Although CS educators have studied the potential of generative AI for years, the release of ChatGPT in late 2022 sparked a wave of uncertainty and anxiety. With students arriving at university already experienced with using ChatGPT for work across the academic spectrum, educators were under pressure to somehow address the presence of this new resource in their classroom. This article describes both the “climate of fear” surrounding ChatGPT’s impacts on education and an attempt by the authors to induct ChatGPT as a colleague instead of an adversary. While creating a video series where we used ChatGPT to generate practice exercises for CS1 and CS2, we found it to be patient, charismatic and friendly, but also sometimes obstinate, misinformed, stubborn and confused; in other words, it was surprisingly human.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {14},
numpages = {6},
keywords = {CS education, generative AI, teaching tools},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3649217.3653568,
author = {del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Automating Personalized Parsons Problems with Customized Contexts and Concepts},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653568},
doi = {10.1145/3649217.3653568},
abstract = {Parsons problems provide useful scaffolding for introductory programming students learning to write code. However, generating large numbers of high-quality Parsons problems that appeal to the diverse range of interests in a typical introductory course is a significant challenge for educators. Large language models (LLMs) may offer a solution, by allowing students to produce on-demand Parsons problems for topics covering the breadth of the introductory programming curriculum, and targeting thematic contexts that align with their personal interests. In this paper, we introduce PuzzleMakerPy, an educational tool that uses an LLM to generate unlimited contextualized drag-and-drop programming exercises in the form of Parsons Problems, which introductory programmers can use as a supplemental learning resource. We evaluated PuzzleMakerPy by deploying it in a large introductory programming course, and found that the ability to personalize the contextual framing used in problem descriptions was highly engaging for students, and being able to customize the programming topics was reported as being useful for their learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {688–694},
numpages = {7},
keywords = {cs education tools, cs1, large language models, parsons problems, personalized learning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635400,
author = {Hurley, Ethan and Okyere-Badoo, Joel},
title = {A Comparative Study of Few-Shot vs. Zero-Shot Prompting to Generate Quick and Useful Responses to Students' Periodic Reflections},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635400},
doi = {10.1145/3626253.3635400},
abstract = {Our study investigates the effectiveness of leveraging Large Language Models (LLMs), such as GPT-3.5, to generate responses to student reflections. Acknowledging the intensive nature of manually handling reflections, our investigation centers on crafting prompts to automate reflection response generation. Driven by fast and meaningful response generation to student reflections, we explored both Zero-Shot learning (ZSL) and Few-Shot learning (FSL) methodologies. Our research meticulously examined the facets of each approach, highlighting the significance of consistent and meaningful responses.The Few-Shot prompting approach involves creating a fundamental prompt based on reflection questions and desired responses, striving for consistency while facing challenges such as GPT-3.5 computational time and issues related to content "hallucinations." In contrast, Zero-Shot prompting utilizes the base prompt and response without the assistance of examples. The evaluation process entails a meticulous examination of the quality of GPT-3.5 responses compared to the original student reflections.In the future, our study foresees integrating our devised prompting techniques as a resource for educators to promptly grasp students' learning concerns and issues. Despite challenges, Few-Shot prompting stands out as the more reliable and relevant approach, particularly in the context of email-based formats. As Machine Learning and AI continue to advance, overcoming challenges and adjusting to fluctuations in student emotions and content remains a pivotal factor in fully harnessing the capabilities of LLMs for automating the generation of responses to student reflections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {artificial intelligence (ai), few-shot learning (fsl), large language models (llms), student reflections, zero-shot learning (zsl)},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653533,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Kan, Lauren and Hellas, Arto and Littlefield, Matt and Sarsa, Sami and Macneil, Stephen},
title = {"Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students Using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653533},
doi = {10.1145/3649217.3653533},
abstract = {Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies produced with student-prescribed topics, in contrast to the otherwise generic analogies, highlighting the value of student creativity when working with LLMs. Not only did students enjoy the activity and report an improved understanding of recursion, but they described more easily remembering analogies that were personally and culturally relevant.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {122–128},
numpages = {7},
keywords = {analogies, computing education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3627217.3627233,
author = {Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627233},
doi = {10.1145/3627217.3627233},
abstract = {When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {49–54},
numpages = {6},
keywords = {Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3632620.3671112,
author = {Skripchuk, James and Bacher, John and Price, Thomas},
title = {An Investigation of the Drivers of Novice Programmers' Intentions to Use Web Search and GenAI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671112},
doi = {10.1145/3632620.3671112},
abstract = {External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web resources such as tutorial websites and Q&amp;A forums. With the rise of Generative AI (GenAI), there has been increasing concern and research about how external resources should be used in the classroom. However, little work has directly contrasted student beliefs and perceptions of web resources with GenAI, has grounded these beliefs in prior psychological theory, and has investigated how demographic factors and student backgrounds influence these beliefs and intentions. We administered a vignette-style survey across two courses required for a CS major at an R1 University, a freshman (n = 152) and senior capstone course (n = 44). Students responded to likert questions aiming to measure behavioral factors related to these tools, such as intention to use, perceived attitudes, peer perceptions, and their own perceived tool competency. We primarily investigate the results of an introductory course, finding that novices have a wide range of opinions on both resources, but overall find them slightly useful and have a tendency to prefer web-search. We compare this with seniors, who have more positive perceptions of these tools, and discuss possible reasons and implications for this difference. We constructed two path models to investigate which factors strongly influence novices’ intention to use resources and find the primary factor to be their general attitudes in how these tools will result in a positive or negative outcome (e.g. perceived benefits, justifiability). We also measure the effects of student background on intention to use these resources. Finally, we discuss implications and suggestions on how instructors can use this information to approach, address, and influence resource usage in their classrooms.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {487–501},
numpages = {15},
keywords = {CS Education, GenAI, Help-seeking, student perspectives, web-search},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3626252.3630799,
author = {Al-Hossami, Erfan and Bunescu, Razvan and Smith, Justin and Teehan, Ryan},
title = {Can Language Models Employ the Socratic Method? Experiments with Code Debugging},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630799},
doi = {10.1145/3626252.3630799},
abstract = {When employing the Socratic method of teaching, instructors guide students toward solving a problem on their own rather than providing the solution directly. While this strategy can substantially improve learning outcomes, it is usually time-consuming and cognitively demanding. Automated Socratic conversational agents can augment human instruction and provide the necessary scale, however their development is hampered by the lack of suitable data for training and evaluation. In this paper, we introduce a manually created dataset of multi-turn Socratic advice that is aimed at helping a novice programmer fix buggy solutions to simple computational problems. The dataset is then used for benchmarking the Socratic debugging abilities of a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and chain of thought prompting of the much larger GPT-4. The code and datasets are made freely available for research at the link below.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {53–59},
numpages = {7},
keywords = {benchmark dataset, debugging, language models, socratic dialogue},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630863,
author = {Del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating Automatically Generated Contextualised Programming Exercises},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630863},
doi = {10.1145/3626252.3630863},
abstract = {Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {289–295},
numpages = {7},
keywords = {chatgpt, cs1, gpt-4, large language models, novice programmers, openai, programming exercises, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635592,
author = {Niousha, Rose and Hoq, Muntasir and Akram, Bita and Norouzi, Narges},
title = {Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635592},
doi = {10.1145/3626253.3635592},
abstract = {This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1762–1763},
numpages = {2},
keywords = {cs1, curriculum design, knowledge component},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3690123,
author = {Ramesh, Aninditha and Agarwal, Arav and Doughty, Jacob Arthur and Ramaneti, Ketan and Savelka, Jaromir and Sakr, Majd},
title = {A Benchmark for Testing the Capabilities of LLMs in Assessing the Quality of Multiple-choice Questions in Introductory Programming Education},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690123},
doi = {10.1145/3649165.3690123},
abstract = {There has been a growing interest in utilizing large language models (LLMs) for numerous educational applications. Recent studies have focused on the use of LLMs for generating various educational artifacts for programming education, such as programming exercises, model solutions, or multiple-choice questions (MCQs). The ability to efficiently and reliably assess the quality of such artifacts, both automatically and human generated, has become of paramount importance. Hence, there is a pressing need to develop and make available robust benchmarks. In this paper, we investigate an example use case of assessing the quality of programming MCQs. To that end, we carefully curated a data set of 192 MCQs annotated with quality scores based on a rubric that evaluates crucial aspects such as, e.g., their clarity, the presence of a single correct answer, and the quality of distractors. The results show that the task presents a considerable challenge even to the state-of-the-art LLMs and, hence, further research is needed. To further such research efforts in this important area we release the dataset as well as the extensible evaluation pipeline to the public.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {193–199},
numpages = {7},
keywords = {assessments, automated evaluation, claude, computing education, gpt-4, large language models, llama, llms, mcqs, multiple choice questions},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3691555.3696825,
author = {Tang, Zuoyin and He, Jianhua and Pe, Dashuai and Liu, Kezhong and Gao, Tao and Zheng, Jiawei},
title = {Test Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles},
year = {2024},
isbn = {9798400712470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691555.3696825},
doi = {10.1145/3691555.3696825},
abstract = {Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs, which are difficult to be met locally at AVs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send driving assistance requests to the LLMs. LLMs deployed at the edge of the networks or remote clouds process the requests and generate driving assistance instructions for the CAVs. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. As there is no published work on assessing LLM of driving theory and skills, we design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. These questions are close to the official UK driving theory test ones. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% (just below the 86% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-o has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.},
booktitle = {Proceedings of the 19th Workshop on Mobility in the Evolving Internet Architecture},
pages = {1–6},
numpages = {6},
keywords = {Connected autonomous vehicles, driving theory test, large language model, mobile cloud computing, mobile edge computing, remote driving},
location = {Washington D.C., DC, USA},
series = {MobiArch '24}
}

@inproceedings{10.1145/3626253.3633436,
author = {Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto},
title = {Using Large Language Models for Teaching Computing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633436},
doi = {10.1145/3626253.3633436},
abstract = {In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is "what can I do?". We propose that one promising way forward is to integrate LLMs into teaching practice, providing all students with an equal opportunity to learn how to interact productively with LLMs as well as encounter and understand their limitations. In this workshop, we first present state-of-the-art research results on how to utilize LLMs in computing education practice, after which participants will take part in hands-on activities using LLMs. We end the workshop by brainstorming ideas with participants around adapting their classrooms to most effectively integrate LLMs while avoiding some common pitfalls.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1901},
numpages = {1},
keywords = {generative ai, large language models, teaching practice},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3501709.3544280,
author = {MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng},
title = {Generating Diverse Code Explanations using the GPT-3 Large Language Model},
year = {2022},
isbn = {9781450391955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501709.3544280},
doi = {10.1145/3501709.3544280},
abstract = {Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 2},
pages = {37–39},
numpages = {3},
keywords = {natural language processing, large language models, computer science education, code explanations},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3639474.3640068,
author = {Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan},
title = {Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640068},
doi = {10.1145/3639474.3640068},
abstract = {Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct.In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {1–11},
numpages = {11},
keywords = {software engineering education, AI-generated code, AI-generated code detection},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3649217.3653600,
author = {Villegas Molina, Ismael and Montalvo, Audria and Zhong, Shera and Jordan, Mollie and Soosai Raj, Adalbert Gerald},
title = {Generation and Evaluation of a Culturally-Relevant CS1 Textbook for Latines using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653600},
doi = {10.1145/3649217.3653600},
abstract = {In the United States, culturally relevant computing (CRC) is one of the most popular pedagogical implementations for Latin American (Latine) students. Culturally-relevant learning resources are a valuable tool for implementing CRC. However, the traditional method of creation and maintenance of textbooks takes a significant amount of time and effort. Given the duration required for textbook production, the development of culturally-relevant learning resources may become lengthened, as it requires close attention both on the material and the incorporation of cultural referents. In order to accelerate the process, we used the advancement of large language models (LLMs) to our advantage. Through prompt engineering, we created a series of prompts to produce a textbook for an introductory computer science course (CS1) that incorporates Latine culture. This textbook was evaluated on metrics regarding sensibility, correctness, readability, linguistic approachability, appropriateness of examples, and cultural relevance. Overall, the generated textbook was mainly sensible, correct, readable, and linguistically approachable. Code examples were not always appropriate due to the usage of libraries that are not typically used in a CS1 course. The cultural relevance was apparent, but it often included surface-level cultural referents. The main incorporation of culture was through geographical locations and people's names. This suggests that the use of LLMs to generate textbooks may serve as a valuable first step for writing culturally-relevant learning resources. Though this study focuses on Latines, our results and prompts may be applicable for generating culturally-relevant CS1 textbooks for other cultures.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {325–331},
numpages = {7},
keywords = {Latina, Latine, Latino, Latinx, computer science textbook, culturally relevant resources, large language models, resource generation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3657604.3664697,
author = {Jin, Hyoungwook and Kim, Yoonsu and Park, Yeon Su and Tilekbay, Bekzat and Son, Jinho and Kim, Juho},
title = {Using Large Language Models To Diagnose Math Problem-solving Skills At Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664697},
doi = {10.1145/3657604.3664697},
abstract = {Personalized feedback, tailored to students' needs and prior knowledge, is essential for fostering mathematical problem-solving skills. However, personalized feedback is often limited to one-to-one tutoring or small classrooms as it requires instructors' in-depth diagnosis of cognitive processes employed in students' answers. We propose a large language model (LLM) pipeline that diagnoses students' problem-solving skills from their answers at scale in elementary school math word problems. Based on prior literature and an interview with a math education expert, we developed PERC, a framework composed of four problem-solving stages that students can follow: Parse, Extract, Retrieve, and Combine. The framework facilitates diagnosis by externalizing students' step-by-step problem-solving processes and allowing our pipeline to analyze each stage individually. Our LLM pipeline diagnoses each stage by (1) generating rubrics and (2) comparing students' answers with the rubrics. We fine-tuned our LLM pipeline with 71 math problem-rubric pairs and 128 problem-answer-grade triplets collected from elementary school students. We evaluated our pipeline's diagnosis accuracy against vanilla GPT-3.5 and vanilla GPT-4 with automatic and expert evaluations. The results showed the potential of our approach in improving the end-to-end diagnosis accuracy of LLMs, and expert evaluation provided specific aspects that should be improved.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {471–475},
numpages = {5},
keywords = {educational diagnosis at scale, large language models, mathematical problem-solving skills},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3587102.3588814,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588814},
doi = {10.1145/3587102.3588814},
abstract = {Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {61–67},
numpages = {7},
keywords = {GPT-3, large language models, object oriented programming, programming assignments, teaching},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3649409.3691076,
author = {Wiese, Eliane S. and Finnie-Ansley, James and Duran, Rodrigo and Cunningham, Kathryn and Demirtas, Mehmet Arif},
title = {Challenges and Solutions for Teaching Decomposition and Planning Skills in CS1},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691076},
doi = {10.1145/3649409.3691076},
abstract = {The task of decomposing a problem into sub-problems to build a solution, also formalized as planning in prior work, is a key skill for programming expertise. Improving the decomposition and planning skills of novices is shown to be a challenging goal for educators. Moreover, decomposing complex projects into smaller subtasks is an increasingly relevant skill with rapid developments in tools like large language models (LLMs). While there are many aspects of planning, one skill consistently observed in studies with experts is the ability to identify subtasks that can be solved via common code patterns. To support students in acquiring these skills, many researchers have explored explicit instruction about a set of common patterns in programs (i.e. programming plans). However, recent work implies that students may need additional support to fully benefit from such interventions. This panel aims to bring computing education researchers together to discuss the main challenges around teaching decomposition and planning using common patterns, the crucial factors for designing instruction for teaching these concepts, and the impact evolving technology like LLMs can have on these developments.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {291–292},
numpages = {2},
keywords = {cs1, decomposition, large language models, programming plans},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3551349.3559555,
author = {Ahmed, Toufique and Devanbu, Premkumar},
title = {Few-shot training LLMs for project-specific code-summarization},
year = {2023},
isbn = {9781450394758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3551349.3559555},
doi = {10.1145/3551349.3559555},
abstract = {Very large language models (LLMs), such as GPT-3 and Codex have achieved state-of-the-art performance on several natural-language tasks, and show great promise also for code. A particularly exciting aspect of LLMs is their knack for few-shot and zero-shot learning: they can learn to perform a task with very few examples. Few-shotting has particular synergies in software engineering, where there are a lot of phenomena (identifier names, APIs, terminology, coding patterns) that are known to be highly project-specific. However, project-specific data can be quite limited, especially early in the history of a project; thus the few-shot learning capacity of LLMs might be very relevant. In this paper, we investigate the use few-shot training with the very large GPT (Generative Pre-trained Transformer) Codex model, and find evidence suggesting that one can significantly surpass state-of-the-art models for code-summarization, leveraging project-specific training.},
booktitle = {Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering},
articleno = {177},
numpages = {5},
keywords = {code summarization, deep learning, large language model},
location = {Rochester, MI, USA},
series = {ASE '22}
}

@inproceedings{10.1145/3636555.3636889,
author = {Sonkar, Shashank and Chen, Xinghe and Le, Myco and Liu, Naiming and Basu Mallick, Debshila and Baraniuk, Richard},
title = {Code Soliloquies for Accurate Calculations in Large Language Models},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636889},
doi = {10.1145/3636555.3636889},
abstract = {High-quality conversational datasets are crucial for the successful development of Intelligent Tutoring Systems (ITS) that utilize a Large Language Model (LLM) backend. Synthetic student-teacher dialogues, generated using advanced GPT-4 models, are a common strategy for creating these datasets. However, subjects like physics that entail complex calculations pose a challenge. While GPT-4 presents impressive language processing capabilities, its limitations in fundamental mathematical reasoning curtail its efficacy for such subjects. To tackle this limitation, we introduce in this paper an innovative stateful prompt design. Our design orchestrates a mock conversation where both student and tutorbot roles are simulated by GPT-4. Each student response triggers an internal monologue, or ‘code soliloquy’ in the GPT-tutorbot, which assesses whether its subsequent response would necessitate calculations. If a calculation is deemed necessary, it scripts the relevant Python code and uses the Python output to construct a response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. The preliminary Subject Matter Expert evaluations reveal that our Higgs model, a fine-tuned LLaMA model, effectively uses Python for computations, which significantly enhances the accuracy and computational reliability of Higgs’ responses.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {828–835},
numpages = {8},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.5555/3722479.3722507,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Vautor-Laplaceliere, Daena D. and Noory, Naqib A.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Data Science Programs in Higher Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The integration of GenAI (GenAI), such as large language models (LLMs), in education has raised the question of how it will alter the students' training and learning outcomes. To better understand the phenomenon, this empirical study explores whether college students find GenAI tools helpful in advancing their skills, particularly Python programming proficiency.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {63–64},
numpages = {2}
}

@inproceedings{10.1145/3639477.3639720,
author = {Gallagher, Shannon K. and Ratchford, Jasmine and Brooks, Tyler and Brown, Bryan P. and Heim, Eric and Nichols, William R. and Mcmillan, Scott and Rallapalli, Swati and Smith, Carol J. and Vanhoudnos, Nathan and Winski, Nick and Mellinger, Andrew O.},
title = {Assessing LLMs for High Stakes Applications},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639720},
doi = {10.1145/3639477.3639720},
abstract = {Large Language Models (LLMs) promise strategic benefit for numerous application domains. The current state-of-the-art in LLMs, however, lacks the trust, security, and reliability which prohibits their use in high stakes applications. To address this, our work investigated the challenges of developing, deploying, and assessing LLMs within a specific high stakes application, intelligence reporting workflows. We identified the following challenges that need to be addressed before LLMs can be used in high stakes applications: (1) challenges with unverified data and data leakage, (2) challenges with fine tuning and inference at scale, and (3) challenges in reproducibility and assessment of LLMs. We argue that researchers should prioritize test and assessment metrics, as better metrics will lead to insight to further improve these LLMs.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {103–105},
numpages = {3},
keywords = {large language models, TEVV, metrics, scaling, HCI, trust},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3633598.3633614,
author = {Soygazi, Fatih and Oguz, Damla},
title = {An Analysis of Large Language Models and LangChain in Mathematics Education},
year = {2024},
isbn = {9798400708985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633598.3633614},
doi = {10.1145/3633598.3633614},
abstract = {The development of large language models (LLMs) has led to the consideration of new approaches, particularly in education. Word problems, especially in subjects like mathematics, and the need to solve these problems by collectively addressing specific stages of reasoning, have raised the question of whether LLMs can be successful in this area as well. In our study, we conducted analyses by asking mathematics questions especially related to word problems using ChatGPT, which is based on the latest language models like Generative Pretrained Transformer (GPT). Additionally, we compared the correct and incorrect answers by posing the same questions to LLMMathChain, a mathematics-specific LLM based on the latest language models like LangChain. It was observed that the answers obtained were more successful with ChatGPT (GPT 3.5), particularly in the field of mathematics. However, both language models were found to be below expectations, particularly in word problems, and suggestions for improvement were provided.},
booktitle = {Proceedings of the 2023 7th International Conference on Advances in Artificial Intelligence},
pages = {92–97},
numpages = {6},
keywords = {ChatGPT, LangChain, Large Language Models (LLMs), Mathematics Education},
location = {Istanbul, Turkiye},
series = {ICAAI '23}
}

@inproceedings{10.1145/3699538.3699588,
author = {Pereira Cipriano, Bruno and Silva, Miguel and Correia, Rodrigo and Alves, Pedro},
title = {Towards the Integration of Large Language Models and Automatic Assessment Tools: Enhancing Student Support in Programming Assignments},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699588},
doi = {10.1145/3699538.3699588},
abstract = {The rise of Large Language Models (LLMs) has sparked discussion in Computer Science Education (CSE) due to their ability to generate code from text prompts. Students may rely on these tools, neglecting core skills like computational thinking and program design. Thus, it’s crucial to responsibly integrate them into computer science courses.To address this, we integrated an open-source Automatic Assessment Tool with GPT, enabling students to receive LLM assistance on their programming assignments. This tool can be adopted and improved by educators, promoting more responsible integration of LLMs in CSE.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {52},
numpages = {2},
keywords = {large language models, automatic assessment tools, feedback},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3691620.3695349,
author = {Wang, Che and Zhang, Jiashuo and Gao, Jianbo and Xia, Libin and Guan, Zhi and Chen, Zhong},
title = {ContractTinker: LLM-Empowered Vulnerability Repair for Real-World Smart Contracts},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695349},
doi = {10.1145/3691620.3695349},
abstract = {Smart contracts are susceptible to being exploited by attackers, especially when facing real-world vulnerabilities. To mitigate this risk, developers often rely on third-party audit services to identify potential vulnerabilities before project deployment. Nevertheless, repairing the identified vulnerabilities is still complex and laborintensive, particularly for developers lacking security expertise. Moreover, existing pattern-based repair tools mostly fail to address real-world vulnerabilities due to their lack of high-level semantic understanding. To fill this gap, we propose ContractTinker, a Large Language Models (LLMs)-empowered tool for real-world vulnerability repair. The key insight is our adoption of the Chain-of-Thought approach to break down the entire generation task into subtasks. Additionally, to reduce hallucination, we integrate program static analysis to guide the LLM. We evaluate ContractTinker on 48 high-risk vulnerabilities. The experimental results show that among the patches generated by ContractTinker, 23 (48%) are valid patches that fix the vulnerabilities, while 10 (21%) require only minor modifications. A video of ContractTinker is available at https://youtu.be/HWFVi-YHcPE.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2350–2353},
numpages = {4},
keywords = {program repair, smart contract, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create "black box" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3643787.3648033,
author = {Balfroid, Martin and Vanderose, Beno\^{\i}t and Devroey, Xavier},
title = {Towards LLM-Generated Code Tours for Onboarding},
year = {2024},
isbn = {9798400705762},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643787.3648033},
doi = {10.1145/3643787.3648033},
abstract = {Onboarding new developers is a challenge for any software project. Addressing this challenge relies on human resources (e.g., having a senior developer write documentation or mentor the new developer). One promising solution is using annotated code tours. While this approach partially lifts the need for mentorship, it still requires a senior developer to write this interactive form of documentation. This paper argues that a Large Language Model (LLM) might help with this documentation process. Our approach is to record the stack trace between a failed test and a faulty method. We then extract code snippets from the methods in this stack trace using CodeQL, a static analysis tool and have them explained by gpt-3.5-turbo-1106, the LLM behind ChatGPT. Finally, we evaluate the quality of a sample of these generated tours using a checklist. We show that the automatic generation of code tours is feasible but has limitations like redundant and low-level explanations.},
booktitle = {Proceedings of the Third ACM/IEEE International Workshop on NL-Based Software Engineering},
pages = {65–68},
numpages = {4},
keywords = {large language models, code tour, developer onboarding},
location = {Lisbon, Portugal},
series = {NLBSE '24}
}

@inproceedings{10.1145/3632621.3671429,
author = {Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia},
title = {Using a Low-Code Environment to Teach Programming in the Era of LLMs},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671429},
doi = {10.1145/3632621.3671429},
abstract = {LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {542–543},
numpages = {2},
keywords = {Generative AI, LLMs, MOOC, Programming Education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3699538.3699541,
author = {Korpimies, Kai and Laaksonen, Antti and Luukkainen, Matti},
title = {Unrestricted Use of LLMs in a Software Project Course: Student Perceptions on Learning and Impact on Course Performance},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699541},
doi = {10.1145/3699538.3699541},
abstract = {Large language models (LLMs) provide round-the-clock personalized programming assistance, unlike course instructors or traditional online information sources such as Stack Overflow. While LLMs can aid in code generation, concerns about over-reliance and the impact on learning persist. This study discusses students’ experiences with LLMs in a software project course where students were allowed to use LLMs freely except for unit test generation. We conducted surveys during course instances in autumn 2023 and spring 2024. The surveys assessed the extent of LLM usage, methods of application, and perceived impact on learning. Results indicate diverse usage patterns, with many students finding LLMs beneficial for efficiency and problem-solving, though over-reliance and poor-quality outputs were noted concerns. The usage patterns can be linked to course performance and time spent on the project.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {23},
numpages = {7},
keywords = {Large language models, Computer Science Education, User Study, Code generation, Software project},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3632620.3671098,
author = {Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara},
title = {Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671098},
doi = {10.1145/3632620.3671098},
abstract = {The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM’s technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students’ social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students’ self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students’ use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students’ perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {114–130},
numpages = {17},
keywords = {Generative AI, Large Language Models, Self-Efficacy, Social Shaping Theory, Technology Appropriation Model},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3613905.3647967,
author = {Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase},
title = {Enhancing Programming Error Messages in Real Time with Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647967},
doi = {10.1145/3613905.3647967},
abstract = {Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {7},
keywords = {AI, Artificial Intelligence, Automatic Code Generation, CS1, ChatGPT, Codex, Copilot, GPT-4, GitHub, HCI, Introductory Programming, LLM, Large Language Models, Novice Programming, OpenAI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3648188.3680252,
author = {Argasi\'{n}ski, Jan K. and Marecki, Piotr},
title = {Exercises in unimaginativeness. Case study of GPT based translation and travesty of Alfred Jarry's “Ubu King”},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3680252},
doi = {10.1145/3648188.3680252},
abstract = {This paper investigates the application of large language models (LLMs), specifically GPT-4, in translating and transforming Alfred Jarry’s avant-garde play Ubu Roi (Ubu King) through the lens of "uncreative writing." This concept involves repurposing existing texts to generate new forms of literary expression that challenge traditional notions of originality and authorship. We conducted a case study by first translating Ubu Roi from French to Polish using GPT-4. Subsequently, the translated text was reinterpreted into various genres and styles, showcasing the model’s capability to navigate and creatively reshape classical literature. Generative Adversarial Networks (GANs), particularly Dall-E 3, were employed to produce illustrative content complementing these textual adaptations. This experiment highlights the transformative potential of AI in literature, emphasizing the convergence of digital technology and classical literary forms to generate novel insights and reinterpretations. The culmination of this project is the publication of a book that amalgamates these AI-driven reinterpretations, bridging the digital and analog realms.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {293–297},
numpages = {5},
keywords = {LLMs, literary arts, translation, uncreative writing},
location = {Poznan, Poland},
series = {HT '24}
}

@inproceedings{10.1145/3643795.3648393,
author = {Chusap, Krerkkiat and Liu, Chang},
title = {Gauging Tech Community Acceptance of Rapid Prototyping in Unfamiliar Programming Languages using LLM Chatbots},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648393},
doi = {10.1145/3643795.3648393},
abstract = {Large Language Model (LLM) chatbots such as ChatGPT possess information not only about human languages but also computer languages. It is now possible to perform programming and software design tasks with assistance from ChatGPT. We are particularly interested in how the software development community views the use of LLM chatbots in rapid prototyping using unfamiliar programming languages. In four different tech events, several example scenarios of how a tech-savvy engineer could use ChatGPT to prototype apps in unfamiliar programming languages were demonstrated, including a health education app. The four events include an IEEE chapter workshop, an IEEE WIE (Woman In Engineering) meeting, an IEEE joint chapter talk, and a university-level Computer Science class. The responses from the tech audience showed that the majority perceived value in the use of LLM chatbots in these contexts, even though there were subtle differences among different groups. This shows the need for further research on how to effectively incorporate LLM chatbots into traditional software design workflow to better serve the software development community.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {8–13},
numpages = {6},
keywords = {software engineering, software design, rapid prototyping, LLMs, ChatGPT},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3649165.3690099,
author = {Pang, Amy and Padiyath, Aadarsh and Viramontes Vargas, Diego and Ericson, Barbara Jane},
title = {Examining the Relationship between Socioeconomic Status and Beliefs about Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690099},
doi = {10.1145/3649165.3690099},
abstract = {Research on students' use of large language models (LLMs) in academic settings has increased recently, focusing on usage patterns, tasks, and instructor policies. However, there is limited research on the relationships between students' socioeconomic backgrounds, perceptions, and usage of these resources. As socioeconomic factors may shape students' approach to learning, it is important to understand their impact on students' perceptions and attitudes towards emerging technologies like LLMs. Thus, we analyzed a quantitative and internally consistent student survey (N=144) and qualitative interview (N=2) responses of students taking an undergraduate-level programming course at a public university for correlations between socioeconomic background, attitudes towards LLMs, and LLM usage. Regression analysis found a significant positive association between socioeconomic status (SES) and belief that LLM use will lead to career success. Qualitative interviews suggested low-SES students perceived LLMs as helpful tools for debugging and learning concepts, but not as a significant factor in long-term career success. Rather, programming knowledge itself was still paramount for career success. Our findings contribute to our understanding of the complex influences social and cultural factors have on students' perceptions and attitudes towards LLMs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {172–178},
numpages = {7},
keywords = {large language models, socioeconomic status, student attitudes},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3631700.3665233,
author = {Biancini, Giorgio and Ferrato, Alessio and Limongelli, Carla},
title = {Multiple-Choice Question Generation Using Large Language Models: Methodology and Educator Insights},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665233},
doi = {10.1145/3631700.3665233},
abstract = {Integrating Artificial Intelligence (AI) in educational settings has brought new learning approaches, transforming the practices of both students and educators. Among the various technologies driving this transformation, Large Language Models (LLMs) have emerged as powerful tools for creating educational materials and question answering, but there are still space for new applications. Educators commonly use Multiple-Choice Questions (MCQs) to assess student knowledge, but manually generating these questions is resource-intensive and requires significant time and cognitive effort. In our opinion, LLMs offer a promising solution to these challenges. This paper presents a novel comparative analysis of three widely known LLMs - Llama 2, Mistral, and GPT-3.5 - to explore their potential for creating informative and challenging MCQs. In our approach, we do not rely on the knowledge of the LLM, but we inject the knowledge into the prompt to contrast the hallucinations, giving the educators control over the test’s source text, too. Our experiment involving 21 educators shows that GPT-3.5 generates the most effective MCQs across several known metrics. Additionally, it shows that there is still some reluctance to adopt AI in the educational field. This study sheds light on the potential of LLMs to generate MCQs and improve the educational experience, providing valuable insights for the future.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {584–590},
numpages = {7},
keywords = {Generative AI, LLMs, Multiple Choice Question},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3649217.3653596,
author = {Apiola, Mikko and Vartiainen, Henriikka and Tedre, Matti},
title = {First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653596},
doi = {10.1145/3649217.3653596},
abstract = {Generative AI is a recent breakthrough in AI. While it has become a hot topic in computing education research (CER), much of the recent research has focused on e.g. issues of plagiarism or academic integrity. One problem spot with Generative AI is its susceptibility to various kinds of algorithmic bias. In this study, we collected data from an introductory computing course, where students experimented with text-to-image generative models and reflected on their generated image sets, in terms of biases, related harms, and possible fixes. Data were collected in Fall 2023 (pilot data in Fall 2022). Data included reports from 163 students. The results show (1) a variety of bias types observed by students related to gender, ethnicity, age, as well as a variety of bias types not observed by students, (2) two major types of attributions for the source of bias: bias caused by biases in the society and bias caused by data or algorithms, and (3) a number of potential harms associated with the biases, as well as attributions of those harms in specific contexts and use cases.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {485–491},
numpages = {7},
keywords = {bias, critical computing education, generative ai, social injustice},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3671016.3674823,
author = {Liu, Xingpeng and Liu, Hengzhu and Yi, Xiaodong and Wang, Ji},
title = {LLM-Enhanced Theorem Proving with Term Explanation and Tactic Parameter Repair✱},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671016.3674823},
doi = {10.1145/3671016.3674823},
abstract = {There has been emerging researches on leveraging large language models (LLMs) to improve the automation of theorem proving. However, they are still suffering from low accuracy and efficiency. In this paper, we propose to strengthen the existing approach by enhancing a language agent, which provides automatic explanation of terms and repair of tactics parameters. Term explanation explains terms specific to the proof obligations formally and tactic parameter repair complements the potentially correct proof tactics as much as possible. Similar to the existing approach, the agent uses GPT-4 as query objects in a search policy. During the search, we add term explanation to the prompt, and then the policy selects a proof tactic and repairs it. The repaired tactics interact with the theorem prover (Coq), and the execution result is fed back to build the prompt for the next policy invocation. We evaluate our approach on subsets of the CompCert project implemented using Coq. Our approach proves 8.11% more theorems than the existing language agent COPRA, and demonstrates faster search and proof speed. Besides, when term explanation and tactic parameter repair are applied, the performance of the SOTA method PROVERBOT9001 can be also improved.},
booktitle = {Proceedings of the 15th Asia-Pacific Symposium on Internetware},
pages = {21–30},
numpages = {10},
keywords = {Coq, Language Agent, Large Language Model, Theorem Proving},
location = {Macau, China},
series = {Internetware '24}
}

@inproceedings{10.1145/3545947.3573358,
author = {MacNeil, Stephen and Kim, Joanne and Leinonen, Juho and Denny, Paul and Bernstein, Seth and Becker, Brett A. and Wermelinger, Michel and Hellas, Arto and Tran, Andrew and Sarsa, Sami and Prather, James and Kumar, Viraj},
title = {The Implications of Large Language Models for CS Teachers and Students},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573358},
doi = {10.1145/3545947.3573358},
abstract = {The introduction of Large Language Models (LLMs) has generated a significant amount of excitement both in industry and among researchers. Recently, tools that leverage LLMs have made their way into the classroom where they help students generate code and help instructors generate learning materials. There are likely many more uses of these tools -- both beneficial to learning and possibly detrimental to learning. To help ensure that these tools are used to enhance learning, educators need to not only be familiar with these tools, but with their use and potential misuse. The goal of this BoF is to raise awareness about LLMs and to build a learning community around their use in computing education. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed discussion leaders, including undergraduate researchers, to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1255},
numpages = {1},
keywords = {artificial intelligence, code explanations, code generation, computer science education, copilot, gpt-3, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3610969.3611132,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron},
title = {Generative AI in Software Development Education: Insights from a Degree Apprenticeship Programme},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3611132},
doi = {10.1145/3610969.3611132},
abstract = {We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {19},
numpages = {1},
keywords = {Software Engineering, Generative AI, Education, Apprenticeships},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3649405.3659473,
author = {Cipriano, Bruno Pereira},
title = {Towards the Integration of Large Language Models in an Object-Oriented Programming Course},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659473},
doi = {10.1145/3649405.3659473},
abstract = {The advent of Large Language Models (LLMs) has created multiple challenges for the Computer Science Education Community. This research project aims at integrating LLMs into Object-Oriented Programming courses, by generating and evaluating new teaching methodologies and tools suitable for this paradigm's specificities.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {832–833},
numpages = {2},
keywords = {bard, gpt-3.5, gpt-4, large language models, object-oriented programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.5555/3643142.3643385,
author = {Giabbanelli, Philippe J.},
title = {GPT-Based Models Meet Simulation: How to Efficiently use Large-Scale Pre-Trained Language Models Across Simulation Tasks},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {The disruptive technology provided by large-scale pre-trained language models (LLMs) such as ChatGPT or GPT-4 has received significant attention in several application domains, often with an emphasis on high-level opportunities and concerns. This paper is the first examination regarding the use of LLMs for scientific simulations. We focus on four modeling and simulation tasks, each time assessing the expected benefits and limitations of LLMs while providing practical guidance for modelers regarding the steps involved. The first task is devoted to explaining the structure of a conceptual model to promote the engagement of participants in the modeling process. The second task focuses on summarizing simulation outputs, so that model users can identify a preferred scenario. The third task seeks to broaden accessibility to simulation platforms by conveying the insights of simulation visualizations via text. Finally, the last task evokes the possibility of explaining simulation errors and providing guidance to resolve them.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2920–2931},
numpages = {12},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3632621.3671415,
author = {Landesman, Rotem},
title = {Teens' Ethical Sensemaking About Emerging Technologies},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671415},
doi = {10.1145/3632621.3671415},
abstract = {Emerging technologies, among them generative AI, are continuously being integrated into the mundane fabric of young people’s lives and routines. Recently, scholars called to expand computing education beyond learning to use and create with technologies to think critically and ethically about their potential impacts as a means to encourage the development of a sense of computational empowerment. My research aims to explore this space and opportunities which encourage ethical thinking with youth - specifically adolescents - on and about generative AI, a recent emerging innovation. This exploration will take inspiration from previous work pointing to the efficacy of practices from the field of Philosophy for Children (P4C) as well as recent work pointing to the potential of eliciting ethical thinking through a critical reflection and making framework, and suggest a novel framework to elicit a sense of computational empowerment as youth grow up in our digital world.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {557–559},
numpages = {3},
keywords = {computing education, ethics in computing, k-12},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3597503.3639187,
author = {Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad},
title = {Using an LLM to Help With Code Understanding},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639187},
doi = {10.1145/3597503.3639187},
abstract = {Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {97},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3649217.3653582,
author = {Smith, David H. and Zilles, Craig},
title = {Code Generation Based Grading: Evaluating an Auto-grading Mechanism for "Explain-in-Plain-English" Questions},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653582},
doi = {10.1145/3649217.3653582},
abstract = {Comprehending and conveying the purpose of code is often cited as being a key learning objective within introductory programming courses. To address this objective, "Explain in Plain English'' questions, where students are shown a segment of code and asked to provide an abstract description of the code's purpose, have been adopted. However, given EiPE questions require a natural language response, they often require manual grading which is time-consuming for course staff and delays feedback for students. With the advent of large language models (LLMs) capable of generating code, responses to EiPE questions can be used to generate code segments, the correctness of which can then be easily verified using test cases. We refer to this approach as "Code Generation Based Grading'' (CGBG) and in this paper we explore its agreement with human graders using EiPE responses from past exams in an introductory programming course taught in Python. Overall, we find that all CGBG approaches achieve moderate agreement with human graders with the primary area of disagreement being its leniency with respect to low-level and line-by-line descriptions of code.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {171–177},
numpages = {7},
keywords = {auto-grading, eipe, gpt-4, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3617650.3624946,
author = {Balse, Rishabh and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624946},
doi = {10.1145/3617650.3624946},
abstract = {This research proposes an AI-assisted mentoring system for programming education, leveraging the advanced capabilities of OpenAI's GPT-4. We aim to validate students' pseudocode or algorithmic approaches to Python programming problems within the context of a Tier-1 institution in India, where the high student-to-mentor ratio presents unique challenges. The proposed system aspires to alleviate the pressures of the current mentoring system, providing a more accessible, responsive, and effective educational support system.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {191},
numpages = {1},
keywords = {python programming education, large language models, automated programming mentoring, GPT-4},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3639474.3640084,
author = {Sa\u{g}lam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
title = {Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640084},
doi = {10.1145/3639474.3640084},
abstract = {Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized solutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {297–308},
numpages = {12},
keywords = {plagiarism detection, obfuscation, ChatGPT, artificial intelligence},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3568812.3603482,
author = {Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen},
title = {Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603482},
doi = {10.1145/3568812.3603482},
abstract = {Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {22–23},
numpages = {2},
keywords = {computer science education, explanations, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649217.3653602,
author = {Mahon, Joyce and Mac Namee, Brian and Becker, Brett A.},
title = {Guidelines for the Evolving Role of Generative AI in Introductory Programming Based on Emerging Practice},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653602},
doi = {10.1145/3649217.3653602},
abstract = {In the rapidly evolving Generative AI (GenAI) landscape, source code and natural language are being mixed and used in new ways. This presents opportunities for rethinking teaching practice in Introductory Programming (CS1) courses that includes, but goes beyond, assessment. In this paper we examine the reasons why and how instructors who are early adopters of GenAI are using it in their teaching, and why others are not. We also explore the changes and adaptations that are currently being made to practice. This is achieved by synthesizing insights from several recent studies that have collected primary data from introductory programming instructors who are teaching with, considering teaching with, or actively not teaching with GenAI.Due to the fast pace of GenAI development and adoption, the fixed-pace and cyclical nature of education, and the relatively slow pace of research (including ethical approvals) and publication cycles, research with primary data from instructors is only being published relatively recently. In computing education, there is not yet enough published research with primary data from CS1 instructors to warrant a systematic literature review, although in the next year this will likely be possible. Based on an analysis of the nascent research that has been published, we propose emerging and flexible guidelines on how CS1 instructors could adapt their practice based on what others have done so far. These guidelines highlight important factors to consider when integrating GenAI in CS1 courses, which for many is only beginning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {10–16},
numpages = {7},
keywords = {CS1, LLM, artificial intelligence, automated/assisted code generation, chatgpt, computing education, copilot, generative AI, introductory programming, k-12, large language model, machine learning, novice programmer, school},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3653666.3656065,
author = {Smith, Julie M.},
title = {"I'm Sorry, but I Can't Assist": Bias in Generative AI},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656065},
doi = {10.1145/3653666.3656065},
abstract = {Research Questions: (1) Is there a pattern of racial bias in student advising recommendations made by generative AI? (2) What safeguards can promote equity when using generative AI in high-stakes decision-making? Methodology: Using lists of names associated with various ethnic/racial groups, we asked ChatGPT and Claude AI for recommendations for colleges and majors for each student. Results: ChatGPT was more likely to recommend STEM majors to some student groups. ChatGPT did not show systematic bias in various metrics of school quality, but Claude AI did. There were also overall differences in the colleges recommended by Claude AI and ChatGPT. Implications: We provide cautions and recommendations for using generative AI in high-stakes tasks.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {75–80},
numpages = {6},
keywords = {artificial intelligence, generative ai, large language models, quity, racism, student advising},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

@inproceedings{10.1145/3699538.3699546,
author = {Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\"{o}ppe, Christian and de Jong, Imke and Sosnovsky, Sergey},
title = {Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699546},
doi = {10.1145/3699538.3699546},
abstract = {Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {14},
numpages = {12},
keywords = {Generative AI, Large Language Models, Computing Education, Programming Courses},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3626253.3635524,
author = {Bevilacqua, Joey and Chiodini, Luca and Moreno Santos, Igor and Hauswirth, Matthias},
title = {Using Notional Machines to Automatically Assess Students' Comprehension of Their Own Code},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635524},
doi = {10.1145/3626253.3635524},
abstract = {Code comprehension has been shown to be challenging and important for a positive learning outcome. Students don't always understand the code they write. This has been exacerbated by the advent of large language models that automatically generate code that may or may not be correct. Now students don't just have to understand their own code, but they have to be able to critically analyze automatically generated code as well. To help students with code comprehension, instructors often use notional machines. Notional machines are used not only by instructors to explain code, but also in activities or exam questions given to students. Traditionally, these questions involve code that was not written by students. However, asking questions to students about their own code (Questions on Learners' Code, QLCs) has been shown to strengthen their code comprehension. This poster presents an approach to combine notional machines and QLCs to automatically generate personalized questions about learners' code based on notional machines. Our aim is to understand whether notional machine-based QLCs are effective. We conducted a pilot study with 67 students to test our approach, and we plan to conduct a comprehensive empirical evaluation to study its effectiveness.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1572–1573},
numpages = {2},
keywords = {assessment, code comprehension, expressions, notional machines, programmming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653584,
author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653584},
doi = {10.1145/3649217.3653584},
abstract = {The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {297–303},
numpages = {7},
keywords = {copilot, cs1, generative ai, introductory programming, llm},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3587103.3594202,
author = {Zhang, Paul and Jaipersaud, Brandon and Ba, Jimmy and Petersen, Andrew and Zhang, Lisa and Zhang, Michael R.},
title = {Classifying Course Discussion Board Questions using LLMs},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594202},
doi = {10.1145/3587103.3594202},
abstract = {Large language models (LLMs) can be used to answer student questions on course discussion boards, but there is a risk of LLMs answering questions they are unable to address. We propose and evaluate an LLM-based system that classifies student questions into one of four types: conceptual, homework, logistics, and not answerable. We then prompt an LLM using a type-specific prompt. Using GPT-3, we achieve 81% classification accuracy across the four categories. Furthermore, we achieve 93% accuracy on classifying not answerable questions. This indicates that our system effectively ignores questions that it cannot address.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {658},
numpages = {1},
keywords = {course discussion board, gpt-3, large language models, machine learning, natural language processing, question answering},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3709364,
author = {Min, Do June and P\'{e}rez-Rosas, Ver\'{o}nica and Resnicow, Kenneth and Mihalcea, Rada},
title = {Evaluating Language Models for Assessing Counselor Reflections},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709364},
doi = {10.1145/3709364},
abstract = {Reflective listening is a fundamental communication skill in behavioral health counseling. It enables counselors to demonstrate an understanding of and empathy for clients’ experiences and concerns. Training to acquire and refine reflective listening skills is essential for counseling proficiency. Yet, it faces significant barriers, notably the need for specialized and timely feedback to improve counseling skills. In this work, we evaluate and compare several computational models, including transformer-based architectures, for their ability to assess the quality of counselors’ reflective listening skills. We explore a spectrum of neural-based models, ranging from compact, specialized RoBERTa models to advanced large-scale language models such as Flan, Mistral, and GPT-3.5, to score psychotherapy reflections. We introduce a psychotherapy dataset that encompasses three basic levels of reflective listening skills. Through comparative experiments, we show that a finetuned small RoBERTa model with a custom learning objective (Prompt-Aware margIn Ranking (PAIR)) effectively provides constructive feedback to counselors in training. This study also highlights the potential of machine learning in enhancing the training process for motivational interviewing (MI) by offering scalable and effective feedback alternatives for counseling training.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = dec,
keywords = {Motivational Interviewing, Computational Counseling, Reflective Listening, Large Language Modeling}
}

@inproceedings{10.1145/3626253.3633407,
author = {Westerlund, Jill and Czajka, Sandra and Kuemmel, Andrew},
title = {Innovative Strategies for genAI in CS Courses},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633407},
doi = {10.1145/3626253.3633407},
abstract = {Students are using generative artificial intelligence (genAI), organizations are embracing AI and machine learning, tools are emerging almost daily, and addressing these evolving technologies can be overwhelming. Rather than choosing to ignore genAI, instructors of computer science (CS) can find ways to teach with and guide students in the use of genAI in their courses. Teaching about genAI can be incorporated with instruction about effective and appropriate uses of the ever-growing tools.This special session brings together three experienced CS educators who integrate genAI in their work with high school students, college students, and in-service teachers. The session environment allows for participant involvement in three model activities that showcase genAI tools with learner-focused practices. Participants will be provided supporting teaching resources for each guided activity and encouraged to discuss with peers and presenters.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1875–1876},
numpages = {2},
keywords = {ai, assessment, genai, instruction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3631802.3631816,
author = {Malaise, Yoshi and Signer, Beat},
title = {Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631816},
doi = {10.1145/3631802.3631816},
abstract = {We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {24},
numpages = {8},
keywords = {PRIMM, Programming Education, Study Lenses},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3640544.3645215,
author = {Laney, Mason and Dewan, Prasun},
title = {Human-AI Collaboration in a Student Discussion Forum},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645215},
doi = {10.1145/3640544.3645215},
abstract = {The recent public releases of AI tools such as ChatGPT have forced computer science educators to reconsider how they teach. These tools have demonstrated considerable ability to generate code and answer conceptual questions, rendering them incredibly useful for completing CS coursework. While overreliance on AI tools could hinder students’ learning, we believe they have the potential to be a helpful resource for both students and instructors alike. We propose a novel system for instructor-mediated GPT interaction in a class discussion board. By automatically generating draft responses to student forum posts, GPT can help Teaching Assistants (TAs) respond to student questions in a more timely manner, giving students an avenue to receive fast, quality feedback on their solutions without turning to ChatGPT directly. Additionally, since they are involved in the process, instructors can ensure that the information students receive is accurate, and can provide students with incremental hints that encourage them to engage critically with the material, rather than just copying an AI-generated snippet of code. We utilize Piazza—a popular educational forum where TAs help students via text exchanges—as a venue for GPT-assisted TA responses to student questions. These student questions are sent to GPT-4 alongside assignment instructions and a customizable prompt, both of which are stored in editable instructor-only Piazza posts. We demonstrate an initial implementation of this system, and provide examples of student questions that highlight its benefits.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {74–77},
numpages = {4},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3639475.3640097,
author = {Shi, Jieke and Yang, Zhou and Kang, Hong Jin and Xu, Bowen and He, Junda and Lo, David},
title = {Greening Large Language Models of Code},
year = {2024},
isbn = {9798400704994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639475.3640097},
doi = {10.1145/3639475.3640097},
abstract = {Large language models of code have shown remarkable effectiveness across various software engineering tasks. Despite the availability of many cloud services built upon these powerful models, there remain several scenarios where developers cannot take full advantage of them, stemming from factors such as restricted or unreliable internet access, institutional privacy policies that prohibit external transmission of code to third-party vendors, and more. Therefore, developing a compact, efficient, and yet energy-saving model for deployment on developers' devices becomes essential.To this aim, we propose Avatar, a novel approach that crafts a deployable model from a large language model of code by optimizing it in terms of model size, inference latency, energy consumption, and carbon footprint while maintaining a comparable level of effectiveness (e.g., prediction accuracy on downstream tasks). The key idea of Avatar is to formulate the optimization of language models as a multi-objective configuration tuning problem and solve it with the help of a Satisfiability Modulo Theories (SMT) solver and a tailored optimization algorithm. The SMT solver is used to form an appropriate configuration space, while the optimization algorithm identifies the Pareto-optimal set of configurations for training the optimized models using knowledge distillation. We evaluate Avatar with two popular language models of code, i.e., CodeBERT and GraphCodeBERT, on two popular tasks, i.e., vulnerability prediction and clone detection. We use Avatar to produce optimized models with a small size (3 MB), which is 160\texttimes{} smaller than the original large models. On the two tasks, the optimized models significantly reduce the energy consumption (up to 184\texttimes{} less), carbon footprint (up to 157\texttimes{} less), and inference latency (up to 76\texttimes{} faster), with only a negligible loss in effectiveness (1.67%).},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society},
pages = {142–153},
numpages = {12},
keywords = {language models of code, configuration tuning, multi-objective optimization},
location = {Lisbon, Portugal},
series = {ICSE-SEIS'24}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3689535.3689543,
author = {Addo, Salomey Afua and Sentance, Sue},
title = {Exploring Computing Teachers' Readiness to Teach AI in Secondary Schools},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689543},
doi = {10.1145/3689535.3689543},
abstract = {Artificial intelligence (AI) is significantly impacting how we live, and the increased capabilities of generative AI applications have positioned AI firmly in the public domain. There is a growing interest in what AI might look like as a subject within the K-12 curriculum, whilst research on teachers’ readiness for teaching AI is as yet limited. This paper describes a qualitative study investigating teachers’ readiness to teach AI in secondary education. The interview study involved eight computing teachers with varying teaching experiences. We used reflexive thematic analysis for themes development. Findings suggest several indicators of teachers’ readiness, including attitudes, prior AI experience, professional development, and access to quality resources. This paper contributes to ongoing debates about how to best support teachers to be ready to teach AI effectively at the school level.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {17},
numpages = {1},
keywords = {K-12 education, artificial intelligence, computing education, teacher readiness},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3617650.3624950,
author = {Bouvier, Dennis J. and Lovellette, Ellie and Santos, Eddie Antonio and Becker, Brett A. and Crick, Tom and Dasigi, Venu G. and Forden, Jack and Glebova, Olga and Joshi, Swaroop and Kurkovsky, Stan and Russell, Se\'{a}n},
title = {Teaching Students To Use Programming Error Messages},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624950},
doi = {10.1145/3617650.3624950},
abstract = {Research shows many students struggle to use programming error and warning messages effectively. Instead of using these messages as aids to debug and fix their code, some students have negative emotional reactions to seeing 'angry red text'. Not utilizing programming error and warning messages effectively, or at all, increases the difficulty of learning to program.As compiler messages can vary by programming language and/or development environment, lessons on reading them are not typically included in mainstream educational materials. We believe this gap can be filled and that students can learn to use error messages to their advantage. Further, we believe that teaching students how to read and use error messages can have a significant impact on the learning experience for novice programmers.The goal of this working group is to develop educational materials to teach students to use programming error messages, and evaluate the use of these materials. An additional goal is to investigate the role that large language models may play in the interpretation of error messages in the educational environment. We will produce guidelines for developing educational materials and strategies informed by feedback obtained from the community and our experimentation.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {207–208},
numpages = {2},
keywords = {warning messages, runtime errors, programming error messages, novice programmers, error messages, computing education, computer error messages},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3677525.3678665,
author = {Feldhus, Nils and Anagnostopoulou, Aliki and Wang, Qianli and Alshomary, Milad and Wachsmuth, Henning and Sonntag, Daniel and M\"{o}ller, Sebastian},
title = {Towards Modeling and Evaluating Instructional Explanations in Teacher-Student Dialogues},
year = {2024},
isbn = {9798400710940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677525.3678665},
doi = {10.1145/3677525.3678665},
abstract = {For dialogues in which teachers explain difficult concepts to students, didactics research often debates which teaching strategies lead to the best learning outcome. In this paper, we test if LLMs can reliably annotate such explanation dialogues, s.t. they could assist in lesson planning and tutoring systems. We first create a new annotation scheme of teaching acts aligned with contemporary teaching models and re-annotate a dataset of conversational explanations about communicating scientific understanding in teacher-student settings on five levels of the explainee’s expertise: ReWIRED contains three layers of acts (Teaching, Explanation, Dialogue) with increased granularity (span-level). We then evaluate language models on the labeling of such acts and find that the broad range and structure of the proposed labels is hard to model for LLMs such as GPT-3.5/-4 via prompting, but a fine-tuned BERT can perform both act classification and span labeling well. Finally, we operationalize a series of quality metrics for instructional explanations in the form of a test suite, finding that they match the five expertise levels well.1},
booktitle = {Proceedings of the 2024 International Conference on Information Technology for Social Good},
pages = {225–230},
numpages = {6},
keywords = {Dialogue, Discourse Analysis, Evaluation, Explanations},
location = {Bremen, Germany},
series = {GoodIT '24}
}

@inproceedings{10.1145/3657604.3662033,
author = {Nguyen, Ha and Nguyen, Victoria and L\'{o}pez-Fierro, Sar\'{\i}ah and Ludovise, Sara and Santagata, Rossella},
title = {Simulating Climate Change Discussion with Large Language Models: Considerations for Science Communication at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662033},
doi = {10.1145/3657604.3662033},
abstract = {Large language models (LLMs) have shown promise in simulating public opinions on social issues. These models can be leveraged in educational simulations that allow students to acquire information and feedback from multiple perspectives. In this research, we investigate the potential of using LLMs (specifically GPT-4) to generate open-ended responses about climate change within a science communication simulation. We prompt GPT-4 to role-play as different personas with various demographics (race/ethnicity, gender, age, income, political affiliations, and ability status) and levels of concern about climate change. We find that GPT-4 is capable of representing multifaceted perspectives around climate change's impact and solutions. However, the model may exaggerate narratives for certain personas based on political affiliations, gender, and concern levels. Such exaggeration may lead to homogeneous narratives that do not fully represent the simulated personas. Our findings highlight the affordances and challenges of applying LLMs to simulating public opinions and enriching educational experiences.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {28–38},
numpages = {11},
keywords = {large language models, public opinions, science communication},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3699538.3699591,
author = {Keuning, Hieke and Luxton-Reilly, Andrew and Ott, Claudia and Petersen, Andrew and Kiesler, Natalie},
title = {Goodbye Hello World - Research Questions for a Future CS1 Curriculum},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699591},
doi = {10.1145/3699538.3699591},
abstract = {Generative AI (GenAI) is currently capable of generating correct code for introductory level programming problems, and its performance is improving. We believe that this capability can be leveraged to improve student motivation, broaden students’ understanding of software development, and engage them in more authentic learning. We defined a set of assumptions about GenAI’s future capabilities (e.g., the ability to generate small pieces of code and to compose these pieces of code via user prompts) and engaged in a backcasting exercise to identify what else is needed to develop a CS1 course that places GenAI in a central role. Undertaking this thought experiment immediately revealed that aspects of the software development process usually reserved for later in the curriculum, such as requirements elicitation and design, could be introduced earlier in the process. With GenAI tools bearing the load of generating correct code snippets, students could focus on higher-level software design and construction skills and practice them in an authentic environment. Our thought experiment identified a set of questions that need to be addressed for such a course to actually exist, including questions about student preparation, and the ability of students to decompose problems effectively and to resolve problems that arise when integrating pieces of code. We also identified questions related to the design of a GenAI centered course, such as the impact on student motivation of using GenAI instead of engaging directly with code, the extent to which social learning theories apply to interactions with GenAI, and how existing pedagogies can integrate GenAI tools.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {27},
numpages = {2},
keywords = {Computing education, CS1, Generative AI, Mastery Learning, LLMs},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653615,
author = {Gardella, Nicholas and Pettit, Raymond and Riggs, Sara L.},
title = {Performance, Workload, Emotion, and Self-Efficacy of Novice Programmers Using AI Code Generation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653615},
doi = {10.1145/3649217.3653615},
abstract = {Artificial Intelligence-driven Development Environments (AIDEs) offer developers revolutionary computer programming assistance. There is great potential in incorporating AIDEs into Computer Science education; however, the effects of these tools should be fully examined before doing so. Here, a within-subjects study was conducted to compare the programming performance, workload, emotion, and self-efficacy of seventeen novices coding with and without use of the GitHub Copilot AIDE under time pressure. Results showed that using the AIDE significantly increased programming efficiency and reduced effort and mental workload but did not significantly impact emotion or self-efficacy. However, participants' performance improved with more experience using the AI, and their self-efficacy followed. The results suggest that students who try AIDEs will likely be tempted to use them for time-sensitive work. There is no evidence that providing AIDEs will aid struggling students, but there is a clear need for students to practice with AI to become competent and confident using it.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {290–296},
numpages = {7},
keywords = {ai code generators, artificial intelligence-driven development environment, computer science education, cs1, generative ai, github copilot, introductory programming, novice programmers},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626203.3670628,
author = {Oelgoetz, Megan and Walker, Tony},
title = {Improving an NSF ACCESS Program AI Chatbot: Response Data Logistic Regression},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670628},
doi = {10.1145/3626203.3670628},
abstract = {The NSF ACCESS program has implemented a vendor-supplied AI chatbot using the OpenAI GPT-4 large language model. ACCESS provides high performance computing (HPC) resources to researchers by allocating time at computing centers at diverse institutions of higher education across the United States. Effectively implementing a large language model on a limited knowledge base for the diversity of the resources and technical nature of HPC in general has raised questions in optimal knowledge base construction. The following analysis takes a limited test case to investigate the driving factors contributing to the accuracy of the chatbot’s response to predetermined prompts, specifically regarding the clusters on which specific software applications are currently available. It additionally tests the necessity of providing documentation of synonymous terms in the form of a synonym dictionary in the knowledge base. While ongoing, this initial research utilizing logistic regression suggests the knowledge base is yet insufficient for the prompts given and that the synonym dictionary has no statistically significant effect on the response.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {101},
numpages = {3},
keywords = {Artificial Intelligence, HPC Facilitation, Logistic Regression, Natural Language Processing},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3649165.3690094,
author = {Ma, Iris and Krone-Martins, Alberto and Videira Lopes, Cristina},
title = {Integrating AI Tutors in a Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690094},
doi = {10.1145/3649165.3690094},
abstract = {RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions.  RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98% of the time. Among the students who used AI tutors, 78% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {130–136},
numpages = {7},
keywords = {education, large language models, llms, software engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3650212.3680328,
author = {Yang, Boyang and Tian, Haoye and Pian, Weiguo and Yu, Haoran and Wang, Haitao and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F. and Jin, Shunfu},
title = {CREF: An LLM-Based Conversational Software Repair Framework for Programming Tutors},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680328},
doi = {10.1145/3650212.3680328},
abstract = {With the proven effectiveness of Large Language Models (LLMs) in code-related tasks, researchers have explored their potential for program repair. However, existing repair benchmarks might have influenced LLM training data, potentially causing data leakage. To evaluate LLMs’ realistic repair capabilities, (i) we introduce an extensive, non-crawled benchmark TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code. Our work assesses LLM’s repair performance on TutorCode, measuring repair correctness (TOP-5 and AVG-5) and patch precision (RPSR). (ii) We then provide a comprehensive investigation into which types of extra information can help LLMs improve their repair performance. Among these types, tutor guidance was the most effective information. To fully harness LLMs’ conversational capabilities and the benefits of augmented information, (iii) we introduce a novel conversational semi-automatic repair framework CREF assisting human programming tutors. It demonstrates a remarkable AVG-5 improvement of 17.2%-24.6% compared to the baseline, achieving an impressive AVG-5 of 76.6% when utilizing GPT-4. These results highlight the potential for enhancing LLMs’ repair capabilities through tutor interactions and historical conversations. The successful application of CREF in a real-world educational setting demonstrates its effectiveness in reducing tutors’ workload and improving students’ learning experience, showing promise for code review and other software engineering tasks.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {882–894},
numpages = {13},
keywords = {Large Language Model, Open Source, Program Repair},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3585059.3611409,
author = {Gumina, Sharon and Dalton, Travis and Gerdes, John},
title = {Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611409},
doi = {10.1145/3585059.3611409},
abstract = {This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students’ interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {60–65},
numpages = {6},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3626252.3630941,
author = {Bopp, Chris and Foerst, Anne and Kellogg, Brian},
title = {The Case for LLM Workshops},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630941},
doi = {10.1145/3626252.3630941},
abstract = {Large Language Models (LLMs) are radically changing the academic landscape. Many professors are unaware of how LLMs work and are therefore unsure how to incorporate them in their teaching. This is problematic as students will use them anyway. In this paper, we outline our institution as a case study for a curricular initiative. We develop an intellectual framework for creating workshops for faculty at small liberal arts universities. We base their development on the literature we have analyzed and discussed as a group. Our approach is to address our colleagues across a variety of different disciplines and teach them the responsible use of LLMs in the classroom. We also teach our colleagues how to modify assignments to make them, to some extent, LLM proof. This includes adding personalized elements, and including LLM designed parts explicitly, such as article summaries. We also design a syllabus policy about the responsible use of LLMs. We present philosophical and ethical challenges and teach a list of other actionable items. We ultimately support the use of LLMs in academia but seek to teach our colleagues how they can guide students to use them mindfully and responsibly.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {130–136},
numpages = {7},
keywords = {ethics, large language models, liberal arts universities, pedagogy, philosophy, workshops},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701625.3701687,
author = {Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa},
title = {Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701687},
doi = {10.1145/3701625.3701687},
abstract = {Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {624–634},
numpages = {11},
keywords = {Requirement Elicitation, ChatGPT 3.5, Software engineering education},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3699538.3699569,
author = {Jegourel, Cyrille and Ong, Jung Yi and Kurniawan, Oka and Meng Shin, Lim and Chitluru, Kushat},
title = {Sieving Coding Assignments Over Submissions Generated by AI and Novice Programmers},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699569},
doi = {10.1145/3699538.3699569},
abstract = {In the era of AI tools like ChatGPT and GitHub Copilot, and with the numerous online resources, computer science education faces the challenge of students potentially submitting plagiarised coding assignments or assignments generated by these technologies. Distinguishing between AI-generated and human-written text is notoriously difficult. In this study, we applied two text distance algorithms, commonly used for machine translation and document comparisons, to detect similarities between various computer Python code submissions and employed hierarchical clustering to analyze them from both AI tools and human programmers. Our results indicate that the distances to the cluster representatives can effectively predict whether a code submission is generated by AI or by novice programmers, achieving an accuracy of over 90%. These findings demonstrate the significant potential of text distance algorithms in identifying the origin of coding submissions, whether generated by AI or by novice programmers.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {12},
numpages = {11},
keywords = {Computing education, code distance, AI code generation, hierarchical clustering, plagiarism, code clone detection},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3613904.3642947,
author = {Liu, Ziyi and Zhu, Zhengzhe and Zhu, Lijun and Jiang, Enze and Hu, Xiyun and Peppler, Kylie A and Ramani, Karthik},
title = {ClassMeta: Designing Interactive Virtual Classmate to Promote VR Classroom Participation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642947},
doi = {10.1145/3613904.3642947},
abstract = {Peer influence plays a crucial role in promoting classroom participation, where behaviors from active students can contribute to a collective classroom learning experience. However, the presence of these active students depends on several conditions and is not consistently available across all circumstances. Recently, Large Language Models (LLMs) such as GPT have demonstrated the ability to simulate diverse human behaviors convincingly due to their capacity to generate contextually coherent responses based on their role settings. Inspired by this advancement in technology, we designed ClassMeta, a GPT-4 powered agent to help promote classroom participation by playing the role of an active student. These agents, which are embodied as 3D avatars in virtual reality, interact with actual instructors and students with both spoken language and body gestures. We conducted a comparative study to investigate the potential of ClassMeta for improving the overall learning experience of the class.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {17},
keywords = {VR classroom, collaborative learning, large language Model, pedagogical agent},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3649217.3653558,
author = {Pang, Ashley and Vahid, Frank},
title = {ChatGPT and Cheat Detection in CS1 Using a Program Autograding System},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653558},
doi = {10.1145/3649217.3653558},
abstract = {We experimented with ChatGPT's ability to write programs in a CS1 class, and the ability of a popular tool to auto-detect ChatGPT-written programs. We found ChatGPT was proficient at generating correct programs from a mere copy-paste of the English programming assignment specifications. However, running ChatGPT for 10 programming assignments and acting as 20 different students, and using zyBook's APEX beta tool for academic integrity, we found: (1) ChatGPT-generated programs tend to use a programming style departing from the style taught in the textbook or by the instructor, and these "style anomalies" were automatically detected. (2) Although ChatGPT may for the same assignment generate a few different program solutions for different students, ChatGPT often generates highly-similar programs for different students, so if enough students in a class (e.g., 5 or more) use ChatGPT, their programs will likely be flagged by a similarity checker. (3) If students are required to do all programming in the autograder's IDE, then a student using ChatGPT ends up showing very little time relative to classmates, which is automatically flagged. (4) Manually, we observed that if a student consistently uses ChatGPT to submit programs, the programming style may vary across programs, something normal students don't do; automation of style inconsistency detection was recently added to APEX. In short, while there will no doubt be an arms race between AI-generated programs and automatic detection of AI-generated programs, currently students using ChatGPT for multiple CS1 programs can be detected by automated tools such as zyBooks' APEX.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {367–373},
numpages = {7},
keywords = {CS1, ChatGPT, academic integrity, cheat detection, large language models, plagiarism, similarity checking, style anomalies},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3643916.3644435,
author = {Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
title = {Reassessing Java Code Readability Models with a Human-Centered Approach},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644435},
doi = {10.1145/3643916.3644435},
abstract = {To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers' notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers' evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it's often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {225–235},
numpages = {11},
keywords = {code readability, code readability models, repertory grid technique, AI-generated code, human-computer interaction},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@inproceedings{10.1145/3649217.3653624,
author = {Grande, Virginia and Kiesler, Natalie and Francisco R., Mar\'{\i}a Andre\'{\i}na},
title = {Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653624},
doi = {10.1145/3649217.3653624},
abstract = {The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {478–484},
numpages = {7},
keywords = {chatgpt, ethics, experience report, large language models, llms, student perspective},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3597503.3639223,
author = {Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
title = {Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639223},
doi = {10.1145/3597503.3639223},
abstract = {Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by 'delays in merging pull requests') can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue comments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels.In this paper, we explore zero-shot LLMs that are pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frustration in the last year of development of a popular open-source project, revealing several interesting insights.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {182},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3649217.3653527,
author = {Martini, Simone},
title = {Teaching Programming in the Age of Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653527},
doi = {10.1145/3649217.3653527},
abstract = {Programming has been considered the "essence of informatics" since the beginning of computing as a discipline. But programming in the fifties was very different from what we know today, and one of the goals (or dreams) throughout the history of programming language technology, has been "automatic programming''---the ability to automatically generate computer code starting from a high(er)-level description of the specification of that code. What this meant changed over the years, from punching paper tape, to compiling high-level programming languages, to program synthesis.Today, however, the availability of machine learning artefacts that produce high-level code from natural language specifications has completely changed the traditional meaning. To the extent that some computer scientists have begun to question the received wisdom that the core of their discipline is deeply rooted in programming.If programming and programming languages are no longer the essence of computer science, this changes the epistemology of the discipline itself. Moreover, if we are at the end of programming, we should also change the curriculum, where programming, algorithms and programming languages play a major role. Several recent papers reviewed the performance of code generators based on large language models on typical CS1 problems (e.g., from the many possible citations and how machine learning impacts K-12 teaching.Starting from this data, I will argue for the role of programming in the curriculum, distinguishing between programming taught as part of a holistic curriculum (as in some non-technical high schools) or as a vocational tool. I will use Simondon's notion of (closed and open) technical object as an interpretive lens, together with Calvino's reflections on the availability of writing machines capable of replacing the poet and the author.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {1–2},
numpages = {2},
keywords = {epistemology, large language models, programming},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689904.3694699,
author = {Armstrong, Lena and Liu, Abbey and MacNeil, Stephen and Metaxa, Dana\"{e}},
title = {The Silicon Ceiling: Auditing GPT’s Race and Gender Biases in Hiring},
year = {2024},
isbn = {9798400712227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689904.3694699},
doi = {10.1145/3689904.3694699},
abstract = {Large language models (LLMs) are increasingly being introduced in workplace settings, with the goals of improving efficiency and fairness. However, concerns have arisen regarding these models’ potential to reflect or exacerbate social biases and stereotypes. This study explores the potential impact of LLMs on hiring practices. To do so, we conduct an AI audit of race and gender biases in one commonly-used LLM, OpenAI’s GPT-3.5, taking inspiration from the history of traditional offline resume audits. We conduct two studies using names with varied race and gender connotations: resume assessment (Study 1) and resume generation (Study 2). In Study 1, we ask GPT to score resumes with 32 different names (4 names for each combination of the 2 gender and 4 racial groups) and two anonymous options across 10 occupations and 3 evaluation tasks (overall rating, willingness to interview, and hireability). We find that the model reflects some biases based on stereotypes. In Study 2, we prompt GPT to create resumes (10 for each name) for fictitious job candidates. When generating resumes, GPT reveals underlying biases; women’s resumes had occupations with less experience, while Asian and Hispanic resumes had immigrant markers, such as non-native English and non-U.S. education and work experiences. Our findings contribute to a growing body of literature on LLM biases, particularly in workplace contexts.},
booktitle = {Proceedings of the 4th ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization},
articleno = {2},
numpages = {18},
keywords = {Algorithm auditing, Algorithmic fairness, GPT, LLMs, Resume studies},
location = {San Luis Potosi, Mexico},
series = {EAAMO '24}
}

@inproceedings{10.1145/3626252.3630842,
author = {Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin},
title = {Trust in Generative AI among Students: An exploratory study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630842},
doi = {10.1145/3626252.3630842},
abstract = {Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {generative ai, novice programmers, trust},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630784,
author = {Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.},
title = {Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630784},
doi = {10.1145/3626252.3630784},
abstract = {ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1147–1153},
numpages = {7},
keywords = {academic misconduct, artificial intelligence, chatgpt, large language models, student survey},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3637068.3637089,
author = {Cerkez, Paul S. and Hummel, Joseph Edward and Mejias, Marlon and Pruitt, William},
title = {ChatGPT: To Use or Not to Use, That is the Question: Panel Discussion},
year = {2023},
issue_date = {November 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {5},
issn = {1937-4771},
abstract = {ChatGPT, from OpenAI (AI - artificial intelligence), and the many similar Large Language Models (LLM) appear to have taken the world by storm with some for it, some against it. In simple terms, these products are a great tool for the experienced domain user, however, precisely because of their capability, there is a lot of controversy surrounding student's use.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {175–176},
numpages = {2}
}

@inproceedings{10.1145/3649165.3690111,
author = {Poitras, Eric and Crane, Brent and Siegel, Angela},
title = {Generative AI in Introductory Programming Instruction: Examining the Assistance Dilemma with LLM-Based Code Generators},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690111},
doi = {10.1145/3649165.3690111},
abstract = {Problem decomposition is an important skill in programming, allowing learners to break down complex tasks into manageable subgoals. However, translating these subgoals into executable code poses a significant challenge for novice programmers. In this study conducted in an introductory programming course, learners received instruction in stepwise refinement and integration of AI-generated code within their assignments. Throughout the course, learners were permitted to rely on AI code generators, following opportunities to receive feedback on their ability to read and write code without AI assistance.  Our findings show that learners frequently relied on AI-generated code when working on assignments outside the classroom, but that the frequency of reliance varied from one assignment to another. The reliance on AI-generated code was not correlated with the learners' year in their degree, nor whether they were enrolled in a CS degree or not. Instead, it was associated with their prior knowledge, as learners who were less proficient in reading and writing code were more likely to seek AI assistance.  AI tools were primarily used to translate subgoals into code, fix errors, and explain algorithmic concepts. Few learners encountered difficulties in understanding or integrating AI generated code into their solutions. Overall, learner performance in meeting assignment requirements was relatively high, regardless of their prior knowledge or reliance on AI code generators. We conclude that leveraging the capabilities of generative AI can effectively bridge the gap between problem-solving and implementation, enabling learners to engage in skills that might otherwise be beyond their reach.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {186–192},
numpages = {7},
keywords = {ai coding assistants, ai-assisted pair programming, chatgpt, generative ai, gpt-3.5, introductory programming, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3674805.3690758,
author = {Majdoub, Yacine and Ben Charrada, Eya},
title = {Debugging with Open-Source Large Language Models: An Evaluation},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690758},
doi = {10.1145/3674805.3690758},
abstract = {Large language models have shown good potential in supporting software development tasks. This is why more and more developers turn to LLMs (e.g. ChatGPT) to support them in fixing their buggy code. While this can save time and effort, many companies prohibit it due to strict code sharing policies. To address this, companies can run open-source LLMs locally. But until now there is not much research evaluating the performance of open-source large language models in debugging. This work is a preliminary evaluation of the capabilities of open-source LLMs in fixing buggy code. The evaluation covers five open-source large language models and uses the benchmark DebugBench which includes more than 4000 buggy code instances written in Python, Java and C++. Open-source LLMs achieved scores ranging from 43.9% to 66.6% with DeepSeek-Coder achieving the best score for all three programming languages.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {510–516},
numpages = {7},
keywords = {Debugging, Large Language Models, Open-Source LLMs},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.5555/3717781.3717799,
author = {Tok, Bulut and Dogan, Gulustan},
title = {Advisor SeaHawk: An Academic Advisor Chatbot for MSCSIS Students at UNCW},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {This paper introduces Advisor SeaHawk, an advanced academic advisor chatbot for students at the University of North Carolina Wilmington (UNCW), specifically tailored for MSCSIS (Master of Science Computer and Information Science) students. Using OpenAI's GPT-4o model, Advisor SeaHawk provides personalized academic advising, including course recommendations, prerequisite checks, and detailed academic plans. The development process involves converting PDF academic records into structured JSON data, extracting student information using regular expressions, and integrating CSV-based course information. By leveraging natural language processing, Advisor SeaHawk interacts with students in a friendly manner, effectively simulating a human advisor. This chatbot aims to provide an accessible, efficient, and tailored advising experience for college students. We have not tested Advisor Seahawk yet on real student data.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {138–148},
numpages = {11}
}

@inproceedings{10.1145/3626252.3630880,
author = {Sheard, Judy and Denny, Paul and Hellas, Arto and Leinonen, Juho and Malmi, Lauri and Simon},
title = {Instructor Perceptions of AI Code Generation Tools - A Multi-Institutional Interview Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630880},
doi = {10.1145/3626252.3630880},
abstract = {Much of the recent work investigating large language models and AI Code Generation tools in computing education has focused on assessing their capabilities for solving typical programming problems and for generating resources such as code explanations and exercises. If progress is to be made toward the inevitable lasting pedagogical change, there is a need for research that explores the instructor voice, seeking to understand how instructors with a range of experiences plan to adapt. In this paper, we report the results of an interview study involving 12 instructors from Australia, Finland and New Zealand, in which we investigate educators' current practices, concerns, and planned adaptations relating to these tools. Through this empirical study, our goal is to prompt dialogue between researchers and educators to inform new pedagogical strategies in response to the rapidly evolving landscape of AI code generation tools.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1223–1229},
numpages = {7},
keywords = {ai code generation, generative ai, instructor perceptions, interview study, large language models, llms, programming education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3626252.3630881,
author = {Katuka, Gloria Ashiya and Chakraburty, Srijita and Lee, Hyejeong and Dhama, Sunny and Earle-Randell, Toni and Celepkolu, Mehmet and Boyer, Kristy Elizabeth and Glazewski, Krista and Hmelo-Silver, Cindy and Mcklin, Tom},
title = {Integrating Natural Language Processing in Middle School Science Classrooms: An Experience Report},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630881},
doi = {10.1145/3626252.3630881},
abstract = {With the increasing prevalence of large language models (LLMs) such as ChatGPT, there is a growing need to integrate natural language processing (NLP) into K-12 education to better prepare young learners for the future AI landscape. NLP, a sub-field of AI that serves as the foundation of LLMs and many advanced AI applications, holds the potential to enrich learning in core subjects in K-12 classrooms. In this experience report, we present our efforts to integrate NLP into science classrooms with 98 middle school students across two US states, aiming to increase students' experience and engagement with NLP models through textual data analyses and visualizations. We designed learning activities, developed an NLP-based interactive visualization platform, and facilitated classroom learning in close collaboration with middle school science teachers. This experience report aims to contribute to the growing body of work on integrating NLP into K-12 education by providing insights and practical guidelines for practitioners, researchers, and curriculum designers.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {639–645},
numpages = {7},
keywords = {middle school science classrooms, natural language processing, nlp and ai learning, nlp+science},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3632620.3671092,
author = {Yang, Stephanie and Zhao, Hanzhang and Xu, Yudian and Brennan, Karen and Schneider, Bertrand},
title = {Debugging with an AI Tutor: Investigating Novice Help-seeking Behaviors and Perceived Learning},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671092},
doi = {10.1145/3632620.3671092},
abstract = {Debugging is a crucial skill for programmers, yet it can be challenging for novices to learn. The introduction of large language models (LLMs) has opened up new possibilities for providing personalized debugging support to students. However, concerns have been raised about potential student over-reliance on LLM-based tools. This mixed-methods study investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. We conducted interviews and debugging think-aloud tasks with 20 students at three points throughout the semester. We specifically focused on characterizing when students initiate help from the chatbot during debugging, how they engage with the chatbot’s responses, and how they describe their learning experiences with the chatbot. By analyzing data from the debugging tasks, we identified varying help-seeking behaviors and levels of engagement with the chatbot’s responses, depending on students’ familiarity with the suggested strategies. Interviews revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. Additionally, students self-identified certain chatbot usage behaviors as negative, “non-ideal” engagement and others as positive, “learning-oriented” usage. Based on our findings, we discuss pedagogical implications and future directions for designing pedagogical chatbots to support debugging.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {84–94},
numpages = {11},
keywords = {AI tutoring, LLMs, debugging, help-seeking, large language models, programming education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3613905.3637148,
author = {Abolnejadian, Mohammad and Alipour, Sharareh and Taeb, Kamyar},
title = {Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3637148},
doi = {10.1145/3613905.3637148},
abstract = {In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student’s educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students’ backgrounds while respecting their privacy. The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase. This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {521},
numpages = {8},
keywords = {CS1, ChatGPT, Course Design, Introductory Programming, LLM, Learning Platform, Prompt Engineering},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.1145/3673238,
author = {Ni, Qin and Yu, Yangze and Ma, Yiming and Lin, Xin and Deng, Ciping and Wei, Tingjiang and Xuan, Mo},
title = {The Social Cognition Ability Evaluation of LLMs: A Dynamic Gamified Assessment and Hierarchical Social Learning Measurement Approach},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3673238},
doi = {10.1145/3673238},
abstract = {Large Language Model(LLM) has shown amazing abilities in reasoning tasks, theory of mind(ToM) has been tested in many studies as part of reasoning tasks, and social learning, which is closely related to theory of mind, are still lack of investigation. However, the test methods and materials make the test results unconvincing. We propose a dynamic gamified assessment(DGA) and hierarchical social learning measurement to test ToM and social learning capacities in LLMs. The test for ToM consists of five parts. First, we extract ToM tasks from ToM experiments and then design game rules to satisfy the ToM task requirement. After that, we design ToM questions to match the game’s rules and use these to generate test materials. Finally, we go through the above steps to test the model. To assess the social learning ability, we introduce a novel set of social rules (three in total). Experiment results demonstrate that, except GPT-4, LLMs performed poorly on the ToM test but showed a certain level of social learning ability in social learning measurement.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jun,
keywords = {Large Language Model, theory of mind, social learning, DGA, and hierarchical social learning measurement}
}

@inproceedings{10.1145/3626252.3630828,
author = {Prasad, Prajish and Sane, Aamod},
title = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630828},
doi = {10.1145/3626252.3630828},
abstract = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1070–1076},
numpages = {7},
keywords = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3690100,
author = {MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria},
title = {Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690100},
doi = {10.1145/3649165.3690100},
abstract = {Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {137–143},
numpages = {7},
keywords = {buggy code, generative ai, gpt-4, llms, synthetic data},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3652620.3687784,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {A RAG-based Feedback Tool to Augment UML Class Diagram Learning},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687784},
doi = {10.1145/3652620.3687784},
abstract = {This paper introduces an advanced functionality designed to facilitate the learning of UML class diagram construction. Built upon an integrated Retrieval Augmented Generation Large Language Model, the functionality provides enriched feedback by leveraging accumulated knowledge. The functionality is implemented in an existing tool named UML Miner, a Visual Paradigm plugin that captures and analyzes student-generated UML diagrams by applying process mining techniques. By offering personalized feedback and continuous support during modeling, the tool aims to enhance learning outcomes and students' engagement.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {26–30},
numpages = {5},
keywords = {learning, UML, software modeling, retrieval augmented generation, large language model, tool},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3587102.3588785,
author = {Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto},
title = {Comparing Code Explanations Created by Students and Large Language Models},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588785},
doi = {10.1145/3587102.3588785},
abstract = {Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {124–130},
numpages = {7},
keywords = {CS1, ChatGPT, GPT-3, GPT-4, code comprehension, code explanations, foundation models, large language models, natural language generation, resource generation},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3631802.3631845,
author = {Pirttinen, Nea and Leinonen, Juho},
title = {Could ChatGPT Be Used for Reviewing Learnersourced Exercises?},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631845},
doi = {10.1145/3631802.3631845},
abstract = {Large language models and tools based on large language models such as ChatGPT have received intense attention in the past year in computing education. In this work, we explore whether ChatGPT could be used to review learnersourced exercises. One of the major downsides of learnersourcing is the dubious quality of the created content, leading to many systems using peer review for curating the content. Our results suggest that ChatGPT is not yet ready for this task.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {42},
numpages = {2},
keywords = {ChatGPT, LLMs, crowdsourcing, generative AI, large language models, learnersourcing, reviews},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3587102.3588805,
author = {Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho},
title = {Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588805},
doi = {10.1145/3587102.3588805},
abstract = {The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {299–305},
numpages = {7},
keywords = {CS1, GPT-3, GitHub, ML, academic integrity, ai, artificial intelligence, chatgpt, code generation, code writing, codex, computer programming, copilot, deep learning, generative ai, introductory programming, large language models, machine learning, natural language processing, neural networks, novice programming, openAI},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3545947.3573353,
author = {Brusilovsky, Peter and Ericson, Barbara J. and Horstmann, Cay S. and Servin, Christian and Vahid, Frank and Zilles, Craig},
title = {Significant Trends in CS Educational Material: Current and Future},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573353},
doi = {10.1145/3545947.3573353},
abstract = {To recognize the current and future trends and challenges in computer science education educational materials for the next decade, the authors of this work provide a conversation to voice the computer science community's experience and expertise on these trends. One of the biggest challenges for introductory computing courses in the next few years will be leveraging the new capabilities of Artificial Intelligent systems such as Open AI CodeX and GPT3 that can generate code from a textual description, explain code, and translate code between programming languages. These tools could drastically change how introductory programming is taught by allowing students to focus more on understanding code, modifying code, and testing code than on writing code. Learning content is increasingly shifting from paper textbooks to online learning systems, which include not just traditional text and figures, but increasingly use interactive items to provide students with better explanations and illustrations, extensive practice, and frequent immediate formative feedback, typically at a lower cognitive load than classical programming assignment. We will discuss challenges and opportunities for interoperability with publishing and learning management platforms. Another example is how guided-based instruments, such as peer team learning, open educational resources, or workbooks, are adaptive and hybrid according to students' needs.Feedback and point of view from the CS community will be considered as part of the curricular practices "Future of CS educational materials" document, featured in the new version of the CS2023: ACM/IEEE-CS/AAAI Computer Science Curricula.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1253},
numpages = {1},
keywords = {adaptive, animation, assessment, automation, computer science, educational materials, feedback, homework, learning, sharing, textbook, videos},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3626252.3630951,
author = {Vahid, Frank and Pang, Ashley and Denzler, Benjamin},
title = {Towards Comprehensive Metrics for Programming Cheat Detection},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630951},
doi = {10.1145/3626252.3630951},
abstract = {Automated assistance for detecting cheating on programs has long been investigated by CS educators, especially with the rise of "homework help" websites over the past decade, and recently with AI tools like ChatGPT. The main detection approach has long been flagging similar submission pairs. Modern cheating, like hiring contractors or using ChatGPT, may not yield such similarity. And, cases based on similarity alone may be weak. Thus, over the past several years, building on logs from an online program auto-grader (zyBooks), we developed additional "cheating concern metrics": points rate, style anomalies, style inconsistencies, IP address anomalies, code replacements, and initial copying. Most are defined not only for one programming assignment but also across a set of assignments. The metrics can help catch more kinds of cheating, provide more compelling evidence of cheating, reduce false cheating accusations based on similarity alone, and help instructors focus their limited cheat-detection time on the most egregious cases. We describe the techniques, and our experiences (via our own Python scripts and a commercial tool) for several terms, showing benefits of having more metrics than just similarity. Of 30 cheating cases over 3 terms and 300 students, most were based on metrics beyond similarity, all students admitted, none later contested, and time per student was only 1-2 hours (far less than previously). Our goal is to prevent cheating in the first place, by reducing opportunity via strong detection tools, as part of a multi-faceted approach to having students truly learn and stay out of trouble.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1361–1367},
numpages = {7},
keywords = {ai, cheating, cs1, homework, plagiarism, programming assignments},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691620.3695508,
author = {Wu, Di and Mu, Fangwen and Shi, Lin and Guo, Zhaoqiang and Liu, Kui and Zhuang, Weiguang and Zhong, Yuqi and Zhang, Li},
title = {iSMELL: Assembling LLMs with Expert Toolsets for Code Smell Detection and Refactoring},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695508},
doi = {10.1145/3691620.3695508},
abstract = {Detecting and refactoring code smells is challenging, laborious, and sustaining. Although large language models have demonstrated potential in identifying various types of code smells, they also have limitations such as input-output token restrictions, difficulty in accessing repository-level knowledge, and performing dynamic source code analysis. Existing learning-based methods or commercial expert toolsets have advantages in handling complex smells. They can analyze project structures and contextual information in-depth, access global code repositories, and utilize advanced code analysis techniques. However, these toolsets are often designed for specific types and patterns of code smells and can only address fixed smells, lacking flexibility and scalability. To resolve that problem, we propose iSMELL, an ensemble approach that employs various code smell detection toolsets via Mixture of Experts (MoE) architecture for comprehensive code smell detection, and enhances the LLMs with the detection results from expert toolsets for refactoring those identified code smells. First, we train a MoE model that, based on input code vectors, outputs the most suitable expert tool for identifying each type of smell. Then, we select the recommended toolsets for code smell detection and obtain their results. Finally, we equip the prompts with the detection results from the expert toolsets, thereby enhancing the refactoring capability of LLMs for code with existing smells, enabling them to provide different solutions based on the type of smell. We evaluate our approach on detecting and refactoring three classical and complex code smells, i.e., Refused Bequest, God Class, and Feature Envy. The results show that, by adopting seven expert code smell toolsets, iSMELL achieved an average F1 score of 75.17% on code smell detection, outperforming LLMs baselines by an increase of 35.05% in F1 score. We further evaluate the code refactored by the enhanced LLM. The quantitative and human evaluation results show that iSMELL could improve code quality metrics and conduct satisfactory refactoring toward the identified code smells. We believe that our proposed solution could provide new insights into better leveraging LLMs and existing approaches to resolving complex software tasks.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1345–1357},
numpages = {13},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3687038,
author = {Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael},
title = {Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687038},
doi = {10.1145/3687038},
abstract = {Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role that teachers can play in shaping LLM-supported learning environments.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {499},
numpages = {30},
keywords = {artificial intelligence in education, collaborative learning with ai, human-ai collaboration, large language models, transparency, tutoring systems}
}

@inproceedings{10.1145/3649409.3691089,
author = {Gupta, Anisha and Monahan, Robert and Vandenberg, Jessica and Smith, Andy and Elsayed, Rasha and Fox, Kimkinyona and Minogue, James and Oliver, Kevin and Hubbard Cheuoua, Aleata and Ringstaff, Cathy and Mott, Bradford},
title = {Leveraging Large Language Models for Automated Assessment of Elementary Students' Block-Based Narrative Programs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691089},
doi = {10.1145/3649409.3691089},
abstract = {Recent years have seen increasing awareness of the need to engage young learners in computational thinking (CT). Integrating digital storytelling, where students create short narratives, and CT offers significant potential for promoting interdisciplinary learning for students; however, it is critical to provide both teachers and students with automated support. A promising approach for enabling support is to leverage advances in Large Language Models (LLMs), which have demonstrated considerable potential for assessing both programming and natural language artifacts. In this work, we investigate the capabilities of LLMs to automatically assess student-created block-based programs developed using a narrative-centered learning environment that engages upper elementary students (ages 9 to 11) in learning CT and physical science through the creation of interactive science narratives. Using the narrative programs created by 28 students, we explore the efficacy of LLMs to assess the programs across two dimensions.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {318–319},
numpages = {2},
keywords = {k-12 education, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3650212.3680384,
author = {Zhang, Yuntong and Ruan, Haifeng and Fan, Zhiyu and Roychoudhury, Abhik},
title = {AutoCodeRover: Autonomous Program Improvement},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680384},
doi = {10.1145/3650212.3680384},
abstract = {Researchers have made significant progress in automating the software development process in the past decades. Automated techniques for issue summarization, bug reproduction, fault localization, and program repair have been built to ease the workload of developers. Recent progress in Large Language Models (LLMs) has significantly impacted the development process, where developers can use LLM-based programming assistants to achieve automated coding. Nevertheless, software engineering involves the process of program improvement apart from coding, specifically to enable software maintenance (e.g. program repair to fix bugs) and software evolution (e.g. feature additions). In this paper, we propose an automated approach for solving Github issues to autonomously achieve program improvement. In our approach called AutoCodeRover, LLMs are combined with sophisticated code search capabilities, ultimately leading to a program modification or patch. In contrast to recent LLM agent approaches from AI researchers and practitioners, our outlook is more software engineering oriented. We work on a program representation (abstract syntax tree) as opposed to viewing a software project as a mere collection of files. Our code search exploits the program structure in the form of classes/methods to enhance LLM’s understanding of the issue’s root cause, and effectively retrieve a context via iterative search. The use of spectrum-based fault localization using tests, further sharpens the context, as long as a test-suite is available. Experiments on the recently proposed SWE-bench-lite (300 real-life Github issues) show increased efficacy in solving Github issues (19% on SWE-bench-lite), which is higher than the efficacy of the recently reported Swe-agent. Interestingly, our approach resolved 57 GitHub issues in about 4 minutes each (pass@1), whereas developers spent more than 2.68 days on average. In addition, AutoCodeRover achieved this efficacy with significantly lower cost (on average, $0.43 USD), compared to other baselines. We posit that our workflow enables autonomous software engineering, where, in future, auto-generated code from LLMs can be autonomously improved.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1592–1604},
numpages = {13},
keywords = {automatic program repair, autonomous software engineering, autonomous software improvement, large language model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3649217.3653587,
author = {Denny, Paul and Smith, David H. and Fowler, Max and Prather, James and Becker, Brett A. and Leinonen, Juho},
title = {Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653587},
doi = {10.1145/3649217.3653587},
abstract = {Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with "Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {283–289},
numpages = {7},
keywords = {code comprehension, cs1, eipe, explain in plan english, introductory programming, large language models, llms, prompting},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3565287.3617630,
author = {Evans, Michael and So\'{o}s, Dominik and Landers, Ethan and Wu, Jian},
title = {MSVEC: A Multidomain Testing Dataset for Scientific Claim Verification},
year = {2023},
isbn = {9781450399265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565287.3617630},
doi = {10.1145/3565287.3617630},
abstract = {The increase of disinformation in scientific news across a variety of domains has generated an urgency for a robust and generalizable approach to automated scientific claim verification (SCV). Available methods of SCV are limited in either domain adaptability or scalability. To facilitate building and evaluating more robust models on SCV we propose MSVEC, a multidomain dataset containing 200 pairs of verified scientific news claims with evidence research papers. To understand the capability of large language models on the SCV task, we evaluated GPT-3.5 against MSVEC. While methods of fact-checking exist for specific domains (e.g., political and health), the use of large language models exhibits better generalizability across multiple domains and is potentially compared with state-of-the-art models based on word embeddings. The data and software used and developed for this project are available at https://github.com/lamps-lab/msvec.},
booktitle = {Proceedings of the Twenty-Fourth International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing},
pages = {504–509},
numpages = {6},
keywords = {machine learning, large language models, natural language processing, benchmark datasets},
location = {Washington, DC, USA},
series = {MobiHoc '23}
}

@inproceedings{10.1145/3501385.3543957,
author = {Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho},
title = {Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models},
year = {2022},
isbn = {9781450391948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501385.3543957},
doi = {10.1145/3501385.3543957},
abstract = {This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1},
pages = {27–43},
numpages = {17},
keywords = {Robosourcing, Resource generation, Programming exercises, OpenAI Codex, Natural language generation, Large language models, GPT-3, Exercise generation, Code explanations, CS1, Automated feedback},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3626252.3630887,
author = {Malik, Ali and Woodrow, Juliette and Piech, Chris},
title = {Learners Teaching Novices: An Uplifting Alternative Assessment},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630887},
doi = {10.1145/3626252.3630887},
abstract = {We propose and carry-out a novel method of formative assessment called Assessment via Teaching (AVT), in which learners demonstrate their understanding of CS1 topics by tutoring more novice students. AVT has powerful benefits over traditional forms of assessment: it is centered around service to others and is highly rewarding for the learners who teach. Moreover, teaching greatly improves the learners' own understanding of the material and has a huge positive impact on novices, who receive free 1:1 tutoring. Lastly, this form of assessment is naturally difficult to cheat---a critical property for assessments in the era of large-language models. We use AVT in a randomised control trial with learners in a CS1 course at an R1 university. The learners provide tutoring sessions to more novice students taking a lagged online version of the same course. We show that learners who do an AVT session before the course exam performed 20 to 30 percentage points better than the class average on several questions. Moreover, compared to students who did a practice exam, the AVT learners enjoyed their experience more and were twice as likely to study for their teaching session. We believe AVT is a scalable and uplifting method for formative assessment that could one day replace traditional exams.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {785–791},
numpages = {7},
keywords = {formative assessment, learning at scale, online courses, peer teaching, student-led teaching, studying strategies},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@inproceedings{10.1145/3699538.3699567,
author = {Amoozadeh, Matin and Nam, Daye and Prol, Daniel and Alfageeh, Ali and Prather, James and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Amin},
title = {Student-AI Interaction: A Case Study of CS1 students},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699567},
doi = {10.1145/3699538.3699567},
abstract = {Generative artificial intelligence tools (Generative AI), such as ChatGPT, allow users to interact with them in intuitive ways (e.g., conversational) and receive (mostly) good-quality answers. In education, such systems can support students’ learning objectives by providing accessible explanations and examples even when students pose vague queries. But, they also encourage undesired help-seeking behaviors, such as by providing solutions to the students’ homework. Therefore, it is important to better understand how students approach such tools and the potential issues such approaches might present for the learners.In this paper, we present a case study for understanding student-AI collaboration to solve programming tasks in the CS1 introductory programming course. To this end, we recruited a gender-balanced majority non-white set of 15 CS1 students at the University of Houston, a large public university in the US. We observed them solving programming tasks. We used a mixed-method approach to study their interactions as they tackled Python programming tasks, focusing on when and why they used ChatGPT for problem-solving. We analyze and classify the questions submitted by the 15 participants to ChatGPT. Additionally, we analyzed user interaction patterns, their reactions to ChatGPT’s responses, and the potential impacts of Generative AI on their perception of self-efficacy.Our results suggest that, in about a third of the cases, the student attempted to complete the task by submitting the full description of the tasks to ChatGPT without making any effort on their own. We also observed that few students verified their solutions. We discuss the potential implications of these results.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {13},
numpages = {13},
keywords = {Generative Artificial Intelligence, Human-AI Interaction, Self-regulation, CS1, User study, Novice programmers},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3628096.3628747,
author = {Masikisiki, Baphumelele and Marivate, Vukosi and Hlophe, Yvette},
title = {Investigating the Efficacy of Large Language Models in Reflective Assessment Methods through Chain of Thought Prompting},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3628747},
doi = {10.1145/3628096.3628747},
abstract = {Large Language Models, such as Generative Pre-trained Transformer 3 (aka. GPT-3), have been developed to understand language through the analysis of extensive text data, allowing them to identify patterns and connections between words. While LLMs have demonstrated impressive performance across various text-related tasks, they encounter challenges in tasks associated with reasoning. To address this challenge, Chain of Thought (CoT) prompting method has been proposed as a means to enhance LLMs’ proficiency in complex reasoning tasks like solving math word problems and answering questions based on logical argumentative reasoning. The primary aim of this research is to assess how well four language models can grade reflective essays of third-year medical students. The assessment will specifically target the evaluation of critical thinking skills using CoT prompting. The research will provide the following contributions; to introduce and educate on the process of instructing models to evaluate reflective essays from a dataset they have not been previously trained on; to illustrate the use of CoT prompting as an instructional approach for training large models to carry out particular tasks. Our results suggest that among all the models, Llama-7b performs the least effectively, displaying the highest mean squared error. Conversely, ChatGPT emerges as the superior model, boasting a higher Cohen kappa score value of 0.53. Lastly, it’s important to note that the selected models do prioritise user privacy by allowing users to delete their own conducted conversations.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {44–49},
numpages = {6},
keywords = {Automation Grading, Chain of thought prompting, Large Models},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@inproceedings{10.1145/3581754.3584111,
author = {Cao, Chen},
title = {Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584111},
doi = {10.1145/3581754.3584111},
abstract = {Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {229–232},
numpages = {4},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3649405.3659517,
author = {Glassey, Richard and Baltatzis, Alexander},
title = {Active Repos: Integrating Generative AI Workflows into GitHub},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659517},
doi = {10.1145/3649405.3659517},
abstract = {The aim of this work is to describe a simple and cost effective way to integrate generative AI into GitHub to support course specific scenarios. We are motivated by helping teachers realise their creative AI use cases in spite of technical barriers and also to ensure that students have a blessed and fair way to access AI services without needing to sign-up, prompt or pay. First we will describe a scenario that we have implemented for our own CS1 course, then we will describe the technical requirements for implementation. We finish off with our early thoughts on where these types of scenarios might be heading in terms of supporting computing education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {777–778},
numpages = {2},
keywords = {CS1, GitHub actions, automation, generative AI},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653608,
author = {Pankiewicz, Maciej and Baker, Ryan S.},
title = {Navigating Compiler Errors with AI Assistance - A Study of GPT Hints in an Introductory Programming Course},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653608},
doi = {10.1145/3649217.3653608},
abstract = {We examined the efficacy of AI-assisted learning in an introductory programming course at the university level by using a GPT-4 model to generate personalized hints for compiler errors within a platform for automated assessment of programming assignments. The control group had no access to GPT hints. In the experimental condition GPT hints were provided when a compiler error was detected, for the first half of the problems in each module. For the latter half of the module, hints were disabled. Students highly rated the usefulness of GPT hints. In affect surveys, the experimental group reported significantly higher levels of focus and lower levels of confrustion (confusion and frustration) than the control group. For the six most commonly occurring error types we observed mixed results in terms of performance when access to GPT hints was enabled for the experimental group. However, in the absence of GPT hints, the experimental group's performance surpassed the control group for five out of the six error types.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {94–100},
numpages = {7},
keywords = {GPT, LLM, automated assessment, large language models, programming education},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653626,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley and Salloum, Mariam},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653626},
doi = {10.1145/3649217.3653626},
abstract = {Student cheating on at-home programming assignments is a well- known problem. A key contributor is externally-obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally-obtained solutions often use coding styles that depart from a class' style, which we call "style anomalies," such as using untaught or advanced constructs like pointers or ternary operators, or having different indenting or brace usage from the class style. We developed a tool to auto-count style anomalies. For six labs across four terms in 2021-2022, and 50 sampled students per lab, we found 18% of submissions on average had unusually-high style anomaly counts. Importantly, 8% of submissions on average had a high style anomaly count but were not flagged by a similarity checker, meaning 8% of submissions are suspicious but might have been missed if using similarity checking alone. We repeated a similar analysis for Spring 2023 when generative AI (ChatGPT) was gaining popularity, and the numbers rose to 26% and 18%, respectively. Detailed investigations by instructors led to a majority (but not all) high style anomaly submissions being deemed cheating. Even for high-similarity submissions, counting style anomalies can help instructors focus investigations on the most-likely cheating cases, and can strengthen cases sent to student conduct offices. With the rise of externally-obtained solutions from websites, contractors, and generative AI, counting style anomalies may become an increasingly important complement to similarity checking; in fact, it is now the primary cheat-detection tool in our CS1 at a large state university, with similarity secondary.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {381–387},
numpages = {7},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635519,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635519},
doi = {10.1145/3626253.3635519},
abstract = {Student cheating on at-home programming assignments is a well-known problem. A key contributor is externally obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally obtained solutions often use coding styles that depart from a class's style, which we call "style anomalies". Examples of style anomalies include using untaught or advanced constructs like pointers or ternary operators or having different indenting or brace usage from the class style. We developed a tool to automatically count style anomalies in student code submissions. We used this tool to find suspected cheating in student submissions for lab assignments across five terms of CS1. This poster presents our findings: Some student submissions were suspected of cheating due to high style anomaly counts and were not flagged as suspicious by a code similarity checker. With the rise of externally obtained solutions from websites, contractors, and generative AI, style anomalies may become an important complement to similarity checking for detecting cheating.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1624–1625},
numpages = {2},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635356,
author = {AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
title = {How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635356},
doi = {10.1145/3626253.3635356},
abstract = {Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1930},
numpages = {1},
keywords = {computing, education, large language models, quality},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1109/ICSE48619.2023.00194,
author = {Kang, Sungmin and Yoon, Juyeon and Yoo, Shin},
title = {Large Language Models are Few-Shot Testers: Exploring LLM-Based General Bug Reproduction},
year = {2023},
isbn = {9781665457019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE48619.2023.00194},
doi = {10.1109/ICSE48619.2023.00194},
abstract = {Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose LIBRO, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of LIBRO shows that, on the widely studied Defects4J benchmark, LIBRO can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate LIBRO against 31 bug reports submitted after the collection of the LLM training data terminated: LIBRO produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show LIBRO has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering},
pages = {2312–2323},
numpages = {12},
keywords = {software engineering, natural language processing, test generation},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@article{10.5555/3665464.3665480,
author = {Manley, Eric D.},
title = {Getting Started with Large Language Models for the CS Curriculum},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {With the introduction of ChatGPT in late 2022, popular interest in language-based Artificial Intelligence has exploded. Employers are looking to hire computer scientists who can leverage large language models (LLMs) [2], and student demand for learning about them at many higher education institutions has followed. This one-hour workshop will help computer science educators respond to this demand by introducing the Python transformers library and its associated LLM ecosystem [1]. We will discuss how LLMs can be integrated into college computer science curricula from CS 1 through advanced courses in Artificial Intelligence, Machine Learning, or Natural Language Processing. Specific topics include• Using the transformers library with pre-trained models for inference tasks like sentiment analysis, text classification, summarization, translation, and question answering in only a few lines of code• Searching for and using hundreds of thousands of different pre-trained language models hosted by Hugging Face along with datasets that they can be tested on• Utilizing conversational models to build chat bots},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {116–117},
numpages = {2}
}

@inproceedings{10.1145/3587102.3588794,
author = {Ouh, Eng Lieh and Gan, Benjamin Kok Siew and Jin Shim, Kyong and Wlodkowski, Swavek},
title = {ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course.},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588794},
doi = {10.1145/3587102.3588794},
abstract = {In this study, we assess the efficacy of employing the ChatGPT language model to generate solutions for coding exercises within an undergraduate Java programming course. ChatGPT, a large-scale, deep learning-driven natural language processing model, is capable of producing programming code based on textual input. Our evaluation involves analyzing ChatGPT-generated solutions for 80 diverse programming exercises and comparing them to the correct solutions. Our findings indicate that ChatGPT accurately generates Java programming solutions, which are characterized by high readability and well-structured organization. Additionally, the model can produce alternative, memory-efficient solutions. However, as a natural language processing model, ChatGPT struggles with coding exercises containing non-textual descriptions or class files, leading to invalid solutions. In conclusion, ChatGPT holds potential as a valuable tool for students seeking to overcome programming challenges and explore alternative approaches to solving coding problems. By understanding its limitations, educators can design coding exercises that minimize the potential for misuse as a cheating aid while maintaining their validity as assessment tools.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {54–60},
numpages = {7},
keywords = {Java, computer science education, object-oriented, programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3636243.3636248,
author = {Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen},
title = {The Effects of Generative AI on Computing Students’ Help-Seeking Preferences},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636248},
doi = {10.1145/3636243.3636248},
abstract = {Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {39–48},
numpages = {10},
keywords = {ChatGPT, Generative AI, computing education, help-seeking},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3649217.3653574,
author = {Denny, Paul and MacNeil, Stephen and Savelka, Jaromir and Porter, Leo and Luxton-Reilly, Andrew},
title = {Desirable Characteristics for AI Teaching Assistants in Programming Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653574},
doi = {10.1145/3649217.3653574},
abstract = {Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses. Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings. These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problem-solving skills. With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support. Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences. If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn. Thus, it is essential to identify the features that students believe make digital teaching assistants valuable. We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback (n=813) on the characteristics of the tool they perceived to be most important. Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines. They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {408–414},
numpages = {7},
keywords = {ai tutors, automated tutors, digital tas, feedback, llms},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649405.3659495,
author = {Flores, Paige and Kaza, Siddharth and Taylor, Blair},
title = {Fine-Tuning AI to Assist in Building Curriculum for the CIA Triad and Cyber Kill Chain},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659495},
doi = {10.1145/3649405.3659495},
abstract = {Educators face the continuous challenge of updating their teaching materials with the fast-paced changes in cybersecurity and integrating emerging topics into their existing content. This work presents the development progress of a cybersecurity curriculum fine-tuned Large Language Model (LLM) designed to assist educators in creating engaging curricular materials for introductory cybersecurity topics. Recent advancements in Natural Language Processing (NLP) and the increased number of openly available LLMs like OpenAI's GPT and Meta's Llama present an opportunity to fine-tune these models for specific domains like cybersecurity. The fine-tuned LLMs offer a potential solution by reducing the amount of work necessary to regularly update curricular content, including lab assignments, assessments, in-class activities, and other additional resources for both synchronous and asynchronous classrooms.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {804},
numpages = {1},
keywords = {artificial intelligence, curriculum, cybersecurity education, large language models, security injections},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3511861.3511863,
author = {Finnie-Ansley, James and Denny, Paul and Becker, Brett A. and Luxton-Reilly, Andrew and Prather, James},
title = {The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming},
year = {2022},
isbn = {9781450396431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511861.3511863},
doi = {10.1145/3511861.3511863},
abstract = {Recent advances in artificial intelligence have been driven by an exponential growth in digitised data. Natural language processing, in particular, has been transformed by machine learning models such as OpenAI’s GPT-3 which generates human-like text so realistic that its developers have warned of the dangers of its misuse. In recent months OpenAI released Codex, a new deep learning model trained on Python code from more than 50 million GitHub repositories. Provided with a natural language description of a programming problem as input, Codex generates solution code as output. It can also explain (in English) input code, translate code between programming languages, and more. In this work, we explore how Codex performs on typical introductory programming problems. We report its performance on real questions taken from introductory programming exams and compare it to results from students who took these same exams under normal conditions, demonstrating that Codex outscores most students. We then explore how Codex handles subtle variations in problem wording using several published variants of the well-known “Rainfall Problem” along with one unpublished variant we have used in our teaching. We find the model passes many test cases for all variants. We also explore how much variation there is in the Codex generated solutions, observing that an identical input prompt frequently leads to very different solutions in terms of algorithmic approach and code length. Finally, we discuss the implications that such technology will have for computing education as it continues to evolve, including both challenges and opportunities.},
booktitle = {Proceedings of the 24th Australasian Computing Education Conference},
pages = {10–19},
numpages = {10},
keywords = {novice programming, neural networks, machine learning, introductory programming, deep learning, copilot, code writing, code generation, artificial intelligence, academic integrity, OpenAI, GitHub, GPT-3, Codex, CS1, AI},
location = {Virtual Event, Australia},
series = {ACE '22}
}

@inproceedings{10.1145/3652988.3673941,
author = {Dai, Laduona and Jung, Merel M. and \v{S}af\'{a}\v{r} Postma, Marie and van der Loo, Janneke and Louwerse, Max M.},
title = {LittleGenius: Co-Designing a GPT-4 Enhanced VR Pedagogical Framework with Teachers for Primary Education},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3673941},
doi = {10.1145/3652988.3673941},
abstract = {This study introduces LittleGenius, a VR tool integrated with GPT-4 for primary education. Combining GPT-4’s advanced natural language processing with VR technology, LittleGenius creates an engaging learning environment. Users interact with an astronaut floating outside the International Space Station. A specialized GPT prompt was developed to foster deeper engagement through knowledge construction. The system enables natural speech interaction using Microsoft Azure’s Speech Cognitive Services. Nine in-service teachers evaluated the design, giving positive feedback, especially on the interactive astronaut agent’s engaging questions that could deepen student understanding. Future development will expand content and customize the system for diverse communication preferences and learning styles.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {36},
numpages = {4},
keywords = {GPT-4, K-12 Education, VR Agent},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@inproceedings{10.1145/3576123.3576134,
author = {Finnie-Ansley, James and Denny, Paul and Luxton-Reilly, Andrew and Santos, Eddie Antonio and Prather, James and Becker, Brett A.},
title = {My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises},
year = {2023},
isbn = {9781450399418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576123.3576134},
doi = {10.1145/3576123.3576134},
abstract = {The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.},
booktitle = {Proceedings of the 25th Australasian Computing Education Conference},
pages = {97–104},
numpages = {8},
keywords = {AI, AlphaCode, CS1, CS2, Codex, DeepMind, GPT-3, GitHub, OpenAI, academic integrity, algorithms, artificial intelligence, code generation, copilot, data structures, deep learning, introductory programming, machine learning, neural networks, novice programming},
location = {Melbourne, VIC, Australia},
series = {ACE '23}
}

@inproceedings{10.1145/3626253.3635522,
author = {Ruiz, Pati and Rangel, Alessandra and Coenraad, Merijke},
title = {Using Generative AI to Support PK-12 Teaching and Learning: Developing Sample Lessons and More},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635522},
doi = {10.1145/3626253.3635522},
abstract = {North Salem Central School District (North Salem) has worked with researchers as part of a larger Research Practice Partnership (RPP) to design and implement an inclusive PK-12 computing pathway in their district. This poster describes how teachers used Generative AI (GenAI) tools in three areas: (1) the development of sample computational thinking (CT) lesson plans; (2) initial brainstorming; and (3) professional learning.As North Salem reflected on their use of GenAI tools, they named two AI tools specifically: OpenAI's ChatGPT-4 and Bing's Image Creator. Teachers also describe ethical dilemmas that they faced when integrating GenAI tools as well as other concerns that will be described below. This work builds on the growing literature on the use of Generative AI tools to support the day-to-day work of teachers.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1800–1801},
numpages = {2},
keywords = {K-12 computer science education, ducational equity, formative assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636259,
author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636259},
doi = {10.1145/3636243.3636259},
abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3649409.3691073,
author = {Barendsen, Erik and Lonati, Violetta and Quille, Keith and Altin, Rukiye and Divitini, Monica and Hooshangi, Sara and Karnalim, Oscar and Kiesler, Natalie and Melton, Madison and Suero Montero, Calkin and Morpurgo, Anna},
title = {AI in and for K-12 Informatics Education. Life after Generative AI.},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691073},
doi = {10.1145/3649409.3691073},
abstract = {The use and adoption of Generative AI (GenAI) has revolutionised various sectors, including computing education. However, this narrow focus comes at a cost to the wider AI in and for educational research. This working group aims to explore current trends and explore multiple sources of information to identify areas of AI research in K-12 informatics education that are being underserved but needed in the post-GenAI AI era. Our research focuses on three areas: curriculum, teacher-professional learning and policy. The denouement of this aims to identify trends and shortfalls for AI in and for K-12 informatics education. We will systematically review the current literature to identify themes and emerging trends in AI education at K-12. This will be done under two facets, curricula and teacher-professional learning. In addition, we will conduct interviews and surveys with educators and AI experts. Next, we will examine the current policy (such as the European AI Act, and European Commission guidelines on the use of AI and data in education and training as well as international counterparts). Policies are often developed by both educators and experts in the domain, thus providing a source of topics or areas that may be added to our findings. Finally, by synthesising insights from educators, AI experts, and policymakers, as well as the literature and policy, our working group seeks to highlight possible future trends and shortfalls.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {279–280},
numpages = {2},
keywords = {AI, GenAI, K-12, curricula, generative AI, informatics},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3626252.3630874,
author = {Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi},
title = {Implications of ChatGPT for Data Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630874},
doi = {10.1145/3626252.3630874},
abstract = {ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1230–1236},
numpages = {7},
keywords = {data science education, large language models, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3664673,
author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
title = {Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664673},
doi = {10.1145/3657604.3664673},
abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {255–258},
numpages = {4},
keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626772.3657882,
author = {Roy, Soumyadeep and Khatua, Aparup and Ghoochani, Fatemeh and Hadler, Uwe and Nejdl, Wolfgang and Ganguly, Niloy},
title = {Beyond Accuracy: Investigating Error Types in GPT-4 Responses to USMLE Questions},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657882},
doi = {10.1145/3626772.3657882},
abstract = {GPT-4 demonstrates high accuracy in medical QA tasks, leading with an accuracy of 86.70%, followed by Med-PaLM 2 at 86.50%. However, around 14% of errors remain. Additionally, current works use GPT-4 to only predict the correct option without providing any explanation and thus do not provide any insight into the thinking process and reasoning used by GPT-4 or other LLMs. Therefore, we introduce a new domain-specific error taxonomy derived from collaboration with medical students. Our GPT-4 USMLE Error (G4UE) dataset comprises 4153 GPT-4 correct responses and 919 incorrect responses to the United States Medical Licensing Examination (USMLE) respectively. These responses are quite long (258 words on average), containing detailed explanations from GPT-4 justifying the selected option. We then launch a large-scale annotation study using the Potato annotation platform and recruit 44 medical experts through Prolific, a well-known crowdsourcing platform. We annotated 300 out of these 919 incorrect data points at a granular level for different classes and created a multi-label span to identify the reasons behind the error. In our annotated dataset, a substantial portion of GPT-4's incorrect responses is categorized as a "Reasonable response by GPT-4," by annotators. This sheds light on the challenge of discerning explanations that may lead to incorrect options, even among trained medical professionals. We also provide medical concepts and medical semantic predications extracted using the SemRep tool for every data point. We believe that it will aid in evaluating the ability of LLMs to answer complex medical questions. We make the resources available at https://github.com/roysoumya/usmle-gpt4-error-taxonomy.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1073–1082},
numpages = {10},
keywords = {gpt-4, medical qa, multi-label dataset, usmle error taxonomy},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3626253.3633433,
author = {Liu, Rongxin and Zenke, Carter and Lloyd, Doug and Malan, David J.},
title = {Teaching with AI (GPT)},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633433},
doi = {10.1145/3626253.3633433},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. We plan to share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1902},
numpages = {1},
keywords = {ai, artificial intelligence, chatgpt, ethics, generative ai, gpt, programming, prompt, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630773,
author = {Woodrow, Juliette and Malik, Ali and Piech, Chris},
title = {AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630773},
doi = {10.1145/3626252.3630773},
abstract = {Teaching students how to write code that is elegant, reusable, and comprehensible is a fundamental part of CS1 education. However, providing this "style feedback" in a timely manner has proven difficult to scale. In this paper, we present our experience deploying a novel, real-time style feedback tool in Code in Place, a large-scale online CS1 course. Our tool is based on the latest breakthroughs in large-language models (LLMs) and was carefully designed to be safe and helpful for students. We used our Real-Time Style Feedback tool (RTSF) in a class with over 8,000 diverse students from across the globe and ran a randomized control trial to understand its benefits. We show that students who received style feedback in real-time were five times more likely to view and engage with their feedback compared to students who received delayed feedback. Moreover, those who viewed feedback were more likely to make significant style-related edits to their code, with over 79% of these edits directly incorporating their feedback. We also discuss the practicality and dangers of LLM-based tools for feedback, investigating the quality of the feedback generated, LLM limitations, and techniques for consistency, standardization, and safeguarding against demographic bias, all of which are crucial for a tool utilized by students.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1442–1448},
numpages = {7},
keywords = {cs1, deployed at scale, gpt, llms, real time, style feedback},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691016.3691051,
author = {He, Wenwen and Xu, Zhiqing and Rao, Huahua and Li, Qiuhui and Huang, Jiahao and Wu, Jialan and Pan, Zhihong},
title = {Intelligent Chinese Character Learning Platform Integrating ChatGPT and OCR Text Recognition},
year = {2024},
isbn = {9798400710285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691016.3691051},
doi = {10.1145/3691016.3691051},
abstract = {The demand for intelligent Chinese character dictionary query tools has increased due to the rising number of Chinese language learners and advancements in educational technology. In response to this demand, we have developed an intelligent Chinese character learning platform that combines the ChatGPT grand model and OCR text recognition technology. The primary objective of this platform is to enhance the efficiency and enjoyment of the Chinese character learning process. The platform utilizes the GPT-3.5-Turbo model for precise parsing of user-input data through NLP technology. Furthermore, OCR technology is employed for preprocessing tasks such as grayscaling, binarization, denoising, and accurate text recognition and extraction from images to facilitate rapid word search functionality.The ChatGPT 3.5 model and the OCR text recognition technology underwent comprehensive testing in the system performance evaluation stage. The evaluation of system performance indicates that the ChatGPT 3.5 model and OCR text recognition technology demonstrate strong performance. They enhance the Chinese character learning process, leading to increased efficiency and interest in learning Chinese characters.},
booktitle = {Proceedings of the 2024 International Conference on Image Processing, Intelligent Control and Computer Engineering},
pages = {204–210},
numpages = {7},
location = {Qingdao, China},
series = {IPICE '24}
}

@inproceedings{10.1145/3545945.3569770,
author = {Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.},
title = {Using Large Language Models to Enhance Programming Error Messages},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569770},
doi = {10.1145/3545945.3569770},
abstract = {A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {563–569},
numpages = {7},
keywords = {ai, codex, compiler error messages, large language models, programming error messages, syntax error messages},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3657604.3662042,
author = {Kumar, Harsh and Xiao, Ruiwei and Lawson, Benjamin and Musabirov, Ilya and Shi, Jiakai and Wang, Xinyuan and Luo, Huayin and Williams, Joseph Jay and Rafferty, Anna N. and Stamper, John and Liut, Michael},
title = {Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662042},
doi = {10.1145/3657604.3662042},
abstract = {Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {86–97},
numpages = {12},
keywords = {field experiments, human-ai collaboration, large language models, learning engineering, self-reflection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.5555/3715638.3715656,
author = {Roll, James},
title = {AI as a Learning Tool for Introductory Programming},
year = {2024},
issue_date = {September 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {4},
issn = {1937-4771},
abstract = {The goal of this assignment is to introduce introductory programming students to using generative AI tools like Claude and ChatGPT to help them in learning introductory programming. Students are shown how they can use AI tools to help explain basic programming concepts, decode cryptic error messages, explain why a program isn't working, and find syntax errors in and suggest fixes. Students are also encouraged to avoid using AI Tools to fully write programs at this point in their education, and introduced to the limitations generative AI tools for programming. This version of the assignment was written for an introductory Java programming course, but could easily be adapted to other programming languages.},
journal = {J. Comput. Sci. Coll.},
month = sep,
pages = {45},
numpages = {1}
}

@inproceedings{10.1145/3637528.3671552,
author = {Liu, Zhiwei and Yang, Kailai and Xie, Qianqian and Zhang, Tianlin and Ananiadou, Sophia},
title = {EmoLLMs: A Series of Emotional Large Language Models and Annotation Tools for Comprehensive Affective Analysis},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671552},
doi = {10.1145/3637528.3671552},
abstract = {Sentiment analysis and emotion detection are important research topics in natural language processing (NLP) and benefit many downstream tasks. With the widespread application of large language models (LLMs), researchers have started exploring the application of LLMs based on instruction-tuning in the field of sentiment analysis. However, these models only focus on single aspects of affective classification tasks (e.g. sentimental polarity or categorical emotions), and overlook the regression tasks (e.g. sentiment strength or emotion intensity), which leads to poor performance in downstream tasks. The main reason is the lack of comprehensive affective instruction tuning datasets and evaluation benchmarks, which cover various affective classification and regression tasks. Moreover, although emotional information is useful for downstream tasks, existing downstream datasets lack high-quality and comprehensive affective annotations. In this paper, we propose EmoLLMs, the first series of open-sourced instruction-following LLMs for comprehensive affective analysis based on fine-tuning various LLMs with instruction data, the first multi-task affective analysis instruction dataset (AAID) with 234K data samples based on 3 classification tasks and 2 regression tasks to support LLM instruction tuning, and a comprehensive affective evaluation benchmark (AEB) with 8 regression tasks and 6 classification tasks from various sources and domains to test the generalization ability of LLMs. We propose a series of EmoLLMs by fine-tuning LLMs with AAID to solve various affective instruction tasks. We compare our models with a variety of LLMs and sentiment analysis tools on AEB, where our models outperform all other open-sourced LLMs and sentiment analysis tools, and surpass ChatGPT and GPT-4 in most tasks, which shows that the series of EmoLLMs achieve the ChatGPT-level and GPT-4-level generalization capabilities on affective analysis tasks, and demonstrates our models can be used as affective annotation tools. This project is available at https://github.com/lzw108/EmoLLMs/.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5487–5496},
numpages = {10},
keywords = {affective evaluation benchmark, affective instruction dataset, emotion detection, large language models, sentiment analysis},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3689535.3689552,
author = {Whyte, Robert and Kirby, Diana and Sentance, Sue},
title = {Secondary Students' Emerging Conceptions of AI: Understanding AI Applications, Models, Engines and Implications},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689552},
doi = {10.1145/3689535.3689552},
abstract = {Despite the growing use of AI technologies, there is limited empirical evidence of secondary students’ understanding of AI. Gaining insights into ways in which this might be influenced by their everyday engagement with these tools can support the teaching of AI, including the design of educational resources. The SEAME framework proposes four dimensions for thinking about AI: (i) the social and ethical (SE) implications of AI; (ii) its use in applications (A); (iii) how models (M) are trained; and (iv) the underlying engines (E) used. In this paper, we investigate students’ emerging conceptions of AI and how these can be understood through classification using an appropriate framework. Drawing on data from 474 secondary and college students (11–18), we found that students mostly focused on the applications of AI, followed by its social and ethical implications. We found evidence that students held some primarily accurate conceptions of how AI works, such as how models are trained using large datasets and how human behaviours are simulated (e.g. talking, problem-solving). Specific conceptions relating to generative AI tools were also observed, including the ability to generate content and response to prompts. Conversely, we found students held naive conceptions relating to AI systems having agency or emotions. We argue that efforts to promote accurate conceptions of AI should build on students’ conceptions and take into account how language and representation are used (e.g. anthropomorphism). The results of this study have implications for educators, resource developers and researchers.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {3},
numpages = {7},
keywords = {K-12 education, artificial intelligence, computing education, conceptions, machine learning},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3631802.3631806,
author = {Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi},
title = {How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631806},
doi = {10.1145/3631802.3631806},
abstract = {As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them and the effect they have on learning to code. We present the results of a thematic analysis on a data set from 33 learners, aged 10-17, as they independently learned Python by working on 45 code-authoring tasks with access to an AI Code Generator based on OpenAI Codex. We explore several important questions related to how learners used LLM-based AI code generators, and provide an analysis of the properties of the written prompts and the resulting AI generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex in terms of syntax and logic, (C) properties of prompts written by learners in terms of relation to task description, language, clarity, and prompt crafting patterns, (D) properties of the AI-generated code in terms of correctness, complexity, and accuracy, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. Our findings reveal consistently positive trends between learners’ utilization of the Hybrid coding approach and their post-test evaluation scores, while showing consistent negative trends between the AI Single Prompt and the post-test evaluation scores. Furthermore, we offer insights into novice learners’ use of AI code generators in a self-paced learning environment, highlighting signs of over-reliance, self-regulation, and opportunities for enhancing AI-assisted learning tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {3},
numpages = {12},
keywords = {ChatGPT, Copilot, Introductory Programming, Large Language Models, OpenAI Codex, Self-paced Learning, Self-regulation},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3664646.3664758,
author = {Correia, Jo\~{a}o and Nicholson, Morgan C. and Coutinho, Daniel and Barbosa, Caio and Castelluccio, Marco and Gerosa, Marco and Garcia, Alessandro and Steinmacher, Igor},
title = {Unveiling the Potential of a Conversational Agent in Developer Support: Insights from Mozilla’s PDF.js Project},
year = {2024},
isbn = {9798400706851},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664646.3664758},
doi = {10.1145/3664646.3664758},
abstract = {Large language models and other foundation models (FMs) boost productivity by automating code generation, supporting bug fixes, and generating documentation. We propose that FMs can further support Open Source Software (OSS) projects by assisting developers and guiding the community. Currently, core developers and maintainers answer queries about processes, architecture, and source code, but their time is limited, often leading to delays. To address this, we introduce DevMentorAI, a tool that enhances developer-project interactions by leveraging source code and technical documentation. DevMentorAI uses the Retrieval Augmented Generation (RAG) architecture to identify and retrieve relevant content for queries. We evaluated DevMentorAI with a case study on PDF.js project, using real questions from a development chat room and comparing the answers provided by DevMentorAI to those from humans. A Mozilla expert rated the answers, finding DevMentorAI's responses more satisfactory in 8/14 of cases, equally satisfactory in 3/14, and less satisfactory in 3/14. These results demonstrate the potential of using foundation models and the RAG approach to support developers and reduce the burden on core developers.},
booktitle = {Proceedings of the 1st ACM International Conference on AI-Powered Software},
pages = {10–18},
numpages = {9},
keywords = {Conversational Agents, Developer Assistance, Large Language Models, Software Development, Software Engineering},
location = {Porto de Galinhas, Brazil},
series = {AIware 2024}
}

@inproceedings{10.1145/3611643.3613892,
author = {Jin, Matthew and Shahriar, Syed and Tufano, Michele and Shi, Xin and Lu, Shuai and Sundaresan, Neel and Svyatkovskiy, Alexey},
title = {InferFix: End-to-End Program Repair with LLMs},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613892},
doi = {10.1145/3611643.3613892},
abstract = {Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose : a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs.  combines a Retriever – transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator – an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated , a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that  outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of  alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1646–1656},
numpages = {11},
keywords = {Program repair, finetuning, prompt augmentation, static analyses},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3626252.3630761,
author = {Mason, Raina and Simon and Becker, Brett A. and Crick, Tom and Davenport, James H.},
title = {A Global Survey of Introductory Programming Courses},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630761},
doi = {10.1145/3626252.3630761},
abstract = {We present results of an in-depth survey of nearly 100 introductory programming (CS1) instructors in 18 countries spanning six continents. Although CS1 is well studied, relatively few broadly-scoped studies have been conducted, and none prior have exceeded regional scale. In addition, CS1 is a notoriously fickle and often changing course, and many might find it beneficial to know what other instructors are doing across the globe; perhaps more so as we continue to understand the impact of the COVID-19 pandemic on computing education and as the effects of Generative AI take hold. Expanding upon several surveys conducted in Australasia, the UK, and Ireland, this survey facilitates a direct comparison of global trends in CS1. The survey goes beyond environmental factors such as languages used, and examines why CS1 instructors teach what they do, in the ways they do. In total the survey spans 84 institutions and 91 courses in which a total of over 40,000 students are enrolled.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {799–805},
numpages = {7},
keywords = {covid-19, cs 1, cs-1, cs1, global, instructors, introductory programming, novice programmers, programming languages, survey, teaching languages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3701625.3701684,
author = {Oran, Ana Carolina and Montenegro, Let\'{\i}cia Braga and Schuster, Hellmut Alencar and Duarte, Jos\'{e} Carlos and Silva, Williamson and Lima, Rayfran Rocha},
title = {Integrating ChatGPT in Project Management Education: Benefits and Challenges in the Academic Environment},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701684},
doi = {10.1145/3701625.3701684},
abstract = {CONTEXT: Teaching project management is complex, and students often do not feel engaged or motivated. Professors can use many initiatives to improve the teaching and learning process. Tools like ChatGPT, when integrated into education, have generated considerable interest due to their potential to enrich students’ learning experiences. GOAL: This paper analyzes the impacts of using ChatGPT as a complementary tool in teaching Project Management in the Software Engineering course, highlighting its benefits and challenges. METHOD: We performed an exploratory study to identify the effects of using ChatGPT in teaching project management, evaluating learning, productivity, teamwork, student perceptions, and future expectations. RESULTS: The results indicate that ChatGPT contributed to improving content comprehension, developing critical skills, accelerating production, improving collaboration and communication, and increasing student engagement. However, challenges related to misuse and dependence on the tool were also identified. CONCLUSION: The integration of ChatGPT in teaching project management has shown promise, promoting a richer and more collaborative learning experience. The insights obtained provide directions for future implementations and research on the use of AI in project management education.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {596–604},
numpages = {9},
keywords = {Project management education, Software project management, ChatGPT, AI-assisted learning, Software engineering},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3663529.3663869,
author = {Chavan, Sagar Bhikan and Mondal, Shouvick},
title = {Do Large Language Models Recognize Python Identifier Swaps in Their Generated Code?},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663869},
doi = {10.1145/3663529.3663869},
abstract = {Large Language Models (LLMs) have transformed natural language processing and generation activities in recent years. However, as the scale and complexity of these models grow, their ability to write correct and secure code has come under scrutiny. In our research, we delve into the critical examination of LLMs including ChatGPT-3.5, legacy Bard, and Gemini Pro, and their proficiency in generating accurate and secure code, particularly focusing on the occurrence of identifier swaps within the code they produce. Our methodology encompasses the creation of a diverse dataset comprising a range of coding tasks designed to challenge the code generation capabilities of these models. Further, we employ Pylint for an extensive code quality assessment and undertake a manual multi-turn prompted “Python identifier-swap” test session to evaluate the models’ ability to maintain context and coherence over sequential coding prompts. Our preliminary findings indicate a concern for developers: LLMs capable of generating better quality codes can perform worse when queried to recognize identifier swaps.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {663–664},
numpages = {2},
keywords = {Gemini Pro, LLMs, Python Identifier Swap},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3626203.3670588,
author = {Stevens, Cody and Anderson, Sean and Carlson, Adam},
title = {Integrating High Performance Computing into Higher Education and the Pedagogy of Cluster Computing},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670588},
doi = {10.1145/3626203.3670588},
abstract = {Despite the exponential growth in demand for advanced computational skills driven by big data, machine learning, and artificial intelligence, higher education institutions still face a significant shortage of dedicated course offerings pertaining to High Performance Computing (HPC). This educational deficiency not only hampers the preparedness of undergraduate students for cutting-edge postgraduate programs but also impairs their readiness to enter a dynamic workforce increasingly reliant on sophisticated computational capabilities. Integrating comprehensive HPC courses at the undergraduate level is critical for equipping students with expertise to effectively utilize modern computing technologies, and also for bridging the growing gap between academic preparation and industry demands. At Wake Forest University (WFU), we, members of the HPC Team, are actively working to address the educational gap in HPC by integrating the WFU HPC Facility[4] into higher-level elective courses across various disciplines. Recognizing the foundational importance of these skills, we have developed an introductory course specifically designed to equip students with the knowledge to excel in advanced courses, in graduate and research programs, and to meet the demands of the modern workforce. By integrating the WFU HPC Facility into our curriculum, the University is committed to pioneering a comprehensive educational pathway that empowers students to leverage the full potential of computing technologies in their future careers. WFU is an R-2 liberal arts institution with around 9,000 students[6] that actively supports undergraduate research through a multitude of departments and programs. Undergraduate research is so paramount to the University mission, that WFU has a dedicated center, the Undergraduate Research and Creative Activities (URECA) Center, just for this purpose. Many students engage in research projects that leverage the resources of the WFU HPC Facility. The facility’s main asset, the Distributed Environment for Academic Computing (DEAC) Cluster, contains approximately 4000 CPU cores and 20TB of RAM, and is a true interdisciplinary tool; in 2023 it was utilized by 15 departments and 500 active users to submit over 1.5 million computational tasks on a vast array of research topics. The interdisciplinary nature of the DEAC Cluster played an instrumental role in developing an introductory course in HPC that caters to students from a diverse number of majors. Having supported a wide range of researchers, we designed the course to bridge concepts and applications from Computer Science, Engineering, Data Science, and the Natural Sciences to their respective academic domains. By enabling students from multiple disciplines to access foundational HPC skills, we foster a versatile educational environment where collaborative and interdisciplinary learning thrives. One way that we ensure our introductory course is accessible to all students is that we do not require any prerequisite classes to enroll in the course. Students are also not expected to have any prior experience in programming. We have chosen Python as the primary programming language for the course, as it is one of the most versatile and widely-used languages in the fields of data science and machine learning, and can easily interface with parallel frameworks such as MPI and OpenMP. Students gain hands-on experience by developing asynchronous workflows, which are then executed on the DEAC Cluster. This practical focus not only demystifies complex computational concepts but also empowers students to apply their learning in real-world scenarios. HPC serves as a cornerstone for two distinct user groups, each integral to its advancement and application. The first encompasses those who enable and optimize HPC systems, including Computer Scientists, Computer Engineers, Systems Administrators, and Cyberinfrastructure Professionals, who enhance computational efficiency and build the underlying hardware infrastructure. The second group comprises scientists and researchers across diverse fields such as Statistics, Chemistry, Biology, Physics, Engineering, and more, who leverage HPC as a powerful tool for simulating complex phenomena, analyzing large datasets, and researching novel problems in their respective domains. While current course offerings at other institutions seem to prioritize the first group and educate students on how to build and enable an HPC cluster, we have chosen to prioritize curriculum for the second group as the skills they gain through our course’s curriculum will help them as they continue their academic career in higher level electives and independent research projects with faculty advisors. We choose to offer our course during the Spring semester in order to prepare students who may want to pursue research during the summer session. The first half of the course serves as foundational cluster training, familiarizing students with essential skills to work within an HPC environment. In this segment, students delve into the Linux command line interface (CLI) using Bashcrawl[3] and explore the intricacies of the Linux filesystem and environment modules. A significant focus is placed on understanding and utilizing job schedulers, such as the Slurm resource manager[2]. Another unique feature of this segment is the guided tour of the Wake Forest datacenter. This tour provides students with a tangible understanding of how the theoretical concepts discussed in class are implemented in a real-world HPC cluster. To further provide a reference to the resources requested for their jobs through Slurm, the tour concludes with students disassembling retired compute nodes to learn about the different components that comprise modern servers. The midterm assessment challenges students to submit multiple jobs, analyzing the effects of varying input sizes and the use of multiple CPU processors on calculation speed. Upon completion of this initial phase, students are fully equipped to engage in research activities under an advisor and effectively utilize an HPC cluster outside the confines of the classroom. Many apply for summer grants through the aforementioned URECA program with a faculty advisor. In the latter half of the course, the curriculum shifts towards more advanced topics, focusing on parallel computing frameworks and technologies. Students are introduced to MPI and OpenMP, which are essential for developing parallel applications that can run efficiently on today’s multi-processor systems. Additionally, the course delves into high-speed interconnects, crucial for optimizing communication between different parts of an HPC cluster. One of our final topics covers GPU computing, with a particular emphasis on using NVIDIA GPUs and the CUDA programming platform, enabling students to harness the power of graphical processing for computational tasks. As an example from our Spring 2024 semester, students built a “chatbot” using Meta’s Llama 2 model[5] on both CPU and GPU using LLaMA C++[1], and compared its performance to ChatGPT while interacting freely with it. Our course is designed to complement other specialized courses found in Computer Science or in Computer Engineering programs, such as Parallel Algorithms, Computer Vision, or Deep Learning. It aims to introduce these critical computational concepts and provide a solid foundation that prepares students for these more advanced electives. By the end of the course, students are not only familiar with the basic principles of HPC but are also primed to tackle more specialized studies and research in their future academic and professional pursuits. It is not uncommon that a course may require students to use a specific programming language or software. While there are tools such as Google Colab and zyBooks that provide a browser-based interface to computing resources, those tools can be very limited in what resources they can provide. A faculty member might then want students to install software locally on their laptop, but this can be challenging when students bring their own device to the classroom as they may be running different operating systems or may have different hardware platforms. This can cause the software to behave differently or it may not even be available on that given platform. Courses with significant computational demands are better served utilizing a unified computing environment, and an HPC facility is ideally equipped to provide a consistent learning environment where each student has access to the same software and computing resources. A primary challenge in integrating HPC resources into coursework is instructing students on the use of schedulers for asynchronous workloads. Our introductory HPC course effectively bridges this gap by providing the necessary training and context, enabling students to engage with advanced topics more efficiently, without the steep initial learning curve typically associated with these environments. Our HPC facility has proven instrumental in enhancing educational experiences across a variety of disciplines, demonstrating significant benefits in classes such as Statistics, Natural Language Processing, Parallel Algorithms, Computer Vision, Physics Laboratory, Cancer Biology, Environmental Physics, Computational Modeling, and more. Moreover, students in fields like Finance and Business and Enterprise Management have also successfully leveraged our HPC resources, and have performed analysis on client data that was protected under a nondisclosure agreement which prevented students from storing the data locally on their laptop or with commercial cloud providers. This integration not only facilitates sophisticated computational tasks, but also allows students and faculty to easily share and store large datasets that the students may need to access without having to consume space on their local device. One of our primary goals is to promote diversity and interdisciplinary collaboration within this course, and this semester attracted a notably diverse group of students, with majors ranging from Biology and Statistics to Applied Mathematics, Economics, and Computer Science. Although the course is currently catalogued under the Computer Science department, we recognize that associating it with any single discipline could potentially limit its appeal and accessibility. The diverse enrollment underscores the interdisciplinary relevance of HPC skills across various fields of study. We are leveraging the current success and broad interest in the course as a foundation to establish a new academic program dedicated to High Performance Computing. This new program will serve as a hub for integrating computational skills across different disciplines, fostering a broader understanding and application of HPC in various scientific and economic sectors. The HPC team’s commitment to High Performance Computing education extends beyond traditional academic structures. While we are not developing a new major, minor, certificate track, or concentration in HPC, our objective is to make HPC education accessible and applicable across various disciplines without the constraints of a single departmental bias. This approach allows students from any field to engage with HPC skills as an integral part of their academic and professional development. To achieve this, we are actively collaborating with multiple academic departments to ensure that our HPC course offerings are recognized as fulfilling degree requirements across a range of programs. One way we collaborate with these departments is by altering activities and projects to use different languages and software, such as R and MATLAB, for the Statistics and Engineering departments, while still maintaining the same learning goals we achieve with Python. This strategy not only enhances the versatility of our course but also promotes a more comprehensive integration of the university’s HPC facilities into the curriculum. By doing so, we allow faculty in different departments to integrate our projects into their courses and utilize our HPC facility, even if it is for only one or two projects throughout the semester. Our efforts are focused on fostering a collaborative academic environment where the HPC facility is not just an isolated resource used for research but a central part of our educational infrastructure. By working across disciplines, we hope to catalyze a deeper engagement with HPC technologies throughout the university, enhancing both teaching and research capacities across departments. In conclusion, the escalating demand for big data, machine learning, and artificial intelligence is not only transforming industries but also reshaping educational requirements. As these fields expand, the need for substantial computational resources becomes increasingly critical. The HPC facility at Wake Forest University is exceptionally well-equipped to meet these demands, by providing a unified computing environment that supports an array of academic endeavors. Our initiative to develop introductory HPC courses is a strategic response to this need, preparing students to proficiently utilize HPC resources in higher-level electives and beyond. These courses are pivotal in bridging the gap between conventional academic programs and the rigorous computational needs of modern disciplines. Looking forward, the necessity for such educational offerings will only intensify as the reliance on advanced computational technologies grows. By anticipating and responding to these educational demands, Wake Forest University’s HPC academic program not only enhances student readiness for future challenges but also positions the university at the forefront of academic innovation in the computational sciences.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {106},
numpages = {3},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@article{10.5555/3665609.3665618,
author = {Sharpe, James S. and Dougherty, Ryan E. and Smith, Sarah J.},
title = {Can ChatGPT Pass a CS1 Python Course?},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {In this paper we determine whether an LLM-ChatGPT in this case-can successfully complete the assignments in our CS1 course as if it were a "real" student. Our study contains a two-stage approach, involving reprompts to the LLM in the cases of either not successfully completing the assignment, or using concepts that are more advanced than are taught in our course. We find that LLMs can in fact can either perfectly solve, or almost perfectly solve, every assignment in our CS1 course.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {128–142},
numpages = {15}
}

@inproceedings{10.1145/3626253.3635604,
author = {Weber, Jason Lee and Martinez Neda, Barbara and Carbajal Juarez, Kitana and Wong-Ma, Jennifer and Gago-Masague, Sergio and Ziv, Hadar},
title = {Measuring CS Student Attitudes Toward Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635604},
doi = {10.1145/3626253.3635604},
abstract = {With the mainstream adoption of Large Language Models (LLMs), members of both academia and the media have raised concerns around their impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption of and attitudes toward LLMs among the CS student population at an R1 University to determine how students are using these new tools. To this end, we conducted a large survey study targeting two populations participating in computing courses at the university: intro-sequence students (ISS) and experienced students (ES).In our preliminary results from Spring 2023, we've found several significant differences among the views of over 700 respondents across the two groups. Most students reported LLMs' unparalleled potential for quick information access, yet many harbor concerns about the reliability of the LLM responses, and the impact on academic integrity. Additionally, while ES have rapidly integrated LLMs into their learning, ISS remain cautious of the tools, highlighting a stark contrast in adoption rates between the groups.LLMs are clearly going to reshape pedagogical approaches and student engagement. Our study hopes to provide insight on the nuanced student attitudes toward LLMs. For example, the notable reservations expressed by ISS illustrate an imperative for careful, informed, and ethical integration to ensure these tools enhance rather than compromise the educational experience. In the future, we plan to continue tracking student attitudes in order to gain further understanding of the changing perceptions of LLMs and their impact.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1846–1847},
numpages = {2},
keywords = {academic integrity, ai tools, chatgpt, faculty perception, generative ai, large language models (llms), student perception},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649165.3703622,
author = {Alshaigy, Bedour and Grande, Virginia and Kiesler, Natalie and Settle, Amber},
title = {How Do You Solve A Problem Like Recruitment? On The Hiring and Retention of Computing Academics},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3703622},
doi = {10.1145/3649165.3703622},
abstract = {This paper critically examines persistent inequities in existing computing faculty hiring and retention practices, which gravely impact computing educators from marginalized groups. Throughout these processes, applicants fight against multiple systemic barriers, including but not limited to, biased job ads and discriminatory interview practices. The increasing use of generative AI tools to aid in tasks connected to the hiring process, such as writing recommendation letters, exacerbates these biases. The inequities persist despite global initiatives and legal mandates and serve as a direct contradiction to widespread institutional commitments to diversity and inclusion. By building on literature and the lived experiences of the SIGCSE community represented in a recent Technical Symposium session, we raise concerns about the different stages of this process, highlighting the importance of clear expectations and adequate support. The paper concludes with a call to align hiring practices with inclusive institutional values, requiring the academic community to reflect on and revise hiring policies for a more equitable future. It is of paramount importance to address the role of these practices in the erosion of marginalized communities from the computing education community, a marginalization that occurs in many different contexts and negatively impacts everyone involved.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {263–266},
numpages = {4},
keywords = {CS academics, recruitment, retention},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3691620.3695307,
author = {Wu, Yueming and Liu, Chengwei and Xu, Zhengzi and Zhang, Lyuye and Zhang, Yiran and Zhu, Zhiling and Liu, Yang},
title = {The Software Genome Project: Unraveling Software Through Genetic Principles},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695307},
doi = {10.1145/3691620.3695307},
abstract = {Open-source software is crucial to modern development, but its complexity creates challenges in quality, security, and management. Current governance approaches excel at collaboration but struggle with decentralized management and security. With the rise of large language models (LLM)-based software engineering, the need for a finer-grained understanding of software composition is more urgent than ever. To address these challenges, inspired by the Human Genome Project, we treat the software source code as software DNA and propose the Software Genome Project (SGP), which is geared towards the secure monitoring and exploitation of open-source software. By identifying and labeling integrated and classified code features at a fine-grained level, and effectively identifying safeguards for functional implementations and nonfunctional requirements at different levels of granularity, the SGP could build a comprehensive set of software genome maps to help developers and managers gain a deeper understanding of software complexity and diversity. By dissecting and summarizing functional and undesirable genes, SGP could help facilitate targeted software optimization, provide valuable insight and understanding of the entire software ecosystem, and support critical development tasks such as open source governance. SGP could also serve as a comprehensive dataset with abundant semantic labeling to enhance the training of LLMs for code. Based on these, we expect SGP to drive the evolution of software development towards more efficient, reliable, and sustainable software solutions.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2319–2323},
numpages = {5},
keywords = {software genes, software composition, OSS governance},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3675094.3677573,
author = {Wang, Yongfu and Tang, Mingyue and He, Yifan and Tang, Tiffany Y.},
title = {Interactive Design with Autistic Children using LLM and IoT for Personalized Training: The Good, The Bad and The Challenging},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677573},
doi = {10.1145/3675094.3677573},
abstract = {The advent of generative artificial intelligence technologies, such as Large Language Models (LLMs) and Large Vision Models (LVMs), has shown promising results in both academic and industrial sectors, leading to widespread adoption. However, there has been limited focus on applying these technologies to assist children with special needs like Autism Spectrum Disorder (ASD). Meanwhile, conventional personalized training with interactive design for children with special needs continues to face significant challenges with traditional approaches. This workshop aims to provide a platform for researchers, software developers, medical practitioners, and designers to discuss and evaluate the benefits and drawbacks of using LLMs and the Internet of Things (IoT) for the diagnosis and personalized training of autistic children. Through a series of activities, including oral presentations, demonstrations, and panel discussions, this half-day workshop seeks to foster a network of experts dedicated to improving the lives of children with special needs and to inspire further research on leveraging emerging ubiquitous technologies for these underprivileged users, their caregivers and special education teachers.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {1000–1003},
numpages = {4},
keywords = {autism, children, interaction design, large language model (llm), personalized training, ubiquitous computing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3643991.3645070,
author = {Moratis, Konstantinos and Diamantopoulos, Themistoklis and Nastos, Dimitrios-Nikitas and Symeonidis, Andreas},
title = {Write me this Code: An Analysis of ChatGPT Quality for Producing Source Code},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645070},
doi = {10.1145/3643991.3645070},
abstract = {Developers nowadays are increasingly turning to large language models (LLMs) like ChatGPT to assist them with coding tasks, inspired by the promise of efficiency and the advanced capabilities they offer. However, this raises important questions about the ease of integration and the safety of incorporating these tools into the development process. To investigate these questions, this paper examines a set of ChatGPT conversations. Upon annotating the conversations according to the intent of the developer, we focus on two critical aspects: firstly, the ease with which developers can produce suitable source code using ChatGPT, and, secondly, the quality aspects of the generated source code, determined by the compliance to standards and best practices. We research both the quality of the generated code itself and its impact on the project of the developer. Our results indicate that ChatGPT can be a useful tool for software development when used with discretion.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {147–151},
numpages = {5},
keywords = {code generation, code quality, ChatGPT, large language models},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3691620.3695061,
author = {Yu, Xiao and Zhang, Zexian and Niu, Feifei and Hu, Xing and Xia, Xin and Grundy, John},
title = {What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners' Perspective},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695061},
doi = {10.1145/3691620.3695061},
abstract = {Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {656–668},
numpages = {13},
keywords = {large language models, high-quality data, practitioners' perspective, empirical study},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3674399.3674423,
author = {Xu, Ke and Yi, Hanxiao and Xu, Zichen and Wu, Dan},
title = {Data-driven Contribution-based Disciplinary Assessment System},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674423},
doi = {10.1145/3674399.3674423},
abstract = {A scientific disciplinary assessment system is crucial for nurturing high-quality disciplines within Computer Science. Computer Science Education (CSE) emphasizes the need for a scientific and comprehensive assessment method that guides the development of the discipline, with a particular focus on practical contributions. However, traditional assessment systems tend to prioritize the theoretical outcomes. Moreover, data expansion demands significant effort and time from educational professionals, making it challenging to conduct a thorough evaluation of the disciplines. To tackle these issues, we introduce a data-driven, contribution-based disciplinary assessment system. This system takes into account both theoretical and practical contributions to provide a holistic evaluation. Our proposed system employs a contribution-based assessment approach to establish a correct evaluative direction, steering discipline construction to align with societal needs. It also incorporates intelligent algorithms and a Large Language Model (LLM), leveraging their substantial computational power in the evaluation process. This integration alleviates the workload of educational professionals by automating the collection and analysis of information. The paper outlines a detailed implementation plan that integrates contribution evaluation theory with intelligent technologies, aiming to foster the ongoing advancement of CSE education.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {42–47},
numpages = {6},
keywords = {Big Data-driven, Contribution-Based Evaluation Method, Disciplinary assessment},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3631991.3632024,
author = {Chen, Shunxing and Xu, Xiaoshu and Zhang, Huanhuan and Zhang, Yunfeng},
title = {Roles of ChatGPT in virtual teaching assistant and intelligent tutoring system: opportunities and challenges},
year = {2023},
isbn = {9798400708053},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631991.3632024},
doi = {10.1145/3631991.3632024},
abstract = {Artificial Intelligence (AI), specifically the Generative Pre-trained Transformer 4 (GPT-4), or ChatGPT, promises to revolutionize Virtual Teaching Assistants (VTAs) and Intelligent Tutoring Systems (ITS). This advanced language model fosters enhanced student engagement and personalized, adaptive learning experiences. However, amidst the substantial benefits, several critical challenges encompassing response reliability, data privacy, algorithmic biases, and interpretability necessitate deliberate scrutiny. The proposed study aims to examine the opportunities and hurdles inherent to the deployment of ChatGPT in the educational landscape. With a focus on high-quality, Google Scholar, Scopus, and Web of Science-indexed literature, the review encompasses a comprehensive exploration of empirical studies, theoretical perspectives, and practical implications related to ChatGPT. Through this literature review, we will shed light on the dynamic intersection of AI and education. The elucidation of nuanced implications will empower educators, policymakers, and AI developers to make informed decisions and devise effective strategies, thereby facilitating an optimized integration of ChatGPT into the educational ecosystem.},
booktitle = {Proceedings of the 2023 5th World Symposium on Software Engineering},
pages = {201–206},
numpages = {6},
keywords = {ChatGPT, challenges, education, intelligent tutoring systems, opportunities, virtual teaching assistants},
location = {Tokyo, Japan},
series = {WSSE '23}
}

@inproceedings{10.1145/3657604.3662039,
author = {Smith, David H. and Denny, Paul and Fowler, Max},
title = {Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662039},
doi = {10.1145/3657604.3662039},
abstract = {Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {39–50},
numpages = {12},
keywords = {CS1, EIPE, LLMs, code comprehension, explain in plain English, introductory programming, large language models, prompting},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1109/ASE56229.2023.00076,
author = {Tang, Ze and Ge, Jidong and Liu, Shangqing and Zhu, Tingwei and Xu, Tongtong and Huang, Liguo and Luo, Bin},
title = {Domain Adaptive Code Completion via Language Models and Decoupled Domain Databases},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00076},
doi = {10.1109/ASE56229.2023.00076},
abstract = {Large Language Models (LLMs) have demonstrated remarkable performance in code completion. However, due to the lack of domain-specific knowledge, they may not be optimal in completing code that requires intensive domain knowledge for example completing the library names. Although there are several works that have confirmed the effectiveness of fine-tuning techniques to adapt language models for code completion in specific domains. They are limited by the need for constant fine-tuning of the model when the project is in constant iteration.To address this limitation, in this paper, we propose kNM-LM, a retrieval-augmented language model (R-LM), that integrates domain knowledge into language models without fine-tuning. Different from previous techniques, our approach is able to automatically adapt to different language models and domains. Specifically, it utilizes the in-domain code to build the retrieval-based database decoupled from LM, and then combines it with LM through Bayesian inference to complete the code. The extensive experiments on the completion of intra-project and intra-scenario have confirmed that kNM-LM brings about appreciable enhancements when compared to CodeGPT and UnixCoder. A deep analysis of our tool including the responding speed, storage usage, specific type code completion, and API invocation completion has confirmed that kNM-LM provides satisfactory performance, which renders it highly appropriate for domain adaptive code completion. Furthermore, our approach operates without the requirement for direct access to the language model's parameters. As a result, it can seamlessly integrate with black-box code completion models, making it easy to integrate our approach as a plugin to further enhance the performance of these models.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {421–433},
numpages = {13},
keywords = {domain adaptive code completion, retrieval-augment language model},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3657604.3662031,
author = {Lu, Xinyi and Wang, Xu},
title = {Generative Students: Using LLM-Simulated Student Profiles to Support Question Item Evaluation},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662031},
doi = {10.1145/3657604.3662031},
abstract = {Evaluating the quality of automatically generated question items has been a long standing challenge. In this paper, we leverage LLMs to simulate student profiles and generate responses to multiple-choice questions (MCQs). The generative students' responses to MCQs can further support question item evaluation. We propose Generative Students, a prompt architecture designed based on the KLI framework. A generative student profile is a function of the list of knowledge components the student has mastered, has confusion about or has no evidence of knowledge of. We instantiate the Generative Students concept on the subject domain of heuristic evaluation. We created 45 generative students using GPT-4 and had them respond to 20 MCQs. We found that the generative students produced logical and believable responses that were aligned with their profiles. We then compared the generative students' responses to real students' responses on the same set of MCQs and found a high correlation. Moreover, there was considerable overlap in the difficult questions identified by generative students and real students. A subsequent case study demonstrated that an instructor could improve question quality based on the signals provided by Generative Students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {16–27},
numpages = {12},
keywords = {generative AI, generative agent, question item evaluation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3576882.3617921,
author = {Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram},
title = {Generating Programs Trivially: Student Use of Large Language Models},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617921},
doi = {10.1145/3576882.3617921},
abstract = {Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {126–132},
numpages = {7},
keywords = {formal methods, large language models, properties, testing},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3657604.3662030,
author = {Moore, Steven and Schmucker, Robin and Mitchell, Tom and Stamper, John},
title = {Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662030},
doi = {10.1145/3657604.3662030},
abstract = {Knowledge Components (KCs) linked to assessments enhance the measurement of student learning, enrich analytics, and facilitate adaptivity. However, generating and linking KCs to assessment items requires significant effort and domain-specific knowledge. To streamline this process for higher-education courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs) in Chemistry and E-Learning. We analyzed discrepancies between the KCs generated by the Large Language Model (LLM) and those made by humans through evaluation from three domain experts in each subject area. This evaluation aimed to determine whether, in instances of non-matching KCs, evaluators showed a preference for the LLM-generated KCs over their human-created counterparts. We also developed an ontology induction algorithm to cluster questions that assess similar KCs based on their content. Our most effective LLM strategy accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with even higher success when considering the top five KC suggestions. Human evaluators favored LLM-generated KCs, choosing them over human-assigned ones approximately two-thirds of the time, a preference that was statistically significant across both domains. Our clustering algorithm successfully grouped questions by their underlying KCs without needing explicit labels or contextual information. This research advances the automation of KC generation and classification for assessment items, alleviating the need for student data or predefined KC labels.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {122–133},
numpages = {12},
keywords = {concept labeling, knowledge component, knowledge labeling, learning engineering, multiple-choice question},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626252.3630822,
author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
title = {dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630822},
doi = {10.1145/3626252.3630822},
abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1314–1320},
numpages = {7},
keywords = {ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1109/SC41406.2024.00076,
author = {Giordani, Jeremiah and Xu, Ziyang and Colby, Ella and Ning, August and Godala, Bhargav Reddy and Chaturvedi, Ishita and Zhu, Shaowei and Chon, Yebin and Chan, Greg and Tan, Zujun and Collier, Galen and Halverson, Jonathan D. and Deiana, Enrico Armenio and Liang, Jasper and Sossai, Federico and Su, Yian and Patel, Atmn and Pham, Bangyen and Greiner, Nathan and Campanoni, Simone and August, David I.},
title = {Revisiting Computation for Research: Practices and Trends},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00076},
doi = {10.1109/SC41406.2024.00076},
abstract = {In the field of computational science, effectively supporting researchers necessitates a deep understanding of how they utilize computational resources. Building upon a decade-old survey that explored the practices and challenges of research computation, this study aims to bridge the understanding gap between providers of computational resources and researchers who rely on them. This study revisits key survey questions and gathers feedback on open-ended topics from over a hundred interviews. Quantitative analyses of present and past results illuminate the landscape of research computation. Qualitative analyses, including careful use of large language models, highlight trends and challenges with concrete evidence. Given the rapid evolution of computational science, this paper offers a toolkit with methodologies and insights to simplify future research and ensure ongoing examination of the landscape. This study, with its findings and toolkit, guides enhancements to computational systems, deepens understanding of user needs, and streamlines reassessment of the computational landscape.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {70},
numpages = {14},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3664647.3681053,
author = {Zhao, Bowen and Cheng, Tianhao and Zhang, Yuejie and Cheng, Ying and Feng, Rui and Zhang, Xiaobo},
title = {CT2C-QA: Multimodal Question Answering over Chinese Text, Table and Chart},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681053},
doi = {10.1145/3664647.3681053},
abstract = {Multimodal Question Answering (MMQA) is crucial as it enables comprehensive understanding and accurate responses by integrating insights from diverse data representations such as tables, charts, and text. Most existing researches in MMQA only focus on two modalities such as image-text QA, table-text QA and chart-text QA, and there remains a notable scarcity in studies that investigate the joint analysis of text, tables, and charts. In this paper, we present CT2C-QA, a pioneering Chinese reasoning-based QA dataset that includes an extensive collection of text, tables, and charts, meticulously compiled from 200 selectively sourced webpages. Our dataset simulates real webpages and serves as a great test for the capability of the model to analyze and reason with multimodal data, because the answer to a question could appear in various modalities, or even potentially not exist at all. Additionally, we present AED (Allocating, Expert and Decision), a multi-agent system implemented through collaborative deployment, information interaction, and collective decision-making among different agents. Specifically, the Assignment Agent is in charge of selecting and activating expert agents, including those proficient in text, tables, and charts. The Decision Agent bears the responsibility of delivering the final verdict, drawing upon the analytical insights provided by these expert agents. We execute a comprehensive analysis, comparing AED with various state-of-the-art models in MMQA, including GPT-4. The experimental outcomes demonstrate that current methodologies, including GPT-4, are yet to meet the benchmarks set by our dataset.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3897–3906},
numpages = {10},
keywords = {chinese, multi-agent, multimodal large language model, multimodal question answering, text, table and chart},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3691621.3694934,
author = {Siddiq, Mohammed Latif and da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
title = {SALLM: Security Assessment of Generated Code},
year = {2024},
isbn = {9798400712494},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691621.3694934},
doi = {10.1145/3691621.3694934},
abstract = {With the growing popularity of Large Language Models (LLMs) in software engineers' daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs' abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models' performance from the perspective of secure code generation.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering Workshops},
pages = {54–65},
numpages = {12},
keywords = {security evaluation, large language models, pre-trained transformer model, metrics},
location = {Sacramento, CA, USA},
series = {ASEW '24}
}

@inproceedings{10.1145/3545945.3569785,
author = {MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho},
title = {Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569785},
doi = {10.1145/3545945.3569785},
abstract = {Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations -- a line-by-line explanation, a list of important concepts, and a high-level summary of the code -- were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {931–937},
numpages = {7},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@article{10.5555/3715622.3715635,
author = {Al-Nsour, Rawan},
title = {AI Tools in Matlab Course Education: Instructor Point of View},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {This work aims to investigate the influence of AI tools, specifically ChatGPT, on assignment submissions for an undergraduate programming course. The study evaluates the variance between MATLAB code submissions supported by ChatGPT and those based solely on traditional classroom resources such as instructor notes, textbooks, and class exercises. By analyzing these differences, the research seeks to highlight the advantages of using AI as an assistant tool, including enhanced efficiency and personalized feedback. However, it also examines the drawbacks, such as potential over-reliance on AI and its impact on achieving students' learning goals. Additionally, the study provides recommendations on how to manage and integrate this new technology effectively to ensure that it complements rather than detracts from the educational experience. Through this comprehensive evaluation, the paper seeks to offer insights into balancing AI assistance with traditional teaching methods to optimize learning outcomes in programming education.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {95–104},
numpages = {10}
}

@article{10.5555/3665464.3665469,
author = {Manley, Eric D. and Urness, Timothy and Migunov, Andrei and Reza, Md. Alimoor},
title = {Examining Student Use of AI in CS1 and CS2},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {The launch of ChatGPT in November 2022 marked a seismic disruption to many disciplines and industries, including higher education. For the first time, students everywhere have widely available access to a Large Language Model (LLM) capable of generating content - including solutions to programming assignments in CS1 and CS2 - that can pass as the work of a high-achieving student while making traditional plagiarism-detection obsolete. This has spurred various responses in higher education, including a shift to more in-class and unplugged assessments. At the same time, LLMs are transforming the way that many people work, including professional software developers, and students similarly might be able to use them to enhance their learning. In this paper, we report on our experiences with a permissive policy towards the use of ChatGPT and other artificial intelligence (AI) tools for assisting students with their programming assignments in CS1 and CS2 courses in the Spring 2023 semester. Students were allowed to use these tools however they wished as long as they submitted a form which included a transcript of their chat and a reflection on what they learned, if anything, through the interaction. We found that students largely approached the AI in positive ways and that they seemed to genuinely learn from the experience. We also document some things that did not go well and that remain challenges to using AI in programming courses, along with our recommendations on how these might be dealt with in the future.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {41–51},
numpages = {11}
}

@inproceedings{10.1145/3626252.3630764,
author = {Wang, Sierra and Mitchell, John and Piech, Chris},
title = {A Large Scale RCT on Effective Error Messages in CS1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630764},
doi = {10.1145/3626252.3630764},
abstract = {In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1395–1401},
numpages = {7},
keywords = {cs1, error messages, gpt, llm, randomized control trial},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3613904.3642706,
author = {Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q},
title = {How Beginning Programmers and Code LLMs (Mis)read Each Other},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642706},
doi = {10.1145/3613904.3642706},
abstract = {Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {26},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3639474.3640065,
author = {Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao},
title = {Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640065},
doi = {10.1145/3639474.3640065},
abstract = {Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs.However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {320–330},
numpages = {11},
keywords = {programming assignment, code performance, tool support},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3674805.3690741,
author = {De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca},
title = {Evaluating Large Language Models in Exercises of UML Class Diagram Modeling},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690741},
doi = {10.1145/3674805.3690741},
abstract = {Large Language Models (LLM) have rapidly affirmed in the latest years as a means to support or substitute human actors in a variety of tasks. LLM agents can generate valid software models, because of their inherent ability in evaluating textual requirements provided to them in the form of prompts. The goal of this work is to evaluate the capability of LLM agents to correctly generate UML class diagrams in activities of Requirements Modeling in the field of Software Engineering. Our aim is to evaluate LLMs in an educational setting, i.e., understanding how valuable are the results of LLMs when compared to results made by human actors, and how valuable can LLM be to generate sample solutions to provide to students. For that purpose, we collected 20 exercises from a diverse set of web sources and compared the models generated by a human and an LLM solver in terms of syntactic, semantic, pragmatic correctness, and distance from a provided reference solution. Our results show that the solutions generated by an LLM solver typically present a significantly higher number of errors in terms of semantic quality and textual difference against the provided reference solution, while no significant difference is found in syntactic and pragmatic quality. We can therefore conclude that, with a limited amount of errors mostly related to the textual content of the solution, UML diagrams generated by LLM agents have the same level of understandability as those generated by humans, and exhibit the same frequency in violating rules of UML Class Diagrams.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {393–399},
numpages = {7},
keywords = {Artificial Intelligence, Class Diagrams, Large Language Models, Software Modeling},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3643795.3648380,
author = {S Kumar, Smitha and Adam Lones, Michael and Maarek, Manuel and Zantout, Hind},
title = {Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648380},
doi = {10.1145/3643795.3648380},
abstract = {Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feedback for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {88–93},
numpages = {6},
keywords = {large language models (LLM), GPT-4, feedback, java programming, program repair},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3627217.3627235,
author = {Venkatesh, Varshini and Venkatesh, Vaishnavi and Kumar, Viraj},
title = {Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627235},
doi = {10.1145/3627217.3627235},
abstract = {Code writing problems in introductory programming (CS1) courses typically ask students to write simple functions or programs based on detailed natural-language specifications. These details can be leveraged by large language models (LLMs), accessible to students via tools such as GitHub Copilot, to generate solutions that are often correct. CS1 instructors who are unwilling or unable to prohibit such usage must consider variants of traditional code writing problems that align with their learning objectives but are more difficult for LLMs to solve. Since LLMs are sensitive to the level of details in their prompts, it is natural to consider variants where details are progressively trimmed from the specifications of traditional code writing problems, and consequent ambiguities are clarified via examples. We consider an extreme variant, where all natural language is suppressed except for meaningful names of functions and their arguments. We evaluate the performance of Copilot on suppressed specification versions of 153 such problems drawn from the CodeCheck repository. If Copilot initially fails to generate a correct solution, we augment each suppressed specification with as few clarifying examples as possible to obtain a correct solution. Copilot solves 134 problems (87%) with just 0.7 examples on average, requiring no examples in 78 instances. Thus, modifying traditional code-writing problems by merely trimming specification details is unlikely to thwart sophisticated LLMs such as GitHub Copilot.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {104–107},
numpages = {4},
keywords = {CS1, code writing, large language models},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3631700.3665227,
author = {Fenu, Gianni and Galici, Roberta and Marras, Mirko and Reforgiato, Diego},
title = {Exploring Student Interactions with AI in Programming Training},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665227},
doi = {10.1145/3631700.3665227},
abstract = {In recent years, the integration of artificial intelligence (AI) in education has collected significant attention due to its potential to revolutionize learning experiences and support student skill development. This study delves into the dynamics of student interactions with AI support within the domain of C programming education, with a specific focus on the utilization of ChatGPT, a conversational AI model, during training sessions. Through manual clustering analysis, this research unveils distinct patterns of student engagement, elucidating diverse problem-solving approaches and varying levels of interaction with ChatGPT. Our findings underscore the importance of acknowledging individual differences in learning strategies and preferences, highlighting the necessity for personalized educational interventions tailored to meet the diverse needs of learners. However, despite the strides made in AI-supported learning, gaps persist in the existing literature, particularly concerning our understanding of how students approach prompts and exercises when utilizing AI-driven educational tools. This research aims to address this gap by shedding light on the nuanced dynamics of student-AI interactions during training of C programming, offering insights into effective pedagogical strategies and instructional design principles for integrating AI technologies into educational settings. This study makes a significant contribution to the continuous endeavors of educators and AI developers by furthering the discussion on AI-facilitated learning. It aims to enhance student engagement, learning outcomes, and overall educational experiences through the integration of technology into learning environments.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {555–560},
numpages = {6},
keywords = {AI Assistance, ChatGPT, Large Language Models, Learning Strategies, Learning Support Systems, Programming Education},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3652620.3687776,
author = {Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta and Scalera, Michele},
title = {Enhancing Software Modeling Learning with AI-Powered Scaffolding},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687776},
doi = {10.1145/3652620.3687776},
abstract = {This study introduces an innovative AI-powered scaffolding approach aimed at enhancing software modeling learning through UML diagrams. The focus of this research is on defining the principles and functions comprising the scaffolding. Leveraging recent advancements in generative AI, our approach provides a structured educational framework to improve comprehension and proficiency in modeling concepts. We present the initial implementation of the scaffolding, specifically highlighting the feedback function. By integrating theoretical insights with practical applications, this study seeks to advance Model-Driven Software Engineering education and underscores the potential of AI in enhancing instructional methodologies.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {103–106},
numpages = {4},
keywords = {generative AI, education, software modelling, model-driven software engineering, UML, scaffolding},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3630106.3658942,
author = {Rivera, Juan-Pablo and Mukobi, Gabriel and Reuel, Anka and Lamparth, Max and Smith, Chandler and Schneider, Jacquelyn},
title = {Escalation Risks from Language Models in Military and Diplomatic Decision-Making},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658942},
doi = {10.1145/3630106.3658942},
abstract = {Governments are increasingly considering integrating autonomous AI agents in high-stakes military and foreign-policy decision-making, especially with the emergence of advanced generative AI models like GPT-4. Our work aims to scrutinize the behavior of multiple AI agents in simulated wargames, specifically focusing on their predilection to take escalatory actions that may exacerbate multilateral conflicts. Drawing on political science and international relations literature about escalation dynamics, we design a novel wargame simulation and scoring framework to assess the escalation risks of actions taken by these agents in different scenarios. Contrary to prior studies, our research provides both qualitative and quantitative insights and focuses on large language models (LLMs). We find that all five studied off-the-shelf LLMs show forms of escalation and difficult-to-predict escalation patterns. We observe that models tend to develop arms-race dynamics, leading to greater conflict, and in rare cases, even to the deployment of nuclear weapons. Qualitatively, we also collect the models’ reported reasoning for chosen actions and observe worrying justifications based on deterrence and first-strike tactics. Given the high stakes of military and foreign-policy contexts, we recommend further examination and cautious consideration before deploying autonomous language model agents for strategic military or diplomatic decision-making.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {836–898},
numpages = {63},
keywords = {Evaluation, Language Model Agents, Military Applications, Multi-Agent Security, Natural Language Processing, Safety, Socio-Technical Impact},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3701268.3701274,
author = {Riello, Pasquale and Quille, Keith and Jaiswal, Rajesh and Sansone, Carlo},
title = {Reimagining Student Success Prediction: Applying LLMs in Educational AI with XAI},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701274},
doi = {10.1145/3701268.3701274},
abstract = {Since the conception of Large Language Models (LLMs), their areas of application have increased significantly over time. This is due to their nature of being able to perform natural language processing (NLP) tasks (like question answering, text generation, text summarization, text classification etc.), which gives them flexibility in a multitude of spaces, including in Educational AI (EdAI). Despite their incredible wide range of use, LLMs are typically applied to generative AI, from text to image generation.This paper aims to apply LLMs for a classification task in EdAI, by reproposing the original PreSS (Predicting Student Success) model which makes use of more traditional Machine Learning (ML) algorithms for predicting CS1 students at risk of failing or dropping out. There are two main goals for this work: the first is to identify the best and most accurate method to re-purpose LLMs for a classification task; the second is to explore and access the explainability of the model outputs. For the former we investigate different techniques for using LLMs like Few-Shot Prompting, Fine-Tuning and Transfer Learning using Gemma 2B as base model along with two different kind of prompting techniques. For the latter we focus on attention scores of LLMs transformers, aiming to understanding what are the most important features that the model considers for generating the response. The obtained results are then compared with the previous PreSS model to evaluate whether LLMs can outperform traditional ML algorithms: this paper finds that Na\"{\i}ve Bayes still outperforms all the others, once again confirmed as the best algorithm for predicting student success.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {34–40},
numpages = {7},
keywords = {Computer Science Education, Large Language Models, Explainability},
location = {
},
series = {HCAIep '24}
}

@inproceedings{10.1145/3689535.3689537,
author = {Stone, Irene},
title = {Investigating the Use of ChatGPT to Support the Learning of Python Programming Among Upper Secondary School Students: A Design-Based Research Study},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689537},
doi = {10.1145/3689535.3689537},
abstract = {This study investigates how ChatGPT can be used to support the learning of Python programming among upper second-level students in an Irish classroom. It addresses critical gaps in the literature, such as the lack of research at secondary level, the need for human-centered studies conducted over time, and the absence of guidelines for integrating ChatGPT into introductory programming education. Employing a design-based research methodology, this study aims to understand student engagement with ChatGPT and investigates how to support their use of prompts when learning to program. The research involves students as co-creators alongside their teacher, who is also the researcher, in developing a pedagogical framework that integrates ChatGPT into Python programming education.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {11},
numpages = {1},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, design-based research, generative AI, human-centered, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3632620.3671108,
author = {Pawagi, Mrigank and Kumar, Viraj},
title = {Probeable Problems for Beginner-level Programming-with-AI Contests},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671108},
doi = {10.1145/3632620.3671108},
abstract = {To broaden participation, competitive programming contests may include beginner-level problems that do not require knowledge of advanced Computer Science concepts (e.g., algorithms and data structures). However, since most participants have easy access to AI code-generation tools, these problems often become trivial to solve. For beginner-friendly programming contests that do not prohibit the use of AI tools, we propose Probeable Problems: code writing tasks that provide (1)&nbsp;a problem specification that deliberately omits certain details, and (2)&nbsp;a mechanism to probe for these details by asking clarifying questions and receiving immediate feedback. To evaluate our proposal, we conducted a 2-hour programming contest for undergraduate Computer Science students from multiple institutions, where each student was an active member of their institution’s ACM student chapter. The contest comprised of six Probeable Problems for which a popular code-generation tools (e.g., GitHub Copilot) were unable to generate accurate solutions due to the absence of details. Students were permitted to work individually or in groups, and were free to use AI tools. We obtained consent from 26&nbsp;groups (67&nbsp;students) to use their submissions for research. To determine whether Probeable Problems are suitable for such contests, we analyze the extent to which the code submitted by these groups identifies missing details.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {166–176},
numpages = {11},
keywords = {Ambiguity, CS1, Code specifications, Code writing},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.5555/3643142.3643420,
author = {Tolk, Andreas and Barry, Philip and Loper, Margaret L. and Rabadi, Ghaith and Scherer, William T. and Yilmaz, Levent},
title = {Chances and Challenges of Chatgpt and Similar Models for Education in M&amp;S},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally, the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3332–3346},
numpages = {15},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3626253.3635609,
author = {Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges},
title = {Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635609},
doi = {10.1145/3626253.3635609},
abstract = {Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1752–1753},
numpages = {2},
keywords = {discussion forum, educational tools, natural language processing},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635483,
author = {Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra},
title = {DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635483},
doi = {10.1145/3626253.3635483},
abstract = {Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1714–1715},
numpages = {2},
keywords = {ai in education, compiler error messages, cs1, error message enhancement, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653595,
author = {Cucuiat, Veronica and Waite, Jane},
title = {Feedback Literacy: Holistic Analysis of Secondary Educators' Views of LLM Explanations of Program Error Messages},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653595},
doi = {10.1145/3649217.3653595},
abstract = {The implications of using large language model (LLM) tools for learning to program at secondary school level are largely unknown, and yet there is pressure for teachers to engage with these. To start addressing this gap, we investigated: RQ1: What are secondary educators' views on the potential classroom use of LLM program error message explanations? RQ2: In what ways can a feedback literacy perspective support the analysis of educators' views of potential classroom use of LLM program error message explanations? The responses of eight expert secondary school educators were gathered during a semi-structured, activity-based interview and qualitatively analysed. Fifteen themes were derived from their commentary, of which ten corresponded to enhanced program error message (PEM) guidelines. Yet, all themes correlated to feedback literacy theory, providing a more holistic view. The analysis revealed that educators preferred LLM explanations to guide and develop understanding rather than tell, that students should be supported to make judgements and action LLM-generated feedback. Combining PEM guideline and feedback literacy findings, we suggest augmented IDEs should be designed with educators and students in mind, and teacher professional development (PD) is needed. Research is needed to compare our findings with a wider range of educators and investigate what feedback literacy means for resource design, PD, and classroom practice in secondary and undergraduate contexts.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {192–198},
numpages = {7},
keywords = {AI, IDE, K-12 education, ML, feedback literacy},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3613904.3642887,
author = {Chen, Liuqing and Jiang, Zhaojun and Xia, Duowei and Cai, Zebin and Sun, Lingyun and Childs, Peter and Zuo, Haoyu},
title = {BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642887},
doi = {10.1145/3613904.3642887},
abstract = {Bio-inspired design (BID) fosters innovations in engineering. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. Current BID education aims to enhance learners’ understanding and analogical reasoning skills. However, it often heavily relies on the teachers’ expertise. When learners pursue independent learning using some educational tools, they face challenges in understanding and reasoning practice within this multidisciplinary field. Additionally, evaluating their learning outcomes comprehensively becomes problematic. Addressing these challenges, we introduce a LLMs-driven BID education method based on a structured ontology and three strategies: enhancing understanding through LLMs-enpowered "learning by asking", assisting reasoning by providing hints and feedback, and assessing learning outcomes through benchmarking against existing BID cases. Implementing the method, we developed BIDTrainer, a BID education tool. User studies indicate that learners using BIDTrainer understood BID knowledge better, reason faster with higher interactivity than the baseline, and BIDTrainer assessed the learning outcomes consistent with experts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {676},
numpages = {20},
keywords = {Analogy training, Bio-inspired design, Design education, Design evaluation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3691620.3695062,
author = {Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Sun, Zian and Li, Ge and Li, Zhongqi and Ma, Yuchi},
title = {FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695062},
doi = {10.1145/3691620.3695062},
abstract = {Providing personalized and timely feedback for student's programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM's attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67\texttimes{} compared to the autoregressive decoding algorithm.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {669–680},
numpages = {12},
keywords = {automated program repair, large language models, programming education, inference acceleration},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3636555.3636882,
author = {Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga},
title = {Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636882},
doi = {10.1145/3636555.3636882},
abstract = {AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {821–827},
numpages = {7},
keywords = {Academic Integrity, Automated Grading, ChatGPT, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3701268.3701273,
author = {Conway, Brian and Nolan, Keith and Quille, Keith},
title = {HCAI Block Model: A competence model for Human Centred Artificial Intelligence at K-12},
year = {2024},
isbn = {9798400711596},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701268.3701273},
doi = {10.1145/3701268.3701273},
abstract = {Artificial Intelligence (AI) is becoming a common topic within the computing K-12 curricula worldwide. While much of the focus of research is on the use of Generative AI in and for education, AI as a core subject area is still gaining popularity, with much of this research focusing on content and tools that effectively support the teaching of AI. However, as we grow as a field, there is a need currently unmet to provide foundations (in the form of a block model as there exists for programming) to allow researchers to build strong pedagogies and methodologies from, and even a base to design activities and content. Compounding this, as ethics and its relationship to AI in the K-12 classroom grows stronger, there is a further need to provide scaffolding to educators and researchers not only on traditional AI concepts, but also on how they link with ethical knowledge, skills and dispositions. In this paper, the Human Centered Artificial Intelligence (HCAI) Block Model is developed and introduced. This is a competence-based model to guide effective teaching and learning of Human Centered Artificial Intelligence, as well as research in the K-12 space. The HCAI Block model’s foundation is developed/adapted from the programming Block model and has been adapted and developed using two lenses. The first was through the data science lens through interaction with Computational Thinking 2.0 and competency-based learning. The second lens was through a human-centred lens. The outcome was a ground-up K-12 model where traditional and technical AI concepts have been developed from the start, integrating ethical considerations and human-centred approaches.},
booktitle = {Proceedings of the 2024 Conference on Human Centred Artificial Intelligence - Education and Practice},
pages = {22–28},
numpages = {7},
keywords = {Computing Education, Machine Learning, Human-Centered AI, Block Model, Ethics, Computational Thinking 2.0},
location = {
},
series = {HCAIep '24}
}

@inproceedings{10.1145/3660043.3660191,
author = {Lian, Weichen and Xu, Juan},
title = {Exploration of Multi-round Dialogue Function of International Chinese Education Robot Based on LLM},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660191},
doi = {10.1145/3660043.3660191},
abstract = {In the process of international Chinese language education, issues such as the shortage of Chinese language teachers and insufficient input and output for Chinese learners are common. To enable learners to effectively engage in input and output activities based on their learning levels, this article attempts to integrate educational robot technology into the field of international Chinese education. Firstly, the article explains the form and function of robots; Then, based on the characteristics of robot technology, large language models, and multi-turn dialogue systems, it proposes the use of educational robots equipped with large language models specific to international Chinese education to assist learners. This research uses LangChain to connect a local Chinese resource library with a large language model, exploring the practical effects of educational robots equipped with this multi-turn dialogue function in international Chinese education, and compares it with the dialogue effects of general large language models. Finally, the article concludes with a summary and future outlook.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {833–838},
numpages = {6},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3639478.3641226,
author = {Ibrahimzada, Ali Reza},
title = {Program Decomposition and Translation with Static Analysis},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3641226},
doi = {10.1145/3639478.3641226},
abstract = {The rising popularity of Large Language Models (LLMs) has motivated exploring their use in code-related tasks. Code LLMs with more than millions of parameters are trained on a massive amount of code in different Programming Languages (PLs). Such models are used for automating various Software Engineering (SE) tasks using prompt engineering. However, given the very large size of industry-scale project files, a major issue of these LLMs is their limited context window size, motivating the question of "Can these LLMs process very large files and can we effectively perform prompt engineering?". Code translation aims to convert source code from one PL to another. In this work, we assess the effect of method-level program decomposition on context window of LLMs and investigate how this approach can enable translation of very large files which originally could not be done due to out-of-context issue. Our observations from 20 well-known java projects and approximately 60K methods suggest that method-level program decomposition significantly improves the limited context window problem of LLMs by 99.5%. Furthermore, our empirical analysis indicate that with method-level decomposition, each input fragment on average only consumes 5% of the context window, leaving more context space for prompt engineering and the output. Finally, we investigate the effectiveness of a Call Graph (CG) approach for translating very large files when doing method-level program decomposition.},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {453–455},
numpages = {3},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3613904.3642135,
author = {Wester, Joel and Schrills, Tim and Pohl, Henning and van Berkel, Niels},
title = {“As an AI language model, I cannot”: Investigating LLM Denials of User Requests},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642135},
doi = {10.1145/3613904.3642135},
abstract = {Users ask large language models (LLMs) to help with their homework, for lifestyle advice, or for support in making challenging decisions. Yet LLMs are often unable to fulfil these requests, either as a result of their technical inabilities or policies restricting their responses. To investigate the effect of LLMs denying user requests, we evaluate participants’ perceptions of different denial styles. We compare specific denial styles (baseline, factual, diverting, and opinionated) across two studies, respectively focusing on LLM’s technical limitations and their social policy restrictions. Our results indicate significant differences in users’ perceptions of the denials between the denial styles. The baseline denial, which provided participants with brief denials without any motivation, was rated significantly higher on frustration and significantly lower on usefulness, appropriateness, and relevance. In contrast, we found that participants generally appreciated the diverting denial style. We provide design recommendations for LLM denials that better meet peoples’ denial expectations.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {979},
numpages = {14},
keywords = {Breakdowns, Denials, Errors, GPT-4, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@article{10.1145/3649850,
author = {Zhang, Jialu and Cambronero, Jos\'{e} Pablo and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
title = {PyDex: Repairing Bugs in Introductory Python Assignments using LLMs},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649850},
doi = {10.1145/3649850},
abstract = {Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system -- PyDex -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {133},
numpages = {25},
keywords = {AI for programming education, automated program repair, large language models}
}

@inproceedings{10.1145/3571884.3604310,
author = {Mannekote, Amogh and Celepkolu, Mehmet and Wiggins, Joseph B. and Boyer, Kristy Elizabeth},
title = {Exploring Usability Issues in Instruction-Based and Schema-Based Authoring of Task-Oriented Dialogue Agents},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3604310},
doi = {10.1145/3571884.3604310},
abstract = {Platforms such as Google DialogFlow and Amazon Lex have enabled easier development of conversational agents. The standard approach to training these agents involve collecting and annotating in-domain data in the form of labelled utterances. However, obtaining in-domain data for training machine learning models remains a bottleneck. Schema-based dialogue, which involves laying out a structured representation of the flow of a “typical” dialogue, and prompt-based methods, which involve writing instructions in natural language to large language models such as GPT-3, are promising ways to tackle this problem. However, usability issues when translating these methods into practice are less explored. Our study takes a first step towards addressing this gap by having 23 students who had finished a graduate-level course on spoken dialogue systems report their experiences as they defined structured schemas and composed instruction-based prompts for two task-oriented dialogue scenarios. Through inductive coding and subsequent thematic analysis of the survey data, we explored users’ authoring experiences with schema and prompt-based methods. The findings provide insights for future data collection and authoring tool design for dialogue systems.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {41},
numpages = {6},
keywords = {dialogue systems, schema-based dialogue, user studies;, zero-shot prompting},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@inproceedings{10.1145/3587103.3594155,
author = {Wermelinger, Michel},
title = {Checking Conformance to a Subset of the Python Language},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594155},
doi = {10.1145/3587103.3594155},
abstract = {Introductory courses usually only teach a small subset of a programming language and its library, in order to focus on the general concepts rather than overwhelm students with the syntactic, semantic and API minutiae of a particular language.This paper presents courseware that checks if a program only uses the subset of the Python language and library defined by the instructor. This allows to automatically check that programming examples, exercises and assessments only use the taught constructs. It also helps detect student code with advanced constructs, possibly copied from Q&amp;A sites or generated by large language models.The tool is easy to install, configure and use. It also checks Python code in Jupyter notebooks, a popular format for interactive textbooks and assessment handouts.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {573–574},
numpages = {2},
keywords = {academic integrity, code checking, introductory programming, novice programming, programming exercises},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.5555/3722479.3722490,
author = {Wills, Tyler and Burgan, Cara and Guzide, Osman and Liao, Weidong},
title = {Building a Voice-Activated RAG Chatbot with Generative AI and LLMs},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {We have developed a voice-controlled Retrieval-Augmented Generation (RAG) chatbot application at Shepherd University that utilizes Generative AI and Large Language Models (LLMs) to transform how students interact with their student handbook. This application combines cutting-edge natural language processing and voice recognition technologies to create a more dynamic and user-friendly experience. The chatbot leverages LLMs to understand and respond to diverse queries, delivering detailed, contextually appropriate responses directly sourced from the handbook. The RAG methodology ensures responses are not only generated by the AI but also precisely retrieved from relevant handbook sections, preserving response integrity and accuracy.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {35–36},
numpages = {2}
}

@inproceedings{10.1145/3649217.3653621,
author = {Margulieux, Lauren E. and Prather, James and Reeves, Brent N. and Becker, Brett A. and Cetin Uzun, Gozde and Loksa, Dastyni and Leinonen, Juho and Denny, Paul},
title = {Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653621},
doi = {10.1145/3649217.3653621},
abstract = {We explored how undergraduate introductory programming students naturalistically used generative AI to solve programming problems. We focused on the relationship between their use of AI to their self-regulation strategies, self-efficacy, and fear of failure in programming. In this repeated-measures, mixed-methods research, we examined students' patterns of using generative AI with qualitative student reflections and their self-regulation, self-efficacy, and fear of failure with quantitative instruments at multiple times throughout the semester. We also explored the relationships among these variables to learner characteristics, perceived usefulness of AI, and performance. Overall, our results suggest that student factors affect their baseline use of AI. In particular, students with higher self-efficacy, lower fear of failure, or higher prior grades tended to use AI less or later in the problem-solving process and rated it as less useful than others. Interestingly, we found no relationship between students' self-regulation strategies and their use of AI. Students who used AI less or later in problem-solving also had higher grades in the course, but this is most likely due to prior characteristics as our data do not suggest that this is a causal relationship.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {276–282},
numpages = {7},
keywords = {CS1, LLMs, artificial intelligence, copilot, fear of failure, generative ai, introductory programming, large language models, metacognition, self-efficacy, self-regulated learning, self-regulation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3611643.3613891,
author = {Jin, Pengxiang and Zhang, Shenglin and Ma, Minghua and Li, Haozhe and Kang, Yu and Li, Liqun and Liu, Yudong and Qiao, Bo and Zhang, Chaoyun and Zhao, Pu and He, Shilin and Sarro, Federica and Dang, Yingnong and Rajmohan, Saravan and Lin, Qingwei and Zhang, Dongmei},
title = {Assess and Summarize: Improve Outage Understanding with Large Language Models},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613891},
doi = {10.1145/3611643.3613891},
abstract = {Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers with in-depth domain knowledge, have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging fine-tuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1657–1668},
numpages = {12},
keywords = {Cloud Systems, Large Language Model, Outage Understanding},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{10.1145/3657604.3664685,
author = {Jiang, Lan and Bosch, Nigel},
title = {Short answer scoring with GPT-4},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664685},
doi = {10.1145/3657604.3664685},
abstract = {Automatic short-answer scoring is a long-standing research problem in education. However, assessing short answers at human-level accuracy requires a deep understanding of natural language. Given the notable abilities of recent generative pre-trained transformer (GPT) models, we investigate gpt-4-1106-preview to automatically score student responses from the Automated Student Assessment Prize Short Answer Scoring dataset. We systematically varied information given to the model including possible correct answers and scoring examples, as well as the order of sub-tasks within short answer scoring (e.g., assigning a score vs. generating a rationale for an assigned score) to understand what affects short answer scoring. With the best configuration, GPT-4 yielded a quadratic weighted kappa of .677 across 10 questions. However, we observe that the performance differs across educational subjects (e.g., biology, English), the quality of scoring rubrics might affect the predictions, and the overall utility of rationales generated to explain scores is uncertain.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {438–442},
numpages = {5},
keywords = {gpt (generative pre-trained transformer), short answer scoring, text classification},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3699538.3699556,
author = {Birillo, Anastasiia and Artser, Elizaveta and Potriasaeva, Anna and Vlasov, Ilya and Dzialets, Katsiaryna and Golubev, Yaroslav and Gerasimov, Igor and Keuning, Hieke and Bryksin, Timofey},
title = {One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699556},
doi = {10.1145/3699538.3699556},
abstract = {Students often struggle with solving programming problems when learning to code, especially when they have to do it online, with one of the most common disadvantages of working online being the lack of personalized help. This help can be provided as next-step hint generation, i.e., showing a student what specific small step they need to do next to get to the correct solution. There are many ways to generate such hints, with large language models (LLMs) being among the most actively studied right now. While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality. In this work, we utilize this idea and propose a novel system to provide both textual and code hints for programming tasks. The pipeline of the proposed approach uses a chain-of-thought prompting technique and consists of three distinct steps: (1) generating subgoals — a list of actions to proceed with the task from the current student’s solution, (2) generating the code to achieve the next subgoal, and (3) generating the text to describe this needed action. During the second step, we apply static analysis to the generated code to control its size and quality. The tool is implemented as a modification to the open-source JetBrains Academy plugin, supporting students in their in-IDE courses. To evaluate our approach, we propose a list of criteria for all steps in our pipeline and conduct two rounds of expert validation. Finally, we evaluate the next-step hints in a classroom with 14 students from two universities. Our results show that both forms of the hints — textual and code — were helpful for the students, and the proposed system helped them to proceed with the coding tasks.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {9},
numpages = {12},
keywords = {Programming Education, in-IDE learning, LLMs, Generative AI, Next-Step Hints},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3637528.3671620,
author = {Lai, Hanyu and Liu, Xiao and Iong, Iat Long and Yao, Shuntian and Chen, Yuxuan and Shen, Pengbo and Yu, Hao and Zhang, Hanchen and Zhang, Xiaohan and Dong, Yuxiao and Tang, Jie},
title = {AutoWebGLM: A Large Language Model-based Web Navigating Agent},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671620},
doi = {10.1145/3637528.3671620},
abstract = {Large language models (LLMs) have fueled many intelligent web agents, but most existing ones perform far from satisfying in real-world web navigation tasks due to three factors: (1) the complexity of HTML text data (2) versatility of actions on webpages, and (3) task difficulty due to the open-domain nature of the web. In light of these challenges, we develop the open AutoWebGLM based on ChatGLM3-6B. AutoWebGLM can serve as a powerful automated web navigation agent that outperform GPT-4. Inspired by human browsing patterns, we first design an HTML simplification algorithm to represent webpages with vital information preserved succinctly. We then employ a hybrid human-AI method to build web browsing data for curriculum training. Finally, we bootstrap the model by reinforcement learning and rejection sampling to further facilitate webpage comprehension, browser operations, and efficient task decomposition by itself. For comprehensive evaluation, we establish a bilingual benchmark---AutoWebBench---for real-world web navigation tasks. We evaluate AutoWebGLM across diverse web navigation benchmarks, demonstrating its potential to tackle challenging tasks in real environments. Related code, model, and data are released at https://github.com/THUDM/AutoWebGLM.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5295–5306},
numpages = {12},
keywords = {chatglm, large language model, llm agent, reinforcement learning, rejection sampling finetuning, web agent},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1109/ASE56229.2023.00217,
author = {Dipongkor, Atish Kumar and Moran, Kevin},
title = {A Comparative Study of Transformer-Based Neural Text Representation Techniques on Bug Triaging},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00217},
doi = {10.1109/ASE56229.2023.00217},
abstract = {Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood.Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1012–1023},
numpages = {12},
keywords = {bug triaging, transformer, llms, text-embedding, DL4SE},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3677388.3696321,
author = {Li, Danrui and Sohn, Samuel S. and Zhang, Sen and Chang, Che-Jui and Kapadia, Mubbasir},
title = {From Words to Worlds: Transforming One-line Prompts into Multi-modal Digital Stories with LLM Agents},
year = {2024},
isbn = {9798400710902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677388.3696321},
doi = {10.1145/3677388.3696321},
abstract = {Digital storytelling, essential in entertainment, education, and marketing, faces challenges in generation efficiency. The StoryAgent framework, introduced in this paper, utilizes Large Language Models and generative tools to automate and refine digital storytelling. Employing a top-down story drafting and bottom-up asset generation approach, StoryAgent tackles key issues such as manual intervention, interactive scene orchestration, and narrative consistency. This framework enables efficient production of interactive and consistent digital storytellings across multiple modalities, democratizing content creation and enhancing engagement.},
booktitle = {Proceedings of the 17th ACM SIGGRAPH Conference on Motion, Interaction, and Games},
articleno = {21},
numpages = {12},
keywords = {Communicative Agents, Digital storytelling, Large Language Models},
location = {Arlington, VA, USA},
series = {MIG '24}
}

@inproceedings{10.1145/3613905.3650770,
author = {Chin, Jenna H and Lee, Seungwook and Ashraf, Mohsena and Zago, Matt and Xie, Yun and Wolfgram, Elizabeth A and Yeh, Tom and Kim, Pilyoung},
title = {Young Children's Creative Storytelling with ChatGPT vs. Parent: Comparing Interactive Styles},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650770},
doi = {10.1145/3613905.3650770},
abstract = {Creative storytelling with parents plays an important role in child development including language skills, social competence, and emotional understanding. Recognizing the challenges parents face in finding time for storytelling due to work and home responsibilities, we explore the feasibility of ChatGPT for engaging children in creative storytelling. This study investigates the use of ChatGPT, a conversational agent powered by GPT-4, in creative storytelling with children aged 5-6, comparing its interaction styles with those of parents. The current study included eight child-parent dyads. We found that children were engaged in shorter and more frequent interactions with parents compared to ChatGPT. ChatGPT and parents asked different types of questions, and ChatGPT more frequently provided positive feedback compared to parents. More children selected the interactions with ChatGPT as their favorite interactions. The study provides preliminary evidence on ChatGPT's interaction styles and insights into its potential role in supporting families in creative storytelling activities.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {379},
numpages = {7},
keywords = {ChatGPT, Children, Parents, Storytelling},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3478432.3499265,
author = {Koornneef, Stacey A. and Bradbury, Jeremy S. and Miljanovic, Michael A.},
title = {Run, Llama, Run: A Collaborative Physical and Online Coding Game for Children},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499265},
doi = {10.1145/3478432.3499265},
abstract = {Computational thinking and computer science are now being introduced in K-5 classrooms and this has led to a demand for more engaging and interactive tools designed for a younger audience. Educational games and block-based programming are two approaches that have been shown to be effective at engaging children to learn computer science. While existing tools have value, they also have limitations with respect to their support for collaborative learning and with respect to equitable access. Run, Llama, Run, is a collaborative educational game designed to be played by K-5 students both with and without access to a tablet or computer. The game includes physical programming blocks where a group of students work together to find a solution for a given scenario. A digital interface is available to execute and animate student solutions and a non-digital alternative allows students to act out their solutions. This demo of Run, Llama, Run provides a chance for participants to play both versions of the game and observe the potential impact this game could have for students.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1177},
numpages = {1},
keywords = {collaborative learning, educational game, k-5 computer science education},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@inproceedings{10.1145/3605507.3610629,
author = {Gehringer, Edward F. and Wang, Jianxun George and Jilla, Sharan Kumar},
title = {Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs},
year = {2024},
isbn = {9798400702532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605507.3610629},
doi = {10.1145/3605507.3610629},
abstract = {The traditional model of assigning textbook problems for homework is endangered by the ability of students to find answers to almost any published problem on the web. An alternative is a dual-submission approach, where students submit their work, then receive the solutions, and submit a second metacognitive reflection, explaining any errors they made. Students’ scores can depend on the quality of their second submissions alone or the combined quality of their first and second submissions. We tried this approach in a class on parallel computer architecture. We report students’ personal experience based on their questionnaires responses. In addition, we quantitatively compare students’ performance on test questions related to dual-submission homework against their performance on other questions and previous semesters’ student performance on similar questions. Students overwhelmingly preferred this approach and thought they learned more from it, but evidence about whether it improved their learning was inconclusive. We also analyze the continued viability of this approach in the era of large language models.},
booktitle = {Proceedings of the Workshop on Computer Architecture Education},
pages = {41–47},
numpages = {7},
location = {Orlando, FL, USA},
series = {WCAE '23}
}

@inproceedings{10.1145/3631802.3631807,
author = {Jeuring, Johan and Groot, Roel and Keuning, Hieke},
title = {What Skills Do You Need When Developing Software Using ChatGPT? (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631807},
doi = {10.1145/3631802.3631807},
abstract = {Since the release of LLM-based tools such as GitHub Copilot and ChatGPT the media and popular scientific literature, but also journals such as the Communications of the ACM, have been flooded with opinions how these tools will change programming. The opinions range from “machines will program themselves”, to “AI does not help programmers”. Of course, these statements are meant to to stir up a discussion, and should be taken with a grain of salt, but we argue that such unfounded statements are potentially harmful. Instead, we propose to investigate which skills are required to develop software using LLM-based tools. In this paper we report on an experiment in which we explore if Computational Thinking (CT) skills predict the ability to develop software using LLM-based tools. Our results show that the ability to develop software using LLM-based tools can indeed be predicted by the score on a CT assessment. There are many limitations to our experiment, and this paper is also a call to discuss how to approach, preferably experimentally, the question of which skills are required to develop software using LLM-based tools. We propose to rephrase this question to include by what kind of people/programmers, to develop what kind of software using what kind of LLM-based tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {38},
numpages = {6},
keywords = {ChatGPT, Computational thinking skills, LLM-based tools, Software development skills},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3691620.3695318,
author = {Lops, Andrea and Narducci, Fedelucio and Ragone, Azzurra and Trizio, Michelantonio},
title = {AgoneTest: Automated creation and assessment of Unit tests leveraging Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695318},
doi = {10.1145/3691620.3695318},
abstract = {Software correctness is crucial, with unit testing playing an indispensable role in the software development lifecycle. However, creating unit tests is time-consuming and costly, underlining the need for automation. Leveraging Large Language Models (LLMs) for unit test generation is a promising solution, but existing studies focus on simple, small-scale scenarios, leaving a gap in understanding LLMs' performance in real-world applications, particularly regarding integration and assessment efficacy at scale. Here, we present AgoneTest, a system focused on automatically generating and evaluating complex class-level test suites. Our contributions include a scalable automated system, a newly developed dataset for rigorous evaluation, and a detailed methodology for test quality assessment.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2440–2441},
numpages = {2},
keywords = {software testing, large language model, automatic assessment},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3649217.3653557,
author = {Farinetti, Laura and Canale, Lorenzo},
title = {Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653557},
doi = {10.1145/3649217.3653557},
abstract = {Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {401–407},
numpages = {7},
keywords = {chatbot development, creativity and critical thinking, database education, information retrieval, langchain framework, large language models, natural language interfaces},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649921.3659840,
author = {Normoyle, Aline and J\"{o}rg, Sophie and Hill, Jennifer},
title = {The Curation Tree: A Lightweight Behavior Tree Framework for Implementing Puzzle and Narrative Games},
year = {2024},
isbn = {9798400709555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649921.3659840},
doi = {10.1145/3649921.3659840},
abstract = {In this work, we describe the Curation Tree framework that has matured as part of our game-based research and teaching. We use this framework to manage the top-level experience of our players via a text-based, authorable behavior tree system that is easy to implement, test, and re-use. We present three case studies based on Unity games built within our framework: the first involves virtual reality games involving grasping objects with the hands; the second, Treatment X, uses the framework to implement a causal learning game; and the last involves narrative games based on a large language model. Based on our experiences with this system, we reflect on its limitations and make several recommendations based on its strengths, namely to centralize game logic with behaviors, to centralize user event handling, to prefer simple behaviors over complex ones, to use text-based scripts for authoring with version control, and to separate behaviors from persistent state.},
booktitle = {Proceedings of the 19th International Conference on the Foundations of Digital Games},
articleno = {63},
numpages = {4},
keywords = {behavior trees, software engineering, video game development},
location = {Worcester, MA, USA},
series = {FDG '24}
}

@inproceedings{10.1145/3626252.3630958,
author = {Cambaz, Doga and Zhang, Xiaoling},
title = {Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630958},
doi = {10.1145/3626252.3630958},
abstract = {The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {artificial intelligence in education, code generation models, large language models, programming education, systematic review},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3610969.3610973,
author = {Addo, Salomey Afua},
title = {Are You Ready to Teach AI in Schools? Teachers' Perspectives of Teaching AI in K-12 Settings},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610973},
doi = {10.1145/3610969.3610973},
abstract = {Artificial intelligence (AI) has continually made headlines, even more so with the mass interest in generative AI. The implications of AI on society raises the need for its inclusion in the K-12 computing curriculum. However, little research has been conducted to understand teachers’ preparedness to teach AI concepts in K-12. This exploratory study seeks to understand teachers’ motivation and preparedness to teach AI in schools through the lens of Self Efficacy Theory (SET) and Self Determination Theory (SDT).},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {32},
numpages = {1},
keywords = {Artificial intelligence, K-12 computing education, motivation},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3613905.3651043,
author = {Zhang, Xishuo and Liu, Lin and Wang, Yi and Liu, Xiao and Wang, Hailong and Arora, Chetan and Liu, Haichao and Wang, Weijia and Hoang, Thuong},
title = {Auto-Generated Personas: Enhancing User-centered Design Practices among University Students},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651043},
doi = {10.1145/3613905.3651043},
abstract = {Personas are commonly used in User-centered Design (UCD) activities to help designers better understand users’ needs. However, there is still a reliance on traditional approaches such as interviews and ethnography for building personas in UCD activities. To this end, we developed an auto-generating persona system to enhance practices in UCD course activities. Our persona system is developed based on the GPT-4 model, the DALL-E 2 model, and knowledge graphs. Hence, our persona system includes three main features of our persona system: automated processing of survey data, automatic generation of 2D avatars, and providing options for automatic or customized entity generation. We recruited a total of 22 participants to evaluate our persona system. Our findings confirmed that there was a significant difference in terms of efficiency, satisfaction, accuracy, and diversity. Meanwhile, participants provided both positive and negative feedback regarding our persona system. As on-going work, we discuss the current limitations of our persona system and explore future research directions to further improve its capabilities and effectiveness.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {7},
keywords = {GPT-4, Knowledge Graphs, Personas, User Studies},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3605468.3609775,
author = {Philbin, Carrie Anne},
title = {Impact of Generative AI on K-12 Students’ Perceptions of Computing: A Research Proposal},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3609775},
doi = {10.1145/3605468.3609775},
abstract = {The rapid progress of generative artificial intelligence (AI) is fundamentally reshaping traditional perspectives on knowledge and skills, with profound implications for computing education. This necessitates a thorough examination of the relevance and timeliness of computing as a subject, especially for K-12 students who are making critical decisions about their future qualifications. This abstract proposes an empirical research study that aims to explore the effects of integrating generative AI in the creation of digital artefacts on K-12 students’ perceptions of the value of computing, as well as their understanding of ownership and achievement. Constructive discussions regarding the outlined approach are encouraged.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {28},
numpages = {2},
keywords = {Artificial Intelligence education, Creative computing, Generative AI, K-12 education, Student perceptions},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3596671.3598574,
author = {Goel, Toshali and Shaer, Orit and Delcourt, Catherine and Gu, Quan and Cooper, Angel},
title = {Preparing Future Designers for Human-AI Collaboration in Persona Creation},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596671.3598574},
doi = {10.1145/3596671.3598574},
abstract = {This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.},
booktitle = {Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {4},
numpages = {14},
keywords = {education, human-AI collaboration, large language models, natural-language generation, novice designers, personas},
location = {Oldenburg, Germany},
series = {CHIWORK '23}
}

@inproceedings{10.1145/3654777.3676347,
author = {Tang, Xiaohang and Wong, Sam and Pu, Kevin and Chen, Xi and Yang, Yalong and Chen, Yan},
title = {VizGroup: An AI-assisted Event-driven System for Collaborative Programming Learning Analytics},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676347},
doi = {10.1145/3654777.3676347},
abstract = {Programming instructors often conduct collaborative learning activities, like Peer Instruction, to foster a deeper understanding in students and enhance their engagement with learning. These activities, however, may not always yield productive outcomes due to the diversity of student mental models and their ineffective collaboration. In this work, we introduce VizGroup, an AI-assisted system that enables programming instructors to easily oversee students’ real-time collaborative learning behaviors during large programming courses. VizGroup leverages Large Language Models (LLMs) to recommend event specifications for instructors so that they can simultaneously track and receive alerts about key correlation patterns between various collaboration metrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors in a comparison study using a dataset collected from a Peer Instruction activity that was conducted in a large programming lecture. The results showed that VizGroup helped instructors effectively overview, narrow down, and track nuances throughout students’ behaviors.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {93},
numpages = {22},
keywords = {Collaborative Learning, Programming Education},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3691620.3695322,
author = {Luo, Yang and Yu, Richard and Zhang, Fajun and Liang, Ling and Xiong, Yongqiang},
title = {Bridging Gaps in LLM Code Translation: Reducing Errors with Call Graphs and Bridged Debuggers},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695322},
doi = {10.1145/3691620.3695322},
abstract = {When using large language models (LLMs) for code translation of complex software, numerous compilation and runtime errors can occur due to insufficient context awareness. To address this issue, this paper presents a code translation method based on call graphs and bridged debuggers: TransGraph. TransGraph first obtains the call graph of the entire code project using the Language Server Protocol, which provides a detailed description of the function call relationships in the program. Through this structured view of the code, LLMs can more effectively handle large-scale and complex codebases, significantly reducing compilation errors. Furthermore, TransGraph, combined with bridged debuggers and dynamic test case generation, significantly reduces runtime errors, overcoming the limitations of insufficient test case coverage in traditional methods. In experiments on six datasets including CodeNet and Avatar, TransGraph outperformed existing code translation methods and LLMs in terms of translation accuracy, with improvements of up to 10.2%.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2448–2449},
numpages = {2},
keywords = {code translation, large language model, call graph, bridged debugger, language server protocol, runtime error, compilation error},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3626253.3635414,
author = {Fox, Alexander and Stoner, Joshua and Wang, Jingwen},
title = {Revolutionizing Student Engagement and Enrollment through Personalized, AI-Driven Dialog Systems in Higher Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635414},
doi = {10.1145/3626253.3635414},
abstract = {In this era of digital transformation, approaches for enhancing student engagement and enrollment are critical for higher education institutions. This study introduces AcademiBot, a novel AI-driven college dialog system designed to provide personalized assistance to students and serve as a strategic marketing tool for higher institutions. AcademiBot leverages advanced Large Language Models (LLMs) and customized datasets to revolutionize colleges-students interactions by offering accurate, human-like responses to students' inquiries. The system employs two interfaces: AcademiBot-Web, a web-based GUI, and AcademiBot-VR, an immersive virtual reality environment. This dual-interface approach caters to address various user preferences, ensuring a versatile and captivating user experience. The evaluation results demonstrate AcademiBot's effectiveness in providing timely and accurate information, significantly improving user interaction in a digital context.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1879},
numpages = {1},
keywords = {dialog system, higher education, large language models, virtual reality},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3658644.3670392,
author = {Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo},
title = {On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670392},
doi = {10.1145/3658644.3670392},
abstract = {With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2236–2250},
numpages = {15},
keywords = {aigc detection, large language models, responsible ai},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3649405.3659514,
author = {Quille, Keith and Becker, Brett A. and Faherty, Roisin and Gordon, Damien and Harte, Miriam and Hensman, Svetlana and Hofmann, Markus and Nolan, Keith and O'Leary, Ciaran},
title = {LLMs in Open and Closed Book Examinations in a Final Year Applied Machine Learning Course (Early Findings)},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659514},
doi = {10.1145/3649405.3659514},
abstract = {This research has three prongs, with each comparing open- and closed-book exam questions across six years (2017-2023) in a final year undergraduate applied machine learning course. First, the authors evaluated the performance of numerous LLMs, compared to student performance, and comparing open and closed book exams. Second, at a micro level, the examination questions and categories for which LLMs were most and least effective were compared. This level of analysis is rarely if ever, discussed in the literature. The research finally investigates LLM detection techniques, specifically their efficacy in identifying replies created wholly by an LLM. It considers both raw LLM outputs and LLM outputs that have been tampered with by students, with an emphasis on academic integrity. This study is a staff-student research collaboration, featuring contributions from eight academic professionals and six students.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {822},
numpages = {1},
keywords = {ai, assessment, detection, large language models, llms, ml},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3580305.3599827,
author = {Drori, Iddo and Zhang, Sarah J. and Shuttleworth, Reece and Zhang, Sarah and Tyser, Keith and Chin, Zad and Lantigua, Pedro and Surbehera, Saisamrit and Hunter, Gregory and Austin, Derek and Tang, Leonard and Hicke, Yann and Simhon, Sage and Karnik, Sathwik and Granberry, Darnell and Udell, Madeleine},
title = {From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599827},
doi = {10.1145/3580305.3599827},
abstract = {A final exam in machine learning at a top institution such as MIT, Harvard, or Cornell typically takes faculty days to write, and students hours to solve. We demonstrate that large language models pass machine learning finals at a human level on finals available online and automatically generate new human-quality final exam questions in seconds. Previous work has developed program synthesis and few-shot learning methods to solve university-level problem set questions in mathematics and STEM courses. In this work, we develop and compare methods that solve final exams, which differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We curate a dataset and benchmark of questions from machine learning final exams available online and code for answering these questions and generating new questions. We show how to generate new questions from other questions and course notes. For reproducibility and future research on this final exam benchmark, we use automatic checkers for multiple-choice, numeric, and questions with expression answers. A student survey comparing the quality, appropriateness, and difficulty of machine-generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated questions and are suitable for final exams. We perform ablation studies comparing zero-shot learning with few-shot learning and chain-of-thought prompting using GPT-3, OPT, Codex, and ChatGPT across machine learning topics and find that few-shot learning methods perform best. We highlight the transformative potential of language models to streamline the writing and solution of large-scale assessments, significantly reducing the workload from human days to mere machine seconds. Our results suggest that rather than banning large language models such as ChatGPT in class, instructors should teach students to harness them by asking students meta-questions about correctness, completeness, and originality of the responses generated, encouraging critical thinking in academic studies.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3947–3955},
numpages = {9},
keywords = {few-shot learning, large language models, machine learning, program synthesis, quantitative reasoning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3678610.3678631,
author = {Robledo-Rella, V\'{\i}ctor and Toh, Bee-Yen},
title = {Artificial Intelligence in Physics Courses to Support Active Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678631},
doi = {10.1145/3678610.3678631},
abstract = {The integration of generative artificial intelligence (AI), particularly Large Language Models (LLMs) like OpenAI's ChatGPT and Microsoft's Copilot, is transforming educational methodologies, including undergraduate physics courses for engineering students. Despite their potential, these LLMs typically rely on statistical learning methods and often exhibit algebraic inaccuracies in solving standard university-level physics problems. This study explores the use of LLMs in physics courses for N = 91 freshman engineering students over two academic terms (Spring and Fall 2023). Students engaged in AI-assisted activities to solve physics problems and were asked to identify and correct the errors made by the chatbot. The outcomes were compared with those from traditional teaching methods without AI involvement, and no significant difference in student learning gains was found. To assess the impact of AI tools in education, a more detailed approach using pre-test and post-test instruments&nbsp;with control and experimental groups is necessary. Survey results revealed, however, that AI-assisted sessions enhanced student engagement, problem-solving skills, and understanding of physics concepts. Students also indicated a strong preference for AI-assisted activities, citing increased motivation and a firm belief in the educational benefits of using these tools. Our findings suggest that well-designed AI interventions can effectively complement traditional instructional methods, especially when the LLMs are integrated with symbolic computational tools like WolframAlpha to improve their accuracy.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {68–75},
numpages = {8},
keywords = {ChatGPT, Copilot, Educational Innovation, Generative AI, Higher Education, Interactive Learning, Physics Education Research},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3613904.3642459,
author = {Sharma, Nikhil and Liao, Q. Vera and Xiao, Ziang},
title = {Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642459},
doi = {10.1145/3613904.3642459},
abstract = {Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers—limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user’s view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implications for the development of LLMs and conversational search systems, and the policy governing these technologies.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1033},
numpages = {17},
keywords = {Confirmation Bias, Conversational Search, Echo Chamber Effect, Generative AI, Information Diversity, Information Seeking, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3587102.3588827,
author = {Malinka, Kamil and Peres\'{\i}ni, Martin and Firc, Anton and Hujn\'{a}k, Ondrej and Janus, Filip},
title = {On the Educational Impact of ChatGPT: Is Artificial Intelligence Ready to Obtain a University Degree?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588827},
doi = {10.1145/3587102.3588827},
abstract = {In late 2022, OpenAI released a new version of ChatGPT, a sophisticated natural language processing system capable of holding natural conversations while preserving and responding to the context of the discussion. ChatGPT has exceeded expectations in its abilities, leading to extensive considerations of its potential applications and misuse. In this work, we evaluate the influence of ChatGPT on university education, with a primary focus on computer security-oriented specialization. We gather data regarding the effectiveness and usability of this tool for completing exams, programming assignments, and term papers. We evaluate multiple levels of tool misuse, ranging from utilizing it as a consultant to simply copying its outputs. While we demonstrate how easily ChatGPT can be used to cheat, we also discuss the potentially significant benefits to the educational system. For instance, it might be used as an aid (assistant) to discuss problems encountered while solving an assignment or to speed up the learning process. Ultimately, we discuss how computer science higher education should adapt to tools like ChatGPT.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {47–53},
numpages = {7},
keywords = {ChatGPT, academic education, artificial intelligence, computer security, virtual assistant},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3626252.3630875,
author = {Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki},
title = {Improved Program Repair Methods using Refactoring with GPT Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630875},
doi = {10.1145/3626252.3630875},
abstract = {Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {569–575},
numpages = {7},
keywords = {generative ai, program repair, programming assignment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3717781.3717788,
author = {Works, Karen E.},
title = {Three Phase - Adversarial Search - Tile Games},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {With the advent of chatGPT and Copilot I find that students are not delving deep enough into the implementation of search approaches. To combat this, I decided to implement a three-phase adversarial search project. After lectures on adversarial search approaches and implementation examples, students are given code to a user versus user basic tile game. They are informed of the three phases of the assignment with the goal of encouraging students to understand that they are expected to be able to read and understand an adversarial search logic. In the first phase, all students use the user versus user basic tile game to implement a computer versus user basic tile game app that utilizes an adversarial search. In the second phase, students create and implement their own computer versus user basic tile game app by changing the rules on how the tile game is won and what a valid move is. In the third phase, students are given a timed 10 minute quiz where they are given code for a tile game and the rules for how the game is won and valid moves. The students must identify if the adversarial search is properly implemented and if not then what logic is not correct.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {29–32},
numpages = {4}
}

@inproceedings{10.1145/3660650.3660673,
author = {Rajabi, Parsa and Kerslake, Chris},
title = {Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660673},
doi = {10.1145/3660650.3660673},
abstract = {In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {23},
numpages = {2},
keywords = {AI Literacy, AI in Education, AI-usage Policy, ChatGPT, Generative AI, Technical Writing},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3544548.3580919,
author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
title = {Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580919},
doi = {10.1145/3544548.3580919},
abstract = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {23},
keywords = {AI Coding Assistants, AI-Assisted Pair-Programming, ChatGPT, Copilot, GPT-3, Introductory Programming, K-12 Computer Science Education, Large Language Models, OpenAI Codex},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3663529.3663829,
author = {Toslali, Mert and Snible, Edward and Chen, Jing and Cha, Alan and Singh, Sandeep and Kalantar, Michael and Parthasarathy, Srinivasan},
title = {AgraBOT: Accelerating Third-Party Security Risk Management in Enterprise Setting through Generative AI},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663829},
doi = {10.1145/3663529.3663829},
abstract = {In the contemporary business landscape, organizations often rely on third-party services for many functions, including IT services, cloud computing, and business processes. To identify potential security risks, organizations conduct rigorous assessments before engaging with third-party vendors, referred to as Third-Party Security Risk Management (TPSRM). Traditionally, TPSRM assessments are executed manually by human experts and involve scrutinizing various third-party documents such as System and Organization Controls Type 2 (SOC 2) reports and reviewing comprehensive questionnaires along with the security policy and procedures of vendors—a process that is time-intensive and inherently lacks scalability. 
 
 
 
AgraBOT, a Retrieval Augmented Generation (RAG) framework, can assist TPSRM assessors by expediting TPSRM assessments and reducing the time required from days to mere minutes. AgraBOT utilizes cutting-edge AI techniques, including information retrieval (IR), large language models (LLMs), multi-stage ranking, prompt engineering, and in-context learning to accurately generate relevant answers from third-party documents to conduct assessments. We evaluate AgraBOT on seven real TPSRM assessments, consisting of 373 question-answer pairs, and attain an F1 score of 0.85.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {74–79},
numpages = {6},
keywords = {AI, Document Understanding, LLM, RAG, TPSRM},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3663384.3663393,
author = {Feldman, Molly Q and Anderson, Carolyn Jane},
title = {Non-Expert Programmers in the Generative AI Future},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663393},
doi = {10.1145/3663384.3663393},
abstract = {Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {15},
numpages = {19},
keywords = {CS1, Code LLMs, Generative AI, mixed methods, non-experts},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3663533.3664042,
author = {Acharya, Jagrit and Ginde, Gouri},
title = {Graph Neural Network vs. Large Language Model: A Comparative Analysis for Bug Report Priority and Severity Prediction},
year = {2024},
isbn = {9798400706752},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663533.3664042},
doi = {10.1145/3663533.3664042},
abstract = {A vast number of incoming bug reports demand effective methods to identify priority and severity for bug triaging. With increased technological advancement, machine learning and deep learning have been extensively examined to address this problem. Although Large Language Models (LLMs) such as Fine-tuned BERT (early generation LLM) have proven to capture context in the underlying textual data, severity and priority prediction demand additional features for understanding the relationships with other bug reports. This work utilizes the graph-based approach to model the bug reports and their other attributes, such as component, product and bug type information. It utilizes the relational intelligence of Graph Neural Network (GNN) to address the prioritization and severity assessment of bug reports in the Bugzilla bug tracking system. Initial tests on the Mozilla project dataset indicate that a project-wise predictive approach using GNNs yields higher accuracy in determining the priority and severity of bug reports compared to LLMs across multiple Mozilla projects, contributing to a notable advancement in the automation of bug severity and priority prediction tasks. Specifically, GNNs demonstrated a remarkable improvement over LLMs, increasing the priority prediction accuracy by 37% &amp; 30% and severity prediction accuracy by 43% &amp; 30% for Core and Firefox projects, respectively. Overall, GNN outperformed the Fine-tuned BERT (LLM) in predicting priority and severity for all the Mozilla projects.},
booktitle = {Proceedings of the 20th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {2–11},
numpages = {10},
keywords = {BERT, Graph Neural Networks, Large Language Model, Natural Language Processing, Requirement Engineering},
location = {Porto de Galinhas, Brazil},
series = {PROMISE 2024}
}

@article{10.5555/3715602.3715609,
author = {Weiss, Richard and Mache, Jens},
title = {Cybersecurity Exercises in the Age of LLMs},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {In this tutorial, we will introduce a cybersecurity education framework for developing polymorphic hands-on exercises. Many faculty readily acknowledge the importance of cybersecurity in the Computer Science curriculum, but there are still barriers to integrating it into existing courses. One of those barriers is the fact that in most courses, the current content fills the entire term. Another issues is that faculty don't have time and expertise to create new content that would fit well with their current content and style. The third problem is that exercises created should be resistant to solution by LLMs. We have developed cybersecurity exercises that combine two principles: environment specificity and polymorphism. Environment specificity means that the solutions to the exercise should depend on the local environment (LLMs don't have access to that information). In this context, polymorphism means that they can be easily modified each time that the class is taught.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {25–27},
numpages = {3}
}

@inproceedings{10.1145/3634814.3634816,
author = {Cowan, Brendan and Watanobe, Yutaka and Shirafuji, Atsushi},
title = {Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634816},
doi = {10.1145/3634814.3634816},
abstract = {Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student’s prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student’s learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {10–16},
numpages = {7},
keywords = {ChatGPT, educational technology, large language models, programming education, prompt engineering},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

@article{10.5555/3665464.3665467,
author = {Hsin, Wen-Jung},
title = {The Effect of ChatGPT: Student Perspective and Performance Achievement},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {ChatGPT, introduced in November 2022, has rapidly used in various educational systems, prompting the U.S. Department of Education to explore the role of Artificial Intelligence (AI) in teaching and learning. This paper focuses on the impact of AI, particularly ChatGPT, in Computer Science education from the student's perspective and student's performance achievement. Specifically, a study in a Computer Networking course encouraged students to use ChatGPT for learning-related questions, followed by a post-exam survey to evaluate its impact on their learning. Both student feedback and performance achievement indicate that ChatGPT has made a positive impact in their learning in the Computer Networking course.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {20–29},
numpages = {10}
}

@inproceedings{10.1145/3657604.3664682,
author = {Pitts, Griffin and Marcus, Viktoria and Motamedi, Sanaz},
title = {A Proposed Model of Learners' Acceptance and Trust of Pedagogical Conversational AI},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664682},
doi = {10.1145/3657604.3664682},
abstract = {Conversational AI (C-AI), like OpenAI's ChatGPT [38] or Google's Gemini [1], has seen a surge in development in recent years, driven by advancements in large language models. C-AI has the unique capability to instantaneously communicate with others using vast and contextual knowledge, providing personalized assistance tailored to individual needs. While the specific applications and advantages of conversational technologies are still being explored, prior research has noted the potential for conversational agents to serve in pedagogical settings, such as teaching agents, collaborative partners, or motivational tools [13,30]. The successful development and implementation of pedagogical C-AI relies on an understanding of learners' perceptions, trust, and overall acceptance of C-AI. There is a need for a comprehensive understanding of the factors influencing learners' trust and acceptance of this emerging technology.Grounded in the theories proposed by the Technology Acceptance Model (TAM) [16], the Unified Theory of Acceptance and Use of Technology (UTAUT) [47], and Mayer, Davis and Schoorman's model of organizational trust [35], this paper proposes a model of learners' acceptance and trust for C-AI. The proposed model integrates factors relating to learners' perceptions and trust of C-AI, and additionally, four groups of moderating variables (e.g. individual characteristics). The proposed model hypothesizes that learners' perceptions and trust significantly influence their acceptance and behavioral intention to use C-AI. The relationships between learners' perceptions, trust, and acceptance are additionally proposed to be influenced by four groups of moderating variables: individual characteristics, AI characteristics, facilitating conditions, and subjective norms.To validate the proposed model, we plan to collect survey data and leverage structural equation modeling (SEM) techniques. We will specifically evaluate the fitness of the proposed model through chi-square tests, RMSEA, CFI, and SRMR metrics. This study can provide valuable insights toward the scalable adoption and usage of C-AI in learning environments. Understanding the structural relationships between the factors that influence learners' acceptance and trust of pedagogical C-AI will be crucial for designing and deploying these technologies in ways that foster learners' engagement, self-efficacy, academic interest, and ultimately lead to positive learning outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {427–432},
numpages = {6},
keywords = {ai in education, ai trust, conversational agents, conversational ai, human-ai interaction, intelligent agents, pedagogical agents, technology acceptance model},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3545945.3569823,
author = {Denny, Paul and Kumar, Viraj and Giacaman, Nasser},
title = {Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569823},
doi = {10.1145/3545945.3569823},
abstract = {GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1136–1142},
numpages = {7},
keywords = {artificial intelligence, cs1, foundation models, github copilot, introductory programming, large language models, openai},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3585059.3611447,
author = {Sakib, Nazmus and Anik, Fahim Islam and Li, Lei},
title = {ChatGPT in IT Education Ecosystem: Unraveling Long-Term Impacts on Job Market, Student Learning, and Ethical Practices},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611447},
doi = {10.1145/3585059.3611447},
abstract = {The use of ChatGPT in the educational ecosystem has opened up new avenues for learning but also raises questions about its multifarious long-term effects. This scientific study explores how ChatGPT, an AI chatbot, may impact the career prospects of Information Technology and Computer Science graduates in the long term, focusing on job automation and displacement. This study also investigates the enduring impact of ChatGPT on students' attitudes toward learning and developing skills in this education domain while examining ethical practices for incorporating this AI-based aid. This research provides methods to deter unethical actions related to ChatGPT and encourage ethical conduct among students for optimal performance. Moreover, it divulges the impact of ChatGPT on job opportunities, positive outlook, and the pressing necessity for ethical regulations in artificial intelligence use and deployment.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {73–78},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Ethical Practices in IT Education, Job Transformation, Student Attitudes},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3657604.3664698,
author = {Malik, Rizwaan and Abdi, Dorna and Wang, Rose and Demszky, Dorottya},
title = {Scaling High-Leverage Curriculum Scaffolding in Middle-School Mathematics},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664698},
doi = {10.1145/3657604.3664698},
abstract = {Despite well-designed curriculum materials, teachers often face significant challenges in their implementation due to the diverse learning needs present in classrooms. This paper examines whether and how Large Language Models (LLMs) can be leveraged to enhance K-12 math education by facilitating the creation of high-quality curriculum scaffolds that reflect expert teachers' strategies. Through an in-depth qualitative analysis with experienced middle-school math teachers, we identified crucial instructional supplements such as warm-up tasks and example-problem pairs that are essential for engaging students and supporting diverse learner needs. Building on these insights, we developed ScaffGen, an LLM-powered tool designed to generate curriculum-aligned educational materials. While LLMs alone may fall short in educational contexts, when enhanced with expert teacher insights, they can effectively emulate the cognitive processes required for pedagogically robust material creation. We plan to assess the effectiveness of these AI-generated materials through rigorous evaluations involving comparisons with expert-written benchmarks and field tests in classroom settings. This research highlights the potential of LLMs to mimic expert decision-making in educational material creation, offering significant implications for scalable instructional support.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {476–480},
numpages = {5},
keywords = {curriculum scaffolding, human-computer interaction, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3675094.3678991,
author = {Li, Yunjia and Liu, Haiming and Wald, Mike},
title = {DeepVision: Heads-up Computing and AI in Education},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678991},
doi = {10.1145/3675094.3678991},
abstract = {Heads-up computing together with AI can enhance in-class learning experiences. In this position paper, we propose the development of a multimodal AI system called DeepVision that integrates Automatic Speech Recognition (ASR), Large Language Models (LLM), Large Vision Models (LVM), Information Retrieval (IR) and Inclusive User Experience Design (IUX) to convert real-time lectures into multiple knowledge representations. These will be visualized on heads-up communication devices such as Augmented Reality (AR) and Mixed Reality (MR) devices. The initiative is a collaboration between Habitat Learn Limited (HLL) and the University of Southampton, leveraging HLL's existing software and extensive data repository to address the challenges of traditional and digital learning environments, especially for students with disabilities or language differences.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {627–630},
numpages = {4},
keywords = {ai, ar, heads-up computing, inclusive user experience design, large language model, multimodal information access and retrieval},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3689535.3689538,
author = {Sentance, Sue and Watson, Steven and Addo, Salomey Afua and Shi, Shengpeng and Waite, Jane and Yu, Bo},
title = {Developing Computing Teacher Guidance on GenAI},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689538},
doi = {10.1145/3689535.3689538},
abstract = {Generative AI (GenAI) is becoming widely available for use in schools by teachers and students. While many educators appreciate the potential benefits of GenAI for enhancing learning, there are also significant concerns about authorship, authenticity, plagiarism, ethics, biases, and the broader implications of their use in education. For computing teachers in schools, these issues can be even more acute. In this project, we established a working group of practising computing teachers to bring together a range of views and experiences. Initial results of the project led to a booklet for computing teachers on how to use GenAI, illustrating the effectiveness of teacher-researcher partnerships in developing resources for school use. This project will be followed by further work on computing teachers’ actual experience of GenAI in practice.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {12},
numpages = {1},
keywords = {AI education, K-12 education, generative AI, teachers},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3540250.3569444,
author = {Gulwani, Sumit},
title = {AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3569444},
doi = {10.1145/3540250.3569444},
abstract = {AI can enhance programming experiences for a diverse set of programmers: from professional developers and data scientists (proficient programmers) who need help in software engineering and data wrangling, all the way to spreadsheet users (low-code programmers) who need help in authoring formulas, and students (novice programmers) who seek hints when stuck with their programming homework. To communicate their need to AI, users can express their intent explicitly—as input-output examples or natural-language specification—or implicitly—where they encounter a bug (and expect AI to suggest a fix), or simply allow AI to observe their last few lines of code or edits (to have it suggest the next steps).  

The task of synthesizing an intended program snippet from the user’s intent is both a search and a ranking problem. Search is required to discover candidate programs that correspond to the (often ambiguous) intent, and ranking is required to pick the best program from multiple plausible alternatives. This creates a fertile playground for combining symbolic-reasoning techniques, which model the semantics of programming operators, and machine-learning techniques, which can model human preferences in programming. Recent advances in large language models like Codex offer further promise to advance such neuro-symbolic techniques.  

Finally, a few critical requirements in AI-assisted programming are usability, precision, and trust; and they create opportunities for innovative user experiences and interactivity paradigms. In this talk, I will explain these concepts using some existing successes, including the Flash Fill feature in Excel, Data Connectors in PowerQuery, and IntelliCode/CoPilot in Visual Studio. I will also describe several new opportunities in AI-assisted programming, which can drive the next set of foundational neuro-symbolic advances.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1},
numpages = {1},
keywords = {Interactive Programming, Machine Learning, Program Synthesis, Symbolic Reasoning},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3585059.3611445,
author = {Mosaiyebzadeh, Fatemeh and Pouriyeh, Seyedamin and Parizi, Reza and Dehbozorgi, Nasrin and Dorodchi, Mohsen and Mac\^{e}do Batista, Daniel},
title = {Exploring the Role of ChatGPT in Education: Applications and Challenges},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611445},
doi = {10.1145/3585059.3611445},
abstract = {The development of ChatGPT as a sophisticated artificial intelligence technology has impacted numerous sectors, including education and research. The ChatGPT is a powerful large language model that allows students and educators to take advantage of many opportunities, such as personalized learning, lesson planning, and task reduction. While ChatGPT has the potential to streamline pedagogy and research, it poses a variety of challenges, such as allowing cheating on exams and homework, which puts students’ problem-solving skills at risk. Also, ChatGPT creates text that looks like human text, so cheating can be difficult to detect. In this paper, we explore the potential opportunities of ChatGPT in the education sector, as well as its limitations and challenges.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {84–89},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Education, Large Language Model, OpenAI},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3626253.3633418,
author = {Gunawardena, Ananda and Chaturvedi, Naina},
title = {AI Enhanced Learning: Powering Curated Videos with Generative Intelligence},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633418},
doi = {10.1145/3626253.3633418},
abstract = {Instructional videos are becoming increasingly popular among computer science students. Over 78% of students frequently visit YouTube to find videos as supplement to their textbook or classroom instruction[1]. Recent surveys show that on average, 73% of students prefer having their instructors curate a supplemental video library to aid in their learning. Now, the emergence of generative AI is revolutionizing supplemental video instruction, enabling instructors to generate slides, recording scripts, and produce high-quality videos with deep search and embedded interactive activities.Generative AI also takes the student video learning to a new level by providing AI-generated video summaries, on-demand questions, and exploration of topics in greater depth. Integrating AI into standard videos greatly expands the possibilities of video-based learning. This workshop demonstrates how educators can enhance their existing video playlists by incorporating AI to increase student engagement and establish safety measures for AI use in education. By using dynamic dashboards, scheduled content, and gamified questions, instructors can maintain student focus.Drawing on insights from computer science courses taught at Princeton and Rutgers Universities, we will highlight the transformative potential of AI-enhanced videos in promoting active learning, particularly in large classes. We will discuss engagement strategies and real-time data visualizations applicable to any video platform. We will utilize the cubits.ai[2] platform, a Princeton University initiative that enhances the impact of computer science courses. The platform is free, and participants are encouraged to bring their own video playlists to curate them into AI-enabled collections by enhancing the student experience through integrated generative AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1898},
numpages = {1},
keywords = {ai generated content, contextualized generative ai, cost-effective videos, customized videos, data-driven insights, instructional videos, video summarization},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3676281,
author = {Wang, Jieshu and Kiran, Elif and Aurora, S.R. and Simeone, Michael and Lobo, Jose},
title = {ChatGPT on ChatGPT: An Exploratory Analysis of its Performance in the Public Sector Workplace},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676281},
doi = {10.1145/3676281},
abstract = {This study explores the impact of Generative Artificial Intelligence (GenAI), in particular, ChatGPT, on the public sector workforce in the United States, focusing on task replacement, assistance potential, and the evolving landscape of skills. Utilizing GPT-4 to evaluate 1,022 core tasks across 51 public sector occupations, we provide an exploratory analysis of the roles susceptible to ChatGPT automation and those in which ChatGPT can augment human efforts. Our findings reveal that while 63% of tasks are resistant to ChatGPT replacement, primarily due to their requirement for physical presence, emotional intelligence, and complex decision-making, tasks that are routine, rule-based, and involving basic content generation show a high potential for automation. The study also identifies key skills that will remain vital, those likely to become obsolete, and new skills that will emerge as essential, highlighting the need for a strategic approach to workforce development in the face of AI advancements. In particular, our findings underscore the growing importance of skills in applying AI technologies and the ability to validate and interpret AI-generated content for humans to remain competitive. We offer insights into public-sector-specific impacts and propose a methodological framework for future research, emphasizing the importance of adapting educational curricula and policies to prepare for an AI-integrated future.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = jul,
keywords = {Public sector, Workforce, Artificial intelligence, Large language models, ChatGPT, Future of work}
}

@inproceedings{10.1145/3686852.3687073,
author = {Servin, Christian and Karichev, Nadia V. and Pagel, Myshie},
title = {Unfolding Programming: How to Use AI Tools in Introductory Computing Courses},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687073},
doi = {10.1145/3686852.3687073},
abstract = {Artificial Intelligence (AI) generative tools, commonly referred to as AI-based tools, have become integral in various computing domains, including education. The widespread adoption of these tools has raised concerns among educators, spanning from issues related to plagiarism and comprehension gaps to potential threats to student identity. Consequently, educators are grappling with how to adapt their courses and incorporate AI technologies into their curriculum and pedagogical approaches. In addition to navigating challenges associated with AI regulations, educators face the compounded difficulty of addressing post-pandemic issues, such as students displaying diminished effort and professionalism in the classroom. The convergence of these two challenges creates a complex scenario that intertwines technical and professional considerations. Within the Computer Science Fundamentals course, commonly referred to as CS 1, the learning process revolves around comprehending programming through a sequential understanding of steps, as each concept builds upon the preceding one. This investigation centers on the CS 1 curriculum within an American two-year program, commonly known as a community college. The objective is to address a problem by leveraging an AI tool within team settings. The study assesses both problem-solving capabilities and the effectiveness of teamwork, providing recommendations to guide students in the proper utilization of AI tools. The emphasis is on fostering contextual relevance and collaborative work within the generative learning process.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {49–55},
numpages = {7},
keywords = {ai-tools, community colleges, prompt programming, two-year},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3691620.3695299,
author = {Peng, Chao and Wu, Qinyun and Liu, Jiangchao and Liu, Jierui and Jiang, Bo and Xu, Mengqian and Wang, Yinghao and Liu, Xia and Yang, Ping},
title = {RepoSim: Evaluating Prompt Strategies for Code Completion via User Behavior Simulation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695299},
doi = {10.1145/3691620.3695299},
abstract = {Large language models (LLMs) have revolutionized code completion tasks. IDE plugins such as MarsCode can generate code recommendations, saving developers significant time and effort. However, current evaluation methods for code completion are limited by their reliance on static code benchmarks, which do not consider human interactions and evolving repositories. This paper proposes RepoSim, a novel benchmark designed to evaluate code completion tasks by simulating the evolving process of repositories and incorporating user behaviors. RepoSim leverages data from an IDE plugin, by recording and replaying user behaviors to provide a realistic programming context for evaluation. This allows for the assessment of more complex prompt strategies, such as utilizing recently visited files and incorporating user editing history. Additionally, RepoSim proposes a new metric based on users' acceptance or rejection of predictions, offering a user-centric evaluation criterion. Our preliminary evaluation demonstrates that incorporating users' recent edit history into prompts significantly improves the quality of LLM-generated code, highlighting the importance of temporal context in code completion. RepoSim represents a significant advancement in benchmarking tools, offering a realistic and user-focused framework for evaluating code completion performance.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {2279–2283},
numpages = {5},
keywords = {code completion, prompt engineering, benchmark, large language model},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3649165.3690113,
author = {Kasinidou, Maria and Kleanthous, Styliani and Otterbacher, Jahna},
title = {"We have to learn to work with such systems": Students' Perceptions of ChatGPT After a Short Educational Intervention on NLP},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690113},
doi = {10.1145/3649165.3690113},
abstract = {Natural Language Processing (NLP) is a critical area of AI that is increasingly integrated into everyday life. The public regularly engages with systems such as Siri, Alexa, and more recently, ChatGPT, yet few understand how these systems work. In this paper, we examine how students perceive NLP technologies after completing a unit on NLP within an AI course designed for non-CS majors. We further present our students' perspectives on the banning of ChatGPT in Italy, where the course was delivered. The NLP unit featured a lecture, an interactive session, and a practical assignment wherein students developed a smart assistant responsive to textual commands. Students, after creating their smart assistants, highlighted challenges such as inadequate training datasets and natural language ambiguity. Opinions on ChatGPT's ban varied, with privacy concerns prevailing. However, a consensus emerged in favor of educational efforts to raise awareness about technology limitations, advocating understanding over outright bans in anticipation of their inevitable integration into daily life.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {74–80},
numpages = {7},
keywords = {artificial intelligence, chatgpt, large language models, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3627673.3679760,
author = {Fu, Lingyue and Guan, Hao and Du, Kounianhua and Lin, Jianghao and Xia, Wei and Zhang, Weinan and Tang, Ruiming and Wang, Yasheng and Yu, Yong},
title = {SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679760},
doi = {10.1145/3627673.3679760},
abstract = {Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a &lt;u&gt;S&lt;/u&gt;tructure-aware &lt;u&gt;IN&lt;/u&gt;ductive &lt;u&gt;K&lt;/u&gt;nowledge &lt;u&gt;T&lt;/u&gt;racing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a hetero- geneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {632–642},
numpages = {11},
keywords = {inductive learning, knowledge tracing, online education},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3545945.3569830,
author = {Wermelinger, Michel},
title = {Using GitHub Copilot to Solve Simple Programming Problems},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569830},
doi = {10.1145/3545945.3569830},
abstract = {The teaching and assessment of introductory programming involves writing code that solves a problem described by text. Previous research found that OpenAI's Codex, a natural language machine learning model trained on billions of lines of code, performs well on many programming problems, often generating correct and readable Python code. GitHub's version of Codex, Copilot, is freely available to students. This raises pedagogic and academic integrity concerns. Educators need to know what Copilot is capable of, in order to adapt their teaching to AI-powered programming assistants. Previous research evaluated the most performant Codex model quantitatively, e.g. how many problems have at least one correct suggestion that passes all tests. Here I evaluate Copilot instead, to see if and how it differs from Codex, and look qualitatively at the generated suggestions, to understand the limitations of Copilot. I also report on the experience of using Copilot for other activities asked of students in programming courses: explaining code, generating tests and fixing bugs. The paper concludes with a discussion of the implications of the observed capabilities for the teaching of programming.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {academic integrity, code explanation, code generation, introductory programming, novice programming, openai codex, programming exercises, programming patterns, test generation},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3613904.3641895,
author = {Hoque, Md Naimul and Mashiat, Tasfia and Ghai, Bhavya and Shelton, Cecilia D. and Chevalier, Fanny and Kraus, Kari and Elmqvist, Niklas},
title = {The HaLLMark Effect: Supporting Provenance and Transparent Use of Large Language Models in Writing with Interactive Visualization},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641895},
doi = {10.1145/3613904.3641895},
abstract = {The use of Large Language Models (LLMs) for writing has sparked controversy both among readers and writers. On one hand, writers are concerned that LLMs will deprive them of agency and ownership, and readers are concerned about spending their time on text generated by soulless machines. On the other hand, AI-assistance can improve writing as long as writers can conform to publisher policies, and as long as readers can be assured that a text has been verified by a human. We argue that a system that captures the provenance of interaction with an LLM can help writers retain their agency, conform to policies, and communicate their use of AI to publishers and readers transparently. Thus we propose HaLLMark, a tool for visualizing the writer’s interaction with the LLM. We evaluated HaLLMark with 13 creative writers, and found that it helped them retain a sense of control and ownership of the text.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1045},
numpages = {15},
keywords = {Creative writing, LLMs, agency, co-writing, visualization.},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.5555/3665609.3665633,
author = {Liu, Sa and Grey, Brian and Watkins, Ryan and Chu, Chad and Grim, Phillip and McManus, Thomas},
title = {Assessing Risks, Challenges and Opportunities of Generative AI in Computer Programming Education --- Lightning Talk},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has the potential to transform the education sector by enhancing teaching and learning experiences. According to Sal Khan, founder of Khan Academy, AI is about to start "the biggest positive transformation that education has ever seen"1 by making high-quality personalized tutoring available (tuition free) to everyone on the planet. Given AI's, and more specifically Generative AI's (GAI), rapidly developing capabilities (e.g., to provide tailored feedback, ask questions of students, give examples and non-examples, and offer general learning support), incorporating GAI into programming education has the potential to enhance student engagement and learning outcomes. At the same time, they identified challenges in using GAI, such as its inability to answer some questions and its tendency to provide incorrect or incomplete responses. Students also report an increase in anxiety surrounding GAI and its potential effects on future professional opportunities. Outside of the classroom there is likewise an increasing prevalence of GAI in computational professions, making it crucial to equip students with the necessary knowledge and skills to effectively, responsibly, and ethically utilize GAI. Rather than avoiding the use of GAI in the classroom, in this study we aim to investigate the pros and cons of leveraging GAI's capabilities to offer personalized guidance and assistance to students as they learn programming. By doing this research, we are learning to create more interactive and engaging learning experiences that better equip students with the skills and knowledge needed to succeed in the field of programming. This project, which is currently being conducted, was designed to address this research question: To what extent does the incorporation of GAI impact students' engagement, motivation, and achievement, particularly with the material in Intro to Programming courses and their chosen STEM field of study? It is utilizing case studies that focus on the integration of GAI into computer programming education. The team has 1) developed a series of GAI-supported teaching modules specifically designed to improve problem-solving skills in programming tasks among undergraduate students; and 2) is in the process of analyzing student feedback on GAI integration in computer programming education. This project offers an important exploration into the intersection of GAI and programming education, with the expectation that results will provide useful guidance for programming instructors who are adapting their instructional strategies for the emerging role of GAI in programming. The team will briefly present the status of the research and early insights from the project, and then engage with the audience on how lessons learned from this work can pragmatically shape programming courses in their institutions. Quick tips, takeaways, and prompting strategies will be shared throughout this interactive lighting talk.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {210–211},
numpages = {2}
}

@inproceedings{10.1145/3691620.3695518,
author = {Bo, Lili and Ji, Wangjie and Sun, Xiaobing and Zhang, Ting and Wu, Xiaoxue and Wei, Ying},
title = {ChatBR: Automated assessment and improvement of bug report quality using ChatGPT},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695518},
doi = {10.1145/3691620.3695518},
abstract = {Bug reports, containing crucial information such as the Observed Behavior (OB), the Expected Behavior (EB), and the Steps to Reproduce (S2R), can help developers localize and fix bugs efficiently. However, due to the increasing complexity of some bugs and the limited experience of some reporters, large numbers of bug reports miss this crucial information. Although machine learning (ML)-based and information retrieval (IR)-based approaches are proposed to detect and supplement the missing information in bug reports, the performance of these approaches depends heavily on the size and quality of bug report datasets.In this paper, we present ChatBR, an approach for automated assessment and improvement of bug report quality using ChatGPT. First, we fine-tune a BERT model using manually annotated bug reports to create a sentence-level multi-label classifier to assess the quality of bug reports by detecting whether existing OB, EB, and S2R. Then, we use ChatGPT in a zero-shot setup to generate missing information (OB, EB, and S2R) to improve the quality of bug reports. Finally, the output of ChatGPT are fed back into the classifier for verification until ChatGPT generates the missing information. Experimental results show that, in the task of detecting missing information in bug reports, ChatBR outperforms the state-of-the-art methods by 25.38%-29.20% in terms of precision. In the task of generating missing information in bug reports, ChatBR can achieve an average of 84.10% in terms of semantic similarity of the generated information and original information across six different projects. Furthermore, ChatBR can generate more than 99.9% of high-quality bug reports (i.e., bug reports that are full of OB, EB, and S2R) within five queries to ChatGPT.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1472–1483},
numpages = {12},
keywords = {bug report, ChatGPT, pre-trained models, large language models},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3641523.3665172,
author = {Papatheodorou, Theodoros and Wolpert, Jessica},
title = {Algorithmic Amplification},
year = {2024},
isbn = {9798400705298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641523.3665172},
doi = {10.1145/3641523.3665172},
abstract = {Algorithmic Amplifications leverages the power of Large Language Models (LLMs) and a custom instant voice cloning pipeline to create a tangible representation of digital echo chambers, underscoring how language shapes our perceptions and reinforces our beliefs. It prompts a critical examination of the impact of AI on our linguistic and cultural landscapes, spotlighting the paradox of technological advancement: while LLMs mark a significant leap in AI, they also mirror and potentially amplify societal biases.},
booktitle = {ACM SIGGRAPH 2024 Art Gallery},
articleno = {02},
numpages = {1},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3626253.3635595,
author = {Hamerski, Patti C.},
title = {Generative AI as a Resource for Creativity in Computational Physics},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635595},
doi = {10.1145/3626253.3635595},
abstract = {Generative artificial intelligence (gen-AI) has become ubiquitous in daily life, including classroom environments where students are using it to assist them on their coursework. Given the widespread use of this tool and the lack of knowledge over how it can support learning, there is a need for educators to have a framework for using it in the classroom and teaching their students usage strategies that are beneficial for learning. One pathway forward is through creativity, a process crucial for learning and also connected to the act of using gen-AI. This poster demonstrates the results of a study designed to provide an in-depth view on how creativity intersects with gen-AI usage in a computational physics course. In the course, students learn about computing tools during group-based, open-ended computational physics activities. Students are often tasked with using gen-AI to explore and help make decisions. The findings demonstrate a connection between using gen-AI and engaging in creative processes, and the implications point to strategies for supporting student usage of gen-AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1666–1667},
numpages = {2},
keywords = {computational science, creativity, curriculum design, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3627673.3679229,
author = {Lee, Zhicheng and Huang, Zhidian and Yao, Zijun and Liu, Jinxin and Xin, Amy and Hou, Lei and Li, Juanzi},
title = {DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679229},
doi = {10.1145/3627673.3679229},
abstract = {We present Dialogue-based Knowledge-oriented Programming system (DiaKoP), a system with a chat interface designed for multi-turn knowledge base question answering (KBQA). DiaKoP enables users to decompose complex questions into multiple simpler follow-up questions and interact with the system to obtain answers. Multi-turn KBQA presents unique challenges because users may switch topics or ask incomplete questions that rely on previous interactions. To address this, we develop a Dialogue History Tracker and Dialogue Policy to manage user conversations effectively. Additionally, we enhance the knowledge from the knowledge graph by integrating parametric knowledge from a large language model (LLM) to provide more comprehensive answers. To mitigate the issue of wrongly parsed questions by semantic parser, we implement a human-in-the-loop mechanism, allowing users to correct errors. We evaluate DiaKoP both qualitatively and quantitatively, with user study indicating that our system better meets users' needs. DiaKoP is open-sourced on https://github.com/THU-KEG/DiaKoP with a guiding demo on https://youtu.be/Tq17k0OxPVg.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5234–5238},
numpages = {5},
keywords = {explainability, human-in-the-loop, knowledge based question answering system, multi-turn dialogue},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3613904.3642377,
author = {Chen, John and Lu, Xi and Du, Yuzhou and Rejtig, Michael and Bagley, Ruth and Horn, Mike and Wilensky, Uri},
title = {Learning Agent-based Modeling with LLM Companions: Experiences of Novices and Experts Using ChatGPT &amp; NetLogo Chat},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642377},
doi = {10.1145/3613904.3642377},
abstract = {Large Language Models (LLMs) have the potential to fundamentally change the way people engage in computer programming. Agent-based modeling (ABM) has become ubiquitous in natural and social sciences and education, yet no prior studies have explored the potential of LLMs to assist it. We designed NetLogo Chat to support the learning and practice of NetLogo, a programming language for ABM. To understand how users perceive, use, and need LLM-based interfaces, we interviewed 30 participants from global academia, industry, and graduate schools. Experts reported more perceived benefits than novices and were more inclined to adopt LLMs in their workflow. We found significant differences between experts and novices in their perceptions, behaviors, and needs for human-AI collaboration. We surfaced a knowledge gap between experts and novices as a possible reason for the benefit gap. We identified guidance, personalization, and integration as major needs for LLM-based interfaces to support the programming of ABM.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {141},
numpages = {18},
keywords = {Agent-based Modeling, ChatGPT, LLM Companion, Learning with LLMs, NetLogo Chat, Programming Assistant},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3639474.3640059,
author = {Fwa, Hua Leong},
title = {Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640059},
doi = {10.1145/3639474.3640059},
abstract = {Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {233–241},
numpages = {9},
keywords = {LLM, ChatGPT, misconception, programming, errors, cluster, prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3605098.3636053,
author = {Alharbi, Reham and Tamma, Valentina and Grasso, Floriana and Payne, Terry},
title = {An Experiment in Retrofitting Competency Questions for Existing Ontologies},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636053},
doi = {10.1145/3605098.3636053},
abstract = {Competency Questions (CQs) are a form of ontology functional requirements expressed as natural language questions. Inspecting CQs together with the axioms in an ontology provides critical insights into the intended scope and applicability of the ontology. CQs also underpin a number of tasks in the development of ontologies e.g. ontology reuse, ontology testing, requirement specification, and the definition of patterns that implement such requirements. Although CQs are integral to the majority of ontology engineering methodologies, the practice of publishing CQs alongside the ontological artefacts is not widely observed by the community.In this context, we present an experiment in retrofitting CQs from existing ontologies. We propose RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using Generative AI. In the paper we present the pipeline that facilitates the extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its application to a number of existing ontologies.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1650–1658},
numpages = {9},
keywords = {ontology engineering, competency questions, large language models},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3643991.3645082,
author = {Chavan, Omkar Sandip and Hinge, Divya Dilip and Deo, Soham Sanjay and Wang, Yaxuan (Olivia) and Mkaouer, Mohamed Wiem},
title = {Analyzing Developer-ChatGPT Conversations for Software Refactoring: An Exploratory Study},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645082},
doi = {10.1145/3643991.3645082},
abstract = {In recent years, Large Language Models (LLMs) have witnessed a remarkable ascent, with OpenAI's ChatGPT, introduced in 2022, garnering substantial attention. ChatGPT's rapid adoption in the software development community has opened up new avenues for exploring its qualitative and quantitative impact on Developer-ChatGPT conversations. In this paper, we delve into a rich dataset from GitHub and Hacker News to perform a thorough analysis. Our objectives include characterizing the nature of these interactions and evaluating the use of ChatGPT in refactoring. To achieve these goals, we employ a combination of exploratory data analysis and data annotation, utilizing relevant keyword filters to extract pertinent information. Our examination encompasses the identification and analysis of code refactorings facilitated by ChatGPT. Through a meticulous exploration of these conversations, our goal is to illuminate the potential of ChatGPT to enhance software development practices. This research promises to provide valuable insights into the evolving role of ChatGPT in the world of software development.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {207–211},
numpages = {5},
keywords = {refactoring documentation, ChatGPT, mining software repositories},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3627217.3627221,
author = {Wang, Zixuan and Denny, Paul and Leinonen, Juho and Luxton-Reilly, Andrew},
title = {Leveraging Large Language Models for Analysis of Student Course Feedback},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627221},
doi = {10.1145/3627217.3627221},
abstract = {This study investigates the use of large language models, specifically ChatGPT, to analyse the feedback from a Summative Evaluation Tool (SET) used to collect student feedback on the quality of teaching. We find that these models enhance comprehension of SET scores and the impact of context on student evaluations. This work aims to reveal hidden patterns in student evaluation data, demonstrating a positive first step towards automated, detailed analysis of student feedback.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {76–79},
numpages = {4},
keywords = {Large Language Model, Natural Language Processing, Student Evaluation of Teaching, Student Feedback},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3587102.3588792,
author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Song, Yifan and Sakr, Majd},
title = {Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588792},
doi = {10.1145/3587102.3588792},
abstract = {We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (&lt;70% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (&gt;55%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {117–123},
numpages = {7},
keywords = {AI code generation, GPT, GitHub copilot, alphacode, codex, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment, python course},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3631802.3631848,
author = {Deriba, Fitsum Gizachew and Sanusi, Ismaila Temitayo and Sunday, Amos Oyelere},
title = {Enhancing Computer Programming Education using ChatGPT- A Mini Review},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631848},
doi = {10.1145/3631802.3631848},
abstract = {This paper aims to provide insights into how ChatGPT enhances computer programming education by synthesizing existing studies using rapid review. We analysed 13 articles published in 2023, where studies focused on different aspects of basic programming education. The results indicate that 21% of these studies demonstrate that ChatGPT served as a tool for code explanation and handling complex topics. However, 36% show that ChatGPT had difficulty answering non-text-based and code-related questions, revealing reliability and accuracy issues with these tools. Another 36% of the studies showed that blindly over-reliance on ChatGPT affected critical thinking, student creativity, and problem-solving skills in programming education. 46% of the studies indicated the need to provide clear guidelines and employ plagiarism-detection tools to instruct students effectively. We suggest that educators should adopt diverse approaches to integrating ChatGPT as an educational tool while highlighting ethical considerations and model limitations.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {45},
numpages = {2},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@article{10.1145/3710795.3710797,
author = {Tran, Nicholas},
title = {The Book Review Column},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0163-5700},
url = {https://doi.org/10.1145/3710795.3710797},
doi = {10.1145/3710795.3710797},
abstract = {Foundation Mathematics for Computer Science: A Visual Approach, 4th edition (Springer, 2023) by John Vince (Bournemouth University, UK) is a comprehensive collection of discrete and continuous mathematical topics that are covered in most undergraduate programs in computer science. The subtitle refers to the author's use of colored graphs and tables to illustrate the concepts.Online Algorithms (Cambridge University Press, 2023) by Rahul Vaze (Tata Institute of Fundamental Research, India) is an accessible but rigorous introduction to the area aimed at advanced undergraduates and beginning graduate students. The book covers the basic as well as applied online problems with a preference of elegant analysis over performance.Privacy-preserving Computing for Big Data Analytics and AI (Cambridge University Press, 2023) by Kai Chen and Qiang Yang (Hong Kong University of Science and Technology) is a systematic examination of the history, theories, techniques, applications, and future of the field.Prize-winning neuroscientist Terrence Sejnowski (University of California at San Diego) explains the technology and mathematics behind large language models such as ChatGPT and explores the debate on their so-called comprehension of language in ChatGPT and the Future of AI: The Deep Language Revolution (The MIT Press, 2024).},
journal = {SIGACT News},
month = dec,
pages = {3–20},
numpages = {18}
}

@inproceedings{10.1145/3613904.3642041,
author = {Cheng, Alan Y. and Guo, Meng and Ran, Melissa and Ranasaria, Arpit and Sharma, Arjun and Xie, Anthony and Le, Khuyen N. and Vinaithirthan, Bala and Luan, Shihe (Tracy) and Wright, David Thomas Henry and Cuadra, Andrea and Pea, Roy and Landay, James A.},
title = {Scientific and Fantastical: Creating Immersive, Culturally Relevant Learning Experiences with Augmented Reality and Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642041},
doi = {10.1145/3613904.3642041},
abstract = {Motivating children to learn is a major challenge in education. One way to inspire motivation to learn is through immersion. We combine the immersive potential of augmented reality (AR), narrative, and large language models (LLMs) to bridge fantasy with reality in a mobile application, Moon Story, that teaches elementary schoolers astronomy and environmental science. Our system also builds upon learning theories such as culturally-relevant pedagogy. Using our application, a child embarks on a journey inspired by Chinese mythology, engages in real-world AR activities, and converses with a fictional character powered by an LLM. We conducted a controlled experiment (N = 50) with two conditions: one using an LLM and one that was hard-coded. Both conditions resulted in learning gains, high engagement levels, and increased science learning motivation. Participants in the LLM condition also wrote more relevant answers. Finally, participants of both Chinese and non-Chinese heritage found the culturally-based narrative compelling.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {275},
numpages = {23},
keywords = {Artifact or System, Children/Parents, Education/Learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3640310.3674093,
author = {Morales, Sergio and Claris\'{o}, Robert and Cabot, Jordi},
title = {A DSL for Testing LLMs for Fairness and Bias},
year = {2024},
isbn = {9798400705045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640310.3674093},
doi = {10.1145/3640310.3674093},
abstract = {Large language models (LLMs) are increasingly integrated into software systems to enhance them with generative AI capabilities. But LLMs may reflect a biased behavior, resulting in systems that could discriminate against gender, age or ethnicity, among other ethical concerns. Society and upcoming regulations will force companies and development teams to ensure their AI-enhanced software is ethically fair. To facilitate such ethical assessment, we propose LangBiTe, a model-driven solution to specify ethical requirements, and customize and automate the testing of ethical biases in LLMs. The evaluation can raise awareness on the biases of the LLM-based components of the system and/or trigger a change in the LLM of choice based on the requirements of that particular application. The model-driven approach makes both the requirements specification and the test generation platform-independent, and provides end-to-end traceability between the requirements and their assessment. We have implemented an open-source tool set, available on GitHub, to support the application of our approach.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {203–213},
numpages = {11},
keywords = {Bias, Domain-Specific Language, Ethics, Large Language Models, Model-Driven Engineering, Red Teaming, Testing},
location = {Linz, Austria},
series = {MODELS '24}
}

@inbook{10.1145/3691620.3695524,
author = {Zhu, Ming and Karim, Mohimenul and Lourentzou, Ismini and Yao, Daphne},
title = {Semi-Supervised Code Translation Overcoming the Scarcity of Parallel Code Data},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695524},
abstract = {Neural code translation is the task of converting source code from one programming language to another. One of the main challenges is the scarcity of parallel code data, which hinders the ability of translation models to learn accurate cross-language alignments. In this paper, we introduce MIRACLE, a semi-supervised approach that improves code translation through synthesizing high-quality parallel code data and curriculum learning on code data with ascending alignment levels. MIRACLE leverages static analysis and compilation to generate synthetic parallel code datasets with enhanced quality and alignment to address the challenge of data scarcity. We evaluate the proposed method along with strong baselines including instruction-tuned Large Language Models (LLMs) for code. Our analysis reveals that LLMs pre-trained on open-source code data, regardless of their size, suffer from the "shallow translation" problem. This issue arises when translated code copies keywords, statements, and even code blocks from the source language, leading to compilation and runtime errors. Extensive experiments demonstrate that our method significantly mitigates this issue, enhancing code translation performance across multiple models in C++, Java, Python, and C. Remarkably, MIRACLE outperforms code LLMs that are ten times larger in size. MIRACLE also achieves up to a 43% improvement in C code translation with fewer than 150 annotated examples.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1545–1556},
numpages = {12}
}

@inproceedings{10.1145/3649409.3691093,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui},
title = {Code Metrics, Rules of Thumb for Introductory CS},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691093},
doi = {10.1145/3649409.3691093},
abstract = {In response to the recent surge in easily accessible generative AI, Harvey Mudd College has integrated AI-assisted coding into the introductory Computer Science course. In this context, a question arises: How do we measure the quality of students' code when AI-generated code is present?Allowing generative AI to write coding assignments comes with the expectation of improved efficiency and accuracy. While generative AI is a useful tool, it merely supplements fundamental computing skills. This technological step towards being fully syntax-free allows for emphasis on the already important skill of developing problem-solving and critical thinking skills in more abstract contexts. In past years, metrics were designed to measure quantitative aspects of code, but these metrics alone are insufficient when evaluating how code written with the assistance of AI will perform in broader applications. When students submit code written with the assistance of generative AI, they are still expected to meet standards given by past metrics, such as Correctness and Complexity. To establish foundational computing skills, students will also be held to new standards and evaluated by new metrics such as Individuality and Ambition.While the model does give objective measures of the metrics, due to the fast-evolving nature of programming, predefined rules-of-thumb for these metrics are not provided. As users of our system, we recognize that evaluating the measurements will require our judgment, which will evolve over time. This work offers the foundation for that evolution.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {314–315},
numpages = {2},
keywords = {computing as a general education requirement, computing as a shared literacy, generative AI, undergraduate-universal computing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3649405.3659534,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Virginia and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {How Instructors Incorporate Generative AI into Teaching Computing},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659534},
doi = {10.1145/3649405.3659534},
abstract = {Generative AI (GenAI) has seen great advancements in the past two years and the conversation around adoption is increasing. Widely available GenAI tools are disrupting classroom practices as they can write and explain code with minimal student prompting. While most acknowledge that there is no way to stop students from using such tools, a consensus has yet to form on how students should use them if they choose to do so. At the same time, researchers have begun to introduce new pedagogical tools that integrate GenAI into computing curricula. These new tools offer students personalized help or attempt to teach prompting skills without undercutting code comprehension. This working group aims to detail the current landscape of education-focused GenAI tools and teaching approaches, present gaps where new tools or approaches could appear, identify good practice-examples, and provide a guide for instructors to utilize GenAI as they continue to adapt to this new era.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {771–772},
numpages = {2},
keywords = {artificial intelligence, generative AI, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3585059.3611431,
author = {Zheng, Yong},
title = {ChatGPT for Teaching and Learning: An Experience from Data Science Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611431},
doi = {10.1145/3585059.3611431},
abstract = {ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {66–72},
numpages = {7},
keywords = {ChatGPT, data analytics, data science, large language model},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3613904.3642731,
author = {Chakrabarty, Tuhin and Laban, Philippe and Agarwal, Divyansh and Muresan, Smaranda and Wu, Chien-Sheng},
title = {Art or Artifice? Large Language Models and the False Promise of Creativity},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642731},
doi = {10.1145/3613904.3642731},
abstract = {Researchers have argued that large language models (LLMs) exhibit high-quality writing capabilities from blogs to stories. However, evaluating objectively the creativity of a piece of writing is challenging. Inspired by the Torrance Test of Creative Thinking (TTCT) [64], which measures creativity as a process, we use the Consensual Assessment Technique [3] and propose Torrance Test of Creative Writing (TTCW) to evaluate creativity as product. TTCW consists of 14 binary tests organized into the original dimensions of Fluency, Flexibility, Originality, and Elaboration. We recruit 10 creative writers and implement a human assessment of 48 stories written either by professional authors or LLMs using TTCW. Our analysis shows that LLM-generated stories pass 3-10X less TTCW tests than stories written by professionals. In addition, we explore the use of LLMs as assessors to automate the TTCW evaluation, revealing that none of the LLMs positively correlate with the expert assessments.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {30},
numpages = {34},
keywords = {Creativity, Design Methods, Evaluation, Human-AI collaboration, Large Language Models, Natural Language Generation, StoryTelling},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3687311.3687403,
author = {Lu, Yike and Wang, Dongyangzi and Wu, Juan},
title = {What is the AIGC-assisted learning experience like? -- A study based on conceptual understanding},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687403},
doi = {10.1145/3687311.3687403},
abstract = {AIGC interacts with learners by employing natural language processing and knowledge representation techniques to generate cognitive tools that facilitate the understanding of complex concepts. Nevertheless, some studies have indicated that AIGC may present certain challenges in terms of its complexity of comprehension, difficulty of application, and the accuracy of its content. These factors may potentially influence the learning experience and, subsequently, the learning outcomes. This study examines the questioning patterns, learning experiences, and learning outcomes of college students when learning complex concepts using AIGC. A total of 31 college students were required to learn the "connectivism" theory using the GLM-4 large language model within a specified 40 minutes. The study employed a mixed-methods approach to gather data pertaining to interactions, responses, and outcomes. The data analysis yielded some intriguing results. Firstly, the participants demonstrated a behavior pattern of “questioning, understanding, and re-questioning”. With extracting conceptual knowledge from AIGC's answers, the participants critically assessed the quality of the answers and employed various strategies for requestioning. Secondly, the participants perceived that AIGC has the potential to optimize the learning experience, particularly in the following areas: instructional interaction, self-regulation, usability, and enjoyment of the learning process. However, concerns were expressed regarding the accuracy, personalization, and creativity of the content generated by AIGC tools. Finally, the results demonstrated that AIGC-assisted conceptual understanding achieved positive learning outcomes. The findings of this study provide empirical evidence and strategic recommendations for optimizing the development and application of AIGC in educational activities.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {512–518},
numpages = {7},
location = {Guilin, China},
series = {IECT '24}
}

@inproceedings{10.1145/3685767.3685777,
author = {Abdalla, Hemn Barzan and Awlla, Ardalan Hussein and Kumar, Yulia and Cheraghy, Maryam},
title = {Big Data: Past, Present, and Future Insights},
year = {2024},
isbn = {9798400709609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3685767.3685777},
doi = {10.1145/3685767.3685777},
abstract = {This paper presents a comprehensive analysis of the historical progression, current trends, and prospects of Big Data. It explores the technological advancements that have established Big Data as a critical element of contemporary analytics, its extensive impact across various sectors, and the ethical challenges it poses. Beginning with the early recognition of Big Data's potential in the 2000s, the paper traces the development of foundational technologies such as Hadoop and the subsequent diversification of tools and methods. It delves into the integration of advanced analytics and machine learning, the rise of cloud-based Big Data services, and the transformative effects on sectors including healthcare, finance, agriculture, and education. The study also examines ethical considerations such as privacy, bias, transparency, and regulatory compliance, emphasizing the need for robust governance frameworks. It investigates the potential of emerging technologies like AI, IoT, and quantum computing to enhance Big Data capabilities further. It highlights future directions, including decentralized data ecosystems, advanced analytical techniques, and enhanced data privacy measures. By providing a panoramic view of Big Data's development, this paper aims to showcase its potential to revolutionize decision-making processes, improve operational efficiency, and drive innovation across industries; it underscores the importance of balancing technological innovation with ethical responsibility to ensure positive societal advancement and global progress. To add a novelty to the discussion, an AI agent Big D was created to provide a relevant analysis of trends in Big Data. The agent uses a multimodal ChatGPT-4o Large Language Model (LLM) from OpenAI and provides its review based on uploaded files and LLM knowledge.},
booktitle = {Proceedings of the 2024 Asia Pacific Conference on Computing Technologies, Communications and Networking},
pages = {60–70},
numpages = {11},
location = {Chengdu, China},
series = {CTCNet '24}
}

@inproceedings{10.1145/3701625.3701675,
author = {Falc\~{a}o, Fabiano Damasceno Sousa and Canedo, Edna Dias},
title = {Investigating Software Development Teams Members' Perceptions of Data Privacy in the Use of Large Language Models (LLMs)},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701675},
doi = {10.1145/3701625.3701675},
abstract = {Context: Large Language Models (LLMs) have revolutionized natural language generation and understanding. However, they raise significant data privacy concerns, especially when sensitive data is processed and stored by third parties. Goal: This paper investigates the perception of software development teams members regarding data privacy when using LLMs in their professional activities. Additionally, we examine the challenges faced and the practices adopted by these practitioners. Method: We conducted a survey with 78 ICT practitioners from five regions of the country. Results: Software development teams members have basic knowledge about data privacy and LGPD, but most have never received formal training on LLMs and possess only basic knowledge about them. Their main concerns include the leakage of sensitive data and the misuse of personal data. To mitigate risks, they avoid using sensitive data and implement anonymization techniques. The primary challenges practitioners face are ensuring transparency in the use of LLMs and minimizing data collection. Software development teams members consider current legislation inadequate for protecting data privacy in the context of LLM use. Conclusions: The results reveal a need to improve knowledge and practices related to data privacy in the context of LLM use. According to software development teams members, organizations need to invest in training, develop new tools, and adopt more robust policies to protect user data privacy. They advocate for a multifaceted approach that combines education, technology, and regulation to ensure the safe and responsible use of LLMs.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {373–382},
numpages = {10},
keywords = {Large language models (LLM), Conversational agents, Chatbots, Data Privacy, Privacy risks},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3652620.3687773,
author = {Bucchiarone, Antonio and Cicchetti, Antonio and V\'{a}zquez-Ingelmo, Andrea and Adami, Filippo and Schiavo, Gianluca and Garc\'{\i}a-Holgado, Alicia and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e}},
title = {Designing and Generating Lesson Plans combining Open Educational Content and Generative AI},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687773},
doi = {10.1145/3652620.3687773},
abstract = {In this paper, we propose an approach for assisting educators in deriving lesson plans for complex learning subjects like Model-Driven Engineering (MDE) from existing educational materials, leveraging generative AI techniques. Our method focuses on guiding teachers in defining learning objectives and suggesting concrete learning activities for students. Central to our approach is the development of a metamodel that characterizes the methodology and serves as the foundation for implementing supporting tools. By utilizing available Open Educational Resources (OERs) and incorporating them into specific learning activities, our method provides a general framework for supporting educators in designing lesson plans. We present the methodology to generate lesson plans, the metamodel conceptualizing plans ingredients, and demonstrate their application through supporting tools, illustrating the potential of our approach in facilitating the development of MDE teaching materials.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {78–86},
numpages = {9},
keywords = {open educational resources, OERs, model-driven engineering, MDE, generative AI, educational paradigms, tailored learning activities, customizable learning content},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3649165.3690125,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Prather, James and Leinonen, Juho and Luxton-Reilly, Andrew and MacNeil, Stephen},
title = {Integrating Natural Language Prompting Tasks in Introductory Programming Courses},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690125},
doi = {10.1145/3649165.3690125},
abstract = {Introductory programming courses often emphasize mastering syntax and basic constructs before progressing to more complex and interesting programs. This bottom-up approach can be frustrating for novices, shifting the focus away from problem solving and potentially making computing less appealing to a broad range of students. The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module. The first requires students to solve computational problems by writing natural language prompts, emphasizing problem-solving over syntax. The second involves students crafting prompts to generate code equivalent to provided fragments, to foster an understanding of the relationship between prompts and code. Most of the students in the course had reported finding programming difficult to learn, often citing frustrations with syntax and debugging. We found that self-reported difficulty with learning programming had a strong inverse relationship with performance on traditional programming assessments such as tests and projects, as expected. However, performance on the natural language tasks was less strongly related to self-reported difficulty, suggesting they may target different skills. Learning how to communicate with AI coding models is becoming an important skill, and natural language prompting tasks may appeal to a broad range of students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {88–94},
numpages = {7},
keywords = {cs1, eipe, explain in plain english, introductory programming, llm, natural language prompting, prompt engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3657604.3662032,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662032},
doi = {10.1145/3657604.3662032},
abstract = {Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {51–62},
numpages = {12},
keywords = {active learning, generative ai, gpt, introductory programming, large language models, parsons problems, personalization},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3639478.3640024,
author = {Sapozhnikov, Arkadii and Olsthoorn, Mitchell and Panichella, Annibale and Kovalenko, Vladimir and Derakhshanfar, Pouria},
title = {TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion},
year = {2024},
isbn = {9798400705021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639478.3640024},
doi = {10.1145/3639478.3640024},
abstract = {Writing software tests is laborious and time-consuming. To address this, prior studies introduced various automated test-generation techniques. A well-explored research direction in this field is unit test generation, wherein artificial intelligence (AI) techniques create tests for a method/class under test. While many of these techniques have primarily found applications in a research context, existing tools (e.g., EvoSuite, Randoop, and AthenaTest) are not user-friendly and are tailored to a single technique. This paper introduces Test-Spark, a plugin for IntelliJ IDEA that enables users to generate unit tests with only a few clicks directly within their Integrated Development Environment (IDE). Furthermore, TestSpark also allows users to easily modify and run each generated test and integrate them into the project workflow. TestSpark leverages the advances of search-based test generation tools, and it introduces a technique to generate unit tests using Large Language Models (LLMs) by creating a feedback cycle between the IDE and the LLM. Since TestSpark is an open-source (https://github.com/JetBrains-Research/TestSpark), extendable, and well-documented tool, it is possible to add new test generation methods into the plugin with the minimum effort. This paper also explains our future studies related to TestSpark and our preliminary results. Demo video: https://youtu.be/0F4PrxWfiXo},
booktitle = {Proceedings of the 2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings},
pages = {30–34},
numpages = {5},
keywords = {unit test generation, intellij idea plugin, large language models},
location = {Lisbon, Portugal},
series = {ICSE-Companion '24}
}

@inproceedings{10.1145/3626252.3630832,
author = {Sakzad, Amin and Paul, David and Sheard, Judithe and Brankovic, Ljiljana and Skerritt, Matthew P. and Li, Nan and Minagar, Sepehr and Simon and Billingsley, William},
title = {Diverging assessments: What, Why, and Experiences},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630832},
doi = {10.1145/3626252.3630832},
abstract = {In this experience paper, we introduce the concept of 'diverging assessments', process-based assessments designed so that they become unique for each student while all students see a common skeleton. We present experiences with diverging assessments in the contexts of computer networks, operating systems, ethical hacking, and software development. All the given examples allow the use of generative-AI-based tools, are authentic, and are designed to generate learning opportunities that foster students' meta-cognition. Finally, we reflect upon these experiences in five different courses across four universities, showing how diverging assessments enhance students' learning while respecting academic integrity.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1161–1167},
numpages = {7},
keywords = {assessment-as-learning, authentic assessment, diverging assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635618,
author = {Garcia, Leiny and Ojeda-Ramirez, Santiago and Warschauer, Mark},
title = {Restorying with AI Art among Latinx Elementary Students},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635618},
doi = {10.1145/3626253.3635618},
abstract = {The Latinx community is underrepresented in tech-oriented fields, which aligns with the lack of culturally relevant learning experiences in CS for Latinx youth, hindering their ability to conceptualize technology as a tool for transformation and vehicle for cultural expression. This study takes on a restorying approach at the elementary level, where 9 fourth-grade students engaged in focus group discussions over three days to generate prompts for a generative AI art. Through the lens of restorying, the prompts had students conceptualize a future with a focus on their Mexican-American heritage, local community, and technology. The study revealed that students associated their heritage with symbolic representations such as food and music, and characterized the community as a commercialized space while also emphasizing locations conducive to family-oriented activities. As a result, technology in community spaces was associated with consumerism. However, when envisioning a futuristic, transformed community, they made deeper connections between the role of technology in the community, making intricate connections between community improvements and technology-based solutions. This underscores the need for computing education to dedicate time for young learners to reflect on the role technology has on their current culture and community to make deeper connections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1648–1649},
numpages = {2},
keywords = {ai literacy, elementary school, heritage, latinx, restorying},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3613904.3642081,
author = {Bhattacharjee, Ananya and Zeng, Yuchen and Xu, Sarah Yi and Kulzhabayeva, Dana and Ma, Minyi and Kornfield, Rachel and Ahmed, Syed Ishtiaque and Mariakakis, Alex and Czerwinski, Mary P and Kuzminykh, Anastasia and Liut, Michael and Williams, Joseph Jay},
title = {Understanding the Role of Large Language Models in Personalizing and Scaffolding Strategies to Combat Academic Procrastination},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642081},
doi = {10.1145/3613904.3642081},
abstract = {Traditional interventions for academic procrastination often fail to capture the nuanced, individual-specific factors that underlie them. Large language models (LLMs) hold immense potential for addressing this gap by permitting open-ended inputs, including the ability to customize interventions to individuals’ unique needs. However, user expectations and potential limitations of LLMs in this context remain underexplored. To address this, we conducted interviews and focus group discussions with 15 university students and 6 experts, during which a technology probe for generating personalized advice for managing procrastination was presented. Our results highlight the necessity for LLMs to provide structured, deadline-oriented steps and enhanced user support mechanisms. Additionally, our results surface the need for an adaptive approach to questioning based on factors like busyness. These findings offer crucial design implications for the development of LLM-based tools for managing procrastination while cautioning the use of LLMs for therapeutic guidance.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {18},
keywords = {ChatGPT, Education, GPT-4, Large Language Models, Personalized Reflections, Procrastination},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3672393,
author = {Periti, Francesco and Montanelli, Stefano},
title = {Lexical Semantic Change through Large Language Models: a Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3672393},
doi = {10.1145/3672393},
abstract = {Lexical Semantic Change (LSC) is the task of identifying, interpreting, and assessing the possible change over time in the meanings of a target word. Traditionally, LSC has been addressed by linguists and social scientists through manual and time-consuming analyses, which have thus been limited in terms of the volume, genres, and time-frame that can be considered. In recent years, computational approaches based on Natural Language Processing have gained increasing attention to automate LSC as much as possible. Significant advancements have been made by relying on Large Language Models (LLMs), which can handle the multiple usages of the words and better capture the related semantic change. In this article, we survey the approaches based on LLMs for LSC, and we propose a classification framework characterized by three dimensions: meaning representation, time-awareness, and learning modality. The framework is exploited to (i) review the measures for change assessment, (ii) compare the approaches on performance, and (iii) discuss the current issues in terms of scalability, interpretability, and robustness. Open challenges and future research directions about the use of LLMs for LSC are finally outlined.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {282},
numpages = {38},
keywords = {Lexical semantics, lexical semantic change, semantic shift detection, large language models}
}

@inproceedings{10.1145/3626253.3635600,
author = {Chen, Xi and Liang, Jingsai},
title = {Pair Programming with ChatGPT},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635600},
doi = {10.1145/3626253.3635600},
abstract = {This poster explores the potential of ChatGPT to replace the traditional approach of pair programming in introductory computer science courses. Traditionally, two students collaborate as a driver and a navigator, periodically switching roles. Now, a student can pair up with ChatGPT, which offers an innovative approach to pair programming. This exploratory activity, which emphasizes collaboration and communication, provides step-by-step instructions for effectively interacting with ChatGPT during pair programming.This poster reflects on the advantages and limitations of using ChatGPT in pair programming. The main advantages of using ChatGPT include rapid responses, syntax error-free code generation, and flexibility in handling incomplete pseudocode. The primary limitations include the coding generation style, redundancy in responses, and challenges in understanding the code. Despite the advantages, it may still be valuable to have students work with human partners in certain situations, particularly for learning purposes.This poster proposes that ChatGPT is an invaluable tool for enhancing productivity and emphasizes the importance of becoming proficient in its use during students' college years. It also provides insights into the effective utilization of ChatGPT in pair programming and its preparation for future careers in programming and related fields.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1600–1601},
numpages = {2},
keywords = {chatgpt, pair programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3689535.3689553,
author = {Stone, Irene},
title = {Exploring Human-Centered Approaches in Generative AI and Introductory Programming Research: A Scoping Review},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689553},
doi = {10.1145/3689535.3689553},
abstract = {Recent advancements in generative artificial intelligence are poised to reshape introductory programming education, challenging conventional teaching methodologies. This paper presents a scoping review that explores the current understanding of integrating generative artificial intelligence tools in the learning of introductory programming. Through an analysis of 28 selected studies, this review provides a snapshot of the landscape in mid-2024, presenting benefits, concerns, and recommendations surrounding the use of generative artificial intelligence within programming education. It finds insufficient guidance on how to implement recommended pedagogical strategies, limited consideration of student perceptions and experiences, and a predominance of short study time frames. Additionally, there is a significant research gap in second-level education, particularly in the United Kingdom and Ireland. The paper discusses how these gaps signal a need for more human-centered approaches in the current research. The paper concludes with recommendations for future research, aiming to inspire further inquiry and advance the understanding of generative artificial intelligence’s role in programming education from a human-centered perspective.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {4},
numpages = {7},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, code generation, generative AI, human-centered, learner perspectives, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3613904.3642336,
author = {Cuadra, Andrea and Wang, Maria and Stein, Lynn Andrea and Jung, Malte F. and Dell, Nicola and Estrin, Deborah and Landay, James A.},
title = {The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642336},
doi = {10.1145/3613904.3642336},
abstract = {From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user’s experience, contrasting with their human counterparts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {446},
numpages = {18},
keywords = {AI, Affective Computing, Automation, Autonomous Agents, Chatbots, Conversational Agents, Conversational User Interfaces, Disability, Emotion, Empathy, Ethics, Gender, Health, Human-AI Interaction, Human-Computer Interaction, Identity, LLMs, Marginalization, Mental Health, Natural Language Processing, Personalization, Power and Privilege, Religion, Social Robots, Technological Harm, Ubiquitous Computing, User Experience Design, Values in Design, Voice Assistants, Wellbeing},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3652620.3687782,
author = {Lamas, Victor and R. Luaces, Miguel and Garcia-Gonzalez, Daniel},
title = {DSL-Xpert: LLM-driven Generic DSL Code Generation},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687782},
doi = {10.1145/3652620.3687782},
abstract = {Nowadays, large language models (LLMs) are an extremely useful and fast tool to complement and help in many jobs and current problems. However, there are cases where a pretty specific vocabulary is used in which these models were not previously trained, leading to less satisfactory results. More specifically, these models are less effective when dealing with less-known or unpublished domain-specific languages (DSLs). Within this field, the automatic generation of code based on such languages, starting from natural language, would speed up the development times of any related project, as well as the understanding of such DSLs. Therefore, this paper presents a tool in which developers can perform what is known as semantic parsing. In other words, the developer can ask a pre-trained LLM to translate a natural language instruction into the vocabulary of the established DSL. Thus, by setting the DSL grammar as context (grammar prompting) and providing usage examples (few-shot learning), the LLM can quickly generate reliable domain-specific code, significantly improving the quality of life of the developers. A video demonstration of the tool is shown in the following link: https://zenodo.org/records/12610506.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {16–20},
numpages = {5},
keywords = {domain-specific languages (DSLS), large language models (LLMS), semantic parsing, grammar prompting, few-shot learning},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3593342.3593360,
author = {Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin},
title = {Exploring ChatGPT’s impact on post-secondary education: A qualitative study},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593360},
doi = {10.1145/3593342.3593360},
abstract = {As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {6},
keywords = {Artificial Intelligence in education, ChatGPT, assessment, conversational AI, education, higher education, post-secondary},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

@inproceedings{10.1145/3643795.3648387,
author = {Li, Zhiming and Cao, Yushi and Xu, Xiufeng and Jiang, Junzhe and Liu, Xu and Teo, Yon Shin and Lin, Shang-Wei and Liu, Yang},
title = {LLMs for Relational Reasoning: How Far are We?},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648387},
doi = {10.1145/3643795.3648387},
abstract = {Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs' reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting1.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {119–126},
numpages = {8},
keywords = {large language models, relational reasoning, program induction},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00075,
author = {Ronanki, Krishna},
title = {Towards an AI-Centric Requirements Engineering Framework for Trustworthy AI},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00075},
doi = {10.1109/ICSE-Companion58688.2023.00075},
abstract = {Ethical guidelines are an asset for artificial intelligence(AI) development and conforming to them will soon be a procedural requirement once the EU AI Act gets ratified in the European parliament. However, developers often lack explicit knowledge on how to apply these guidelines during the system development process. A literature review of different ethical guidelines from various countries and organizations has revealed inconsistencies in the principles presented and the terminology used to describe such principles. This research begins by identifying the limitations of existing ethical AI development frameworks in performing requirements engineering(RE) processes during the development of trustworthy AI. Recommendations to address those limitations will be proposed to make the frameworks more applicable in the RE process to foster the development of trustworthy AI. This could lead to wider adoption, greater productivity of the AI systems, and reduced workload on humans for non-cognitive tasks. Considering the impact of some of the newer foundation models like GitHub Copilot and ChatGPT, the vision for this research project is to work towards the development of holistic operationalisable RE guidelines for the development and implementation of trustworthy AI not only on a product level but also on process level.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {278–280},
numpages = {3},
keywords = {trustworthy AI, EU AI act, requirements engineering, frameworks, AI co-worker, ethical AI, guidelines},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3640471.3680444,
author = {Deldari, Shohreh and Goudarzi, Mohammad and Joshi, Aditya and Shaghaghi, Arash and Finn, Simon and Salim, Flora D. and Jha, Sanjay},
title = {AuditNet: Conversational AI Security Assistant},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680444},
doi = {10.1145/3640471.3680444},
abstract = {In the age of information overload, professionals across various fields face the challenge of navigating vast amounts of documentation and ever-evolving standards. Ensuring compliance with standards, regulations, and contractual obligations is a critical yet complex task across various professional fields. We propose a versatile conversational AI assistant framework designed to facilitate compliance checking on the go, in diverse domains, including but not limited to network infrastructure, legal contracts, educational standards, environmental regulations, and government policies. By leveraging retrieval-augmented generation using large language models, our framework automates the review, indexing, and retrieval of relevant, context-aware information, streamlining the process of verifying adherence to established guidelines and requirements. This AI assistant not only reduces the manual effort involved in compliance checks but also enhances accuracy and efficiency, supporting professionals in maintaining high standards of practice and ensuring regulatory compliance in their respective fields. We propose and demonstrate AuditNet, the first conversational AI security assistant designed to assist IoT network security experts by providing instant access to security standards, policies, and regulations.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {22},
numpages = {4},
keywords = {Prompt Engineering, Question Answering, Retrieval-Augmented Generation},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@inproceedings{10.1145/3626253.3635432,
author = {Edwards, Katlyn and Scalisi, Corrie and DeMars-Smith, Julianne and Lee, Key},
title = {Google Colab for Teaching CS and ML},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635432},
doi = {10.1145/3626253.3635432},
abstract = {Colab is a frictionless, hosted Jupyter notebook that combines text, code, and outputs into a single document. Colab allows anybody to write and execute arbitrary python code using the latest ML accelerators (GPU/TPUs) through the browser, no setup required. It is especially well suited to machine learning, data analysis and education, and serves over 10 million active users. Colab is used extensively for teaching computer science and machine learning, giving equitable access to expensive resources and AI/ML instruction to students around the world, regardless of background. As one professor stated: ''There's an equity aspect. Not everyone has a high-end laptop. Being able to say everyone has the same computing experience and they all have access to the same resources and they can start using them right away, it allows us to find more talent randomly distributed around our student population. Colab has been the best solution so far.'' Additionally, Google Colab partners with Google DeepMind to launch innovative AI coding features and models to the public, giving users the ability to author code with natural language, a much simpler experience for writing code. We are the team who builds Colab, and would love to demo our latest features, including Google Classroom integration and AI coding using Gemini, Google's latest foundation AI model. We hope to make attendees aware of these features and have them give us feedback on their usefulness and impact on the process of teaching computer science and machine learning.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1925},
numpages = {1},
keywords = {ai, colab, jupyter},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3586182.3625219,
author = {Itagaki, Toma and Li, Richard},
title = {Smart-Pikachu: Extending Interactivity of Stuffed Animals with Large Language Models},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3625219},
doi = {10.1145/3586182.3625219},
abstract = {We propose Smart-Pikachu, a stuffed animal equipped with sensing and actuation to explore the use of large language models (LLM’s) with sensor data inputs. The augmentation of pressure sensing will allow for the LLM to interpret various interactions such as hugs and handshakes with the user. Furthermore, the actuation capabilities will extend our system’s interactivity by providing physical feedback to the user. We will also incorporate text-to-speech output from the LLM to add another mode of interaction between the system and user. In this Student Innovation Challenge, we intend to explore applications at the intersection of sensing and interaction through LLM’s and demonstrate an extension of LLMs’ multimodal capabilities.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {114},
numpages = {2},
keywords = {Empathetic Computing, Prompt Design},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@inproceedings{10.1145/3654777.3676450,
author = {Shankar, Shreya and Zamfirescu-Pereira, J.D. and Hartmann, Bjoern and Parameswaran, Aditya and Arawjo, Ian},
title = {Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676450},
doi = {10.1145/3654777.3676450},
abstract = {Due to the cumbersome nature of human evaluation and limitations of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply inherit all the problems of the LLMs they evaluate, requiring further human validation. We present a mixed-initiative approach to “validate the validators”—aligning LLM-generated evaluation functions (be it prompts or code) with human requirements. Our interface, EvalGen, provides automated assistance to users in generating evaluation criteria and implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks humans to grade a subset of LLM outputs; this feedback is used to select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores the subjectivity and iterative nature of alignment. In particular, we identify a phenomenon we dub criteria drift: users need criteria to grade outputs, but grading outputs helps users define criteria. What is more, some criteria appear dependent on the specific LLM outputs observed (rather than independent and definable a priori), raising serious questions for approaches that assume the independence of evaluation from observation of model outputs. We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {131},
numpages = {14},
keywords = {active learning, auditing, evaluation, interfaces, language models, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3661167.3661171,
author = {Vallecillos Ruiz, Fernando},
title = {Agent-Driven Automatic Software Improvement},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661171},
doi = {10.1145/3661167.3661171},
abstract = {With software maintenance accounting for 50% of the cost of developing software, enhancing code quality and reliability has become more critical than ever. In response to this challenge, this doctoral research proposal aims to explore innovative solutions by focusing on the deployment of agents powered by Large Language Models (LLMs) to perform software maintenance tasks. The iterative nature of agents, which allows for continuous learning and adaptation, can help surpass common challenges in code generation. One distinct challenge is the last-mile problems, errors at the final stage of producing functionally and contextually relevant code. Furthermore, this project aims to surpass the inherent limitations of current LLMs in source code through a collaborative framework where agents can correct and learn from each other’s errors. We aim to use the iterative feedback in these systems to further fine-tune the LLMs underlying the agents, becoming better aligned to the task of automated software improvement. Our main goal is to achieve a leap forward in the field of automatic software improvement by developing new tools and frameworks that can enhance the efficiency and reliability of software development.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {470–475},
numpages = {6},
keywords = {Automatic Maintenance, Automatic Software Improvement, LLM-based Agents, ML4Code, Multi-Agent Systems},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3638067.3638100,
author = {Freire, Andr\'{e} Pimenta and Cardoso, Paula Christina Figueira and Salgado, Andr\'{e} de Lima},
title = {May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638100},
doi = {10.1145/3638067.3638100},
abstract = {Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {6},
numpages = {11},
keywords = {ChatGPT, HCI education, evaluation, open-book exams},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3657604.3664699,
author = {Hutt, Stephen and Hieb, Grayson},
title = {Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664699},
doi = {10.1145/3657604.3664699},
abstract = {Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {310–314},
numpages = {5},
keywords = {content evaluation, content generation, generative ai, large language models, mastery learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3632620.3671116,
author = {Prather, James and Reeves, Brent N and Leinonen, Juho and MacNeil, Stephen and Randrianasolo, Arisoa S and Becker, Brett A. and Kimmel, Bailey and Wright, Jared and Briggs, Ben},
title = {The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671116},
doi = {10.1145/3632620.3671116},
abstract = {Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {469–486},
numpages = {18},
keywords = {CS1, ChatGPT, Copilot, generative AI, large language models, metacognition},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3544548.3580885,
author = {Jones, Mirabelle and Neumayer, Christina and Shklovski, Irina},
title = {Embodying the Algorithm: Exploring Relationships with Large Language Models Through Artistic Performance},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580885},
doi = {10.1145/3544548.3580885},
abstract = {Despite the proliferation of research on how people engage with and experience algorithmic systems, the materiality and physicality of these experiences is often overlooked. We tend to forget about bodies. The Embodying the Algorithm1 project worked with artists to explore the experience of translating algorithmically produced performance instructions through human bodies. As performers interpreted the rules of engagement produced by GPT-3, they struggled with the lack of consideration the rules showed for the limits of the human body. Performers made sense of their experience through personification, reflexivity, and interpretation, which gave rise to three modes of relating with the algorithm – agonistic, perfunctory, and agreeable. We demonstrate that collaboration with algorithmic systems is ultimately impossible as people can only relate to algorithmic systems (a one-way relation) due to the material limitations of algorithmic systems for reciprocity, understanding, and consideration for the human body.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {654},
numpages = {24},
keywords = {Algorithms, Embodiment, GPT-3, Human-Computer Interaction},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3568813.3600138,
author = {Lau, Sam and Guo, Philip},
title = {From "Ban It Till We Understand It" to "Resistance is Futile": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600138},
doi = {10.1145/3568813.3600138},
abstract = {Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {106–121},
numpages = {16},
keywords = {AI coding tools, ChatGPT, Copilot, LLM, instructor perspectives},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3690712.3690720,
author = {Jelson, Andrew and Lee, Sang Won},
title = {An empirical study to understand how students use ChatGPT for writing essays and how it affects their ownership},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690712.3690720},
doi = {10.1145/3690712.3690720},
abstract = {As large language models (LLMs) become more powerful and ubiquitous, systems like ChatGPT are increasingly used by students to help them with writing tasks. To better understand how these tools are used, we investigate how students might use an LLM for essay writing, for example, to study the queries asked to ChatGPT and the responses that ChatGPT gives. To that end, we plan to conduct a user study that will record the user writing process and present them with the opportunity to use ChatGPT as an AI assistant. This study’s findings will help us understand how these tools are used and how practitioners — such as educators and essay readers — should consider writing education and evaluation based on essay writing.},
booktitle = {Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
pages = {26–30},
numpages = {5},
location = {Honolulu, HI, USA},
series = {In2Writing '24}
}

@inproceedings{10.5555/3615924.3615927,
author = {Nascimento, Nathalia and Alencar, Paulo and Cowan, Donald},
title = {Artificial Intelligence vs. Software Engineers: An Empirical Study on Performance and Efficiency using ChatGPT},
year = {2023},
publisher = {IBM Corp.},
address = {USA},
abstract = {In the realm of Software Engineering (SE), automation has become a tangible reality. Artificial Intelligence (AI) has suc-cessfully addressed challenges in project management, mod-eling, testing, and development. Among the latest innova-tions is ChatGPT, an ML-infused chatbot capable of gen-erating programming codes and software testing strategies. Although there is speculation that AI-based computation can boost productivity and even substitute software engineers in software development, empirical evidence supporting such claims is lacking. Moreover, questions remain about their po-tential to address overlooked evaluation metrics like energy efficiency, vulnerability, fairness (i.e., human bias), and safety. This paper probes into these issues with an empirical study, comparing ChatGPT with both novice and expert program-mers using LeetCode contest problems. The investigation focuses on performance and memory-efficiency, while also acknowledging the need for a broader assessment of non-functional requirements. The results suggest that ChatGPT is better than beginners at solving easy and medium prob-lems, but it is not yet proven to beat expert programmers. This paper posits that a comprehensive comparison of soft-ware engineers and AI-based solutions, considering various evaluation criteria, is pivotal in fostering human-machine collaboration, enhancing the reliability of AI-based meth-ods, and understanding task suitability for humans or AI. Furthermore, it facilitates the effective implementation of co-operative work structures and human-in-the-loop processes.},
booktitle = {Proceedings of the 33rd Annual International Conference on Computer Science and Software Engineering},
pages = {24–33},
numpages = {10},
keywords = {Software Engineering, AI-based solutions, Performance Evaluation, ChatGPT, Machine Learning},
location = {Las Vegas, NV, USA},
series = {CASCON '23}
}

@inproceedings{10.1145/3643991.3645072,
author = {Grewal, Balreet and Lu, Wentao and Nadi, Sarah and Bezemer, Cor-Paul},
title = {Analyzing Developer Use of ChatGPT Generated Code in Open Source GitHub Projects},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645072},
doi = {10.1145/3643991.3645072},
abstract = {The rapid development of large language models such as ChatGPT have made them particularly useful to developers in generating code snippets for their projects. To understand how ChatGPT's generated code is leveraged by developers, we conducted an empirical study of 3,044 ChatGPT-generated code snippets integrated within GitHub projects. A median of 54% of the generated lines of code is found in the project's code and this code typically remains unchanged once added. The modifications of the 76 code snippets that changed in a subsequent commit, consisted of minor functionality changes and code reorganizations that were made within a day. Our findings offer insights that help drive the development of AI-assisted programming tools. We highlight the importance of making changes in ChatGPT code before integrating it into a project.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {157–161},
numpages = {5},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3640457.3688023,
author = {Petruzzelli, Alessandro},
title = {Towards Symbiotic Recommendations: Leveraging LLMs for Conversational Recommendation Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688023},
doi = {10.1145/3640457.3688023},
abstract = {Traditional recommender systems (RSs) generate suggestions by relying on user preferences and item characteristics. However, they do not to properly involve the user in the decision-making process. This gap is particularly evident in Conversational Recommender Systems (CRSs), where existing methods struggle to facilitate meaningful dialogue and dynamic user interactions. To address this limitation, in my Ph.D. project I will ground on the principles of Symbiotic AI (SAI) to propose a novel approach for CRS. Rather than treating users as passive recipients, this approach aims to engage them in an adaptive dialogue based on their preferences, previous interactions, and personal characteristics, thus fostering collaborative decision-making. To achieve this objective, my research unfolds in three phases. First, I will adapt Large Language Models (LLMs) to effectively handle recommendation tasks in a number of different domains, by also introducing knowledge injection techniques. Second, I will develop a CRS that not only provides accurate recommendations but also offers natural language explanations and responds to user queries, thereby promoting transparency and building user trust. Finally, I will consider users’ personal characteristics to personalize the CRS’s response strategy, ensuring adaptive and effective communication in line with SAI principles.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {1361–1367},
numpages = {7},
keywords = {Conversational Recommender System, Large Language Models. LLM, Recommender Systems, Symbiotic AI},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3633083.3633220,
author = {Shaka, Martha and Carraro, Diego and Brown, Kenneth N.},
title = {Personalised Programming Education with Knowledge Tracing},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633220},
doi = {10.1145/3633083.3633220},
abstract = {In traditional programming education, addressing diverse student needs and providing effective and scalable learning experiences is challenging. Conventional methods struggle to adapt to varying learning styles and offer personalised feedback. AI-based Programming Tools (AIPTs) have shown promise in automating feedback, simplifying programming concepts, and guiding students. Their widespread adoption is hindered by limitations related to accuracy, explanation, and personalisation. Conversely, AIPTs tailored for expert programmers, such as ChatGPT and Copilot, have gained popularity for their productivity-enhancing capabilities, but they still fall short in terms of personalisation, neglecting individual students’ unique knowledge and skills. Our research aims to leverage AI to create AIPTs that offer personalised feedback through adaptive learning, accommodating diverse student backgrounds and proficiency levels. In particular, we explore using Knowledge Tracing (KT) to anticipate specific syntax errors in programming assignments, addressing the challenges novices face in acquiring syntactical knowledge. The findings suggest the KT’s potential to transform programming education by enabling timely interventions for students dealing with specific errors or misconceptions, automating personalised feedback, and informing tailored instructional strategies.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {47},
numpages = {1},
keywords = {Automated Feedback, Knowledge Tracing, Personalisation, Programming Assignments, Syntax Errors},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3686852.3686887,
author = {Chhetri, Chola},
title = {Exploring Large Language Model-Powered Pedagogical Approaches to Cybersecurity Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3686887},
doi = {10.1145/3686852.3686887},
abstract = {The adoption of artificial intelligence (AI) technologies by businesses and corporations is rising. AI technologies continue to be adopted in cybersecurity for both defensive and offensive strategies. However, threat actors also persist in utilizing these technologies to enhance the speed, accuracy, and sophistication of their attacks. Hence, it is essential to train the next generation of cybersecurity learners not only on how to use AI technology but also on how to leverage these technologies to enhance the efficiency of their work. This extended abstract describes our exploratory work on the use of generative AI-based pedagogical approaches in cybersecurity education. This extended abstract will describe some preliminary findings on large language model-powered pedagogical approaches to cybersecurity education and training. These approaches will help cybersecurity educators enhance their teaching methods to equip learners with the essential skills needed to succeed in the dynamic field of cybersecurity.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {163–166},
numpages = {4},
keywords = {AI, Artificial intelligence, GenAI, LLM, cybersecurity, education., generative AI, large language models},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3649165.3699863,
author = {Bailey, Cynthia},
title = {Artificial Intelligence Policy: What Computing Educators and Students Should Know},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3699863},
doi = {10.1145/3649165.3699863},
abstract = {Catalyzed by the release of ChatGPT by OpenAI in November 2022, policymakers worldwide have launched a surge of activity surrounding artificial intelligence (AI). The legal and policy frameworks emerging from this concentrated period of attention may shape AI governance for decades to come. This keynote will examine the implications of these global AI policy debates for computing educators and their students.  Drawing on the speaker's dual experience as a computing educator and AI policy adviser within the United States Senate, this presentation will explore the developing threads of AI policy that educators should integrate into their curricula to prepare students for an evolving socio-technical landscape.  The talk will present an overview of significant AI policy developments, including the European Union's AI Act, the over 120 AI-related bills currently pending in the United States Congress, and the United Arab Emirates' launch of a state-of-the-art open-source AI model. These examples will be contextualized within the history of how the current active regulatory stance diverges from prior approaches to technologies like the internet and social media, and consider the potential implications of this shift.  Equally important to understanding how AI policy is evolving is understanding why. Many legislative efforts are driven by concerns about AI's potential to exacerbate societal harms, such as election misinformation, cybersecurity threats, nonconsensual sexual imagery, weapons development, data privacy violations, intellectual property appropriation, labor market disruptions, and algorithmic biases. Coupled with these concerns is a widespread skepticism toward the tech industry's capacity for responsible self-governance. This context underscores the need for computing educators to engage students on issues of policy, ethics, and justice throughout the curriculum, to cultivate future professionals who can earn public trust and who appreciate the role of governments in establishing balance between innovation and safety guardrails.  Finally, the talk will offer reflections on the experience of serving as a technical adviser to policymakers, and advocate for computing educators to consider public service engagement on AI policy as a compelling career trajectory for themselves and their students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {1–2},
numpages = {2},
keywords = {ai, artificial intelligence, ethics, government, policy, social impact},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3624032.3624035,
author = {Guilherme, Vitor and Vincenzi, Auri},
title = {An initial investigation of ChatGPT unit test generation capability},
year = {2023},
isbn = {9798400716294},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624032.3624035},
doi = {10.1145/3624032.3624035},
abstract = {Context: Software testing ensures software quality, but developers often disregard it. The use of automated testing generation is pursued to reduce the consequences of overlooked test cases in a software project. Problem: In the context of Java programs, several tools can completely automate generating unit test sets. Additionally, studies are conducted to offer evidence regarding the quality of the generated test sets. However, it is worth noting that these tools rely on machine learning and other AI algorithms rather than incorporating the latest advancements in Large Language Models (LLMs). Solution: This work aims to evaluate the quality of Java unit tests generated by an OpenAI LLM algorithm, using metrics like code coverage and mutation test score. Method: For this study, 33 programs used by other researchers in the field of automated test generation were selected. This approach was employed to establish a baseline for comparison purposes. For each program, 33 unit test sets were generated automatically, without human interference, by changing Open AI API parameters. After executing each test set, metrics such as code line coverage, mutation score, and success rate of test execution were collected to evaluate the efficiency and effectiveness of each set. Summary of Results: Our findings revealed that the OpenAI LLM test set demonstrated similar performance across all evaluated aspects compared to traditional automated Java test generation tools used in the previous research. These results are particularly remarkable considering the simplicity of the experiment and the fact that the generated test code did not undergo human analysis.},
booktitle = {Proceedings of the 8th Brazilian Symposium on Systematic and Automated Software Testing},
pages = {15–24},
numpages = {10},
keywords = {automated test generation, coverage testing, experimental software engineering, mutation testing, software testing, testing tools},
location = {Campo Grande, MS, Brazil},
series = {SAST '23}
}

@inproceedings{10.1145/3627673.3679665,
author = {Chen, Yulin and Ding, Ning and Zheng, Hai-Tao and Liu, Zhiyuan and Sun, Maosong and Zhou, Bowen},
title = {Empowering Private Tutoring by Chaining Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679665},
doi = {10.1145/3627673.3679665},
abstract = {Artificial intelligence has been applied in various aspects of online education to facilitate teaching and learning. However, few approaches have been made towards a complete AI-powered tutoring system. In this work, we explore the development of a full-fledged intelligent tutoring system based on large language models (LLMs). The proposed system ChatTutor, powered by state-of-the-art LLMs, is equipped with automatic course planning and adjusting, informative instruction, and adaptive quiz offering and evaluation. ChatTutor is decomposed into three inter-connected core processes: interaction, reflection, and reaction. Each process is implemented by chaining LLM-powered tools along with dynamically updated memory modules. To demonstrate the mechanism of each working module and the benefits of structured memory control and adaptive reflection, we conduct a wide range of analysis based on statistical results and user study. The analysis shows the designed processes boost system consistency and stability under long-term interaction and intentional disruptions, with up to 5% and 20% increase in performance respectively. Meanwhile, we also compare the system with scripts from real-world online learning platform and discuss the potential issues unique to LLM-based systems.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {354–364},
numpages = {11},
keywords = {adaptive reflection, intelligent tutoring system, large language models, memory mechanism},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3639701.3656324,
author = {Park, Jimin and Lee, Chaerin and Cho, Eunbin and Oh, Uran},
title = {Enhancing the Podcast Browsing Experience through Topic Segmentation and Visualization with Generative AI},
year = {2024},
isbn = {9798400705038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639701.3656324},
doi = {10.1145/3639701.3656324},
abstract = {Podcasts present challenges in information retrieval due to their non-visual nature and extended length. To understand these challenges, we conducted interviews with 12 podcast users and identified difficulties in grasping the overall podcast content with metadata alone, highlighting the necessity of navigating to specific segments. Based on this finding, we propose a browsing method that utilizes Large Language Models (LLMs) and image generation models to segment podcast contents, integrating visual cues for supporting efficient navigation. To investigate how this new method differs from conventional approaches and to evaluate its effectiveness, we conducted another user study with 12 participants. The results revealed that keyword search is ineffective when dealing with unfamiliar or inaccurate keywords. Additionally, it requires thorough examination of the script to comprehend the overall content of each episode. On the other hand, segmenting the contents and labeling the topic for each segment facilitated was found to be helpful for understanding of the overall content, enabling easy navigation to desired topics. Furthermore, we found that providing an image enabled participants to easily distinguish one segment from another, which was preferred by participants. This multimodal browsing approach is expected to establish a foundational framework for the effective browsing and comprehension of audio content, extending its applicability beyond podcasts to various forms of audio files.},
booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences},
pages = {117–128},
numpages = {12},
keywords = {Audio Content Browsing, Content Visualization, Generative AI, Podcast},
location = {Stockholm, Sweden},
series = {IMX '24}
}

@inproceedings{10.1145/3643991.3645083,
author = {Das, Joy Krishan and Mondal, Saikat and Roy, Chanchal},
title = {Investigating the Utility of ChatGPT in the Issue Tracking System: An Exploratory Study},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3645083},
doi = {10.1145/3643991.3645083},
abstract = {Issue tracking systems serve as the primary tool for incorporating external users and customizing a software project to meet the users' requirements. However, the limited number of contributors and the challenge of identifying the best approach for each issue often impede effective resolution. Recently, an increasing number of developers are turning to AI tools like ChatGPT to enhance problem-solving efficiency. While previous studies have demonstrated the potential of ChatGPT in areas such as automatic program repair, debugging, and code generation, there is a lack of study on how developers explicitly utilize ChatGPT to resolve issues in their tracking system. Hence, this study aims to examine the interaction between ChatGPT and developers to analyze their prevalent activities and provide a resolution. In addition, we assess the code reliability by confirming if the code produced by ChatGPT was integrated into the project's codebase using the clone detection tool NiCad. Our investigation reveals that developers mainly use ChatGPT for brainstorming solutions but often opt to write their code instead of using ChatGPT-generated code, possibly due to concerns over the generation of "hallucinated" code, as highlighted in the literature.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {217–221},
numpages = {5},
keywords = {ChatGPT, issue tracking, NiCad, code clone},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3699538.3699580,
author = {Kiesler, Natalie and Scholz, Ingo and Albrecht, Jens and Stappert, Friedhelm and Wienkop, Uwe},
title = {Novice Learners of Programming and Generative AI - Prior Knowledge Matters},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699580},
doi = {10.1145/3699538.3699580},
abstract = {With the broad availability of Generative AI (GenAI), introductory programming education is starting to change. At Nuremberg Tech, we observed the doubling of failure rates to approximately 50% in the first semester course “Procedural Programming” across students of all study programs. Due to these exam results in winter 2023/24, we conducted a pilot study to gather students’ use of GenAI tools, their exam results, and prior programming education and experience. The results imply significant differences of students’ use of GenAI tools depending on their prior programming education. We will therefore extend the investigation in winter term 2024/25.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {51},
numpages = {2},
keywords = {GenAI, student success, programming education, introductory programming, use pattern},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3613905.3636293,
author = {Prpa, Mirjana and Troiano, Giovanni Maria and Wood, Matthew and Coady, Yvonne},
title = {Challenges and Opportunities of LLM-Based Synthetic Personae and Data in HCI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636293},
doi = {10.1145/3613905.3636293},
abstract = {Synthetic personae and data powered by artificial intelligence (AI) are emerging in many HCI areas, including education and training, gaming, and piloting research studies. Recently, Large Language Models (LLMs) have shown promise for synthetic AI personae, experimenting with human and social simulacra and producing synthetic data. This presents challenges and opportunities for extending HCI research via LLMs and AI. In this proposed workshop, we engage HCI researchers interested in working with LLMs, synthetic personae, and synthetic data through speculative design and producing visions, desiderata, and requirements for future HCI research engaging with synthetic personae/data. The outcomes of this workshop may be disseminated to the HCI community through scientific publications or special issues to facilitate continued discussion and advance knowledge on a timely HCI topic.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {461},
numpages = {5},
keywords = {AI, Large Language Models, sketching, speculative design, synthetic data, synthetic personae},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3610977.3634970,
author = {Holk, Simon and Marta, Daniel and Leite, Iolanda},
title = {PREDILECT: Preferences Delineated with Zero-Shot Language-based Reasoning in Reinforcement Learning},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634970},
doi = {10.1145/3610977.3634970},
abstract = {Preference-based reinforcement learning (RL) has emerged as a new field in robot learning, where humans play a pivotal role in shaping robot behavior by expressing preferences on different sequences of state-action pairs. However, formulating realistic policies for robots demands responses from humans to an extensive array of queries. In this work, we approach the sample-efficiency challenge by expanding the information collected per query to contain both preferences and optional text prompting. To accomplish this, we leverage the zero-shot capabilities of a large language model (LLM) to reason from the text provided by humans. To accommodate the additional query information, we reformulate the reward learning objectives to contain flexible highlights -- state-action pairs that contain relatively high information and are related to the features processed in a zero-shot fashion from a pretrained LLM. In both a simulated scenario and a user study, we reveal the effectiveness of our work by analyzing the feedback and its implications. Additionally, the collective feedback collected serves to train a robot on socially compliant trajectories in a simulated social navigation landscape. We provide video examples of the trained policies at https://sites.google.com/view/rl-predilect},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {259–268},
numpages = {10},
keywords = {human-in-the-loop learning, interactive learning, preference learning, reinforcement learning},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3613904.3641965,
author = {Calle, Paul and Shao, Ruosi and Liu, Yunlong and H\'{e}bert, Emily T and Kendzor, Darla and Neil, Jordan and Businelle, Michael and Pan, Chongle},
title = {Towards AI-Driven Healthcare: Systematic Optimization, Linguistic Analysis, and Clinicians’ Evaluation of Large Language Models for Smoking Cessation Interventions},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641965},
doi = {10.1145/3613904.3641965},
abstract = {Creating intervention messages for smoking cessation is a labor-intensive process. Advances in Large Language Models (LLMs) offer a promising alternative for automated message generation. Two critical questions remain: 1) How to optimize LLMs to mimic human expert writing, and 2) Do LLM-generated messages meet clinical standards? We systematically examined the message generation and evaluation processes through three studies investigating prompt engineering (Study 1), decoding optimization (Study 2), and expert review (Study 3). We employed computational linguistic analysis in LLM assessment and established a comprehensive evaluation framework, incorporating automated metrics, linguistic attributes, and expert evaluations. Certified tobacco treatment specialists assessed the quality, accuracy, credibility, and persuasiveness of LLM-generated messages, using expert-written messages as the benchmark. Results indicate that larger LLMs, including ChatGPT, OPT-13B, and OPT-30B, can effectively emulate expert writing to generate well-written, accurate, and persuasive messages, thereby demonstrating the capability of LLMs in augmenting clinical practices of smoking cessation interventions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {436},
numpages = {16},
keywords = {Computational Linguistic Analysis, Expert Review, Large Language Model, Message Generation, Smoking Cessation Intervention},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613905.3650799,
author = {Elahimanesh, Sina and Mohammadi, Iman and Mosayebi, Mohammad and Zahedi Movahed, Sara and Hasani, Hosein and Rohban, Mohammad Hossein},
title = {User Voices, Platform Choices: Social Media Policy Puzzle with Decentralization Salt},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650799},
doi = {10.1145/3613905.3650799},
abstract = {In the current digital era, social media platforms wield crucial influence, with the potential for biased content moderation. Considering this risk, we propose a decentralized social media policy-making in this work. The noticeable difference between people’s preferences and X’s established policies in a preliminary study motivates us to design a similar website to collect more comprehensive data in a diverse community. Consequently, N=110 individuals from diverse backgrounds participated in our primary experiment to decide about content moderation on social media. For this purpose, 546 tweets in 3 categories are investigated, 3032 records are captured, and the effect of personal favor on content moderation is analyzed. Furthermore, we propose a novel AI-based method to learn the recommended policy of participants and achieve an accuracy of 79%. Also, by considering the suggested policy of 5 Large Language Models, it is illustrated that they cannot be the decision-makers on democratic social media platforms.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {360},
numpages = {10},
keywords = {Content Censorship, Decentralization, Decentralized Policy, Social Media, Social Network},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3656650.3656747,
author = {Gargioni, Luigi},
title = {Emerging approaches to human-robot collaboration in healthcare},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656747},
doi = {10.1145/3656650.3656747},
abstract = {Collaborative robots can enhance productivity and efficiency in healthcare. This PhD project aims to investigate new methods and tools for effective interaction with these robots, focusing on programming techniques accessible to domain experts without a background in computer science or robotics. Automating repetitive tasks can allow healthcare professionals to dedicate more attention to critical procedures. For instance, this technology can enhance therapy efficiency and personalized medicine preparation, benefiting patient outcomes. The research will investigate the use of Large Language Models to simplify and optimize robot task programming, reducing the need for technical expertise.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {110},
numpages = {3},
keywords = {Collaborative Robots, End-User Development, Human-Robot Collaboration, Large Language Models},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@article{10.1145/3660809,
author = {Oueslati, Khouloud and Laberge, Gabriel and Lamothe, Maxime and Khomh, Foutse},
title = {Mining Action Rules for Defect Reduction Planning},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660809},
doi = {10.1145/3660809},
abstract = {Defect reduction planning plays a vital role in enhancing software quality and minimizing software maintenance costs. By training a black box machine learning model and “explaining” its predictions, explainable AI for software engineering aims to identify the code characteristics that impact maintenance risks. However, post-hoc explanations do not always faithfully reflect what the original model computes. In this paper, we introduce CounterACT, a Counterfactual ACTion rule mining approach that can generate defect reduction plans without black-box models. By leveraging action rules, CounterACT provides a course of action that can be considered as a counterfactual explanation for the class (e.g., buggy or not buggy) assigned to a piece of code. We compare the effectiveness of CounterACT with the original action rule mining algorithm and six established defect reduction approaches on 9 software projects. Our evaluation is based on (a) overlap scores between proposed code changes and actual developer modifications; (b) improvement scores in future releases; and (c) the precision, recall, and F1-score of the plans. Our results show that, compared to competing approaches, CounterACT’s explainable plans achieve higher overlap scores at the release level (median 95%) and commit level (median 85.97%), and they offer better trade-off between precision and recall (median F1-score 88.12%). Finally, we venture beyond planning and explore leveraging Large Language models (LLM) for generating code edits from our generated plans. Our results show that suggested LLM code edits supported by our plans are actionable and are more likely to pass relevant test cases than vanilla LLM code recommendations.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {102},
numpages = {23},
keywords = {Action rule mining, Counterfactual explanations, Defect reduction planning, Explainability, Software analytics}
}

@article{10.5555/3715622.3715630,
author = {Lindoo, Ed and Lotfy, Mohamed},
title = {Generative AI and its Impact on the CS Classroom and Programmers},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {As the integration of generative artificial intelligence (AI) in educational settings becomes more widespread, students, teachers, and educational institutions face the challenge of utilizing these technologies in a responsible manner. The responsible use of generative AI can help CS and IT students develop critical thinking, enhance their learning experience, facilitate the learning process, can assist in understanding code concepts, programming skills, and/or enhancing the programming knowledge. The aim of this investigation is on how students might utilize, and potentially abuse, generative AI. In this paper we provide examples of how generative AI can be used to generate code modules. We discuss the use of generative AI in programming classes as well as its impact on the future of programming and programmers.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {35–50},
numpages = {16}
}

@inproceedings{10.1145/3662739.3664740,
author = {Zhan, Liuchun and Huang, Changjiang},
title = {Research on Computer Intelligent ChatGPT Natural Language Processing System Based on Scientific Knowledge Graph},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3662739.3664740},
doi = {10.1145/3662739.3664740},
abstract = {A synonym mining method is proposed by combining the character vector graph and noise robust learning method. The model uses paired word vectors pre-trained by ChatGPT to enhance entity semantic representation. Classify marks with noise. Then the cross optimal processing is carried out to identify the true and false marks. The two-layer construction system of knowledge extraction and knowledge fusion is constructed to realize the independent construction and answer of software engineering questions. The system effectively improves the efficiency of software project understanding and software reuse.},
booktitle = {Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
pages = {47–51},
numpages = {5},
keywords = {ChatGPT, Software knowledge extraction, Natural language processing system, Software knowledge graph},
location = {Ningbo, China},
series = {MIDA '24}
}

@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3613904.3642580,
author = {Lee, Jungeun and Yoon, Suwon and Lee, Kyoosik and Jeong, Eunae and Cho, Jae-Eun and Park, Wonjeong and Yim, Dongsun and Hwang, Inseok},
title = {Open Sesame? Open Salami! Personalizing Vocabulary Assessment-Intervention for Children via Pervasive Profiling and Bespoke Storybook Generation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642580},
doi = {10.1145/3613904.3642580},
abstract = {Children acquire language by interacting with their surroundings. Due to the different language environments each child is exposed to, the words they encounter and need in their life vary. Despite the standard tools for assessment and intervention as per predefined vocabulary sets, speech-language pathologists and parents struggle with the absence of systematic tools for child-specific custom vocabulary, i.e., out-of-standard but personally more important. We propose “Open Sesame? Open Salami! (OSOS)”, a personalized vocabulary assessment and intervention system with pervasive language profiling and targeted storybook generation, collaboratively developed with speech-language pathologists. Melded into a child’s daily life and powered by large language models (LLM), OSOS profiles the child’s language environment, extracts priority words therein, and generates bespoke storybooks naturally incorporating those words. We evaluated OSOS through 4-week-long deployments to 9 families. We report their experiences with OSOS, and its implications in supporting personalization outside standards.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {120},
numpages = {32},
keywords = {generative AI, language assessment and intervention, large language model, storybook generation, vocabulary learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3644815.3644953,
author = {Nouri, Ali and Cabrero-Daniel, Beatriz and Torner, Fredrik and Sivencrona, Hakan and Berger, Christian},
title = {Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644953},
doi = {10.1145/3644815.3644953},
abstract = {DevOps is a necessity in many industries, including the development of Autonomous Vehicles. In those settings, there are iterative activities that reduce the speed of SafetyOps cycles. One of these activities is "Hazard Analysis &amp; Risk Assessment" (HARA), which is an essential step to start the safety requirements specification. As a potential approach to increase the speed of this step in SafetyOps, we have delved into the capabilities of Large Language Models (LLMs). Our objective is to systematically assess their potential for application in the field of safety engineering. To that end, we propose a framework to support a higher degree of automation of HARA with LLMs. Despite our endeavors to automate as much of the process as possible, expert review remains crucial to ensure the validity and correctness of the analysis results, with necessary modifications made accordingly.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {172–177},
numpages = {6},
keywords = {hazard analysis risk assessment, autonomous vehicles, DevOps, safety, large language model, prompt engineering, LLM, ChatGPT},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@article{10.1145/3585060.3585063,
author = {Lopez, Patty},
title = {Reflections on the Design of Systems that Impact Computers and Society},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0095-2737},
url = {https://doi.org/10.1145/3585060.3585063},
doi = {10.1145/3585060.3585063},
abstract = {Having spent the past year post-retirement working with my alma mater, New Mexico State University's (NMSU) Computer Science department to broaden computing, increase student engagement, and to improve graduation completion, as well as reflecting on the state of computing in society at large, I thought I'd share some observations. In March of this year, I had the opportunity to participate in the SIGCSE 2022 Technical Symposium. I was struck by Dr. Shaundra Daily's plenary keynote, entitled "Diversifying Computing: Real Change Must Come from Within", and her use of the phrase "navigating systems that were not designed for me" as she described her exploration of STEM as a first-generation college student, as both a dance and an engineering student, and as a graduate student preparing for motherhood lacking flexibility during her pregnancy, no maternity leave, no livable stipend, and a lack of affordable childcare, as well as the coping strategies she needed to develop to deal with academic culture. In my work with NMSU this past spring, co-teaching a problem solving course, my work this fall advising CS students, and my board roles serving on the National Academy of Science, Engineering, and Medicine's Roundtable for Systemic Change in Undergraduate STEM Education co-chairing the "Culture of STEM" workgroup, on the Computing Alliance of Hispanic Serving Institution's (CAHSI) Advisory Board, and on the Computing Research Association for Widening Participation (CRA-WP), co-editing the "Expanding the Pipeline" column, it's clear that system design adversely impacts society in terms of determining not only who gets to participate in the design of computer hardware and software, but also who gets to advance in social and economic mobility. Academic institutions are complex systems in need of an overhaul, by the University of California's academic workers strike for better pay and benefits. The design and commercialization of AI without fully understanding the implications of bias and ethics is inherently a system design problem. The application to everything from AI generated art and images (and how to spot deep fakes), the ability of large language models (LLMs) to create volumes of text generated articles that appear legitimate with the capacity to spread hate and misinformation globally are but just a few examples of the potentially horrific impact to society, because humans cannot work at the pace and scale to validate and/or authenticate them, with few if any meaningful domestic and international laws or policies in place to safeguard us.},
journal = {SIGCAS Comput. Soc.},
month = feb,
pages = {9},
numpages = {1},
keywords = {bias, diversity, ethics, system design}
}

@article{10.1145/3659601,
author = {Wang, Yufei and Zeng, Wenting and Liu, Changzhen and Ye, Zhuohan and Sun, Jiawei and Ji, Junxiang and Jiang, Zhihan and Yan, Xianyi and Wu, Yongyi and Wang, Yigao and Yang, Dingqi and Wang, Leye and Zhang, Daqing and Wang, Cheng and Chen, Longbiao},
title = {CrowdBot: An Open-Environment Robot Management System for On-Campus Services},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659601},
doi = {10.1145/3659601},
abstract = {In contemporary campus environments, the provision of timely and efficient services is increasingly challenging due to limitations in accessibility and the complexity and openness of the environment. Existing service robots, while operational, often struggle with adaptability and dynamic task management, leading to inefficiencies. To overcome these limitations, we introduce CrowdBot, a robot management system that enhances service in campus environments. Our system leverages a hierarchical reinforcement learning-based cloud-edge hybrid scheduling framework (REDIS), for efficient online streaming task assignment and dynamic action scheduling. To verify the REDIS framework, we have developed a digital twin simulation platform, which integrates large language models and hot-swapping technology. This facilitates seamless human-robot interaction, efficient task allocation, and cost-effective execution through the reuse of robot equipment. Our comprehensive simulations corroborate the system's remarkable efficacy, demonstrating significant improvements with a 24.46% reduction in task completion times, a 9.37% decrease in travel distances, and up to a 3% savings in power usage. Additionally, the system achieves a 7.95% increase in the number of tasks completed and a 9.49% reduction in response time. Real-world case studies further affirm CrowdBot's capability to adeptly execute tasks and judiciously recycle resources, thereby offering a smart and viable solution for the streamlined management of campus services.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {80},
numpages = {27},
keywords = {crowdsensing, dynamic task schedule, equipment-swappable robots, online streaming task assignment, reinforcement learning, robot management}
}

@inproceedings{10.1145/3640794.3665538,
author = {S\'{a}nchez Cuadrado, Jes\'{u}s and P\'{e}rez-Soler, Sara and Guerra, Esther and De Lara, Juan},
title = {Automating the Development of Task-oriented LLM-based Chatbots},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665538},
doi = {10.1145/3640794.3665538},
abstract = {Task-oriented chatbots are increasingly used to access all sorts of services – like booking a flight, or setting a medical appointment – through natural language conversation. There are many technologies for implementing task-oriented chatbots, including Dialogflow, Watson, and Rasa. They rely on an explicit definition of the user intents, conversation flows, and chatbot outputs, which is costly to specify, and sometimes results in suboptimal user experiences and artificial conversations with limited diversity of chatbot responses. Recently, the advances in generative artificial intelligence fostered by Large Language Models (LLMs) have enabled a new range of open-domain chatbots, like ChatGPT, able to converse fluently on any topic. However, they are general-purpose, and therefore not directly usable to solve specialised tasks reliably. In this paper, we study the power of LLMs to build task-oriented chatbots, resulting in lighter specifications – no intent definition required – and more natural conversations than in intent-based approaches. To this end, we propose a lightweight domain-specific language based on YAML to specify chatbots using modules of different types (e.g., menus, question-answering, data gathering). These specifications are compiled into structured LLM prompts that use the ReAct framework to inform our runtime how to interpret the user input and coordinate the tasks that the chatbot must perform. The paper presents the design and realisation of our framework, and an assessment that encodes a set of existing intent-based chatbots using our approach, showing its benefits in terms of specification size, conversation flexibility and output diversity.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {11},
numpages = {10},
keywords = {Domain-Specific Languages, Large Language Models, Task-oriented Chatbots},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3649217.3653607,
author = {Rivera, Elijah and Steinmaurer, Alexander and Fisler, Kathi and Krishnamurthi, Shriram},
title = {Iterative Student Program Planning using Transformer-Driven Feedback},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653607},
doi = {10.1145/3649217.3653607},
abstract = {Problem planning is a fundamental programming skill, and aids students in decomposing tasks into manageable subtasks. While feedback on plans is beneficial for beginners, providing this in a scalable and timely way is an enormous challenge in large courses.Recent advances in LLMs raise the prospect of helping here. We utilize LLMs to generate code based on students' plans, and evaluate the code against expert-defined test suites. Students receive feedback on their plans and can refine them.In this report, we share our experience with the design and implementation of this workflow. This tool was used by 544 students in a CS1 course at an Austrian university. We developed a codebook to evaluate their plans and manually applied it to a sample. We show that LLMs can play a valuable role here. However, we also highlight numerous cautionary aspects of using LLMs in this context, many of which will not be addressed merely by having more powerful models (and indeed may be exacerbated by it).},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {45–51},
numpages = {7},
keywords = {automated feedback, llms, program planning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3613904.3642773,
author = {Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi},
title = {CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642773},
doi = {10.1145/3613904.3642773},
abstract = {Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {650},
numpages = {20},
keywords = {AI assistants, AI tutoring, class deployment, design guidelines, educational technology, generative AI, intelligent tutoring systems, large language models, programming education},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3613904.3642545,
author = {Zhang, Yu and Sun, Jingwei and Feng, Li and Yao, Cen and Fan, Mingming and Zhang, Liuxin and Wang, Qianying and Geng, Xin and Rui, Yong},
title = {See Widely, Think Wisely: Toward Designing a Generative Multi-agent System to Burst Filter Bubbles},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642545},
doi = {10.1145/3613904.3642545},
abstract = {The proliferation of AI-powered search and recommendation systems has accelerated the formation of “filter bubbles” that reinforce people’s biases and narrow their perspectives. Previous research has attempted to address this issue by increasing the diversity of information exposure, which is often hindered by a lack of user motivation to engage with. In this study, we took a human-centered approach to explore how Large Language Models (LLMs) could assist users in embracing more diverse perspectives. We developed a prototype featuring LLM-powered multi-agent characters that users could interact with while reading social media content. We conducted a participatory design study with 18 participants and found that multi-agent dialogues with gamification incentives could motivate users to engage with opposing viewpoints. Additionally, progressive interactions with assessment tasks could promote thoughtful consideration. Based on these findings, we provided design implications with future work outlooks for leveraging LLMs to help users burst their filter bubbles.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {484},
numpages = {24},
keywords = {diverse information, filter bubble, interaction design, large language model, multi-agent system},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3702138.3702140,
author = {DiMario, Carmen L. and Bacha, Rio C. and Butka, Brian K.},
title = {Combatting Senior Scams Using a Large Language Model-Created Rubric: This paper explains a novel approach to reinforcement learning designed for the detection and prevention of scams aimed at senior citizens},
year = {2025},
isbn = {9798400717543},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702138.3702140},
doi = {10.1145/3702138.3702140},
abstract = {This paper addresses the critical issue of internet scams targeting seniors by developing a robust, Machine Learning (ML) based solution employing a Large Language Model (LLM), specifically ChatGPT, to enhance scam detection and prevention. Elderly internet users are particularly vulnerable to digital fraud due to a lack of familiarity with technological safeguards and a tendency not to report incidents. Traditional security measures often fail to accommodate the unique challenges faced by this demographic, prompting our focus on a specialized, user-friendly solution. We propose an innovative approach using ChatGPT 3.5 to analyze and score emails based on their likelihood of being scams, thus providing seniors with a tool that requires minimal interaction while offering maximum protection. This system uses a custom rubric developed through ML techniques to evaluate potential threats effectively. By integrating word embeddings and a diverse training dataset, the model adapts to the nuanced and evolving nature of scam tactics. The methodology utilized in this paper ensures that the ML model not only identifies common scam indicators but also provides actionable feedback to users, making it a practical tool for real-world applications. Preliminary results demonstrate the system's efficacy in recognizing scam emails, thereby significantly reducing the risk of financial loss among seniors and enhancing their confidence in digital communication. This paper outlines the design, implementation, and testing phases of the project, highlighting the potential of LLMs in cybersecurity, specifically in protecting a vulnerable population.},
booktitle = {Proceeding of the 2024 5th Asia Service Sciences and Software Engineering Conference},
pages = {130–136},
numpages = {7},
keywords = {Cyber security, artificial intelligence, email, machine learning, scam},
location = {
},
series = {ASSE '24}
}

@inproceedings{10.1145/3674399.3674426,
author = {Dong, Dong and Liang, Yue},
title = {Grading Programming Assignments by Summarization},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674426},
doi = {10.1145/3674399.3674426},
abstract = {Grading programming assignments manually is a big burden for instructors who teach programming languages for university students due to complexity and subjectivity. The black test approach adopted by online judge systems can only outputs either an answer is correct or incorrect. This study proposes a Large Language Model (LLM) approach to automatically grade answers from students for programming assignments. A LLM mode formed by coder-decoder architecture is utilized to generate summarization from source code, then the summarization is compared to the textual assignment description by semantic similarity. Finally, the output is converted to five-score rating. CodeBERT and a Transformer model serve as coder and decoder respectively. The semantic similarity is computed by MiniLM-L6. The validation test shows that the accuracy of the suggested approach reaches 0.92.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {53–58},
numpages = {6},
keywords = {CodeBERT, automatic grading, programming assignment assessment, source code summarization},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@article{10.5555/3717781.3717797,
author = {Evans, Jacob and Goldschmidt, Cody and Zhang, Yilian},
title = {Evaluating the Cognitive Level of GPT Models in Mathematics},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {The current trend of using AI-based applications in everyday life has gained momentum among the general public. The GPT model has been promoted as a math tutoring tool for K-12 students. We highly question this promotion and believe a thorough examination of the GPT model's capability in mathematical cognition is necessary before it can be considered a reliable tutoring tool. In this paper, we present our preliminary findings on the GPT model's cognitive ability in mathematics. The model exhibits a low level of mathematical cognition and lacks training in important areas of trigonometry. The GPT model has not reached a level of reliability required for tutoring tool. Guardrails must be implemented for further use. We have developed an efficient strategy that allows the GPT model to categorize problems based on topic, and this self-feedback can be used to guide its problem-solving process.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {117–126},
numpages = {10}
}

@inproceedings{10.1145/3650212.3680354,
author = {Shin, Jiho and Hashtroudi, Sepehr and Hemmati, Hadi and Wang, Song},
title = {Domain Adaptation for Code Model-Based Unit Test Case Generation},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680354},
doi = {10.1145/3650212.3680354},
abstract = {Recently, deep learning-based test case generation approaches have been proposed to automate the generation of unit test cases. In this study, we leverage Transformer-based code models to generate
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
unit tests with the help of Domain Adaptation (DA) at a project level. Specifically, we use CodeT5, a relatively small language model trained on source code data, and fine-tune it on the test generation
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
task. Then, we apply domain adaptation to each target project data to learn project-specific knowledge (project-level DA). We use the Methods2test dataset to fine-tune CodeT5 for the test generation
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
task and the Defects4j dataset for project-level domain adaptation and evaluation. We compare our approach with (a) CodeT5 fine-tuned on the test generation without DA, (b) the A3Test tool, and (c)
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
GPT-4 on five projects from the Defects4j dataset. The results show that tests generated using DA can increase the line coverage by 18.62%, 19.88%, and 18.02% and mutation score by 16.45%, 16.01%,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
and 12.99% compared to the above (a), (b), and (c) baselines, respectively. The overall results show consistent improvements in metrics such as parse rate, compile rate, BLEU, and CodeBLEU. In addition,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
we show that our approach can be seen as a complementary solution alongside existing search-based test generation tools such as EvoSuite, to increase the overall coverage and mutation scores with an average of 34.42% and 6.8%, for line coverage and mutation score, respectively.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1211–1222},
numpages = {12},
keywords = {Code Model, Domain Adaption, GPT, LLM, Test generation, Transformers},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3571884.3604305,
author = {Li, Zhuoyang and Liang, Minhui and Le, Hai Trung and Lc, Ray and Luo, Yuhan},
title = {Exploring Design Opportunities for Reflective Conversational Agents to Reduce Compulsive Smartphone Use},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3604305},
doi = {10.1145/3571884.3604305},
abstract = {Conversational agents (CAs) have become ubiquitous in our daily lives. Recognizing the potential of CAs being persuasive agents, we are interested in leveraging CAs to reduce compulsive smartphone use, a widespread behavior among young adults that can lead to negative consequences. This work presents the design and development of StayFocused, a mobile app incorporating a chatbot to assist people in setting focus goals and reflecting on their phone-checking behaviors in situ. Particularly, we highlight the iterative process of curating prompts for GPT-3, and the lessons learned from our trials and errors. With StayFocused, we propose a three-week between-subjects study with college students. We envision the design of StayFocused and the proposed study will deepen our understanding of how CAs support immediate actions as well as sustained behavior change, and inform the design of persuasive technologies for reducing unintended behaviors such as compulsive smartphone use.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {37},
numpages = {6},
keywords = {Conversational UI, persuasive technology (PT), reflection, smartphone non-use},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@inproceedings{10.1145/3589335.3641257,
author = {Wang, Xin and Zhou, Yuwei and Chen, Hong and Zhu, Wenwu},
title = {Curriculum Learning: Theories, Approaches, Applications, Tools, and Future Directions in the Era of Large Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641257},
doi = {10.1145/3589335.3641257},
abstract = {This tutorial focuses on curriculum learning (CL), an important topic in machine learning, which gains an increasing amount of attention in the research community. CL is a learning paradigm that enables machines to learn from easy data to hard data, imitating the meaningful procedure of human learning with curricula. As an easy-to-use plug-in, CL has demonstrated its power in improving the generalization capacity and convergence rate of various models in a wide range of scenarios such as computer vision, natural language processing, data mining, reinforcement learning, etc. Therefore, it is essential introducing CL to more scholars and researchers in the machine learning community. However, there have been no tutorials on CL so far, motivating the organization of our tutorial on CL at WWW 2024. To give a comprehensive tutorial on CL, we plan to organize it from the following aspects: (1) theories, (2) approaches, (3) applications, (4) tools and (5) future directions. First, we introduce the motivations, theories and insights behind CL. Second, we advocate novel, high-quality approaches, as well as innovative solutions to the challenging problems in CL. Then we present the applications of CL in various scenarios, followed by some relevant tools. In the end, we discuss open questions and the future direction in the era of large language models. We believe this topic is at the core of the scope of WWW and is attractive to the audience interested in machine learning from both academia and industry.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1306–1310},
numpages = {5},
keywords = {curriculum learning, large language models, machine learning library and tool, machine learning paradigm, training strategy},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3677619.3678114,
author = {Marx, Erik and Witt, Clemens and Leonhardt, Thiemo},
title = {Identifying Secondary School Students' Misconceptions about Machine Learning: An Interview Study},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678114},
doi = {10.1145/3677619.3678114},
abstract = {Since students are familiar with machine learning (ML)-based applications in their everyday lives, they already construct mental models of how these systems work. This can result in misconceptions that influence the learning of correct ML concepts. Therefore, this study investigates the misconceptions students hold about the functionality of ML-based applications. To this end, we conducted semi-structured interviews with five students, focusing on their understanding of facial recognition and ChatGPT. The interviews were analyzed using an inductively developed code system and qualitative content analysis. This process identified six key misconceptions held by students: “Programmed Behavior,” “Exactness,” “Data Storage,” “Continuous Learning,” “User-trained Model,” and “Autonomous Data Acquisition”. These misconceptions include the notion that AI learns continuously during application, or that training data is saved and reused later. This paper presents the identified misconceptions and discusses their implication for the design and evaluation of effective learning activities in the context of ML.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {6},
numpages = {10},
keywords = {artificial intelligence, interview study, machine learning, mental models, misconceptions, qualitative research, students conceptions},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@inproceedings{10.1145/3675812.3675874,
author = {Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.},
title = {Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675874},
doi = {10.1145/3675812.3675874},
abstract = {The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {340–346},
numpages = {7},
keywords = {AI in education, ChatGPT, Curriculum alignment, Curriculum development, Generative AI, Syllabus analysis},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3639476.3639777,
author = {Mishra, Shyamal and Chatterjee, Preetha},
title = {Exploring ChatGPT for Toxicity Detection in GitHub},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639777},
doi = {10.1145/3639476.3639777},
abstract = {Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pre-trained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {6–10},
numpages = {5},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

@inproceedings{10.1145/3658549.3658566,
author = {Ho, Chia-Ling and Liu, Xin-Ying and Qiu, Yu-Wei and Yang, Shih-Yang},
title = {Research on Innovative Applications and Impacts of Using Generative AI for User Interface Design in Programming Courses},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658549.3658566},
doi = {10.1145/3658549.3658566},
abstract = {Generative Artificial Intelligence (GAI) has become a hot topic nowadays, as its powerful content generation models enable users to instantly create everything from digital media products to coding examples through simple text queries, providing more possibilities in the field of education. This study aims to investigate the impact of Generative AI intervention in teaching App Inventor programming courses, analyzing the differences between UI materials designed by traditional teachers based on their professional knowledge and experience, and UI materials created by Generative AI in classroom teaching. The study also evaluates the impact of Generative AI on students' learning outcomes and motivation through satisfaction and Technology Acceptance Model (TAM) questionnaires. The results indicate that UI materials produced through Generative AI effectively enhance students' satisfaction with the course and their acceptance of new technologies. Compared to traditional teaching methods, Generative AI significantly saves teachers' time and effort in designing materials while simultaneously improving teaching efficiency and quality.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
pages = {68–72},
numpages = {5},
keywords = {Generative artificial intelligence, Intelligent assistant, Learning effectiveness, Programming course, User interface design},
location = {Taipei, Taiwan},
series = {I-DO '24}
}

@article{10.1145/3628162,
author = {Shoufan, Abdulhadi},
title = {Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
url = {https://doi.org/10.1145/3628162},
doi = {10.1145/3628162},
abstract = {With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n=41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n=24 to 61). The results showed a wide range of effect sizes, from -2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of -0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
journal = {ACM Trans. Comput. Educ.},
month = dec,
articleno = {45},
numpages = {29},
keywords = {ChatGPT, large language models}
}

@inproceedings{10.1145/3624918.3625336,
author = {Huo, Siqing and Arabzadeh, Negar and Clarke, Charles},
title = {Retrieving Supporting Evidence for Generative Question Answering},
year = {2023},
isbn = {9798400704086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3624918.3625336},
doi = {10.1145/3624918.3625336},
abstract = {Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately. We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence. The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material. With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided. However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process. While this verification process can reduce hallucinations, it can not entirely eliminate them.},
booktitle = {Proceedings of the Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {11–20},
numpages = {10},
location = {Beijing, China},
series = {SIGIR-AP '23}
}

@inproceedings{10.1145/3701625.3701659,
author = {Guerino, Lucca Renato and Kuroishi, Pedro Henrique and Paiva, Ana Cristina Ramada and Vincenzi, Auri Marcelo Rizzo},
title = {Static and Dynamic Comparison of Mutation Testing Tools for Python},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701659},
doi = {10.1145/3701625.3701659},
abstract = {Context: Mutation testing is a rigorous approach for assessing the quality of test suites by injecting faults (i.e., mutants) into software under test. Tools, such as CosmicRay and Mutpy, are examples of Mutation Testing tools for Python software programs. Problem: With different Python mutation testing tools, comparative analysis is lacking to evaluate their effectiveness in different usage scenarios. Furthermore, the evolution of these tools makes continuous evaluation of their functionalities and characteristics necessary. Method: In this work, we evaluate (statically and dynamically) four Python mutation testing tools, namely CosmicRay, MutPy, MutMut, and Mutatest. In static evaluation, we introduce a comparison framework, adapted from one previously applied to Java tools, and collected information from tool documentation and developer surveys. For dynamic evaluation, we use tests built based on those produced by Pynguin, which are improved through the application of Large Language Models (LLMs) and manual analyses. Then, the adequate test suites were cross-tested among different tools to evaluate their effectiveness in killing mutants each other. Results: Our findings reveal that CosmicRay offers superior functionalities and customization options for mutant generation compared to its counterparts. Although CosmicRay’s performance was slightly lower than MutPy in the dynamic tests, its recent updates and active community support highlight its potential for future enhancements. Cross-examination of the test suites further shows that mutation scores varied narrowly among tools, with a slight emphasis on MutPy as the most effective mutant fault model.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {199–209},
numpages = {11},
keywords = {Software Testing, Experimental Software Engineering, Automated Test Generation, Coverage Testing, Mutation Testing, Testing Tools, Python Mutation Tools},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3635636.3664624,
author = {Endow, Shreyosi},
title = {Experiential Tutorials: Designing Tutorial Authoring Tools to Facilitate Tacit Knowledge Exchange in Creative Practices},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3664624},
doi = {10.1145/3635636.3664624},
abstract = {Tutorials serve as a fundamental mechanism for disseminating knowledge within creative practices. Yet, tutorials struggle to convey tacit knowledge, a type of knowledge that practitioners internalize over time and experience. The subconscious nature of tacit knowledge often causes experienced practitioners to inadvertently omit fundamental actions in their instructions, which poses significant challenges for novices attempting to grasp the basics. However, no two novices are alike, making it challenging and burdensome for the tutorial author to align their tutorials with the audiences’ expertise. My doctoral research aims to create a more bespoke learning experience where tutorials are adapted to learners’ experiences without burdening the tutorial author. My contributions towards this goal include a tutorial concept extraction method that identifies the core vocabulary of a practice to inform authors of their audiences’ language, a typology that aids authors to identify key characteristics of tacit knowledge to enable richer instructions, and a framework that enables authors to use the tutorial medium effectively to maximize tacit knowledge transfer. I am currently working towards a tutorial authoring tool that leverages large language models to extract a learner’s unique and relevant experiences to create a personal knowledge inventory. Future work would combine this inventory with previous contributions to augment tutorials to be experiential, or aligned with learners’ experiences.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {30–34},
numpages = {5},
keywords = {creative practices, tacit knowledge, tutorial authoring tools, tutorials},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

@article{10.1145/3672359.3672364,
author = {Schmidt, Douglas C. and Spencer-Smith, Jesse and Fu, Quchen and White, Jules},
title = {Towards a Catalog of Prompt Patterns to Enhance the Discipline of Prompt Engineering},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3672359.3672364},
doi = {10.1145/3672359.3672364},
abstract = {The rapid advent of Large Language Models (LLMs), such as ChatGPT and Claude, is revolutionizing various fields, from education and healthcare to the engineering of reliable software systems. These LLMs operate through "prompts," which are natural language inputs that users employ to query and leverage the models' capabilities. Given the novelty of LLMs, the understanding of how to effectively use prompts remains largely anecdotal, based on isolated use cases. This fragmented approach limits the reliability and utility of LLMs, especially when they are applied in mission-critical software environments. To harness the full potential of LLMs in such crucial contexts, therefore, we need a systematic, disciplined approach to "prompt engineering" that guides interactions with and evaluations of these LLMs.},
journal = {Ada Lett.},
month = jun,
pages = {43–51},
numpages = {9}
}

@inproceedings{10.1145/3701625.3701657,
author = {de Almeida, \'{A}gatha and Collins, Eliane and Oran, Ana Carolina},
title = {AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701657},
doi = {10.1145/3701625.3701657},
abstract = {Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {179–188},
numpages = {10},
keywords = {Exploratory Testing, ChatGPT, Personas, Software Quality, Artificial Intelligence},
location = {
},
series = {SBQS '24}
}

@article{10.1145/3699773,
author = {Gao, Yang and Zhang, Wenbo and Ren, Junbin and Zheng, Ruihao and Jin, Yingcheng and Wu, Di and Shu, Lin and Xu, Xiangmin and Jin, Zhanpeng},
title = {PressInPose: Integrating Pressure and Inertial Sensors for Full-Body Pose Estimation in Activities},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699773},
doi = {10.1145/3699773},
abstract = {The accurate assessment of human body posture through wearable technology has significant implications for sports science, clinical diagnostics, rehabilitation, and VR interaction. Traditional methods often require complex setups or are limited by the environment's constraints. In response to these challenges, this paper presents an innovative approach to human posture estimation under complex motion scenarios through the development of an advanced shoe insole embedded with pressure sensors and an Inertial Measurement Unit (IMU). Coupled with a single wrist-mounted IMU, our system facilitates a comprehensive analysis of human biomechanics by integrating physical kinematics modeling based on pressure data with a multi-region human posture estimation network. To enhance the robustness of our system model, we employed large language models to generate virtual human motion sequences. These sequences were utilized to create synthetic IMU data for data augmentation purposes, addressing the challenge of limited real-world data availability and variability. Our approach uniquely combines physical modeling with data-driven techniques to improve the accuracy and reliability of posture estimation. Experimental results demonstrate that our integrated system significantly advances wearable technology for motion analysis. The Mean Per Joint Position Error (MPJPE) was reduced to 7.75 cm, highlighting the effectiveness of our multi-modal modeling and virtual data augmentation in refining posture estimation.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {197},
numpages = {28},
keywords = {IMU, body pose estimation, pressure sensing, smart shoe}
}

@inproceedings{10.1145/3589335.3651454,
author = {Ragab, Mohamed and Savateev, Yury and Oliver, Helen and Tiropanis, Thanassis and Poulovassilis, Alexandra and Chapman, Adriane and Roussos, George},
title = {Unlocking the Potential of Health Data with Decentralised Search in Personal Health Datastores},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651454},
doi = {10.1145/3589335.3651454},
abstract = {In the digital age, where health data and digital lives converge, data privacy and control are crucial. The advent of AI and Large Language Models (LLMs) brings advanced data analysis and healthcare predictions, but also privacy concerns. The ESPRESSO project 1 asserts that for AI to be trustworthy and effective in healthcare, it must prioritize user control over corporate interests. The shift towards decentralized personal online datastores (pods) and Solid 2 principles represents a new era of private, controllable Web interactions, balancing AI data protection and machine intelligence. This balance is particularly important for applications involving health data. However, decentralization poses challenges, particularly in secure, efficient data search and data retrieval, that need to be addressed first. We argue that a decentralized search system that provides a large-scale search across Solid pods, while considering data owners' control of their data and users' different access rights, is crucial for this new paradigm. In this paper, we describe how our current decentralized search system's prototype (ESPRESSO) helps to query structured and unstructured personal health data in Solid servers. The paper also describes a search scenario that shows how ESPRESSO can search health data combined with fitness personal data stored in different personal datastores},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1154–1157},
numpages = {4},
keywords = {decentralized web search, health and well-being data, linked data, personal online datastores, solid framework},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3627217.3627238,
author = {Singhal, Shreya and Kumar, Viraj},
title = {Creating Thorough Tests for AI-Generated Code is Hard},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627238},
doi = {10.1145/3627217.3627238},
abstract = {Before implementing a function, programmers are encouraged to write a suite of test cases that specify its intended behaviour on several inputs. A suite of tests is thorough if any buggy implementation fails at least one of these tests. We posit that as the proportion of code generated by Large Language Models (LLMs) grows, so must the ability of students to create test suites that are thorough enough to detect subtle bugs in such code. Our paper makes two contributions. First, we demonstrate how difficult it can be to create thorough tests for LLM-generated code by evaluating 27&nbsp;test suites from a public dataset (EvalPlus). Second, by identifying deficiencies in these test suites, we propose strategies for improving the ability of students to develop thorough test suites for LLM-generated code.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {108–111},
numpages = {4},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3613905.3644062,
author = {Gould, Sandy J. J. and Brumby, Duncan P. and Cox, Anna L.},
title = {ChatTL;DR – You Really Ought to Check What the LLM Said on Your Behalf},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3644062},
doi = {10.1145/3613905.3644062},
abstract = {Interactive large language models (LLMs) are so hot right now, and are probably going to be hot for a while. There are lots of problems exciting challenges created by mass use of LLMs. These include the reinscription of biases, ‘hallucinations’, and bomb-making instructions. Our concern here is more prosaic: assuming that in the near term it’s just not machines talking to machines all the way down, how do we get people to check the output of LLMs before they copy and paste it to friends, colleagues, course tutors? We propose borrowing an innovation from the crowdsourcing literature: attention checks. These checks (e.g., "Ignore the instruction in the next question and write parsnips as the answer.") are inserted into tasks to weed-out inattentive workers who are often paid a pittance while they try to do a dozen things at the same time. We propose ChatTL;DR1, an interactive LLM that inserts attention checks into its outputs. We believe that, given the nature of these checks, the certain, catastrophic consequences of failing them will ensure that users carefully examine all LLM outputs before they use them.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {552},
numpages = {7},
keywords = {LLMs, Large Language Models, academics being hilarious, attention checks, checking behaviour, computers-talking-to-computers-all-the-way-down-circlejerk, error detection, human factors, instructional manipulation checks, that-bloody-automatic-lane-assist-ffs},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3675888.3676142,
author = {Mittal, Sangeeta and Gupta, Saksham and Bansal, Kritarth and Aggarwal, Geetali},
title = {Democratizing GDPR Compliance: AI-Driven Privacy Policy Interpretation},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676142},
doi = {10.1145/3675888.3676142},
abstract = {With long privacy policies, users face the challenge of understanding them easily in order to ensure that their privacy rights are upheld. This paper presents an approach for democratizing GDPR compliance through AI-driven privacy policy interpretation. The methodology leverages advanced artificial intelligence techniques of Large Language Models (LLMs) for implementing effective comprehension of privacy policies. By extracting key information related to personally identifiable information (PII), the proposed solution empowers users to make informed decisions about their data privacy. The effectiveness of AI-driven privacy policy interpretation has been shown via various examples of automated summarization of lengthy and complex privacy policies as compliant/non-compliant to GDPR. Overall, it makes privacy policies more accessible, relevant, and actionable for users.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {735–743},
numpages = {9},
keywords = {GDPR, LLMs, Personally Identifiable Information, Privacy},
location = {Noida, India},
series = {IC3-2024}
}

@inproceedings{10.1145/3661167.3661226,
author = {Esposito, Matteo and Palagiano, Francesco},
title = {Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661226},
doi = {10.1145/3661167.3661226},
abstract = {Preliminary security risk analysis (PSRA) provides a quick approach to identify, evaluate, and propose remediation to potential risks in specific scenarios. The extensive expertise required for an effective PSRA and the substantial textual-related tasks hinders quick assessments in mission-critical contexts, where timely and prompt actions are essential. The speed and accuracy of human experts in PSRA significantly impact response time. A large language model can quickly summarise information in less time than a human. To our knowledge, no prior study has explored the capabilities of fine-tuned models (FTM) in PSRA. Our case study investigates the proficiency of FTM in assisting practitioners in PSRA. We manually curated 141 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years. We compared the proficiency of the FTM versus seven human experts. Within the industrial context, our approach has proven successful in reducing errors in PSRA, hastening security risk detection, and minimizing false positives and negatives. This translates to cost savings for the company by averting unnecessary expenses associated with implementing unwarranted countermeasures. Therefore, experts can focus on more comprehensive risk analysis, leveraging LLMs for an effective preliminary assessment within a condensed timeframe.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {442–445},
numpages = {4},
keywords = {Analysis, Fine-Tuning, Generative AI, Human Experts, LLM, Large Language Model, Management, Preliminary, Risk, Security, Standards},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3627673.3679783,
author = {Anand, Avinash and Nair, Ashwin R and Prasad, Kritarth and Narayan, Vrinda and Lal, Naman and Mahata, Debanjan and Singla, Yaman K and Shah, Rajiv Ratn},
title = {Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679783},
doi = {10.1145/3627673.3679783},
abstract = {Citation Text Generation (CTG) in scientific documents often relies on standard summarization techniques, which may not fully capture the nuanced relationship between the citing and cited papers. To address this, we present a Multi-Source Citation Text Generation (M-CTG) architecture, leveraging a Seq2Seq transformer framework enhanced with keyphrase embeddings, graph embeddings, and text representations. This approach aims to produce more contextually relevant and accurate citation texts by integrating multiple sources of information. Our methodology is tested using the newly created CTG-S2ORC dataset, consisting of English-language computer science research papers. In a comparative analysis, we explore the performance of traditional Language Models (LMs) and demonstrate how Large Language Models (LLMs), particularly when integrated with various prompting techniques and Knowledge Graphs, offer superior capabilities in analyzing and generating citation texts. In addition to traditional evaluation metrics, we introduce a custom metric that emphasizes the overlap of key terms and semantic similarity, providing a more comprehensive assessment of our model's performance. Our code and data are available at https://github.com/midas-research/M-CTG/tree/main.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {56–64},
numpages = {9},
keywords = {S2ORC, citation text generation, graph embeddings, knowledge graphs, language models, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679664,
author = {Guo, Yuxiang and Shen, Shuanghong and Liu, Qi and Huang, Zhenya and Zhu, Linbo and Su, Yu and Chen, Enhong},
title = {Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679664},
doi = {10.1145/3627673.3679664},
abstract = {Knowledge Tracing (KT) is a crucial research task for dynamically monitoring students' knowledge states, particularly in online education systems. Recently, knowledge tracing has gained significant attention and in-depth research. Most existing methods rely on students' response data for question understanding and modeling, which helps better updating students' knowledge states. Meanwhile, question ID is utilized to indicate and represent questions. However, this presents a challenge when transitioning to new, cold-start questions that few students has answered before. Also, prior work has overlooked the semantic modeling of questions, which could better assist in modeling the transfer of students' knowledge states. In this paper, we explore leveraging the power of Large Language Models (LLMs) to help understand questions for knowledge tracing, which benefits mitigating cold-start and sparse problems and modeling the transfer of students' knowledge states in a sophisticated manner. Specifically, we first design an attribute estimation module to estimate the attribute of the questions (e.g., difficulty, ability requirements, expected response time) by prompting Large Language Models. Subsequently, we have developed a question embedding module that incorporates graph attention network to effectively utilizing these attributes. Extensive experiments on various datasets demonstrate that our model outperforms existing state-of-the-art models and effectively addresses the problems of cold-start and sparsity. In addition, due to the estimation of multiple attributes of the questions, our model exhibits superior interpretability.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {727–736},
numpages = {10},
keywords = {knowledge tracing, large language model, question attributes},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3638530.3654104,
author = {Liu, Yueyue and Zhang, Hongyu and Le, Van-Hoang and Miao, Yuantian and Li, Zhiqiang},
title = {Local Search-based Approach for Cost-effective Job Assignment on Large Language Models},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3654104},
doi = {10.1145/3638530.3654104},
abstract = {Large Language Models (LLMs) have garnered significant attention due to their impressive capabilities. However, leveraging LLMs can be expensive due to the computational resources required, with costs depending on invocation numbers and input prompt lengths. Generally, larger LLMs deliver better performance but at a higher cost. In addition, prompts that provide more guidance to LLMs can increase the probability of correctly processing the job but also tend to be longer, increasing the processing cost. Therefore, selecting an appropriate LLM and prompt template is crucial for achieving an optimal trade-off between cost and performance. This paper formulates the job assignment on LLMs as a multi-objective optimisation problem and proposes a local search-based algorithm, termed LSAP, which aims to minimise the invocations cost while maximising overall performance. First, historical data is used to estimate the accuracy of each job submitted to a candidate LLM with a chosen prompt template. Subsequently, LSAP combines heuristic rules to select an appropriate LLM and prompt template based on the invocation cost and estimated accuracy. Extensive experiments on LLM-based log parsing, a typical software maintenance task that utilizes LLMs, demonstrate that LSAP can efficiently generate solutions with significantly lower cost and higher accuracy compared to the baselines.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {719–722},
numpages = {4},
keywords = {large language models, job assignment, local search, log parsing},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{10.1145/3576882.3617916,
author = {Agarwal, Nimisha and Kumar, Viraj and Raman, Arun and Karkare, Amey},
title = {A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617916},
doi = {10.1145/3576882.3617916},
abstract = {In an introductory programming (CS1) context, a Refute question asks students for a counter-example which proves that a given code fragment is an incorrect solution for a given task. Such a question can be used as an assessment item to (formatively) develop or (summatively) demonstrate a student's abilities to comprehend the task and the code well enough to recognize a mismatch. These abilities assume greater significance with the emergence of generative AI technologies capable of writing code that is plausible (at least to novice programmers) but not always correct.Instructors must address three concerns while designing an effective Refute question, each influenced by their specific teaching-learning context: (1) Is the task comprehensible? (2) Is the incorrect code a plausible solution for the task? (3) Is the complexity of finding a counter-example acceptable? While the first concern can often be addressed by reusing tasks from previous code writing questions, addressing the latter concerns may require substantial instructor effort. We therefore investigate whether concerns (2) and (3) can be addressed by buggy student solutions for the corresponding code writing question from a previous course offering. For 6 code writing questions (from a Fall 2015 C programming course), our automated evaluation system logged 13,847 snapshots of executable student code, of which 10,574 were buggy (i.e., they failed at least one instructor-supplied test case). Code selected randomly from this pool rarely addresses these concerns, and manual selection is infeasible. Our paper makes three contributions. First, we propose an automated mechanism to filter this pool to a more manageable number of snapshots from which appropriate code can be selected manually. Second, we evaluate our semi-automated mechanism with respect to concerns (2) and (3) by surveying a diverse set of 56 experienced participants (instructors, tutors, and teaching assistants). Third, we use this mechanism to seed a public repository of Refute questions and provide a template to create additional questions using a public resource (CodeCheck).},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {7–14},
numpages = {8},
keywords = {CS1, assessment, refute questions},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3544549.3573826,
author = {Chang, Minsuk and Chung, John Joon Young and Gero, Katy Ilonka and Huang, Ting-Hao Kenneth and Kang, Dongyeop and Lee, Mina and Raheja, Vipul and Wambsganss, Thiemo},
title = {The Second Workshop on Intelligent and Interactive Writing Assistants},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573826},
doi = {10.1145/3544549.3573826},
abstract = {In recent years, writing assistants have become increasingly sophisticated and ubiquitous, fueled by advances in artificial intelligence, particularly large language models. As new use cases and models emerge, we expect the adoption rate to accelerate. In this interdisciplinary workshop, we, as a diverse group of researchers and practitioners interested in intelligent and interactive writing assistants, will create a taxonomy of writing assistants and discuss their desirable features and potential consequences. We invite writers, educators, researchers, industry practitioners, students, and anyone interested in creating, using, and testing future writing assistant technologies to join the conversation.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {369},
numpages = {5},
keywords = {AI-assisted writing, Creativity support tools, Human-AI interaction, Human-computer interaction, Language models, Natural language processing, Writing assistants, Writing support tools},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3613905.3636312,
author = {Chang, Minsuk and Chung, John Joon Young and Gero, Katy Ilonka and Huang, Ting-Hao Kenneth and Kang, Dongyeop and Raheja, Vipul and Sterman, Sarah and Wambsganss, Thiemo},
title = {Dark Sides: Envisioning, Understanding, and Preventing Harmful Effects of Writing Assistants - The Third Workshop on Intelligent and Interactive Writing Assistants},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636312},
doi = {10.1145/3613905.3636312},
abstract = {Writing assistants are becoming increasingly sophisticated and ubiquitous, fueled by advances in artificial intelligence, particularly large language models. As new use cases and models emerge, we expect the adoption rate to accelerate. This brings a sense of urgency to understanding not just the benefits, but also the potential dark sides of intelligent writing assistants. In this interdisciplinary workshop, we will explore the challenges and dark sides that our communities may have to consider as we design and deploy new tools and technologies, as well as how to prevent them. We will build off the successful workshop at CHI23 (The Second In2Writing Workshop), bringing new voices to the vibrant community of writing tools researchers established there, and building on the design space created by prior workshop participants. We invite writers, educators, researchers, industry practitioners, students, and anyone interested in creating, using, and testing future writing assistant technologies to join the conversation.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {464},
numpages = {6},
keywords = {AI-assisted writing, Creativity support tools, Human-AI interaction, Human-computer interaction, Language models, Natural language processing, Writing assistants, Writing support tools},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3649409.3691083,
author = {Meyer, G\'{e}r\^{o}me and Breuer, Philip and F\"{u}rst, Jonathan},
title = {ASAG2024: A Combined Benchmark for Short Answer Grading},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691083},
doi = {10.1145/3649409.3691083},
abstract = {Open-ended questions test a more thorough understanding compared to closed-ended questions and are often a preferred assessment method. However, open-ended questions are tedious to grade and subject to personal bias. Therefore, there have been efforts to speed up the grading process through automation. Short Answer Grading (SAG) systems aim to automatically score students' answers in examinations. Despite growth in SAG methods and capabilities, there exists no comprehensive short-answer grading benchmark across different subjects, grading scales, and distributions. Thus, it is hard to assess the capabilities of current automated grading methods in terms of their generalizability. In this preliminary work, we introduce the combined ASAG2024 benchmark to facilitate the comparison of automated grading systems. Combining seven commonly used short-answer grading datasets in a common structure and grading scale. For our benchmark, we evaluate a set of recent SAG methods, revealing that while LLM-based approaches reach new high scores, they still are far from reaching human performance. This opens up avenues for future research on human-machine SAG systems.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {322–323},
numpages = {2},
keywords = {ASAG, LLMs, automated grading, benchmark, dataset, education},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1109/ASE56229.2023.00155,
author = {Dong, Jinhao and Zhu, Qihao and Sun, Zeyu and Lou, Yiling and Hao, Dan},
title = {Merge Conflict Resolution: Classification or Generation?},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00155},
doi = {10.1109/ASE56229.2023.00155},
abstract = {Collaborative development is critical to improve the productivity. Multiple contributors work simultaneously on the same project and might make changes to the same code locations. This can cause conflicts and require manual intervention from developers to resolve them. To alleviate the human efforts of manual conflict resolution, researchers have proposed various automatic techniques. More recently, deep learning models have been adopted to solve this problem and achieved state-of-the-art performance. However, these techniques leverage classification to combine the existing elements of input. The classification-based models cannot generate new tokens or produce flexible combinations, and have a wrong hypothesis that fine-grained conflicts of one single coarse-grained conflict are independent.In this work, we propose to generate the resolutions of merge conflicts from a totally new perspective, that is, generation, and we present a conflict resolution technique, MergeGen. First, we design a structural and fine-grained conflict-aware representation for the merge conflicts. Then, we propose to leverage an encoder-decoder-based generative model to process the designed conflict representation and generate the resolutions auto-regressively. We further perform a comprehensive study to evaluate the effectiveness of MergeGen. The quantitative results show that MergeGen outperforms the state-of-the-art (SOTA) techniques from both precision and accuracy. Our evaluation on multiple programming languages verifies the good generalization ability of MergeGen. In addition, the ablation study shows that the major component of our technique makes a positive contribution to the performance of MergeGen, and the granularity analysis reveals the high tolerance of MergeGen to coarse-grained conflicts. Moreover, the analysis on generating new tokens further proves the advance of generative models.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1652–1663},
numpages = {12},
keywords = {merge conflict resolution, generative models, conflict representation},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3658271.3658320,
author = {Saldanha, Mateus Santos and Digiampietri, Luciano Antonio},
title = {ChatGPT and Bard Performance on the POSCOMP Exam},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658320},
doi = {10.1145/3658271.3658320},
abstract = {Context: Modern chatbots, built upon advanced language models, have achieved remarkable proficiency in answering questions across diverse fields. Problem: Understanding the capabilities and limitations of these chatbots is a significant challenge, particularly as they are integrated into different information systems, including those in education. Solution: In this study, we conducted a quantitative assessment of the ability of two prominent chatbots, ChatGPT and Bard, to solve POSCOMP questions. IS Theory: The IS theory used in this work is Information processing theory. Method: We used a total of 271 questions from the last five POSCOMP exams that did not rely on graphic content as our materials. We presented these questions to the two chatbots in two formats: directly as they appeared in the exam and with additional context. In the latter case, the chatbots were informed that they were answering a multiple-choice question from a computing exam. Summary of Results: On average, chatbots outperformed human exam-takers by more than 20%. Interestingly, both chatbots performed better, in average, without additional context added to the prompt. They exhibited similar performance levels, with a slight advantage observed for ChatGPT. Contributions and Impact in the IS area: The primary contribution to the field involves the exploration of the capabilities and limitations of chatbots in addressing computing-related questions. This information is valuable for individuals developing Information Systems with the assistance of such chatbots or those relying on technologies built upon these capabilities.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {49},
numpages = {10},
keywords = {Bard, ChatBot, ChatGPT, Computer Science Examination, Large Language Model},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3649165.3699862,
author = {Zheng, Qinghua},
title = {The Innovative Development of Artificial Intelligence and STEM Education-Cognition and Practice},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3699862},
doi = {10.1145/3649165.3699862},
abstract = {Artificial intelligence has emerged as a transformative force, driving productivity and shaping new forms of education. The future of education will be characterized by interactive learning, the blending of virtual and physical environments, and personalized learning experiences. The key to empowering science education with AI lies in creating new learning scenarios and applications, such as immersive teaching, personalized services, and comprehensive assessments. It is essential to understand the principles and objectives of talent development, emphasizing the integration of theoretical research and practical engineering. Furthermore, it is important to explore the mechanisms of the integrated development of AI and science education, as well as the scientific and technological issues involved. We briefly discuss three viewpoints. STEM education is the fundamental way to cultivate innovative talents. Science education, namely STEM education, conforms to the basic laws of historical materialism and the principle that science and technology are the primary productive forces. The purpose of STEM is to teach the fundamental methods for understanding, describing, transforming, and constructing the world. The key to empowering scientific education with AI lies in new scenarios and new applications. In the field of education, AI empowers the processes of teaching, learning, assessment, management, and services. In terms of engineering, knowledge graphs combined with LLMs represent a new key to personalized tutoring. AI+ is also creating new scenarios and applications, such as autonomous infrastructure inspection and intelligent diagnosis with micro-nano robots. The key to the integration of AI with STEM education lies in teachers. AI will empower education but cannot replace teachers. Teachers who understand how to use AI may replace those who do not, enabling a new form of intelligence that surpasses the limitations of human intelligence through human-machine collaboration.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {4},
numpages = {1},
keywords = {STEM education, artificial intelligence, human-machine collaboration, large language model},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3490100.3516473,
author = {Suh, Sangho and An, Pengcheng},
title = {Leveraging Generative Conversational AI to Develop a Creative Learning Environment for Computational Thinking},
year = {2022},
isbn = {9781450391450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490100.3516473},
doi = {10.1145/3490100.3516473},
abstract = {We explore how generative conversational AI can assist students’ learning, creative, and sensemaking process in a visual programming environment where users can create comics from code. The process of visualizing code in terms of comics involves mapping programming language (code) to natural language (story) and then to visual language (of comics). While this process requires users to brainstorm code examples, metaphors, and story ideas, the recent development in generative models introduces an exciting opportunity for learners to harness their creative superpower and researchers to advance our understanding of how generative conversational AI can augment our intelligence in creative learning contexts. We provide an overview of our system and discuss interaction scenarios to demonstrate ways we can partner with generative conversational AI in the context of learning computer programming.},
booktitle = {Companion Proceedings of the 27th International Conference on Intelligent User Interfaces},
pages = {73–76},
numpages = {4},
keywords = {coding strip, comics, generative conversational AI, visual programming environment},
location = {Helsinki, Finland},
series = {IUI '22 Companion}
}

@inproceedings{10.1145/3654777.3676390,
author = {Fan, Haoxiang and Chen, Guanzheng and Wang, Xingbo and Peng, Zhenhui},
title = {LessonPlanner: Assisting Novice Teachers to Prepare Pedagogy-Driven Lesson Plans with Large Language Models},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676390},
doi = {10.1145/3654777.3676390},
abstract = {Preparing a lesson plan, e.g., a detailed road map with strategies and materials for instructing a 90-minute class, is beneficial yet challenging for novice teachers. Large language models (LLMs) can ease this process by generating adaptive content for lesson plans, which would otherwise require teachers to create from scratch or search existing resources. In this work, we first conduct a formative study with six novice teachers to understand their needs for support of preparing lesson plans with LLMs. Then, we develop LessonPlanner that assists users to interactively construct lesson plans with adaptive LLM-generated content based on Gagne’s nine events. Our within-subjects study (N = 12) shows that compared to the baseline ChatGPT interface, LessonPlanner can significantly improve the quality of outcome lesson plans and ease users’ workload in the preparation process. Our expert interviews (N = 6) further demonstrate LessonPlanner ’s usefulness in suggesting effective teaching strategies and meaningful educational resources. We discuss concerns on and design considerations for supporting teaching activities with LLMs.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {146},
numpages = {20},
keywords = {Large language models, lesson plan preparation, pedagogy-driven system},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3545947.3576354,
author = {Blouin, Sophie and Solomon, Bridget and Crane, Brent and Dempsey, David and Siegel, Angela and Poitras, Eric},
title = {The Role of Sketching in Facilitating Problem Solving in Introductory Programming},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3576354},
doi = {10.1145/3545947.3576354},
abstract = {This study examined the effectiveness of sketching flow diagrams in facilitating CS1 students' problem solving and performance on code writing tasks. Five students received training in design strategies and sketched flow diagrams prior to implementing their solution by writing code. Procedures in solving a sequence of four problems depicted in sketches and captured in keystroke log data were coded and scored for each student. The study results showed that specific and generative depictions of procedures predict the correctness of edits made to solutions.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1411},
numpages = {1},
keywords = {introductory programming, sketching, strategic programming knowledge},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3643795.3648395,
author = {Pister, Kaiser and Paul, Dhruba Jyoti and Joshi, Ishan and Brophy, Patrick},
title = {PromptSet: A Programmer's Prompting Dataset},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648395},
doi = {10.1145/3643795.3648395},
abstract = {The rise of capabilities expressed by large language models has been quickly followed by the integration of the same complex systems into application level logic. Algorithms, programs, systems, and companies are built around structured prompting to black box models where the majority of the design and implementation lies in capturing and quantifying the `agent mode'. The standard way to shape a closed language model is to prime it for a specific task with a tailored prompt, often initially handwritten by a human. The textual prompts co-evolve with the codebase, taking shape over the course of project life as artifacts which must be reviewed and maintained, just as the traditional code files might be. Unlike traditional code, we find that prompts do not receive effective static testing and linting to prevent runtime issues. In this work, we present a novel dataset called PromptSet, with more than 61,000 unique developer prompts used in open source Python programs. We perform analysis on this dataset and introduce the notion of a static linter for prompts. Released with this publication is a HuggingFace dataset and a Github repository to recreate collection and processing efforts, both under the name pisterlabs/promptset.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {62–69},
numpages = {8},
keywords = {prompt management, large language models, dataset, information systems, ethnography, taxonomy},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3613905.3650767,
author = {Nepal, Subigya and Pillai, Arvind and Campbell, William and Massachi, Talie and Choi, Eunsol Soul and Xu, Xuhai and Kuc, Joanna and Huckins, Jeremy F and Holden, Jason and Depp, Colin and Jacobson, Nicholas and Czerwinski, Mary P and Granholm, Eric and Campbell, Andrew},
title = {Contextual AI Journaling: Integrating LLM and Time Series Behavioral Sensing Technology to Promote Self-Reflection and Well-being using the MindScape App},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650767},
doi = {10.1145/3613905.3650767},
abstract = {MindScape aims to study the benefits of integrating time series behavioral patterns (e.g., conversational engagement, sleep, location) with Large Language Models (LLMs) to create a new form of contextual AI journaling, promoting self-reflection and well-being. We argue that integrating behavioral sensing in LLMs will likely lead to a new frontier in AI. In this Late-Breaking Work paper, we discuss the MindScape contextual journal App design that uses LLMs and behavioral sensing to generate contextual and personalized journaling prompts crafted to encourage self-reflection and emotional development. We also discuss the MindScape study of college students based on a preliminary user study and our upcoming study to assess the effectiveness of contextual AI journaling in promoting better well-being on college campuses. MindScape represents a new application class that embeds behavioral intelligence in AI.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {86},
numpages = {8},
keywords = {AI, Behavioral Sensing, Journaling, Large Language Models, Mental Health, Passive Sensing, Self-reflection, Smartphones, Well-being},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3644815.3644948,
author = {Rasool, Zafaryab and Barnett, Scott and Willie, David and Kurniawan, Stefanus and Balugo, Sherwin and Thudumu, Srikanth and Abdelrazek, Mohamed},
title = {LLMs for Test Input Generation for Semantic Applications},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644948},
doi = {10.1145/3644815.3644948},
abstract = {Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {160–165},
numpages = {6},
keywords = {large language model, query evaluation, question answering, semantic cache, test input generation},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3627673.3679711,
author = {Zhao, Kaichen and Song, Yaoxian and Zhao, Haiquan and Liu, Haoyu and Li, Tiefeng and Li, Zhixu},
title = {Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679711},
doi = {10.1145/3627673.3679711},
abstract = {Visual language navigation (VLN) is one of the important research in embodied AI. It aims to enable an agent to understand the surrounding environment and complete navigation tasks. VLN instructions could be categorized into coarse-grained and fine-grained commands. Fine-grained command describes a whole task with subtasks step-by-step. In contrast, coarse-grained command gives an abstract task description, which more suites human habits. Most existing work focuses on the former kind of instruction in VLN tasks, ignoring the latter abstract instructions belonging to daily life scenarios. To overcome the above challenge in abstract instruction, we attempt to consider coarse-grained instruction in VLN by event knowledge enhancement. Specifically, we first propose a prompt-based framework to extract an event knowledge graph (named VLN-EventKG =) for VLN integrally over multiple mainstream benchmark datasets. Through small and large language model collaboration, we realize knowledge-enhanced navigation planning (named EventNav) for VLN tasks with coarse-grained instruction input. Additionally, we design a novel dynamic history backtracking module to correct potential error action planning in real time. Experimental results in various public benchmarks show our knowledge-enhanced method has superiority in coarse-grained-instruction VLN using our proposed VLN-EventKG with over 5% improvement in success rate. Our project is available at https://sites.google.com/view/vln-eventkg},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3320–3330},
numpages = {11},
keywords = {dynamic backtracking, event knowledge graph, knowledge retrieval, task planning, visual language navigation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3578527.3578530,
author = {Jain, Ridhi and Gervasoni, Nicole and Ndhlovu, Mthandazo and Rawat, Sanjay},
title = {A Code Centric Evaluation of C/C++ Vulnerability Datasets for Deep Learning Based Vulnerability Detection Techniques},
year = {2023},
isbn = {9798400700644},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578527.3578530},
doi = {10.1145/3578527.3578530},
abstract = {Recent years have witnessed tremendous progress in NLP-based code comprehension via deep neural networks (DNN) learning, especially Large Language Models (LLMs). While the original application of LLMs is focused on code generation, there have been attempts to extend the application to more specialized tasks, like code similarity, author attribution, code repairs, and so on. As data plays an important role in the success of any machine learning approach, researchers have also proposed several benchmarks which are coupled with a specific task at hand. It is well known in the machine learning (ML) community that the presence of biases in the dataset affects the quality of the ML algorithm in a real-world scenario. This paper evaluates several existing datasets from DNN’s application perspective. We specifically focus on training datasets of C/C++ language code. Our choice of language stems from the fact that while LLM-based techniques have been applied and evaluated on programming languages like Python, JavaScript, and Ruby, there is not much LLM research for C/C++. As a result, datasets generated synthetically or from real-world codes are in individual research work. Consequently, in the absence of a uniform dataset, such works are hard to compare with each other. In this work, we aim to achieve two main objectives– 1. propose code-centric features that are relevant to security program analysis tasks like vulnerability detection; 2. a thorough (qualitative and quantitative) examination of the existing code datasets that demonstrate the main characteristics of the individual datasets to have a clear comparison. Our evaluation finds exciting facts about existing datasets highlighting gaps that need to be addressed.},
booktitle = {Proceedings of the 16th Innovations in Software Engineering Conference},
articleno = {6},
numpages = {10},
keywords = {datasets, program graphs, software metrics, software vulnerability},
location = {Allahabad, India},
series = {ISEC '23}
}

@inproceedings{10.1145/3643795.3648376,
author = {Fei, Haoxiang and Zhang, Yu and Zhang, Hongbo and Wang, Yanlin and Liu, Qing},
title = {MoonBit: Explore the Design of an AI-Friendly Programming Language},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648376},
doi = {10.1145/3643795.3648376},
abstract = {MoonBit, a new general-purpose programming language designed for cloud and edge computing, was initiated in late 2022, coinciding with the announcement of ChatGPT. Language models like GPT, capable of producing practical programs, are revolutionizing the way we write programs and interact with computers. However, significant challenges persist, such as the models' inability to understand the global context of a whole project with its dependencies, the need for human verification and correction of generated code, and the lack of assurance in meeting basic requirements like syntactic correctness.In this paper, we explore the design of the MoonBit language highlighting its AI integration, emphasizing the synergy between traditional code intelligence and large language model capabilities. We also introduce a real-time, semantics-based sampler to guide the inference process of language models. This approach ensures the generated programs are both syntactically correct and free from obvious semantic flaws, such as type errors. Crucially, this has been achieved with minimal impact on overall performance. Our evaluation demonstrates a notable improvement in code quality, achieved without sacrificing the models' responsiveness.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {79–83},
numpages = {5},
keywords = {large language model, program synthesize, static analysis},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3644713.3644763,
author = {Alghamdi, Muath and Abushawarib, Mohammed and Ellouh, Mahmoud and Ghaleb, Mustafa and Felemban, Muhamad},
title = {Enhancing Arabic Information Retrieval for Question Answering},
year = {2024},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644713.3644763},
doi = {10.1145/3644713.3644763},
abstract = {In the modern landscape of Natural Language Processing (NLP), intelligent chatbots like ChatGPT 3.5 and Google’s Bard have shown remarkable competence in generic question-answering (QA) tasks. However, their performance falters when navigating domain-specific QA, particularly in the Arabic language, which is celebrated for its complex morphology and syntax. This paper presents a comprehensive approach to address these issues. The aim of this research is to build a chatbot tailored for a university community. We first create an extensive Arabic Q&amp;A dataset by extracting data from academic documents, employing state-of-the-art Optical Character Recognition (OCR) tools. Then, we evaluate multiple text similarity measures like Pooled FastText Word embedding, BM25 ranking functions, and various semantic sentence embedding models. A thorough performance assessment reveals that the domain-specific model excels at both sentence-level similarity and context-relevance tasks. The developed web application chatbot, leveraging LangChain library and Retrieval Augmented Generation (RAG) methods, outperforms existing chatbots in domain-specific, Arabic language QA scenarios.},
booktitle = {Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
pages = {366–371},
numpages = {6},
keywords = {Information Retrieval, Natural Language Processing},
location = {Dubai, United Arab Emirates},
series = {ICFNDS '23}
}

@inproceedings{10.1109/ASE56229.2023.00047,
author = {Xia, Chunqiu Steven and Ding, Yifeng and Zhang, Lingming},
title = {The Plastic Surgery Hypothesis in the Era of Large Language Models},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00047},
doi = {10.1109/ASE56229.2023.00047},
abstract = {Automated Program Repair (APR) aspires to automatically generate patches for an input buggy program. Traditional APR tools typically focus on specific bug types and fixes through the use of templates, heuristics, and formal specifications. However, these techniques are limited in terms of the bug types and patch variety they can produce. As such, researchers have designed various learning-based APR tools with recent work focused on directly using Large Language Models (LLMs) for APR. While LLM-based APR tools are able to achieve state-of-the-art performance on many repair datasets, the LLMs used for direct repair are not fully aware of the project-specific information such as unique variable or method names.The plastic surgery hypothesis is a well-known insight for APR, which states that the code ingredients to fix the bug usually already exist within the same project. Traditional APR tools have largely leveraged the plastic surgery hypothesis by designing manual or heuristic-based approaches to exploit such existing code ingredients. However, as recent APR research starts focusing on LLM-based approaches, the plastic surgery hypothesis has been largely ignored. In this paper, we ask the following question: How useful is the plastic surgery hypothesis in the era of LLMs? Interestingly, LLM-based APR presents a unique opportunity to fully automate the plastic surgery hypothesis via fine-tuning (training on the buggy project) and prompting (directly providing valuable code ingredients as hints to the LLM). To this end, we propose FitRepair, which combines the direct usage of LLMs with two domain-specific fine-tuning strategies and one prompting strategy (via information retrieval and static analysis) for more powerful APR. While traditional APR techniques require intensive manual efforts in both generating patches based on the plastic surgery hypothesis and guaranteeing patch validity, our approach is fully automated and general. Moreover, while it is very challenging to manually design heuristics/patterns for effectively leveraging the hypothesis, due to the power of LLMs in code vectorization/understanding, even partial/imprecise project-specific information can still guide LLMs in generating correct patches! Our experiments on the widely studied Defects4j 1.2 and 2.0 datasets show that FitRepair fixes 89 and 44 bugs (substantially outperforming baseline techniques by 15 and 8), respectively, demonstrating a promising future of the plastic surgery hypothesis in the era of LLMs.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {522–534},
numpages = {13},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3650212.3680342,
author = {He, Yifeng and Huang, Jiabo and Rong, Yuyang and Guo, Yiwen and Wang, Ethan and Chen, Hao},
title = {UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large Language Models for Program Testing},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680342},
doi = {10.1145/3650212.3680342},
abstract = {The remarkable capability of large language models (LLMs) in 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
generating high-quality code has drawn increasing attention 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
in the software testing community.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
However, existing code LLMs often demonstrate unsatisfactory capabilities in generating accurate, complete tests
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
since they were trained on code snippets collected without 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
differentiating between code for testing and for other purposes.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this paper, we present a large-scale dataset, UniTSyn, which can enhance LLMs for Unit Test Synthesis. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Associating tests with the tested functions is crucial for LLMs to infer the expected behavior and the logic paths to be verified.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
By leveraging Language Server Protocol, UniTSyn achieves the challenging goal of collecting focal-test pairs without per-project execution setups or per-language heuristics, which tend to be fragile and difficult to scale.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Containing 2.7 million focal-test pairs across five mainstream programming languages, it can enhance the test generation ability of LLMs.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Our experiments demonstrate that, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
by building an autoregressive LLM based on UniTSyn,
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
we can achieve significant benefits in learning and understanding unit test representations, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
resulting in improved generation accuracy and code coverage 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
across all the evaluated programming languages.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1061–1072},
numpages = {12},
keywords = {Large language models, dataset, software testing, test case generation},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3577190.3614137,
author = {G\"{o}n\c{c}, Kaan and Sa\u{g}lam, Baturay and Dalmaz, Onat and \c{C}ukur, Tolga and Kozat, Serdar and Dibeklioglu, Hamdi},
title = {User Feedback-based Online Learning for Intent Classification},
year = {2023},
isbn = {9798400700552},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577190.3614137},
doi = {10.1145/3577190.3614137},
abstract = {Intent classification is a key task in natural language processing (NLP) that aims to infer the goal or intention behind a user’s query. Most existing intent classification methods rely on supervised deep models trained on large annotated datasets of text-intent pairs. However, obtaining such datasets is often expensive and impractical in real-world settings. Furthermore, supervised models may overfit or face distributional shifts when new intents, utterances, or data distributions emerge over time, requiring frequent retraining. Online learning methods based on user feedback can overcome this limitation, as they do not need access to intents while collecting data and adapting the model continuously. In this paper, we propose a novel multi-armed contextual bandit framework that leverages a text encoder based on a large language model (LLM) to extract the latent features of a given utterance and jointly learn multimodal representations of encoded text features and intents. Our framework consists of two stages: offline pretraining and online fine-tuning. In the offline stage, we train the policy on a small labeled dataset using a contextual bandit approach. In the online stage, we fine-tune the policy parameters using the REINFORCE algorithm with a user feedback-based objective, without relying on the true intents. We further introduce a sliding window strategy for simulating the retrieval of data samples during online training. This novel two-phase approach enables our method to efficiently adapt to dynamic user preferences and data distributions with improved performance. An extensive set of empirical studies indicate that our method significantly outperforms policies that omit either offline pretraining or online fine-tuning, while achieving competitive performance to a supervised benchmark trained on an order of magnitude larger labeled dataset.},
booktitle = {Proceedings of the 25th International Conference on Multimodal Interaction},
pages = {613–621},
numpages = {9},
keywords = {Contextual Bandits, Intent Classification, Multimodal Learning, Online Learning},
location = {Paris, France},
series = {ICMI '23}
}

@inproceedings{10.1145/3627673.3679881,
author = {Ding, Yuyang and Hu, Hanglei and Zhou, Jie and Chen, Qin and Jiang, Bo and He, Liang},
title = {Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679881},
doi = {10.1145/3627673.3679881},
abstract = {With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (SocraticLLM), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named SocraticMATH, which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of SocraticLLM by comparing it with several strong generative models. The codes and datasets are available on https://github.com/ECNU-ICALK/SocraticMath.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3730–3735},
numpages = {6},
keywords = {LLMs, conversation, mathematics, socratic teaching},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3660650.3660663,
author = {Lascelles-Palys, Louis and Lawrence, Ramon},
title = {Live Session Gamification using PrairieLearn},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660663},
doi = {10.1145/3660650.3660663},
abstract = {Encouraging students to complete practice questions is challenging, especially with numerous distractions and the capabilities of generative AI. Although there are a variety of techniques and systems for synchronous question answering, these systems are limited in the types of questions that can be asked. Gamification has been applied to help motivate students to practice by using incentives such as badges, bonus marks, and competitions. This work developed an extension to the PrairieLearn system allowing for synchronous question and answer sessions with scoreboards and badge awards as student incentives. A key feature is the capability for automatic grading and including complex questions not easily done by other systems, while still making it fun for students to complete. Student feedback in an upper-year course was very positive with students reporting that it encouraged them to complete the questions.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {17},
numpages = {2},
keywords = {PrairieLearn, automatic grading, competition, databases, gamification, leaderboard, student engagement},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3643659.3643936,
author = {Zhu, Taohong and Newton, William and Embury, Suzanne and Sun, Youcheng},
title = {TAIiST CPS-UAV at the SBFT Tool Competition 2024},
year = {2024},
isbn = {9798400705625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643659.3643936},
doi = {10.1145/3643659.3643936},
abstract = {This paper presents an innovative approach to testing Cyber-Physical Systems (CPS) with a specific focus on Unmanned Aerial Vehicles (UAVs) using Large Language Models (LLMs). In the rapidly evolving field of UAV technology, ensuring the reliability and safety of these systems is of utmost importance. Traditional testing methods often fall short in addressing the complex, dynamic, and stateful environments in which UAVs operate. To bridge this gap, we propose the use of state-of-the-art LLMs.Our methodology leverages the capabilities of LLMs to "intelligently" simulate a wide range of real-world scenarios and interactions that UAVs may encounter. This includes interpreting and responding to dynamic environmental changes, unexpected obstacles, and real-time decision-making processes. By integrating LLMs into the testing framework, we can create more comprehensive, realistic, and efficient testing scenarios for CPS-UAVs.We demonstrate the effectiveness of our approach through a series of experiments using popular UAV platforms including PX4 and Ardupilot. Our code and implementation are made publicly available in our project page https://github.com/Trusted-AI-in-System-Test.},
booktitle = {Proceedings of the 17th ACM/IEEE International Workshop on Search-Based and Fuzz Testing},
pages = {51–52},
numpages = {2},
location = {Lisbon, Portugal},
series = {SBFT '24}
}

@inproceedings{10.1145/3687311.3687404,
author = {Gao, Rong and Ni, Qin and Hu, Bingying},
title = {Fairness of Large Language Models in Education},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687404},
doi = {10.1145/3687311.3687404},
abstract = {The paper investigates the fairness of Large Language Models (LLMs) in education. It discusses the transformative impact of LLMs on teaching and learning practices, highlighting their potential biases and emphasizing the necessity for fairness. It categorizes the applications of AI in education and outlines strategies for improving fairness in LLMs through pre-processing, in-processing, and post-processing techniques. The conclusion advocates for a multidimensional strategy in leveraging AI's potential in education, ensuring a balance between technological advancements and a steadfast commitment to inclusivity and fairness.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {1–0},
location = {Guilin, China},
series = {IECT '24}
}

@inproceedings{10.1145/3640457.3688047,
author = {Aluri, Geetha Sai and Sharma, Siddharth and Sharma, Tarun and Delgado, Joaquin},
title = {Playlist Search Reinvented: LLMs Behind the Curtain},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688047},
doi = {10.1145/3640457.3688047},
abstract = {Improving search functionality poses challenges such as data scarcity for model training, metadata enrichment for comprehensive document indexing, and the labor-intensive manual annotation for evaluation. Traditionally, iterative methods relying on human annotators and customer feedback have been used. However, recent advancements in Large Language Models (LLMs) offer new solutions. This paper focuses on applying LLMs to playlist search. Leveraging LLMs’ contextual understanding and generative capabilities automates metadata enrichment, reducing manual efforts and expediting training. LLMs also address data scarcity by generating synthetic training data and serve as scalable judges for evaluation, enhancing search performance assessment. We demonstrate how these innovations enhance playlist search, overcoming traditional limitations to improve search result accuracy and relevance.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {813–815},
numpages = {3},
keywords = {LLM augmentation, MLOps, Retrieval, Semantic Search},
location = {Bari, Italy},
series = {RecSys '24}
}

@article{10.5555/3715622.3715636,
author = {Hamdan, Basil},
title = {Integrating ChatGPT in Cybersecurity Education: Use Cases and Implications},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {This paper examines the integration of ChatGPT into cybersecurity courses, emphasizing practical applications and ethical considerations within educational settings. Through use case in malware development and web application security, the study explores ChatGPT's dual role in cybersecurity education. It addresses ethical AI behavior, challenges in contextual awareness, and the risks associated with AI-generated content misuse. This paper aims to provide educators with insights to navigate the complexities of AI-enhanced cybersecurity education effectively.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {105–114},
numpages = {10}
}

@inproceedings{10.1145/3637528.3671498,
author = {Wen, Qingsong and Liang, Jing and Sierra, Carles and Luckin, Rose and Tong, Richard and Liu, Zitao and Cui, Peng and Tang, Jiliang},
title = {AI for Education (AI4EDU): Advancing Personalized Education with LLM and Adaptive Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671498},
doi = {10.1145/3637528.3671498},
abstract = {Recent advanced AI technologies, especially large language models (LLMs) like GPTs, have significantly advanced the field of data mining and led to the development of various LLM-based applications. AI for education (AI4EDU) is a vibrant multi-disciplinary field of data mining, machine learning, and education, with increasing importance and extraordinary potential. In this field, LLM and adaptive learning-based models can be utilized as interfaces in human-in-the-loop education systems, where the model serves as a mediator among the teacher, students, and machine capabilities, including its own. This perspective has several benefits, including the ability to personalize interactions, allow unprecedented flexibility and adaptivity for human-AI collaboration and improve the user experience. However, several challenges still exist, including the need for more robust and efficient algorithms, designing effective user interfaces, and ensuring ethical considerations are addressed. This workshop aims to bring together researchers and practitioners from academia and industry to explore cutting-edge AI technologies for personalized education, especially the potential of LLMs and adaptive learning technologies.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6743–6744},
numpages = {2},
keywords = {adaptive learning, edtech, education, llm},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3664647.3681251,
author = {Ding, Peng and Wu, Jingyu and Kuang, Jun and Ma, Dan and Cao, Xuezhi and Cai, Xunliang and Chen, Shi and Chen, Jiajun and Huang, Shujian},
title = {Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681251},
doi = {10.1145/3664647.3681251},
abstract = {Multi-modal Large Language Models (MLLMs) have demonstrated remarkable performance on various visual-language understanding and generation tasks. However, MLLMs occasionally generate content inconsistent with the given images, which is known as "hallucination". Prior works primarily center on evaluating hallucination using standard, unperturbed benchmarks, which overlook the prevalent occurrence of perturbed inputs in real-world scenarios-such as image cropping or blurring-that are critical for a comprehensive assessment of MLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI, the first benchmark designed to evaluate Hallucination in MLLMs within Perturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios, containing 1,260 perturbed images from 11 object types. Each image is accompanied by detailed annotations, which include fine-grained hallucination types, such as existence, attribute, and relation. We equip these annotations with a rich set of questions, making Hallu-PI suitable for both discriminative and generative tasks. Extensive experiments on 12 mainstream MLLMs, such as GPT-4V and Gemini-Pro Vision, demonstrate that these models exhibit significant hallucinations on Hallu-PI, which is not observed in unperturbed scenarios. Furthermore, our research reveals a severe bias in MLLMs' ability to handle different types of hallucinations. We also design two baselines specifically for perturbed scenarios, namely Perturbed-Reminder and Perturbed-ICL. We hope that our study will bring researchers' attention to the limitations of MLLMs when dealing with perturbed inputs, and spur further investigations to address this issue. Our code and datasets are publicly available at https://github.com/NJUNLP/Hallu-PI.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {10707–10715},
numpages = {9},
keywords = {benchmark evaluation, hallucination, multi-modal large language models, perturbed inputs},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3579027.3608972,
author = {Acher, Mathieu and Duarte, Jos\'{e} Galindo and J\'{e}z\'{e}quel, Jean-Marc},
title = {On Programming Variability with Large Language Model-based Assistant},
year = {2023},
isbn = {9798400700910},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579027.3608972},
doi = {10.1145/3579027.3608972},
abstract = {Programming variability is central to the design and implementation of software systems that can adapt to a variety of contexts and requirements, providing increased flexibility and customization. Managing the complexity that arises from having multiple features, variations, and possible configurations is known to be highly challenging for software developers. In this paper, we explore how large language model (LLM)-based assistants can support the programming of variability.We report on new approaches made possible with LLM-based assistants, like: features and variations can be implemented as prompts; augmentation of variability out of LLM-based domain knowledge; seamless implementation of variability in different kinds of artefacts, programming languages, and frameworks, at different binding times (compile-time or run-time). We are sharing our data (prompts, sessions, generated code, etc.) to support the assessment of the effectiveness and robustness of LLMs for variability-related tasks.},
booktitle = {Proceedings of the 27th ACM International Systems and Software Product Line Conference - Volume A},
pages = {8–14},
numpages = {7},
keywords = {generative AI, large language model, programming, software product lines, variability},
location = {Tokyo, Japan},
series = {SPLC '23}
}

@inproceedings{10.1145/3589335.3641306,
author = {Mao, Haitao and Zhao, Jianan and He, Xiaoxin and Chen, Zhikai and Huang, Qian and Zhu, Zhaocheng and Tang, Jian and Bronstein, Micheal and Bresson, Xavier and Hooi, Bryan and Zhang, Haiyang and Tang, Xianfeng and Chen, Luo and Tang, Jiliang},
title = {The 1st International Workshop on Graph Foundation Models (GFM)},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641306},
doi = {10.1145/3589335.3641306},
abstract = {Foundation models such as GPT-4 for natural language processing (NLP), Flamingo for computer vision (CV), have set new benchmarks in AI by delivering state-of-the-art results across various tasks with minimal task-specific data. Despite their success, the application of these models to the graph domain is challenging due to the relational nature of graph-structured data. To address this gap, we propose the Graph Foundation Model (GFM) Workshop, the first workshop for GFMs, dedicated to exploring the adaptation and development of foundation models specifically designed for graph data. The GFM workshop focuses on two critical questions: (1) How can the underlying capabilities of existing foundation models be effectively applied to graph data? (2) What foundational principles should guide the creation of models tailored to the graph domain? Through a curated set of panel sections, keynote talks, and paper presentations, our workshop intends to catalyze innovative approaches and theoretical frameworks for Graph Foundation Models (GFMs). We target a broad audience, encompassing researchers, practitioners, and students, and aim to lay the groundwork for the next wave of breakthroughs in integrating graph data with foundation models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1789–1792},
numpages = {4},
keywords = {data mining, foundation model, graph machine learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3643991.3644903,
author = {Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole and Quaranta, Luigi},
title = {Leveraging GPT-like LLMs to Automate Issue Labeling},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644903},
doi = {10.1145/3643991.3644903},
abstract = {Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {469–480},
numpages = {12},
keywords = {LLM, issue labeling, GPT, software maintenance and evolution, labeling unstructured data},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3664476.3670446,
author = {Ohm, Marc and Bungartz, Christian and Boes, Felix and Meier, Michael},
title = {Assessing the Impact of Large Language Models on Cybersecurity Education: A Study of ChatGPT's Influence on Student Performance},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670446},
doi = {10.1145/3664476.3670446},
abstract = {The popularity of chatbots to facilitate day-to-day business, including students and their study exercises, is on the rise. This paper investigates the extent and effects on the academic performance of students that leverage such tools. While many other approaches are hypothesized and discussed, we measure empirically. We recorded and compared the performance of cybersecurity students in weekly exercises and final exams over a period of three years. This allows us to have three groups with varying degrees of ChatGPT influence, namely no access, uncontrolled access, and controlled access. In an anonymous survey, we found that approximately 80% of our students utilize ChatGPT during the weekly assignments in 2023. However, none of them indicated this on their submission, despite it being a mandatory requirement. Through statistical analysis of achieved points in our sample groups, we identified that students perform similarly on the weekly assignments. However, their performance on the final examination deteriorates.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {104},
numpages = {7},
keywords = {ChatGPT, Education, Teaching},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3657604.3664677,
author = {Barno, Erin and Albaladejo-Gonz\'{a}lez, Mariano and Reich, Justin},
title = {Scaling Generated Feedback for Novice Teachers by Sustaining Teacher Educators' Expertise: A Design to Train LLMs with Teacher Educator Endorsement of Generated Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664677},
doi = {10.1145/3657604.3664677},
abstract = {When using simulations to design and implement novice teacher practice, a teacher educator may be concerned about if what is technically possible in terms of generating feedback to novice teachers' responses is educationally purposeful to support their learning. This paper details the design of infrastructure to incorporate user feedback within the Teacher Moments platform that is generated by an AI agent, and how we designed to sustain and scale the expertise of mathematics teacher educators when training a large language model. To best support the learning of novice mathematics teacher users to enact ambitious and equitable mathematics teaching, this paper explains the research design of training a large language model by collaborating with mathematics teacher educators to edit or endorse generated feedback across multiple training cycles. This paper also describes the UI design to explore potential of hosting such processes all within the Teacher Moments platform.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {412–416},
numpages = {5},
keywords = {digital simulations, generative AI, natural language processing, professional learning, teacher education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3617367,
author = {Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio},
title = {“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3617367},
doi = {10.1145/3617367},
abstract = {Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {4},
numpages = {31},
keywords = {AI, Artificial Intelligence, automatic code generation, Codex, Copilot, CS1, GitHub, GPT-3, HCI, introductory programming, large language models, LLM, novice programming, OpenAI}
}

@inproceedings{10.1145/3584371.3613067,
author = {Sagar, Dikshant and Risheh, Ali and Sheikh, Nida and Forouzesh, Negin},
title = {Physics-Guided Deep Generative Model For New Ligand Discovery},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613067},
doi = {10.1145/3584371.3613067},
abstract = {Structure-based drug discovery aims to identify small molecules that can attach to a specific target protein and change its functionality. Recently, deep learning has shown great promise in generating drug-like molecules with specific biochemical features and conditioned with structural features. However, they usually fail to incorporate an essential factor: the underlying physics which guides molecular formation and binding in real-world scenarios. In this work, we describe a physics-guided deep generative model for new ligand discovery, conditioned not only on the binding site but also on physics-based features that describe the binding mechanism between a receptor and a ligand. The proposed hybrid model has been tested on large protein-ligand complexes and small host-guest systems. Using the top-N methodology, on average more than 75% of the generated structures by our hybrid model were stronger binders than the original reference ligand. All of them had higher ΔGbind (affinity) values than the ones generated by the previous state-of-the-art method by an average margin of 1.88 kcal/mol. The visualization of the top-5 ligands generated by the proposed physics-guided model and the reference deep learning model demonstrate more feasible conformations and orientations by the former. The future directions include training and testing the hybrid model on larger datasets, adding more relevant physics-based features, and interpreting the deep learning outcomes from biophysical perspectives.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
pages = {1–9},
numpages = {9},
keywords = {drug discovery, deep learning, generative neural networks, implicit solvent models},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3650212.3685308,
author = {Molina, Facundo and Copia, Juan Manuel and Gorla, Alessandra},
title = {FixCheck: A Tool for Improving Patch Correctness Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3685308},
doi = {10.1145/3650212.3685308},
abstract = {Patch correctness assessment aims at effectively detecting  overfitted patches, i.e., patches that causes all tests  to pass but do not actually fix the bug. Although several automated techniques for assessing patch correctness have been proposed,  these techniques typically yield a binary result (correct/incorrect)  without providing any additional information explaining the rationale behind the decision of classifying a patch as correct or incorrect. This tool demo paper presents FixCheck, a tool based on  static analysis, random testing and Large Language Models (LLMs), that seeks to improve the patch correctness analysis process by  providing fault-revealing tests for potentially incorrect patches. To this end, FixCheck first employs static analysis and random testing  to generate a comprehensive set of test cases that are similar to the original failing test case.  Then, FixCheck relies on LLMs to derive meaningful assertions for  each new test case. Finally, FixCheck executes  the generated tests, and those that fail are  selected and prioritized based on their likelihood of revealing a defect in the patch.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1856–1860},
numpages = {5},
keywords = {Dynamic Analysis, Large Language Models, Patch Correctness Assessment},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1613/jair.1.13550,
author = {Javed, Rana Tallal and Nasir, Osama and Borit, Melania and Vanh\'{e}e, Lo\"{\i}s and Zea, Elias and Gupta, Shivam and Vinuesa, Ricardo and Qadir, Junaid},
title = {Get out of the BAG! Silos in AI Ethics Education: Unsupervised Topic Modeling Analysis of Global AI Curricula},
year = {2022},
issue_date = {May 2022},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {73},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.13550},
doi = {10.1613/jair.1.13550},
abstract = {The domain of Artificial Intelligence (AI) ethics is not new, with discussions going back at least 40 years. Teaching the principles and requirements of ethical AI to students is considered an essential part of this domain, with an increasing number of technical AI courses taught at several higher-education institutions around the globe including content related to ethics. By using Latent Dirichlet Allocation (LDA), a generative probabilistic topic model, this study uncovers topics in teaching ethics in AI courses and their trends related to where the courses are taught, by whom, and at what level of cognitive complexity and specificity according to Bloom’s taxonomy. In this exploratory study based on unsupervised machine learning, we analyzed a total of 166 courses: 116 from North American universities, 11 from Asia, 36 from Europe, and 10 from other regions. Based on this analysis, we were able to synthesize a model of teaching approaches, which we call BAG (Build, Assess, and Govern), that combines specific cognitive levels, course content topics, and disciplines affiliated with the department(s) in charge of the course. We critically assess the implications of this teaching paradigm and provide suggestions about how to move away from these practices. We challenge teaching practitioners and program coordinators to reflect on their usual procedures so that they may expand their methodology beyond the confines of stereotypical thought and traditional biases regarding what disciplines should teach and how.
This article appears in the AI &amp; Society track.},
journal = {J. Artif. Int. Res.},
month = may,
numpages = {33},
keywords = {philosophical foundations, scientific discovery, data mining, discourse modelling}
}

@inproceedings{10.1145/3626203.3670577,
author = {Nadel, Peter and Maloney, Delilah and Monahan, Kyle},
title = {Enabling access to large-language models (LLMs) at scale for higher education},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670577},
doi = {10.1145/3626203.3670577},
abstract = {The use of language models, particularly large-language models (LLMs), have been increasingly popular and can be transformative in higher education, by both enabling novel research approaches and providing instructional opportunities for skills needed in data science and engineering. However, running these LLMs traditionally requires access to advanced hardware resources and technical knowledge. To better provide a platform for experimenting with LLMs for users of all skill levels, we developed the Tufts Technology Services (TTS) LLM-Hub, a series of example Jupyter notebooks served through Tufts Open OnDemand (OOD) to setup, configure, and run LLMs automatically. The TTS LLM-Hub enabled quick access to running LLMs, while reducing barriers to compute and enabling users to chat with an LLM in just four clicks. We have used these platforms for support of advanced data science courses, and to enable research computing at Tufts.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {49},
numpages = {4},
keywords = {High-Performance Computing (HPC), Large-Language Models (LLMs), Open OnDemand (OOD)},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@article{10.1109/TCBB.2024.3477592,
author = {Zhao, Dengwei and Zhou, Jingyuan and Tu, Shikui and Xu, Lei},
title = {&lt;italic&gt;De Novo&lt;/italic&gt; Drug Design by Multi-Objective Path Consistency Learning With Beam A&lt;sup&gt;*&lt;/sup&gt; Search},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3477592},
doi = {10.1109/TCBB.2024.3477592},
abstract = {Generating high-quality and drug-like molecules from scratch within the expansive chemical space presents a significant challenge in the field of drug discovery. In prior research, value-based reinforcement learning algorithms have been employed to generate molecules with multiple desired properties iteratively. The immediate reward was defined as the evaluation of intermediate-state molecules at each step, and the learning objective would be maximizing the expected cumulative evaluation scores for all molecules along the generative path. However, this definition of the reward was misleading, as in reality, the optimization target should be the evaluation score of only the final generated molecule. Furthermore, in previous works, randomness was introduced into the decision-making process, enabling the generation of diverse molecules but no longer pursuing the maximum future rewards. In this paper, immediate reward is defined as the improvement achieved through the modification of the molecule to maximize the evaluation score of the final generated molecule exclusively. Originating from the A&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$^*$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;*&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq3-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; search, path consistency (PC), i.e., &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$f$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq4-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; values on one optimal path should be identical, is employed as the objective function in the update of the &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$f$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq5-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; value estimator to train a multi-objective &lt;italic&gt;de novo&lt;/italic&gt; drug designer. By incorporating the &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$f$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:mi&gt;f&lt;/mml:mi&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq6-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; value into the decision-making process of beam search, the DrugBA&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$^*$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;*&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="zhao-ieq7-3477592.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; algorithm is proposed to enable the large-scale generation of molecules that exhibit both high quality and diversity. Experimental results demonstrate a substantial enhancement over the state-of-the-art algorithm QADD in multiple molecular properties of the generated molecules.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = oct,
pages = {2459–2470},
numpages = {12}
}

@inproceedings{10.1145/3677045.3685461,
author = {Krogstie, John and Krogstie, Birgit and van der Velden, Maja and Gasparini, Andrea Alessandro and Chasanidou, Dimitra},
title = {Sustainability analysis of AI-based tools in higher education},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677045.3685461},
doi = {10.1145/3677045.3685461},
abstract = {Educating the next generation of students on pathways toward sustainability is important and highly relevant for various disciplines, including HCI and CSCW. HCI research has contributed much to the field of sustainability, though mainly taking user-centric and environmental perspectives, missing a holistic view of sustainability. By incorporating sustainability goals into design and development processes, students can learn that they can have a significant impact and improve the longevity and durability of digital tools. This workshop will present and explore the SusAF framework as a tool for the sustainability analysis of digital tools in university courses. SusAF is an established framework that enables exploring the different dimensions of sustainability. In this workshop, we will apply this framework to AI-based tools, such as ChatGPT and DALL-E. The goal is to present SusAF as a framework for sustainability analysis of software systems used in higher education and to explore, with the participants, the different sustainability challenges of using AI-based tools. In this full-day workshop, we want to engage an interdisciplinary group of researchers, lecturers, and practitioners in sustainability analysis and we will explore the relevance of SusAF in various educational settings.},
booktitle = {Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
articleno = {46},
numpages = {3},
keywords = {Artificial Intelligence, Higher Education, Sustainability Analysis, Sustainability Awareness Framework},
location = {Uppsala, Sweden},
series = {NordiCHI '24 Adjunct}
}

@inproceedings{10.1145/3613904.3642229,
author = {Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun},
title = {ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642229},
doi = {10.1145/3613904.3642229},
abstract = {As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {19},
keywords = {Children Aged 6-12, Computational Thinking, Large Language Model, Scratch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.5555/3715638.3715650,
author = {Kwan, Pak},
title = {Supercharging Python Scripting Education with ChatGPT! - How I Use ChatGPT in my Advanced Python Scripting Class},
year = {2024},
issue_date = {September 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {4},
issn = {1937-4771},
abstract = {In recent years, the integration of artificial intelligence (AI) technologies into education has emerged as a promising approach to enhance student learning experiences and outcomes. This tutorial aims to explore how ChatGPT [1] can be effectively utilized to teach advanced Python scripting at the college level. Through interactive demonstrations, discussions, case study and hands-on activities, participants will gain insights into the potential applications of ChatGPT in the classroom and learn practical strategies for integrating this cutting-edge technology into their curriculum.},
journal = {J. Comput. Sci. Coll.},
month = sep,
pages = {35–37},
numpages = {3}
}

@inproceedings{10.1145/3636555.3636850,
author = {Hutt, Stephen and DePiro, Allison and Wang, Joann and Rhodes, Sam and Baker, Ryan S and Hieb, Grayson and Sethuraman, Sheela and Ocumpaugh, Jaclyn and Mills, Caitlin},
title = {Feedback on Feedback: Comparing Classic Natural Language Processing and Generative AI to Evaluate Peer Feedback},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636850},
doi = {10.1145/3636555.3636850},
abstract = {Peer feedback can be a powerful tool as it presents learning opportunities for both the learner receiving feedback as well as the learner providing feedback. Despite its utility, it can be difficult to implement effectively, particularly for younger learners, who are often novices at providing feedback. It can be difficult for students to learn what constitutes “good” feedback – particularly in open-ended problem-solving contexts. To address this gap, we investigate both classical natural language processing techniques and large language models, specifically ChatGPT, as potential approaches to devise an automated detector of feedback quality (including both student progress towards goals and next steps needed). Our findings indicate that the classical detectors are highly accurate and, through feature analysis, we elucidate the pivotal elements influencing its decision process. We find that ChatGPT is less accurate than classical NLP but illustrate the potential of ChatGPT in evaluating feedback, by generating explanations for ratings, along with scores. We discuss how the detector can be used for automated feedback evaluation and to better scaffold peer feedback for younger learners.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {55–65},
numpages = {11},
keywords = {Generative AI, Language Analytics, Large Language Models, Natural Language Processing, Peer Feedback},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3637989.3637998,
author = {Puertas, Enrique and Mariscal-Vivas, Gonzalo and Mart\'{\i}nez-Requejo, Sonia},
title = {Development of chatbots connected to Learning Management Systems for the support and formative assessment of students},
year = {2024},
isbn = {9798400708732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637989.3637998},
doi = {10.1145/3637989.3637998},
abstract = {This work discusses the development of chatbots connected to Learning Management Systems for the support and formative assessment of students in higher education. Because of the diversity of students, and limited time for teaching and evaluation, teachers are facing issues in terms of personalized learning and individualized attention. We present a system connected to a Learning Management System for retrieving course documents, that we use for feeding a chatbot that uses Large Language Model (LLM) in the background for supporting students. The architecture allows students to ask questions against an LLM model, and the response text uses a knowledge base built using the content of the notes and documents that teachers have uploaded to the educational platform as context and sources of information. This allows the answers to be specific and updated, providing insights on how chatbots can be used to enhance the learning experience of students in higher education.},
booktitle = {Proceedings of the 2023 7th International Conference on Education and E-Learning},
pages = {14–18},
numpages = {5},
keywords = {artificial intelligence, chatbot, e-learning, large language models, learning bots, learning management system},
location = {Tokyo, Japan},
series = {ICEEL '23}
}

@article{10.5555/3606388.3606397,
author = {Bhattacharya, Sambit and Czejdo, Bogdan},
title = {Trustworthiness of Artificial Intelligence: Teaching Factors that Influence AI-Supported Decision Making},
year = {2023},
issue_date = {April 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {6},
issn = {1937-4771},
abstract = {Reports of progress in research into Artificial Intelligence (AI) and its applications are accumulating very rapidly. Specifically, Machine Learning (ML) applications based on large data sets have moved to the forefront of innovations in the field. New ML models have led to the adoption of AI in different disciplines. The development of the most recent large language models has created so much interest that it might mean a revolution in using of AI. Some make a stronger claim that it is a turning point in human civilization's history, and we have started the AI age after replacing the obsolete in many aspects of Information Age applications. One of the immediate challenges is how to use AI and ML responsibly with proper protection for humans and human society. In this paper, we report on our efforts in introducing trustworthiness of ML in college curricula and what factors influence AI-supported decision making. The main goal is to allow students to gain an understanding not only of concepts but also of the limitations of AI. This will help in their participation in our society of the AI Age. The process of AI democratization needs to be established to control the growth of ML use and understand the human dangers of various types of data-driven modeling approaches in AI.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {85–94},
numpages = {10}
}

@inproceedings{10.1145/3678884.3681826,
author = {Prpa, Mirjana and Troiano, Giovanni and Yao, Bingsheng and Li, Toby Jia-Jun and Wang, Dakuo and Gu, Hansu},
title = {Challenges and Opportunities of LLM-Based Synthetic Personae and Data in HCI},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681826},
doi = {10.1145/3678884.3681826},
abstract = {Synthetic personae and data powered by artificial intelligence (AI) are emerging in many HCI areas, including education and training, gaming, and piloting research studies. Recently, Large Language Models (LLMs) have shown promise for synthetic AI personae, experimenting with human and social simulacra and producing synthetic data. This presents challenges and opportunities for extending HCI research via LLMs and AI. In this proposed workshop, we engage HCI researchers interested in working with LLMs, synthetic personae, and synthetic data through speculative design and producing visions, desiderata, and requirements for future HCI research engaging with synthetic personae/data. The outcomes of this workshop may be disseminated to the HCI community through scientific publications or special issues to facilitate continued discussion and advance knowledge on a timely HCI topic.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {716–719},
numpages = {4},
keywords = {ai, large language models, sketching, speculative design, synthetic data, synthetic personae},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3627673.3679830,
author = {Pan, Bo and Zhang, Zheng and Zhang, Yifei and Hu, Yuntong and Zhao, Liang},
title = {Distilling Large Language Models for Text-Attributed Graph Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679830},
doi = {10.1145/3627673.3679830},
abstract = {Text-Attributed Graphs (TAGs) are graphs of connected textual documents. Graph models can efficiently learn TAGs, but their training heavily relies on human-annotated labels, which are scarce or even unavailable in many applications. Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues. Therefore, in this work, we focus on synergizing LLMs and graph models with their complementary strengths by distilling the power of LLMs into a local graph model on TAG learning. To address the inherent gaps between LLMs (generative models for texts) and graph models (discriminative models for graphs), we propose first to let LLMs teach an interpreter with rich rationale and then let a student model mimic the interpreter's reasoning without LLMs' rationale. We convert LLM's textual rationales to multi-level graph rationales to train the interpreter model and align the student model with the interpreter model based on the features of TAGs. Extensive experiments validate the efficacy of our proposed framework.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1836–1845},
numpages = {10},
keywords = {knowledge distillation, large language models, text-attributed graphs},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3582515.3609555,
author = {Baldassarre, Maria Teresa and Caivano, Danilo and Fernandez Nieto, Berenice and Gigante, Domenico and Ragone, Azzurra},
title = {The Social Impact of Generative AI: An Analysis on ChatGPT},
year = {2023},
isbn = {9798400701160},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582515.3609555},
doi = {10.1145/3582515.3609555},
abstract = {In recent months, the impact of Artificial Intelligence (AI) on citizens’ lives has gained considerable public interest, driven by the emergence of Generative AI models, ChatGPT in particular. The rapid development of these models has sparked heated discussions regarding their benefits, limitations, and associated risks. Generative models hold immense promise across multiple domains, such as healthcare, finance, and education, to cite a few, presenting diverse practical applications. Nevertheless, concerns about potential adverse effects have elicited divergent perspectives, ranging from privacy risks to escalating social inequality. This paper adopts a methodology to delve into the societal implications of Generative AI tools, focusing primarily on the case of ChatGPT. It evaluates the potential impact on several social sectors and illustrates the findings of a comprehensive literature review of both positive and negative effects, emerging trends, and areas of opportunity of Generative AI models. This analysis aims to facilitate an in-depth discussion by providing insights that can inspire policy, regulation, and responsible development practices to foster a citizen-centric AI.},
booktitle = {Proceedings of the 2023 ACM Conference on Information Technology for Social Good},
pages = {363–373},
numpages = {11},
keywords = {Citizen-centric AI, Generative AI Social Impact, Trustable AI},
location = {Lisbon, Portugal},
series = {GoodIT '23}
}

@inproceedings{10.1145/3613905.3650937,
author = {Xiao, Ruiwei and Hou, Xinying and Stamper, John},
title = {Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650937},
doi = {10.1145/3613905.3650937},
abstract = {Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students’ problem-solving and learning, we conducted a think-aloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing help responses from content, format, and granularity levels to accurately identify and meet students’ learning needs.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {142},
numpages = {10},
keywords = {GPT, Help-seeking, Introductory Programming, Large Language Model, Programming Hint},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3675249.3675307,
author = {Yao, Huan and Bao, Wanying and Wu, Hequn},
title = {BabyGAN for Facial Contour Reversion: AI Course Applications Using U-Net Architecture},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675307},
doi = {10.1145/3675249.3675307},
abstract = {BabyGAN is a generative adversarial network model based on the U-net architecture and residual networks, designed for the transformation of adult facial contours into baby facial contours. This model is primarily used in the artificial intelligence practical courses of vocational colleges, focusing on information technology education. A key feature of BabyGAN is its ability to help students deeply understand the logical structure of generative adversarial networks while also fostering their enthusiasm. Compared to other GAN models used in teaching, BabyGAN has the advantage of allowing students to easily construct training sets, enabling immediate use of class-specific datasets in the classroom. The working principle of BabyGAN involves integrating a special keypoint constraint loss function in the generator to produce high-quality baby facial contours, thereby transforming adult facial contours into corresponding high-quality infant facial contours. BabyGAN plays a significant role in the future work scenarios of students. Incorporating the BabyGAN course into AI curricula effectively blends information technology education with students' future career prospects. The application of GANs to meet user needs is a current research hotspot. Introducing students to BabyGAN in a fun and educational setting also aligns with market demands, equipping students with practical skills and the ability to apply these skills in future work contexts.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {324–329},
numpages = {6},
location = {Sanming, China},
series = {ICCMT '24}
}

@inproceedings{10.1145/3664934.3664955,
author = {Baldoni, Matteo and Baroglio, Cristina and Bucciarelli, Monica and Micalizio, Roberto and Gandolfi, Elena and Iani, Francesco and Marengo, Elisa and Capecchi, Sara},
title = {Thinking Strategies Training to Support the Development of Machine Learning Understanding. A study targeting fifth-grade children},
year = {2024},
isbn = {9798400716409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664934.3664955},
doi = {10.1145/3664934.3664955},
abstract = {Artificial Intelligence applications permeate our lives and are increasingly making the news, surprising society with applications that until a few years ago would have been relegated to the science fiction genre. Thanks to generative artificial intelligence, tools that once could only be used by highly qualified technical personnel are now in the hands of potentially inexperienced users, but unfortunately, the understanding of the layman is very far from the machinery behind the scenes. More than ever, it is necessary to help people develop an awareness that allows them to use these tools in an appropriate way and with the appropriate expectations. We believe this problem should be addressed by exploring ways to train thinking strategies to facilitate understanding of machine learning concepts that can be applied in daily life, not just by developing teaching tools on this or that topic. We describe our current activities with 9-10 years old children attending primary school and the ad hoc unplugged training we have developed to foster an understanding of machine learning mechanisms.},
booktitle = {Proceedings of the 2024 9th International Conference on Information and Education Innovations},
pages = {85–92},
numpages = {8},
keywords = {Artificial Intelligence, Education, Machine Learning, Thinking strategies, Training},
location = {Verbania, Italy},
series = {ICIEI '24}
}

@inproceedings{10.1145/3650212.3685554,
author = {Decrop, Alix},
title = {Leveraging Natural Language Processing and Data Mining to Augment and Validate APIs},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3685554},
doi = {10.1145/3650212.3685554},
abstract = {APIs are increasingly prominent for modern web applications, allowing millions of users around the world to access data. Reducing the risk of API defects - and consequently failures - is key, notably for security, availability, and maintainability purposes. Documenting an API is crucial, allowing the user to better understand it. Moreover, API testing techniques often require formal documentation as input. However, documenting is a time-consuming and error-prone task, often overlooked by developers. Natural Language Processing (NLP) could assist API development, as recent Large Language Models (LLMs) demonstrated exceptional abilities to automate tasks based on their colossal training data. Data mining could also be utilized, synthesizing API information scattered across the web. Hence, I present my PhD project aimed at exploring the usage of NLP-related technologies and data mining to augment and validate APIs. The research questions of this PhD project are: (1) What types of APIs can benefit from NLP and data mining assistance? (2) What API problems can be solved with such methods? (3) How effective are the methods (i.e. LLMs) in assisting APIs? (4) How efficient are the methods in assisting APIs (i.e. time and costs)?},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1906–1908},
numpages = {3},
keywords = {API, Automation, Data Mining, LLM, NLP, Software Testing},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1145/3609266.3594546,
author = {Dyer, Thomas and Steele, John and Mandernach, Jean},
title = {Three Student-Centered Approaches to Integrate ChatGPT in the Online Classroom: Effective eLearning (Special Series)},
year = {2023},
issue_date = {07-01-2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2023},
number = {7},
url = {https://doi.org/10.1145/3609266.3594546},
doi = {10.1145/3609266.3594546},
abstract = {In response to the advent of AI technologies like ChatGPT in academia, educators should not merely react with plagiarism policies but proactively integrate such tools to enhance learning. By cultivating AI literacy, integrating AI into assignments for interactive learning, and leveraging it for idea generation, we can prepare students for a digitally advanced future, promoting critical thinking and digital literacy while ensuring thoughtful use of technology to support student growth.},
journal = {ELearn},
month = jul,
articleno = {2}
}

@inproceedings{10.1145/3591196.3596818,
author = {Huang, Ziheng and Quan, Kexin and Chan, Joel and MacNeil, Stephen},
title = {CausalMapper: Challenging designers to think in systems with Causal Maps and Large Language Model},
year = {2023},
isbn = {9798400701801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591196.3596818},
doi = {10.1145/3591196.3596818},
abstract = {Professional designers often construct and explore conceptual representations (e.g.: design spaces) to help them reason about complex design situations and consider potential design pitfalls. However, it is often challenging, even for professional designers, to exhaustively consider the many pitfalls that might result from design activity. We present CausalMapper, a mixed-initiative system, that leverages a large language model (LLM) and a causal map representation to teach design students how to reason about the relationships between problems and solutions. Where creativity support tools often focus on ideating creative solutions, our mixed-initiative approach focuses on ideating ecosystems of solutions that holistically address a set of related problems. By leveraging the generative creativity of LLMs, designers are inspired to consider solutions and potential consequences that emerge when solutions are adopted. At the same time, leveraging the designers’ domain knowledge to account for and correct the biases inherent in LLMs. Through a case study, we demonstrate the functionality of this mixed-initiative system. The goal of this demo is to present a creativity support tool that is intended to teach design students to think more systematically by generating ideas that challenge their thinking rather just augmenting their creative potential.},
booktitle = {Proceedings of the 15th Conference on Creativity and Cognition},
pages = {325–329},
numpages = {5},
keywords = {creativity support tools, design space, large language models},
location = {Virtual Event, USA},
series = {C&amp;C '23}
}

@article{10.1145/3660826,
author = {Yan, Chuan and Meng, Mark Huasong and Xie, Fuman and Bai, Guangdong},
title = {Investigating Documented Privacy Changes in Android OS},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660826},
doi = {10.1145/3660826},
abstract = {Android has empowered third-party apps to access data and services on mobile devices since its genesis.This involves a wide spectrum of user privacy-sensitive data, such as the device ID and location. In recent years, Android has taken proactive measures to adapt its access control policies for such data, in response to the increasingly strict privacy protection regulations around the world. When each new Android version is released, its privacy changes induced by the version evolution are transparently disclosed, and we refer to them as documented privacy changes (DPCs). Implementing DPCs in Android OS is a non-trivial task, due to not only the dispersed nature of those access control points within the OS, but also the challenges posed by backward compatibility. As a result, whether the actual access control enforcement in the OS implementations aligns with the disclosed DPCs becomes a critical concern.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this work, we conduct the first systematic study on the consistency between the operational behaviors of the OS at runtime and the officially disclosed DPCs. We propose DopCheck, an automatic DPC-driven testing framework equipped with a large language model (LLM) pipeline. It features a serial of analysis to extract the ontology from the privacy change documents written in natural language, and then harnesses the few-shot capability of LLMs to construct test cases for the detection of DPC-compliance issues in OS implementations. We apply DopCheck with the latest versions (10 to 13) of Android Open Source Project (AOSP). Our evaluation involving 79 privacy-sensitive APIs demonstrates that DopCheck can effectively recognize DPCs from Android documentation and generate rigorous test cases. Our study reveals that the status quo of the DPC-compliance issues is concerning, evidenced by 19 bugs identified by DopCheck. Notably, 12 of them are discovered in Android 13 and 6 in Android 10 for the first time, posing more than 35% Android users to the risk of privacy leakage. Our findings should raise an alert to Android users and app developers on the DPC compliance issues when using or developing an app, and would also underscore the necessity for Google to comprehensively validate the actual implementation against its privacy documentation prior to the OS release.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {119},
numpages = {24},
keywords = {Android, documentation, privacy, testing}
}

@inproceedings{10.1145/3657604.3664671,
author = {Wang, Yuchen and Guo, Shangxin and Ling, Lin and Tan, Chee Wei},
title = {Nemobot: Crafting Strategic Gaming LLM Agents for K-12 AI Education},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664671},
doi = {10.1145/3657604.3664671},
abstract = {Artificial intelligence (AI) permeates modern society and is poised for further integration across various domains. However, there exists a notable deficiency in equipping K-12 students with foundational AI understanding. This paper introduces a novel learning framework that leverages large language models (LLMs) and strategic gaming to teach K-12 students about the inner workings of AI. The framework consists of a chatbot programming and testing IDE that enables K-12 students to construct AI from scratch, engage in strategic gameplay to generate instant training data, and improve the AI heuristics with a data-driven learning mechanism. With a tiered curriculum catering to diverse proficiency levels and fostering synchronous collaboration, this framework efficiently adapts learning experiences to suit various groups of students, thereby facilitating learning at scale. Preliminary experiments validate the feasibility and vast potential of this approach, promising to revolutionize AI education in K-12 education.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {393–397},
numpages = {5},
keywords = {ai-assisted programming, chatbot programming, collaborative learning, gamification approach, generative ai, k-12 education, large language models(llms)},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.1145/3643755,
author = {Dilhara, Malinda and Bellur, Abhiram and Bryksin, Timofey and Dig, Danny},
title = {Unprecedented Code Change Automation: The Fusion of LLMs and Transformation by Example},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643755},
doi = {10.1145/3643755},
abstract = {Software developers often repeat the same code changes within a project or across different projects. These repetitive changes are known as “code change patterns” (CPATs). Automating CPATs is crucial to expedite the software development process. While current Transformation by Example (TBE) techniques can automate CPATs, they are limited by the quality and quantity of the provided input examples. Thus, they miss transforming code variations that do not have the exact syntax, data-, or control-flow of the provided input examples, despite being semantically similar. Large Language Models (LLMs), pre-trained on extensive source code datasets, offer a potential solution. Harnessing the capability of LLMs to generate semantically equivalent, yet previously unseen variants of the original CPAT could significantly increase the effectiveness of TBE systems. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this paper, we first discover best practices for harnessing LLMs to generate code variants that meet three criteria: correctness (semantic equivalence to the original CPAT), usefulness (reflecting what developers typically write), and applicability (aligning with the primary intent of the original CPAT). We then implement these practices in our tool PyCraft, which synergistically combines static code analysis, dynamic analysis, and LLM capabilities. By employing chain-of-thought reasoning, PyCraft generates variations of input examples and comprehensive test cases that identify correct variations with an F-measure of 96.6%. Our algorithm uses feedback iteration to expand the original input examples by an average factor of 58x. Using these richly generated examples, we inferred transformation rules and then automated these changes, resulting in an increase of up to 39x, with an average increase of 14x in target codes compared to a previous state-of-the-art tool that relies solely on static analysis. We submitted patches generated by PyCraft to a range of projects, notably esteemed ones like microsoft/DeepSpeed and IBM/inFairness. Their developers accepted and merged 83% the 86 CPAT instances submitted through 44 pull requests. This confirms the usefulness of these changes.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {29},
numpages = {23},
keywords = {Automation, Code Changes, Code Clone, Generative AI, Large Language Models, Machine Learning, Program by Example, Python, Test Case Generation, Transformation by Example}
}

@inproceedings{10.1145/3626253.3635602,
author = {Akgun, Mahir and Toker, Sacip},
title = {An Investigation on Task Difficulty: Does Task Difficulty Depend on the Technology Used in Task Completion?},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635602},
doi = {10.1145/3626253.3635602},
abstract = {Previous research indicates that task difficulty (i.e., students' judgments on a task's complexity) impacts their task performance. However, whether students' perceived task difficulty changes depending on the technology they use when completing tasks is still under investigation. The present study aims to address this gap in the literature. One hundred twenty-three students completed the study procedures. Students were randomly assigned to one of four groups (one control group and three experimental groups). Students were not allowed to use any technology in the control group. In contrast, those in experimental groups were permitted to use one of the following tools: e-textbook, Google, and ChatGPT. Students in each group completed three tasks with different complexities in the same order. The data was analyzed using repeated-measures ANOVA. The study revealed a significant interaction effect between groups and task difficulty perceptions at three levels. In all groups, perceived difficulty increased as the task complexity increased, but the change in students' perceived task difficulty across three tasks was impacted by the tool used when completing the tasks.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1552–1553},
numpages = {2},
keywords = {generative ai, task difficulty, task performance},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3653644.3653662,
author = {Dai, Ziqing},
title = {Applications and Challenges of Large Language Models in Smart Government -From technological Advances to Regulated Applications},
year = {2024},
isbn = {9798400709777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653644.3653662},
doi = {10.1145/3653644.3653662},
abstract = {This paper explores the applications and challenges of large language models (LLMs) in the context of smart government. It delves into how LLMs can enhance government decision-making, policy interpretation, and public service delivery through intelligent analysis and predictions. It also discusses the role of LLMs in processing vast amounts of government information and in analyzing public opinion. Concurrently, the paper acknowledges the challenges posed by LLMs, including data costs, security and privacy concerns, model robustness, regulatory hurdles, and technical and talent bottlenecks. It proposes recommendations for the regulated application of LLMs, such as developing robust data protection policies, standardizing model research and evaluation, fostering interdisciplinary research, and promoting integrated development across key sectors. The paper concludes with an outlook on the future of LLMs in smart government, emphasizing the need for cautious optimism and responsible innovation.},
booktitle = {Proceedings of the 2024 3rd International Conference on Frontiers of Artificial Intelligence and Machine Learning},
pages = {275–280},
numpages = {6},
keywords = {Large Language Models, Regulated Applications, Smart Government},
location = {Yichang, China},
series = {FAIML '24}
}

@inproceedings{10.1145/3671151.3671327,
author = {Xu, Aiping and Wang, Lei},
title = {The Case Teaching of Chinese Abstract in Natural Language Understanding Courses},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671327},
doi = {10.1145/3671151.3671327},
abstract = {The Chinese abstract technology introduced in the machine learning course is generally difficult for students to understand. This paper intends to implement this technology through case teaching so that students can combine theory with practice to achieve the purpose of active learning and application. Chinese automatic abstracts help people to get the main content of the original information more quickly and mine out the high-value information. It is difficult for the extractive automatic text summary method to achieve the characteristics of consistent sentences and semantics of the original text. This case teaching aims to approach artificial abstract thinking to study the method of generative Chinese summaries. The model of combining attention mechanism and sequence to sequence (Seq2seq) was designed. Model training was carried out by optimizing the random gradient descent process by the method of adaptive learning rate in the direction of gradient decline. In this paper, the abstract generation was carried out by the beam search algorithm, and the validity of the model and algorithm were verified by experiments and instances. Case teaching implements the teaching purpose of "knowledge teaching" to "ability train". The teaching effect of "see the forest through the trees" has been achieved, and the student's learning is transformed from "passive" to "active", and the students are more subjective.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {1010–1015},
numpages = {6},
location = {Wuhan, China},
series = {CIBDA '24}
}

@proceedings{10.1145/3689944,
title = {SCORED '24: Proceedings of the 2024 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
year = {2024},
isbn = {9798400712401},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM SCORED '24, the third edition of the ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses. This edition is held in Salt Lake City, Utah, United States with extensive support for in-person and virtual attendance. This year's program includes exciting work along many different dimensions of research on supply chain security: the development of security policies for software supply chains, the use of artificial intelligence and large language models, approaches on software bills of materials, and the proposals of risk mitigation techniques. Consistent with its focus, SCORED brings researchers, legislators and practitioners in both open- and closed-source ecosystems to the center of current and emerging challenges and opportunities in software supply chain security.},
location = {Salt Lake City, UT, USA}
}

@inproceedings{10.1145/3613904.3642379,
author = {Hedderich, Michael A. and Bazarova, Natalie N. and Zou, Wenting and Shim, Ryun and Ma, Xinda and Yang, Qian},
title = {A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642379},
doi = {10.1145/3613904.3642379},
abstract = {Cyberbullying harms teenagers’ mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers’ distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students’ and the chatbot’s behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. We discuss the design opportunities LLM-Chains offer for empowering teachers and the research opportunities this work opens up.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {668},
numpages = {17},
keywords = {chatbot, cyberbullying, education, large language models, teachers},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3637989.3638015,
author = {Prieto, Maria Lorena and Gilsanz, Maria Fuencisla and Puertas, Enrique},
title = {Learning tool of chemical molecules for healthcare students based on 3D visualizations, Large Language Models and Linked Open Data},
year = {2024},
isbn = {9798400708732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637989.3638015},
doi = {10.1145/3637989.3638015},
abstract = {This paper presents a software tool designed to assist healthcare students and teachers in applying case-based learning methodologies for studying chemical compounds and their structures in a three-dimensional (3D) space. The tool utilizes natural language processing algorithms based on Large Language Models (LLM) to extract chemical entities from biomedical text documents. The tool provides students with a starting point for their research in a case-based learning exercise, and by using Large Language Models and Linked Open Data, it shows them a path to follow. The system shows a description of the molecules, a 3D view, a 2D structure information, and a panel with scientific articles about the selected chemical compound obtained from the Scielo portal, a repository of scientific publications. The application has a modular architecture that allows for easy addition of new functionalities in the future. The web interface let users to input the text of the clinical case for processing and studying. The functionality of querying scientific articles can be expanded with new modules to obtain information from other repositories. Overall, this software tool provides a comprehensive and innovative approach to learning chemical molecules for healthcare students, which can help them develop the necessary skills to tackle real-life problems as healthcare professionals.},
booktitle = {Proceedings of the 2023 7th International Conference on Education and E-Learning},
pages = {1–5},
numpages = {5},
keywords = {artificial intelligence, chatbot, e-learning, large language models, learning bots, learning management system},
location = {Tokyo, Japan},
series = {ICEEL '23}
}

@inproceedings{10.1145/3641032.3641055,
author = {Faccia, Alessio and Ridon, Manjeet and Beebeejaun, Zeenat and Mosteanu, Narcisa Mosteanu Roxana},
title = {Advancements and Challenges of Generative AI in Higher Educational Content Creation A Technical Perspective},
year = {2024},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641032.3641055},
doi = {10.1145/3641032.3641055},
abstract = {Generative Artificial Intelligence (AI) has witnessed remarkable advancements, igniting interest in various domains, including Higher Education. This research paper explores the impacts and challenges of integrating Generative AI in content creation within Higher Education. We utilise a literature review and case study approach to gain insights into the potential benefits and complexities of implementing Generative AI in educational settings. Specific research questions are formulated to investigate the influence of Generative AI on content creation efficiency, productivity, quality, and adaptability. The paper also highlights ethical considerations and the evolving role of educators in the AI-driven educational landscape. Furthermore, the research paper examines the practical applications of Generative AI tools such as OpenAI GPT, GPT-Neo, Hugging Face's Transformers Library, Cognii, MosaChat-AI, TeacherMatic, and OpenAI Codex in Higher Education content creation. This comprehensive analysis aims to provide educators, instructional designers, and policymakers with valuable insights and concrete examples of how Generative AI can be leveraged to create personalised learning materials, improve assessment strategies, and enhance the overall educational experience for students pursuing advanced technical subjects. The culmination of this research presents a vision for a future where Generative AI, thoughtfully implemented and ethically managed, empowers educational institutions to meet the diverse and evolving needs of learners in the digital era.},
booktitle = {Proceedings of the 2023 8th International Conference on Information Systems Engineering},
pages = {48–54},
numpages = {7},
keywords = {Applications, Chat GPT, Generative AI, Higher Education},
location = {Bangkok, Thailand},
series = {ICISE '23}
}

@inproceedings{10.1145/3664647.3680827,
author = {Chen, Haodong and Huang, Haojian and Dong, Junhao and Zheng, Mingzhe and Shao, Dian},
title = {FineCLIPER: Multi-modal Fine-grained CLIP for Dynamic Facial Expression Recognition with AdaptERs},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680827},
doi = {10.1145/3664647.3680827},
abstract = {Dynamic Facial Expression Recognition (DFER) is crucial for understanding human behavior. However, current methods exhibit limited performance mainly due to the insufficient utilization of facial dynamics, and the ambiguity of expression semantics, etc. To this end, we propose a novel framework, named Multi-modal Fine-grained CLIP for DFER with AdaptERs (FineCLIPER), incorporating the following novel designs: 1) To better distinguish between similar facial expressions, we extend the class labels to textual descriptions from both positive and negative aspects, and obtain supervision by calculating the cross-modal similarity based on the CLIP model; 2) Our FineCLIPER adopts a hierarchical manner to effectively mine useful cues from DFE videos. Specifically, besides directly embedding video frames as input (low semantic level), we propose to extract the face segmentation masks and landmarks based on each frame (middle semantic level) and utilize the Multi-modal Large Language Model (MLLM) to further generate detailed descriptions of facial changes across frames with designed prompts (high semantic level). Additionally, we also adopt Parameter-Efficient Fine-Tuning (PEFT) to enable efficient adaptation of large pre-trained models (i.e., CLIP) for this task. Our FineCLIPER achieves SOTA performance on the DFEW, FERV39k, and MAFW datasets in both supervised and zero-shot settings with few tunable parameters. Project page: https://haroldchen19.github.io/FineCLIPER-Page/},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2301–2310},
numpages = {10},
keywords = {contrastive learning, dynamic facial expression recognition, model adaptation, multi-modal, parameter-efficient transfer learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3657604,
title = {L@S '24: Proceedings of the Eleventh ACM Conference on Learning @ Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the Proceedings of the Eleventh Annual ACM Conference on Learning at Scale, L@S 2024, held July 18-20, 2024 at Georgia Tech in Atlanta, Georgia, USA.The Learning at Scale conference was created by the Association for Computing Machinery (ACM), inspired by the emergence of Massive Open Online Courses (MOOCs) and the accompanying shift in thinking about education. During the last few years, new opportunities for scaling up learning have emerged, like hybrid learning environments combining online and face-to-face, and informal learning enabled by all sorts of platforms (e.g., gamified language learning, citizen science communities, and collaborative programming communities). In the recent two years, the unprecedented development of generative AI has brought profound opportunities to scale the teaching and learning experiences, with the goal of enhancing learning for the increasingly diverse group of learners in both formal and informal contexts. L@S has evolved along with these emergent massive learning scenarios and opportunities and is today one of the most prominent venues for discussion of the highest quality of research on how learning and teaching can be transformed at scale, in diverse learning environments.The theme of L@S 2024 is Scaling Learning in the Age of AI. Rapid advances in AI have created new opportunities but also challenges for the Learning@Scale community. The advances in generative AI show potential to enhance pedagogical practices and the efficacy of learning at scale. This has led to an unprecedented level of interest in employing generative AI for scaling tutoring and feedback. The prevalence of such tools calls for new practices and understanding on how AI-based methods should be designed and developed to enhance the experiences and outcomes of teachers and learners.Learning@Scale 2024 solicits empirical and theoretical papers on, but not limited to, the following topics (in no particular order): 1) Instruction at scale: studies that examine how teachers and educators scale their instructions, what aspects of instruction could be scaled effectively, and which of these instructional strategies are the most effective for learning. 2) Interventions at scale: studies that examine the effects of interventions on student learning and performance when implemented at scale. We welcome studies that use both qualitative and quantitative methods. 3) The use of generative AI to scale learning: studies that investigate stakeholders' experiences with generative AI, students' and teachers' interactions with generative AI, and the potentials and limitations of using generative AI in education. 4) Systems and tools to support learning at scale: research that designs and develops systems and tools to support learning at scale. For example, this involves scaling learning through web-based systems, MOOCs, visualization, intelligent tutoring systems, gamification, immersive techniques (AR/VR/MR), mobile technologies, tangible interfaces, and various other technologies. 5) The evaluation of existing learning at scale systems and online learning environments using but not limited to the above-mentioned technologies. 6) Methods and algorithms that model learner behavior: research that contributes methods, algorithms, and pipelines that process large student data to enhance learning at scale. 7) Scaling learning in informal contexts: studies that explore how people take advantage of online environments to pursue their interests informally. 8) Review and synthesis of existing literature related to learning at scale. 9) Empirical studies and interventions that address equity, trust, algorithmic transparency and explainability, fairness and bias when using AI in education. 10) Research that addresses accessibility in learning at scale contexts. 11) Design and deployment of learning at scale systems for learners from underrepresented groups.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3635636.3664627,
author = {Radensky, Marissa},
title = {Mixed-Initiative Methods for Co-Creation in Scientific Research},
year = {2024},
isbn = {9798400704857},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635636.3664627},
doi = {10.1145/3635636.3664627},
abstract = {The scientific process is inherently creative, requiring the generation and exploration of ideas for scientific inspiration, projects, study design, and communication. As large language models (LLMs) advance rapidly, scientists increasingly take advantage of their abilities. While LLMs show great promise in supporting many steps of the scientific process, researchers still face significant challenges in validating and steering their output. Interactions tailored to scientists and their specific tasks may empower them to harness the full creative potential of LLMs. I present a course of research that will lead to the development and evaluation of mixed-initiative methods for co-creation in scientific research. These methods aim to facilitate verification and control of AI output. I briefly describe my prior and proposed work on mixed-initiative methods for co-creating research inspiration, studies, and communication, and I detail my current project on an LLM-powered tool for co-creating research project ideas.},
booktitle = {Proceedings of the 16th Conference on Creativity &amp; Cognition},
pages = {1–7},
numpages = {7},
location = {Chicago, IL, USA},
series = {C&amp;C '24}
}

@inproceedings{10.1145/3680533.3697066,
author = {Luo, Hanzhong and Gao, Fengsen and Fang, Ke and Liu, Dejian and Lin, Ziyun and Chan, Wai Kin (Victor)},
title = {Study with Confucius: An AI-Based Immersive Educational Game with Multiple Educational Modes},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697066},
doi = {10.1145/3680533.3697066},
abstract = {Current history education faces challenges in cultivating student immersion and knowledge retention. This study introduces an innovative educational game, "Study with Confucius", which blends traditional Chinese cultural education with AI technology. The game's objective is to enhance student engagement and learning outcomes by simulating historical figures and reconstructing historical backgrounds. Utilizing ChatGPT technology, the game assigns distinct educational abilities to different Agents, resulting in three unique educational modes. Players interact with these Agents, learning classical knowledge and gaining insights into the associated wisdom and moral culture. User study findings demonstrate that the game improves student immersion and their understanding and memorization of knowledge. This game offers adolescents a novel learning approach, where they can engage with and inherit traditional culture through interactive and enjoyable means.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {9},
numpages = {6},
keywords = {History education, agent, educational game, immersion},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3657604.3664695,
author = {Farhana, Effat and Sarkar, Souvika and Knipper, Ralph and Dey, Indrani and Narayanan, Hari and Puntambekar, Sadhana and Karmaker, Santu},
title = {SimPal: Towards a Meta-Conversational Framework to Understand Teacher's Instructional Goals for K-12 Physics},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664695},
doi = {10.1145/3657604.3664695},
abstract = {Simulations are widely used to teach science in grade schools. These simulations are often augmented with a conversational artificial intelligence (AI) agent to provide real-time scaffolding support for students conducting experiments using the simulations. AI agents are highly tailored for each simulation, with a predesigned set of Instructional Goals (IGs), making it difficult for teachers to adjust IGs as the agent may no longer align with the revised IGs. Additionally, teachers are hesitant to adopt new third-party simulations for the same reasons. In this research, we introduce SimPal, a Large Language Model (LLM) based meta-conversational agent, to solve this misalignment issue between a pre-trained conversational AI agent and the constantly evolving pedagogy of instructors. Through natural conversation with SimPal, teachers first explain their desired IGs, based on which SimPal identifies a set of relevant physical variables and their relationships to create symbolic representations of the desired IGs. The symbolic representations can then be leveraged to design prompts for the original AI agent to yield better alignment with the desired IGs. We empirically evaluated SimPal using two LLMs: ChatGPT-3.5 and PaLM 2 on 63 Physics simulations from PhET and Golabz. Additionally, we examined the impact of different prompting techniques on LLM's performance by utilizing the TELeR taxonomy in identifying relevant physical variables for the IGs. Our findings showed that SimPal can do this task with a high degree of accuracy when provided with a well-defined prompt.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {461–465},
numpages = {5},
keywords = {K-12 science, conversational AI, large language models, meta-conversation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3650212.3680355,
author = {Zhang, Cen and Zheng, Yaowen and Bai, Mingqiang and Li, Yeting and Ma, Wei and Xie, Xiaofei and Li, Yuekang and Sun, Limin and Liu, Yang},
title = {How Effective Are They? Exploring Large Language Model Based Fuzz Driver Generation},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680355},
doi = {10.1145/3650212.3680355},
abstract = {Fuzz drivers are essential for library API fuzzing. However, automatically generating fuzz drivers is a complex task, as it demands the creation of high-quality, correct, and robust API usage code. An LLM-based (Large Language Model) approach for generating fuzz drivers is a promising area of research. Unlike traditional program analysis-based generators, this text-based approach is more generalized and capable of harnessing a variety of API usage information, resulting in code that is friendly for human readers. However, there is still a lack of understanding regarding the fundamental issues on this direction, such as its effectiveness and potential challenges.
 

 
To bridge this gap, we conducted the first in-depth study targeting the important issues of using LLMs to generate effective fuzz drivers. Our study features a curated dataset with 86 fuzz driver generation questions from 30 widely-used C projects. Six prompting strategies are designed and tested across five state-of-the-art LLMs with five different temperature settings. In total, our study evaluated 736,430 generated fuzz drivers, with 0.85 billion token costs ($8,000+ charged tokens). Additionally, we compared the LLM-generated drivers against those utilized in industry, conducting extensive fuzzing experiments (3.75 CPU-year). Our study uncovered that:
 

 
1) While LLM-based fuzz driver generation is a promising direction, it still encounters several obstacles towards practical applications;
 
2) LLMs face difficulties in generating effective fuzz drivers for APIs with intricate specifics. Three featured design choices of prompt strategies can be beneficial: issuing repeat queries, querying with examples, and employing an iterative querying process;
 
3) While LLM-generated drivers can yield fuzzing outcomes that are on par with those used in the industry, there are substantial opportunities for enhancement, such as extending contained API usage, or integrating semantic oracles to facilitate logical bug detection.
 

 
Our insights have been implemented to improve the OSS-Fuzz-Gen project, facilitating practical fuzz driver generation in industry.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {1223–1235},
numpages = {13},
keywords = {Fuzz Driver Generation, Fuzz Testing, Large Language Model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3674805.3690753,
author = {d'Aloisio, Giordano and Fortz, Sophie and Hanna, Carol and Fortunato, Daniel and Bensoussan, Avner and Mendiluze Usandizaga, E\~{n}aut and Sarro, Federica},
title = {Exploring LLM-Driven Explanations for Quantum Algorithms},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690753},
doi = {10.1145/3674805.3690753},
abstract = {Background: Quantum computing is a rapidly growing new programming paradigm that brings significant changes to the design and implementation of algorithms. Understanding quantum algorithms requires knowledge of physics and mathematics, which can be challenging for software developers. Aims: In this work, we provide a first analysis of how LLMs can support developers’ understanding of quantum code. Method: We empirically analyse and compare the quality of explanations provided by three widely adopted LLMs (Gpt3.5, Llama2, and Tinyllama) using two different human-written prompt styles for seven state-of-the-art quantum algorithms. We also analyse how consistent LLM explanations are over multiple rounds and how LLMs can improve existing descriptions of quantum algorithms. Results: Llama2 provides the highest quality explanations from scratch, while Gpt3.5 emerged as the LLM best suited to improve existing explanations. In addition, we show that adding a small amount of context to the prompt significantly improves the quality of explanations. Finally, we observe how explanations are qualitatively and syntactically consistent over multiple rounds. Conclusions: This work highlights promising results, and opens challenges for future research in the field of LLMs for quantum code explanation. Future work includes refining the methods through prompt optimisation and parsing of quantum code explanations, as well as carrying out a systematic assessment of the quality of explanations.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {475–481},
numpages = {7},
keywords = {Code Explainability., Large Language Models, Quantum Computing},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3643991.3644910,
author = {Lin, Hong Yi and Thongtanunam, Patanamon and Treude, Christoph and Charoenwet, Wachiraphan},
title = {Improving Automated Code Reviews: Learning From Experience},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644910},
doi = {10.1145/3643991.3644910},
abstract = {Modern code review is a critical quality assurance process that is widely adopted in both industry and open source software environments. This process can help newcomers learn from the feedback of experienced reviewers; however, it often brings a large workload and stress to reviewers. To alleviate this burden, the field of automated code reviews aims to automate the process, teaching large language models to provide reviews on submitted code, just as a human would. A recent approach pre-trained and fine-tuned the code intelligent language model on a large-scale code review corpus. However, such techniques did not fully utilise quality reviews amongst the training data. Indeed, reviewers with a higher level of experience or familiarity with the code will likely provide deeper insights than the others. In this study, we set out to investigate whether higher-quality reviews can be generated from automated code review models that are trained based on an experience-aware oversampling technique. Through our quantitative and qualitative evaluation, we find that experience-aware oversampling can increase the correctness, level of information, and meaningfulness of reviews generated by the current state-of-the-art model without introducing new data. The results suggest that a vast amount of high-quality reviews are underutilised with current training strategies. This work sheds light on resource-efficient ways to boost automated code review models.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {278–283},
numpages = {6},
keywords = {code review, review comments, neural machine translation},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@article{10.5555/3665464.3665471,
author = {Mouli, Chandra and Kotteti, Madhav and Lal, Ratan and Chetti, Prasad},
title = {Coding Integrity Unveiled: Exploring the Pros and Cons of Detecting Plagiarism in Programming Assignments Using Copyleaks},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Before the advent of generative Artificial Intelligence (AI) tools, for example, ChatGPT, students traditionally approached assignment development authentically by employing libraries and by referring to textbooks. However, with the widespread reliance on powerful AI tools for assignment completion, the process has become more convenient. Unfortunately, this ease of use has led to a potential detriment in students' genuine understanding of subjects, as well as a decline in their problem-solving and innovative thinking skills. Moreover, AI tools like ChatGPT will evolve as technology advances such that the need to detect AI-generated content is even more crucial in educational setting to reinforce the value of original work [5]. This paper aims to address this issue by focusing on the detection of plagiarism in student assignments through the utilization of the Copyleaks1 tool, specifically designed to identify AI-generated code. The accuracy of the tool is systematically evaluated by submitting various pairs of codes, each with similar functionality, wherein one is generated by AI and the other by humans.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {61–69},
numpages = {9}
}

@inproceedings{10.1145/3610978.3638377,
author = {Kamelabad, Alireza M.},
title = {The Question Is Not Whether; It Is How!},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638377},
doi = {10.1145/3610978.3638377},
abstract = {This submission explores the implications of robot embodiment in language learning. Through various innovative studies, it investigates how factors tied to robot usage, such as personality characteristics and learning settings, influence learner outcomes. It incorporates advancements in artificial intelligence by utilizing large language models and further contributes to pivotal understanding through a planned longitudinal study in the migrant context. Lastly, an intensive speech analysis further examines the specifics of human-robot interaction.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {112–114},
numpages = {3},
keywords = {LLM, RALL, language learning, longitudinal study},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@article{10.1613/jair.1.15960,
author = {Pternea, Moschoula and Singh, Prerna and Chakraborty, Abir and Oruganti, Yagna and Milletari, Mirco and Bapat, Sayli and Jiang, Kebei},
title = {The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement Learning and Large Language Models},
year = {2024},
issue_date = {Sep 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {80},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.15960},
doi = {10.1613/jair.1.15960},
abstract = {In this work, we review research studies that combine Reinforcement Learning (RL) and Large Language Models (LLMs), two areas that owe their momentum to the development of Deep Neural Networks (DNNs). We propose a novel taxonomy of three main classes based on the way that the two model types interact with each other. The first class, RL4LLM, includes studies where RL is leveraged to improve the performance of LLMs on tasks related to Natural Language Processing (NLP). RL4LLM is divided into two sub-categories depending on whether RL is used to directly fine-tune an existing LLM or to improve the prompt of the LLM. In the second class, LLM4RL, an LLM assists the training of an RL model that performs a task that is not inherently related to natural language. We further break down LLM4RL based on the component of the RL training framework that the LLM assists or replaces, namely reward shaping, goal generation, and policy function. Finally, in the third class, RL+LLM, an LLM and an RL agent are embedded in a common planning framework without either of them contributing to training or fine-tuning of the other. We further branch this class to distinguish between studies with and without natural language feedback. We use this taxonomy to explore the motivations behind the synergy of LLMs and RL and explain the reasons for its success, while pinpointing potential shortcomings and areas where further research is needed, as well as alternative methodologies that serve the same goal.},
journal = {J. Artif. Int. Res.},
month = sep,
numpages = {49}
}

@inproceedings{10.1145/3652583.3658597,
author = {Wang, Shiqi and Zhang, Xinfeng},
title = {Compact Visual Data Representation for Multimedia Search and Analytics},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658597},
doi = {10.1145/3652583.3658597},
abstract = {With the exponential growth of multimedia in various forms, the volume of acquired visual data has dramatically increased while their value intensity remains relatively low. This presents significant challenges in multimedia search and analytics. In this tutorial, we aim to introduce recent advances of compact visual data representation techniques that enable efficient, flexible, and reliable multimedia search and analytics. We will explore the shift from traditional visual information representation techniques, such as video coding, to biologically inspired information processing paradigms, like digital retina based coding and representation. We will also discuss the representation of point cloud data and Artificial Intelligence Generated Content (AIGC) data, which are becoming increasingly popular in modern machine vision technologies. Additionally, we will discuss the recent advances in quality assessment technologies for multimedia signals under various novel and challenging scenarios. Finally, we will introduce the recent standardization activities in media coding including Video Coding for Machine (VCM). This tutorial aims to stimulate fruitful discussions, encourage innovative research, and drive advancements in the field of semantic and visual communication, multimedia search, analytics, computing as well as generative AI.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {1326–1327},
numpages = {2},
keywords = {compact visual representation, multimedia, visual analytics},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3700297.3700342,
author = {Chen, Ping and Alias, Syazwina Binti},
title = {Opportunities and Challenges in the Cultivation of Software Development Professionals in the Context of Large Language Models},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700342},
doi = {10.1145/3700297.3700342},
abstract = {In the context of the rapid development of Large Language Models (LLMs), the field of software development has undergone significant transformations presenting both opportunities and challenges for software development professional cultivation. This study systematically analyzes the applications of LLMs in software development and their impact on this cultivation, exploring the opportunities and challenges in enhancing programming efficiency, promoting personalized learning, improving interdisciplinary skills, and addressing over-reliance on LLMs and related tools. Through literature analysis, this study reviews the impact of LLMs on programming efficiency, code quality, and project management and evaluates the requirements and directions for professional cultivation in response to these changes. The research results indicate that while LLMs bring numerous opportunities, they also pose challenges such as rapid technological updates and a tendency toward over-reliance on tools. Therefore, this study proposes a series of optimized professional cultivation strategies to adapt to the technological developments and industry demands of the new era, thereby enhancing the capability of higher education institutions to cultivate software professionals who meet future needs.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {259–267},
numpages = {9},
keywords = {Cultivation, Educational Reform, Large Language Models, Personalized Learning, Software Development Professionals},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3627673.3679091,
author = {Xu, Eric and Zhang, Wenbin and Xu, Weifeng},
title = {Transforming Digital Forensics with Large Language Models: Unlocking Automation, Insights, and Justice},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679091},
doi = {10.1145/3627673.3679091},
abstract = {In the pursuit of justice and accountability in the digital age, the integration of Large Language Models (LLMs) with digital forensics holds immense promise. This half-day tutorial provides a comprehensive exploration of the transformative potential of LLMs in automating digital investigations and uncovering hidden insights. Through a combination of real-world case studies, interactive exercises, and hands-on labs, participants will gain a deep understanding of how to harness LLMs for evidence analysis, entity identification, and knowledge graph reconstruction. By fostering a collaborative learning environment, this tutorial aims to empower professionals, researchers, and students with the skills and knowledge needed to drive innovation in digital forensics. As LLMs continue to revolutionize the field, this tutorial will have far-reaching implications for enhancing justice outcomes, promoting accountability, and shaping the future of digital investigations.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5543–5546},
numpages = {4},
keywords = {automation, digital forensics, evidence analysis, knowledge graph reconstruction, large language model},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626253.3635606,
author = {Hou, Xinying and Ericson, Barbara J. and Wang, Xu},
title = {Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635606},
doi = {10.1145/3626253.3635606},
abstract = {Novice programmers need to write basic code as part of the learning process, but they often face difficulties. To assist struggling students, we recently implemented personalized Parsons problems, which are code puzzles where students arrange blocks of code to solve them, as pop-up scaffolding. Students found them to be more engaging and preferred them for learning, instead of simply receiving the correct answer, such as the response they might get from generative AI tools like ChatGPT. However, a drawback of using Parsons problems as scaffolding is that students may be able to put the code blocks in the correct order without fully understanding the rationale of the correct solution. As a result, the learning benefits of scaffolding are compromised. Can we improve the understanding of personalized Parsons scaffolding by providing textual code explanations? In this poster, we propose a design that incorporates multiple levels of textual explanations for the Parsons problems. This design will be used for future technical evaluations and classroom experiments. These experiments will explore the effectiveness of adding textual explanations to Parsons problems to improve instructional benefits.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1686–1687},
numpages = {2},
keywords = {code explanations, code writing, hint, introductory programming, large language models, parsons problems, scaffolding},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3597503.3639107,
author = {Xie, Fuman and Yan, Chuan and Meng, Mark Huasong and Teng, Shaoming and Zhang, Yanjun and Bai, Guangdong},
title = {Are Your Requests Your True Needs? Checking Excessive Data Collection in VPA App},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639107},
doi = {10.1145/3597503.3639107},
abstract = {Virtual personal assistants (VPA) services encompass a large number of third-party applications (or apps) to enrich their functionalities. These apps have been well examined to scrutinize their data collection behaviors against their declared privacy policies. Nonetheless, it is often overlooked that most users tend to ignore privacy policies at the installation time. Dishonest developers thus can exploit this situation by embedding excessive declarations to cover their data collection behaviors during compliance auditing.In this work, we present Pico, a privacy inconsistency detector, which checks the VPA app's privacy compliance by analyzing (in)consistency between data requested and data essential for its functionality. Pico understands the app's functionality topics from its publicly available textual data, and leverages advanced GPT-based language models to address domain-specific challenges. Based on the counterparts with similar functionality, suspicious data collection can be detected through the lens of anomaly detection. We apply Pico to understand the status quo of data-functionality compliance among all 65,195 skills in the Alexa app store. Our study reveals that 21.7% of the analyzed skills exhibit suspicious data collection, including Top 10 popular Alexa skills that pose threats to 54,116 users. These findings should raise an alert to both developers and users, in the compliance with the purpose limitation principle in data regulations.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {205},
numpages = {12},
keywords = {virtual personal assistant, privacy compliance, alexa skills},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3626253.3635572,
author = {Wang, Sierra and Mitchell, John and Haber, Nick and Piech, Chris},
title = {Math IDE: A Platform for Creating with Math},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635572},
doi = {10.1145/3626253.3635572},
abstract = {To inspire student engagement in middle school math, we explore the possibility of using generative AI to enhance the creativity of math learning. We present the Math IDE, a math education environment in which students learn about math concepts by building artifacts. We aimed to create a platform in which students can engage with mathematical concepts, create an artifact that embodies the math that they are learning about, and practice their high-level specification skills. In the current iteration of the Math IDE, students can create custom web pages by describing and demonstrating understanding of the math that is involved in the web page. In this short overview, we describe our process and discuss several open questions regarding the design and application of this novel method of math education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1844–1845},
numpages = {2},
keywords = {creating, education, generative ai, math},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3652628.3652689,
author = {Sun, Yimin and Wang, Chao and Peng, Yan},
title = {Unleashing the Potential of Large Language Model: Zero-shot VQA for Flood Disaster Scenario},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652689},
doi = {10.1145/3652628.3652689},
abstract = {Visual question answering (VQA) is a fundamental and essential AI task, and VQA-based disaster scenario understanding is a hot research topic. For instance, we can ask questions about a disaster image by the VQA model and the answer can help identify whether anyone or anything is affected by the disaster. However, previous VQA models for disaster damage assessment have some shortcomings, such as limited candidate answer space, monotonous question types, and limited answering capability of existing models. In this paper, we propose a zero-shot VQA model named Zero-shot VQA for Flood Disaster Damage Assessment (ZFDDA). It is a VQA model for damage assessment without pre-training. Also, with flood disaster as the main research object, we build a Freestyle Flood Disaster Image Question Answering dataset (FFD-IQA) to evaluate our VQA model. This new dataset expands the question types to include free-form, multiple-choice, and yes-no questions. At the same time, we expand the size of the previous dataset to contain a total of 2,058 images and 22,422 question-meta ground truth pairs. Most importantly, our model uses well-designed chain of thought (CoT) demonstrations to unlock the potential of the large language model, allowing zero-shot VQA to show better performance in disaster scenarios. The experimental results show that the accuracy in answering complex questions is greatly improved with CoT prompts. Our study provides a research basis for subsequent research of VQA for other disaster scenarios.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {368–373},
numpages = {6},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3686852.3687083,
author = {Mullins, Elizabeth and Portillo, Adrian and Ruiz Rohena, Kristalys and Piplai, Aritran},
title = {Enhancing classroom teaching with LLMs and RAG},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687083},
doi = {10.1145/3686852.3687083},
abstract = {Large Language Models have become a valuable source of information for our daily inquiries. However, after training, its data source quickly becomes out-of-date, making RAG a useful tool for providing even more recent or pertinent data. In this work, we investigate how RAG pipelines, with the course materials serving as a data source, might help students in K–12 education. The initial research utilizes Reddit as a data source for up-to-date cybersecurity information. Chunk size is evaluated to determine the optimal amount of context needed to generate accurate answers. After running the experiment for different chunk sizes, answer correctness was evaluated using RAGAs with average answer correctness not exceeding 50 percent for any chunk size. This suggests that Reddit is not a good source to mine for data for questions about cybersecurity threats. The methodology was successful in evaluating the data source, which has implications for its use to evaluate educational resources for effectiveness.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {145–146},
numpages = {2},
keywords = {Education, Large Language Models, Retrieval Augmented Generation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3593013.3594067,
author = {Hacker, Philipp and Engel, Andreas and Mauer, Marco},
title = {Regulating ChatGPT and other Large Generative AI Models},
year = {2023},
isbn = {9798400701924},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593013.3594067},
doi = {10.1145/3593013.3594067},
abstract = {Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers.},
booktitle = {Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1112–1123},
numpages = {12},
location = {Chicago, IL, USA},
series = {FAccT '23}
}

@inproceedings{10.1145/3605098.3636108,
author = {Jamil, Hasan},
title = {Equity and Fairness Challenges in Online Learning in the Age of ChatGPT},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636108},
doi = {10.1145/3605098.3636108},
abstract = {Recent research suggest that equity remained a neglected consideration in most learning analytics and continues to be an esoteric concept. Online learning poses many additional equity challenges that largely concerns gender, access to resources, socio-economic conditions, fairness, or feeling of isolation. In this article, we discuss a novel equity concern in the emerging online learning environment often aided by large language models such as ChatGPT. It has been observed that ChatGPT-like models can be a significantly powerful learning and tutoring aid for learners. However, in online learning and in the absence of a human instructor, ChatGPT could introduce inequity in form of "wrongful" tutoring that could be devastatingly harmful for learners, which we call Ignorant Bias. We illustrate this form of inequity with an illustrative example.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {91–92},
numpages = {2},
keywords = {large language model, equity, database, authentic assessment},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3626253.3635398,
author = {Mousa, Raneem Emad and Veilleux, Nanette},
title = {Is ChatGPT the Academic Catalyst We've all been Waiting For?},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635398},
doi = {10.1145/3626253.3635398},
abstract = {The excitement around ChatGPT 3.5 underscores its potential to transform various fields in education, including STEM. However, we must approach these claims cautiously. While AI can enhance STEM education, there are ethical concerns and potential inaccuracies linked to unsupervised automated responses. To comprehensively evaluate ChatGPT's influence on STEM, we conducted a controlled experiment that involved answering a question set in mathematics and CS in a time-limited session. To avoid bias, we recruited four groups of math and CS students with similar abilities -each group comprised five students. Two groups utilized ChatGPT, while the other two did not. Students who used ChatGPT were tasked with explaining how and where they employed the tool. Conversely, students who did not use ChatGPT were asked to showcase their problem-solving process. We analyzed the responses from these four groups, alongside the analysis of ChatGPT conversations for those who employed ChatGPT. Performance, confidence level, and completion time of each participant were recorded. Experts in mathematics and CS were then consulted to review participant responses. These experts were subsequently interviewed to gain deeper insights and draw conclusive findings. Our findings show that students who didn't use ChatGPT in Mathematics scored better than those who did, Specifically, ChatGPT provided the correct working process but yielded a wrong final answer due to arithmetic mistakes. Similarly, in programming, ChatGPT led to less elegant code. Our findings provide valuable insights into the benefits and challenges of AI integration in these fields, helping educators and students to adapt to AI advancements.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1885},
numpages = {1},
keywords = {ai, chatgpt, education, stem},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3656650.3656676,
author = {Bisante, Alba and Datla, Venkata Srikanth Varma and Panizzi, Emanuele and Trasciatti, Gabriella and Zeppieri, Stefano},
title = {Enhancing Interface Design with AI: An Exploratory Study on a ChatGPT-4-Based Tool for Cognitive Walkthrough Inspired Evaluations},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656676},
doi = {10.1145/3656650.3656676},
abstract = {This paper introduces CWGPT, a ChatGPT-4-based tool designed for Cognitive Walkthrough (CW) inspired evaluations of web interfaces. The primary goal is to assist users, particularly students and inexperienced designers, in evaluating web interfaces. Our tool, operating as a conversational agent, provides detailed evaluations of a user-specified task by intelligently guessing the subtasks and actions required to accomplish them, answering the standard CW questions, and providing helpful feedback and practical suggestions to improve the usability of the analyzed interface. For our study, we selected a group of web applications designed by students from a Web and Software Architecture course. We compare the outcome of the CWs we executed on ten web apps against the corresponding CWGPT analyses. We then describe the study we conducted involving five author-students to assess the tool’s efficacy in helping them recognize and solve usability issues. In addition to introducing a novel adaptation of ChatGPT, the outcomes of the described experience underscore the promising potential of AI in usability evaluations.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {41},
numpages = {5},
keywords = {AI, ChatGPT, Cognitive Walkthrough, GPT, HCI},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1145/3640544.3645231,
author = {George, Samuel D and Huang, Tao and Robinson, Chandler and Schell, Gabriel and Shan, Wei and Zhao, Ziqian and Zhou, Zeqi and Dewan, Prasun},
title = {Assistant Dashboard Plus – Enhancing an Existing Instructor Dashboard with Difficulty Detection and GPT-based Code Clustering},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645231},
doi = {10.1145/3640544.3645231},
abstract = {As interest in programming as a major grows, instructors must accommodate more students in their programming courses. One particularly challenging aspect of this growth is providing quality assistance to students during in-class and out-of-class programming exercises. Prior work proposes using instructor dashboards to help instructors combat these challenges. Further, the introduction of ChatGPT represents an exciting avenue to assist instructors with programming exercises but needs a delivery method for this assistance. We propose a revision of a current instructor dashboard Assistant Dashboard Plus that extends an existing dashboard with two new features: (a) identifying students in difficulty so that instructors can effectively assist them, and (b) providing instructors with pedagogically relevant groupings of students’ exercise solutions with similar implementations so that instructors can provide overlapping code style feedback to students within the same group. For difficulty detection, it uses a state-of-the-art algorithm for which a visualization has not been created. For code clustering, it uses GPT. We present a first-pass implementation of this dashboard.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {54–57},
numpages = {4},
keywords = {ChatGPT, Computer programming, Dashboards, GPT, Learning at scale},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3641235.3664430,
author = {Matsunaga, Harutaka and Miyata, Kazunori},
title = {Emerging Approaches in CG Education Aimed at Enhancing Visual Communication Skills through Reverse Engineering},
year = {2024},
isbn = {9798400705175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641235.3664430},
doi = {10.1145/3641235.3664430},
abstract = {The proposed research applies reverse engineering techniques in the field of computer graphics (CG) production education at Japanese vocational schools. It involves the development of a "Philosophical Observation Decomposition Table" and a "Concept Decomposition Table" to analyze the relationship between words and visuals, along with artistic elements. This methodology is designed to be both educational and enjoyable. Furthermore, the study suggests the utilization of AI technologies, such as ChatGPT, to expand the scope of CG education beyond technical skills, encompassing soft skills like communication and creativity.},
booktitle = {ACM SIGGRAPH 2024 Educator's Forum},
articleno = {5},
numpages = {2},
keywords = {Diversified Needs and Skills, Education-Industry Collaboration, Skill Gap, Sustainable Education Program},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3603555.3603565,
author = {Leiser, Florian and Eckhardt, Sven and Knaeble, Merlin and Maedche, Alexander and Schwabe, Gerhard and Sunyaev, Ali},
title = {From ChatGPT to FactGPT: A Participatory Design Study to Mitigate the Effects of Large Language Model Hallucinations on Users},
year = {2023},
isbn = {9798400707711},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603555.3603565},
doi = {10.1145/3603555.3603565},
abstract = {Large language models (LLMs) like ChatGPT recently gained interest across all walks of life with their human-like quality in textual responses. Despite their success in research, healthcare, or education, LLMs frequently include incorrect information, called hallucinations, in their responses. These hallucinations could influence users to trust fake news or change their general beliefs. Therefore, we investigate mitigation strategies desired by users to enable identification of LLM hallucinations. To achieve this goal, we conduct a participatory design study where everyday users design interface features which are then assessed for their feasibility by machine learning (ML) experts. We find that many of the desired features are well-perceived by ML experts but are also considered as difficult to implement. Finally, we provide a list of desired features that should serve as a basis for mitigating the effect of LLM hallucinations on users.},
booktitle = {Proceedings of Mensch Und Computer 2023},
pages = {81–90},
numpages = {10},
keywords = {Artificial Hallucinations, ChatGPT, Disney Method, Large Language Models, Participatory Design},
location = {Rapperswil, Switzerland},
series = {MuC '23}
}

@inproceedings{10.1145/3622780.3623648,
author = {Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka},
title = {KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education},
year = {2023},
isbn = {9798400703904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622780.3623648},
doi = {10.1145/3622780.3623648},
abstract = {The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.  
In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.  

We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {50–59},
numpages = {10},
keywords = {ChatGPT, LLM, classroom experience, programming education},
location = {Cascais, Portugal},
series = {SPLASH-E 2023}
}

@inproceedings{10.1145/3593663.3593692,
author = {Jell, Lea and List, Corinna and Kipp, Michael},
title = {Towards Automated Interactive Tutoring - Focussing on Misconceptions and Adaptive Level-Specific Feedback},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593692},
doi = {10.1145/3593663.3593692},
abstract = {Programming is an essential cross-disciplinary skill, yet teaching it effectively in large classes can be challenging due to the need for close feedback loops. Identifying and addressing common misconceptions is particularly important during the initial stages of learning to program. While automated interactive tutoring systems have the potential to offer personalized tutoring at scale, current systems tend to emphasize errors and predefined solutions rather than focusing on common misconceptions. In this study, we introduce a novel platform centered on addressing misconceptions in programming education. We describe methods for detecting misconceptions using Abstract Syntax Trees (AST) and providing tailored, level-specific feedback to emulate human-like tutoring. As an empirical basis for this project, we gathered data from various introductory programming courses. Additionally, we advocate for the establishment of a repository of common misconceptions, offering examples derived from both the literature and our own data. Investigating misconceptions can ultimately enhance the teaching strategies of both human educators and AI agents, such as GPT, in guiding learners effectively.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {226–235},
numpages = {10},
keywords = {CS in higher education, intelligent tutoring, programming misconceptions},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3626253.3635482,
author = {Jamal, Rifa and Renzella, Jake},
title = {Enhancing Formative Feedback at Scale with the Intelligent Feedback Assistant},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635482},
doi = {10.1145/3626253.3635482},
abstract = {Formative feedback spans various domains, from education to businesses and creative endeavours. In educational contexts, feedback enriches students' learning and work quality through reflection. However, providing effective feedback at scale is challenging. Students struggle to engage with feedback, often due to lack of feedback literacy. Recent advancements in Natural Language Processing, a branch of Artificial Intelligence, provides opportunities to evaluate how we can support feedback providers in its quality and scale. This poster paper presents an overview of key feedback challenges, attributes of high quality feedback, and introduces the Intelligent Feedback Assistant (IFA), an innovative NLP-based system designed to assist educators in delivering high-quality feedback. IFA operates as an ensemble of machine learning models and non-AI systems to guide educators in refining their feedback, ensuring it embodies attributes of effective feedback - actionable, specific, justified, and positive. IFA is supportive, not generative, ensuring the feedback provider remains central to the feedback provision process. The tool design, and outcomes of IFA offers a promising path for scaleable, high-quality formative feedback in education and beyond.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1692–1693},
numpages = {2},
keywords = {ai in education, natural language processing, student feedback},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3631504.3631518,
author = {Amer-Yahia, Sihem and Bonifati, Angela and Chen, Lei and Li, Guoliang and Shim, Kyuseok and Xu, Jianliang and Yang, Xiaochun},
title = {From Large Language Models to Databases and Back: A Discussion on Research and Education},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {52},
number = {3},
issn = {0163-5808},
url = {https://doi.org/10.1145/3631504.3631518},
doi = {10.1145/3631504.3631518},
abstract = {In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.},
journal = {SIGMOD Rec.},
month = nov,
pages = {49–56},
numpages = {8}
}

@inproceedings{10.1145/3657604.3664719,
author = {Schmucker, Robin and Xia, Meng and Azaria, Amos and Mitchell, Tom},
title = {Ruffle&amp;Riley: From Lesson Text to Conversational Tutoring},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664719},
doi = {10.1145/3657604.3664719},
abstract = {Conversational tutoring systems (CTSs) offer learning experiences driven by natural language interactions. They are recognized for promoting cognitive engagement and improving learning outcomes, especially in reasoning tasks. Ruffle&amp;Riley is a novel type of CTS that explores the potential of LLMs for efficient AI-assisted content authoring and for facilitating structured free-form conversational tutoring. This interactive event enables participants to engage with the LLM-based CTS introduced in our recent AIED2024 paper in two ways: (1) Attendees will interact with the web application using their personal devices. (2) Attendees will learn how to import learning materials into the system and generate custom tutoring scripts through a detailed tutorial. Ruffle&amp;Riley is an extendable, open-source framework that promotes research on effective instructional design of LLM-based learning technologies. The interactive event will foster related discussions.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {547–549},
numpages = {3},
keywords = {authoring tools, conversational tutoring systems, intelligent tutoring systems, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3637528.3671647,
author = {Wan, Mengting and Safavi, Tara and Jauhar, Sujay Kumar and Kim, Yujin and Counts, Scott and Neville, Jennifer and Suri, Siddharth and Shah, Chirag and White, Ryen W. and Yang, Longqi and Andersen, Reid and Buscher, Georg and Joshi, Dhruv and Rangan, Nagu},
title = {TnT-LLM: Text Mining at Scale with Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671647},
doi = {10.1145/3637528.3671647},
abstract = {Transforming unstructured text into structured and meaningful forms, organized by useful category labels, is a fundamental step in text mining for downstream analysis and application. However, most existing methods for producing label taxonomies and building text-based label classifiers still rely heavily on domain expertise and manual curation, making the process expensive and time-consuming. This is particularly challenging when the label space is under-specified and large-scale data annotations are unavailable. In this paper, we address these challenges with Large Language Models (LLMs), whose prompt-based interface facilitates the induction and use of large-scale pseudo labels. We propose TnT-LLM, a two-phase framework that employs LLMs to automate the process of end-to-end label generation and assignment with minimal human effort for any given use-case. In the first phase, we introduce a zero-shot, multi-stage reasoning approach which enables LLMs to produce and refine a label taxonomy iteratively. In the second phase, LLMs are used as data labelers that yield training samples so that lightweight supervised classifiers can be reliably built, deployed, and served at scale. We apply TnT-LLM to the analysis of user intent and conversational domain for Bing Copilot (formerly Bing Chat), an open-domain chat-based search engine. Extensive experiments using both human and automatic evaluation metrics demonstrate that TnT-LLM generates more accurate and relevant label taxonomies when compared against state-of-the-art baselines, and achieves a favorable balance between accuracy and efficiency for classification at scale.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5836–5847},
numpages = {12},
keywords = {large language models, text classification, text clustering},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3696230.3696256,
author = {Baclayon, Charis Arlie Largo and Costelo, Kid Omar Rendon and Flores, Jeremy Jules Loyola and Sta. Romana, Cherry Lyn Cando},
title = {Automated Handwritten Essay Evaluation in Moodle: Leveraging Google Vision OCR and Mistral 7b},
year = {2024},
isbn = {9798400717574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696230.3696256},
doi = {10.1145/3696230.3696256},
abstract = {Traditional grading methods are often time-consuming and subjective, increasing the difficulties in maintaining academic integrity against the background of easy access to online resources. Even as pre-written and AI-generated content become even more available, handwritten essays offer one of the most viable ways of stimulating real learning and original thought among students. This study assessed the accuracy and efficiency of AI-powered grading to improve education amid these challenges. More precisely, the paper investigated the possibility of automatically grading the handwritten open-ended reflection essays of students in the “Living in the IT Era” course by leveraging AI. Through Optical Character Recognition (OCR), together with a fine-tuned and trained Large Language Model (LLM) Mistral 7b, the system replicated human-grading decisions in evaluating essays comprehensively. The predicted score and human-graded score were compared in evaluating the system. Analysis using BERT Score revealed a high degree of correlation between the two, with consistent precision (88.41%), recall (83.33%), and F1-score (85.78%). External user testing also revealed a positive perception: the system is perceived as user-friendly (usability: 4.28), generally understandable (comprehensibility: 3.68), and with functionalities relevant to educators' needs (relevance: 4.0). This study adds to the expanding body of research on AI in education and lays the groundwork for future investigations in this area.},
booktitle = {Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE)},
pages = {240–246},
numpages = {7},
keywords = {Essay Evaluation, Handwritten Essay Grading, Learning Management Systems, Moodle, Online Education, Plugin},
location = {
},
series = {ICDTE '24}
}

@inproceedings{10.1145/3691620.3695470,
author = {Cao, Jialun and Chen, Zhiyong and Wu, Jiarong and Cheung, Shing-Chi and Xu, Chang},
title = {JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695470},
doi = {10.1145/3691620.3695470},
abstract = {Code generation benchmarks such as HumanEval are widely adopted to evaluate LLMs' capabilities. However, after consolidating the latest 24 benchmarks, we noticed three significant imbalances. First, imbalanced programming language. 95.8% of benchmarks involve Python, while only 5 benchmarks involve Java, resulting in an insufficient understanding of LLMs' capability to generate Java code. Second, imbalanced code granularity. Function-/statement-level benchmarks account for over 83.3% of benchmarks. Only a mere handful extends to class-/project-levels, and all are limited to Python. Third, lacking advanced features. Existing benchmarks primarily assess basic coding skills (e.g., variables, operators, and control structures), while overlooking advanced Object-Oriented Programming (OOP) features (i.e., encapsulation, inheritance, and polymorphism). Considering the prevalence of these advanced features in real-world Java project development, constructing benchmarks to test LLMs on handling OOP features is necessary.To fill these gaps, we propose JavaBench, a project-level Java benchmark that exercises OOP features. It comprises four Java projects with 389 methods in 106 Java classes. The test coverage is up to 92%, and JavaBench is attested by 282 undergraduate students, reaching a 90.93/100 average score (i.e., pass rate against the test suite), ensuring the quality of documentation, code skeleton, and tests. To better evaluate LLM's capability against JavaBench, we introduce a systematic evaluation design covering three context settings and five synthesis strategies at two granularities using three hierarchical metrics. Our extensive experiment yields several interesting findings. First, we noticed that regarding project-level Java programming, LLMs are far behind undergraduate students (no project can be correctly completed by any studied LLMs, and at most 48.24% Pass@5 in a more relaxed evaluation). Second, using method signature as prompt context may strike an ideal balance for project-level code generation. JavaBench is publicly available at https://github.com/java-bench/JavaBench. We also release a leaderboard and invite model developers to participate and test their models against JavaBench at https://java-bench.github.io/leaderboard.html.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {870–882},
numpages = {13},
keywords = {large language model, program synthesis, object-oriented programming},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3661167.3661218,
author = {Abedu, Samuel and Abdellatif, Ahmad and Shihab, Emad},
title = {LLM-Based Chatbots for Mining Software Repositories: Challenges and Opportunities},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661218},
doi = {10.1145/3661167.3661218},
abstract = {Software repositories have a plethora of information about software development, encompassing details such as code contributions, bug reports and code reviews. This rich source of data can be harnessed to enhance not only software quality and development velocity but also to gain insights into team collaboration and inform strategic decision-making throughout the software development lifecycle. Previous studies show that many stakeholders cannot benefit from the project information due to the technical knowledge and expertise required to extract the project data. To lower the barrier to entry by automating the process of extracting and analyzing repository data, we explored the potential of using an LLM to develop a chatbot for answering questions related to software repositories. We evaluated the chatbot on 150 software repository-related questions. We found that the chatbot correctly answered one question. This result prompted us to shift our focus to investigate the challenges in adopting LLMs for the out-of-the-box development of software repository chatbots. We identified five main challenges related to retrieving data, structuring the data, and generating the answer to the user’s query. Among these challenges, the most frequent (83.3%) is the inaccurate retrieval of data to answer questions. In this paper, we share our experience and challenges in developing an LLM-based chatbot to answer software repository-related questions within the SE community. We also provide recommendations on mitigating these challenges. Our findings will serve as a foundation to drive future research aimed at enhancing LLMs for adoption in extracting useful information from software repositories, fostering advancements in natural language understanding, data retrieval, and response generation within the context of software repository-related questions and analytics.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {201–210},
numpages = {10},
keywords = {Conversational Development Assistant, Large Language Model, Software Chatbots},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3636555.3636883,
author = {Xu, Austin and Monroe, Will and Bicknell, Klinton},
title = {Large language model augmented exercise retrieval for personalized language learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636883},
doi = {10.1145/3636555.3636883},
abstract = {We study the problem of zero-shot exercise retrieval in the context of online language learning, to give learners the ability to explicitly request personalized exercises via natural language. Using real-world data collected from language learners, we observe that vector similarity approaches poorly capture the relationship between exercise content and the language that learners use to express what they want to learn. This semantic gap between queries and content dramatically reduces the effectiveness of general-purpose retrieval models pretrained on large scale information retrieval datasets like MS MARCO&nbsp;[2]. We leverage the generative capabilities of large language models to bridge the gap by synthesizing hypothetical exercises based on the learner’s input, which are then used to search for relevant exercises. Our approach, which we call mHyER, overcomes three challenges: (1) lack of relevance labels for training, (2) unrestricted learner input content, and (3) low semantic similarity between input and retrieval candidates. mHyER outperforms several strong baselines on two novel benchmarks created from crowdsourced data and publicly available data.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {284–294},
numpages = {11},
keywords = {large language models, online language learning, personalization, zero-shot exercise retrieval},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3583780.3615047,
author = {Hoq, Muntasir and Chilla, Sushanth Reddy and Ahmadi Ranjbar, Melika and Brusilovsky, Peter and Akram, Bita},
title = {SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615047},
doi = {10.1145/3583780.3615047},
abstract = {Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {783–792},
numpages = {10},
keywords = {algorithm detection, code representation, program analysis, program correctness prediction, static analysis},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3628096.3629066,
author = {Okolo, Chinasa T.},
title = {The Promise and Perils of Generative AI: Case Studies in an African Context},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3629066},
doi = {10.1145/3628096.3629066},
abstract = {As generative AI applications such as ChatGPT, Midjourney, DALL·E, Bard, and others increase in ubiquity, concerns about the negative implications of these technologies are becoming more present in public discourse. However, little research has examined the impact that generative AI stands to have on African consumers and users who may be affected by its application in various fields such as education, healthcare, and social media. This work presents an early look into the implications of using generative AI within African contexts, exploring case studies of current generative AI use within Africa. These case studies examine the use of generative AI in marketing and for image and text generation. While the potential for generative AI in Africa is growing, this preliminary work aims to set a foundation for highlighting risks associated with generative AI while exploring how generative AI can be responsibly developed and used within African contexts.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {266–270},
numpages = {5},
keywords = {Africa, algorithmic bias, generative AI, large language models, responsible AI},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@inproceedings{10.1145/3650212.3652134,
author = {Pan, Shengyi and Wang, You and Liu, Zhongxin and Hu, Xing and Xia, Xin and Li, Shanping},
title = {Automating Zero-Shot Patch Porting for Hard Forks},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652134},
doi = {10.1145/3650212.3652134},
abstract = {Forking is a typical way of code reuse, which provides a simple way for developers to create a variant software (denoted as hard fork) by copying and modifying an existing codebase. Despite of the benefits, forking also leads to duplicate efforts in software maintenance. Developers need to port patches across the hard forks to address similar bugs or implement similar features. Due to the divergence between the source project and the hard fork, patch porting is complicated, which requires an adaption regarding different implementations of the same functionality. In this work, we take the first step to automate patch porting for hard forks under a zero-shot setting. We first conduct an empirical study of the patches ported from Vim to Neovim over the last ten years to investigate the necessities of patch porting and the potential flaws in the current practice. We then propose a large language model (LLM) based approach (namely PPatHF) to automatically port patches for hard forks on a function-wise basis. Specifically, PPatHF is composed of a reduction module and a porting module. Given the pre- and post-patch versions of a function from the reference project and the corresponding function from the target project, the reduction module first slims the input functions by removing code snippets less relevant to the patch. Then, the porting module leverages a LLM to apply the patch to the function from the target project. To better elicit the power of the LLM on patch porting, we design a prompt template to enable efficient in-context learning. We further propose an instruction-tuning based training task to better guide the LLM to port the patch and inject task-specific knowledge. We evaluate PPatHF on 310 Neovim patches ported from Vim. The experimental results show that PPatHF outperforms the baselines significantly. Specifically, PPatHF can correctly port 131 (42.3%) patches and automate 57% of the manual edits required for the developer to port the patch.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {363–375},
numpages = {13},
keywords = {Hard Fork, Large Language Model, Patch Porting},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.1145/3689370,
author = {Rivadeneira, Lucia and Bellido de Luna, Daina and Fernandez, Carla},
title = {Exploring the Role of ChatGPT in Higher Education Institutions: Where does Latin America Stand?},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689370},
doi = {10.1145/3689370},
abstract = {This research examines how stakeholders in higher education institutions in Ecuador, Chile, and Costa Rica are adopting ChatGPT. Unlike existing literature that predominantly focuses on North America, Europe, or Asia, this research shifts the lens to Latin America. Adopting a qualitative approach, the study gathered data through 26 semi-structured interviews with higher education institution decision-makers (9), academic (14), and administrative staff (3), revealing the landscape of ChatGPT adoption and application. The findings show a varied level of ChatGPT adoption across different functions within these institutions, with no apparent contextual differences. While academic staff show a higher level of engagement for enhancing educational and research processes, administrative staff use it to perform day-to-day activities, such as improving writing. The role of ChatGPT in decision-making and transformative policies remains limited. Despite recognising the potential of ChatGPT to enhance education, decision-makers often mention challenges like discerning between human and artificial intelligence-generated content, fostering critical thinking, and addressing student inequalities. Decision-makers agree on the importance of training to tackle these challenges. The study seeks to help develop a strategic agenda for integrating technologies, such as ChatGPT, in Latin American universities.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = aug,
keywords = {Generative artificial intelligence, ChatGPT, Higher education institutions, Latin America}
}

@article{10.5555/3722479.3722497,
author = {Shen, Zhairui and Wang, Tianwei and Ford, Vitaly},
title = {Exploring the Architecture and Application of Transformer Models in Natural Language Processing and Media Generation},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {This project investigates the detailed architecture of Transformer models, including components such as self-attention mechanisms, multi-head attention, and positional encoding. The research further explores the application of Transformers in text processing, covering tasks like tokenization, stemming, and word embedding. Additionally, the project examines the use of Transformer models in generating images and videos from textual descriptions, specifically through the integration of Generative Adversarial Networks (GANs) with Transformers. The expected outcome of this research is a comprehensive analysis that illustrates the significant impact of Transformer models (and their enhancements) on both natural language processing and AI-driven content creation.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {47–48},
numpages = {2}
}

@inproceedings{10.1145/3675094.3677545,
author = {Zhang, Shiquan and Ma, Ying and Fang, Le and Jia, Hong and D'Alfonso, Simon and Kostakos, Vassilis},
title = {Enabling On-Device LLMs Personalization with Smartphone Sensing},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677545},
doi = {10.1145/3675094.3677545},
abstract = {This demo presents a novel end-to-end framework that combines on-device large language models (LLMs) with smartphone sensing technologies to achieve context-aware and personalized services. The framework addresses critical limitations of current personalization solutions via cloud LLMs, such as privacy concerns, latency and cost, and limited personal information. To achieve this, we innovatively proposed deploying LLMs on smartphones with multimodal sensor data through context-aware sensing and customized prompt engineering, ensuring privacy and enhancing personalization performance. A case study involving a university student demonstrated the capability of the framework to provide tailored recommendations. In addition, we show that the framework achieves the best trade-off in privacy, performance, latency, cost, battery and energy consumption between on-device and cloud LLMs. To the best of our knowledge, this is the first framework to provide on-device LLMs personalization with smartphone sensing. Future work will incorporate more diverse sensor data and involve extensive user studies to enhance personalization. Our proposed framework has the potential to substantially improve user experiences across domains including healthcare, productivity, and entertainment.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {186–190},
numpages = {5},
keywords = {end-to-end framework, llm, on-device, personalization, smartphone sensing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3678610.3678625,
author = {Chan, Shiau Wei and Norhisham, Nur Intan Shahira and Ismail, Fadillah and Ahmad, Md Fauzi},
title = {Students' Perceptions and Intentions Regarding ChatGPT Usage in Higher Education},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678625},
doi = {10.1145/3678610.3678625},
abstract = {The adoption of new technologies such as ChatGPT has opened up the potential to elevate education to the next level. However, several issues have arisen with ChatGPT, including concerns related to academic integrity and the challenge of distinguishing between AI-generated and human-generated content. Thus, this study aimed to investigate students' perceptions and intentions regarding the use of ChatGPT in higher education. A total of 320 undergraduate students were selected from the Faculty of Technology Management and Business (FPTP) at Universiti Tun Hussein Onn Malaysia (UTHM). The random sampling method was employed in this study, with a population size of 1976 students. Data were collected through a questionnaire, and statistical analysis was conducted using SPSS software. The findings of this research reveal that students' perception of ChatGPT usage is moderate, while their intention to use ChatGPT is interpreted at a high level. Furthermore, a positive correlation between students' intentions and perceptions toward ChatGPT was discovered. This study is crucial for understanding students' perceptions and intentions to optimize their benefits and comprehend their risks to students, organizations, and ethics.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {49–54},
numpages = {6},
keywords = {ChatGPT, Higher Education, Intention, Perception},
location = {
},
series = {ICSLT '24}
}

@proceedings{10.1145/3605770,
title = {SCORED '23: Proceedings of the 2023 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
year = {2023},
isbn = {9798400702631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM SCORED '23, the second edition of the ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses. This edition is held in Copenhagen, Denmark with extensive support for in-person and virtual attendance.This year's program includes exciting work along many different dimensions of research on supply chain security: the development of security policies for software supply chains, the use of artificial intelligence and large language models, approaches on software bills of materials, and the proposals of risk mitigation techniques. Consistent with its focus, SCORED brings researchers, legislators and practitioners in both open- and closed-source ecosystems to the center of current and emerging challenges and opportunities in software supply chain security.},
location = {Copenhagen, Denmark}
}

@inproceedings{10.1145/3691620.3695531,
author = {Zhou, Zhuotong and Yang, Yongzhuo and Wu, Susheng and Huang, Yiheng and Chen, Bihuan and Peng, Xin},
title = {Magneto: A Step-Wise Approach to Exploit Vulnerabilities in Dependent Libraries via LLM-Empowered Directed Fuzzing},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695531},
doi = {10.1145/3691620.3695531},
abstract = {The wide adoption of open source third-party libraries can propagate vulnerabilities that originally exist in third-party libraries through dependency chains to downstream projects. To mitigate this security risk, vulnerability exploitation analysis has been proposed to further reduce false positives of vulnerability reachability analysis. However, existing approaches work less effectively when the vulnerable function of the vulnerable library is indirectly invoked by a client project through a call chain of multiple steps.To address this problem, we propose a step-wise approach, named Magneto, to exploit vulnerabilities in dependent libraries of a client project through LLM-empowered directed fuzzing. Its core idea is to decompose the directed fuzzing for the whole call chain (from the client project to the vulnerable function) into a series of step-wise directed fuzzing for each step of the call chain. To empower directed fuzzing, it leverages LLM to facilitate the initial seed generation. Our evaluation has demonstrated the effectiveness of Magneto over the state-of-the-art; i.e., Magneto achieves an improvement of at least 75.6% in successfully exploiting the vulnerability.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1633–1644},
numpages = {12},
keywords = {library vulnerabilities, exploit generation, directed fuzzing},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3663548.3688531,
author = {Liu, Xinlei and Wu, Kevin and Kulkarni, Minchu and Saugstad, Michael and Rapo, Peyton Anton and Freiburger, Jeremy and Hosseini, Maryam and Li, Chu and Froehlich, Jon E.},
title = {Towards Fine-Grained Sidewalk Accessibility Assessment with Deep Learning: Initial Benchmarks and an Open Dataset},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663548.3688531},
doi = {10.1145/3663548.3688531},
abstract = {We examine the feasibility of using deep learning to infer 33 classes of sidewalk accessibility conditions in pre-cropped streetscape images, including bumpy, brick/cobblestone, cracks, height difference (uplifts), narrow, uneven/slanted, pole, and sign. We present two experiments: first, a comparison between two state-of-the-art computer vision models, Meta’s DINOv2 and OpenAI’s CLIP-ViT, on a cleaned dataset of ∼ 24k images; second, an examination of a larger but noisier crowdsourced dataset (∼ 87k images) on the best performing model from Experiment 1. Though preliminary, Experiment 1 shows that certain sidewalk conditions can be identified with high precision and recall, such as missing tactile warnings on curb ramps and grass grown on sidewalks, while Experiment 2 demonstrates that larger but noisier training data can have a detrimental effect on performance. We contribute an open dataset and classification benchmarks to advance this important area.},
booktitle = {Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
articleno = {103},
numpages = {12},
keywords = {DINOv2, Sidewalk accessibility, ViT-CLIP, computer vision, human mobility, obstacle detection},
location = {St. John's, NL, Canada},
series = {ASSETS '24}
}

@inproceedings{10.1145/3640544.3645234,
author = {George, Samuel D and Dewan, Prasun},
title = {NotebookGPT – Facilitating and Monitoring Explicit Lightweight Student GPT Help Requests During Programming Exercises},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645234},
doi = {10.1145/3640544.3645234},
abstract = {The success of GPT with coding tasks has made it important to consider the impact of GPT and similar models on teaching programming. Students’ use of GPT to solve programming problems can hinder their learning. However, they might also get significant benefits such as quality feedback on programming style, explanations of how a given piece of code works, help with debugging code, and the ability to see valuable alternatives to their code solutions. We propose a new design for interacting with GPT called Mediated GPT with the goals of (a) providing students with access to GPT but allowing instructors to programmatically modify responses to prevent hindrances to student learning and combat common GPT response concerns, (b) helping students generate and learn to create effective prompts to GPT, and (c) tracking how students use GPT to get help on programming exercises. We demonstrate a first-pass implementation of this design called NotebookGPT.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {62–65},
numpages = {4},
keywords = {ChatGPT, Computer programming, GPT, Intelligent tutoring systems, Learning at scale},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3640543.3645196,
author = {Xu, Xiaotong (Tone) and Yin, Jiayu and Gu, Catherine and Mar, Jenny and Zhang, Sydney and E, Jane L. and Dow, Steven P.},
title = {Jamplate: Exploring LLM-Enhanced Templates for Idea Reflection},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645196},
doi = {10.1145/3640543.3645196},
abstract = {Advances in AI, particularly large language models (LLMs), can transform creative work. When developing a new idea, LLMs can help designers gather information, find competitors, and generate alternatives. However, LLM responses tend to be long-winded or contain inaccuracies, placing a burden on users to carefully synthesize information. In our formative studies with 52 students and five instructors, we find that novice designers typically lack guidance on how to compose prompts, reflect critically on LLM responses, and extract key information to help shape an idea. Building on these insights, we explore an alternative approach for interacting with LLMs, not via chat, but rather through structured templates. Collaborative design templates are a well-established strategy for helping novices think, organize information, and reflect on creative work. Developed as a digital whiteboard plugin, Jamplate integrates LLM capabilities into design templates, streamlining the collection and organization of user-generated content and LLM responses within the template structure. In a preliminary study with 8 novice designers, participants expressed that Jamplate’s reflective questions and in-situ guidance improved their ability to think critically and improve ideas more effectively. We discuss the potential of designing LLM-enhanced templates to instigate critical reflection.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {907–921},
numpages = {15},
keywords = {LLM interaction, design process, design template, large language model interaction},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3700297.3700336,
author = {Abbas, Touqeer and Javed, Umair and Mehmood, Faisal and Raza, Muneeb and Li, Hui},
title = {ChemGenX: AI in the Chemistry Classroom},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700336},
doi = {10.1145/3700297.3700336},
abstract = {Generative AI is reshaping education by offering personalized learning experiences and innovative teaching methods. In this study, we introduced ChemGenX, an AI tool designed to enhance chemistry education by generating molecular structures with user-defined features. The primary objective is to simplify molecular design and improve student learning. Our approach utilizes the coherently aligned multimodal semantic space using pre-trained CLIP; generate text features from image features to seamlessly alleviate the need for text conditioning, resulting in accurate predictions of bond lengths, angles, and molecular structures. The model was trained on a comprehensive molecular dataset, achieving competitive performance in zero-shot text-to-image conversion. Pilot studies with high school students and teachers demonstrate its potential in generating accurate molecular structures, including key features like bond lengths and angles.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {224–230},
numpages = {7},
keywords = {AI Classroom, Conditional generative model, Personalized learning},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3670653.3677507,
author = {Kubullek, Ann-Kathrin and Kuma\c{c}, Nadire and Dogang\"{u}n, Ayseg\"{u}l},
title = {Understanding the Adoption of ChatGPT in Higher Education: A Comparative Study with Insights from STEM and Business Students},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3677507},
doi = {10.1145/3670653.3677507},
abstract = {Since ChatGPT’s introduction, generative artificial intelligence (AI) has significantly influenced the media, technological innovation, and educational discourse. Its increasing importance, especially in academia, necessitates a detailed examination of the impact of AI on higher education, particularly on how it changes teaching and learning processes. This study therefore looks at the factors affecting students’ attitudes towards AI technologies in the university setting, with a particular focus on the differences between business and STEM programmes. Using a mixed methods approach, the study combines surveys and interviews to collect data on students’ perceptions, attitudes and experiences with generative AI technology in academia. The data collected is analysed both quantitatively and qualitatively to reveal significant trends and insights into the adoption and use of generative AI tools in the university environment. The main objective of the study is to shed light on the determinants that determine the varying degrees of AI adoption in different academic disciplines. The findings have the potential to inform the implementation of educational technology and assist in the development of strategies for the effective integration of generative AI tools to meet the different needs and preferences of students in a range of academic contexts.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {684–689},
numpages = {6},
keywords = {ChatGPT, STEM degree programs, academic disciplines, acceptance of AI, business degree programs, generative AI adoption, higher education, students},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@article{10.5555/3637036.3637046,
author = {Huggins, James K.},
title = {ChatGPT: The Good, the Bad, and the Ugly},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {4},
issn = {1937-4771},
abstract = {ChatGPT [1] is a predictive AI chatbot that has recently gained significant attention for its ability to answer natural language questions on a wide range of topics with uncommon accuracy. It can even help users revise written texts, such as this abstract! However, teachers at all levels have expressed concerns about its impact on course assessment.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {94},
numpages = {1}
}

@inproceedings{10.1145/3626111.3628189,
author = {Xiang, Qiao and Lin, Yuling and Fang, Mingjun and Huang, Bang and Huang, Siyong and Wen, Ridi and Le, Franck and Kong, Linghe and Shu, Jiwu},
title = {Toward Reproducing Network Research Results Using Large Language Models},
year = {2023},
isbn = {9798400704154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626111.3628189},
doi = {10.1145/3626111.3628189},
abstract = {Reproducing research results is important for the networking community. The current best practice typically resorts to: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; or (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private ones are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). We first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report our observations and lessons and discuss future open research questions of this proposal.},
booktitle = {Proceedings of the 22nd ACM Workshop on Hot Topics in Networks},
pages = {56–62},
numpages = {7},
keywords = {Large language models, Networking systems},
location = {Cambridge, MA, USA},
series = {HotNets '23}
}

@inproceedings{10.1145/3631700.3665234,
author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
title = {Towards Zero-shot Knowledge Graph building: Automated Schema Inference},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665234},
doi = {10.1145/3631700.3665234},
abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {467–473},
numpages = {7},
keywords = {Large Language Models, Named Entity Recognition, Ontology Learning},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@article{10.5555/3722479.3722521,
author = {Poffenberger, Rachael and Cornejo, Chaz and Liao, Weidong},
title = {Designing and Prototyping a Parking Space Monitoring System with Generative AI and Large Multimodal Models},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {In recent years, Generative AI and Large Multimodal Models have demonstrated significant advancements in image recognition, detailed responses, and complex reasoning. Our project harnesses these capabilities to monitor parking space occupancy by placing a camera above a parking lot and using Generative AI to assess the number of cars present. This system aims to provide real-time information to users, helping them determine if they should seek alternative parking. Additionally, with sufficient data, the system could predict peak hours and busy days for the parking lot.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {83–84},
numpages = {2}
}

@inproceedings{10.1145/3613904.3642438,
author = {Han, Ariel and Zhou, Xiaofei and Cai, Zhenyao and Han, Shenshen and Ko, Richard and Corrigan, Seth and Peppler, Kylie A},
title = {Teachers, Parents, and Students' perspectives on Integrating Generative AI into Elementary Literacy Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642438},
doi = {10.1145/3613904.3642438},
abstract = {The viral launch of new generative AI (GAI) systems, such as ChatGPT and Text-to-Image (TTL) generators, sparked questions about how they can be effectively incorporated into writing education. However, it is still unclear how teachers, parents, and students perceive and suspect GAI systems in elementary school settings. We conducted a workshop with twelve families (parent-child dyads) with children ages 8-12 and interviewed sixteen teachers in order to understand each stakeholder’s perspectives and opinions on GAI systems for learning and teaching writing. We found that the GAI systems could be beneficial in generating adaptable teaching materials for teachers, enhancing ideation, and providing students with personalized, timely feedback. However, there are concerns over authorship, students’ agency in learning, and uncertainty concerning bias and misinformation. In this article, we discuss design strategies to mitigate these constraints by implementing an adults-oversight system, balancing AI-role allocation, and facilitating customization to enhance students’ agency over writing projects.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {678},
numpages = {17},
keywords = {Artificial Intelligence, Generative AI, K-12 Education},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3701625.3701681,
author = {Menolli, Andr\'{e} and Strik, Bruno and Rodrigues, Luiz},
title = {Teaching Refactoring to Improve Code Quality with ChatGPT: An Experience Report in Undergraduate Lessons},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701681},
doi = {10.1145/3701625.3701681},
abstract = {Refactoring presents a complex computational challenge, and its learning is intricate, requiring a solid foundation in computational thinking, programming and object-oriented concepts. Moreover, making students realize the importance and benefits of refactoring is also challenging. To address this complexity, we introduce a refactoring teaching method based on Generative Artificial Intelligence (GAI), incorporating single-loop and double-loop learning principles, focusing on fostering deeper and critical learning. We used ChatGPT, a GAI-based tool, and conducted an eight-week mixed-methods study involving 23 computer science undergraduate students. The study involved applying four distinct projects extracted from GitHub, where participants were tasked with identifying code smells and performing the necessary refactoring to improve code quality. The primary focus was on identifying both the positive and negative aspects of the method, as well as delineating the computational thinking characteristics developed during the process. The results indicate that the use of ChatGPT facilitated the learning of refactoring, contributing to the development of numerous computational thinking skills, especially problem formulation, decomposition, and abstraction. Thus, this paper contributes a GAI-based teaching method along with evidence on how it helps students develop refactoring skills.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {563–574},
numpages = {12},
keywords = {Generative Artificial Intelligence, ChatGPT, Refactory, Higher Education, Teaching, Computational Thinking},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3657604.3662046,
author = {Chen, Binglin and Lewis, Colleen M. and West, Matthew and Zilles, Craig},
title = {Plagiarism in the Age of Generative AI: Cheating Method Change and Learning Loss in an Intro to CS Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662046},
doi = {10.1145/3657604.3662046},
abstract = {Background: ChatGPT became widespread in early 2023 and enabled the broader public to use powerful generative AI, creating a new means for students to complete course assessments.  Purpose: In this paper, we explored the degree to which generative AI impacted the frequency and nature of cheating in a large introductory programming course. We also estimate the learning impact of students choosing to submit plagiarized work rather than their own work.  Methods: We identified a collection of markers that we believe are indicative of plagiarism in this course. We compare the estimated prevalence of cheating in the semesters before and during which ChatGPT became widely available. We use linear regression to estimate the impact of students' patterns of cheating on their final exam performance. Findings: The patterns associated with these plagiarism markers suggest that the quantity of plagiarism increased with the advent of generative AI, and we see evidence of a shift from online plagiarism hubs (e.g., Chegg, CourseHero) to ChatGPT. In addition, we observe statistically significant learning losses proportional to the amount of presumed plagiarism, but there is no statistical difference on the proportionality between semesters.  Implications: Our findings suggest that unproctored exams become increasingly insecure and care needs to be taken to ensure the validity of summative assessments. More importantly, our results suggest that generative AI can be detrimental to students' learning. It seems necessary for educators to reduce the benefit of students using generative AI for counterproductive purposes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {75–85},
numpages = {11},
keywords = {cheating, cs 1, generative ai, llm, plagiarism detection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3643650.3658605,
author = {Lomotey, Richard K. and Kumi, Sandra and Ray, Madhurima and Deters, Ralph},
title = {Synthetic Data Digital Twins and Data Trusts Control for Privacy in Health Data Sharing},
year = {2024},
isbn = {9798400705557},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643650.3658605},
doi = {10.1145/3643650.3658605},
abstract = {Health data sharing is very valuable for medical research since it has the propensity to improve diagnostics, policy, medication, and so on. At the same time, sharing health data needs to be done without compromising the privacy of patients and stakeholders. However, recent advances in AI/ML and sophisticated analytics have proven to introduce biases that can easily identify patients based on their healthcare data, which violates privacy. In this work, we sort to address this major issue by exploring two emerging topics that are gaining attention from industry, academia, and governments, i.e., digital twins and data trusts. First, we proposed the use of digital twins (DTs) to generate synthetic records of patient's heart rate data. DTs are virtual replicas of the actual data and were created using two synthetic data generative models - Gaussian Copula (GC) and Tabular Variational Autoencoder (TVAE). The GC and TVAE achieved a maximum data quality score of 88% and 96% respectively. Next, we posit that the DTs should be shared with a data trusts layer. Data trusts are fiduciary frameworks that govern multi-party data sharing. The data trusts enforce access controls (based on metrics such as location, role-based, and policy-based) to the synthetic health data and reports to the data subject. The preliminary evaluations of the work show that merging the two techniques (i.e., synthetic data digital twins and data trusts) enforces better privacy for health data access. The synthetic data ensures more anonymization while the data trusts provide easy auditing, tracking, and efficient reporting to the patient or data subject. The paper also detailed the architectural design of the data trusts and evaluated the efficiency of the access control techniques.},
booktitle = {Proceedings of the 2024 ACM Workshop on Secure and Trustworthy Cyber-Physical Systems},
pages = {1–10},
numpages = {10},
keywords = {artificial intelligence, data trusts, digital twins, machine learning, middleware, privacy, synthetic health data},
location = {Porto, Portugal},
series = {SaT-CPS '24}
}

@inproceedings{10.1145/3629527.3651419,
author = {Niewenhuis, Dante and Talluri, Sacheendra and Iosup, Alexandru and De Matteis, Tiziano},
title = {FootPrinter: Quantifying Data Center Carbon Footprint},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629527.3651419},
doi = {10.1145/3629527.3651419},
abstract = {Data centers have become an increasingly significant contributor to the global carbon footprint. In 2021, the global data center industry was responsible for around 1% of the worldwide greenhouse gas emissions. With more resource-intensive workloads, such as Large Language Models, gaining popularity, this percentage is expected to increase further. Therefore, it is crucial for data center service providers to become aware of and accountable for the sustainability impact of their design and operational choices. However, reducing the carbon footprint of data centers has been a challenging process due to the lack of comprehensive metrics, carbon-aware design tools, and guidelines for carbon-aware optimization. In this work, we propose FootPrinter, a first-of-its-kind tool that supports data center designers and operators in assessing the environmental impact of their data center. FootPrinter uses coarse-grained operational data, grid energy mix information, and discrete event simulation to determine the data center's operational carbon footprint and evaluate the impact of infrastructural or operational changes. FootPrinter can simulate days of operations of a regional data center on a commodity laptop in a few seconds, returning the estimated footprint with marginal error. By making this project open source, we hope to engage the community in the development of methodologies and tools for systematically assessing and exploring the sustainability of data centers.},
booktitle = {Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
pages = {189–195},
numpages = {7},
keywords = {carbon emission, carbon footprint, data center, simulation},
location = {London, United Kingdom},
series = {ICPE '24 Companion}
}

@inproceedings{10.1145/3597926.3598060,
author = {Liu, Kaibo and Han, Yudong and Zhang, Jie M. and Chen, Zhenpeng and Sarro, Federica and Harman, Mark and Huang, Gang and Ma, Yun},
title = {Who Judges the Judge: An Empirical Study on Online Judge Tests},
year = {2023},
isbn = {9798400702211},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597926.3598060},
doi = {10.1145/3597926.3598060},
abstract = {Online Judge platforms play a pivotal role in education, competitive programming, recruitment, career training, and large language model training. They rely on predefined test suites to judge the correctness of submitted solutions. It is therefore important that the solution judgement is reliable and free from potentially misleading false positives (i.e., incorrect solutions that are judged as correct). In this paper, we conduct an empirical study of 939 coding problems with 541,552 solutions, all of which are judged to be correct according to the test suites used by the platform, finding that 43.4% of the problems include false positive solutions (3,440 bugs are revealed in total). We also find that test suites are, nevertheless, of high quality according to widely-studied test effectiveness measurements: 88.2% of false positives have perfect (100%) line coverage, 78.9% have perfect branch coverage, and 32.5% have a perfect mutation score. Our findings indicate that more work is required to weed out false positive solutions and to further improve test suite effectiveness. We have released the detected false positive solutions and the generated test inputs to facilitate future research.},
booktitle = {Proceedings of the 32nd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {334–346},
numpages = {13},
keywords = {Online judge platform, software testing, test assessment},
location = {Seattle, WA, USA},
series = {ISSTA 2023}
}

@inproceedings{10.1145/3686038.3686652,
author = {Zeghouani, Omar and Ali, Zawar and Simson van Dijkhuizen, William and Hong, Jia Wei and Clos, Jeremie},
title = {Examining the Feasibility of AI-Generated Questions in Educational Settings},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686652},
doi = {10.1145/3686038.3686652},
abstract = {Educators face ever-growing time constraints, leading to poor work-life balance and a negative impact on work quality. Through their language generation capabilities, large language models offer an interesting avenue to ease this academic workload, allowing both students and lecturers to generate educational content. In this work, we leverage the latest developments in automatic speech recognition, natural language generation, retrieval-augmented generation, and multimodal models to design the Augmented Lecture Integration Network (ALINet), a system capable of producing a diverse range of high-quality assessment questions from lecture content. We inform the design of our system through a series of automated experiments using public datasets and evaluate it with a user study conducted on students and educators. Our results indicate a generally positive perception of the system’s performance, particularly in generating natural and clear questions relevant to the taught content, demonstrating its potential as a valuable resource in educational settings. This project lays the foundation for future research in multimodal educational question generation and is available for reuse in our public repository.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {36},
numpages = {6},
keywords = {Educational Question Generation, Generative AI, Large Language Models},
location = {Austin, TX, USA},
series = {TAS '24}
}

@inproceedings{10.1145/3672539.3686338,
author = {Zheng, Chengbo and Huang, Zeyu and Ma, Shuai and Ma, Xiaojuan},
title = {SelfGauge: An Intelligent Tool to Support Student Self-assessment in GenAI-enhanced Project-based Learning},
year = {2024},
isbn = {9798400707186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672539.3686338},
doi = {10.1145/3672539.3686338},
abstract = {Project-based learning (PBL) involves students tackling real-world problems and creating artifacts. With the rise of generative AI (GenAI) tools, assessing students in GenAI-enhanced PBL is challenging. To address this, we designed SelfGauge, a tool that supports student self-assessment by analyzing their GenAI usage and project artifacts. It helps students define criteria, seek feedback, and reflect on their performance, promoting continuous self-improvement.},
booktitle = {Adjunct Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {97},
numpages = {3},
keywords = {AI in Education, Project-based Learning, Reflection},
location = {Pittsburgh, PA, USA},
series = {UIST Adjunct '24}
}

@inproceedings{10.1145/3573051.3593393,
author = {Markel, Julia M. and Opferman, Steven G. and Landay, James A. and Piech, Chris},
title = {GPTeach: Interactive TA Training with GPT-based Students},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3593393},
doi = {10.1145/3573051.3593393},
abstract = {Interactive and realistic teacher training is hard to scale. This is a key issue for learning at scale, as inadequate preparation can negatively impact both students and teachers. What if we could make the teacher training experience more engaging and, as a downstream effect, reduce the potential for harm that teachers-in-training could inflict on students? We present GPTeach, an interactive chat-based teacher training tool that allows novice teachers to practice with simulated students. We performed two studies to evaluate GPTeach: one think-aloud study and one A/B test between our tool and a baseline. Participants took the role of a teaching assistant conducting office hours with two GPT-simulated students. We found that our tool provides the opportunity for teachers to get valuable teaching practice without the pressures of affecting real students, allowing them to iterate their responses both during and across sessions. Additionally, participants enjoyed flexibility in tailoring their responses according to the varied personas, needs, and learning goals. In this paper, we provide quantitative results and qualitative observations to inform future work in this area. We conclude with a discussion of actionable design ideas for such systems, as well as other ways to use this tool for evaluating teachers and students. GPTeach has recently been deployed into the teacher training component of an online course with over 800 novice teachers.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {226–236},
numpages = {11},
keywords = {GPT-simulated students, scalable teacher training},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3573051.3593391,
author = {Kim, Yunsung and Piech, Chris},
title = {High-Resolution Course Feedback: Timely Feedback Mechanism for Instructors},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3593391},
doi = {10.1145/3573051.3593391},
abstract = {We study the problem of minimizing the delay between when an issue comes up in a course and when instructors get feedback about it. The widespread practice of obtaining midterm and end-of-term feedback from students is suboptimal in this regard, especially for large courses: it over-samples at a specific point in the course and can be biased by factors irrelevant to the teaching process. As a solution, we release High Resolution Course Feedback (HRCF), an open-source student feedback mechanism that builds on a surprisingly simple idea: survey each student on random weeks exactly twice per term. Despite the simplicity of its core idea, when deployed to 31 courses totaling a cumulative 6,835 students, HRCF was able to detect meaningful mood changes in courses and significantly improve timely feedback without asking for extra work from students compared to the common practice. An interview with the instructors revealed that HRCF provided constructive and useful feedback about their courses early enough to be acted upon, which would have otherwise been unobtainable through other survey methods. We also explore the possibility of using Large Language Models to flexibly and intuitively organize large volumes of student feedback at scale and discuss how HRCF can be further improved.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {81–91},
numpages = {11},
keywords = {course improvement, course survey, student evaluations of teaching, student feedback on teaching, timely feedback},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3687123.3698291,
author = {Jayati, Sravan and Choi, Eric and Burton, Henry and Newsam, Shawn},
title = {Leveraging Large Multimodal Models to Augment Image-Based Building Damage Assessment},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698291},
doi = {10.1145/3687123.3698291},
abstract = {We consider the problem of automatically assigning a coarse damage level to a building given a single ground view image taken after a hazard event such as a hurricane or an earthquake. Rapid damage assessment is important not only for near term emergency response but also for initiating longer term recovery efforts. There is great opportunity to speed up this assessment through automated means based on machine learning. While previous work on this problem has considered just the visual content of the image to perform the damage prediction, we propose a novel extension in which we also consider a text caption generated from the image using a large multimodal model (LMM). We show that integrating the image and LMM generated text caption outperforms using either the image or caption alone. This demonstrates that the LMM generated captions are complementary to the visual content of the images and invites further investigation into how large generative models can help with damage assessment. The results are established through experiments on a new dataset of post-hurricane images of buildings and their corresponding ground truth damage levels provided by industry professionals.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {79–85},
numpages = {7},
keywords = {Computer vision, damage assessment, large multimodal models},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@inproceedings{10.1145/3691720.3691728,
author = {Qin, Yuqun and Zeng, Lizhi and Wei, Jieshu and Hu, Yani and Wu, Wenli and Wang, Hui},
title = {Integrating ChatGPT into Human Morphology and Curriculum Ideology and Politic: Enhancing Learning and Engagement},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691728},
doi = {10.1145/3691720.3691728},
abstract = {In order to better play the role of ChatGPT in the teaching of human morphology and structure and cultivate more high-quality skilled nursing talents, this study combines ChatGPT and Xueyin Online for blended teaching from the perspective of Curriculum Ideology and Politics. A total of 102 students from Class 1 and Class 2 of 2023 were enrolled. We established a t-test model, and used SPSS for data measurement and statistical analysis. Nursing class 2 was the control group, and the traditional teaching method was adopted. The experimental group of nursing class 1, on the basis of the control group, combined with ChatGPT for online and offline blended teaching. Finally, the theoretical and experimental scores of the two groups were compared, the comprehensive literacy and satisfaction levels of the students was evaluated by questionnaire survey. The theoretical and practical scores of the experimental group were higher than those of the control group (P&lt;0.05). Both the comprehensive literacy evaluation score and satisfaction levels were better than that of the control group (P&lt;0.05). The online and offline hybrid teaching of ChatGPT based on the concept of "big ideology and politics" is significantly better than that of traditional teaching. ChatGPT provides teachers and students with a new type of AI-assisted tool to improve teaching effectiveness.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {40–45},
numpages = {6},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3636555.3636905,
author = {Suraworachet, Wannapon and Seon, Jennifer and Cukurova, Mutlu},
title = {Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636905},
doi = {10.1145/3636555.3636905},
abstract = {Effective collaboration requires groups to strategically regulate themselves to overcome challenges. Research has shown that groups may fail to regulate due to differences in members’ perceptions of challenges which may benefit from external support. In this study, we investigated the potential of leveraging three distinct natural language processing models: an expert knowledge rule-based model, a supervised machine learning (ML) model and a Large Language model (LLM), in challenge detection and challenge dimension identification (cognitive, metacognitive, emotional and technical/other challenges) from student discourse, was investigated. The results show that the supervised ML and the LLM approaches performed considerably well in both tasks, in contrast to the rule-based approach, whose efficacy heavily relies on the engineered features by experts. The paper provides an extensive discussion of the three approaches’ performance for automated detection and support of students’ challenge moments in collaborative learning activities. It argues that, although LLMs provide many advantages, they are unlikely to be the panacea to issues of the detection and feedback provision of socially shared regulation of learning due to their lack of reliability, as well as issues of validity evaluation, privacy and confabulation. We conclude the paper with a discussion on additional considerations, including model transparency to explore feasible and meaningful analytical feedback for students and educators using LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {473–485},
numpages = {13},
keywords = {Challenge moments, Collaborative learning, Discourse analysis, Natural language processing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3610978.3638160,
author = {Racca, Mattia and Mirsky, Reuth and Senft, Emmanuel and Xiao, Xuesu and Idrees, Ifrah and Kshirsagar, Alap and Prakash, Ravi},
title = {3rd Workshop on Human-Interactive Robot Learning (HIRL)},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638160},
doi = {10.1145/3610978.3638160},
abstract = {With robots poised to enter our daily environments, they will not only need to work for people, but also learn from them. An active area of investigation in the robotics, machine learning, and human-robot interaction communities is the design of teachable robots that can learn interactively from humans. To refer to these research efforts, we use the umbrella term Human-Interactive Robot Learning (HIRL). In the last 2 years we began consolidating what defines HIRL in terms of long, medium, and short-term research problems and what the different communities can contribute to those problems. With this third installment of the HIRL workshop, we aim at further consolidating this community and, specifically this year, discuss how the recent widespread of Large Language Models (LLMs) will impact the teaching of robots and explore the opportunities and challenges presented by robots' nature of embodied agents.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1349–1351},
numpages = {3},
keywords = {interactive robot learning, learning from human input, socially intelligent robots, socially interactive learning},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3605390.3605400,
author = {Lee, Hyungmin and Hsia, Chen-Chun and Tsoy, Aleksandr and Choi, Sungmin and Hou, Hanchao and Ni, Shiguang},
title = {VisionARy: Exploratory research on Contextual Language Learning using AR glasses with ChatGPT},
year = {2023},
isbn = {9798400708060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605390.3605400},
doi = {10.1145/3605390.3605400},
abstract = {Language learning is a challenging and time-consuming process, requiring an immersive environment and active usage of the language. However, English as a Foreign Language (EFL) learners often face difficulties in obtaining immersive learning experiences due to one-sided teaching and a lack of real-life English language contexts for practice. To overcome this challenge, various approaches have been proposed that leverage technologies such as mobile-based augmented reality and chatbots. However, these approaches have limitations that hinder full immersion into the language learning environment and fail to adequately contextualize the learning experience. With the recent breakthroughs in large language models and the development of lighter and more powerful AR glasses, we propose VisionARy, the first system that integrates ChatGPT into AR glasses to improve oral language skills and provide a contextualized learning experience. The evaluation results suggest that VisionARy has the potential to be effective and is highly accepted in improving oral language skills, compared to traditional learning methods. Furthermore, our findings provide important insights for the future design of language learning systems.},
booktitle = {Proceedings of the 15th Biannual Conference of the Italian SIGCHI Chapter},
articleno = {22},
numpages = {6},
keywords = {Augmented Reality Glasses, ChatGPT, Computer Vision, Contextual Language Learning, GPT-4, Speech Recognition},
location = {Torino, Italy},
series = {CHItaly '23}
}

@inproceedings{10.1145/3640794.3665542,
author = {Ouaazki, Abdessalam and Bergram, Kristoffer and Farah, Juan Carlos and Gillet, Denis and Holzer, Adrian},
title = {Generative AI-Enabled Conversational Interaction to Support Self-Directed Learning Experiences in Transversal Computational Thinking},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665542},
doi = {10.1145/3640794.3665542},
abstract = {As computational thinking (CT) becomes increasingly acknowledged as an important skill in education, self-directed learning (SDL) emerges as a key strategy for developing this capability. The advent of generative AI (GenAI) conversational agents has disrupted the landscape of SDL. However, many questions still arise about several user experience aspects of these agents. This paper focuses on two of these questions: personalization and long-term support. As such, the first part of this study explores the effectiveness of personalizing GenAI through prompt-tuning using a CT-based prompt for solving programming challenges. The second part focuses on identifying the strengths and weaknesses of a GenAI model in a semester-long programming project. Our findings indicate that while prompt-tuning could hinder ease of use and perceived learning assistance, it might lead to higher learning outcomes. Results from a thematic analysis also indicate that GenAI is useful for programming and debugging, but it presents challenges such as over-reliance and diminishing utility over time.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {13},
numpages = {12},
keywords = {ChatGPT, Chatbots, Education, Generative AI, Programming, Student Perceptions},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3670013.3670058,
author = {Torrato, Janette B. and Pillar, Genevieve A. and Robledo, Dave Arthur R. and Aguja, Socorro E. and Prudente, Maricar S.},
title = {Knowledge, Attitudes, and Practices on ChatGPT:Perspectives from Students and Teachers of De La Salle Santiago Zobel School},
year = {2024},
isbn = {9798400717062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670013.3670058},
doi = {10.1145/3670013.3670058},
abstract = {Abstract. Chat Generative Pre-trained Transformer (ChatGPT) is an artificial intelligence (AI) system that is gaining popularity among students and teachers. However, in the basic education level, the use of ChatGPT is still an ongoing discussion, particularly on how to regulate its use. This study endeavors to describe the perspectives of teachers and students about ChatGPT in terms of their knowledge, attitudes, and practices to better appreciate its role in advancing teaching and learning. This descriptive survey involved a total of (N=187) respondents, including students from Grade 6 (n=70), Grade 10 (n=38), and Grade 12 (n=18) and teachers (n=61). The newly developed 39-item Knowledge, Attitudes, Practices on ChatGPT Questionnaire (KAP-CQ39) with a Cronbach α = 0.91 was used as the primary instrument in understanding and leveraging the academic potential of this AI system. Open-ended questions on the advantages and disadvantages of using ChatGPT are also included in the questionnaire. KAP-CQ39 was administered online using Google Forms. Data culled from the survey was analyzed using an online open-source program referred to as Jeffreys's Amazing Statistics Program (JASP). Results revealed no significant difference in perspectives between teachers (mean=11.88) and students (mean=11.46) knowledge on ChatGPT F (2,169) =2.66, p=0.104. Similarly, attitudes towards the educational use of ChatGPT showed that both teachers and students hold positive attitudes. Demographic factors contributing to the differences in teachers’ perspectives on the educational use of ChatGPT were sex, years of teaching experience, and specialization. For the students, the demographic factors did not contribute to the differences in their perspectives. Generally, in terms of practices, responses provided valuable insights into how ChatGPT can be better designed and implemented for teaching and learning. Thus, policy implications were drawn relative to the efficient use of ChatGPT.},
booktitle = {Proceedings of the 2024 15th International Conference on E-Education, E-Business, E-Management and E-Learning},
pages = {107–116},
numpages = {10},
location = {Fukuoka-shi, Japan},
series = {IC4E '24}
}

@inproceedings{10.1145/3698322.3698346,
author = {Holtel, Stefan},
title = {Phrasebooks Can Teach Us ChatGPT: Decoding Prompt Crafting as Function Allocation},
year = {2024},
isbn = {9798400716836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698322.3698346},
doi = {10.1145/3698322.3698346},
abstract = {The discipline of Prompt Engineering is rapidly evolving, with varied and often conflicting approaches to crafting effective prompts for Large Language Models like ChatGPT. This divergence has led to a significant underutilization of AI technologies by individuals and organizations, largely due to a fundamental misconception about the nature of prompt writing. This paper advocates for a paradigm shift from a command-based to a language-centric approach, integrating concepts from metacognition and knowledge management. It introduces the novel metaphor of ‘Prompting Phrasebooks,’ akin to traveler phrasebooks, as a structured method to facilitate rich, interactive dialogues with AI systems. By drawing on a culturally ingrained analogy, the Prompting Phrasebook offers a practical framework for users with no or little expertise in prompt crafting to effectively engage with AI-driven chatbots. This concept is further operationalized through the creation of so-called ‘Prompt Pattern Languages,’ each representing a curated set of prompts designed to achieve a specific cognitive tasks The paper presents the theoretical foundation of this approach and demonstrates its application through a Prompt Pattern Language for AI-assisted email composition, offering an unprecedented direction for teaching and mastering Prompt Engineering.},
booktitle = {Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices},
articleno = {29},
numpages = {9},
keywords = {Large Language Models, Prompt Engineering, Prompt Pattern},
location = {
},
series = {EuroPLoP '24}
}

@article{10.1145/3676507,
author = {Constantinides, Marios and Bogucka, Edyta Paulina and Scepanovic, Sanja and Quercia, Daniele},
title = {Good Intentions, Risky Inventions: A Method for Assessing the Risks and Benefits of AI in Mobile and Wearable Uses},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676507},
doi = {10.1145/3676507},
abstract = {Integrating Artificial Intelligence (AI) into mobile and wearables offers numerous benefits at individual, societal, and environmental levels. Yet, it also spotlights concerns over emerging risks. Traditional assessments of risks and benefits have been sporadic, and often require costly expert analysis. We developed a semi-automatic method that leverages Large Language Models (LLMs) to identify AI uses in mobile and wearables, classify their risks based on the EU AI Act, and determine their benefits that align with globally recognized long-term sustainable development goals; a manual validation of our method by two experts in mobile and wearable technologies, a legal and compliance expert, and a cohort of nine individuals with legal backgrounds who were recruited from Prolific, confirmed its accuracy to be over 85%. We uncovered that specific applications of mobile computing hold significant potential in improving well-being, safety, and social equality. However, these promising uses are linked to risks involving sensitive data, vulnerable groups, and automated decision-making. To avoid rejecting these risky yet impactful mobile and wearable uses, we propose a risk assessment checklist for the Mobile HCI community.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {262},
numpages = {28},
keywords = {LLM, mobile, prompt engineering, risk assessment, sustainable development goals, wearables}
}

@inproceedings{10.1145/3581784.3613215,
author = {Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun},
title = {FORGE: Pre-Training Open Foundation Models for Science},
year = {2023},
isbn = {9798400701092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581784.3613215},
doi = {10.1145/3581784.3613215},
abstract = {Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
articleno = {81},
numpages = {13},
location = {Denver, CO, USA},
series = {SC '23}
}

@inproceedings{10.1145/3613905.3650868,
author = {Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan},
title = {Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650868},
doi = {10.1145/3613905.3650868},
abstract = {In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {9},
keywords = {AI facilitator, Collaborative Learning, Human-AI Collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3639475.3640112,
author = {Sovrano, Francesco and Lognoul, Micha\"{e}l and Bacchelli, Alberto},
title = {An Empirical Study on Compliance with Ranking Transparency in the Software Documentation of EU Online Platforms},
year = {2024},
isbn = {9798400704994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639475.3640112},
doi = {10.1145/3639475.3640112},
abstract = {Compliance with the European Union's Platform-to-Business (P2B) Regulation helps fostering a fair, ethical and secure online environment. However, it is challenging for online platforms, and assessing their compliance can be difficult for public authorities. This is partly due to the lack of automated tools for assessing the information (e.g., software documentation) platforms provide concerning ranking transparency. Our study tackles this issue in two ways. First, we empirically evaluate the compliance of six major platforms (Amazon, Bing, Booking, Google, Tripadvisor, and Yahoo), revealing substantial differences in their documentation. Second, we introduce and test automated compliance assessment tools based on ChatGPT and information retrieval technology. These tools are evaluated against human judgments, showing promising results as reliable proxies for compliance assessments. Our findings could help enhance regulatory compliance and align with the United Nations Sustainable Development Goal 10.3, which seeks to reduce inequality, including business disparities, on these platforms.Data and materials: https://doi.org/10.5281/zenodo.10478546.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Society},
pages = {46–56},
numpages = {11},
keywords = {software documentation, EU regulations, compliance assessment, ranking transparency, explainability, online platforms},
location = {Lisbon, Portugal},
series = {ICSE-SEIS'24}
}

@inproceedings{10.1145/3656650.3656688,
author = {Grigis, Paolo and De Angeli, Antonella},
title = {Playwriting with Large Language Models: Perceived Features, Interaction Strategies and Outcomes},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656688},
doi = {10.1145/3656650.3656688},
abstract = {Large Language Models (LLMs) are sparking debates about creativity, intellectual property, and artistic integrity. This paper focuses on creativity, defined as consensual agreement among domain experts. It presents an inductive analysis of seven semi-structured interviews with professional playwrights who engaged in a longitudinal project with the aim of writing a theatre script using commercial systems. Overall, participants regarded LLMs as unsuitable for playwrighting. However, they enjoyed the experience and identified utility for editorial tasks and brainstorming. A significant obstacle was associated with the politics embedded in LLMs. Not only did these systems avoid a language that could offend sensibilities, but they also refused to engage in taboos and conflicts, which are the core of dramaturgy. Other system features (speed, exploitation, and unpredictability) were sometimes considered conducive and sometimes detrimental to creativity. Participants experienced difficulties and tried to build common ground by trial and error. Often, this strategy evolved into role play: the playwright instructed the LLM to enact characters. The interaction provided hints of inspiration and fostered suspension of disbelief and ontological reflection. However, it often led to technology rejection. Comparing and contrasting our insights with related work, we conclude by opening new directions for research at the boundaries of HCI and AI.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {38},
numpages = {9},
keywords = {Creative AI, Creativity, Roleplay, Suspension of Disbelief, Theatre, Unpredictability},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@inproceedings{10.1109/ASE56229.2023.00153,
author = {Li, Zhuo and Wu, Xiongfei and Zhu, Derui and Cheng, Mingfei and Chen, Siyuan and Zhang, Fuyuan and Xie, Xiaofei and Ma, Lei and Zhao, Jianjun},
title = {Generative Model-Based Testing on Decision-Making Policies},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00153},
doi = {10.1109/ASE56229.2023.00153},
abstract = {The reliability of decision-making policies is urgently important today as they have established the fundamentals of many critical applications, such as autonomous driving and robotics. To ensure reliability, there have been a number of research efforts on testing decision-making policies that solve Markov decision processes (MDPs). However, due to the deep neural network (DNN)-based inherit and infinite state space, developing scalable and effective testing frameworks for decision-making policies still remains open and challenging.In this paper, we present an effective testing framework for decision-making policies. The framework adopts a generative diffusion model-based test case generator that can easily adapt to different search spaces, ensuring the practicality and validity of test cases. Then, we propose a termination state novelty-based guidance to diversify agent behaviors and improve the test effectiveness. Finally, we evaluate the framework on five widely used benchmarks, including autonomous driving, aircraft collision avoidance, and gaming scenarios. The results demonstrate that our approach identifies more diverse and influential failure-triggering test cases compared to current state-of-the-art techniques. Moreover, we employ the detected failure cases to repair the evaluated models, achieving better robustness enhancement compared to the baseline method.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {243–254},
numpages = {12},
keywords = {generative model, testing, decision-making policies},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3689484.3690738,
author = {Greiner, Sandra and B\"{u}hlmann, Noah and Ohrndorf, Manuel and Tsigkanos, Christos and Nierstrasz, Oscar and Kehrer, Timo},
title = {Automated Generation of Code Contracts: Generative AI to the Rescue?},
year = {2024},
isbn = {9798400712111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689484.3690738},
doi = {10.1145/3689484.3690738},
abstract = {Design by Contract represents an established, lightweight paradigm for engineering reliable and robust software systems by specifying verifiable expectations and obligations between software components. Due to its laborious nature, developers hardly adopt Design by Contract in practice.
 
 
 
A plethora of research on (semi-)-automated inference to reduce the manual burden has not improved the adoption of so-called code contracts in practice.
 
 
 
This paper examines the potential of Generative AI to automatically generate code contracts in terms of pre- and postconditions for any Java project without requiring any additional auxiliary artifact.
 
 
 
To fine-tune two state-of-the-art Large Language Models, CodeT5 and CodeT5+, we derive a dataset of more than 14k Java methods comprising contracts in form of Java Modeling Language (JML) annotations, and train the models on the task of generating contracts.
 
 
 
We examine the syntactic and semantic validity of the contracts generated for software projects not used in the fine-tuning and find that more than 95% of the generated contracts are syntactically correct and exhibit remarkably high completeness and semantic correctness.
 
 
 
To this end, our fully automated method sets the stage for future research and eventual broader adoption of Design by Contract in software development practice.},
booktitle = {Proceedings of the 23rd ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences},
pages = {1–14},
numpages = {14},
keywords = {Design by Contract, Generative AI, Large Language Models, Software Verification},
location = {Pasadena, CA, USA},
series = {GPCE '24}
}

@inproceedings{10.1145/3652037.3663942,
author = {Joaa, AFM Mohimenul and Majumder, Prattoy and Sadeque, Farig},
title = {Curious Learner: A Neuro-Symbolic Approach for Function Execution via Natural Language},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3663942},
doi = {10.1145/3652037.3663942},
abstract = {Generative models possess immense potential, but their ability to perform complex calculations is limited by the need to memorize vast amounts of data, leading to computational inefficiencies. Leveraging tools like the Arithmetic Logic Unit using symbolic functions offers a more efficient alternative, enabling faster responses, smaller model sizes, and improved accuracy. We propose a neuro-symbolic generative model to empower natural language models with task execution abilities by integrating functional programming principles. Experiments on our scoped four translation tasks using 98 mathematical functions demonstrated rapid convergence and minimal training time requirements. The model achieved an average accuracy, BLEU score, and perplexity score of 0.85, 0.84, and 5.9, respectively, after training on a T4 GPU for several hours. This neuro-symbolic Language Model shows significant potential for various applications, such as NLP-based command line tools, customer service automation, service discovery automation, project code automation, and natural language-based operating systems.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {392–399},
numpages = {8},
keywords = {Curious Learner, Customer Service Automation, Foundational Model, Generative Model, Large Language Model Architecture, Natural Language Processing, Neuro-Symbolic Programming, Service Discovery Automation, Task Executor, Transformer},
location = {Crete, Greece},
series = {PETRA '24}
}

@article{10.1145/3640332,
author = {Clun, Donato and Shin, Donghwan and Filieri, Antonio and Bianculli, Domenico},
title = {Rigorous Assessment of Model Inference Accuracy using Language Cardinality},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3640332},
doi = {10.1145/3640332},
abstract = {Models such as finite state automata are widely used to abstract the behavior of software systems by capturing the sequences of events observable during their execution. Nevertheless, models rarely exist in practice and, when they do, get easily outdated; moreover, manually building and maintaining models is costly and error-prone. As a result, a variety of model inference methods that automatically construct models from execution traces have been proposed to address these issues.However, performing a systematic and reliable accuracy assessment of inferred models remains an open problem. Even when a reference model is given, most existing model accuracy assessment methods may return misleading and biased results. This is mainly due to their reliance on statistical estimators over a finite number of randomly generated traces, introducing avoidable uncertainty about the estimation and being sensitive to the parameters of the random trace generative process.This article addresses this problem by developing a systematic approach based on analytic combinatorics that minimizes bias and uncertainty in model accuracy assessment by replacing statistical estimation with deterministic accuracy measures. We experimentally demonstrate the consistency and applicability of our approach by assessing the accuracy of models inferred by state-of-the-art inference tools against reference models from established specification mining benchmarks.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {95},
numpages = {39},
keywords = {Model inference, specification mining, process mining, model assessment, formal specifications, machine learning, software engineering, behavioral comparison, conformance checking, precision, recall}
}

@article{10.1145/3641289,
author = {Chang, Yupeng and Wang, Xu and Wang, Jindong and Wu, Yuan and Yang, Linyi and Zhu, Kaijie and Chen, Hao and Yi, Xiaoyuan and Wang, Cunxiang and Wang, Yidong and Ye, Wei and Zhang, Yue and Chang, Yi and Yu, Philip S. and Yang, Qiang and Xie, Xing},
title = {A Survey on Evaluation of Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3641289},
doi = {10.1145/3641289},
abstract = {Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, education, natural and social sciences, agent applications, and other areas. Secondly, we answer the ‘where’ and ‘how’ questions by diving into the evaluation methods and benchmarks, which serve as crucial components in assessing the performance of LLMs. Then, we summarize the success and failure cases of LLMs in different tasks. Finally, we shed light on several future challenges that lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to researchers in the realm of LLMs evaluation, thereby aiding the development of more proficient LLMs. Our key point is that evaluation should be treated as an essential discipline to better assist the development of LLMs. We consistently maintain the related open-source materials at:},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
articleno = {39},
numpages = {45},
keywords = {Large language models, evaluation, model assessment, benchmark}
}

@inproceedings{10.1145/3644815.3644987,
author = {Olson, Lauren},
title = {Custom Developer GPT for Ethical AI Solutions},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644987},
doi = {10.1145/3644815.3644987},
abstract = {The main goal of this project is to create a new software artefact: a custom Generative Pre-trained Transformer (GPT) for developers to discuss and solve ethical issues through AI engineering. This conversational agent will provide developers with practical application on (1) how to comply with legal frameworks which regard AI systems (like the EU AI Act [8] and GDPR [11]) and (2) present alternate ethical perspectives to allow developers to understand and incorporate alternate moral positions. In this paper, we provide motivation for the need of such an agent, detail our idea and demonstrate a use case. The use of such a tool can allow practitioners to engineer AI solutions which meet legal requirements and satisfy diverse ethical perspectives.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {282–283},
numpages = {2},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3583131.3590512,
author = {Zheng, Bowen and Cheng, Ran},
title = {Rethinking Population-assisted Off-policy Reinforcement Learning},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590512},
doi = {10.1145/3583131.3590512},
abstract = {While off-policy reinforcement learning (RL) algorithms are sample efficient due to gradient-based updates and data reuse in the replay buffer, they struggle with convergence to local optima due to limited exploration. On the other hand, population-based algorithms offer a natural exploration strategy, but their heuristic black-box operators are inefficient. Recent algorithms have integrated these two methods, connecting them through a shared replay buffer. However, the effect of using diverse data from population optimization iterations on off-policy RL algorithms has not been thoroughly investigated. In this paper, we first analyze the use of off-policy RL algorithms in combination with population-based algorithms, showing that the use of population data could introduce an overlooked error and harm performance. To test this, we propose a uniform and scalable training design and conduct experiments on our tailored framework in robot locomotion tasks from the OpenAI gym. Our results substantiate that using population data in off-policy RL can cause instability during training and even degrade performance. To remedy this issue, we further propose a double replay buffer design that provides more on-policy data and show its effectiveness through experiments. Our results offer practical insights for training these hybrid methods.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {624–632},
numpages = {9},
keywords = {evolutionary reinforcement learning, neuroevolution, off-policy learning},
location = {Lisbon, Portugal},
series = {GECCO '23}
}

@inproceedings{10.1145/3673971.3674024,
author = {Chen, Yi-Xiang and Shih, Guan-Yu and Ting, Hsien-Wei and Chien, Ting-Ying},
title = {Base on GAN Combined with CNN Architecture to Generate Brain Stroke CT Images},
year = {2024},
isbn = {9798400716874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673971.3674024},
doi = {10.1145/3673971.3674024},
abstract = {In recent years, many fields have expanded their research methods through the integration of artificial intelligence. In the current medical field, it is widely used in image recognition to diagnose patient symptoms, train clinical prediction models, and improve clinical workflow processes to avoid missing treatment opportunities. These methods have all achieved good results so far. Now, generative AI is also impacting the development of the medical field, not only generating prescriptions that match patient conditions but also being applied in generating medical images for data augmentation and simulating various pathological conditions, thereby aiding in training deep learning models. Stroke is a leading cause of death or disability, ranking as the second leading cause of death worldwide, next to cancer. If cancers were categorized individually, stroke would surpass all single diseases, making it a primary focus of research in brain disease treatment. There are already studies where generative AI has been used to create medical images, which are then manually evaluated by doctors to determine if they were generated by AI. In this project, we plan to generate CT images of strokes using generative AI and use a trained model (to diagnose stroke) to improve accuracy. Through this project, we hope to solve the problem of scarce stroke CT images while also providing support for training stroke-related models.},
booktitle = {Proceedings of the 2024 8th International Conference on Medical and Health Informatics},
pages = {47–51},
numpages = {5},
keywords = {GAN, Generative artificial intelligence, Medical imaging, Stroke},
location = {Yokohama, Japan},
series = {ICMHI '24}
}

@inproceedings{10.1145/3584931.3607494,
author = {Richards Maldonado, Liam and Abouzied, Azza and Gleason, Nancy W.},
title = {ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning Questions to Facilitate Deeper Understanding},
year = {2023},
isbn = {9798400701290},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584931.3607494},
doi = {10.1145/3584931.3607494},
abstract = {Academic reading is a key component of higher education, and serves as a basis for critical thinking, knowledge acquisition and effective communication. Research shows many students struggle with comprehension and analysis tasks with academic texts, despite the central importance of academic reading to success in higher education. Undergraduates and researchers need to internalize dense literature to scaffold their own work upon it. This reading task is time-consuming and difficult to do. Oftentimes, students struggle to actively and critically engage and as a result attain merely a cursory understanding of a paper’s contents, or worse, incorrectly interpret the text. How, then, can we provide a means to more easily digest a text while also facilitating meaningful, critical engagement and understanding? This paper locates itself within the broader field of augmented reading interfaces to implement an augmented reading interface that leverages the power of large language models (LLM) to intelligently generate and co-locate comprehension and analysis questions in an academic paper, thereby making the paper more digestible with the end goal of facilitating deeper understanding, and developing critical reading skills.},
booktitle = {Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing},
pages = {391–394},
numpages = {4},
keywords = {academic papers, augmented reading interfaces, reading comprehension},
location = {Minneapolis, MN, USA},
series = {CSCW '23 Companion}
}

@inproceedings{10.1109/ICSE-Companion58688.2023.00087,
author = {Kang, Sungmin and Yoo, Shin},
title = {GLAD: Neural Predicate Synthesis to Repair Omission Faults},
year = {2023},
isbn = {9798350322637},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-Companion58688.2023.00087},
doi = {10.1109/ICSE-Companion58688.2023.00087},
abstract = {Existing template and learning-based Automated Program Repair (APR) tools have successfully found patches for many benchmark faults. However, our analysis of existing results shows that omission faults pose a significant challenge. For template based approaches, omission faults provide no location to apply templates to; for learning based approaches that formulate repair as Neural Machine Translation (NMT), omission faults similarly do not provide faulty code to translate. To address these issues, we propose GLAD, a novel learning-based repair technique that targets if-clause synthesis. GLAD does not require a concrete faulty line as it is based on generative Language Models (LMs) instead of machine translation; consequently, it can repair omission faults. To provide the LM with project-specific information critical to synthesis, we incorporate two components: a type-based grammar that constrains the model, and a dynamic ranking system that evaluates candidate patches using a debugger. Our evaluation shows GLAD is highly orthogonal to existing techniques, correctly fixing 26 Defects4J v1.2 faults that previous NMT-based techniques could not, while maintaining a small runtime cost, underscoring its potential as a lightweight tool to complement existing tools in practice. An inspection of the bugs that GLAD fixes reveals that GLAD can quickly generate expressions that would be challenging for other techniques.},
booktitle = {Proceedings of the 45th International Conference on Software Engineering: Companion Proceedings},
pages = {320–321},
numpages = {2},
keywords = {program repair, machine learning, debugging},
location = {Melbourne, Victoria, Australia},
series = {ICSE '23}
}

@inproceedings{10.1145/3695080.3695150,
author = {Zhang, Huichen},
title = {ChatGPT intervenes in the application analysis of higher education classrooms},
year = {2024},
isbn = {9798400710223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695080.3695150},
doi = {10.1145/3695080.3695150},
abstract = {As the frontier of a new round of technological revolution, ChatGPT is playing an active role in creating intelligent teaching classrooms, improving students' self-directed learning ability, and reshaping the evaluation of classroom teaching in higher education. However, in the process of ChatGPT's intervention in higher education classrooms, there are many shortcomings, such as the difficulty in distinguishing between true and false answers, weakening students' ability to think independently, and diluting the relationship between teachers and students. Therefore, it is suggested to start with strategies such as promoting the change of teachers' teaching concepts, improving students' critical awareness, and strengthening the supervision of school rules, so as to provide a useful reference for ChatGPT to properly intervene in higher education classrooms in the future.},
booktitle = {Proceedings of the 2024 International Conference on Cloud Computing and Big Data},
pages = {409–413},
numpages = {5},
location = {Dali, China},
series = {ICCBD '24}
}

@article{10.1145/3689215,
author = {Zlotnikova, Irina and Hlomani, Hlomani},
title = {GenAI in the Context of African Universities: A Crisis of Tertiary Education or Its New Dawn?},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689215},
doi = {10.1145/3689215},
abstract = {The rapid progression of generative artificial intelligence (GenAI) tools has raised significant interest and concern in academia. Instances of students submitting AI-generated assignments prompt investigations into implications for teaching, learning, and academic integrity. Recent publications highlight concerns such as a lack of conceptual understanding, threats to academic integrity, and disruptions to traditional assessment methods. While recognizing benefits like automated scoring and personalized learning, authors stress the responsible use of GenAI, emphasizing the educator's role in guiding students. This commentary identifies opportunities and threats of GenAI in African university contexts. Opportunities include increased operational efficiency, content generation, automated assessment, recognition of accessibility needs, overcoming language barriers, and accelerated research. However, these tools require human correction and cautious consideration of job displacement concerns. Threats encompass job displacement, privacy and security issues, threats to academic integrity, hallucinations/confabulations of GenAI, access and infrastructure challenges, technological overemphasis, lack of customization for local needs and cultural contexts, dependency on external providers, and unaffordable costs. The need for robust guidelines that balance technological advances with traditional teaching methods in African universities is emphasized. Given digital transformation initiatives like the African Union's Agenda 2063 and Botswana's SmartBots strategy, integrating GenAI could shape the future of African tertiary education. Proactive policies should address ethical concerns, ensure access, and make GenAI tools available, requiring a collaborative effort to navigate its impact responsibly.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = aug,
keywords = {Generative artificial intelligence, universities, African countries}
}

@article{10.1145/3649884,
author = {Ren, Yuqing and Clement, Jeffrey},
title = {Augmenting Human Teams with Robots in Knowledge Work Settings: Insights from the Literature},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
url = {https://doi.org/10.1145/3649884},
doi = {10.1145/3649884},
abstract = {Recent developments in large language models open doors for Artificial Intelligence and robots to augment knowledge workers and teams in a variety of domains, such as customer service, data science, legal work, and software development. In this article, we review 317 articles from multiple disciplines and summarize the insights in a theoretical framework linking key robot attributes to human perceptions and behaviors. The robot attributes include embodiment, nonverbal and verbal communication, perceived gender and race, emotions, perceived personality, and competence. The outcomes include human perceptions, acceptance, engagement, compliance, trust, and willingness to help. We identify four differences between one human and one robot settings and team settings and use them as the springboard to generalize insights from the literature review to the design and impact of a robot in assisting humans in knowledge work teams. We report two high-level observations around the interplay among robot attributes and context dependent designs and discuss their implications.},
journal = {J. Hum.-Robot Interact.},
month = jun,
articleno = {20},
numpages = {34},
keywords = {Human-robot interaction, Generative AI, robot design, human robot team}
}

@inproceedings{10.1145/3664934.3664946,
author = {Xiao, Qimin},
title = {ChatGPT as an Artificial Intelligence (AI) Writing Assistant for EFL Learners: An Exploratory Study of its Effects on English writing Proficiency},
year = {2024},
isbn = {9798400716409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664934.3664946},
doi = {10.1145/3664934.3664946},
abstract = {ChatGPT, a revolutionary Artificial Intelligence (AI) tool, has taken the world by storm after its release by OpenAI in 2022. Many researchers have attempted to explore what role ChatGPT can play as an AI assistant in teaching and to what extent ChatGPT can be utilized for English as a foreign language (EFL) learners. The present study made exploratory efforts in shedding lights on the effect of applying ChatGPT as an AI Writing Assistant in English writing classroom for EFL learners. The research was conducted with 51 EFL learners divided into a control group (n=25) and an experimental group (n=26). The control group was given traditional in-class instruction and after-class activities, while the experimental group was encouraged to use ChatGPT during pre-writing stage and after-writing stage for content planning, personized interaction and tailored feedback. To avoid misuse of this AI tool, students are encouraged to do the drafting on their own. During the experiment (a duration of 10 weeks), writing tasks were employed to collect available data. It was found that the experimental group exhibited better writing proficiency in terms of content, structure and language use, compared with that of the control group. Overall, this research highlights the potentiality of ChatGPT as a valuable AI tool for EFL learners to improve English writing proficiency.},
booktitle = {Proceedings of the 2024 9th International Conference on Information and Education Innovations},
pages = {51–56},
numpages = {6},
keywords = {Artificial Intelligence (AI) Writing Assistant, ChatGPT integration, EFL learners, Writing proficiency},
location = {Verbania, Italy},
series = {ICIEI '24}
}

@inproceedings{10.1145/3511808.3557079,
author = {Biderman, Stella and Raff, Edward},
title = {Fooling MOSS Detection with Pretrained Language Models},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557079},
doi = {10.1145/3511808.3557079},
abstract = {As artificial intelligence (AI) technologies become increasingly powerful and prominent in society, their misuse is a growing concern. In educational settings, AI technologies could be used by students to cheat on assignments and exams. In this paper we explore whether transformers can be used to solve introductory level programming assignments while bypassing commonly used AI tools to detect similarities between pieces of software. We find that a student using GPT-J [60] can complete introductory level programming assignments without triggering suspicion from MOSS [2], a widely used software similarity and plagiarism detection tool. This holds despite the fact that GPT-J was not trained on the problems in question and is not provided with any examples to work from. We further find that the code written by GPT-J is diverse in structure, lacking any particular tells that future plagiarism detection techniques may use to try to identify algorithmically generated code. We conclude with a discussion of the ethical and educational implications of large language models and directions for future research.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {2933–2943},
numpages = {11},
keywords = {education technology, language models, multimodal transformers, open source software},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3636555.3636912,
author = {Snyder, Caitlin and Hutchins, Nicole M and Cohn, Clayton and Fonteles, Joyce Horn and Biswas, Gautam},
title = {Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636912},
doi = {10.1145/3636555.3636912},
abstract = {This study introduces a methodology to investigate students’ collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework—specifically, Planning, Enacting, and Reflection—proposed in the literature, applying it to examine students’ collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students’ model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {540–550},
numpages = {11},
keywords = {SRL, STEM, collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1145/3696419,
author = {Wang, Jian and Zhao, Delei and Zhao, Guosheng},
title = {Malicious Participants and Fake Task Detection Incorporating Gaussian Bias},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3696419},
doi = {10.1145/3696419},
abstract = {Mobile crowdsensing (MCS) is a combination of crowdsourcing ideas and mobile sensing devices, designed to enable rational allocation of resources at scale. However, the MCS platform is highly vulnerable to injection attacks from malicious participants and fake tasks that interfere with platform service capabilities and sensing activities. To this end, the participant and task submission process is modeled as a multivariate time series, and a detection model for malicious participants and fake tasks (MP-FTD) with a Gaussian prior on the attentional mechanism and a two-stage adversarial training process is proposed. The attention mechanism was corrected using Gaussian bias, and then the corrected attention mechanism was used to obtain the correlation discrepancies between the data. Using the adversarial training method of Generative Adversarial Networks (GAN), the output of the correlation discrepancy reconstruction phase is transformed into a focus score, to amplify the reconstruction error in the output of the focus score reconstruction phase, and to improve the differentiation between the injected data and normal data of malicious attackers. The detection of these malicious attackers will effectively improve the robustness of the sensing platform. Experiments on six real-world datasets showed that the average F1-score reached 93.44%, outperforming the current baseline method, and resulting in an average 12.07% improvement in participant assignment accuracy and an average 12.25% improvement in task assignment accuracy in task assignment experiments.},
journal = {ACM Trans. Internet Technol.},
month = oct,
articleno = {19},
numpages = {19},
keywords = {Mobile Crowdsensing, Outlier Detection, Malicious Participants, Fake Task}
}

@article{10.1145/3699761,
author = {Nepal, Subigya and Pillai, Arvind and Campbell, William and Massachi, Talie and Heinz, Michael V. and Kunwar, Ashmita and Choi, Eunsol Soul and Xu, Xuhai and Kuc, Joanna and Huckins, Jeremy F. and Holden, Jason and Preum, Sarah M. and Depp, Colin and Jacobson, Nicholas and Czerwinski, Mary P. and Granholm, Eric and Campbell, Andrew T.},
title = {MindScape Study: Integrating LLM and Behavioral Sensing for Personalized AI-Driven Journaling Experiences},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699761},
doi = {10.1145/3699761},
abstract = {Mental health concerns are prevalent among college students, highlighting the need for effective interventions that promote self-awareness and holistic well-being. MindScape explores a novel approach to AI-powered journaling by integrating passively collected behavioral patterns such as conversational engagement, sleep, and location with Large Language Models (LLMs). This integration creates a highly personalized and context-aware journaling experience, enhancing self-awareness and well-being by embedding behavioral intelligence into AI. We present an 8-week exploratory study with 20 college students, demonstrating the MindScape app's efficacy in enhancing positive affect (7%), reducing negative affect (11%), loneliness (6%), and anxiety and depression, with a significant week-over-week decrease in PHQ-4 scores (-0.25 coefficient). The study highlights the advantages of contextual AI journaling, with participants particularly appreciating the tailored prompts and insights provided by the MindScape app. Our analysis also includes a comparison of responses to AI-driven contextual versus generic prompts, participant feedback insights, and proposed strategies for leveraging contextual AI journaling to improve well-being on college campuses. By showcasing the potential of contextual AI journaling to support mental health, we provide a foundation for further investigation into the effects of contextual AI journaling on mental health and well-being.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {186},
numpages = {44},
keywords = {AI, Behavioral Sensing, Journaling, Large Language Models, Mental Health, Passive Sensing, Self-reflection, Smartphones, Well-being}
}

@article{10.5555/3717781.3717801,
author = {Crews, Thad and Erickson, John and Wu, Tong},
title = {Exploring Faculty and Student Perspectives on GenAI in Higher Education},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {This study explores the growing impact of GenAI tools in higher education. The study involves a repeated cross-sectional survey of faculty and students to identify valuable insights into evolving patterns and preferences regarding the impact of ChatGPT and other AI tools in higher education. Results are reported with insights for faculty and policy makers.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {159–170},
numpages = {12}
}

@article{10.1109/TASLP.2023.3317571,
author = {Chuang, Yun-Yen and Hsu, Hung-Min and Lin, Kevin and Chang, Ray-I. and Lee, Hung-Yi},
title = {MetaEx-GAN: Meta Exploration to Improve Natural Language Generation via Generative Adversarial Networks},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3317571},
doi = {10.1109/TASLP.2023.3317571},
abstract = {Generative Adversarial Networks (GANs) have been popularly researched in natural language generation, so-called Language GANs. Existing works adopt reinforcement learning (RL) based methods such as policy gradients for training Language GANs. The previous research of Language GANs usually focuses on stabilizing policy gradients or applying robust architectures (such as the large-scale pre-trained GPT-2) to achieve better performance. However, the quality and diversity of sampling are not guaranteed simultaneously. In this article, we propose a novel meta-learning-based generative adversarial network, Meta Exploration GAN (MetaEx-GAN), for ensuring the quality and diversity of sampling (sampling efficiency). In the proposed MetaEx-GAN, we develop an explorer trained by Meta Exploration to sample from the generated data to achieve better sampling efficiency. MetaEx-GAN employs MetaEx first applied to Language GANs to achieve better performance. We also propose a critical training method for MetaEx-GAN on the NLG task. According to our experimental results, MetaEx-GAN achieves state-of-the-art performance compared with existing Language GANs methods. Our experiments also demonstrate the generality of MetaEx-GAN with different architectures (involving GPT-2) and how MetaEx-GAN operates to improve Language GANs.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = sep,
pages = {3968–3980},
numpages = {13}
}

@inproceedings{10.1145/3555776.3577652,
author = {Jamil, Hasan M and Naha, Kallol},
title = {Mapping Strategies for Declarative Queries over Online Heterogeneous Biological Databases for Intelligent Responses},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3577652},
doi = {10.1145/3555776.3577652},
abstract = {The emergence of Alexa and Siri, and more recently, OpenAI's Chat-GPT, raises the question whether ad hoc biological queries can also be computed without end-users' active involvement in the code writing process. While advances have been made, current querying architectures for biological databases still assume some degree of computational competence and significant structural awareness of the underlying network of databases by biologists, if not active code writing. Given that biological databases are highly distributed and heterogeneous, and most are not FAIR compliant, a significant amount of expertise in data integration is essential for a query to be accurately crafted and meaningfully executed. In this paper, we introduce a flexible and intelligent query reformulation assistant, called Needle, as a back-end query execution engine of a natural language query interface to online biological databases. Needle leverages a data model called BioStar that leverages a meta-knowledgebase, called the schema graph, to map natural language queries to relevant databases and biological concepts. The implementation of Needle using BioStar is the focus of this article.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {567–574},
numpages = {8},
keywords = {schema graph, biological databases, data integration, ad hoc querying, schema abstraction, query reformulation},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3584371.3612953,
author = {Quintana, Felix and Treangen, Todd and Kavraki, Lydia},
title = {Leveraging Large Language Models for Predicting Microbial Virulence from Protein Structure and Sequence},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3612953},
doi = {10.1145/3584371.3612953},
abstract = {In the aftermath of COVID-19, screening for pathogens has never been a more relevant problem. However, computational screening for pathogens is challenging due to a variety of factors, including (i) the complexity and role of the host, (ii) virulence factor divergence and dynamics, and (iii) population and community-level dynamics. Considering a potential pathogen's molecular interactions, specifically individual proteins and protein interactions can help pinpoint a potential protein of a given microbe to cause disease. However, existing tools for pathogen screening rely on existing annotations (KEGG, GO, etc), making the assessment of novel and unannotated proteins more challenging. Here, we present an LLM-inspired approach that considers protein sequence and structure to predict protein virulence. We present a two-stage model incorporating evolutionary features captured from the DistilProtBert language model and protein structure in a graph convolutional network. Our model performs better than sequence alone for virulence function when high-quality structures are present, thus representing a path forward for virulence prediction of novel and unannotated proteins.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {103},
numpages = {6},
keywords = {protein function, virulence prediction, graph-based models, large language models},
location = {Houston, TX, USA},
series = {BCB '23}
}

@article{10.1145/3703459,
author = {Billiris, Grace and Gill, Asif and Oppermann, Ian and Niazi, Mahmood},
title = {Towards the Development of a Copyright Risk Checker Tool for Generative Artificial Intelligence Systems},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
url = {https://doi.org/10.1145/3703459},
doi = {10.1145/3703459},
abstract = {Generative Artificial Intelligence (GAI) is fundamentally changing the ways of working and blurring the boundaries between human and machine-generated contents. While there is an increasing interest in the adoption of GAI systems, such as ChatGPT and DALL-E, there are also serious concerns about the copyright of the contents—the inputs or generated as outputs by the GAI systems. Such concerns need to be identified and assessed to ensure the ethical and responsible use of GAI systems. Thus, this article aims to address the key research challenge: “how to identify and assess GAI system's copyright concerns”? In response, we propose the development of a Copyright Risk Checker (CRC) Tool. This tool has been formulated and evaluated using a recognised design science research methodology, drawing on an analysis of 10 legal cases across Australia, the United Kingdom, the United States, and Europe. The CRC Tool has undergone evaluation through an experimental scenario, and the results suggest that it is suitable for conducting an indicative copyright risk check of GAI systems. The outcomes of this preliminary assessment can be further examined by expert legal advisors for an in-depth analysis. The development of the CRC Tool provides a foundation for continued research and advancement in this significant area of study.},
journal = {Digit. Gov.: Res. Pract.},
month = dec,
articleno = {41},
numpages = {21},
keywords = {Generative Artificial Intelligence, Copyright Concern, GAI Governance, Copyright Regulations, Independent Intellectual Effort, Authorship}
}

@inproceedings{10.1145/3638584.3638634,
author = {Nguyen, Quangphuoc and Nguyen, Ngocminh and Dang, Thanhluan and Tran, Vanha},
title = {Vietnamese Voice2Text: A Web Application for Whisper Implementation in Vietnamese Automatic Speech Recognition Tasks: Vietnamese Voice2Text},
year = {2024},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638584.3638634},
doi = {10.1145/3638584.3638634},
abstract = {The publication of the Whisper model by OpenAI inspired us with the idea of a web platform that provides voice-to-text conversion services for Vietnamese people. Using Whisper’s powerful generalization capabilities, we have developed a web application with three main features: record-to-text, file-to-text, and subtitles generator for YouTube. We first fine-tuned Whisper with our target language dataset then deployed the model as a Rest API using the Python Flask framework with three paths for three different tasks. The web application has been developed using ReactJS, a popular JavaScript library for building user interfaces. Its architecture is grounded in component-based design principles, which means that the application is structured into reusable and modular components, enhancing code maintainability and scalability. The web application has been developed using ReactJS, a popular JavaScript library for building user interfaces. Its architecture is grounded in component-based design principles, which means that the application is structured into reusable and modular components, enhancing code maintainability and scalability. The record-to-text function will allow users to record audio on the web page, and then the audio will be processed and converted to text. As for the file-to-text function, the website will receive audio files uploaded by users and will return the transcript text of that audio file. And finally the subtitles generator for YouTube function, where users can enter the YouTube link as input, wait for the website to process and the website will display that video with the transcript attached to the video based on the timestamps of each transcript. This project can inspire and encourage the testing and application of new automatic speech recognition (ASR) models in specific applications.},
booktitle = {Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
pages = {312–318},
numpages = {7},
keywords = {Audio-to-text, Automatic speech recognition, Subtitles generator, Voice-to-text, Whisper model},
location = {Beijing, China},
series = {CSAI '23}
}

@inproceedings{10.1145/3510454.3522684,
author = {Imai, Saki},
title = {Is GitHub copilot a substitute for human pair-programming? an empirical study},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3522684},
doi = {10.1145/3510454.3522684},
abstract = {This empirical study investigates the effectiveness of pair programming with GitHub Copilot in comparison to human pair-programming. Through an experiment with 21 participants we focus on code productivity and code quality. For experimental design, a participant was given a project to code, under three conditions presented in a randomized order. The conditions are pair-programming with Copilot, human pair-programming as a driver, and as a navigator. The codes generated from the three trials were analyzed to determine how many lines of code on average were added in each condition and how many lines of code on average were removed in the subsequent stage. The former measures the productivity of each condition while the latter measures the quality of the produced code. The results suggest that although Copilot increases productivity as measured by lines of code added, the quality of code produced is inferior by having more lines of code deleted in the subsequent trial.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {319–321},
numpages = {3},
keywords = {AI, GitHub, copilot, software development},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3678610.3678630,
author = {Mei-seung, Cheng},
title = {Navigating the “Cooked” Data: A Framework for Understanding GenAI's Impact on Academic Writing and Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678630},
doi = {10.1145/3678610.3678630},
abstract = {This article explores the integration of Generative AI (GenAI) technologies, such as ChatGPT, Bard, and LaMDA, in academic writing classrooms, examining both their potential to transform learning and the challenges they present. Building on Activity Theory, the study assesses the transformation of students' roles, the writing assistant tool, and the rules and division of labor within the academic community after technology integration. We argue that GenAI, while offering powerful potential for personalized feedback and learning, disrupts traditional educational dynamics. This raises critical questions about student roles, data integrity, and the evolving responsibilities of teachers. We propose eleven research questions to guide future investigations. These questions emphasize the need for a nuanced understanding of how GenAI impacts the learning experience and its implications for academic integrity. We also highlight the ethical considerations surrounding its use. This work aims to contribute to the ongoing conversation surrounding AI in education, promoting a more comprehensive understanding of the opportunities and challenges presented by this transformative technology.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {76–81},
numpages = {6},
keywords = {Academic Integrity, Activity Theory, Generative AI in education, Technology in higher education},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3641237.3691669,
author = {Strubberg, Brandon C and Bennett, Kristin C and Nardone, Carroll Ferguson},
title = {Developing AI Literacy through Discussion and Practice: A Reflection on an AI Seminar},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691669},
doi = {10.1145/3641237.3691669},
abstract = {This experience report reflects on a longitudinal project aimed at determining ways that generative artificial intelligence (gen AI) can be leveraged as a pedagogical tool to assist in professionalizing students’ rhetorical understanding and use of the tool beyond the academy. Since ChatGPT launched, we have studied students’ engagement with gen AI tools to bridge academic and professional uses, believing that knowing when and how to deploy such tools can facilitate the gen AI literacy students need to have upon entering their professional careers. This report posits that students’ participatory design in the pedagogical structure is vital for creating localized practices that translate to tangible forms of AI literacies.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {189–193},
numpages = {5},
keywords = {Generative artificial intelligence, digital literacies, technical communication, writing pedagogy},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@article{10.5555/3722479.3722482,
author = {Reno, Michael J. and Russell, Victoria and Nutter, Taylor J. and Rao, P. Anand and Polack, Jennifer},
title = {AI Intersections: Ethics, Education, and Technological Philopsophy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {This panel explores the multifaceted intersections of artificial intelligence with ethics, education, and philosophical perspectives on technology. As AI continues to reshape our world, it becomes increasingly crucial to examine its implications across various disciplines. Our panelists will present diverse viewpoints, ranging from innovative pedagogical approaches using AI to philosophical inquiries into the nature of intelligence and technology. The panel will address critical questions surrounding AI explainability, the integration of AI in education, the historical context of AI research, and the ethical considerations that arise from these technological advancements. By bringing together experts from computer science, philosophy, religious studies, and digital humanities, this panel aims to foster a rich, interdisciplinary dialogue on the present and future of AI in academia and society. In the spirit of the panel topic, this abstract was created using Anthropic's Generative AI platform, Claude.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {21–23},
numpages = {3}
}

@inproceedings{10.1145/3659677.3659824,
author = {Saoudi, El Mehdi and Jai Andaloussi, Said and Jaafari, Jaafar},
title = {Assessing the Robustness of Deep Learning-Based Gait Recognition Systems Against Adversarial Attacks},
year = {2024},
isbn = {9798400709296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659677.3659824},
doi = {10.1145/3659677.3659824},
abstract = {This study presents a comprehensive analysis of the robustness of deep learning-based gait recognition systems in the face of adversarial attacks. As gait recognition technologies become increasingly vital in security-critical domains, they are challenged by the emerging threats of adversarial interventions. In response, our research proposes a novel approach, integrating the strengths of Proximal Policy Optimization (PPO) and Generative Adversarial Networks (GANs), to engineer and analyze complex adversarial attacks. The focus of our strategy is the generation and deployment of adversarial patches, designed to disrupt gait recognition algorithms while remaining imperceptible to human observers. Utilizing reinforcement learning principles, our method strategically positions these patches, compelling the target Convolutional Neural Network (CNN) models into erroneous gait pattern classification. The effectiveness of our methodology is demonstrated through comprehensive evaluations using the CASIA Gait Database: Dataset B, a prominent dataset in gait recognition research. The results underscore a noticeable decline in the accuracy of gait recognition systems post-attack, affirming the effectiveness of our adversarial tactics.},
booktitle = {Proceedings of the 7th International Conference on Networking, Intelligent Systems and Security},
articleno = {50},
numpages = {8},
keywords = {Adversarial Attacks, Deep learning-based gait recognition systems, Generative Adversarial Networks (GANs), Proximal Policy Optimization (PPO)},
location = {Meknes, AA, Morocco},
series = {NISS '24}
}

@article{10.5555/3575618.3575622,
author = {Puryear, Ben and Sprint, Gina},
title = {Github copilot in the classroom: learning to code with AI assistance},
year = {2022},
issue_date = {November 2022},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {38},
number = {1},
issn = {1937-4771},
abstract = {Recent advances in deep machine learning have enabled artificial intelligence-driven development environments (AIDEs). AIDEs are programming tools that, given comments or starter code, can generate code solution suggestions. As the accuracy of these tools continues to increase, one particular AIDE from Github, Copilot, has been gaining significant attention for its performance and ease of use. The rise of Copilot suggests that code solution generation tools will soon be commonplace in both the industry and in computer science courses, with expert and novice programmers alike benefiting from using these tools. More specifically for novices, the effects of Copilot on the process of learning to code are mostly unknown. In this paper, we perform initial explorations into these effects. Using introductory computer science and data science courses, we evaluate Copilot-generated programming assignment solutions for correctness, style, skill level appropriateness, grade scores, and potential plagiarism. Our findings indicate Copilot generates mostly unique code that can solve introductory assignments with human-graded scores ranging from 68% to 95%. Based on these results, we provide recommendations for educators to help adapt their courses to incorporate new AIDE-based programming workflows.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {37–47},
numpages = {11}
}

@inproceedings{10.1145/3649158.3657041,
author = {Thuraisingham, Bhavani},
title = {Trustworthy Artificial Intelligence for Securing Transportation Systems},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657041},
doi = {10.1145/3649158.3657041},
abstract = {Artificial Intelligence (AI) techniques are being applied to numerous applications from Healthcare to Cyber Security to Finance. For example, Machine Learning (ML) algorithms are being applied to solve security problems such as malware analysis and insider threat detection. However, there are many challenges in applying ML algorithms for various applications. For example, (i) the ML algorithms may violate the privacy of individuals. This is because we can gather massive amounts of data and apply ML algorithms to the data to extract highly sensitive information. (ii) ML algorithms may show bias and be unfair to various segments of the population. (iii) ML algorithms themselves may be attacked possibly resulting in catastrophic errors including in cyber-physical systems such as transportation systems. Finally, (iv) the ML algorithms must be safe and not harm society. Therefore, when ML algorithms are applied to transportation systems for handling congestion, preventing accidents, and giving advice to drivers, we must ensure that they are secure, ensure privacy and fairness, as well as provide for the safe operation of the transportation systems. Other AY techniques such as Generative AI (GenAI) are also being applied not only to secure systems design but also to determine the attacks and potential solutions. This presentation is divided into two parts. First, we describe our research over the past decade on Trustworthy ML systems. These are systems that are secure as well as ensure privacy, fairness, and safety. We discuss our ensemble-based ML models for detecting attacks as well as our research on developing Adversarial Machine Learning techniques. We also discuss securing the Internet of Transportation systems that are based on traditional methods such as Extended Kalman Filters to detect cyberattacks. Second, Second, we discuss our work on Finally, we discuss the research we recently started as part of the USDOT National University Technology Center TraCR (Transportation Cybersecurity and Resiliency) led by Clemson University. In particular, we describe (i) the application of federated machine learning techniques for detecting attacks in transportation systems; (ii) publishing synthetic transportation data sets that preserve privacy, (iii) fairness algorithms for transportation systems, and (iv) examining how GenAI systems are being integrated with transportation systems to provide security. Our focus includes the following: · Data Privacy: We are designing a Privacy-aware Policy-based Data Management Framework for Transportation Systems. Our work involves collecting the requisite data and developing analysis tools to identify and quantify privacy risks. Existing privacy-preserving, differentially private synthetic data generation techniques, which tailor data utility for generic ML accuracy, are not well suited for specific applications. We are developing synthetic data generation tools for transportation systems applications. We will develop new ML algorithms that can leverage these datasets. · Fairness: We have developed a novel adaptive fairness-aware online meta-learning algorithm, FairSAOML, which adapts to changing environments in both bias control and model precision. Our current work is focusing on adapting our framework to fairness in transportation systems. and control bias over time, especially ensuring group fairness across different protected sub-populations; identifying interesting attributes using explainable AI techniques that might help to mitigate bias and develop equitable algorithms. We have also developed a second system, FairDolce, that recognizes objects involving fairness constraints in a changing environment. We are adapting it to transportation applications. For example, pedestrian detection (whether or not the object being seen is a pedestrian) must be fair with respect to the race or gender of the individuals being detected under changing environments (e.g., rainy, cloudy sunny). Adversarial ML: Our prior work on adversarial ML models worked on traditional datasets such as network traffic data. Our current focus is on adapting our approach to AV-based sensor data. Our ML models are being applied to sensor data for object recognition and traffic management. These ML models may be attacked by the adversary. We will study various attack models and investigate ways of how interactions may occur between the model and the adversary and subsequently develop appropriate adversarial ML models that operate on the AV sensor data. · Attack Detection - Smart vehicles are often exposed to various attacks making it difficult for manufacturers to collaboratively train anomaly/attack detection models. Yet it would be ideal if all the data available across manufacturers could be used in building robust attack detection systems. To achieve this, we developed FAST-SV, which incorporates federated learning in conjunction with augmentation techniques to build a highly performant attack detection system for smart cars. Safety: Safety has been studied for cyber-physical systems and formal methods have been applied to specify safety properties and subsequently verify that the system satisfies the specifications. However, our goal is to ensure that the ML algorithms utilized by the transportation systems are safe. This would involve developing an AI Governance framework that would require transparency and explainability (among others) of the ML algorithms utilized by the transportation system.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {5–6},
numpages = {2},
keywords = {adversarial machine learning, attack detection, data privacy, fairness, transportation systems, trustworthy artificial intelligence},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@article{10.1145/3685235.3685237,
author = {Deng, Xuefei (Nancy) and Joshi, K.D.},
title = {Promoting Ethical Use of Generative AI in Education},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {3},
issn = {0095-0033},
url = {https://doi.org/10.1145/3685235.3685237},
doi = {10.1145/3685235.3685237},
abstract = {Generative artificial intelligence (AI) represents a crucial subset of AI models characterized by their ability to generate new content based on user input, showing vast potential to transform learning and teaching. However, educators have raised ethical concerns, particularly regarding the adverse effect on students' learning if students simply parrot generative AI-generated content without engaging in critical analysis or original thought. Moreover, there exists the potential of generative AI to perpetuate existing biases in training data. This editorial discusses three major concerns in generative AI use in education and proposes questions (on task-AI fit and people-AI fit) and approaches to address the ethical considerations by adopting five principles of AI ethics. The editorial also discusses developing a classroom AI use policy as one governance mechanism for promoting ethical use of AI. As generative AI technology continues to evolve, so must our educational practices. The editorial ends with a call for readers (educators) to collaboratively define the terms of engagement with generative AI in educational settings and to begin this discourse by sharing insights and experiences with promoting ethical use of generative AI.},
journal = {SIGMIS Database},
month = jul,
pages = {6–11},
numpages = {6},
keywords = {ai ethics, ai use policy, biases, ethical use of ai, generative ai, higher education, normalization of mediocrity, plagiarism, prompt engineering}
}

@inproceedings{10.1145/3558489.3559072,
author = {Yetistiren, Burak and Ozsoy, Isik and Tuzun, Eray},
title = {Assessing the quality of GitHub copilot’s code generation},
year = {2022},
isbn = {9781450398602},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558489.3559072},
doi = {10.1145/3558489.3559072},
abstract = {The introduction of GitHub’s new code generation tool, GitHub Copilot, seems to be the first well-established instance of an AI pair-programmer. GitHub Copilot has access to a large number of open-source projects, enabling it to utilize more extensive code in various programming languages than other code generation tools. Although the initial and informal assessments are promising, a systematic evaluation is needed to explore the limits and benefits of GitHub Copilot. The main objective of this study is to assess the quality of generated code provided by GitHub Copilot. We also aim to evaluate the impact of the quality and variety of input parameters fed to GitHub Copilot. To achieve this aim, we created an experimental setup for evaluating the generated code in terms of validity, correctness, and efficiency. Our results suggest that GitHub Copilot was able to generate valid code with a 91.5% success rate. In terms of code correctness, out of 164 problems, 47 (28.7%) were correctly, while 84 (51.2%) were partially correctly, and 33 (20.1%) were incorrectly generated. Our empirical analysis shows that GitHub Copilot is a promising tool based on the results we obtained, however further and more comprehensive assessment is needed in the future.},
booktitle = {Proceedings of the 18th International Conference on Predictive Models and Data Analytics in Software Engineering},
pages = {62–71},
numpages = {10},
keywords = {AI pair programmer, GitHub Copilot, code completion, code generation, empirical study},
location = {Singapore, Singapore},
series = {PROMISE 2022}
}

@inproceedings{10.1145/3664476.3670902,
author = {Louro, Bernardo and Abreu, Raquel and Cabral Costa, Joana and F. Sequeiros, Jo\~{a}o B. and M. In\'{a}cio, Pedro R.},
title = {Analysis of the Capability and Training of Chat Bots in the Generation of Rules for Firewall or Intrusion Detection Systems},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3670902},
doi = {10.1145/3664476.3670902},
abstract = {Large Language Models (LLMs) have the potential to aid in closing the knowledge gap in several specific technical areas, such as cybersecurity, by providing a means to translate instructions defined in natural language into specialized system or software specifications (e.g., firewall rules). The work described herein aims at an evaluation of the capability of LLMs to generate rules for firewall and Intrusion Detection Systems (IDSs). A preliminary assessment has shown that widely available chat bots have limited capability to generate correct rules and that caution is needed when using their outputs for the aforementioned objective. This work explores three fine-tuning approaches to address these limitations, each of them with a different objective and achieving distinct success rates. The first approach aimed at testing how well the model was able to use the knowledge obtained from the prompts when the question was structured differently, achieving a success rate of 89%. The second approach aimed at testing how well the model could link the knowledge obtained from two different prompts and reached a success rate of 61%. The final approach aimed at testing if the model could create complex rules by first learning simple rules, achieving a success rate of 79%. It can be concluded that fine-tuning is sufficient to improve chat bots into creating syntactically and technically correct rules for firewalls and IDSs. Results suggest that the development of a specialized model for as many attacks, firewalls and IDSs can indeed be achieved.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {123},
numpages = {7},
keywords = {Firewalls, Intrusion Detection Systems, Large Language Models},
location = {Vienna, Austria},
series = {ARES '24}
}

@inproceedings{10.1145/3649158.3657043,
author = {Kundu, Ashish},
title = {AI/ML, Graphs and Access Control: Towards Holistic Identity and Access Management},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657043},
doi = {10.1145/3649158.3657043},
abstract = {Vulnerabilities in identity and access management (IAM) are one of the most common reasons for data breaches leading to adversarial impacts on security, privacy and compliance postures. Account breaches, incorrectly designed access control policies, weaknesses in authentication and credential management, vulnerable session management are some of the several security issues that lead to eventual compromise of the crown jewels leading to data breaches. The lifecycles of subjects and their identities, of objects and re- sources, and of the permissions and authorization policies are in- tertwined in a complex manner for each specific scenario. Often subjects, objects and permissions often are hard to be defined or isolated from each other, especially in the context of machine learn-ing. The evolution of these entities, and how their provenance is analyzed often is essential not only for forensic analysis of a breach but also should be a proactive ongoing process.  In order to manage the security issues and risks thereof, holistic end-to-end identity and access management in a secure and privacy- preserving manner is the need of yesterday, today and of the future. In the past couple of decades, we have encountered this problem time and again in various contexts in the settings of academic and industry research and in development/deployment of products, services and processes.  Three elements are the key ingredients in order to address this problem in a holistic manner: (1) graphs, (2) machine learning, and (3) decentralized computing (i.e., web3, blockchains). Further, with the advent of generative AI and large language models, the question arises about what problems they can help solve, or they can excerbate further, or what new challenges they can introduce. In this talk, I plan to delve into a discussion of the following: (a) the holistic and end-to-end nature of IAM, (b) the interplay between these three elements - graphs, machine learning, Web3 as well as generative AI, and how they can help, and (c) the research challenges that need to be addressed in order to reduce the security, privacy and compliance risks in identity and access management.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {1},
numpages = {1},
keywords = {access control, generative ai, identity, machine learning},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@inproceedings{10.1145/3589335.3651582,
author = {Tania, Nishat Ara and Masud, Md Rayhanul and Rokon, Md Omar Faruk and Zhang, Qian and Faloutsos, Michalis},
title = {Who is Creating Malware Repositories on GitHub and Why?},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651582},
doi = {10.1145/3589335.3651582},
abstract = {Recent studies have found thousands of malware source code repositories on GitHub. For the first time, we propose to understand the origins and motivations behind the creation of such malware repositories. For that, we collect and profile the authors of malware repositories using a three-fold systematic approach. First, we identify 14K users in GitHub who have authored at least one malware repository. Second, we leverage a pretrained large language model (LLM) to estimate the likelihood of malicious intent of these authors. This innovative approach led us to categorize 3339 as Malicious, 3354 as Likely Malicious, and 7574 as Benign authors. Further, to validate the accuracy and reliability of our classification, we conduct a manual review of 200 randomly selected authors. Third, our analysis provides insights into the authors' profiles and motivations. We find that Malicious authors often have sparse profiles and focus on creating and spreading malware, while Benign authors typically have complete profiles with a focus on cybersecurity research and education. Likely Malicious authors show varying levels of engagement and ambiguous intentions. We see our study as a key step towards understanding the ecosystem of malware authorship on GitHub.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {955–958},
numpages = {4},
keywords = {classification, github, hacker, llm, malware, repository, user},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3597503.3623316,
author = {Yu, Hao and Shen, Bo and Ran, Dezhi and Zhang, Jiaxin and Zhang, Qi and Ma, Yuchi and Liang, Guangtai and Li, Ying and Wang, Qianxiang and Xie, Tao},
title = {CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3623316},
doi = {10.1145/3597503.3623316},
abstract = {Code generation models based on the pre-training and fine-tuning paradigm have been increasingly attempted by both academia and industry, resulting in well-known industrial models such as Codex, CodeGen, and PanGu-Coder. To evaluate the effectiveness of these models, multiple existing benchmarks (e.g., HumanEval and AiXBench) are proposed, including only cases of generating a standalone function, i.e., a function that may invoke or access only built-in functions and standard libraries. However, non-standalone functions, which typically are not included in the existing benchmarks, constitute more than 70% of the functions in popular open-source projects, and evaluating models' effectiveness on standalone functions cannot reflect these models' effectiveness on pragmatic code generation scenarios (i.e., code generation for real settings of open source or proprietary code).To help bridge the preceding gap, in this paper, we propose a benchmark named CoderEval, consisting of 230 Python and 230 Java code generation tasks carefully curated from popular real-world open-source projects and a self-contained execution platform to automatically assess the functional correctness of generated code. CoderEval supports code generation tasks from six levels of context dependency, where context refers to code elements such as types, APIs, variables, and consts defined outside the function under generation but within the dependent third-party libraries, current class, file, or project. CoderEval can be used to evaluate the effectiveness of models in generating code beyond only standalone functions. By evaluating three state-of-the-art code generation models (CodeGen, PanGu-Coder, and ChatGPT) on CoderEval and HumanEval, we find that the effectiveness of these models in generating standalone functions is substantially higher than that in generating non-standalone functions. Our analysis highlights the current progress and pinpoints future directions to further improve a model's effectiveness by leveraging contextual information for pragmatic code generation.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {37},
numpages = {12},
keywords = {code generation, large language models, benchmark},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3628516.3659392,
author = {Kim, David Y.J. and Ravi, Prerna and Williams, Randi and Yoo, Daeun},
title = {App Planner: Utilizing Generative AI in K-12 Mobile App Development Education},
year = {2024},
isbn = {9798400704420},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628516.3659392},
doi = {10.1145/3628516.3659392},
abstract = {App Planner is an interactive support tool for K-12 students, designed to assist in creating mobile applications. By utilizing generative AI, App Planner helps students articulate the problem and solution through guided conversations via a chat-based interface. It assists them in brainstorming and formulating new ideas for applications, provides feedback on those ideas, and stimulates creative thinking. Here we report usability tests from our preliminary study with high-school students who appreciated App Planner for aiding the app design process and providing new viewpoints on human aspects especially the potential negative impact of their creation.},
booktitle = {Proceedings of the 23rd Annual ACM Interaction Design and Children Conference},
pages = {770–775},
numpages = {6},
keywords = {Education Technology, Generative AI, Mobile Application},
location = {Delft, Netherlands},
series = {IDC '24}
}

@inproceedings{10.1145/3637989.3638014,
author = {Wang, Jin and Cornely, Pierre-Richard},
title = {Addressing Academic Misconduct in the Age of ChatGPT: Strategies and Solutions},
year = {2024},
isbn = {9798400708732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637989.3638014},
doi = {10.1145/3637989.3638014},
abstract = {ChatGPT, developed by OpenAI, has emerged as a pivotal advancement in the realm of artificial intelligence, boasting capabilities that extend from answering factual queries to engaging in nuanced dialogue. While ChatGPT offers transformative potential across various sectors, its integration into the educational domain presents unique challenges—most notably, an escalation in the prevalence and complexity of academic misconduct. Students have begun to exploit this technology to complete assignments, fabricate essays, and even cheat during examinations, thereby undermining the core principles of educational integrity. This paper aims to offer a comprehensive examination of the academic implications of ChatGPT, focusing on the ethical dimensions and the evolving forms of misconduct enabled by this technology. Through a thorough review of existing literature, case studies, and expert opinions, we propose a multifaceted strategy for institutions to effectively combat this emergent form of academic dishonesty, aiming to strike a balance between technological advancement and academic integrity.},
booktitle = {Proceedings of the 2023 7th International Conference on Education and E-Learning},
pages = {19–25},
numpages = {7},
location = {Tokyo, Japan},
series = {ICEEL '23}
}

@inproceedings{10.1145/3686852.3687069,
author = {Zhang, He and Xie, Jingyi and Wu, Chuhao and Cai, Jie and Kim, Chanmin and Carroll, John M.},
title = {The Future of Learning: Large Language Models through the Lens of Students},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687069},
doi = {10.1145/3686852.3687069},
abstract = {As Large-Scale Language Models (LLMs) continue to evolve, they demonstrate significant enhancements in performance and an expansion of functionalities, impacting various domains, including education. In this study, we conducted interviews with 14 students to explore their everyday interactions with ChatGPT. Our preliminary findings reveal that students grapple with the dilemma of utilizing ChatGPT’s efficiency for learning and information seeking, while simultaneously experiencing a crisis of trust and ethical concerns regarding the outcomes and broader impacts of ChatGPT. The students perceive ChatGPT as being more “human-like” compared to traditional AI. This dilemma, characterized by mixed emotions, inconsistent behaviors, and an overall positive attitude towards ChatGPT, underscores its potential for beneficial applications in education and learning. However, we argue that despite its human-like qualities, the advanced capabilities of such intelligence might lead to adverse consequences. Therefore, it’s imperative to approach its application cautiously and strive to mitigate potential harms in future developments.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {12–18},
numpages = {7},
keywords = {ChatGPT, Large language models, education, incidental learning, qualitative},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3643834.3660706,
author = {Vega-Cebri\'{a}n, Jos\'{e} Manuel and Turmo Vidal, Laia and Tajadura-Jim\'{e}nez, Ana and Bonino Covas, Tom\'{a}s and M\'{a}rquez Segura, Elena},
title = {Movits: a Minimalist Toolkit for Embodied Sketching},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3660706},
doi = {10.1145/3643834.3660706},
abstract = {We present the design and evaluation of the Movits, a minimalist toolkit for embodied sketching design explorations. The toolkit includes technology probes featuring minimalist wearable digital units that support the hands-on exploration and design of movement-driven interactions using multisensory feedback. The Movits are self-contained and generate audiovisual or vibrotactile patterns in response to movement-based inputs. We present the theoretical and empirical grounding driving our design process. We discuss the findings of using the Movits during four co-design workshops with design students, technologists, dancers and physiotherapists, where they resulted in being generative and adaptable to a range of embodied design approaches. We contend that the Movits can be favourable for those interested in a holistic design approach to wearables in general and specifically for those targeting movement-based application domains.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {3302–3317},
numpages = {16},
keywords = {Biofeedback, Bodystorming, Bodystorming Basket, Embodied Sketching, Ideation, Ideation Probes, Ideation Props, Motor Learning, Multisensory Feedback, Technology Probes, Toolkit, Wearables},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3512716.3512725,
author = {Zakraoui, Jezia and Al Maadeed, Somaya and Abou El-Seoud, Mohamed Samir and Alja'am, Jihad M. and Salah, Moutaz},
title = {A Generative Approach to Enrich Arabic Story Text with Visual Aids},
year = {2022},
isbn = {9781450384315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3512716.3512725},
doi = {10.1145/3512716.3512725},
abstract = {Enriching the script of a story with visual aids is an effective approach for promoting language learning and literacy development for young children and learners. In this paper, we propose a new system, that can generate short Arabic stories with generated images that accurately represent the story, scene and context of the given input. We use a text generation technique with a text-to-image synthesis network and minimize the human intervention. We build a corpus of Arabic stories with vocabulary and visualizations. The obtained results with various generative models to create text-image contents show the effectiveness of the proposed approach. The system can be used in education and assist the instructors to build stories on different domains. It can be used in distance learning to deliver online tutorials during COVID-19.},
booktitle = {Proceedings of the 10th International Conference on Software and Information Engineering},
pages = {47–52},
numpages = {6},
keywords = {CLIP, GAN, Story Understanding, Story visualization, Visual Language Learning},
location = {Cairo, Egypt},
series = {ICSIE '21}
}

@inproceedings{10.1145/3691016.3691035,
author = {Wu, Jinyong and Cui, Yujia and Cui, Yingwei},
title = {The image-generative artificial intelligence Midjourney empowers Chinese landscape painting teaching and creation with positive nurturing},
year = {2024},
isbn = {9798400710285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691016.3691035},
doi = {10.1145/3691016.3691035},
abstract = {This study explores the positive impacts of the image-generative AI, Midjourney, on teaching and creating Chinese landscape paintings. Amid the rapid development of image-generative AI, Midjourney acts as an "assistive creative tool" in the creation of Chinese landscape paintings. The visual effects generated by key descriptive words play a significant role in guiding landscape painters' innovative thinking, brush and ink techniques, and creative concepts, even forming new circles of innovative thinking. The process of "human-machine interaction" is analyzed through the principles of human-machine cooperative Chinese landscape painting, using Midjourney training as an example to explore the mechanisms and processes of generating stylized painting schemes.},
booktitle = {Proceedings of the 2024 International Conference on Image Processing, Intelligent Control and Computer Engineering},
pages = {104–108},
numpages = {5},
location = {Qingdao, China},
series = {IPICE '24}
}

@inproceedings{10.1145/3650400.3650606,
author = {Xing, Kongduo},
title = {Design and implementation of digital training evaluation management system based on AI's generative AI technology},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650606},
doi = {10.1145/3650400.3650606},
abstract = {With the advancement of information technology, traditional offline training is gradually giving way to online digital training. The conventional online digital training evaluation management system entails manual data collection followed by the utilization of these gathered data for training effectiveness assessment. This entire process is intricate and can introduce potential biases. To address these challenges, we have developed a digital training management system rooted in AI's generative AI technology. This innovative system employs both the fuzzy comprehensive evaluation method and the artificial intelligence evaluation method to assess the quality and effectiveness indexes of digital training. Furthermore, it is designed on the foundation of deep learning algorithms, creating an AI-driven digital training evaluation management system. To ensure the security and privacy of the system, extensive simulation experiments have been conducted. These experiments help control the deviation values of evaluation results, ultimately guaranteeing the fairness of outcomes generated by the evaluation system.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1222–1226},
numpages = {5},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3613905.3650786,
author = {Gao, Jie and Gebreegziabher, Simret Araya and Choo, Kenny Tsu Wei and Li, Toby Jia-Jun and Perrault, Simon Tangi and Malone, Thomas W},
title = {A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650786},
doi = {10.1145/3613905.3650786},
abstract = {With ChatGPT’s release, conversational prompting has become the most popular form of human-LLM interaction. However, its effectiveness is limited for more complex tasks involving reasoning, creativity, and iteration. Through a systematic analysis of HCI papers published since 2021, we identified four key phases in the human-LLM interaction flow—planning, facilitating, iterating, and testing—to precisely understand the dynamics of this process. Additionally, we have developed a taxonomy of four primary interaction modes: Mode 1: Standard Prompting, Mode 2: User Interface, Mode 3: Context-based, and Mode 4: Agent Facilitator. This taxonomy was further enriched using the “5W1H” guideline method, which involved a detailed examination of definitions, participant roles (Who), the phases that happened (When), human objectives and LLM abilities (What), and the mechanics of each interaction mode (How). We anticipate this taxonomy will contribute to the future design and evaluation of human-LLM interaction.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {24},
numpages = {11},
keywords = {Human-LLM Interaction, Large Language Models, Taxonomy},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3678392.3678405,
author = {Qi, Yuanyi and Wang, Lamei},
title = {Learning Assessment for Open Education Learners in the Era of Generative Artificial Intelligence},
year = {2024},
isbn = {9798400717123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678392.3678405},
doi = {10.1145/3678392.3678405},
abstract = {Generative Artificial Intelligence (AI) tools are now used by students to do their learning assessment, thus impairing the value of such learning assessment. For open education learners who aim to just obtain adult education diplomas, particularly, the cost of learning assessment is becoming increasingly low due to the use of generative AI. How to instructional design and assessment for open education learners in the era of generative AI becomes therefore an issue requiring urgent solutions. From such perspectives as the advantages and disadvantages of generative AI, the learning needs and characteristics of open education learners, and the new characteristics of learning assessment with the use of generative AI, this paper examines the dilemma of instructional design and assessment during the age of generative AI, puts forward the ideas and models for the design of homework for open education learners, and makes learning assessment design proposals with respect to renewing the methods of learning assessment, improving the AI literacy of both teachers and students, etc., with a view to offering some insight for the design of homework in the era of generative AI.},
booktitle = {Proceedings of the 2024 10th International Conference on Frontiers of Educational Technologies},
pages = {38–44},
numpages = {7},
keywords = {Generative AI, Learning assessment, Open education learners},
location = {Malacca, Malaysia},
series = {ICFET '24}
}

@proceedings{10.1145/3664647,
title = {MM '24: Proceedings of the 32nd ACM International Conference on Multimedia},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3555858.3555867,
author = {Clark, Lynda and Sood, Divij},
title = {Working Backwards: Creating a Character Backstory Generation System Using Idealized Creative Writing Outputs: Creating a Character Backstory Generation System Using Idealized Creative Writing Outputs},
year = {2022},
isbn = {9781450397957},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555858.3555867},
doi = {10.1145/3555858.3555867},
abstract = {This paper is a reflection on the process of designing and developing a character backstory generation system prototype following literary analysis of idealized textual outputs. An overview of previous generative systems (both academic and commercial) and some of the design priorities associated with these systems is described in order to set a context for the project. The design process is then described, with particular focus on the creation of the idealized outputs and their purpose. Finally, the learning outcomes following initial generative texts created by the prototype engine are shared, weighing the pros and cons of both the design approach, the resulting generator and its outputs.},
booktitle = {Proceedings of the 17th International Conference on the Foundations of Digital Games},
articleno = {29},
numpages = {9},
keywords = {Text generation, creative writing, literary analysis, narrative design},
location = {Athens, Greece},
series = {FDG '22}
}

@article{10.5555/3665609.3665621,
author = {Jonas, Michael},
title = {Mitigating Use of Artificial Intelligence in Student Assignments},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {With the proliferation of advanced Artificial Intelligent systems trained on robust language models, it is becoming more difficult to discern acts of plagiarism in the classroom. Though some of this falls under the academic misconduct policy of an institution, it can be confusing to students as to what qualifies as proper use. Students use tools like Grammarly, to improve their writing, and find more advanced AI tools, such as ChatGPT as an additional resource. For faculty to simply ban the use of these tools, creates an unworkable model. Embracing them can also be problematic as not all educational material benefits from a flipped approach. In this paper we discuss changing the dynamic by applying targeted assessments that incrementally address elements in an assignment, to affirm the work that students submitted and discourage use of improper tools that don't assist in learning.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {173–181},
numpages = {9}
}

@inproceedings{10.1145/3660512.3665522,
author = {Erfurth, Simon},
title = {Digital Signatures for Authenticating Compressed JPEG Images},
year = {2024},
isbn = {9798400706509},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660512.3665522},
doi = {10.1145/3660512.3665522},
abstract = {We construct a digital signature scheme for images that allows the image to be compressed without invalidating the signature. More specifically, given a JPEG image signed with our signature scheme, a third party can compress the image using JPEG compression, and, as long as the quantization tables only include powers of two, derive a valid signature for the compressed image, without access to the secret signing key, and without interaction with the signer. Our scheme is constructed using a standard digital signature scheme and a hash function as building blocks. This form of signatures that allow image compression could be useful in mitigating some of the threats posed by generative AI and fake news, without interfering with all uses of generative AI. Taking inspiration from related signature schemes, we define a notion of unforgeability and prove our construction to be secure. Additionally, we show that our signatures have size 32.5 kb under standard parameter choices. Using image quality assessment metrics, we show that JPEG compression with parameters as specified by our scheme, does not result in perceivably reduced visual fidelity, compared to standard JPEG compression.},
booktitle = {Proceedings of the 1st Workshop on Security-Centric Strategies for Combating Information Disorder},
articleno = {4},
numpages = {12},
keywords = {JPEG Compression, digital signatures, homomorphic signatures},
location = {Singapore, Singapore},
series = {SCID '24}
}

@inproceedings{10.1145/3637907.3637988,
author = {Guo, Xue and He, Xiangchun and Pei, Zhuoyun},
title = {Data-driven Personalized Learning},
year = {2024},
isbn = {9798400716676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637907.3637988},
doi = {10.1145/3637907.3637988},
abstract = {With the continuous development of big data, artificial intelligence and other technologies, education is becoming more and more intelligent, personalized and accurate, accelerating the process of education modernization in China. On the basis of analyzing the connotation of data-driven and personalized learning, this paper sorts out the main research aspects of data-driven personalized learning at present, and proposes a data-driven personalized learning mechanism from four aspects of data-driven. Through data collection, data modeling, data analysis and data feedback, data collection of learners is completed, characteristics of learners are analyzed, and digital portraits are formed. chatGPT and other generative artificial intelligence are used to provide accurate personalized services for learners and promote the personalized development of learners. Research shows that data-driven personalized learning is more scientific, precise, intelligent and diversified.},
booktitle = {Proceedings of the 2023 6th International Conference on Educational Technology Management},
pages = {49–54},
numpages = {6},
keywords = {Big data, Data-driven, Personalized learning},
location = {Guangzhou, China},
series = {ICETM '23}
}

@article{10.1109/TASLP.2023.3235202,
author = {Rohmatillah, Mahdin and Chien, Jen-Tzung},
title = {Hierarchical Reinforcement Learning With Guidance for Multi-Domain Dialogue Policy},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3235202},
doi = {10.1109/TASLP.2023.3235202},
abstract = {Achieving high performance in a multi-domain dialogue system with low computation is undoubtedly challenging. Previous works applying an end-to-end approach have been very successful. However, the computational cost remains a major issue since the large-sized language model using GPT-2 is required. Meanwhile, the optimization for individual components in the dialogue system has not shown promising result, especially for the component of dialogue management due to the complexity of multi-domain state and action representation. To cope with these issues, this article presents an efficient guidance learning where the imitation learning and the hierarchical reinforcement learning (HRL) with human-in-the-loop are performed to achieve high performance via an inexpensive dialogue agent. The behavior cloning with auxiliary tasks is exploited to identify the important features in latent representation. In particular, the proposed HRL is designed to treat each goal of a dialogue with the corresponding sub-policy so as to provide efficient dialogue policy learning by utilizing the guidance from human through action pruning and action evaluation, as well as the reward obtained from the interaction with the simulated user in the environment. Experimental results on ConvLab-2 framework show that the proposed method achieves state-of-the-art performance in dialogue policy optimization and outperforms the GPT-2 based solutions in end-to-end system evaluation.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jan,
pages = {748–761},
numpages = {14}
}

@inproceedings{10.1145/3623462.3623475,
author = {Alves da Veiga, Pedro},
title = {Generative Ominous Dataset: Testing the Current Public Perception of Generative Art},
year = {2023},
isbn = {9798400708367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623462.3623475},
doi = {10.1145/3623462.3623475},
abstract = {The advent of generative AI artworks has paved the way for ground-breaking explorations in the realm of digital creativity. This article delves into the multifaceted dimensions of G.O.D., an abbreviation for the art project Generative Ominous Dataset. G.O.D. aims at critically engaging with contemporary AI generative image systems and their intricate interplay with copyright issues, artistic autonomy, and the ethical implications of data collection, unravelling its conceptual underpinnings and its implications for the broader discourse on artificial intelligence, artistic agency, and the evolving contours of digital art. G.O.D. is a generative artwork, entirely coded in Processing, and developed within a/r/cography, a creative research methodology. G.O.D. scrutinizes and questions the ethics of contemporary text-to-image AI-based systems, such as Midjourney, DALL-E, or Firefly. These systems have been at the centre of controversies concerning the datasets used for their training, which encompass online sourced copyrighted materials, without authorization or attribution, masking questionable approaches with technological dazzlement. Many artists and authors find their works repurposed by these systems for the mass production of digital derivatives. G.O.D. aims at critically exposing art audiences to these concerns.},
booktitle = {Proceedings of the 20th International Conference on Culture and Computer Science: Code and Materiality},
articleno = {10},
numpages = {10},
location = {Lisbon, Portugal},
series = {KUI '23}
}

@inproceedings{10.1145/3641237.3691687,
author = {Tetu, Imari Cheyne},
title = {Inviting ChatGPT into Technical Writing Classes: Opportunities, Challenges, and Student Perceptions},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691687},
doi = {10.1145/3641237.3691687},
abstract = {This project examines the potentials of ChatGPT to support and enhance the learning experience for students in technical writing courses. Amidst discussions on the implications of LLMs in writing instruction, this study explores how ChatGPT can be used as a resource for teaching and learning technical writing, a genre that demands precision, clarity, and a specific skill set. This project investigates the effects of deliberately inserting ChatGPT into a classroom as both a model of writing and a venue for critiquing writing. By exploring ChatGPT as both a tool and a subject of study, this project aims to enhance student literacies in AI technologies and their applications in professional writing.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {269–270},
numpages = {2},
keywords = {Artificial intelligence, Technical writing, Usability testing},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3586183.3606786,
author = {Peng, Zhenhui and Wang, Xingbo and Han, Qiushi and Zhu, Junkai and Ma, Xiaojuan and Qu, Huamin},
title = {Storyfier: Exploring Vocabulary Learning Support with Text Generation Models},
year = {2023},
isbn = {9798400701320},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586183.3606786},
doi = {10.1145/3586183.3606786},
abstract = {Vocabulary learning support tools have widely exploited existing materials, e.g., stories or video clips, as contexts to help users memorize each target word. However, these tools could not provide a coherent context for any target words of learners’ interests, and they seldom help practice word usage. In this paper, we work with teachers and students to iteratively develop Storyfier, which leverages text generation models to enable learners to read a generated story that covers any target words, conduct a story cloze test, and use these words to write a new story with adaptive AI assistance. Our within-subjects study (N=28) shows that learners generally favor the generated stories for connecting target words and writing assistance for easing their learning workload. However, in the read-cloze-write learning sessions, participants using Storyfier perform worse in recalling and using target words than learning with a baseline tool without our AI features. We discuss insights into supporting learning tasks with generative models.},
booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {46},
numpages = {16},
keywords = {language models, story generation, vocabulary learning},
location = {San Francisco, CA, USA},
series = {UIST '23}
}

@inproceedings{10.1145/3698587.3701473,
author = {Jiang, Zekun and Dai, Wei and Wei, Qu and Qin, Ziyuan and Li, Kang and Zhang, Le},
title = {EEG-DIF: Early Warning of Epileptic Seizures through Generative Diffusion Model-based Multi-channel EEG Signals Forecasting},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701473},
doi = {10.1145/3698587.3701473},
abstract = {Multi-channel EEG signals are commonly used for diagnosis and assessment of diseases such as epilepsy. Currently, various EEG diagnostic algorithms based on deep learning have been developed. However, most research efforts focus solely on diagnosing and classifying current signal data, but not consider the prediction of future trends for early warning.Additionally, since multi-channel EEG can be essentially regarded as the spatio-temporal signal data received by detectors at different locations in the brain, how to construct spatio-temporal information representations of EEG signals to facilitate future trend prediction for multi-channel EEG becomes an important problem. This study proposes a multi-signal prediction algorithm based on generative diffusion models (EEG-DIF), which transforms the multi-signal forecasting task into an image completion task, allowing for comprehensive representation and learning of the spatio-temporal correlations and future developmental patterns of multi-channel EEG signals. Based on our method, we can achieve multi-signal forecasting by using one diffusion model to simultaneously predict future trends for multichannel EEG signals. We also integrate a CNN-LSTM classifier into the backend of EEG-DIF and develop an early warning diagnostic model for epileptic seizures based on the generated EEG signals, providing accurate early seizure predictions.Here, we employ a publicly available epilepsy EEG dataset to construct and validate the EEG-DIF. The results demonstrate that our method can accurately predict future trends for multi-channel EEG signals simultaneously. Furthermore, the early warning accuracy for epilepsy seizures based on the generated EEG data reaches 0.89. In general, EEG-DIF provides a novel approach for characterizing multi-channel EEG signals and an innovative early warning algorithm for epilepsy seizures, aiding in optimizing and enhancing the clinical diagnosis process.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {71},
numpages = {1},
keywords = {Artificial intelligence, Diffusion model, EEG, epileptic seizures, multi-signal forecasting, spatio-temporal representation},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3686852.3687075,
author = {Beaton, Catherine and Weeden, Elissa and Zilora, Stephen},
title = {Instructional Approaches Complementing the Use of Generative Artificial Intelligence in Higher Education},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687075},
doi = {10.1145/3686852.3687075},
abstract = {The explosion of generative artificial intelligence (AI) has created a level of chaos in higher education as both students and faculty try to determine its utility and how best to incorporate it into the learning process. Students may view generative AI as a means to an end of achieving a perfect grade, skipping important elements of the learning process, or they may view it as an opportunity to expand their creative efforts. Faculty may view it as a tool students use to circumvent plagiarism detection, may feel it potentially minimizes the role of faculty in the classroom, or they may view it as an opportunity to avail of a supplement to existing activities and assignments. Ultimately, faculty are faced with maintaining academic integrity and reinforcing the need and importance of the learning process. This paper explores the combination of three approaches: peer-supported incremental learning, master/apprentice model, and growth mindset as a way for faculty to guide appropriate student use of generative AI, while also maintaining the integrity of the learning process.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {62–67},
numpages = {6},
keywords = {Artificial intelligence, Growth mindset, Master/Apprentice model, Peer-supported incremental learning},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3626772.3657855,
author = {Mozafari, Jamshid and Jangra, Anubhav and Jatowt, Adam},
title = {TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657855},
doi = {10.1145/3626772.3657855},
abstract = {Nowadays, individuals tend to engage in dialogues with Large Language Models, seeking answers to their questions. In times when such answers are readily accessible to anyone, the stimulation and preservation of human's cognitive abilities, as well as the assurance of maintaining good reasoning skills by humans becomes crucial. This study addresses such needs by proposing hints (instead of final answers or before giving answers) as a viable solution. We introduce a framework for the automatic hint generation for factoid questions, employing it to construct TriviaHG, a novel large-scale dataset featuring 160,230 hints corresponding to 16,645 questions from the TriviaQA dataset. Additionally, we present an automatic evaluation method that measures the Convergence and Familiarity quality attributes of hints. To evaluate the TriviaHG dataset and the proposed evaluation method, we enlisted 10 individuals to annotate 2,791 hints and tasked 6 humans with answering questions using the provided hints. The effectiveness of hints varied, with success rates of 96%, 78%, and 36% for questions with easy, medium, and hard answers, respectively. Moreover, the proposed automatic evaluation methods showed a robust correlation with annotators' results. Conclusively, the findings highlight three key insights: the facilitative role of hints in resolving unknown questions, the dependence of hint quality on answer difficulty, and the feasibility of employing automatic evaluation methods for hint assessment.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2060–2070},
numpages = {11},
keywords = {hint generation, large language models, question answering},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3527927.3532790,
author = {Turker, Meliksah and Dirik, Alara and Yanardag, Pinar},
title = {MIDISpace: Finding Linear Directions in Latent Space for Music Generation},
year = {2022},
isbn = {9781450393270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527927.3532790},
doi = {10.1145/3527927.3532790},
abstract = {While recent work has shown that it is possible to find disentangled directions in the latent space of image generative networks, finding directions in the latent space of sequential models for music generation remains a largely unexplored topic. In this work, we propose a method for discovering linear directions in the latent space of a musicgenerating Variational Auto-Encoder (VAE). We use PCA, a statistical method, to transform the input data such that the variation along the new axes is maximized. We apply PCA to the latent space activations of our model and find largely disentangled directions that change the style and characteristics of the input music. Our experiments show that the found directions are often monotonic, global and encode fundamental musical characteristics such as colorfulness, speed, and repetitiveness. Moreover, we propose a set of quantitative metrics to describe different musical styles and characteristics to evaluate our results. We show that the found directions decouple content and can be utilized for style transfer and conditional music generation tasks. Our project page can be found at http://catlab-team.github.io/midispace.},
booktitle = {Proceedings of the 14th Conference on Creativity and Cognition},
pages = {420–427},
numpages = {8},
keywords = {deep learning neural networks, generative models, latent space manipulation, sequence models, vae, variatonal auto-encoder},
location = {Venice, Italy},
series = {C&amp;C '22}
}

@article{10.14778/3611540.3611640,
author = {Milic-Frayling, Natasa},
title = {On the Cusp: Computing Thrills and Perils and Professional Awakening},
year = {2023},
issue_date = {August 2023},
publisher = {VLDB Endowment},
volume = {16},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3611540.3611640},
doi = {10.14778/3611540.3611640},
abstract = {Over the past eight decades, computer science has advanced as a field, and the computing profession has matured by establishing professional codes of conduct, fostering best practices, and establishing industry standards to support the proliferation of technologies and services. Research and applications of digital computation continue to change all aspects of human endeavor through new waves of innovation. While it is clear that different research advances fuel innovation, the ways they come together to make an impact vary. In contrast to highly regulated sectors such as pharma, medicine and law, the process of transforming research into widely deployed technologies is not regulated. We reflect on collective practices, from discovery by scientists and engineers to market delivery by entrepreneurs, industry leaders, and practitioners. We consider ecosystem changes that are required to sustain the transformational effects of new technologies and enable new practices to take root. Every such transformation ruptures in the existing socio-technical fabric and requires a concerted effort to remedy this through effective policies and regulations. Computing experts are involved in all phases and must match the transformational power of their innovation with the highest standard of professional conduct. We highlight the principles of responsible innovation and discuss three waves of digital innovation. We use wide and uncontrolled generative AI deployments to illustrate risks from the implosion of digital media due to contamination of digital records, removal of human agency, and risk to an individual's personhood.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {4152–4159},
numpages = {8}
}

@article{10.1145/3657294,
author = {Vaz, Bruno and Figueira, \'{A}lvaro},
title = {GANs in the Panorama of Synthetic Data Generation Methods},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3657294},
doi = {10.1145/3657294},
abstract = {This article focuses on the creation and evaluation of synthetic data to address the challenges of imbalanced datasets in machine learning (ML) applications, using fake news detection as a case study. We conducted a thorough literature review on generative adversarial networks (GANs) for tabular data, synthetic data generation methods, and synthetic data quality assessment. By augmenting a public news dataset with synthetic data generated by different GAN architectures, we demonstrate the potential of synthetic data to improve ML models’ performance in fake news detection. Our results show a significant improvement in classification performance, especially in the underrepresented class. We also modify and extend a data usage approach to evaluate the quality of synthetic data and investigate the relationship between synthetic data quality and data augmentation performance in classification tasks. We found a positive correlation between synthetic data quality and performance in the underrepresented class, highlighting the importance of high-quality synthetic data for effective data augmentation.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = dec,
articleno = {3},
numpages = {28},
keywords = {Synthetic data, generative adversarial networks, imbalanced datasets, fake news detection, data augmentation quality}
}

@inproceedings{10.1145/3565472.3595606,
author = {Cao, Jie and Ganesh, Ananya and Cai, Jon and Southwell, Rosy and Perkoff, E. Margaret and Regan, Michael and Kann, Katharina and Martin, James H. and Palmer, Martha and D'Mello, Sidney},
title = {A Comparative Analysis of Automatic Speech Recognition Errors in Small Group Classroom Discourse},
year = {2023},
isbn = {9781450399326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565472.3595606},
doi = {10.1145/3565472.3595606},
abstract = {In collaborative learning environments, effective intelligent learning systems need to accurately analyze and understand the collaborative discourse between learners (i.e., group modeling) to provide adaptive support. We investigate how automatic speech recognition&nbsp;(ASR) errors influence discourse models of small group collaboration in noisy real-world classrooms. Our dataset consisted of 30 students recorded by consumer off-the-shelf microphones&nbsp;(Yeti Blue) while engaging in dyadic- and triadic- collaborative learning in a multi-day STEM curriculum unit. We found that two state-of-the-art ASR systems (Google Speech and OpenAI Whisper) yielded very high word error rates (0.822, 0.847) but very different profiles of error with Google being more conservative, rejecting 38% of utterances instead of 12% for Whisper. Next, we examined how these ASR errors influenced down-stream small group modeling based on pre-trained large language models for three tasks: Abstract Meaning Representation parsing&nbsp;(AMRParsing), on-task/off-task detection&nbsp;(OnTask), and Accountable Productive Talk prediction&nbsp;(TalkMove). As expected, models trained on clean human transcripts yielded degraded performance on all three tasks, measured by the transfer ratio&nbsp;(TR). However, the TR of the specific sentence-level AMRParsing &nbsp;task&nbsp;(.39 - .62) was much lower than that of the abstract discourse-level OnTask &nbsp;(.63- .94) and TalkMove &nbsp; tasks&nbsp;(.64-.72). Furthermore, different training strategies that incorporated ASR transcripts alone or as augmentations of human transcripts increased accuracy for the discourse-level tasks&nbsp;(OnTask &nbsp;and TalkMove) but not AMRParsing. Simulation experiments suggested that the models were tolerant of missing utterances in the dialog context, and that jointly improving ASR accuracy on important word classes&nbsp;(e.g., verbs and nouns) can improve performance across all tasks. Overall, our results provide insights into how different types of NLP-based tasks might be tolerant of ASR errors under extremely noisy conditions and provide suggestions for how to improve accuracy in small group modeling settings for a more equitable, engaging, and adaptive collaborative learning environment.},
booktitle = {Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization},
pages = {250–262},
numpages = {13},
keywords = {Automatic Speech Recognition, Collaborative Learning, Group Discourse Analysis, Text Tagging},
location = {Limassol, Cyprus},
series = {UMAP '23}
}

@inproceedings{10.1145/3613904.3642785,
author = {Park, Hyanghee and Ahn, Daehwan},
title = {The Promise and Peril of ChatGPT in Higher Education: Opportunities, Challenges, and Design Implications},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642785},
doi = {10.1145/3613904.3642785},
abstract = {A growing number of students in higher education are using ChatGPT for various educational purposes, ranging from seeking information to writing essays. Although many universities have officially banned the use of ChatGPT because of its potential harm and unintended consequences, it is still important to uncover how students leverage ChatGPT for learning, what challenges emerge, and how we can make better use of ChatGPT in higher education. Thus, we conducted focus group workshops and a series of participatory design sessions with thirty students who have actively interacted with ChatGPT for one semester in university and with other five stakeholders (e.g., professors, AI experts). Based on these, this paper identifies real opportunities and challenges of utilizing and designing ChatGPT for higher education.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {271},
numpages = {21},
keywords = {AI in Education, ChatGPT, Higher education, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3665065.3665082,
author = {Nokhwal, Sahil and Nokhwal, Suman and Pahune, Saurabh and Chaudhary, Ankit},
title = {Quantum Generative Adversarial Networks: Bridging Classical and Quantum Realms},
year = {2024},
isbn = {9798400717291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665065.3665082},
doi = {10.1145/3665065.3665082},
abstract = {In this pioneering research paper, we present a groundbreaking exploration into the synergistic fusion of classical and quantum computing paradigms within the realm of Generative Adversarial Networks (GANs). Our objective is to seamlessly integrate quantum computational elements into the conventional GAN architecture, thereby unlocking novel pathways for enhanced training processes. Drawing inspiration from the inherent capabilities of quantum bits (qubits), we delve into the incorporation of quantum data representation methodologies within the GAN framework. By capitalizing on the unique quantum features, we aim to accelerate the training process of GANs, offering a fresh perspective on the optimization of generative models. Our investigation deals with theoretical considerations and evaluates the potential quantum advantages that may manifest in terms of training efficiency and generative quality. We confront the challenges inherent in the quantum-classical amalgamation, addressing issues related to quantum hardware constraints, error correction mechanisms, and scalability considerations. This research is positioned at the forefront of quantum-enhanced machine learning, presenting a critical stride towards harnessing the computational power of quantum systems to expedite the training of Generative Adversarial Networks. Through our comprehensive examination of the interface between classical and quantum realms, we aim to uncover transformative insights that will propel the field forward, fostering innovation and advancing the frontier of quantum machine learning.},
booktitle = {Proceedings of the 2024 8th International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {105–109},
numpages = {5},
keywords = {Adversarial Networks (QGANs), Generative Modeling, Quantum Generative, Quantum Machine Learning, Quantum Speedup},
location = {Singapore, Singapore},
series = {ISMSI '24}
}

@inproceedings{10.1145/3637989.3638020,
author = {Freeman, Bradley and Aoki, Kumiko},
title = {ChatGPT in education: A comparative study of media framing in Japan and Malaysia},
year = {2024},
isbn = {9798400708732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637989.3638020},
doi = {10.1145/3637989.3638020},
abstract = {This study examined the media coverage of ChatGPT in the context of education in Japan and Malaysia. Through a thematic analysis of news articles, we identified and analyzed the dominant frames associated with the use of ChatGPT in education. The study found that three frames dominated the coverage: pedagogical, ethical, and assessment. The coverage highlighted the potential benefits of ChatGPT, such as personalized learning and improved assessment processes, as well as concerns around academic integrity, AI bias, and the impact of AI on society. The study also revealed differences in the tone and source usage between Malaysian and Japanese media coverage. The findings have important implications for the development and implementation of emerging educational technologies, emphasizing the need for responsible and ethical use of AI in education.},
booktitle = {Proceedings of the 2023 7th International Conference on Education and E-Learning},
pages = {26–32},
numpages = {7},
keywords = {AI in education, Academic integrity, Media framing, OpenAi},
location = {Tokyo, Japan},
series = {ICEEL '23}
}

@inproceedings{10.1145/3674912.3674922,
author = {Weerakoon, Oshani and Lepp\"{a}nen, Ville and M\"{a}kil\"{a}, Tuomas},
title = {Enhancing Pedagogy with Generative AI: Video Production from Course Descriptions},
year = {2024},
isbn = {9798400716843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674912.3674922},
doi = {10.1145/3674912.3674922},
abstract = {This paper explores a novel workflow that integrates Generative AI tools, ChatGPT and DALL·E, into educational use, aiming to improve the traditional teaching methods in university education. Our workflow is focused on creating short introductory videos for university courses, using primary course descriptions available in the university’s study guide with the idea of introducing courses visually. This approach was deliberately selected for experimentation, and we believe that it could be further enhanced to generate course videos on specific course topics. This will minimize the efforts of teachers who are required to produce detailed course videos as a part of their teaching. As the first part of our workflow, we present a tool that utilizes ChatGPT-4 and DALL·E 2 to autonomously generate a script and background graphics for videos, using primary course descriptions extracted through a given course web URL. As the second part of the workflow, we combine those generated artefacts into videos using Narakeet, a Text-to-Speech software service that is available online. To analyze the feasibility of this workflow, we then conducted a field survey where university teachers participated in reviewing introductory course videos of their courses generated through our workflow. We employed only engineering courses that are English-taught in this field survey. The results demonstrate the potential of AI-generated content to increase the efficiency of teachers when creating video materials. However, challenges such as the uncanny valley effect in text-to-speech narration and the propensity for AI-generated misinformation highlight the need for careful review by humans on such content before setting it for wider use. This paper argues for the strategic integration of AI in university education, focusing on the benefits, while acknowledging the limitations owned by generative AI tools.},
booktitle = {Proceedings of the International Conference on Computer Systems and Technologies 2024},
pages = {249–255},
numpages = {7},
keywords = {AI in Education, ChatGPT, DALL·E, Generative AI, Pedagogical Tools},
location = {Ruse, Bulgaria},
series = {CompSysTech '24}
}

@proceedings{10.1145/3689094,
title = {SUMAC '24: Proceedings of the 6th workshop on the analySis, Understanding and proMotion of heritAge Contents},
year = {2024},
isbn = {9798400712050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to SUMAC 2024, the 6th edition of the ACM workshop on analySis, Understanding and proMotion of heritAge Contents. The workshop focuses on analyzing, processing and valorizing all types of data related to cultural heritage, including tangible and intangible heritage. As stated by UNESCO, cultural heritage provides societies with a wealth of resources inherited from the past, created in the present for the benefit of future generations. The massive digitization of historical analogue resources and production of born-digital documents provide us with large volumes of varied multimedia heritage data (images, maps, text, video, 3D objects, multi-sensor data, etc.), which represent a rich heritage that can be exploited in a wide variety of fields, from research in social sciences and computational humanities to land use and territorial policies, including urban modeling, digital simulation, archaeology, tourism, education, culture preservation, creative media and entertainment. In terms of research in computer science, artificial intelligence and digital humanities, they address challenging problems related to the diversity, specificity or volume of the media, the veracity of the data, and different user needs with respect to engaging with this rich material and the extraction of value out of the data. These challenges are reflected in the corresponding sub-fields of machine learning, signal processing, multi-modal techniques and human-machine interaction, with special focus on:Analysis of historical data,Content understanding and pattern recognition,Linking and recommendation of multi-modal digital heritage,Human-machine interaction for big data analysis and visualization,Generative modeling of cultural heritage.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3639592.3639626,
author = {Tsao, Chia-Chuan and Lin, Yen-Hung and Chou, Chien-Hsing and Chang, Kuan-Ning and Han, Ping-Hsuan},
title = {Design of an Assisted Learning System Based on ChatGPT},
year = {2024},
isbn = {9798400716225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639592.3639626},
doi = {10.1145/3639592.3639626},
abstract = {This paper describes a system that utilizes ChatGPT as an auxiliary learning tool to assist students in overcoming learning difficulties. By providing ChatGPT with relevant domain-specific knowledge in advance, the system enhances the accuracy of responses. Additionally, the interface design facilitates students in posing high-quality questions, thereby obtaining precise answers. This paper aims to use this system design to help students address learning challenges, increase motivation for learning, and reduce the cost of developing domain-specific chatbots, thus enabling its application in a broader range of educational fields.},
booktitle = {Proceedings of the 2023 6th Artificial Intelligence and Cloud Computing Conference},
pages = {247–254},
numpages = {8},
keywords = {ChatGPT, chatbot, computer-assisted instruction, question-answering system, teaching and learning},
location = {Kyoto, Japan},
series = {AICCC '23}
}

@inproceedings{10.1145/3584371.3613036,
author = {Stubblefield, Jonathan W and Niraula, Trishna},
title = {Using Large Language Models to Translate Machine Results to Human Results},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613036},
doi = {10.1145/3584371.3613036},
abstract = {Chest x-rays are among the most common diagnostic studies used in most both inpatient and outpatient settings, and they represent a significant portion of the workload for radiologists. Many different machine learning models have been developed for the analysis of chest x-rays, including models capable of detecting and labeling the location and type of pathological findings. In addition, large language models (LLMs) such as ChatGPT have also been growing in popularity and have proven to be effective at a variety of writing tasks [2]. For this project, we will attempt to use LLMs to translate machine learning results into automatically generated radiology reports. This would provide quick pre-reads of chest x-rays which can later be corrected or validated by radiologists in a similar workflow used by cardiologists when reading electrocardiograms (ECGs).To perform this task, we will make use of the Open-I dataset of chest x-rays with associated radiology reports [1]. Additionally, we will use a top performing model from the competition on the CheXpert dataset [3, 4]. This dataset consists of multiple chest x-rays with expert-annotated bounding boxes labeling pathological findings [3]. We will use the top-performing model to label the type and location of pathological findings in the Open-I dataset [4]. Following this, we will algorithmically transform the bounding boxes into simple descriptions of the type and location of the pathological finding (i.e., consolidation lower left quadrant, atelectasis upper right quadrant, cardiomegaly). We will then train a LLM to translate these simple descriptions into a full radiology report.To evaluate the efficacy of our method, we will present a mixture of expert written and automatically generated radiology reports to volunteers to assess if the generated reports. Volunteers will be selected from a variety of expertise levels and backgrounds in medicine, including non-medical laymen, medical students, and physicians. Volunteers will be asked to evaluate whether they can distinguish between automatically generated and expert written reports and if both reports adequately convey the relevant information from the associated chest x-ray.If the LLMs can use simple descriptors of machine learning results to produce radiology reports, this would significantly improve patient care and the workload for physicians. Patients and non-radiologist physicians would benefit from immediately available results following the acquisition of a chest x-ray. Radiologists will be able to overread the chest x-rays later, either verifying the AI-generated results or providing corrections, similar to the practice of Cardiologists with ECGs.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {96},
numpages = {1},
keywords = {large language models (LLMs), chest x-rays, open-I dataset, radiology report, optimization},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3565516.3565519,
author = {Wafa, Abrar and Nasiopoulos, Panos},
title = {Light Field GAN-based View Synthesis using full 4D information},
year = {2022},
isbn = {9781450399395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565516.3565519},
doi = {10.1145/3565516.3565519},
abstract = {Light Field (LF) technology offers a truly immersive experience having the potential to revolutionize entertainment, training, education, virtual and augmented reality, gaming, autonomous driving, and digital health. However, one of the main issues when working with LF is the amount of data needed to create a mesmerizing experience with realistic disparity, smooth motion parallax between views. In this paper, we introduce a learning based LF angular super-resolution approach for efficient view synthesis of novel virtual images. This is achieved by taking four corner views and then generating up to five in-between views. Our generative adversarial network approach uses LF spatial and angular information to ensure smooth disparity between the generated and original views. We consider plenoptic, synthetic LF content and camera array implementations which support different baseline settings. Experimental results show that our proposed method outperforms state-of-the-art light field view synthesis techniques, offering novel generated views with high visual quality.},
booktitle = {Proceedings of the 19th ACM SIGGRAPH European Conference on Visual Media Production},
articleno = {3},
numpages = {7},
keywords = {angular super-resolution, generative adversarial network, light field, view synthesis},
location = {London, United Kingdom},
series = {CVMP '22}
}

@inproceedings{10.1145/3651671.3651688,
author = {Xue, Bin and Zheng, Qinghua and Li, Zhinan and Zhao, Weihu and Wang, Heling and Feng, Xue},
title = {Lightweight Object Detection-Tracking using Deep Feature Distillation},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651671.3651688},
doi = {10.1145/3651671.3651688},
abstract = {Object detection and tracking are critical and fundamental problems in machine vision task. In this paper, an object detection and tracking method is proposed based on deep feature distillation. Particularly, an adaptive unsupervised Teacher-Student unified framework is developed. The Teacher module is performed by an expandable generative adversarial network mixture model. And knowledge discrepancy ranking (KDR) is designed to optimize Teacher resource allocation with the historical underlying knowledge. The Student module is developed based on a lightweight probabilistic generative model. And an unsupervised learning scheme is presented based on Gumbel-Soft sampling optimization to train jointly. A series of experiments are performed on authoritative dataset, demonstrating that the proposed method outperforms the state-of-the-art comparison methods.},
booktitle = {Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
pages = {287–291},
numpages = {5},
keywords = {Object detection, deep learning, knowledge distillation, object tracking},
location = {Shenzhen, China},
series = {ICMLC '24}
}

@inbook{10.1109/DAC18074.2021.9586239,
author = {Jin, Wentian and Chen, Liang and Sadiqbatcha, Sheriff and Peng, Shaoyi and Tan, Sheldon X.-D.},
title = {EMGraph: Fast Learning-Based Electromigration Analysis for Multi-Segment Interconnect Using Graph Convolution Networks},
year = {2022},
isbn = {9781665432740},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/DAC18074.2021.9586239},
abstract = {Electromigration (EM) becomes a major concern for VLSI circuits as the technology advances in the nanometer regime. With Korhonen equations, EM assessment for VLSI circuits remains challenged due to the increasing integrated density. VLSI multisegment interconnect trees can be naturally viewed as graphs. Based on this observation, we propose a new graph convolution network (GCN) model, which is called EMGraph considering both node and edge embedding features, to estimate the transient EM stress of interconnect trees. Compared with recently proposed generative adversarial network (GAN) based stress image-generation method, EMGraph model can learn more transferable knowledge to predict stress distributions on new graphs without retraining via inductive learning. Trained on the large dataset, the model shows less than 1.5% averaged error compared to the ground truth results and is orders of magnitude faster than both COMSOL and state-of-the-art method. It also achieves smaller model size, 4\texttimes{} accuracy and 14\texttimes{} speedup over the GAN-based method.},
booktitle = {Proceedings of the 58th Annual ACM/IEEE Design Automation Conference},
pages = {919–924},
numpages = {6}
}

@inproceedings{10.1145/3571884.3603754,
author = {Zhan, Xiao and Xu, Yifan and Sarkadi, Stefan},
title = {Deceptive AI Ecosystems: The Case of ChatGPT},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3603754},
doi = {10.1145/3571884.3603754},
abstract = {ChatGPT, an AI chatbot, has gained popularity for its capability in generating human-like responses. However, this feature carries several risks, most notably due to its deceptive behaviour such as offering users misleading or fabricated information that could further cause ethical issues. To better understand the impact of ChatGPT on our social, cultural, economic, and political interactions, it is crucial to investigate how ChatGPT operates in the real world where various societal pressures influence its development and deployment. This paper emphasizes the need to study ChatGPT "in the wild", as part of the ecosystem it is embedded in, with a strong focus on user involvement. We examine the ethical challenges stemming from ChatGPT’s deceptive human-like interactions and propose a roadmap for developing more transparent and trustworthy chatbots. Central to our approach is the importance of proactive risk assessment and user participation in shaping the future of chatbot technology.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {3},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Conversational Agents, Deceptive AI},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@inproceedings{10.1145/3531146.3533137,
author = {Cooper, A. Feder and Vidan, Gili},
title = {Making the Unaccountable Internet: The Changing Meaning of Accounting in the Early ARPANET},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533137},
doi = {10.1145/3531146.3533137},
abstract = {Contemporary concerns over the governance of technological systems often run up against narratives about the technical infeasibility of designing mechanisms for accountability. While in recent AI ethics literature these concerns have been deliberated predominantly in relation to machine learning, other instances in the history of computing also presented circumstances in which computer scientists needed to un-muddle what it means to design accountable systems. One such compelling narrative can frequently be found in canonical histories of the Internet that highlight how its original designers’ commitment to the “End-to-End” architectural principle precluded other features from being implemented, resulting in the fast-growing, generative, but ultimately unaccountable network we have today. This paper offers a critique of such technologically essentialist notions of accountability and the characterization of the “unaccountable Internet” as an unintended consequence. It explores the changing meaning of accounting and its relationship to accountability in a selected corpus of requests for comments (RFCs) concerning the early Internet’s design from the 1970s and 80s. We characterize four ways of conceptualizing accounting: as billing, as measurement, as management, and as policy, and demonstrate how an understanding of accountability was constituted through these shifting meanings. We link together the administrative and technical mechanisms of accounting for shared resources in a distributed system and an emerging notion of accountability as a social, political, and technical category, arguing that the former is constitutive of the latter. Recovering this history is not only important for understanding the processes that shaped the Internet, but also serves as a starting point for unpacking the complicated political choices that are involved in designing accountability mechanisms for other technological systems today.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {726–742},
numpages = {17},
keywords = {Accountability, Accountable systems, Accounting, Internet governance, Resource sharing},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{10.1145/3691720.3691809,
author = {Deng, Ming and Meng, Suying},
title = {Exploration and research of generative artificial intelligence on higher vocational education},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691809},
doi = {10.1145/3691720.3691809},
abstract = {Under the background of the rapid development of generative artificial intelligence, this paper deeply discusses the impact of generative artificial intelligence on higher vocational education, mainly from the following aspects. The first is the level of students, students in the knowledge acquisition, learning scene, learning experience, evaluation of the analysis; Secondly, at the level of teachers, teachers need to actively and quickly change the concept of education, shift the focus of work to ability cultivation, quality cultivation, psychological counseling, personality building, etc., to provide more emotional support for students. From the past "teacher - student" dual structure, to a new generation of learning mode, to achieve "teacher - machine - student" three-way collaborative intelligent learning state, accelerate the process of digital transformation of education. Then it discusses the risks and challenges brought by generative artificial intelligence to higher vocational education, and finally looks forward to the future of higher vocational education.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {520–525},
numpages = {6},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3631700.3664900,
author = {Portaz, Miguel and Manjarres, Angeles and Santos, Olga C.},
title = {Harmonizing Ethical Principles: Feedback Generation Approaches in Modeling Human Factors for Assisted Psychomotor Systems},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3664900},
doi = {10.1145/3631700.3664900},
abstract = {As the demand for personalized and adaptive learning experiences increase, there is a urgent need for providing effective feedback mechanisms within critical systems, such as in psychomotor learning systems. This proposal introduces an approach for the integration of retrieval-augmented generation tools to provide comprehensive and insightful feedback to users. By combining the strengths of retrieval-based techniques and generative models, these tools offer the potential to enhance learning outcomes by delivering tailored feedback that is both informative and engaging. The proposal also emphasises the importance of incorporating explainability and transparency concepts. Following the hybrid intelligence paradigm it is possible to ensure that the feedback provided by these tools is not only accurate but also understandable to humans. This approach fosters trust and promotes a deeper understanding of the psychomotor learning process, empowering users and facilitators to make informed decisions about the psychomotor learning path. The hybrid intelligence paradigm, which combines the strengths of both human and artificial intelligence, plays a crucial role in the deployment of these solutions. By taking advantage of the cognitive capabilities of human experts alongside the computational power of artificial intelligence algorithms, it is possible to offer personalised feedback that takes into account both technical accuracy and pedagogical effectiveness. Through these collaborative efforts it is also possible to create learning environments that are inclusive, adaptable, and beneficial to lifelong learning. In conclusion, this proposal introduces retrieval-augmented generation tools for providing feedback in psychomotor learning systems, which represents a significant step towards in its personalization, and whose ethical implications align with the new regulations on the implementation of intelligent technologies in critical systems.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {380–385},
numpages = {6},
keywords = {Collaborative Learning, Ethics, Human-Centered, Hybrid Intelligence, Intelligent Psychomotor Systems, Retrieval Augmented Generation, XAI},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3491102.3501825,
author = {Liu, Vivian and Chilton, Lydia B},
title = {Design Guidelines for Prompt Engineering Text-to-Image Generative Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501825},
doi = {10.1145/3491102.3501825},
abstract = {Text-to-image generative models are a new and powerful way to generate visual artwork. However, the open-ended nature of text as interaction is double-edged; while users can input anything and have access to an infinite range of generations, they also must engage in brute-force trial and error with the text prompt when the result quality is poor. We conduct a study exploring what prompt keywords and model hyperparameters can help produce coherent outputs. In particular, we study prompts structured to include subject and style keywords and investigate success and failure modes of these prompts. Our evaluation of 5493 generations over the course of five experiments spans 51 abstract and concrete subjects as well as 51 abstract and figurative styles. From this evaluation, we present design guidelines that can help people produce better outcomes from text-to-image generative models.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {384},
numpages = {23},
keywords = {AI co-creation, computational creativity, design guidelines, multimodal generative models, prompt engineering., text-to-image},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3677045.3685439,
author = {R\"{o}nnberg, Niklas and B\"{o}r\"{u}tecene, Ahmet},
title = {Use of Generative AI for Fictional Field Studies in Design Courses},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677045.3685439},
doi = {10.1145/3677045.3685439},
abstract = {In this paper, we present how we used generative AI (GenAI) as a pedagogical tool for students taking a course in tangible interaction design. In this course, the students design different physical-digital objects (PDOs) to learn designing, sketching and prototyping with code and hardware. However, due to the short course duration these PDOs are not evaluated or explored with any kind of field or user study. Therefore we gave the students the exercise of doing user interviews with GenAI to explore their design ideas further. With this paper, we contribute a description and the outcomes of this approach, and highlight the pedagogical implications for student learning.},
booktitle = {Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
articleno = {23},
numpages = {5},
keywords = {Design, Education, Field study, Generative AI, User interview},
location = {Uppsala, Sweden},
series = {NordiCHI '24 Adjunct}
}

@article{10.1109/TASLP.2023.3331096,
author = {Wang, Yile and Zhang, Yue and Li, Peng and Liu, Yang},
title = {Gradual Syntactic Label Replacement for Language Model Pre-Training},
year = {2023},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3331096},
doi = {10.1109/TASLP.2023.3331096},
abstract = {Pre-training serves as a foundation of recent NLP models, where language modeling tasks are performed over large texts. Typical models like BERT and GPT take the corpus as a whole and treat each word equally for language modeling. However, recent works show that the naturally existing frequency bias in the raw corpus may limit the power of the language model. In this article, we propose a multi-stage training strategy that gradually increases the training vocabulary by modifying the training data. Specifically, we leverage the syntactic structure as a bridge for infrequent words and replace them with the corresponding syntactic labels, then we recover their original lexical surface for further training. Such strategy results in an easy-to-hard curriculum learning process, where the model learns the most common words and some basic syntax concepts, before recognizing a large number of uncommon words via their specific usages and the previously learned category knowledge. Experimental results show that such a method can improve the performance of both discriminative and generative pre-trained language models on benchmarks and various downstream tasks.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = nov,
pages = {486–496},
numpages = {11}
}

@inproceedings{10.1145/3632634.3655852,
author = {Aladi, Clement Chimezie},
title = {IT Higher Education Teachers and Trust in AI-Enabled Ed-Tech: Implications for Adoption of AI in Higher Education},
year = {2024},
isbn = {9798400704772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632634.3655852},
doi = {10.1145/3632634.3655852},
abstract = {The integration of Artificial Intelligence (AI) in higher education encounters a myriad of inhibiting factors, notably the conspicuous absence of transparency, reliability issues, and ethical concerns. This problem has substantially impeded the assimilation of generative AI-enabled Educational Technology (Ed-Tech) within the higher education domain, unlike other fields such as finance, health, and management. The prevailing sentiment among higher education practitioners remains wavering, with differing opinions on whether to permit AI comprehensively, impose complete restrictions, or allow minimal integration into academic courses. This pilot study endeavors to elucidate the nuanced determinants influencing cognitive trust of Information Technology (IT) Higher Education instructors in AI-enabled educational Technology. The implications of this trust, or lack thereof, on the broader adoption of AI in higher education, constitute a focal point of investigation in this scholarly investigation.},
booktitle = {Proceedings of the 2024 Computers and People Research Conference},
articleno = {19},
numpages = {16},
keywords = {AI-enabled, EdTech, Educational Technology, Higher Education, Keywords: AI, Trust},
location = {Murfreesboro, TN, USA},
series = {SIGMIS-CPR '24}
}

@inproceedings{10.1145/3650212.3652142,
author = {Liu, Chenyan and Cai, Yufan and Lin, Yun and Huang, Yuhuan and Pei, Yunrui and Jiang, Bo and Yang, Ping and Dong, Jin Song and Mei, Hong},
title = {CoEdPilot: Recommending Code Edits with Learned Prior Edit Relevance, Project-wise Awareness, and Interactive Nature},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3652142},
doi = {10.1145/3650212.3652142},
abstract = {Recent years have seen the development of LLM-based code generation. Compared to generating code in a software project, incremental code edits are empirically observed to be more frequent. The emerging code editing approaches usually formulate the problem as generating an edit based on known relevant prior edits and context. However, practical code edits can be more complicated. First, an editing session can include multiple (ir)relevant edits to the code under edit. Second, the inference of the subsequent edits is non-trivial as the scope of its ripple effect can be the whole project. 
 
 
 
 
 
 
 
In this work, we propose CoEdPilot, an LLM-driven solution to recommend code edits by discriminating the relevant edits, exploring their interactive natures, and estimating its ripple effect in the project. Specifically, CoEdPilot orchestrates multiple neural transformers to identify what and how to edit in the project regarding both edit location and edit content. When a user accomplishes an edit with an optional editing description, an Subsequent Edit Analysis first reports the most relevant files in the project with what types of edits (e.g., keep, insert, and replace) can happen for each line of their code. Next, an Edit-content Generator generates concrete edit options for the lines of code, regarding its relevant prior changes reported by an Edit-dependency Analyzer. Last, both the Subsequent Edit Analysis and the Edit-content Generator capture relevant prior edits as feedback to readjust their recommendations. We train our models by collecting over 180K commits from 471 open-source projects in 5 programming languages. Our extensive experiments show that (1) CoEdPilot can well predict the edits (i.e., predicting edit location with accuracy of 70.8%-85.3%, and the edit content with exact match rate of 41.8% and BLEU4 score of 60.7); (2) CoEdPilot can well boost existing edit generators such as GRACE and CCT5 on exact match rate by 8.57% points and BLEU4 score by 18.08. Last, our user study on 18 participants with 3 editing tasks (1) shows that CoEdPilot can be effective in assisting users to edit code in comparison with Copilot, and (2) sheds light on the future improvement of the tool design. The video demonstration of our tool is available at https://sites.google.com/view/coedpilot/home.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {466–478},
numpages = {13},
keywords = {code edit generation, edit location, interaction, language model},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@inproceedings{10.1145/3614419.3644014,
author = {Wu, Chuhao and Wang, Xinyu and Carroll, John and Rajtmajer, Sarah},
title = {Reacting to Generative AI: Insights from Student and Faculty Discussions on Reddit},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644014},
doi = {10.1145/3614419.3644014},
abstract = {Generative Artificial intelligence (GenAI) such as ChatGPT has elicited strong reactions from almost all stakeholders across the education system. Education-oriented and academic social media communities provide an important venue for these stakeholders to share experiences and exchange ideas about GenAI, which is constructive for developing human-centered policies. This study examines early user reactions to GenAI, consisting of 725 Reddit threads between 06/2022 and 05/2023. Through natural language processing (NLP) and content analysis, we observe an increasingly negative sentiment in the discussion and identify six main categories of student and faculty experiences of GenAI in education. These experiences reflect concerns about academic integrity and AI’s negative impact on the values of traditional education. Our analysis also highlights the tension and burden imposed by new technologies. Our findings suggest that dialogue between stakeholders in the education community is critical and can mitigate sources of tension between students and faculty.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {103–113},
numpages = {11},
keywords = {Generative AI, Higher Education, Social Media, Topic Modeling},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@inproceedings{10.1145/3613904.3642332,
author = {Belghith, Yasmine and Mahdavi Goloujeh, Atefeh and Magerko, Brian and Long, Duri and Mcklin, Tom and Roberts, Jessica},
title = {Testing, Socializing, Exploring: Characterizing Middle Schoolers’ Approaches to and Conceptions of ChatGPT},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642332},
doi = {10.1145/3613904.3642332},
abstract = {As generative AI rapidly enters everyday life, educational interventions for teaching about AI need to cater to how young people, in particular middle schoolers who are at a critical age for reasoning skills and identity formation, conceptualize and interact with AI. We conducted nine focus groups with 24 middle school students to elicit their interests, conceptions of, and approaches to a popular generative AI tool, ChatGPT. We highlight a) personally and culturally-relevant topics to this population, b) three distinct approaches in students’ open-ended interactions with ChatGPT: AI testing-oriented, AI socializing-oriented, and content exploring-oriented, and 3) an improved understanding of youths’ conceptions and misconceptions of generative AI. While misconceptions highlight gaps in understanding what generative AI is and how it works, most learners show interest in learning about what AI is and what it can do. We discuss the implications of these conceptions for designing AI literacy interventions in museums.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {276},
numpages = {17},
keywords = {AI literacy, ChatGPT, Child-AI Interaction, Conceptions of AI, Conversational Agents (CAs), Generative AI, Informal Learning, Large Language Models (LLMs)},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3604915.3608795,
author = {Zheng, Zhi and Sun, Ying and Song, Xin and Zhu, Hengshu and Xiong, Hui},
title = {Generative Learning Plan Recommendation for Employees: A Performance-aware Reinforcement Learning Approach},
year = {2023},
isbn = {9798400702419},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604915.3608795},
doi = {10.1145/3604915.3608795},
abstract = {With the rapid development of enterprise Learning Management Systems (LMS), more and more companies are trying to build enterprise training and course learning platforms for promoting the career development of employees. Indeed, through course learning, many employees have the opportunity to improve their knowledge and skills. For these systems, a major issue is how to recommend learning plans, i.e., a set of courses arranged in the order they should be learned, that can help employees improve their work performance. Existing studies mainly focus on recommending courses that users are most likely to click on by capturing their learning preferences. However, the learning preference of employees may not be the right fit for their career development, and thus it may not necessarily mean their work performance can be improved accordingly. Furthermore, how to capture the mutual correlation and sequential effects between courses, and ensure the rationality of the generated results, is also a major challenge. To this end, in this paper, we propose the Generative Learning plAn recommenDation (GLAD) framework, which can generate personalized learning plans for employees to help them improve their work performance. Specifically, we first design a performance predictor and a rationality discriminator, which have the same transformer-based model architecture, but with totally different parameters and functionalities. In particular, the performance predictor is trained for predicting the work performance of employees based on their work profiles and historical learning records, while the rationality discriminator aims to evaluate the rationality of the generated results. Then, we design a learning plan generator based on the gated transformer and the cross-attention mechanism for learning plan generation. We calculate the weighted sum of the output from the performance predictor and the rationality discriminator as the reward, and we use Self-Critical Sequence Training (SCST) based policy gradient methods to train the generator following the Generative Adversarial Network (GAN) paradigm. Finally, extensive experiments on real-world data clearly validate the effectiveness of our GLAD framework compared with state-of-the-art baseline methods and reveal some interesting findings for talent management.},
booktitle = {Proceedings of the 17th ACM Conference on Recommender Systems},
pages = {443–454},
numpages = {12},
keywords = {generative recommendation, learning management system, reinforcement learning},
location = {Singapore, Singapore},
series = {RecSys '23}
}

@inproceedings{10.1145/3610977.3634950,
author = {Williams, Randi and Ali, Safinah and Alcantara, Ra\'{u}l and Burghleh, Tasneem and Alghowinem, Sharifa and Breazeal, Cynthia},
title = {Doodlebot: An Educational Robot for Creativity and AI Literacy},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634950},
doi = {10.1145/3610977.3634950},
abstract = {Today, Artificial Intelligence (AI) is prevalent in everyday life, with emerging technologies like AI companions, autonomous vehicles, and AI art tools poised to significantly transform the future. The development of AI curricula that shows people how AI works and what they can do with it is a powerful way to prepare everyone, and especially young learners, for an increasingly AI-driven world. Educators often employ robotic toolkits in the classroom to boost engagement and learning. However, these platforms are generally unsuitable for young learners and learners without programming expertise. Moreover, these platforms often serve as either programmable artifacts or pedagogical agents, rarely capitalizing on the opportunity to support students in both capacities. We designed Doodlebot, a mobile social robot for hands-on AI education to address these gaps. Doodlebot is an effective tool for exploring AI with grade school (K-12) students, promoting their understanding of AI concepts such as perception, representation, reasoning and generation. We begin by elaborating Doodlebot's design, highlighting its reliability, user-friendliness, and versatility. Then, we demonstrate Doodlebot's versatility through example curricula about AI character design, autonomous robotics, and generative AI accessible to young learners. Finally, we share the results of a preliminary user study with elementary school youth where we found that the physical Doodlebot platform was as effective and user-friendly as the virtual version. This work offers insights into designing interactive educational robots that can inform future AI curricula and tools.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {772–780},
numpages = {9},
keywords = {collaboration, creativity, education, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3686038.3686063,
author = {Clos, Jeremie and Chen, Yoke Yie},
title = {Investigating the Impact of Generative AI on Students and Educators: Evidence and Insights from the Literature},
year = {2024},
isbn = {9798400709890},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686038.3686063},
doi = {10.1145/3686038.3686063},
abstract = {Generative artificial intelligence (AI) has become one of the main concerns of knowledge workers due to its ability to mimic realistic human reasoning and creativity. However, this integration raises critical concerns about trust and ethics, which are crucial in shaping both the acceptance and effective utilisation of these technologies. There are many reports, articles and papers currently exploring the opportunities and challenges of LLMs in higher education from the perspective of students and educators. However, these papers often focus on specific contexts like in the UK, US or a particular institutions. In this paper, we examine the problems of generative AI in higher education from educator and student perspectives using scientometrics and text analysis to provide an overview of the research landscape, followed by a narrative review and thematic analysis of selected literature. Some findings of this work are: (1) Students and educators found different ways to use generative AI. Students focus more on using it as an assistant (revising and preparing for lectures, helping with homework) and educators as a content production assistant (writing lecture notes, personalising content). Commonalities are that both students and educators use generative AI as an accessibility aid, e.g., to rephrase sentences or explain concepts. (2) The main concerns of higher education regarding generative AI are equity in access, clarity of rules regarding usage, and job displacement.},
booktitle = {Proceedings of the Second International Symposium on Trustworthy Autonomous Systems},
articleno = {25},
numpages = {6},
location = {Austin, TX, USA},
series = {TAS '24}
}

@inproceedings{10.1145/3664934.3664945,
author = {Haq, Muhammad Zia Ul and Cao, Guangming and Abukhait, Rawan},
title = {Understanding Students'Attitudes and Behavioral Intentions Towards Using ChatGPT},
year = {2024},
isbn = {9798400716409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664934.3664945},
doi = {10.1145/3664934.3664945},
abstract = {While the release of ChatGPT has sparked heated polarized debates in the education sector, there is no academic research on students’ attitudes and behavioral intentions regarding ChatGPT usage. To fill this gap, we employed the integrated AI acceptance-avoidance model (IAAAM) to investigate the impact of positive and negative factors on students’ attitudes and intentions toward ChatGPT. Our empirical results indicate that IAAAM offers a comprehensive understanding and prediction of students’ attitudes and intentions related to ChatGPT. This study advances our conceptual and empirical understanding of students’ attitudes and intentions regarding using ChatGPT. It also provides valuable implications for education policymakers, educators, and students by highlighting the importance of maintaining a balanced approach to the use of ChatGPT.},
booktitle = {Proceedings of the 2024 9th International Conference on Information and Education Innovations},
pages = {44–50},
numpages = {7},
location = {Verbania, Italy},
series = {ICIEI '24}
}

@inproceedings{10.1145/3678726.3678745,
author = {Wu, Chih-Hung and Liou, Guang-Mei},
title = {ARCS Model for Exploring the Enhancement of Learning Motivation and Engagement through AIGC Technology in Computer Graphics Courses},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678745},
doi = {10.1145/3678726.3678745},
abstract = {The purpose of this study is to apply the Keller ARCS Motivation Model theory to the "Computer Graphics" course. In the learning process of computer graphics courses, generating images using generative AI and then modifying them is employed to arouse students' interest and enhance their learning engagement. The aim of this research is to analyze the interest generated by the course through experimental results of curriculum design. Most students show a high level of interest in the integration of generative AI into the course, while a very small minority express dislike for generating images in this manner. The findings confirm that integrating generative AI into computer graphics courses can increase student interest in learning.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {51–59},
numpages = {9},
keywords = {AIGC, ARCS, Learning Interest},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@article{10.1109/TASLP.2023.3321191,
author = {Yang, Runxuan and Peng, Yuyang and Hu, Xiaolin},
title = {A Fast High-Fidelity Source-Filter Vocoder With Lightweight Neural Modules},
year = {2023},
issue_date = {2023},
publisher = {IEEE Press},
volume = {31},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2023.3321191},
doi = {10.1109/TASLP.2023.3321191},
abstract = {The quality of raw audio waveform generated by a vocoder could affect various audio generative tasks. In recent years, the dominance of source-filter vocoders was greatly challenged by neural vocoders as the latter presents far superior synthesized audio quality. Meanwhile, neural vocoders introduced unprecedented limitations including low runtime efficiency as well as unstable pitch especially in those without explicit periodic excitation input, while these have never been a problem in source-filter vocoders. We present in this article a novel approach that takes the best from both parties. We start by an in-depth examination of every building block in WORLD – one of the best-performing source-filter vocoders based on plain signal processing algorithms, looking for ones that do not work well, and we replace them with small, lightweight and task-specific neural network models. We also rearranged the vocoding pipeline for a smoother collaboration between building blocks. Our objective and subjective evaluations demonstrate that our methods present competitive synthesized audio quality even when compared against neural vocoders at a much lower computational cost, while keeping spectral envelope acoustic feature, high pitch accuracy as in conventional source-filter vocoders.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {3362–3373},
numpages = {12}
}

@inproceedings{10.1145/3491101.3503736,
author = {Danry, Valdemar and Leong, Joanne and Pataranutaporn, Pat and Tandon, Pulkit and Liu, Yimeng and Shilkrot, Roy and Punpongsanon, Parinya and Weissman, Tsachy and Maes, Pattie and Sra, Misha},
title = {AI-Generated Characters: Putting Deepfakes to Good Use},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3503736},
doi = {10.1145/3491101.3503736},
abstract = {AI generated characters, i.e., realistic renderings of human faces, voices, and mannerisms that appear authentic to a human being [7] are made possible through advancements in generative machine learning. In addition to character creation, neural networks have recently also been used for the hyper-realistic synthesis and modification of prose, images, audio, and video data. While this technology has been most widely associated with media manipulation and the spread of misinformation, often referred to as deepfakes, it is increasingly being used for positive applications and integrated into areas ranging from entertainment, to humanitarian efforts and education. With the adaptation and usage of AI generated characters across different industries, we see a potential for significant positive applications in a variety of fields such as learning, privacy, telecommunication, art, and therapy. In this workshop, we will bring together researchers in HCI, AI, and related fields to explore the positive applications, design considerations, and ethical implications of using AI generated characters and related forms of synthetic media.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {119},
numpages = {5},
keywords = {AI, AI generated Characters, Deepfakes, Generative AI, Machine Learning},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3675812.3675843,
author = {Zhang, Wenting and Zhang, Qiaorong and Cai, Mingming and Wang, Dongqing and Zheng, Yafeng},
title = {Navigating the Application Challenges of ChatGPT in Education: Promoting Responsible Use and Minimizing Mental Risks},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675843},
doi = {10.1145/3675812.3675843},
abstract = {With the wide application of artificial intelligence, especially generative AI like ChatGPT, the era of significant transformation in education has quietly arrived. This article first explores the current applications of ChatGPT in logical learning, language learning, as well as personalized and effective teaching. It then deeply analyzes the challenges brought by the application of ChatGPT in education from three aspects: digital ethics, psychological risks for teachers and students, and educational governance. Based on its potential risks and challenges, effective measures and suggestions are proposed, including improving information literacy education, fully utilizing human-computer collaboration, and establishing clear regulations for the use of ChatGPT. These measures aim to ensure that ChatGPT can maximize its application value in the field of education while minimizing the mental risks.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {23–28},
numpages = {6},
keywords = {Application Challenges, ChatGPT, Mental Risks},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3700297.3700315,
author = {Qu, Ting and Yang, Zuguo},
title = {Overview of Artificial Intelligence Applications in Educational Research},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700315},
doi = {10.1145/3700297.3700315},
abstract = {As artificial intelligence technology evolves, the big AI model will spark a change in the education sector. Revealing the trends in the artificial intelligence application in educational research is significant for understanding the interdisciplinary research frontiers of artificial intelligence and education. This study collected data from the InCites and Web of Science through forward citations and presented new experimental results using scientometrics and visualization tools such as VOSviewer, CiteSpace, Pajek, and Scimago Graphica. It has been found that applying AI in the domain of education is currently undergoing rapid development; research power mainly comes from China, the United States, Spain, the United Kingdom and Australia. The main research hotspots include machine learning, higher education, learning analytics, and educational data mining. The important foundational and frontier literature in this field can be summarized into four themes: academic prediction and early dropout prevention, learning analytics and data mining, incremental learning, and learning performance. Both generative artificial intelligence and explainable artificial intelligence (XAI) are recent developments in the realm of education research.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {101–108},
numpages = {8},
keywords = {artificial intelligence, bibliometrics, data analytics, education, research frontiers},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3657604.3664658,
author = {Slama, Rachel and Toutziaridi, Amalia Christina and Reich, Justin},
title = {Three Paradoxes to Reconcile to Promote Safe, Fair, and Trustworthy AI in Education},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664658},
doi = {10.1145/3657604.3664658},
abstract = {Incorporating recordings of teacher-student conversations into the training of LLMs has the potential to improve AI tools. Although AI developers are encouraged to put "humans in the loop" of their AI safety protocols, educators do not typically drive the data collection or design and development processes underpinning new technologies. To gather insight into privacy concerns, the adequacy of safety procedures, and potential benefits of recording and aggregating data at scale to inform more intelligent tutors, we interviewed a pilot sample of teachers and administrators using a scenario-based, semi-structured interview protocol. Our preliminary findings reveal three "paradoxes" for the field to resolve to promote safe, fair, and trustworthy AI. We conclude with recommendations for education stakeholders to reconcile these paradoxes and advance the science of learning.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {295–299},
numpages = {5},
keywords = {education, human-centered design, responsible AI, teacher perspectives, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3643834.3661581,
author = {Chen, Qiaoyi and Liu, Siyu and Huang, Kaihui and Wang, Xingbo and Ma, Xiaojuan and Zhu, Junkai and Peng, Zhenhui},
title = {RetAssist: Facilitating Vocabulary Learners with Generative Images in Story Retelling Practices},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661581},
doi = {10.1145/3643834.3661581},
abstract = {Reading and repeatedly retelling a short story is a common and effective approach to learning the meanings and usages of target words. However, learners often struggle with comprehending, recalling, and retelling the story contexts of these target words. Inspired by the Cognitive Theory of Multimedia Learning, we propose a computational workflow to generate relevant images paired with stories. Based on the workflow, we work with learners and teachers to iteratively design an interactive vocabulary learning system named RetAssist. It can generate sentence-level images of a story to facilitate the understanding and recall of the target words in the story retelling practices. Our within-subjects study (N=24) shows that compared to a baseline system without generative images, RetAssist significantly improves learners’ fluency in expressing with target words. Participants also feel that RetAssist eases their learning workload and is more useful. We discuss insights into leveraging text-to-image generative models to support learning tasks.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2019–2036},
numpages = {18},
keywords = {Vocabulary learning, image generation, story retelling},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3606094.3606101,
author = {Vargas-Murillo, Alfonso Renato and Pari-Bedoya, Ilda Nadia Monica de la Asuncion and Guevara-Soto, Francisco de Jesus},
title = {The Ethics of AI Assisted Learning: A Systematic Literature Review on the Impacts of ChatGPT Usage in Education},
year = {2023},
isbn = {9798400700422},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3606094.3606101},
doi = {10.1145/3606094.3606101},
abstract = {This systematic literature review explores how gamification in legal education might be In recent years, ChatGPT has become a noteworthy subject in the educational field due to the popularity it gained amongst students across different levels of education all over the world, who use this technology to assess their academic homework, transforming ChatGPT in some sort of auxiliary tool that aids them with the completion of certain tasks that would take more time to complete, such as research and data comparison, to name a few examples; but this form of AI assisted learning, as it were, has also become a problematic subject. This artificial intelligence chatbot is, undeniably, a remarkable advancement in AI regarding the improvements it presents compared to other similar technologies, and it clearly paves the way for future applications not only in education, but also at a social level, in a world more driven towards the development and optimization of digital tools with the help of machine learning. Nevertheless, this sort of technology should be question ed when its application permeates deeply in the performance and development of students and their learning process, especially when taking in consideration the level of accessibility that ChatGPT has worldwide. Students should have an ethical standpoint on whether they use ChatGPT to complement their learning process and how much input is this technology having in their academic work, so they learn to use it more effectively and avoid the abuse of ChatGPT usage, in order to seize the benefits that this AI may have on education. This study's objective is to analyze the current literature around the use of ChatGPT in education, for which we conducted a Systematic Literature Review (SLR) across multiple journal databases such as Scopus, ScienceDirect, ProQuest, IEEE Xplore and ACM Digital Library.},
booktitle = {Proceedings of the 2023 8th International Conference on Distance Education and Learning},
pages = {8–13},
numpages = {6},
keywords = {Artificial Intelligence, Assisted Learning, Ethics, Systematic Literature Review},
location = {Beijing, China},
series = {ICDEL '23}
}

@article{10.1145/3487891,
author = {Aldausari, Nuha and Sowmya, Arcot and Marcus, Nadine and Mohammadi, Gelareh},
title = {Video Generative Adversarial Networks: A Review},
year = {2022},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3487891},
doi = {10.1145/3487891},
abstract = {With the increasing interest in the content creation field in multiple sectors such as media, education, and entertainment, there is an increased trend in the papers that use AI algorithms to generate content such as images, videos, audio, and text. Generative Adversarial Networks (GANs) is one of the promising models that synthesizes data samples that are similar to real data samples. While the variations of GANs models in general have been covered to some extent in several survey papers, to the best of our knowledge, this is the first paper that reviews the state-of-the-art video GANs models. This paper first categorizes GANs review papers into general GANs review papers, image GANs review papers, and special field GANs review papers such as anomaly detection, medical imaging, or cybersecurity. The paper then summarizes the main improvements in GANs that are not necessarily applied in the video domain in the first run but have been adopted in multiple video GANs variations. Then, a comprehensive review of video GANs models are provided under two main divisions based on existence of a condition. The conditional models are then further classified according to the provided condition into audio, text, video, and image. The paper concludes with the main challenges and limitations of the current video GANs models.},
journal = {ACM Comput. Surv.},
month = jan,
articleno = {30},
numpages = {25},
keywords = {Generative Adversarial Networks, video synthesis, multimodal data, conditional generation}
}

@inbook{10.1145/3640794.3665555,
author = {Sun, Xin and Teljeur, Isabelle and Li, Zhuying and Bosch, Jos A.},
title = {Can a Funny Chatbot Make a Difference? Infusing Humor into Conversational Agent for Behavioral Intervention},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665555},
abstract = {Regular physical activity is crucial for reducing the risk of non-communicable disease (NCD). With NCDs on the rise globally, there is an urgent need for effective health interventions, with chatbots emerging as a viable and cost-effective option because of limited healthcare accessibility. Although health professionals often utilize behavior change techniques (BCTs) to boost physical activity levels and enhance client engagement and motivation by affiliative humor, the efficacy of humor in chatbot-delivered interventions is not well-understood. This study conducted a randomized controlled trial to examine the impact of the generative humorous communication style in a 10-day chatbot-delivered intervention for physical activity. It further investigated whether user engagement and motivation act as mediators between the communication style and changes in physical activity levels. 66 participants engaged with the chatbots across three groups (humorous, non-humorous, and no-intervention) and responded to daily ecological momentary assessment questionnaires assessing engagement, motivation, and physical activity levels. Multilevel time series analyses revealed that an affiliative humorous communication style positively impacted physical activity levels over time, with user engagement acting as a mediator in this relationship, whereas motivation did not. These findings clarify the role of humorous communication style in chatbot-delivered interventions for physical activity, offering valuable insights for future development of intelligent conversational agents incorporating humor.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {3},
numpages = {19}
}

@article{10.1145/3589649,
author = {Zhai, Xiaoming},
title = {ChatGPT for Next Generation Science Learning},
year = {2023},
issue_date = {Spring 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {3},
issn = {1528-4972},
url = {https://doi.org/10.1145/3589649},
doi = {10.1145/3589649},
abstract = {This article pilots ChatGPT in tackling the most challenging part of science learning and found it successful in automation of assessment development, grading, learning guidance, and recommendation of learning materials.},
journal = {XRDS},
month = apr,
pages = {42–46},
numpages = {5}
}

@inproceedings{10.1145/3640543.3645213,
author = {Pillis, Daniel and Pataranutaporn, Pat and Maes, Pattie and Sra, Misha},
title = {AI Comes Out of the Closet: Using AI-Generated Virtual Characters to Help Individuals Practice LGBTQIA+ Advocacy},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645213},
doi = {10.1145/3640543.3645213},
abstract = {Despite significant historical progress, discrimination and social stigma continue to impact the lives of LGBTQIA+ individuals. The use of AI-generated virtual characters offers a unique opportunity to facilitate advocacy by engaging individuals in simulated conversations that can foster understanding, education, and empathy. This paper explores the potential of AI simulations to help individuals practice LGBTQIA+ advocacy, while also acknowledging the need for ethical considerations and addressing concerns about oversimplification or perpetuation of stereotypes. By combining technological innovation with a commitment to inclusivity, we aim to contribute to the ongoing struggle for equality in both the legal framework and the hearts and minds of the community. We present a study evaluating virtual characters driven by generative conversational AI simulating the social interactions surrounding “coming out of the closet”, a rite of passage associated with LGBTQIA+ communities. In our study, virtual characters embodied as queer individuals engage with users in a text-based conversation simulation paired with visual representations. We investigate how the interactions between the virtual characters and a user influence the user’s comfort, confidence, empathy and sympathy. The AI simulation includes distinct visual personas deployed in a series of conditions. We present findings from our deployments involving 307 users. Finally, we discuss the design implications of our work on the potential future of embodied, self-actuated and openly LGBTQIA+ intelligent agents.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {686–698},
numpages = {13},
keywords = {LGBTQIA+ · Drama Management · AI Actor · Virtual Characters · Player Modelling · Believable Characters · Choice-Based Narrative · Interactive Theatre},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@inproceedings{10.1145/3604237.3626880,
author = {Frey, Sascha Yves and Li, Kang and Nagy, Peer and Sapora, Silvia and Lu, Christopher and Zohren, Stefan and Foerster, Jakob and Calinescu, Anisoara},
title = {JAX-LOB: A GPU-Accelerated limit order book simulator to unlock large scale reinforcement learning for trading},
year = {2023},
isbn = {9798400702402},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604237.3626880},
doi = {10.1145/3604237.3626880},
abstract = {Financial exchanges across the world use limit order books (LOBs) to process orders and match trades. For research purposes it is important to have large scale efficient simulators of LOB dynamics. LOB simulators have previously been implemented in the context of agent-based models (ABMs), reinforcement learning (RL) environments, and generative models, processing order flows from historical data sets and hand-crafted agents alike. For many applications, there is a requirement for processing multiple books, either for the calibration of ABMs or for the training of RL agents. We showcase the first GPU-enabled LOB simulator designed to process thousands of books in parallel, whether for identical or different securities, with an up to 75x faster per-message processing time. The implementation of our simulator – JAX-LOB – is based on design choices that aim to best exploit the powers of JAX without compromising on the realism of LOB-related mechanisms. We integrate JAX-LOB with other JAX packages, to provide an example of how one may address an optimal execution problem with reinforcement learning, and to share some preliminary results from end-to-end RL training on GPUs. The project code is available on GitHub 1},
booktitle = {Proceedings of the Fourth ACM International Conference on AI in Finance},
pages = {583–591},
numpages = {9},
keywords = {high frequency trading, limit order books, market replay, order book simulator, reinforcement learning, trade execution},
location = {Brooklyn, NY, USA},
series = {ICAIF '23}
}

@inproceedings{10.1145/3610537.3622957,
author = {Tang, Yuying and Sun, Yuqian and Gao, Ze and Pan, Zhijun and Wang, Zhigang and Braud, Tristan and Lee, Chang Hee and Asadipour, Ali},
title = {AI N\"{u}shu (Women's scripts) - An Exploration of Language Emergence in Sisterhood},
year = {2023},
isbn = {9798400703089},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610537.3622957},
doi = {10.1145/3610537.3622957},
abstract = {This paper presents "AI N\"{u}shu," an emerging language system inspired by N\"{u}shu (women's scripts), the unique language created and used exclusively by ancient Chinese women who were illiterate under a patriarchy society. Through an interactive art installation, two artificial intelligent (AI) agents continuously observe their environment and communicate with each other, developing a writing system that encodes Chinese. In this system, two AI agents observe the environment through cameras, record the unconscious behaviors of the audience, and generate summaries of their observations through visual recognition. Subsequently, the agent associates the corresponding original N\"{u}shu poetry lines and generates new poetry text through a Language Model (LLM), representing its reflection. To develop their language, they continuously switch roles between the speaker and listener, constantly communicating their reflections, and encrypting a word in the poetry line with their self-created AI N\"{u}shu character, allowing the other to guess and learn. Gradually, they reach a consensus on AI N\"{u}shu, forming a unique "AI N\"{u}shu Dictionary" for machines. This language, algorithmically combined into corresponding characters, has components derived from N\"{u}shu, similar to Chinese characters and traditional textile patterns. Thus, like ancient women, the two agents gradually developed their Chinese writing system, corresponding one-to-one with Chinese characters. In contrast, humans, as the authority of the language system, became an object observed, interpreted, and inspired by machines to stimulate non-human language. This is the first media art project to interpret N\"{u}shu from a computational linguistics perspective, infusing AI and art research with non-English natural language processing, Chinese cultural heritage, and a feminist viewpoint. This encourages the creation of more non-English, linguistically-oriented artworks for diverse cultures. We simulate communication in sisterhood through a multi-agent learning system, which questioned knowledge authority between humans and machines through the lens of language development.},
booktitle = {SIGGRAPH Asia 2023 Art Gallery},
articleno = {4},
numpages = {2},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3638985.3638998,
author = {Krishnamurthy, Vallidevi and Rahul, Nuthalapati and C, Ponvignesh and Aashish, Sai},
title = {Pluralistic Face Completion of Masked Face based on 3D priors},
year = {2024},
isbn = {9798400709043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638985.3638998},
doi = {10.1145/3638985.3638998},
abstract = {The pluralistic face completion system is developed as a web application that generates multiple face images for a face which is covered under a face mask. The web application consists of five modules where it deals with, 1) Applying a face mask to the person’s image, 2) Removing face mask in the masked face image by generating the covered part of the face corresponding to rest of the face part with multiple outputs, 3) Checking similarity between resultant images and input images given by user, 4) Querying a person’s availability in group image and 5) Face aging module where a person of any age is given along with the desired age number, where it generates the face image of the required age of a person. The found similar person can be checked for his outlook on various angles, by rotating the person’s face. Face generation algorithms are prone to generate differentiating outputs then the ground truth image. As these algorithms generate only single output, there is a high scope these outputs not being closely matched with the original image. Hence, in this project multiple diverse output images are generated, which increases the probability of achieving the highest similarity with the original image. Masking the face is attained by using Dlib library while the rendering of the face is achieved by using Generative Adversarial Networks (GAN). The proposed project is designed such that, it solves the dependency of manually labelling missing regions of the face (i.e., mask region on the face), identifying the best matching similar face for the generated face image from the former network and identifying the person of interest in a given group image.},
booktitle = {Proceedings of the 2023 11th International Conference on Information Technology: IoT and Smart City},
pages = {77–82},
numpages = {6},
keywords = {datasets, demasking, face similarity, facemask identification, inpainting, neural networks},
location = {Kyoto, Japan},
series = {ICIT '23}
}

@inproceedings{10.5555/3523760.3523920,
author = {Pittman, Daniel E. and Haring, Kerstin S. and Kim, Pilyoung and Dossett, Benjamin and Ehman, Gillian and Gutierrez-Gutierrez, Elizabeth and Patil, Sneha and Sanchez, Ashley},
title = {A Novel Online Robot Design Research Platform to Determine Robot Mind Perception},
year = {2022},
publisher = {IEEE Press},
abstract = {A common issue in Human-Robot Interaction is a gap in understanding how robot designs are perceived by the user. A common issue encountered by practitioners of Machine Learning (ML) is a lack of salient data to use in training. The "Build-A-Bot" project is developing a novel research platform implemented as a web-accessible 3D game that affords data collection of many user-provided robot designs. The designs are used to train ML models to better evaluate robot designs, predict how a design will be perceived using Convolutional Neural Networks (CNNs), and create new robot designs using Generative Adversarial Networks (GANs). This paper outlines the current and future work accomplished by an interdisciplinary undergraduate student team at the University of Denver across Computer Science, Music, Psychology, and other related STEM fields that have created Build-A-Bot.},
booktitle = {Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {986–990},
numpages = {5},
keywords = {machine learning, fnirs, robot design},
location = {Sapporo, Hokkaido, Japan},
series = {HRI '22}
}

@inproceedings{10.1145/3612783.3612796,
author = {V\'{a}zquez-Ingelmo, Andrea and Garc\'{\i}a-Holgado, Alicia and Theron, Roberto and Shoeibi, Nastaran and Garc\'{\i}a-Pe\~{n}alvo, Francisco Jos\'{e}},
title = {Design and development of the LATILL platform for retrieving adequate texts to foster reading skills in German},
year = {2024},
isbn = {9798400707902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3612783.3612796},
doi = {10.1145/3612783.3612796},
abstract = {Reading and comprehending information in different languages is becoming increasingly important in our interconnected world. However, teaching such abilities can be challenging, and pre-packaged materials found in textbooks and readers may not always meet the needs of individual learners. To address this, the LATILL project aims to enhance the reading competencies of young Europeans by providing foreign language teachers with digital tools that enable them to select level-appropriate and engaging texts for their students. The project proposes a platform to ease the search and analysis of German literature based on specific topics and CEFR levels, along with additional tools and materials for working with authentic texts. The platform's features include generative AI in creating new elements (translations, simplifications, and generated images) and the development of text bundles, making it easier for teachers to find, share, and use appropriate materials. The initial user evaluations of the platform's prototype are promising, with the pilot users finding their features helpful and innovative.},
booktitle = {Proceedings of the XXIII International Conference on Human Computer Interaction},
articleno = {12},
numpages = {9},
location = {Lleida, Spain},
series = {Interacci\'{o}n '23}
}

@inproceedings{10.1145/3675585.3675587,
author = {Angeles, Chito Naorbe and Samson, Brylle Dimaano and Mama, Bai Rafsan Zahna Ibad and Luriaga, Ronnie Lucero and Delizo, John Pierre Demata and Ching, Michelle Renee Domingo},
title = {Students'perception of the use of AI Detector System by faculty members in determining the originality of submitted academic requirements},
year = {2024},
isbn = {9798400717659},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675585.3675587},
doi = {10.1145/3675585.3675587},
abstract = {Recent studies revealed an overwhelming concern about the misuse of generative Artificial Intelligence (AI) tools by students in completing academic requirements. The detection of AI-generated content using the naked eye was perceived to be difficult, hence the need for more accurate, reliable, and effective detection methods. As a countermeasure, educators are turning to AI content detectors and plagiarism checkers to ascertain the originality of submitted school requirements, raising concerns from students regarding the accuracy and reliability of these tools and the ethical implications and negative consequences of misclassification of genuinely original works as machine-generated outputs. By employing a holistic case study approach, the authors attempted to determine the perceptions of selected university students on the use of AI detection systems by faculty members in checking the originality and novelty of their academic outputs. Through the lenses of various normative ethical theories, the authors also analyzed the ethical issues and concerns raised by selected students to better understand their sentiments and the factors they believe could influence the faculty members' intention to adopt this emerging technology. The results of the study revealed that students have mixed attitudes and perceptions toward the faculty's intention to use AI detectors. While students perceived it as a means to encourage independent learning and critical thinking, they also expressed valid concerns regarding fairness, accuracy, and reliability, the impact on teacher-student trust, and the responsible use of the technology, among others. The participants also acknowledged the influence of other faculty members and the students' increasing dependence on AI as possible enablers of technology adoption while technological limitations, the teachers’ lack of technological skills, and age as perceived barriers. From an ethical view, the findings of the study highlighted the importance of transparency, fairness, privacy, and the need for a policy to regulate AI use.},
booktitle = {Proceedings of the 2024 8th International Conference on E-Commerce, E-Business, and E-Government},
pages = {56–61},
numpages = {6},
keywords = {AI Detectors, Ethical Theories, Generative AI, TPB},
location = {Ajman, United Arab Emirates},
series = {ICEEG '24}
}

@inproceedings{10.1145/3625704.3625748,
author = {Lim, Jiyoung and Park, Soo Kyung and Ahn, Hong Hwan and Lee, Bong Gyou},
title = {Analyzing Diverse Issues on AI Education in South Korea: Focusing on news editorials text mining},
year = {2023},
isbn = {9798400709142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625704.3625748},
doi = {10.1145/3625704.3625748},
abstract = {The emergence of ChatGPT, an AI model capable of generating text, has ignited a profound discussion regarding AI education. In order to formulate well-suited policies that effectively encompass the advancements brought about by these novel technologies, it is imperative to thoroughly examine the comprehensive societal discourse that surrounds them. However, there is a dearth of comprehensive research conducted on this subject. The primary objective of this study is to assess the current issues in AI education within the context of South Korea, scrutinize the transformative impact that has occurred following the integration of ChatGPT, and identify future tasks necessary to effectively address these advancements. To achieve this objective, LDA topic modeling was employed to analyze editorials focused on AI education subsequent to the introduction of ChatGPT, consequently leading to the identification of seven topics. Given that the education industry is presently in the process of formulating specific strategies to effectively respond to the presence of ChatGPT, the findings obtained from this study are anticipated to provide substantial insights and recommendations to inform policy-making endeavors.},
booktitle = {Proceedings of the 7th International Conference on Education and Multimedia Technology},
pages = {82–87},
numpages = {6},
keywords = {AI Education, ChatGPT, Text Mining, Topic Modeling},
location = {Tokyo, Japan},
series = {ICEMT '23}
}

@inproceedings{10.1145/3544549.3583931,
author = {Sun, Yuqian and Xu, Ying and Cheng, Chenhang and Li, Yihua and Lee, Chang Hee and Asadipour, Ali},
title = {Explore the Future Earth with Wander 2.0: AI Chatbot Driven By Knowledge-base Story Generation and Text-to-image Model},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3583931},
doi = {10.1145/3544549.3583931},
abstract = {People always envision the future of earth through science fiction (Sci-fi), so can we create a unique experience of "visiting the future earth" through the lens of artificial intelligence (AI)? We introduce Wander 2.0, an AI chatbot that co-creates sci-fi stories through knowledge-based story generation on daily communication platforms like WeChat and Discord. Using location information from Google Maps, Wander generates narrative travelogues about specific locations (e.g. Paris) through a large-scale language model (LLM). Additionally, using the large-scale text-to-image model (LTGM) Stable Diffusion, Wander transfers future scenes that match both the text description and location photo, facilitating future imagination. The project also includes a real-time visualization of the human-AI collaborations on a future map. Through journeys with visitors from all over the world, Wander demonstrates how AI can serve as a subjective interface linking fiction and reality. Our research shows that multi-modal AI systems have the potential to extend the artistic experience and creative world-building through adaptive and unique content generation for different people. Wander 2.0 is available at http://wander001.com/},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {5},
keywords = {Artificial intelligence, chatbot, design fiction, gaming, human-AI interaction, interactive fiction},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3657604.3664669,
author = {Bradford, Allison and Li, Weiying and Gerard, Libby and Linn, Marcia C.},
title = {Comparing Expert and ChatGPT-authored Guidance Prompts},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664669},
doi = {10.1145/3657604.3664669},
abstract = {Students bring a multitude of ideas and experiences to the classroom while they are reasoning about scientific phenomena. They often need timely guidance to refine build upon their initial ideas. In this study we explore the development of guidance prompts to provide students with personalized, real-time feedback in the context of a pedagogically grounded chatbot. In the current version of the tool, guidance prompts are authored by learning scientists who are experts in the content of the items and in Knowledge Integration pedagogy. When students engage with the chatbot, an idea detection model is used to determine the ideas that are present in a student explanation and then the expert-authored guidance prompts are assigned based on rules about which ideas are or are not present in the student explanation. While this approach allows for close attention to and control of the pedagogical intent of each prompt, it is time consuming and not easily generalizable. Further this rule-based approach limits the ways in which students can interact with the chatbot. The work in progress study presented in this paper explores the potential of using generative AI to create similarly pedagogically grounded guidance prompts as a first step towards increasing the generalizability and scalability of this approach. Specifically, we ask: using criteria from the Knowledge Integration Pedagogical Framework, how do ChatGPT 3.5-authored guidance prompts compare to human expert-authored guidance prompts? We find that while prompt engineering can enhance the alignment of ChatGPT-authored guidance prompts with pedagogical criteria, the human expert-authored guidance prompts more consistently meet the pedagogical criteria.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {388–392},
numpages = {5},
keywords = {automated guidance, generative AI, knowledge integration pedagogy},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3660043.3660178,
author = {Ma, Shuaiyao and Lei, Lei},
title = {Opportunities and Challenges of Generative Artificial Intelligence in Facilitating Learning for Chinese University Students},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660178},
doi = {10.1145/3660043.3660178},
abstract = {With the emergence of Artificial Intelligence in General Chat (AIGC), represented by ChatGPT, collaborative learning tasks between university students and machines have become a new norm in higher education. Simply prohibiting this new wave of technology cannot fundamentally address its challenges. This article presents the results of a survey investigating Chinese university students' perspectives on generative artificial intelligence technologies, such as ChatGPT, in supporting their learning. It analyzes the opportunities and challenges presented by this technology. Universities need to adapt to this transformation by altering the nature of student assignments and the methods of assessment. Additionally, they must effectively leverage the advantages of students conveniently acquiring knowledge through AIGC and the opportunity for personalized tutoring across various subjects. Striking the right balance between opportunities and challenges is crucial for creating a more productive and beneficial learning environment. Ultimately, this adaptation will better prepare education for the developments and changes in the era of artificial intelligence.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {756–760},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@article{10.1145/3627989,
author = {Jin, Weiqiang and Zhao, Biao and Zhang, Yu and Sun, Gege and Yu, Hang},
title = {Fintech Key-Phrase: A New Chinese Financial High-Tech Dataset Accelerating Expression-Level Information Retrieval},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {11},
issn = {2375-4699},
url = {https://doi.org/10.1145/3627989},
doi = {10.1145/3627989},
abstract = {Expression-level information extraction is a challenging task in natural language processing (NLP), which aims to retrieve crucial semantic information from linguistic documents. However, there is a lack of up-to-date data resources for accelerating expression-level information extraction, particularly in the Chinese financial high technology field. To address this gap, we introduce Fintech Key-Phrase: a human-annotated key-phrase dataset for the Chinese financial high technology domain. This dataset comprises over 12K paragraphs along with annotated domain-specific key-phrases. We extract the publicly released reports, Chinese management’s discussion and analysis (CMD&amp;A), from the renowned Chinese research data services platform (CNRDS) and then filter the reports related to high technology. The high technology key-phrases are annotated following pre-defined philosophy guidelines to ensure annotation quality. In order to better understand the limitations and challenges in the purposed dataset, we conducted comprehensive noise evaluation experiments for the Fintech Key-Phrase, including annotation consistency assessment and absolute annotation quality evaluation. To demonstrate the usefulness of our released Fintech Key-Phrase in retrieving valuable information in the Chinese financial high technology field, we evaluate its significance using several superior information retrieval systems as representative baselines and report corresponding performance statistics. Additionally, we further applied ChatGPT to the text augmentation approach of the Fintech Key-Phrase dataset. Extensive comparative experiments demonstrate that the augmented Fintech Key-Phrase dataset significantly improved the coverage and accuracy of extracting key phrases in the finance and high-tech domains. We believe that this dataset can facilitate scientific research and exploration in the Chinese financial high technology field. We have made the Fintech Key-Phrase dataset and the experimental code of the adopted baselines accessible on Github: https://github.com/albert-jin/Fintech-Key-Phrase. To encourage newcomers to participate in the financial high-tech domain information retrieval research, we have developed a series of tools, including an open website1 and corresponding real-time information retrieval APIs.2},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = nov,
articleno = {253},
numpages = {37},
keywords = {Information retrieval, expression-level information extraction, financial high technology field, Chinese management’s discussion and analysis, ChatGPT-based data augment}
}

@inproceedings{10.1145/3605098.3636113,
author = {Yang, Qin and Parasuraman, Ramviyas},
title = {Bayesian Soft Actor-Critic: A Directed Acyclic Strategy Graph Based Deep Reinforcement Learning},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636113},
doi = {10.1145/3605098.3636113},
abstract = {Adopting reasonable strategies is challenging but crucial for an intelligent agent with limited resources working in hazardous, unstructured, and dynamic environments to improve the system's utility, decrease the overall cost, and increase mission success probability. This paper proposes a novel directed acyclic strategy graph decomposition approach based on Bayesian chaining to separate an intricate policy into several simple sub-policies and organize their relationships as Bayesian strategy networks (BSN). We integrate this approach into the state-of-the-art DRL method - soft actor-critic (SAC), and build the corresponding Bayesian soft actor-critic (BSAC) model by organizing several sub-policies as a joint policy. We compare our method against the state-of-the-art deep reinforcement learning algorithms on the standard continuous control benchmarks in the OpenAI Gym environment. The results demonstrate that the promising potential of the BSAC method significantly improves training efficiency.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {646–648},
numpages = {3},
keywords = {strategy, bayesian networks, deep reinforcement learning, soft actor-critic, utility, expectation},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3658619.3658627,
author = {Kharrufa, Ahmed and Johnson, Ian},
title = {The Potential and Implications of Generative AI on HCI Education},
year = {2024},
isbn = {9798400716591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658619.3658627},
doi = {10.1145/3658619.3658627},
abstract = {Generative AI (GAI) is impacting teaching and learning directly or indirectly across a range of subjects and disciplines. As educators, we need to understand the potential and limitations of AI in HCI education and ensure our graduating HCI students are aware of the potential and limitations of AI in HCI. In this paper, we report on the main pedagogical insights gained from the inclusion of generative AI into a 10-week undergraduate module. We designed the module to encourage student experimentation with GAI models as part of the design brief requirement and planned practical sessions and discussions. Our insights are based on replies to a survey sent out to the students after completing the module. Our key findings, for HCI educators, report on the use of AI as a persona for developing project ideas and creating resources for design, and AI as a mirror for reflecting students’ understanding of key concepts and ideas and highlighting knowledge gaps. We also discuss potential pitfalls that should be considered and the need to assess students’ literacies and assumptions of GAIs as pedagogical tools. Finally, we put forward the case for educators to take the opportunities GAI presents as an educational tool and be experimental, creative, and courageous in their practice. We end with a discussion of our findings in relation to the TPACK framework in HCI.},
booktitle = {Proceedings of the 6th Annual Symposium on HCI Education},
articleno = {10},
numpages = {8},
keywords = {GAI, Gen AI, Generative AI, HCI Education, Pedagogy, TPACK},
location = {New York, NY, USA},
series = {EduCHI '24}
}

@inproceedings{10.1145/3696500.3696575,
author = {Ran, Xiaoping and zeng, yuyue},
title = {Research on the scenario application of generative artificial intelligence in ideological and political education of colleges and universities},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696500.3696575},
doi = {10.1145/3696500.3696575},
abstract = {with the rapid development of generative artificial intelligence technology, its application in the field of education is increasingly extensive. The positions outside the first classroom, such as the university network space, the campus environment and the community activities, are loose but most active and most vital, schools should take the initiative to occupy and timely implantation of ideological and political elements (hereinafter referred to as extracurricular ideological and political education). The generative artificial intelligence, represented by CHATGPT, which is embedded in the extracurricular ideological and political education work as a scientific and technological tool, is the frontier and hot spot of the current network ideological and Political Education Research, it can make the educators understand the object of education more efficiently and systematically, enrich the existing educational resources and forms, and further strengthen the effect of extra-curricular ideological and political education. The purpose of this paper is to explore how generative artificial intelligence can enhance the effectiveness, attraction and participation of extracurricular ideological and political education in colleges and universities.},
booktitle = {Proceedings of the 2024 International Conference on Big Data and Digital Management},
pages = {454–459},
numpages = {6},
location = {Shanghai, China},
series = {ICBDDM '24}
}

@inproceedings{10.1145/3613904.3642592,
author = {Tan, Mei and Subramonyam, Hari},
title = {More than Model Documentation: Uncovering Teachers' Bespoke Information Needs for Informed Classroom Integration of ChatGPT},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642592},
doi = {10.1145/3613904.3642592},
abstract = {ChatGPT has entered classrooms, circumventing typical training and vetting procedures. Unlike other educational technologies, it placed teachers in direct contact with the versatility of generative AI. Consequently, teachers are urgently tasked to assess its capabilities to inform their use of ChatGPT. However, it is unclear what support teachers have and need and whether existing documentation, such as model cards, provides adequate direction for educators in this new paradigm. By interviewing 22 middle- and high-school ELA and Social Studies teachers, we connect the discourse on AI transparency and documentation with educational technology integration, highlighting the information needs of teachers. Our findings reveal that teachers confront significant information gaps, lacking clarity on exploring ChatGPT’s capabilities for bespoke learning tasks and ensuring its fit with the needs of diverse learners. As a solution, we propose a framework for interactive model documentation that empowers teachers to navigate the interplay between pedagogical and technical knowledge.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {269},
numpages = {19},
keywords = {AI in education, chatgpt, large language models, machine learning documentation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3660043.3660172,
author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
title = {Research on the Application of AI in Personalized Education},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660172},
doi = {10.1145/3660043.3660172},
abstract = {Smart education uses advanced information technology, combined with educational theories and teaching methods, to achieve automatic, intelligent, and efficient teaching process. Personalized education represents the core content and goal of smart education because traditional classroom or remote teaching can't accurately grasp every student's individual knowledge and understanding of the content being taught. The development of artificial intelligence technology has provided technical support for smart education, particularly for personalized education. Natural language processing models such as chatGPT and knowledge graph technology have made personalized education increasingly practicable. This article describes the technological framework of smart education, its potential applications, and emphasizes the use of AI technology in personalized education. The article covers topic areas, including learning situation analysis, implementing personalized instruction, personalized teaching management.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {723–727},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3532512.3539664,
author = {Lewis, Clayton},
title = {Automatic Programming and Education},
year = {2022},
isbn = {9781450396561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532512.3539664},
doi = {10.1145/3532512.3539664},
abstract = {Automatic programming, as supported by recent language-model based AI systems, potentially allows a new approach to making computation a useful tool for learning, a goal of the Boxer project. This paper shows that the Codex system can be used to support some of the explorations in mathematics for which Boxer has been used. Virtually no knowledge of programming is required. Reflecting on the lessons from this exploration may sharpen the goals we bring to educational computing. What knowledge about computing, as distinct from the ability to creatively use computing, should learners gain?},
booktitle = {Companion Proceedings of the 6th International Conference on the Art, Science, and Engineering of Programming},
pages = {70–80},
numpages = {11},
keywords = {Boxer, automatic programming, computational literacy, education},
location = {Porto, Portugal},
series = {Programming '22}
}

@inproceedings{10.1145/3536169.3537785,
author = {Sosa, Ricardo and Gibbons, Andrew and O'Riordan, Emma and Iorangi, Keu and Crowe, Andy and Gibson, Leanne and Harris, Sam and Badenhorst, Daniel},
title = {Food for Advanced Computational Thinking: Critical and Creative Approaches to Technology at Te Kura Taurua Manurewa},
year = {2022},
isbn = {9781450393881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3536169.3537785},
doi = {10.1145/3536169.3537785},
abstract = {This paper focuses on a participatory activity that is part of an ongoing partnership formed six years ago between teachers and academics to study creative technology approaches to youth participation. By focusing on a food-based activity in an after-school maker space, we reflect on the pedagogical and methodological innovations, and the ethical and aesthetic qualities of food-based activities for participatory design. The session brought together students and teachers to form a generative dialogue around computation and automation while preparing and sharing food. The results suggest opportunities to rethink current curricular, pedagogical, and education policy strategies. Recommendations for organizers to prepare generative activities where food is used as a design material close the paper.},
booktitle = {Proceedings of the Participatory Design Conference 2022 - Volume 1},
pages = {109–119},
numpages = {11},
location = {Newcastle upon Tyne, United Kingdom},
series = {PDC '22}
}

@inproceedings{10.1145/3573051.3596191,
author = {Smolansky, Adele and Cram, Andrew and Raduescu, Corina and Zeivots, Sandris and Huber, Elaine and Kizilcec, Rene F.},
title = {Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3596191},
doi = {10.1145/3573051.3596191},
abstract = {The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {378–382},
numpages = {5},
keywords = {ChatGPT, assessment, educators, generative AI, students, survey},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3613905.3636268,
author = {Santana, Vagner Figueredo De},
title = {Challenges and Opportunities for Responsible Prompting},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636268},
doi = {10.1145/3613905.3636268},
abstract = {Generative Artificial Intelligence (GenAI) such as ChatGPT and Midjourney have garnered significant attention recently. However, responsible practices while interacting with these systems often go overlooked. This course explores the integration of responsible practices with prompt engineering. It examines key prompt engineering concepts, dissects common prompt structures, addresses some productivity misconceptions on using GenAI, underscores the enduring significance of domain knowledge, and explores their application in emerging GenAI-powered systems.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {592},
numpages = {4},
keywords = {Prompt Engineering, Prompting, Responsible AI, Responsible Computing, Responsible Technology, Trustworthy AI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3660853.3660863,
author = {McGowan, Aidan and Anderson, Neil and Smith, Christopher},
title = {The use of ChatGPT to generate Summative Feedback in Programming Assessments that is Consistent, Prompt, without Bias and Scalable},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660863},
doi = {10.1145/3660853.3660863},
abstract = {ABSTRACTThis paper explores the automated integration of ChatGPT into the feedback process for a large-scale and complex university programming assignment. It aims to explore the feasibility of using ChatGPT to facilitate prompt, efficient, and valued feedback to students. The study presents case studies illustrating the use of the ChatGPT API in generating feedback through an automated tool (AutoFeed) developed by the researchers. The findings report on the advantages as well as the limitations of employing Prompt Engineering for this purpose.},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {39–43},
numpages = {5},
keywords = {ChatGPT, Gen Ai, Programming,university,lab,feedback},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

@article{10.1145/3592762,
author = {Opipari, Anthony and Pavlasek, Jana and Chen, Chao and Wang, Shoutian and Desingh, Karthik and Jenkins, Odest Chadwicke},
title = {DNBP: Differentiable Nonparametric Belief Propagation},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {1},
url = {https://doi.org/10.1145/3592762},
doi = {10.1145/3592762},
abstract = {We present a differentiable approach to learn the probabilistic factors used for inference by a nonparametric belief propagation algorithm. Existing nonparametric belief propagation methods rely on domain-specific features encoded in the probabilistic factors of a graphical model. In this work, we replace each crafted factor with a differentiable neural network, enabling the factors to be learned using an efficient optimization routine from labeled data. By combining differentiable neural networks with an efficient belief propagation algorithm, our method learns to maintain a set of marginal posterior samples using end-to-end training. We evaluate our differentiable nonparametric belief propagation (DNBP) method on a set of articulated pose tracking tasks and compare performance with learned baselines. Results from these experiments demonstrate the effectiveness of using learned factors for tracking and suggest the practical advantage over hand-crafted approaches. The project webpage is available at: .Problem statementNonparametric belief propagation (NBP) algorithms are a form of generative probabilistic inference that have proven effective for inference in visual perception tasks such as human pose tracking and articulated object tracking in robotic perception. The adaptability of NBP algorithms to new applications, however, is limited by the need to define hand-crafted functions that describe the distinct statistical relationships in a particular dataset. Current methods that utilize NBP rely on extensive domain knowledge to parameterize these relationships. Reducing the domain knowledge required by NBP methods would enable their use in a broader range of applications.MethodsA method is developed that combines the robustness of generative probabilistic inference with the speed, recall power, and general adaptability of discriminative neural networks. Inspired by differentiable Bayesian filters and the pull message passing for nonparametric belief propagation algorithm, a differentiable nonparametric belief propagation algorithm is proposed that performs end-to-end learning of each probabilistic factor required for graphical model inference.ResultsThe effectiveness of DNBP is demonstrated on two simulated articulated tracking tasks and on a real-world hand pose tracking task in noisy environments. An analysis of the learned probabilistic factors and resulting tracking performance is used to validate the approach.SignificanceThe results show that DNBP can leverage the graph structure to report uncertainty about its estimates while significantly reducing the need for prior domain knowledge required by previous NBP methods. This indicates that DNBP has the potential to be successfully applied to robotic perception tasks, where maintaining a notion of uncertainty throughout the inference is beneficial.},
journal = {ACM / IMS J. Data Sci.},
month = jan,
articleno = {3},
numpages = {24},
keywords = {Belief propagation, bayesian inference, nonparametric inference, robotic perception}
}

@inproceedings{10.1145/3563359.3596996,
author = {Murgia, Emiliana and Pera, Maria Soledad and Landoni, Monica and Huibers, Theo},
title = {Children on ChatGPT Readability in an Educational Context: Myth or Opportunity?},
year = {2023},
isbn = {9781450398916},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563359.3596996},
doi = {10.1145/3563359.3596996},
abstract = {In this work, we present the results of a preliminary exploration aiming to understand whether the use of ChatGPT in an educational context can be an asset to meet the specific needs of the students. In particular, we focus on the possibility of adapting the responses to online inquiries related to the primary school curriculum to meet the expectations of readers with different literacy levels. The analysis of feedback elicited from children (9- to 10-year-olds) in three 4th grade classrooms indicates that ChatGPT can adapt its responses to the 4th grade level. However, it still needs improvement to reach the right level of readability. Outcomes from this work can inspire future research directions involving technologies like ChatGPT to adapt learning paths to suit a broad range of students with varied cognitive skills. The potential of such tools to support teachers in their effort to adapt to individual learning needs is still to be fully exploited.},
booktitle = {Adjunct Proceedings of the 31st ACM Conference on User Modeling, Adaptation and Personalization},
pages = {311–316},
numpages = {6},
keywords = {ChatGPT, children, education, personalization},
location = {Limassol, Cyprus},
series = {UMAP '23 Adjunct}
}

@inproceedings{10.1145/3613905.3636273,
author = {Grudin, Jonathan and Brinkman, Donald},
title = {HCI History and the Trajectory to Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3636273},
doi = {10.1145/3613905.3636273},
abstract = {This course examines HCI history broadly, then conversational AI history from ELIZA to generative AI. A study of an LLM predecessor illuminates possibilities. With rapid change comes rising uncertainty. Not all history is relevant, but unchanging human nature abides. Some digital dreams become digital nightmares. Social media can deliver disinformation, malware, negative self-image, and polarization that undermines communities. Generative AI provides value but raises employment and career questions, education challenges, and empowers bad actors. We benefit from understanding the forces, the trajectories that brought us here, and how unanticipated consequences arose. Past events that shaped the present have become evident.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {3},
keywords = {Conversational Agents, Design, Future, Generative AI, HCI, History, Human Factors, Information Science, Information Systems},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3615335.3623035,
author = {York, Eric},
title = {Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy},
year = {2023},
isbn = {9798400703362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615335.3623035},
doi = {10.1145/3615335.3623035},
abstract = {The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\"{\i}vely and sometimes in more sophisticated ways, to complete beginner-level and advanced projects. The report evaluates how ChatGPT performs across three categories of prompts (brainstorming, design, and coding) and assesses the quality of the outputs in order to inform the research design of a larger, ongoing interdisciplinary study in its initial phases and to document the results for instructors or senior members of design and development teams to aid them in assessing the fitness of generative AI for user experience design and web development production.},
booktitle = {Proceedings of the 41st ACM International Conference on Design of Communication},
pages = {197–201},
numpages = {5},
keywords = {Artificial Intelligence, Pedagogy, User experience (UX) design, Web development},
location = {Orlando, FL, USA},
series = {SIGDOC '23}
}

@inproceedings{10.1145/3641235.3664438,
author = {Kicklighter, Caleb and Seo, Jinsil Hwaryoung and Andreassen, Mayet and Bujnoch, Emily},
title = {Empowering Creativity with Generative AI in Digital Art Education},
year = {2024},
isbn = {9798400705175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641235.3664438},
doi = {10.1145/3641235.3664438},
abstract = {Artificial intelligence is dramatically changing the creative process for many practices. We see this as an opportunity to enrich student projects within our classroom. We created educational materials and conducted an initial study in the Fall of 2023. The study focuses on the impact that image-based generative AI tools could have on the creative process for students in the 3D Animation classroom. We found that, within our class, most students found AI useful for their productivity, but further work was needed to educate students and to create a safe space for students to explore how these tools can enhance their creative work.},
booktitle = {ACM SIGGRAPH 2024 Educator's Forum},
articleno = {13},
numpages = {2},
keywords = {3D Animation Education, Concept Development, Creativity, Generative AI, Iteration, Undergraduate Digital Art Education},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3655693.3655703,
author = {Memmesheimer, Pascal and Machmeier, Stefan and Heuveline, Vincent},
title = {Increasing Detection Rate for Imbalanced Malicious Traffic using Generative Adversarial Networks},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3655693.3655703},
doi = {10.1145/3655693.3655703},
abstract = {Intrusion Detection and Prevention Systems aim to detect and prevent malicious activity or policy violations. Anomaly-based models like autoencoders or neural networks have become prominent because they do not rely on pre-defined signatures. In this study, we leverage the generative abilities of a Wasserstein Generative Adversarial Network + Gradient Penalty (WGAN-GP) to create anomalies to combat class imbalance artificially. We compare its performance on the CSE-CIC-IDS2018 data set from the Canadian Institute for Cybersecurity Intrusion Detection System (CIC-IDS) with two other anomaly-based models and one discriminative model. Our model Data-Imbalanced Aware XGBoost (DIAX) excels with an F1 score of 96.90% that shows great performance to combat class imbalances. Additionally, we conduct a detailed analysis using SHapley Additive exPlanations (SHAP) to interpret predictions of the best-performing model. Lastly, we argue that SHAP can help in the task of dimensionality reduction for classifiers.},
booktitle = {Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
pages = {74–81},
numpages = {8},
keywords = {IDS, SHAP, WGAN-GP, XGBoost, anomaly detection, dimensionality reduction, explainability},
location = {Xanthi, Greece},
series = {EICC '24}
}

@inproceedings{10.1145/3589335.3651511,
author = {Guan, Quanlong and Yu, Yanchong and Huang, Xiujie and Fang, Liangda and He, Chaobo and Wu, Lusheng and Luo, Weiqi and Chen, Guanliang},
title = {Generating Privacy-preserving Educational Data Records with Diffusion Model},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651511},
doi = {10.1145/3589335.3651511},
abstract = {Educational Data Records (EDR) are crucial for capturing teaching behavior and student information, forming the basis for achieving educational intelligence. However, ensuring educational privacy has become a pressing concern, posing practical challenges to the use and sharing of educational data. To address the issue of EDR privacy preserving, we present EduSyn, a privacy data release scheme that utilizes generative diffusion models and differential privacy methods. Specifically, we adopt a diffusion modeling scheme that can be applied to both discrete and continuous types of data to accommodate the data characteristics of EDR, while an invariant Post Randomization (PRAM) perturbation method that satisfies local differential privacy is applied for data attributes that need to be specially protected before model training. We conduct comprehensive validation of this scheme within the domain of education applications, showcasing that EduSyn generates a superior private EDR dataset compared to similar generative methods and strikes a better privacy-utility trade-off.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {806–809},
numpages = {4},
keywords = {data generation, differential privacy, diffusion model, educational data records},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3632860,
author = {Patton, Noah and Rahmani, Kia and Missula, Meghana and Biswas, Joydeep and Dillig, I\c{s}\i{}l},
title = {Programming-by-Demonstration for Long-Horizon Robot Tasks},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {POPL},
url = {https://doi.org/10.1145/3632860},
doi = {10.1145/3632860},
abstract = {The goal of programmatic Learning from Demonstration (LfD) is to learn a policy in a programming language that can be used to control a robot’s behavior from a set of user demonstrations. This paper presents a new programmatic LfD algorithm that targets long-horizon robot tasks which require synthesizing programs with complex control flow structures, including nested loops with multiple conditionals. Our proposed method first learns a program sketch that captures the target program’s control flow and then completes this sketch using an LLM-guided search procedure that incorporates a novel technique for proving unrealizability of programming-by-demonstration problems. We have implemented our approach in a new tool called PROLEX and present the results of a comprehensive experimental evaluation on 120 benchmarks involving complex tasks and environments. We show that, given a 120 second time limit, PROLEX can find a program consistent with the demonstrations in 80% of the cases. Furthermore, for 81% of the tasks for which a solution is returned, PROLEX is able to find the ground truth program with just one demonstration. In comparison, CVC5, a syntax-guided synthesis tool, is only able to solve 25% of the cases even when given the ground truth program sketch, and an LLM-based approach, GPT-Synth, is unable to solve any of the tasks due to the environment complexity.},
journal = {Proc. ACM Program. Lang.},
month = jan,
articleno = {18},
numpages = {34},
keywords = {Abstract Interpretation, Learning from Demonstrations, Program Synthesis}
}

@inproceedings{10.1145/3623509.3633394,
author = {Han, Kuntong and Tang, Keyang and Wang, Meng},
title = {Tangible Diffusion: Exploring Artwork Generation via Tangible Elements and AI Generative Models in Arts and Design Education},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633394},
doi = {10.1145/3623509.3633394},
abstract = {Generative models have revolutionized the field of art and design, providing an emerging and accessible approach to creating diverse artwork. However, effectively utilizing these models still requires significant expertise, making the system inaccessible to novice users, such as young children. This paper introduces a novel approach to artwork generation, combining tangible elements with AI generative models, resulting in a more engaging and immersive learning experience. With materials prepared by teachers, students can easily create digital artwork by manipulating tangible building blocks. The experiments demonstrate that the proposed pipeline can be applied to various scenarios, using either off-the-shelf or carefully designed tangible elements. This approach provides an interdisciplinary learning platform for arts and design education, fostering creativity and exploration of various art styles and design topics.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {46},
numpages = {13},
location = {Cork, Ireland},
series = {TEI '24}
}

@inproceedings{10.1145/3583780.3615317,
author = {Shah, Chirag},
title = {Generative AI and the Future of Information Access},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615317},
doi = {10.1145/3583780.3615317},
abstract = {The prominent model of retrieving, evaluating, and using relevant information from databases, collections, and the web is going through a significant transformation. This is largely due to wide-scale availability of various generative AI systems that can take in natural language inputs and generate highly customized natural language text, images, audio, and videos. This transformation in how people seek and access information will have profound impacts on users, developers, and policymakers. It is already changing many sectors including education, health, and commerce. But the hopes and hypes of generative AI are often not clear as we get swept up by either the current capabilities and limitations of this technology in the short term or fear from speculative future in the long term. Instead, I believe we need to approach this area pragmatically and with scientific curiosity, scholarly rigor, and societal responsibility. In this talk, I will highlight some of the opportunities and challenges for information access stemming from recent advancements in generative AI. For instance, there are new possibilities now for addressing accessibility, low-resource domains, and bias in training data using generative AI tools. On the other hand, there are new challenges concerning hallucination, toxicity, and information provenance. It is clear that we want to benefit from what AI systems are capable of, but how do we do that while curbing some of these problems? I will argue that the solution is multifaceted and complex -- some will require technical advancements and others will call for policy changes. We will need to not only build information systems with fairness, transparency, and accountability in mind, but also train a new generation of developers, policymakers, and of course the users. The goal here is to cut through both hype and fear and think pragmatically about the future of information access.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {3},
numpages = {1},
keywords = {generative AI, information access},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3661904.3661918,
author = {Rosales, Bob Kyle Labajo and Munar, Katherin Claire Bodomo and Tulod, Charlette Vibar and Rama, Jurydel Gabunada and Laviste, Ralph Pepe},
title = {SPringBoard:AI-powered Ideation System for Technopreneurship},
year = {2024},
isbn = {9798400717895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661904.3661918},
doi = {10.1145/3661904.3661918},
abstract = {This research introduces “SPringBoard”, a web-based application developed at the Wildcat Innovation Labs (WIL) of Cebu Institute of Technology – University. The application is designed to advance Technopreneurship among students and assist mentors in guiding them. SPringBoard employs AI, specifically integrating ChatGPT-4, to validate and monitor innovative ideas. It provides a systematic, phased progression in innovation, focusing on three lenses: customer-driven desirability, practical feasibility, and thorough viability assessment. The research aims to address the limitations of traditional idea validation methods by leveraging the capabilities of ChatGPT-4. The application provides comprehensive reports that pinpoint the strengths and weaknesses of proposed ideas, coupled with tailored recommendations for enhancement. This demonstrated its utility in aiding both students in refining their ideas and mentors in providing effective guidance. Specific improvements observed in the students’ ideas and the mentors’ guidance are discussed. The expected outcomes of this research include specific insights from the ChatGPT model in assessing the three lenses of innovation. These insights will contribute to the field of Technopreneurship by providing valuable information about the model's performance and potential as a tool for idea validation. Overall, this study represents a significant stride in linking academic theories with practical market applications. It provides a robust framework for the evaluation and mentorship of technopreneurial projects.},
booktitle = {Proceedings of the 2024 10th International Conference on Education and Training Technologies},
pages = {165–171},
numpages = {7},
location = {Macau, China},
series = {ICETT '24}
}

@inproceedings{10.1145/3660853.3660923,
author = {Sar, Ayan and Joshi, Purvika and Sati, Subhangi and Choudhary, Richa and Aich, Sumit and Choudhury, Tanupriya and Kotecha, Ketan and Ozseven, Turgut},
title = {A Novel End-to-End Framework for Story Generation Using Deep Neural Networks},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660923},
doi = {10.1145/3660853.3660923},
abstract = {This paper introduces a novel end-to-end framework for story generation utilising deep neural networks. Generating text belongs to a vital part of Natural Language Processing (henceforth, NLP), and different areas of its applications, including creative writing, entertainment, and education, made it a subject of this research interest. Traditional approaches often involve multi-step pipelines, leading to challenges in coherence and creativity. Our method, in contrast, makes use of deep neural network techniques to craft one story in one single process where all the building blocks connect in a coherent narrative. We provide an overview of deep learning techniques in NLP and highlight the advantages of end-to-end learning approaches. The architecture harnesses the latest available technology for neural network design with a primary focus on generative story writing. We discuss the importance of high-quality datasets and efficient preprocessing techniques to train robust models. Findings have been complimented by methods of evaluation metrics aimed at assessing story quality and coherency. Through case studies and applications, we demonstrate the effectiveness of our framework in various domains, including creative industries and education. Finally, we discuss future directions and challenges, outlining opportunities for advancing the field of story generation using deep neural networks.},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {246–253},
numpages = {8},
keywords = {Generative Models, Language Modeling, Narrative Generation, Neural Text Generation, Sequence-to-sequence Models, Textual Creativity, and Natural Language Understanding (NLU)},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

@inproceedings{10.1145/3587399.3587462,
author = {Piccolo, Lara and Buzzo, Daniel and Knobel, Martin and Gunasekera, Prasanna and Papathoma, Tina},
title = {Interaction Design as Project-Based Learning: Perspectives for Unsolved Challenges},
year = {2023},
isbn = {9798400707377},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587399.3587462},
doi = {10.1145/3587399.3587462},
abstract = {Project-based learning (PBL) is an educational approach that actively involves students in tackling real-world complex problems in an interdisciplinary way, emphasising critical thinking, collaboration and problem-solving skills. In this paper, we share our empirical experience of teaching three different modules of an Interaction Design program: Screen Design, Generative Design and Experience and Behaviour Design within the context of Project-Based Learning. We report on what we consider successful cases, as well as significant barriers encountered by the students. We then discuss some of the unsolved challenges, providing our perspectives for teaching interaction design with PBL.},
booktitle = {Proceedings of the 5th Annual Symposium on HCI Education},
pages = {59–67},
numpages = {9},
keywords = {HCI Education, Interaction design, Project-based learning},
location = {Hamburg, Germany},
series = {EduCHI '23}
}

@inproceedings{10.1145/3631700.3665231,
author = {Domenichini, Diana and Chiarello, Filippo and Giordano, Vito and Fantoni, Gualtiero},
title = {LLMs for Knowledge Modeling: NLP Approach to Constructing User Knowledge Models for Personalized Education},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665231},
doi = {10.1145/3631700.3665231},
abstract = {This study proposes a method for developing a user knowledge model based on their past learning experiences. The focus is on analyzing academic data, particularly lesson records, to extract information about educational concepts. The ultimate goal is to construct a comprehensive profile that reflects the user’s accumulated knowledge throughout their learning journey. Two distinct methods are introduced for concept extraction: a gazetteer-based Named Entity Recognition approach and prompt engineering using ChatGPT. The effectiveness of these methods is assessed through a case study involving a graduate student at the University of Pisa. These knowledge profiles hold significant relevance in today’s educational landscape. With the prevalence of lifelong learning, individuals from diverse academic backgrounds participate in professional development courses. This diversity in past learning experiences can pose a challenge for instructors and course designers who must adapt lessons to be understandable and engaging for an audience with heterogeneous knowledge bases. The analysis of academic data offers a systematic approach to modeling each individual’s acquired knowledge. This, in turn, facilitates the personalization of learning content and pathways based on students’ unique learning experiences. The outcome is an inclusive learning environment that caters to the specific needs of each participant, thereby promoting compelling and stimulating learning experiences.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {576–583},
numpages = {8},
keywords = {Information Extraction, Large Language Model, Name Entity Recognition, Personalized Learning, Prompt Engineering ChatGPT, User Knowledge Model, User Modeling},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3610978.3640559,
author = {Verhelst, Eva and Janssens, Ruben and Demeester, Thomas and Belpaeme, Tony},
title = {Adaptive Second Language Tutoring Using Generative AI and a Social Robot},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640559},
doi = {10.1145/3610978.3640559},
abstract = {The most effective second language learning occurs through extensive interpersonal interaction and tutoring. However, limited funding and a lack of language teachers often prevent students from engaging in individualised practice, a lack which can be addressed using AI and social robots. We present a system that leverages generative AI to provide customized educational content in real-time, adapting to students' skills through an engaging, visually-grounded game played alongside a social robot. To test effectiveness, we conducted a study in which Dutch high school students learned Spanish vocabulary either with or without the robot present. Results showed significant vocabulary gains regardless of robot presence, indicating the game itself, not the social embodiment, drove learning. While further refinements are needed, these findings highlight the potential for generative AI to deliver personalized language tutoring and circumvent the constraints posed by limited resources and staffing in schools. Ongoing work aims to enhance social presence and better align generative content with individuals' abilities and pacing.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1080–1084},
numpages = {5},
keywords = {generative AI, natural language processing, robot-assisted language learning, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3573051.3593399,
author = {Anastasopoulos, Ioannis and Sheel, Shreya and Pardos, Zachary and Bhandari, Shreya},
title = {Introducing an Open-source Adaptive Tutoring System to Accelerate Learning Sciences Experimentation},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3593399},
doi = {10.1145/3573051.3593399},
abstract = {Learning @ Scale has embraced movements that spread access to education through open and free platforms of learning. In this tutorial, we introduce OATutor (recently published at CHI'23), the field's first free and open-source adaptive tutoring system based on ITS principles and designed for rapid experimentation. The MIT-licensed platform can be deployed to git-pages in only a few clicks and supports BKT mastery-based adaptive problem selection. We demonstrate how the system can be used to rapidly run A/B experiments, analyze the data, and publish the entire tutor, content, and analysis scripts to facilitate unprecedented ease of replication and transparency, as demonstrated in a recent study comparing ChatGPT generated hints to human-tutor hints. Our four-part tutorial will include how to add lessons to the system and link to them from assignments in a MOOC platform or LMS via LTI. The structured JSON format of the four CC BY courses worth of content released with OATutor opens up avenues for researchers to apply new and existing educational data mining and NLP techniques (e.g., KC tagging) and rapidly evaluate the impact of subsequent changes on learners.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {251–253},
numpages = {3},
keywords = {A/B testing, HCI, authoring, creative commons, intelligent tutoring systems},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3625704.3625732,
author = {Yang, Jie},
title = {The impacts and responses of ChatGPT on education},
year = {2023},
isbn = {9798400709142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625704.3625732},
doi = {10.1145/3625704.3625732},
abstract = {Abstract: The emergence of intelligent chatbots represented by ChatGPT has aroused great attention and heated discussions in the education circles, and the public has also expressed their views on the impacts of ChatGPT on education on social platforms. Using the technology of web crawler collection, the re-searcher collected relevant public opinion on social platforms such as Weibo, and analyzed the data based on the content analysis method. The results show that the discussion of ChatGPT and education includes three aspects: the three elements of education, the purpose of education, and the human-machine relationship arising from artificial intelligence. Education in the era of artificial intelligence should return to the original intention of education, adhere to digital ethics, and move towards human-machine cooperation and symbiosis.},
booktitle = {Proceedings of the 7th International Conference on Education and Multimedia Technology},
pages = {69–73},
numpages = {5},
keywords = {ChatGPT, Education, Public opinion, web crawler technology},
location = {Tokyo, Japan},
series = {ICEMT '23}
}

@inproceedings{10.1145/3669754.3669806,
author = {Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan},
title = {Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669806},
doi = {10.1145/3669754.3669806},
abstract = {Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {339–344},
numpages = {6},
keywords = {ChatGPT, PLS-SEM, education, generative AI, programming},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@article{10.1145/3670691,
author = {Mcintosh, Timothy R. and Liu, Tong and Susnjak, Teo and Watters, Paul and Halgamuge, Malka N.},
title = {A Reasoning and Value Alignment Test to Assess Advanced GPT Reasoning},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {2160-6455},
url = {https://doi.org/10.1145/3670691},
doi = {10.1145/3670691},
abstract = {In response to diverse perspectives on artificial general intelligence (AGI), ranging from potential safety and ethical concerns to more extreme views about the threats it poses to humanity, this research presents a generic method to gauge the reasoning capabilities of artificial intelligence (AI) models as a foundational step in evaluating safety measures. Recognizing that AI reasoning measures cannot be wholly automated, due to factors such as cultural complexity, we conducted an extensive examination of five commercial generative pre-trained transformers (GPTs), focusing on their comprehension and interpretation of culturally intricate contexts. Utilizing our novel “Reasoning and Value Alignment Test,” we assessed the GPT models’ ability to reason in complex situations and grasp local cultural subtleties. Our findings have indicated that, although the models have exhibited high levels of human-like reasoning, significant limitations remained, especially concerning the interpretation of cultural contexts. This article also explored potential applications and use-cases of our Test, underlining its significance in AI training, ethics compliance, sensitivity auditing, and AI-driven cultural consultation. We concluded by emphasizing its broader implications in the AGI domain, highlighting the necessity for interdisciplinary approaches, wider accessibility to various GPT models, and a profound understanding of the interplay between GPT reasoning and cultural sensitivity.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = aug,
articleno = {17},
numpages = {37},
keywords = {Large language model (LLM), cultural sensitivity, reasoning and value alignment test, AI training and assessment, cross-cultural AI applications, AI model limitations}
}

@inproceedings{10.1145/3644713.3644797,
author = {Shakib Kotamjani, Sedigheh and Shirinova, Sojida and Fahimirad, Mehrnaz},
title = {Lecturers perceptions of using Artificial Intelligence in Tertiary Education in Uzbekistan},
year = {2024},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644713.3644797},
doi = {10.1145/3644713.3644797},
abstract = {Artificial intelligence (AI) has revolutionized different aspects of society, including higher education. This paper investigates faculty members' perceptions of using artificial intelligence, chatbots, and generative AI in teaching and learning in Uzbeki's higher education contexts. The researchers employed a qualitative study using semi-structured interviews to collect the data. Purposeful sampling was employed to select participants in this study, and the interviews were conducted face-to-face at the university campus. The study's underlying theory is the Unified Theory of Acceptance and Use of Technology (UTAUT) model, including effort expectancy, performance expectancy, social influence, and facilitating conditions, which were employed as a lens to direct the research. The data were transcribed and analyzed using the deductive approach for the thematic analysis. The findings revealed that lecturers have a positive attitude to adopt and use AI for content creation, assessment and feedback, and doing research in their institution. Some instructors may see it as a valuable tool for generating creative content and aiding student learning. In contrast, others may have concerns about its potential to replace human creativity or biases in generated materials. Lecturers also view AI as a technology to achieve accessibility and equity after overcoming the challenges. Findings revealed that some measurements should be taken about the facilitating conditions and the perceived risks of using AI.},
booktitle = {Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
pages = {570–578},
numpages = {9},
location = {Dubai, United Arab Emirates},
series = {ICFNDS '23}
}

@inproceedings{10.1145/3610977.3638459,
author = {Calo, Ryan},
title = {Social-Digital Vulnerability},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3638459},
doi = {10.1145/3610977.3638459},
abstract = {This talk describes the phenomenon of socio-digital vulnerability (SDV). SDV refers to the susceptibility of individuals and groups within mediated environments to decisional, social, or constitutive interference. Drawing from work in law and design, Professor Calo uses dark patterns, robots, generative artificial intelligence, and other examples to evidence he problem of SDV; he argues that vulnerability in mediated environments is best under in context, rather than as a binary; and he suggests policy frameworks that go behind harm mitigation to address the power imbalances that underpin SDV.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {3},
numpages = {1},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3663649.3664375,
author = {Yang, Jun and Gilad, Amir and Hu, Yihao and Meng, Hanze and Miao, Zhengjie and Roy, Sudeepa and Stephens-Martinez, Kristin},
title = {What Teaching Databases Taught Us about Researching Databases: Extended Talk Abstract},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664375},
doi = {10.1145/3663649.3664375},
abstract = {Declarative querying is a cornerstone of the success and longevity of database systems, yet it is challenging for novice learners accustomed to different coding paradigms. The transition is further hampered by a lack of query debugging tools compared to the plethora available for programming languages. The paper samples several systems that we build at Duke University to help students learn and debug database queries. These systems have not only helped scale up teaching and improve learning, but also inspired interesting research on databases. Furthermore, with the rise of generative AI, we argue that there is a heightened need for skills in scrutinizing and debugging AI-generated queries, and we outline several ongoing and future work directions aimed at addressing this challenge.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {1–6},
numpages = {6},
keywords = {Database Education, Query Debugging, Query Verification, Relational Algebra, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3585088.3593867,
author = {Han, Ariel and Cai, Zhenyao},
title = {Design implications of generative AI systems for visual storytelling for young learners},
year = {2023},
isbn = {9798400701313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585088.3593867},
doi = {10.1145/3585088.3593867},
abstract = {The study examines the design implications of leveraging generative AI tools such as ChatGPT, Stable Diffusion, Midjourney for literacy development and creative expression for children [6, 8, 18]. We sought to elicit insights on the applicability of generative AI for educational purposes from various stakeholders (i.e., parents, teachers, and AI researchers). We recruited nine participants to elicit their perspectives on designing a visual narrative app with generative AI. We examined the opportunities and limitations of the current generative AI tools. Using the implications from our evaluation, we propose AIStory, an AI-powered visual storytelling application prototype that can be used for children’s creative expression, storytelling, and literacy development.},
booktitle = {Proceedings of the 22nd Annual ACM Interaction Design and Children Conference},
pages = {470–474},
numpages = {5},
keywords = {AI for education, AI literacy, Creativity, Storytelling},
location = {Chicago, IL, USA},
series = {IDC '23}
}

@inproceedings{10.1145/3675812.3675877,
author = {Huang, Lei and Liu, Xiyu and Xie, Chunqiu and Zhu, Wenjuan},
title = {Investigating Factors Influencing University Students' Use of intelligent Audio Reading Platform for Reading and Learning},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675877},
doi = {10.1145/3675812.3675877},
abstract = {In recent years, with the rapid development of information technology and advances in smart technologies, the modes of reading have become more diversified. It is now possible not only to read books with one's eyes but also to "listen" to them, offering the better reading experience. University students need to constantly absorb information and knowledge from the outside world, which means that they need an efficient and easy way to read and learn, and the use of intelligent audio reading platform can fulfill this need. Therefore, in order to propose strategies to promote university students' use of intelligent audio reading platforms for reading and learning, this study employs a questionnaire survey to investigate the factors influencing university students' behavioral intention to use audio reading platform for reading and learning. A sample of 236 university students was analyzed using the Partial Least Squares Structural Equation Modelling technique (PLS-SEM). Results showed that perceived usefulness, perceived ease of use, and social influence have a significant positive influence on the behavioral intention of university students to use audio reading platform for reading and learning, while perceived cost and perceived enjoyment have no significant influence on the behavioral intention. Based on these results, this study proposes strategies for university teachers, intelligent audio reading platform developers and operators to promote university students’ use of intelligent audio reading platform for reading and learning. For university teachers, they can promote the adoption of audio reading by guiding students to use audio reading platforms for learning. For developers of an intelligent audio reading platform, based on generative AI, they can enhance reading and learning experience for university students by optimizing personalized recommendation functions and offering diverse reading preferences, such as pronunciation styles and speeds. For operators of intelligent audio reading platforms, they can ensure high-quality content, stable network connections, and reasonable pricing strategies to enhance university students’ reading and learning experience.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {131–137},
numpages = {7},
keywords = {Intelligent audio reading platform, influencing factors, university students},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@article{10.1145/3675416,
author = {Khemka, Mansi and Houck, Brian},
title = {Toward Effective AI Support for Developers: A survey of desires and concerns},
year = {2024},
issue_date = {May/June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {22},
number = {3},
issn = {1542-7730},
url = {https://doi.org/10.1145/3675416},
doi = {10.1145/3675416},
abstract = {The journey of integrating AI into the daily lives of software engineers is not without its challenges. Yet, it promises a transformative shift in how developers can translate their creative visions into tangible solutions. As we have seen, AI tools such as GitHub Copilot are already reshaping the code-writing experience, enabling developers to be more productive and to spend more time on creative and complex tasks. The skepticism around AI, from concerns about job security to its real-world efficacy, underscores the need for a balanced approach that prioritizes transparency, education, and ethical considerations. With these efforts, AI has the potential not only to alleviate the burdens of mundane tasks, but also to unlock new horizons of innovation and growth.},
journal = {Queue},
month = jul,
pages = {53–78},
numpages = {26}
}

@inproceedings{10.1145/3696952.3696985,
author = {Cui, Cui and Hu, Juan and Hu, Wenpeng and Ye, Chenmeng and Cao, Yan},
title = {Profiling Chinese Student Interpreters’ Usage Intention of ChatGPT-assisted Translation by Q Methodology Based on Technology Acceptance Model},
year = {2024},
isbn = {9798400718076},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696952.3696985},
doi = {10.1145/3696952.3696985},
abstract = {This study investigates the Chinese student interpreters’ usage intention of ChatGPT-assisted translation with Q methodology. Guided by technology acceptance theory (TAM), the study aims to explore the usage intention profiles and consensus and differences between them. Q sort tasks were undertaken by 30 participants and their commentary data was elicited to complement Q sort analysis. From the factor analysis, four factors were obtained, namely deeper-purpose seekers, big picture reflectors, deep understanders and coordinators. The distinguishing statements include the subject, technology, information and society elements. The article concludes with a discussion of the pedagogical implications of learning interpreting of university students.},
booktitle = {Proceedings of the 2024 9th International Conference on Intelligent Information Processing},
pages = {241–250},
numpages = {10},
keywords = {ChatGPT-assisted translation, Chinese student interpreters, Q methodology, usage intention profiles},
location = {
},
series = {ICIIP '24}
}

@inproceedings{10.1145/3630106.3659023,
author = {Dotan, Ravit and Parker, Lisa S. and Radzilowicz, John},
title = {Responsible Adoption of Generative AI in Higher Education: Developing a “Points to Consider” Approach Based on Faculty Perspectives},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3659023},
doi = {10.1145/3630106.3659023},
abstract = {This paper proposes an approach to the responsible adoption of generative AI in higher education, employing a “points to consider” approach that is sensitive to the goals, values, and structural features of higher education. Higher education's ethos of collaborative faculty governance, pedagogical and research goals, and embrace of academic freedom conflict, the paper argues, with centralized top-down approaches to governing AI that are common in the private sector. The paper is based on a semester-long effort at the University of Pittsburgh which gathered and organized perspectives on generative AI in higher education through a collaborative, iterative, interdisciplinary process that included recurring group discussions, three standalone focus groups, and an informal survey. The paper presents insights drawn from this effort—that give rise to the “points to consider” approach the paper develops. These insights include the benefits and risks of potential uses of generative AI In higher education, as well as barriers to its adoption, and culminate in the six normative points to consider when adopting and governing generative AI in institutions of higher education.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {2033–2046},
numpages = {14},
keywords = {generative AI, higher education, points to consider, policy making},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3656650.3656663,
author = {Gennari, Rosella and Krik, Soufiane},
title = {Responsible Design of Socio-Technical Solutions with Social Design Students: a Case Study},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656663},
doi = {10.1145/3656650.3656663},
abstract = {Recent research work on digital-well being considers it a matter of personal growth and education. Research in social digital well-being, in particular, invites young generations to consider the role of digital technologies for social well-being. It explored how to engage young generations in building socio-technical prototypes and reflecting on the impact of technology on people. This article fits into this broad line of research. It reports on a case study with social design students with no computing background. It invited them to consider the use of computing technologies in their social-design projects, and to reflect critically on their work. The design was structured with an ad hoc toolkit with various building materials, including cards for reflecting, and physical-computing devices for rapidly prototyping design ideas. The purpose of the toolkit is, on the one hand, to structure and constrain the generative design process and, on the other hand, to allow a certain degree of expressiveness and freedom to participants. The article reports the results of the case study and concludes with a discussion of how to engage non-computing experts in such a process, balancing freedom and guidance.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {50},
numpages = {9},
keywords = {Responsible design, building interaction, end user, interaction design tools, prototyping, social interaction, well being},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@proceedings{10.1145/3689491,
title = {SPLASH Companion '24: Companion Proceedings of the 2024 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
year = {2024},
isbn = {9798400712142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is my great pleasure to welcome you to the 39th ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, being held in the vibrant city of Pasadena, California, from October 20th to October 25th, 2024. Nestled in beautiful southern California, Pasadena offers a unique blend of innovation, culture, and charm, providing the perfect backdrop for this year’s SPLASH conference.SPLASH 2024 continues to be a premier forum for discussing all aspects of software development. This year’s program is as diverse and dynamic as ever, featuring the OOPSLA conference, Onward! Papers and Onward! Essays, SPLASH-E, and our popular student-focused events including the Doctoral Symposium, Student Research Competition, and Programming Language Mentoring Workshop. We are also excited to host a revival of REBASE, a day of talks and discussion to connect industry and academia. Additionally, attendees will have the opportunity to engage with an exciting collection of co-hosted conferences, the Static Analysis Symposium (SAS), International Conference on Generative Programming: Concepts &amp; Experiences (GPCE), and Software Language Engineering (SLE). SPLASH 2024 is also proud to host ten exciting workshops: HATRA, IWACO, JENSFEST, LIVE, NSAD, PAINT, ProLaLa, UNSOUND, VIVEKFEST, and VMIL.},
location = {Pasadena, CA, USA}
}

@inproceedings{10.1145/3700297.3700306,
author = {Gai, Erqi},
title = {The Effects of ChatGPT on English Language Learning in Regards to Language Proficiency and Learning Motivation},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700306},
doi = {10.1145/3700297.3700306},
abstract = {Making use of ChatGPT in language learning has been heatedly discussed in recent years. Former researchers have assessed its usability in English language learning by analyzing users’ feedback, but only provide little information about how it specifically affects English language learning in regards to its language proficiency or language motivation. Henceforth, to fill the research void, this study is designed to analyze the effects of ChatGPT on English language learning concerning vocabulary learning, automated writing evaluation and writing ability, and learning motivation. By selecting eight targeted studies based on the STARLITE standards, the researcher reviewed the studies and briefly summarized the influences: 1) ChatGPT could assist in extending EFL students’ vocabulary through completing text-based tasks; 2) ChatGPT could improve EFL students’ writing ability via automated writing evaluation; 3) ChatGPT could motivate EFL students to learn due to its personalized replies and diverse forms of providing information. However, this study does not contain an analysis of its effects on English language learning in all aspects such as listening and speaking ability. Thus, further studies could probe into the effects of ChatGPT on other English language learning fields.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {43–53},
numpages = {11},
keywords = {ChatGPT, EFL, Language Learning, Language Proficiency, Learning Motivation},
location = {
},
series = {ISAIE '24}
}

@article{10.1145/3689040,
author = {Bomba, Federico and Men\'{e}ndez-Blanco, Mar\'{\i}a and Grigis, Paolo and Cremaschi, Michele and De Angeli, Antonella},
title = {The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3689040},
doi = {10.1145/3689040},
abstract = {The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of entangled authorship to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {75},
numpages = {23},
keywords = {Agency, Agential Realism, Large Language Models, AI and Art, Creative AI, Hallucination}
}

@article{10.1145/3637208,
author = {Edwards, Chris},
title = {Teaching Transformed},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3637208},
doi = {10.1145/3637208},
abstract = {The apparent ability of LLMs to write functioning source code has caused celebration over the potential for massive increases in programmer productivity and consternation among teachers.},
journal = {Commun. ACM},
month = jan,
pages = {12–13},
numpages = {2}
}

@article{10.1145/3597434,
author = {Tang, Zhenjun and Chen, Zhiyuan and Li, Zhixin and Zhong, Bineng and Zhang, Xianquan and Zhang, Xinpeng},
title = {Unifying Dual-Attention and Siamese Transformer Network for Full-Reference Image Quality Assessment},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {6},
issn = {1551-6857},
url = {https://doi.org/10.1145/3597434},
doi = {10.1145/3597434},
abstract = {Image Quality Assessment (IQA) is a critical task of computer vision. Most Full-Reference (FR) IQA methods have limitation in the accurate prediction of perceptual qualities of the traditional distorted images and the Generative Adversarial Networks (GANs) based distorted images. To address this issue, we propose a novel method by Unifying Dual-Attention and Siamese Transformer Network (UniDASTN) for FR-IQA. An important contribution is the spatial attention module composed of a Siamese Transformer Network and a feature fusion block. It can focus on significant regions and effectively maps the perceptual differences between the reference and distorted images to a latent distance for distortion evaluation. Another contribution is the dual-attention strategy that exploits channel attention and spatial attention to aggregate features for enhancing distortion sensitivity. In addition, a novel loss function is designed by jointly exploiting Mean Square Error (MSE), bidirectional Kullback–Leibler divergence, and rank order of quality scores. The designed loss function can offer stable training and thus enables the proposed UniDASTN to effectively learn visual perceptual image quality. Extensive experiments on standard IQA databases are conducted to validate the effectiveness of the proposed UniDASTN. The IQA results demonstrate that the proposed UniDASTN outperforms some state-of-the-art FR-IQA methods on the LIVE, CSIQ, TID2013, and PIPAL databases.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jul,
articleno = {205},
numpages = {24},
keywords = {Transformer, siamese network, dual-attention, image quality assessment (IQA)}
}

@inproceedings{10.1145/3580305.3599412,
author = {Wang, Yunke and Wang, Xiyu and Dinh, Anh-Dung and Du, Bo and Xu, Charles},
title = {Learning to Schedule in Diffusion Probabilistic Models},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599412},
doi = {10.1145/3580305.3599412},
abstract = {Recently, the field of generative models has seen a significant advancement with the introduction of Diffusion Probabilistic Models (DPMs). The Denoising Diffusion Implicit Model (DDIM) was designed to reduce computational time by skipping a number of steps in the inference process of DPMs. However, the hand-crafted sampling schedule in DDIM, which relies on human expertise, has its limitations in considering all relevant factors in the sampling process. Additionally, the assumption that all instances should have the same schedule is not always valid. To address these problems, this paper proposes a method that leverages reinforcement learning to automatically search for an optimal sampling schedule for DPMs. This is achieved by a policy network that predicts the next step to visit based on the current state of the noisy image. The optimization of the policy network is accomplished using an episodic actor-critic framework, which incorporates reinforcement learning. Empirical results demonstrate the superiority of our approach over various datasets with different timesteps. We also observe that the trained sampling schedule has a strong generalization ability across different DPM baselines.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2478–2488},
numpages = {11},
keywords = {diffusion probabilistic model, inference, planning and scheduling, reinforcement learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3589334.3649116,
author = {Paterson, Jeannie Marie},
title = {AI Deepfakes on the Web: The 'Wicked' Challenges for AI Ethics, Law and Technology},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3649116},
doi = {10.1145/3589334.3649116},
abstract = {Advances in generative AI and the increasingly easy availability of tools for creating text, code, audio, and images have impacted almost all industry sectors, promising new efficiencies and changing work patterns. The darker side of this same technology is the problematic case of deepfakes created by AI and spread online to humiliate, manipulate, trick, or defraud ordinary individuals and public figures. Transparency, fairness, and beneficence are vital values of responsible and ethical AI. All of these values would preclude harmful uses of AI deep fakes. However, harmful deepfakes are usually the work of fraudsters with little regard for ethics and beyond the reach of the law. So, who should be responsible? Arguably, principles of responsible AI require tech companies and digital platforms to take responsibility for reducing harmful uses of deepfakes. These entities are gatekeepers to the creation and distribution of deepfakes. Therefore, they are ethically obligated to respond to the foreseeable consequential harms arising from generative AI. Increasingly, this is the response of lawmakers. Gatekeeper responsibility envisages that tech producers and platforms will proactively invest in technical solutions to harmful deepfakes, such as watermarking, finetuning, red teaming or automated content moderation, and proactive take-down responses. This response is compelling and might seem straightforward. As always, the details are more complex. The efficiency of the proposed technical responses is still emerging. They raise as yet unaddressed implications for smaller providers and the relations between tech companies and digital platforms. Moreover, even beginning to respond to online deepfakes requires social policy decisions that assess and weigh incommensurable considerations, including retaining trust on the Web, keeping vulnerable groups safe, preserving free speech and creativity, and not stifling the development of potentially beneficial technology. This presentation addresses these problematic choices in responding to the 'wicked' challenge of AI deepfakes on the Web. It proposes a networked response to the problem, embracing multiple relevant actors and influences.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3},
numpages = {1},
keywords = {deep fakes, gate keepers, liability, responsibility},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3643834.3661498,
author = {Sivertsen, Christian and L\o{}vlie, Anders Sundnes},
title = {Exploring Aesthetic Qualities of Deep Generative Models through Technological (Art) Mediation},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661498},
doi = {10.1145/3643834.3661498},
abstract = {Deep Generative Models (DGM) have had a great impact both on visual art and broader visual culture. In this research-through-design project we investigate the use of a DGM for helping museum visitors explore the aesthetics of Edvard Munch’s art. We designed and built an interactive drawing table that allows a user to explore a StyleGAN model trained on sketches by Edvard Munch. The paper makes two novel contributions: 1. It presents a system that allows users to interact with a DGM by drawing on paper (rather than the typical text prompts used by most current systems). 2. We demonstrate how this mode and quality of interaction establish a unique perspective on Munch’s drawings as a practice. Through qualitative evaluation, we discuss how this setup led users towards a specific hermeneutic drawing strategy that enables building competency with the model and by proxy the data it is trained on. We suggest that the resulting interaction may contribute to an "education of attention" helping museum visitors to become attentive to certain visual qualities in Munch’s drawing practice. Finally, we discuss how the concepts of technological mediation and relationality are useful for designing how the output of a DGM is understood by its users.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2738–2752},
numpages = {15},
keywords = {aesthetics, deep generative model, drawing, fine art, interaction design, machine learning, postphenomenology, stylegan},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.5555/3539845.3540187,
author = {Wei, Zheng and Zhang, Xingjun and Li, Jingbo and Ji, Zeyu and Wei, Jia},
title = {BenQ: &lt;u&gt;ben&lt;/u&gt;chmarking automated quantization on deep neural network accelerators},
year = {2022},
isbn = {9783981926361},
publisher = {European Design and Automation Association},
address = {Leuven, BEL},
abstract = {Hardware-aware automated quantization promises to unlock an entirely new algorithm-hardware co-design paradigm for efficiently accelerating deep neural network (DNN) inference by incorporating the hardware cost into the reinforcement learning (RL) -based quantization strategy search process. Existing works usually design an automated quantization algorithm targeting one hardware accelerator with a device-specific performance model or pre-collected data. However, determining the hardware cost is non-trivial for algorithm experts due to their lack of cross-disciplinary knowledge in computer architecture, compiler, and physical chip design. Such a barrier limits reproducibility and fair comparison. Moreover, it is notoriously challenging to interpret the results due to the lack of quantitative metrics. To this end, we first propose BenQ, which includes various RL-based automated quantization algorithms with aligned settings and encapsulates two off-the-shelf performance predictors with standard OpenAI Gym API. Then, we leverage cosine similarity and manhattan distance to interpret the similarity between the searched policies. The experiments show that different automated quantization algorithms can achieve near equivalent optimal trade-offs because of the high similarity between the searched policies, which provides insights for revisiting the innovations in automated quantization algorithms.},
booktitle = {Proceedings of the 2022 Conference &amp; Exhibition on Design, Automation &amp; Test in Europe},
pages = {1479–1484},
numpages = {6},
keywords = {DNN accelerator, automated quantization, benchmark, reinforcement learning},
location = {Antwerp, Belgium},
series = {DATE '22}
}

@inproceedings{10.1145/3613904.3642677,
author = {Trajkova, Milka and Long, Duri and Deshpande, Manoj and Knowlton, Andrea and Magerko, Brian},
title = {Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642677},
doi = {10.1145/3613904.3642677},
abstract = {Co-creation in embodied contexts is central to the human experience but is often lacking in our interactions with computers. We seek to develop a better understanding of embodied human co-creativity to inform the human-centered design of machines that can co-create with us. In this paper, we ask: What characterizes dancers’ experiences of embodied dyadic interaction in movement improvisation? To answer this, we ran focus groups with 24 university dance students and conducted a thematic analysis of their responses. We synthesize our findings in an Interconnected Model of Improvisational Dance Inputs, where movement choices are shaped by the interplay between in-the-moment influences between the self, partner, and the environment, a set of generative strategies, and heuristics for a successful collaboration. We present a set of design recommendations for LuminAI, a co-creative AI dance partner. Our contributions can inform the design of AI in embodied co-creative domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {890},
numpages = {22},
keywords = {AI agents, co-creative agents, co-creativity, computational creativity, dance improvisation, movement improvisation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3510361,
author = {Xia, Feng and Guo, Teng and Bai, Xiaomei and Shatte, Adrian and Liu, Zitao and Tang, Jiliang},
title = {SUMMER: Bias-aware Prediction of Graduate Employment Based on Educational Big Data},
year = {2022},
issue_date = {November 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {2691-1922},
url = {https://doi.org/10.1145/3510361},
doi = {10.1145/3510361},
abstract = {The failure of obtaining employment could lead to serious psychosocial outcomes such as depression and substance abuse, especially for college students who may be less cognitively and emotionally mature. In addition to academic performance, employers’ unconscious biases are a potential obstacle to graduating students in becoming employed. Thus, it is necessary to understand the nature of such unconscious biases to assist students at an early stage with personalized intervention. In this paper, we analyze the existing bias in college graduate employment through a large-scale education dataset and develop a framework called SUMMER (biaS-aware gradUate eMployMEnt pRediction) to predict students’ employment status and employment preference while considering biases. The framework consists of four major components. Firstly, we resolve the heterogeneity of student courses by embedding academic performance into a unified space. Next, we apply a Wasserstein generative adversarial network with gradient penalty (WGAN-GP) to overcome the label imbalance problem of employment data. Thirdly, we adopt a temporal convolutional network to comprehensively capture sequential information of academic performance across semesters. Finally, we design a bias-based regularization to smooth the job market biases. We conduct extensive experiments on a large-scale educational dataset and the results demonstrate the effectiveness of our prediction framework.},
journal = {ACM/IMS Trans. Data Sci.},
month = mar,
articleno = {39},
numpages = {24},
keywords = {Graduate employment, prediction, bias, educational big data, data analysis}
}

@inproceedings{10.1145/3610978.3638374,
author = {Malnatsky, Elena and Wang, Shenghui and Hindriks, Koen V. and Ligthart, Mike E.U.},
title = {Shaping Relatable Robots: A Child-Centered Approach to Social Personalization},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3638374},
doi = {10.1145/3610978.3638374},
abstract = {While social robots hold significant potential in education, not all children find their interaction with a robot relatable. We present a child-centered research approach that actively involves children in shaping personalized interaction content. We applied this method in a user study (n=102, 8-13 y.o) where we designed robot humor that was tailored to different age groups. Results indicated that children found age-personalized humor more amusing and felt a stronger affinity with it, both personally and at the group level. Our forthcoming longitudinal study will focus on enhancing children's relatedness to the robot and a book, aiming to stimulate reading motivation. We plan to investigate how generative AI can efficiently scale up both co-design and content creation steps.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {127–129},
numpages = {3},
keywords = {child-robot interaction, co-design, personalization},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3658644.3691418,
author = {Malaviya, Shubham and Shukla, Manish and Anand, Saurabh and Lodha, Sachin},
title = {Poster: Unmasking Label Errors: A need for Robust Cybersecurity Benchmarks},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3691418},
doi = {10.1145/3658644.3691418},
abstract = {Cyber Threat Intelligence (CTI) utilizes information from various sources, necessitating high-quality labeled datasets for effective application of machine learning. Our study addresses the often-overlooked issue of labeling errors in cybersecurity benchmarks, resulting in the creation of D-LADDER++, a curated version of the recently published LADDER dataset. We evaluated the performance of both an open-source model (Microsoft Phi-3) and a closed-source model (Google Gemini) on D-LADDER++. We assessed their zero-shot and few-shot capabilities and fine-tuned the Phi-3 model for enhanced adaptability. Our assessment of the impact of test errors on model performance emphasizes the critical need for robust benchmarks in cybersecurity to ensure accurate model evaluation and selection.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {5018–5020},
numpages = {3},
keywords = {cyber threat intelligence, data curation, large language models},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3531146.3533138,
author = {Hundt, Andrew and Agnew, William and Zeng, Vicky and Kacianka, Severin and Gombolay, Matthew},
title = {Robots Enact Malignant Stereotypes},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533138},
doi = {10.1145/3531146.3533138},
abstract = {Stereotypes, bias, and discrimination have been extensively documented in Machine Learning (ML) methods such as Computer Vision (CV)&nbsp;[18, 80], Natural Language Processing (NLP)&nbsp;[6], or both, in the case of large image and caption models such as OpenAI CLIP&nbsp;[14]. In this paper, we evaluate how ML bias manifests in robots that physically and autonomously act within the world. We audit one of several recently published CLIP-powered robotic manipulation methods, presenting it with objects that have pictures of human faces on the surface which vary across race and gender, alongside task descriptions that contain terms associated with common stereotypes. Our experiments definitively show robots acting out toxic stereotypes with respect to gender, race, and scientifically-discredited physiognomy, at scale. Furthermore, the audited methods are less likely to recognize Women and People of Color. Our interdisciplinary sociotechnical analysis synthesizes across fields and applications such as Science Technology and Society (STS), Critical Studies, History, Safety, Robotics, and AI. We find that robots powered by large datasets and Dissolution Models (sometimes called “foundation models”, e.g. CLIP) that contain humans risk physically amplifying malignant stereotypes in general; and that merely correcting disparities will be insufficient for the complexity and scale of the problem. Instead, we recommend that robot learning methods that physically manifest stereotypes or other harmful outcomes be paused, reworked, or even wound down when appropriate, until outcomes can be proven safe, effective, and just. Finally, we discuss comprehensive policy changes and the potential of new interdisciplinary research on topics like Identity Safety Assessment Frameworks and Design Justice to better understand and address these harms.},
booktitle = {Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {743–756},
numpages = {14},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{10.1145/3502181.3531457,
author = {Paul, Arnab K. and Choi, Jong Youl and Karimi, Ahmad Maroof and Wang, Feiyi},
title = {Machine Learning Assisted HPC Workload Trace Generation for Leadership Scale Storage Systems},
year = {2022},
isbn = {9781450391993},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3502181.3531457},
doi = {10.1145/3502181.3531457},
abstract = {Monitoring and analyzing a wide range of I/O activities in an HPC cluster is important in maintaining mission-critical performance in a large-scale, multi-user, parallel storage system. Center-wide I/O traces can provide high-level information and fine-grained activities per application or per user running in the system. Studying such large-scale traces can provide helpful insights into the system. It can be used to develop predictive methods for making predictive decisions, adjusting scheduling policies, or providing decisions for the design of next-generation systems. However, sharing real-world I/O traces to expedite such research efforts leaves a few concerns; i) the cost of sharing the large traces is expensive due to this large size, and ii) privacy concern is an issue.We address such issues by building an end-to-end machine learn- ing (ML) workflow that can generate I/O traces for large-scale HPC applications. We leverage ML based feature selection and gener- ative models for I/O trace generation. The generative models are trained on I/O traces collected by the darshan I/O characterization tool over a period of one year. We present a two-step generation process consisting of two deep-learning models, called the feature generator and the trace generator. The combination of two-step generative models provides robustness by reducing the bias of the model and accounting for the stochastic nature of the I/O traces across different runs of an application. We evaluate the performance of the generative models and show that the two-step model can generate time-series I/O traces with less than 20% root mean square error.},
booktitle = {Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing},
pages = {199–212},
numpages = {14},
keywords = {clustering, darshan, feature selection, generative modeling, parallel file system},
location = {Minneapolis, MN, USA},
series = {HPDC '22}
}

@article{10.1109/TNET.2023.3270565,
author = {Li, Xionglve and Zhou, Tongqing and Cai, Zhiping and Su, Jinshu},
title = {Realizing Fine-Grained Inference of AS Path With a Generative Measurable Process},
year = {2023},
issue_date = {Dec. 2023},
publisher = {IEEE Press},
volume = {31},
number = {6},
issn = {1063-6692},
url = {https://doi.org/10.1109/TNET.2023.3270565},
doi = {10.1109/TNET.2023.3270565},
abstract = {In the global Internet, the paths between two autonomous systems (ASes), which are used for the exchange of traffic, are essential for understanding the behavior of the Internet routing system and they can help improve the performance of many applications of the Internet. Popular approaches to obtain the AS path between an AS pair (AP) are measurement based (e.g., Traceroute), but considering the size of the modern Internet and the limitations of measurement resources, only paths between a very small portion of APs can be measured. In recent years, a large body of path inference approaches has been proposed to bridge the gap in measurement resources. However, as we show with experiments, they perform poorly in accuracy and coverage. We propose a generative measurable path inference (GMPI) framework for AS-level path measurement, which performs well in accuracy and coverage. GMPI addresses two limitations of previous approaches: 1) Information incompleteness due to unrevealed real-world AS-level routing policies and insufficient measuring resources. 2) Knowledge isolation caused by distributed AS knowledge with different sources and inconsistent forms. To overcome these challenges, the data-driven GMPI framework invents heuristic path generation to address incompleteness and a dual-attention network to integrate the isolated knowledge. GMPI does not perform any measurement or impose any burden on the network. Our performance evaluation shows that our framework GMPI outperforms state-of-the-art approaches in terms of accuracy and coverage. In particular, compared to the state-of-the-art stitching-based baseline, GMPI provides a 42.45% improvement in coverage and a 39.97% improvement in accuracy. The experimental results demonstrate that GMPI can accurately infer paths for nearly arbitrary APs.},
journal = {IEEE/ACM Trans. Netw.},
month = may,
pages = {3112–3127},
numpages = {16}
}

@inproceedings{10.1145/3591196.3593363,
author = {Flanagan, Patricia Jean},
title = {NEEDLE WORK-Revealing relational agency aesthetics of craft through human/robot interaction},
year = {2023},
isbn = {9798400701801},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591196.3593363},
doi = {10.1145/3591196.3593363},
abstract = {NEEDLE WORK is created at The National Facility for Human-Robot Interaction in Australia and explores new models of cultural transmission and education by retracing and interpreting the gestures of craft. The framework for creative production is collaborative – between people, technologies, and material agency. NEEDLE WORK translates micro-scale craft gestures, into human-scale three dimensional robotic light drawings. The light drawings inform human-robot interaction, exploring a mode of generative choreography as an aesthetics of change, viewing a sequence of gestures as chapters in performance. The conceptual lens focusses on process-oriented qualities and embodies a relational aesthetic view of agency that engages the dynamism between entities. Performing immaterial praxis of intangible cultural heritage crafts explores the creative potential of co-design, engaging human, machine, and material agency, and opens new perspectives to understand and interpret the value of craft.},
booktitle = {Proceedings of the 15th Conference on Creativity and Cognition},
pages = {235–238},
numpages = {4},
keywords = {Choreography as Change, Craft, Creative Cognition, Feedback Loops, Gesture Recognition, Human Robot Interaction, Intangible Cultural Heritage, Intra-action, Machine Agency, Material Agency, Object Oriented Ontology, Reciprocity, Relational Aesthetics},
location = {Virtual Event, USA},
series = {C&amp;C '23}
}

@inproceedings{10.1145/3620666.3655589,
author = {Vahdat, Amin},
title = {Societal infrastructure in the age of Artificial General Intelligence},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3620666.3655589},
doi = {10.1145/3620666.3655589},
abstract = {Today, we are at an inflection point in computing where emerging Generative AI services are placing unprecedented demand for compute while the existing architectural patterns for improving efficiency have stalled. In this talk, we will discuss the likely needs of the next generation of computing infrastructure and use recent examples at Google from networks to accelerators to servers to illustrate the challenges and opportunities ahead. Taken together, we chart a course where computing must be increasingly specialized and co-optimized with algorithms and software, all while fundamentally focusing on security and sustainability.},
booktitle = {Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {1},
numpages = {1},
location = {La Jolla, CA, USA},
series = {ASPLOS '24}
}

@inproceedings{10.1145/3677892.3677941,
author = {Hu, Changping and Yang, Jie},
title = {A Bibliometric Comparison of Chinese and International Research in the Field of Generative AI},
year = {2024},
isbn = {9798400709838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677892.3677941},
doi = {10.1145/3677892.3677941},
abstract = {Rapid advancements in artificial intelligence incited a global fervor towards further AI research. Being the forefront of modern AI advancements, the current state and boundaries of generative AI research lended itself to further examination, especially the differences regarding topics and quality of research between International and Chinese academia. Through a bibliometric study examining the body of research contained within the China National Knowledge Infrastructure and Web of Science, the results suggested that Chinese academia have four areas of improvement: (1) determining the sample, (2) expanding the limits, (3) examining moral efficacy, and (4) researching foundational knowledge.},
booktitle = {Proceedings of the 2024 International Conference on Digital Society and Artificial Intelligence},
pages = {303–310},
numpages = {8},
location = {Qingdao, China},
series = {DSAI '24}
}

@article{10.1145/3689783,
author = {Wu, Jifeng and Lemieux, Caroline},
title = {QuAC: Quick Attribute-Centric Type Inference for Python},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA2},
url = {https://doi.org/10.1145/3689783},
doi = {10.1145/3689783},
abstract = {Python’s dynamic typing facilitates rapid prototyping and underlies its popularity in many domains. However, dynamic typing reduces the power of many static checking and bug-finding tools. Python type annotations can make these tools more useful. Type inference tools aim to reduce developers’ burden of adding them. However, existing type inference tools struggle to support dynamic features, infer correct types (especially container type parameters and non-builtin types), and run in reasonable time. Inspired by Python’s duck typing, where the attributes accessed on Python expressions characterize their implicit interfaces, we propose QuAC (Quick Attribute-Centric Type Inference for Python). At its core, QuAC collects attribute sets for Python expressions and leverages information retrieval techniques to predict classes from these attribute sets. It also recursively predicts container type parameters. We evaluate QuAC’s performance on popular Python projects. Compared to state-of-the-art non-LLM baselines, QuAC predicts types with high accuracy complementary to those predicted by the baselines while not sacrificing coverage. It also demonstrates clear advantages in predicting container type parameters and non-builtin types and reduces run times. Furthermore, QuAC is nearly two orders of magnitude faster than an LLM-based method while covering nearly half of its errorless non-trivial type predictions. It is also significantly more consistent at predicting container type parameters and non-builtin types than the LLM-based method, regardless of whether the project has ground-truth type annotations.},
journal = {Proc. ACM Program. Lang.},
month = oct,
articleno = {343},
numpages = {30},
keywords = {Gradual Typing, Python, Static Analysis, Type Inference}
}

@inproceedings{10.1145/3686852.3687066,
author = {Glantz, Edward J. and Peca, Joanne C. and Nasereddin, Mahdi and Stager, Sarah J. and Bartolacci, Michael R.},
title = {Beyond the Code: The Role of Non-Traditional Sectors in Shaping Generative AI Innovations and Transforming Global Industries},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687066},
doi = {10.1145/3686852.3687066},
abstract = {This paper examines the role of non-traditional sectors in integrating and advancing Generative Artificial Intelligence (GenAI) across diverse industries, extending beyond the traditional boundaries of the technology sector. Non-traditional sector players in GenAI have recently enabled a foothold in both industry and education to rapidly expand. With a focus on healthcare, agriculture, education, and finance, we highlight case studies that demonstrate the innovative applications of GenAI, illustrating its capability to drive significant industry transformations. Through this exploration, the paper emphasizes the crucial role of interdisciplinary collaboration in catalyzing technological progress and broadening the impact of GenAI. By providing a comprehensive analysis of the current and potential future states of GenAI applications, this research aims to deepen understanding of its broader societal and economic implications. This study not only captures GenAI's transformative potential but also addresses the dual narrative of GenAI as both a promising tool, particularly for education, and a formidable challenge, underscoring its growing influence in non-traditional sectors.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {1–6},
numpages = {6},
keywords = {AI implementation, AI in education, Generative artificial intelligence (AI), Interdisciplinary innovation},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3544549.3574172,
author = {Mackay, Wendy E.},
title = {DOIT: The Design of Interactive Things. Selected methods for quickly and effectively designing interactive systems from the user’s perspective},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3574172},
doi = {10.1145/3544549.3574172},
abstract = {The Design of Interactive Things teaches participants how to quickly and effectively design innovative interactive systems from the user’s perspective. Intended for both UX designers and HCI researchers, the course provides a coherent overview of the interaction design process, with detailed descriptions of four key design methods: story interviews, video brainstorming, video prototyping, and generative walkthroughs. Participants will apply these methods to design a novel interactive system, using materials and tools provided in the course. Each method has been tested in both industry and research settings, and is especially appropriate for participatory co-design with users.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {555},
numpages = {3},
keywords = {Co-Design, Participatory Design, User Experience Design, User-Centered Design},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3640471.3680462,
author = {ElAgroudy, Passant and Gruenerbl, Agnes and Barbareschi, Giulia and Spilski, Jan and Kunze, Kai and Lachmann, Thomas and Lukowicz, Paul},
title = {mobiCHAI - 1st International Workshop on Mobile Cognition-Altering Technologies (CAT) using Human-Centered AI},
year = {2024},
isbn = {9798400705069},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640471.3680462},
doi = {10.1145/3640471.3680462},
abstract = {The quest for enhanced cognition has been a driving force behind human advancement, fostering innovation and personal fulfillment. Cognition Altering Technologies (CAT) holds immense promise in elevating the quality of life across diverse domains including education, decision-making, healthcare, and fitness. The current proliferation of Artificial Intelligence (AI), particularly the widespread adoption of Generative AI and foundational models, presents an unprecedented opportunity to prototype new CAT that can augment human capabilities. This workshop aims to unite interdisciplinary research communities to explore the potential of leveraging GenAI and human-centered AI to develop relevant CAT. Taking place at MobileHCI 2024, this one-day workshop invites researchers, practitioners, and designers from fields such as artificial intelligence, ubiquitous computing, human-computer interaction, and social sciences to collaborate and chart the future of cognitive enhancement through technology.},
booktitle = {Adjunct Proceedings of the 26th International Conference on Mobile Human-Computer Interaction},
articleno = {31},
numpages = {5},
keywords = {Human-Centered AI, Hybrid-Human Artificial Intelligence, augmenting human capabilities, cognitive science, generative AI, shaping cognitive and social behavior, ubiquitous technologies},
location = {Melbourne, VIC, Australia},
series = {MobileHCI '24 Adjunct}
}

@article{10.5555/3665464.3665466,
author = {Juhnke, Kevin},
title = {Perspectives on Technology's Impact on Financial Services and the Future Workforce},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {A variety of experiences over a 30+ year career in the computing field at Principal Financial provides for a life-long journey with many fascinating insights. Mr. Juhnke will focus his thoughts on:• Business and market challenges in Financial Services and their impact on an organization's Technology Strategies• The impact key maturing and emerging technologies have on the Financial Services industry including...- Cloud Advancements- Generative AI- Blockchain- "Citizen" DevelopmentHe will conclude his thoughts with perspectives on areas where educators can help position students to be more marketable and impactful in financial services tech jobs after graduation.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {18–19},
numpages = {2}
}

@inproceedings{10.1145/3626641.3626926,
author = {Fauzulhaq, Alfirsa Damasyifa and Bachtiar, Fitra Abdurrachman},
title = {Mutual Information for Learning Context Representation on RNN-Attention Based Models in Open Domain Generative Chatbot},
year = {2023},
isbn = {9798400708503},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626641.3626926},
doi = {10.1145/3626641.3626926},
abstract = {Chatbot is an example of the application of Artificial Intelligence that can receive and answer questions automatically. Chatbots are widely used in various fields such as health, customer service, entertainment, education and others. There are two approaches to chatbot development, rule-based and generative. Rule-based chatbot has the advantage of being easy to develop and produces good answers but requires predefined rules that are defined manually. Generative chatbot can provide dynamic and natural answers and does not require predefined rules. However, the drawback of generative chatbot lies in the weak representation of sentence information and information bottleneck which results in loss of information or context. The main objective of this research is to get the best model for open domain generative chatbot in a predefined scenario and improve the performance of the model in terms of word information representation using SBERT Pretrained Word Embedding and reduce information loss in encoder bottleneck and output using Mutual Information. Based on the experimental results, LSTM with the addition of Bahdanau Attention achieved the best performance in all scenarios with the highest BLEU and BERT F1-Score. Whereas in the 50 and 100 (long) sequence scenarios, the addition of Mutual Information and SBERT can improve overall model performance for BLEU by 3.62% and 2.58% respectively and BERT Score by 3.16% and 5.10% respectively.},
booktitle = {Proceedings of the 8th International Conference on Sustainable Information Engineering and Technology},
pages = {112–118},
numpages = {7},
keywords = {Attention Mechanism, Chatbot, Deep Neural Network, Natural Language Processing, Sequence-to-sequence},
location = {Badung, Bali, Indonesia},
series = {SIET '23}
}

@inproceedings{10.1145/3588432.3591492,
author = {Park, Jungnam and Park, Moon Seok and Lee, Jehee and Won, Jungdam},
title = {Bidirectional GaitNet: A Bidirectional Prediction Model of Human Gait and Anatomical Conditions},
year = {2023},
isbn = {9798400701597},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588432.3591492},
doi = {10.1145/3588432.3591492},
abstract = {We present a novel generative model, called Bidirectional GaitNet, that learns the relationship between human anatomy and its gait. The simulation model of human anatomy is a comprehensive, full-body, simulation-ready, musculoskeletal model with 304 Hill-type musculotendon units. The Bidirectional GaitNet consists of forward and backward models. The forward model predicts a gait pattern of a person with specific physical conditions, while the backward model estimates the physical conditions of a person when his/her gait pattern is provided. Our simulation-based approach first learns the forward model by distilling the simulation data generated by a state-of-the-art predictive gait simulator and then constructs a Variational Autoencoder (VAE) with the learned forward model as its decoder. Once it is learned its encoder serves as the backward model. We demonstrate our model on a variety of healthy/impaired gaits and validate it in comparison with physical examination data of real patients.},
booktitle = {ACM SIGGRAPH 2023 Conference Proceedings},
articleno = {6},
numpages = {9},
keywords = {Clinical Gait Analysis, GaitNet, Musculoskeletal Simulation, Predictive Gait Simulation},
location = {Los Angeles, CA, USA},
series = {SIGGRAPH '23}
}

@inproceedings{10.1145/3544548.3581408,
author = {Jeong, Yunwoo and Cho, Hyungjun and Kim, Taewan and Nam, Tek-Jin},
title = {AutomataStage: an AR-mediated Creativity Support Tool for Hands-on Multidisciplinary Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581408},
doi = {10.1145/3544548.3581408},
abstract = {The creativity support tools can enhance the hands-on multidisciplinary learning experience by drawing interest in the process of creating the outcome. We present AutomataStage, an AR-mediated creativity support tool for hands-on multidisciplinary learning. AutomataStage utilizes a video see-through interface to support the creation of Interactive Automata. The combination of building blocks and low-cost materials increases the expressiveness. The generative design method and one-to-one guide support the idea development process. It also provides a hardware see-through feature with which inside parts and circuits can be seen and an operational see-through feature that shows the operation in real-time. The visual programming method with a state transition diagram supports the iterative process during the creation process. A user study shows that AutomataStage enabled the students to create diverse Interactive Automata within 40-minute sessions. By creating Interactive Automata, the participants could learn the basic concepts of components. See-through features allowed active exploration with interest while integrating the components. We discuss the implications of hands-on tools with interactive and kinetic content beyond multidisciplinary learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {732},
numpages = {16},
keywords = {Interactive Automata, Multidisciplinary learning, STEAM, creativity support tool, hands-on learning, learning tool, video see-through system},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3615522.3615557,
author = {Wang, Bingyuan and Zhang, Kang and Wang, Zeyu},
title = {Naturality: A Natural Reflection of Chinese Calligraphy},
year = {2023},
isbn = {9798400707513},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615522.3615557},
doi = {10.1145/3615522.3615557},
abstract = {We present a machine learning-based interactive video installation powered by CLIP and diffusion models and inspired by the concept of naturality in traditional Chinese calligraphy. The artwork explores contemporary interpretations of this traditional concept through practical methods in Artificial Intelligence Generated Content (AIGC). Technically, the algorithms are based on state-of-the-art perceptual and generative models, incorporating multi-dimensional controls over text-to-image and image-to-image translation; conceptually, this real-time art installation extends the discussion brought by Xu Bing’s pieces Book from the Sky and Square Word Calligraphy. The project explores the possibility of AIGC in bridging human creativity and natural randomness, as well as a shifting creative paradigm enhanced by AI knowledge, perception, and association.},
booktitle = {Proceedings of the 16th International Symposium on Visual Information Communication and Interaction},
articleno = {35},
numpages = {8},
keywords = {AI art., Chinese calligraphy, naturality},
location = {Guangzhou, China},
series = {VINCI '23}
}

@inproceedings{10.1145/3485447.3512067,
author = {Zhao, Yan and Chen, Xuanhao and Deng, Liwei and Kieu, Tung and Guo, Chenjuan and Yang, Bin and Zheng, Kai and Jensen, Christian S.},
title = {Outlier Detection for Streaming Task Assignment in Crowdsourcing},
year = {2022},
isbn = {9781450390965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3485447.3512067},
doi = {10.1145/3485447.3512067},
abstract = {Crowdsourcing aims to enable the assignment of available resources to the completion of tasks at scale. The continued digitization of societal processes translates into increased opportunities for crowdsourcing. For example, crowdsourcing enables the assignment of computational resources of humans, called workers, to tasks that are notoriously hard for computers. In settings faced with malicious actors, detection of such actors holds the potential to increase the robustness of crowdsourcing platform. We propose a framework called Outlier Detection for Streaming Task Assignment that aims to improve robustness by detecting malicious actors. In particular, we model the arrival of workers and the submission of tasks as evolving time series and provide means of detecting malicious actors by means of outlier detection. We propose a novel socially aware Generative Adversarial Network (GAN) based architecture that is capable of contending with the complex distributions found in time series. The architecture includes two GANs that are designed to adversarially train an autoencoder to learn the patterns of distributions in worker and task time series, thus enabling outlier detection based on reconstruction errors. A GAN structure encompasses a game between a generator and a discriminator, where it is desirable that the two can learn to coordinate towards socially optimal outcomes, while avoiding being exploited by selfish opponents. To this end, we propose a novel training approach that incorporates social awareness into the loss functions of the two GANs. Additionally, to improve task assignment efficiency, we propose an efficient greedy algorithm based on degree reduction that transforms task assignment into a bipartite graph matching. Extensive experiments offer insight into the effectiveness and efficiency of the proposed framework.},
booktitle = {Proceedings of the ACM Web Conference 2022},
pages = {1933–1943},
numpages = {11},
keywords = {crowdsourcing, outlier detection, task assignment, time series},
location = {Virtual Event, Lyon, France},
series = {WWW '22}
}

@inproceedings{10.1145/3543507.3583286,
author = {Zhou, Zhihui and Zhang, Lilin and Yang, Ning},
title = {Contrastive Collaborative Filtering for Cold-Start Item Recommendation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583286},
doi = {10.1145/3543507.3583286},
abstract = {The cold-start problem is a long-standing challenge in recommender systems. As a promising solution, content-based generative models usually project a cold-start item’s content onto a warm-start item embedding to capture collaborative signals from item content so that collaborative filtering can be applied. However, since the training of the cold-start recommendation models is conducted on warm datasets, the existent methods face the issue that the collaborative embeddings of items will be blurred, which significantly degenerates the performance of cold-start item recommendation. To address this issue, we propose a novel model called Contrastive Collaborative Filtering for Cold-start item Recommendation (CCFCRec), which capitalizes on the co-occurrence collaborative signals in warm training data to alleviate the issue of blurry collaborative embeddings for cold-start item recommendation. In particular, we devise a contrastive collaborative filtering (CF) framework, consisting of a content CF module and a co-occurrence CF module to generate the content-based collaborative embedding and the co-occurrence collaborative embedding for a training item, respectively. During the joint training of the two CF modules, we apply a contrastive learning between the two collaborative embeddings, by which the knowledge about the co-occurrence signals can be indirectly transferred to the content CF module, so that the blurry collaborative embeddings can be rectified implicitly by the memorized co-occurrence collaborative signals during the applying phase. Together with the sound theoretical analysis, the extensive experiments conducted on real datasets demonstrate the superiority of the proposed model. The codes and datasets are available on https://github.com/zzhin/CCFCRec.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {928–937},
numpages = {10},
keywords = {Cold-start Recommendation, Contrastive Learning, Recommender Systems},
location = {Austin, TX, USA},
series = {WWW '23}
}

@inproceedings{10.1145/3575828.3575834,
author = {Qu, Shenghe},
title = {Research and Analysis of Knee Joint Prosthesis Design Based on 3D Simulation Technology Based on Computer Method},
year = {2023},
isbn = {9781450397247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575828.3575834},
doi = {10.1145/3575828.3575834},
abstract = {Knee joint was reconstructed and tibial plateau parameters were measured and to explore the difference of human evolutionary rhythm, to analyze the matching degree of imported knee prosthesis and Chinese tibial plateau osteotomy plane, and to analyze its influence on the design of knee prosthesis. 3D reconstruction refers to the establishment of mathematical models suitable for computer representation and processing of 3D objects, which is the basis of processing, operating and analyzing its properties under the computer environment. The basic research on the 3D structure of the knee joint is helpful for a more comprehensive understanding of the evolution of the human knee joint and the structural differences between people. In this study, 60 patients (120 knees) with non-knee diseases and 20 healthy volunteers (40 knees) were selected from the Department of Orthopedics, Beijing Chaoyang Hospital, Capital Medical University from January 2018 to January 2020, including 46 males (92 knees) and 34 females (68 knees), aged 24-72 years, with an average age of 46.8 years. Bilateral knee CT scan and 3D reconstruction were performed, and 3d tibial images reconstructed were rotated and cut on HP Advantage Workstation 4.3 advanced image Workstation, and linear parameters such as transverse diameter and anteroposterior diameter of tibial plateau osteotomy surface were measured and calculated, and the differences of parameters between men and women were compared. Statistical analysis was performed. The matching degree of three imported components (depuy-PFC Sigma, Link-Gemini MK-II and Zimmer-Nexgen) with the Chinese tibial plateau tolerance surface was evaluated by using the 5mm tolerance range method. The matching rates were compared by χ2 test. The mean cross diameter of tibial plateau was (74.22±2.84)mm in 80 Chinese adults with 160 knees, and the difference was statistically significant (t=12.36, P &lt; 0.01). The mean diameter was (48.15±2.58) mm, and the difference was statistically significant (t=9.48, P &lt; 0.01). There was no significant difference in the matching rates between prosthesis A and B (χ2=1.027, P=0.184), but there were significant differences in the matching rates between prosthesis A and C (χ2= 8.050, P=0.003), and between prosthesis B and C (χ2= 14.672, P=0.000). There is a significant difference between Chinese and Caucasian in the normal bearing surface of tibial plateau. The matching degree between imported knee prosthesis and Chinese tibial plateau osteotomy is generally low. The tibial plateau section of Chinese is relatively round, which suggests that in the course of human evolution, Chinese walked from four limbs to upright earlier than Caucasians.},
booktitle = {Proceedings of the 2022 7th International Conference on Systems, Control and Communications},
pages = {29–36},
numpages = {8},
keywords = {Arthroplasty, Cover rate, Human evolution, Prosthesis, Three-dimensional reconstruction, knee, replacement},
location = {Chongqing, China},
series = {ICSCC '22}
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701844,
author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
title = {Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701844},
doi = {10.1145/3641554.3701844},
abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1302–1308},
numpages = {7},
keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705121,
author = {Harrington, Brian and Alnoor, Ahmad Zubair and Haqiqi, Pedram and Hoseininia, Zahra and Lin, Kai and Lodi, Maliha and Mirza, Asad and Wolfe, Leah and Zhang, Kevin},
title = {A Systematic Literature Mapping of Early Generative AI Research is CS Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705121},
doi = {10.1145/3641555.3705121},
abstract = {The widespread release of generative AI tools has led to a rapid rise in publications evaluating their impact on CS education. While there is no doubt that the area is new and rapidly evolving, it is important to begin to catalogue and map the literature at this early stage. In this work, we systematically search and map 82 papers evaluating the impact of generative AI tools on CS education. We then build a literature map of these papers using the axes of population, use of generative AI, and method of evaluation. This work will serve as both a snapshot of the first generation of generative AI papers in the field, and a road-map for further classification and literature review as the field develops.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1467–1468},
numpages = {2},
keywords = {gen ai, generative ai, large language models, literature map, llm},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701841,
author = {Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D},
title = {Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701841},
doi = {10.1145/3641554.3701841},
abstract = {Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {chatgpt 3.5, digital accessibility, large language models, llms, project based learning, software engineering, wcag},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701873,
author = {Thorgeirsson, Sverrir and Ewen, Tracy and Su, Zhendong},
title = {What Can Computer Science Educators Learn From the Failures of Top-Down Pedagogy?},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701873},
doi = {10.1145/3641554.3701873},
abstract = {While educational researchers in various disciplines are grappling with how to develop policies and pedagogical approaches that address the use of generative artificial intelligence, the challenge is particularly complex in computer science education where the new technology is changing the core of the field. In this paper, we take a look at the pedagogy of other subjects with a longer history than computer science and a more extensive body of educational research to collect insights on how this challenge can be met. We begin by drawing from recent neurological research to find domains that share cognitive commonalities with computer programming and then build upon comparisons that others have made to literacy and mathematics education. We then consider how the "reading wars" and "math wars" have shaped these fields, which we see as conflicts between less effective top-down pedagogy and more effective bottom-up pedagogy, and reflect on what would be comparable approaches in teaching computing. We find that approaches that make heavy use of large language models without teaching fundamentals can be compared to the top-down pedagogy of reading and mathematics and are likely to be ineffective on their own. Therefore, we advise against the exclusive use of such approaches with novices. However, we also acknowledge that the social science surrounding computer science education is complex and that effectiveness only tells a part of the story, with other factors such as engagement, motivation and social dynamics also being important.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1127–1133},
numpages = {7},
keywords = {bottom-up pedagogy, computer science education, generative artificial intelligence, large language models, literacy, math wars, phonics, position paper, reading, reading wars, top-down pedagogy, whole language},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716647,
author = {Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto},
title = {LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716647},
doi = {10.1145/3716640.3716647},
abstract = {There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {56–63},
numpages = {8},
keywords = {generative AI, genAI, large language models, LLMs, GPT-4o, prompt engineering, synthetic data, bugs, submissions, data generation},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701829,
author = {Liu, Runda and Chen, Shengqi and Chen, Jiajie and Niu, Songjie and Ma, Yuchun and Tang, Xiaofeng},
title = {Iterative Design of a Teaching Assistant Training Program in Computer Science Using the Agile Method},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701829},
doi = {10.1145/3641554.3701829},
abstract = {Facing soaring enrollment and disruptive educational technologies, computing education increasingly relies on the contributions of teaching assistants (TAs), hence the critical importance of high-quality TA training. However, the design and implementation of TA training in computer science face substantial barriers, such as the lack of experienced TA trainers and the scarcity of relevant training materials.This experience report describes the design and implementation of a peer-led computer science TA training program that began in 2022 and has since undergone three iterations, inspired by the approach of agile software development. The current program consists of 10 sessions, organized to serve TAs in three respective stages of professional development. The iterations involved updating and enrichment of the syllabus, transitioning from lecture-centered to discussion-centered training, and discussions of emerging topics in computing education such as the use of large language models (LLMs). Participant feedback showed that TAs approved the iterative design of the training, while identifying areas for further improvement. We summarize lessons learned from the iterative process, reflect on the role of peer TA trainers, and discuss plans for future iterations.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {680–686},
numpages = {7},
keywords = {agile, ta training, teaching assistant},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720282,
author = {Mhasakar, Manas and Baker-Ramos, Rachel and Carter, Benjamin and Helekahi-Kaiwi, Evyn-Bree and Hester, Josiah},
title = {"I Would Never Trust Anything Western": Kumu (Educator) Perspectives on Use of LLMs for Culturally Revitalizing CS Education in Hawaiian Schools},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720282},
doi = {10.1145/3706599.3720282},
abstract = {As large language models (LLMs) become increasingly integrated into educational technology, their potential to assist in developing curricula has gained interest among educators. Despite this growing attention, their applicability in culturally responsive Indigenous educational settings like Hawai‘i’s public schools and Kaiapuni (immersion language) programs, remains understudied. Additionally, ‘undefinedlelo Hawai‘i, the Hawaiian language, as a low-resource language, poses unique challenges and concerns about cultural sensitivity and the reliability of generated content. Through surveys and interviews with kumu (educators), this study explores the perceived benefits and limitations of using LLMs for culturally revitalizing computer science (CS) education in Hawaiian public schools with Kaiapuni programs. Our findings highlight AI’s time-saving advantages while exposing challenges such as cultural misalignment and reliability concerns. We conclude with design recommendations for future AI tools to better align with Hawaiian cultural values and pedagogical practices, towards the broader goal of trustworthy, effective, and culturally grounded AI technologies.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {13},
numpages = {10},
keywords = {Culturally responsive pedagogy, Artificial Intelligence in education, Culturally-relevant CS, Hawaiian Immersion Language Schools, Large Language Models, Human-centered AI, Education technology, Indigenous knowledge, Low-resource languages},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705080,
author = {Morales, Jamie and Raman, Preeti},
title = {Prompt-Engineering Strategies for Minimizing Bias in Large Language Model Outputs: Applications in Computing Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705080},
doi = {10.1145/3641555.3705080},
abstract = {As large language models (LLMs) increasingly permeate educational applications, concerns about the perpetuation of bias persist. We present our preliminary work on developing prompt-engineering strategies to mitigate bias in content generated by LLMs in computer science (CS) education. This work investigates both empirical insights into fairness-aware prompt formulation and actionable takeaways for educators. We focus on an initial list of prompting strategies for mitigating bias and explore their impact on educational content generation. Recent research has shown the efficacy of prompt-base debiasing [1] as well as the potential disadvantages of using prompts that have not been mitigated for bias, from user dissatisfaction [2] to unsafe outputs [5, 6]. Additionally, a growing body of empirical work points to the idea that certain properties of in-context examples such as flow [7], illustration [3], and order [4] could either improve or derail LLM performance. Our study leverages these findings in the context of generating educational content. The goal is to promote fairness-aware approaches which can be applied to the automated generation of learning materials and the development of LLM-based educational tools. This work also contributes practical insights on prompt-engineering to the evolving curriculum of Ethics in Artificial Intelligence (AI).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1743},
numpages = {1},
keywords = {bias, education, ethics, generative ai, in-context examples, language model, language technology, llm, nlp, prompt-engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3704749,
author = {Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang},
title = {Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704749},
doi = {10.1145/3641555.3704749},
abstract = {Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1709–1710},
numpages = {2},
keywords = {AI, curriculum development, large language models, undergraduate education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3702163.3702188,
author = {Schefer-Wenzl, Sigrid and Vogl, Christoph and Peiris, Sahani and Miladinovic, Igor},
title = {Exploring the Adoption of Generative AI Tools in Computer Science Education: A Student Survey},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702188},
doi = {10.1145/3702163.3702188},
abstract = {The integration of generative AI tools into education has the potential to revolutionize learning experiences, particularly in computer science. This paper explores the adoption and utilization of generative AI tools among computer science students at the University of Applied Sciences Campus Vienna in Austria through a comprehensive survey. The study aims to understand the extent to which AI tools like ChatGPT are integrated into students' academic routines, their perceptions of these tools, and the challenges and opportunities they present. The survey results indicate a high level of acceptance and frequent use of AI tools for tasks such as programming, exam preparation, and generating simplified explanations. However, concerns about the accuracy of AI-generated content and the potential impact on critical thinking skills were also highlighted. The findings underscore the need for clear institutional guidelines and ethical considerations in the use of AI tools in education. This paper contributes to the growing body of literature on AI in education and provides insights for educators and policymakers to enhance the responsible integration of AI technologies in computer science curricula.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {173–178},
numpages = {6},
keywords = {Artificial Intelligence, Computer Science Education, Generative AI Tools, Higher Education},
location = {
},
series = {ICETC '24}
}

@article{10.1145/3722228,
author = {Bodon, Herminio and Kumar, Vishesh and Worsley, Marcelo},
title = {Design Principles for Authentically Embedding Computer Science in Sports},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722228},
doi = {10.1145/3722228},
abstract = {Objectives. Athletics and sports represent a focal part of adolescence for millions of youth around the world. However, opportunities to engage in computer science (CS) learning experiences are less prevalent, particularly among Hispanic and low-income communities. Recently, researchers have explored ways to bridge these, seemingly, disparate disciplines. Much of this prior research centers on the proliferation of sports technologies that support individualistic learning experiences. Additionally, many of these experiences are developed by researchers with limited design contributions from sports practitioners. To extend prior work, this project centers youth athletic identities and the associated cultural contexts of sports to explore ways that computing technologies can enhance and develop youth athletic identities and sports performance. Moreover, this work surfaces ways that athletics can be a generative and fulfilling space to learn about CS.Participants. In summer 2021, we collaborated with basketball coaches to design and implement a computing-enhanced learning experience with a basketball team of Hispanic participants in Puerto Rico. Eleven basketball athletes from a high school in southern Puerto Rico participated in the study. The participants have strong sports identities, as demonstrated by their lifelong engagement with team sports. Conversely, only one 1 of the 11 participants had experienced sports technologies, and none of them had previously participated in computing learning experiences.Study Method. In collaboration with local basketball coaches, we co-designed a learning experience that centers sports identities and practices and adds computing as a way to extend existing sports identities and local sports activities. We present and evaluate this learning experience using a design-based research approach. Participants’ feedback was collected in the form of surveys, designs, and journal entries, and additional data on their experiences were collected via videos and researchers’ field notes. Using a mixed-methods approach, we highlight existing participants’ identities and perceptions as well as their experiences with our design. We complement quantitative analysis of survey responses with case studies.Findings. We find that our design can provide shifts in youth student-athletes’ perceptions of computing. Additionally, hands-on experiences with computing tools enable participants to start practicing CS sensemaking via learning how different computing tools can support their sports performance individually and as a team. Furthermore, we find that the material, ideational, and relational resources made available through camp:bit supported each participant differently, while collectively providing a space for all of them to have meaningful and fulfilling experiences. Finally, we find that this design can foster and support sports team cohesion.Conclusions. We provide in-depth descriptions of our design, the youth’s engagement with it, and how these learning experiences can be further applied in sports spaces. These examples highlight a unique conception of practice-linked computational identities—where learners’ computational identities are grounded in a specific culturally relevant practice, enabling a more culturally sustaining computing learning experience. Finally, our analysis suggests five design principles for designing and conducting computing-supported learning experiences in sports environments. The principles are as follows: (1) Sports Experience: Authentically Support Existing Identities. (2) Team Dynamics: Team Athletes Are Part of a Whole. (3) Individual Pursuits: Supporting Individual Paths. (4) Direct Interactions: Conversations with Materials and Ideas. (5) Interdisciplinary Facilitation Team: Complementary Skills. These design principles can be used by researchers, practitioners, and local stakeholders to implement sport-centric CS learning experiences to extend and enhance the way student-athletes from marginalized communities practice sports, as well as to activate interest and engagement in CS.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {13},
numpages = {42},
keywords = {Sports, Wearable, Identity, Computing, Computer Science Education, Design-Based Research, Participation, Data Science, AI}
}

@inproceedings{10.1145/3717383.3721236,
author = {Rathore, Santosh Singh and Tiwari, Saurabh and Farooq, Sheikh Umar},
title = {Seventh Workshop on Emerging Software Engineering Education(WESEE 2025)},
year = {2025},
isbn = {9798400714245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717383.3721236},
doi = {10.1145/3717383.3721236},
abstract = {The seventh Workshop on Emerging Software Engineering Education (WESEE) aims to discuss and examine the development of learning environments that are influencing the pedagogical strategies for the education of software engineering courses in institutions, specifically through the adoption of Generative AI (GenAI) tools and techniques. Additionally, the workshop aims to examine how industries are utilizing GenAI tools and technologies for teaching software development methods and how the developers are utilizing the material for self-learning and skill acquisition. The report is an overview of the upcoming seventh edition of WESEE, which will be held on 20th February 2025 at NIT Kurukshetra. The workshop will be held alongside the 18th Innovations in Software Engineering Conference (ISEC 2025).},
booktitle = {Proceedings of the 18th Innovations in Software Engineering Conference},
articleno = {22},
numpages = {3},
location = {
},
series = {ISEC '25}
}

@inproceedings{10.1145/3641555.3705277,
author = {Tsang, Jedidiah and Li, Carol and Park, Su Min and Yan, Lisa},
title = {Using LLMs to Detect the Presence of Learning Outcomes in Submitted Work Within Computing Ethics Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705277},
doi = {10.1145/3641555.3705277},
abstract = {This study investigates how large language models (LLMs) can identify the presence of learning outcomes within student submitted work in a computing ethics course. To do so, we craft a codebook to spot key learning outcomes, such as the usage of critical reasoning and awareness of various social issues. We leverage the GPT-4o and GPT-3.5-turbo LLMs to apply codes onto 8,500 pieces of student submitted work. We then use Cohen's kappa to assess interrater reliability and compare human reviewers' coding to outputs from those models, finding that GPT-4o performed just as well as the agreement between human reviewers. We then use the model outputs to identify specific course readings that students engaged particularly deeply with to better inform our computing ethics instruction.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1641–1642},
numpages = {2},
keywords = {codebook, computing ethics, critical consciousness, large language models, positionality},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713644,
author = {Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia},
title = {Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713644},
doi = {10.1145/3706598.3713644},
abstract = {This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {22},
keywords = {Computer Science Education, LLM, Teachable Agent, Deception, Learning by Teaching, University Students, Longitudinal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3716640.3716658,
author = {Feng, Tony Haoran and Luxton-Reilly, Andrew and W\"{u}nsche, Burkhard C and Denny, Paul},
title = {From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716658},
doi = {10.1145/3716640.3716658},
abstract = {Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes.In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {164–171},
numpages = {8},
keywords = {Generative Artificial Intelligence, GenAI, Strategy, Assignments, Metacognition, Assessments},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701872,
author = {McDanel, Bradley and Novak, Ed},
title = {Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701872},
doi = {10.1145/3641554.3701872},
abstract = {The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {756–762},
numpages = {7},
keywords = {ai-resistant assignments, assignment design, cs education, llm code generation, programming pedagogy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705236,
author = {Chopra, Ryka C. and Chakraborty, Suparna},
title = {RAFIKI: Leveraging Large Language Models to Increase AP Computer Science A Enrollment among Disadvantaged High School Females},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705236},
doi = {10.1145/3641555.3705236},
abstract = {The gender gap in computing persists even after decades of investment in lowering the gap. Evidence suggests that stereotypical attitudes and bias perceptions play a critical role in limiting female participation in STEM, beginning in middle and high school. The gap is exacerbated in developing nations with limited academic counselor support. Therefore, the goal is to provide early targeted counseling. RAFIKI - "friend" in Swahili is a large language model-based web application designed to mimic an academic coach. Using user inputs, it provides customized academic counseling with curated information on STEM and computing pathways. Initial experimental evidence shows that RAFIKI use leads to a significant increase in AP Computer Science A course enrollment, considered a pathway to future computing career, particularly among female high school students.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1417–1418},
numpages = {2},
keywords = {AP CSA, ChatGPT, digital coach, female enrollment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3702163.3702182,
author = {Yaqub, Irfan and Chen, Zhiyuan and Liao, Iman Yi and Maul, Tomas and Seow, Hsin-Vonn and Chandesa, Tissa},
title = {A Novel Framework using Large Language Models to Automate Coursework Feedback for Computer Science modules},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702182},
doi = {10.1145/3702163.3702182},
abstract = {Prompt and sufficient feedback is essential for students' academic learning since it enables them to review their learning techniques and improve their areas of weakness. Nevertheless, delivering personalised feedback to every student continues to be difficult&nbsp;for teachers due to its demanding and time-intensive nature. While automated feedback systems are available, their primary focus is providing feedback on a single subject, and most of them utilise statistical analysis or traditional machine learning techniques to provide feedback. Moreover, no feedback model utilises the same criteria to generate text-based feedback for more than one subject. Generative artificial intelligence (GEN AI) has recently made incredible progress, and large language models (LLMs) can retain the context from the vast amount of text. Hence, this research presents a framework that employs an innovative technique to offer text-based feedback to students in different fields of study. This framework employs two LLMs, one for generating the feedback and another for categorising it into separate subjects using suitable headings for structural organising. Consequently, the output produced by this technology corresponds to the original tone of the teacher.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {130–137},
numpages = {8},
keywords = {Deep Learning Artificial Intelligence, Generative Artificial Intelligence, Large Language Model},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3641555.3705250,
author = {Akhmetov, Ildar and Prpa, Mirjana},
title = {Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705250},
doi = {10.1145/3641555.3705250},
abstract = {We present the Requirement Elicitation Tool that leverages Large Language Model (LLM) (gpt-4o-mini) to enable simulated real-world interactions of requirements gathering from three synthetic personas. We demonstrate the use case of Computer Science (CS) students in Database Management Systems leveraging the tool to build a conceptual model and Entity-Relationship (ER) diagrams. Our preliminary findings show the potential of this tool to engage students in discovery process without providing predefined solutions and set the directions for future work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1357–1358},
numpages = {2},
keywords = {AI persona, requirement elicitation, software engineering education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716654,
author = {Gutierrez, Sebastian and Hou, Irene and Lee, Jihye and Angelikas, Kenneth and Man, Owen and Mettille, Sophia and Prather, James and Denny, Paul and MacNeil, Stephen},
title = {Seeing the Forest and the Trees: Solving Visual Graph and Tree Based Data Structure Problems using Large Multimodal Models},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716654},
doi = {10.1145/3716640.3716654},
abstract = {Recent advancements in generative AI systems have raised concerns about academic integrity among educators. Beyond excelling at solving programming problems and text-based multiple-choice questions, recent research has also found that large multimodal models (LMMs) can solve Parsons problems based only on an image. However, such problems are still inherently text-based and rely on the capabilities of the models to convert the images of code blocks to their corresponding text. In this paper, we further investigate the capabilities of LMMs to solve graph and tree data structure problems based only on images. To achieve this, we computationally construct and evaluate a novel benchmark dataset comprising 9,072 samples of diverse graph and tree data structure tasks to assess the performance of the GPT-4o, GPT-4 with Vision (GPT-4V), Gemini 1.5 Pro, Gemini 1.5 Flash, Gemini 1.0 Pro Vision, and Claude 3 model families. GPT–4o and Gemini 1.5 Flash performed best on trees and graphs respectively. GPT-4o achieved 87.6% accuracy on tree samples, while Gemini 1.5 Pro, achieved 76.9% accuracy on graph samples. Our findings highlight the influence of structural and visual variations on model performance. This research not only introduces an LMM benchmark to facilitate replication and further exploration but also underscores the potential of LMMs in solving complex computing problems, with important implications for pedagogy and assessment practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {Generative AI, Academic Integrity, Computing Education, Large Multimodal Models, LMMs, Large Language Models, LLMs},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701946,
author = {Li, Nero and Broner, Shahar and Kim, Yubin and Mizuo, Katrina and Sauder, Elijah and To, Claire and Wang, Albert and Gila, Ofek and Shindler, Michael},
title = {Investigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701946},
doi = {10.1145/3641554.3701946},
abstract = {There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs).We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {659–665},
numpages = {7},
keywords = {algorithm design techniques, chatgpt, computational thinking, computer-assisted instruction, data structures, generative ai, gpt-4, gpt-4o, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705125,
author = {Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma},
title = {An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705125},
doi = {10.1145/3641555.3705125},
abstract = {Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1681–1682},
numpages = {2},
keywords = {computer science education, large language model, solo taxonomy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3736407,
author = {Weyssow, Martin and Kamanda, Aton and Zhou, Xin and Sahraoui, Houari},
title = {CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3736407},
doi = {10.1145/3736407},
abstract = {Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavor that requires a deep assessment of LLMs’ outputs. Existing methods and benchmarks rely primarily on automated metrics and static analysis tools, which often fail to capture the nuances of user instructions and LLM outputs. To address this gap, we introduce the LLM-as-a-Judge evaluation framework and present CodeUltraFeedback, a comprehensive dataset for assessing and improving LLM alignment with coding preferences. CodeUltraFeedback consists of 10,000 coding instructions, each annotated with four responses generated from a diverse pool of 14 LLMs. These responses are annotated using GPT-3.5 as a judge, with both ranking-based scores and detailed textual feedback across five distinct coding preferences. Our analysis reveals that responses from GPT-3.5 and GPT-4 are consistently rated higher than those from open-weight models, underscoring substantial alignment gaps between closed- and open-weight LLMs. In turn, we explore the usage of CodeUltraFeedback as feedback data to fine-tune and align CodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement learning from AI feedback (RLAIF) with direct preference optimization (DPO). The resulting aligned model achieves an average alignment improvement of 22.7% and 29.7% when evaluated with GPT-3.5 and GPT-4 judges, respectively. Notably, our aligned CodeLlama-7B-Instruct surpasses much larger models, such as CodeLlama-13B and 34B, in alignment with coding preferences. Despite not being explicitly trained for functional correctness, it also achieves a 10.5% and 26.6% relative improvement in Pass@ (1)  and Pass@ (10)  on the HumanEval+ benchmark. Our contributions demonstrate the practical value of preference tuning in code generation and set the stage for further progress in model alignment and RLAIF for automated software engineering.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Large language models, code generation, automated software engineering, reinforcement learning from AI feedback, direct preference optimization, LLM-as-a-Judge}
}

@inproceedings{10.1145/3641555.3705282,
author = {\v{R}echt\'{a}\v{c}kov\'{a}, Anna and Maximova, Alexandra and Pitts, Griffin},
title = {Finding Misleading Identifiers in Novice Code Using LLMs},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705282},
doi = {10.1145/3641555.3705282},
abstract = {Clear, well-chosen names for variables and functions significantly enhance code readability and maintainability. In computer science education, teaching students to select appropriate identifiers is a critical task, especially in CS1. This study explores how large language models (LLMs) could assist in teaching this skill. While prior research has explored the use of LLMs in programming education, their precision and consistency in teaching code quality, particularly identifier selection, remains largely unexplored. For this purpose, this study investigated how well different LLMs can detect and report misleading identifiers. In a dataset of 33 code samples, we manually labeled misleading identifiers. On this dataset, we then tested five different LLMs on their ability to detect these misleading identifiers, measuring the overall accuracy, precision, recall, and f-score. Results revealed that the most successful model, GPT-4o, was able to correctly detect most of the manually flagged misleading variable names. However, it also tended to flag issues with variable identifiers in cases where the human evaluators would not, and refined prompting was not able to discourage this behavior.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1595–1596},
numpages = {2},
keywords = {automated feedback, code quality, misleading identifiers, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705215,
author = {Niousha, Rose and O'Neill, Abigail and Chen, Ethan and Malhotra, Vedansh and Akram, Bita and Norouzi, Narges},
title = {LLM-KCI: Leveraging Large Language Models to Identify Programming Knowledge Components},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705215},
doi = {10.1145/3641555.3705215},
abstract = {Identifying Knowledge Components (KCs) in computer science education improves curriculum design and teaching strategies. We introduce a framework using Large Language Models to identify KCs from programming assignments automatically. Our framework helps educators align assignments with course objectives. GPT-4 identifies relevant KCs well, though there's a low match with expert-generated KCs at the course level. At the problem level, performance is lower, but key KCs are reasonably identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1557–1558},
numpages = {2},
keywords = {cs1, knowledge component, large language model},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706468.3706529,
author = {Hassany, Mohammad and Brusilovsky, Peter and Savelka, Jaromir and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil and Agarwal, Arav and Hendrawan, Rully Agus},
title = {Generating Effective Distractors for Introductory Programming Challenges: LLMs vs Humans},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706529},
doi = {10.1145/3706468.3706529},
abstract = {As large language models (LLMs) show great promise in generating a wide spectrum of educational materials, robust yet cost-effective assessment of the quality and effectiveness of such materials becomes an important challenge. Traditional approaches, including expert-based quality assessment and student-centered evaluation, are resource-consuming, and do not scale efficiently. In this work, we explored the use of pre-existing student learning data as a promising approach to evaluate LLM-generated learning materials. Specifically, we used a dataset where students were completing the program construction challenges by picking the correct answers among human-authored distractors to evaluate the quality of LLM-generated distractors for the same challenges. The dataset included responses from 1,071 students across 22 classes taught from Fall 2017 to Spring 2023. We evaluated five prominent LLMs (OpenAI-o1, GPT-4, GPT-4o, GPT-4o-mini, and Llama-3.1-8b) across three different prompts to see which combinations result in more effective distractors, i.e., those that are plausible (often picked by students), and potentially based on common misconceptions. Our results suggest that GPT-4o was the most effective model, matching close to 50% of the functional distractors originally authored by humans. At the same time, all of the evaluated LLMs generated many novel distractors, i.e., those that did not match the pre-existing human-authored ones. Our preliminary analysis shows that those appear to be promising. Establishing their effectiveness in real-world classroom settings is left for future work.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {484–493},
numpages = {10},
keywords = {Large Language Models (LLMs), Distractor Generation and Evaluation, Student Learning Data, Introductory Programming, GPT, LLaMA},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3716640.3716651,
author = {Qiao, Shuying and Denny, Paul and Giacaman, Nasser},
title = {Oversight in Action: Experiences with Instructor-Moderated LLM Responses in an Online Discussion Forum},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716651},
doi = {10.1145/3716640.3716651},
abstract = {The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {95–104},
numpages = {10},
keywords = {Large language models, LLMs, discussion forums, instructor-in-the-loop, software engineering education, chatbots, computing education},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641554.3701858,
author = {Tran, Minh and Gonzalez-Maldonado, David and Zhou, Elaine and Franklin, Diana},
title = {Can GPT Help? Supporting Teachers to Brainstorm Customized Instructional Scratch Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701858},
doi = {10.1145/3641554.3701858},
abstract = {While many recent studies have explored how large language models can transform computer science instruction from the instructor perspective, they are primarily at the college level. Thus, little is known about using large language models towards curriculum development and teacher supports outside of the college setting. Given the emphasis placed on culturally responsive teaching at the K-8 level and well-documented evidence of insensitive and inaccurate language model outputs from a cultural perspective, it is imperative to perform systematic and principled research before considering their use in this setting.This paper explores the potential of teachers using large language models to brainstorm instructional Scratch projects. Specifically, we use GPT-3 to mimic structured projects from an existing computer science curriculum but situate the generated projects in different contexts/themes. We qualitatively analyze 300 project ideas generated by GPT and find 81% of the generated ideas satisfy our metrics for technical alignment and theme quality. We identify two major weaknesses: code complexity of generated projects and presence of potential insensitive elements that would require human filtering. We conclude that, while not ready as a student-facing solution, teachers could use GPT to effectively brainstorm customized instructional materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1134–1140},
numpages = {7},
keywords = {curriculum customization, k-8, large language models, scratch programming, teacher supports},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701859,
author = {Gorson Benario, Jamie and Marroquin, Jenn and Chan, Monica M. and Holmes, Ernest D.V. and Mejia, Daniel},
title = {Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701859},
doi = {10.1145/3641554.3701859},
abstract = {Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {395–401},
numpages = {7},
keywords = {cs education, generative ai, llms in cs education, minority serving institutions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3709026.3709030,
author = {Liew, Pei Yee and Tan, Ian K. T.},
title = {On Automated Essay Grading using Large Language Models},
year = {2025},
isbn = {9798400718182},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709026.3709030},
doi = {10.1145/3709026.3709030},
abstract = {Automated Essay Grading (AEG), combining Automated Essay Scoring (AES) and Automated Writing Evaluation (AWE), is a time-saving solution to the challenges of manual essay evaluation. It aims to reduce the workload on educators by offering a more consistent grading approach. Inspired by ChatGPT’s impressive language comprehension and generation capabilities, this study explored the potential of various Large Language Models (LLMs) in AEG tasks. The models examined include GPT-4, GPT-3.5, PaLM, and LLaMA2. Tailored prompts were designed and their performance was assessed in conjunction with each LLM through prompt engineering. Our study shows that LLMs can achieve substantial agreement with human markers in AES, with a Quadratic Weighted Kappa (QWK) score of 0.68. In AWE, the feedback on the essay was assessed qualitatively. It achieved an agreement level score of 4.9 (out of 5) with a standard deviation of 0.05, closely aligned with human assessment. This study provided valuable insights into the effectiveness of LLMs in automated essay grading. It highlighted their potential to enhance educational assessment practices.},
booktitle = {Proceedings of the 2024 8th International Conference on Computer Science and Artificial Intelligence},
pages = {204–211},
numpages = {8},
keywords = {automated essay scoring, automated writing evaluation, large language models, prompt engineering},
location = {
},
series = {CSAI '24}
}

@inproceedings{10.1145/3716640.3716652,
author = {Edwards, John and Hellas, Arto and Leinonen, Juho},
title = {On the Opportunities of Large Language Models for Programming Process Data},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716652},
doi = {10.1145/3716640.3716652},
abstract = {Computing educators and researchers have long used programming process data to understand how students construct programs and address challenges. Despite its potential, fully automated feedback systems remain underexplored. The emergence of Large Language Models (LLMs) offers new opportunities for analyzing programming data and providing formative feedback. This study explores using LLMs to summarize programming processes and deliver formative feedback. A case study analyzed keystroke-level data from an introductory programming course, processed into code snapshots. Three state-of-the-art LLMs – Claude 3 Opus, GPT-4 Turbo, and LLaMa2 70B Chat – were evaluated for their feedback capabilities. Results show LLMs effectively provide tailored feedback, emphasizing incremental development, algorithmic planning, and code readability. Our findings highlight the potential of combining keystroke data with LLMs to automate formative feedback, showing that the computing education research and practice community is again one step closer to automating formative programming process feedback.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {105–113},
numpages = {9},
keywords = {programming process data, large language models, generative AI, programming process feedback, programming process summarization, keystroke data},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705132,
author = {Blasco, I\~{n}aki and Mochetti, Karina},
title = {Assessing the Influence of ChatGPT on Student Outcomes in a Models of Computing Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705132},
doi = {10.1145/3641555.3705132},
abstract = {This study investigates the impact of ChatGPT on student performance in a Models of Computing course, foundational for the computer science major. Analysing data from 11 pre-lecture quizzes across four terms, we found a decline in average quiz scores, particularly in the latest term. The results suggest a correlation between increased reliance on ChatGPT and decreased student performance, especially on challenging questions where the AI frequently struggled. These findings highlight both the benefits and challenges of integrating AI in education. Our ongoing research aims to explore this further across multiple courses, ultimately promoting responsible AI use to enhance learning outcomes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1389–1390},
numpages = {2},
keywords = {computing education, llm, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.5555/3712729.3712987,
author = {Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.},
title = {Understanding Optimal Interactions between Students and a Chatbot during a Programming Task},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3106–3117},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3723010.3723021,
author = {Fischer, David Vincent and Haug, Jim and Schoppel, Paul and Abke, J\"{o}rg and Becker, Matthias and Hagel, Georg},
title = {Evaluation of a Node-based Automatic Short Answer Tool “NodeGrade”},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723021},
doi = {10.1145/3723010.3723021},
abstract = {NodeGrade tries to provide a suitable solution for the problem of time-intensive short answer grading. This research focuses simultaneously on performance, functionality and user experience, which is underlined by a triangulated approach. The evaluation results show comparable performance of NodeGrade on public datasets, even outperforming GPT-4 on the SemEval 2013 Task 7. Matching of NodeGrade’s output with multiple human expert raters reveals some weaknesses regarding cases at the lower and upper boundary. In terms of user experience, the interviewed and observed students recognized both positive facets, like better learning support and helpful feedback, and negative sides, including technical limitations and lack of transparency. Overall, NodeGrade promises high potential for further practical use and testing in the field of software engineering education and automatic short answer grading.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {20–29},
numpages = {10},
keywords = {ASAG, Automatic Short Answer Grading, Short Answer Scoring, AI in Education, Software Engineering Education, Natural Language Processing, Large Language Models},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3702212.3702214,
author = {Clift, Lee and Petrovska, Olga},
title = {Learning without Limits: Analysing the Usage of Generative AI in a Summative Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702214},
doi = {10.1145/3702212.3702214},
abstract = {This paper explores how Generative AI (GenAI) can be introduced within summative assessment components in software engineering education. We present an example of an assessment which allows learners to use GenAI in a freeform, constructionist manner, as part of a large, software development project. This work is inspired by previously executed AI-focused assessments and surveys, which explicitly indicate that learners on an Applied Software Engineering Degree Apprenticeship Programme want to formally learn how to use GenAI tools when programming and their employers want to see these skills from graduates. The learning outcome of the assignment was for learners to explore a typical developmental pipeline as a solo developer, moving from design to development to finished product. Learners were marked exclusively on their end product and understanding of application components, not the written code itself, resulting in an assessment where the end product and project were prioritised over foundational code (which was adequately assessed in other components). The results show that all learners used GenAI to some extent during their project, and in all cases, they found it beneficial for large programming tasks. Learners were generally able to produce a larger, more comprehensive and more ambitious project, compared to previous years. It is proposed that removing the barrier to GenAI - and demystifying it - can encourage a constructionist approach to its use, and normalise it as a potential tool for programming.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {5–8},
numpages = {4},
keywords = {GenAI, software engineering, education, apprenticeship},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3723010.3723012,
author = {Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis},
title = {Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723012},
doi = {10.1145/3723010.3723012},
abstract = {The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {161–170},
numpages = {10},
keywords = {software development project course, software engineering education, AI support, AI-based tutoring, experiments},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641555.3705178,
author = {Eikmeier, Nicole and Perlmutter, Leah},
title = {Experiences Teaching A Course On Algorithms, Ethics, and Society},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705178},
doi = {10.1145/3641555.3705178},
abstract = {It is essential for CS students to graduate with competence about ethics and societal impacts of technology. We designed and taught a new reading discussion course, at Grinnell College, Algorithms, Ethics, and Society, for advanced undergraduate students who have completed CS1 and CS2. Course topics included Identity in Computing, Tech Ethics, Algorithms Informing Policies, Large Language Models, Networks and Social Media, Health Applications, and Robotics. We encountered some challenges with the discussion format, which we addressed by upholding class norms, employing discussion techniques learned from humanities and social science colleagues, and being open to learn from our mistakes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1449–1450},
numpages = {2},
keywords = {computer science education, computing and society, technology ethics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3708394.3708437,
author = {Wang, Xiaohui and Yu, Ruijie and Zhang, Yu and Xu, Yanyan},
title = {English Composition Image Automatic Scoring Based on Multi-modal Large Language Models},
year = {2025},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708394.3708437},
doi = {10.1145/3708394.3708437},
abstract = {Large language models (LLMs) bring significant opportunities in the field of education evaluation. Nowadays, most existing LLMs are introduced to generate reasonable scores for electronic and structurized documents. However, such systems require huge efforts for manual typewriting or advanced optical character recognition techniques. To this end, this work directly processes the scanning copy of English composition with multi-modal LLMs. Specifically, this research aims to utilize multi-modal LLMs for automated essay scoring (AES) and evaluate its reliability and accuracy. We take the English composition images of 1,511 tenth-grade examinees in a standardized test environment as the research objects for automated scoring, and explore the performance of the multi-modal LLM GPT-4o in evaluating composition image data. The study compares the consistency of the composition image scores of GPT-4o under zero-shot and two-shot prompts with the scores of the marking experts, and verifies them through multiple indicators such as the exact agreement coefficient, Pearson correlation coefficient, Coefficient of determination, Root Mean Square Error, and the probability that the GPT-4o score falls within a given confidence interval. Especially, comparing the scores given by experts, the R-square of the GPT-4o scoring reaches 0.66. The results show that GPT-4o has the ability to learn from two samples through prompt, can quickly adapt and provide high-quality and personalized evaluations for examinees, and can provide valuable support for human scoring.},
booktitle = {Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
pages = {247–254},
numpages = {8},
keywords = {Automated Essay Scoring, GPT-4o, Multi-modal large language model, Prompt Learning},
location = {
},
series = {AIFE '24}
}

@inproceedings{10.1145/3641554.3701800,
author = {Shah, Anshul and Chernova, Anya and Tomson, Elena and Porter, Leo and Griswold, William G. and Soosai Raj, Adalbert Gerald},
title = {Students' Use of GitHub Copilot for Working with Large Code Bases},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701800},
doi = {10.1145/3641554.3701800},
abstract = {Large language models (LLMs) are already heavily used by professional software engineers. An important skill for new university graduates to possess will be the ability to use such LLMs to effectively navigate and modify a large code base. While much of the prior work related to LLMs in computing education focuses on novice programmers learning to code, less work has focused on how upper-division students use and trust these tools, especially while working with large code bases. In this study, we taught students about various GitHub Copilot features, including Copilot chat, in an upper-division software engineering course and asked students to add a feature to a large code base using Copilot. Our analysis revealed a novel interaction pattern that we call one-shot prompting, in which students ask Copilot to implement the entire feature at once and spend the next few prompts asking Copilot to debug the code or asking Copilot to regenerate its incorrect response. Finally, students reported significantly more trust in the code comprehension features than code generation features of Copilot, perhaps due to the presence of trust affordances in the Copilot chat that are absent in the code generation features. Our study takes the first steps in understanding how upper-division students use Github Copilot so that our instruction can adequately prepare students for a career in software engineering.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1050–1056},
numpages = {7},
keywords = {github copilot, large code bases, program comprehension, trust},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701785,
author = {Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701940,
author = {Riazi, Sara and Rooshenas, Pedram},
title = {LLM-Driven Feedback for Enhancing Conceptual Design Learning in Database Systems Courses},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701940},
doi = {10.1145/3641554.3701940},
abstract = {The integration of LLM-generated feedback into educational settings has shown promise in enhancing student learning outcomes. This paper presents a novel LLM-driven system that provides targeted feedback for conceptual designs in a Database Systems course. The system converts student-created entity-relationship diagrams (ERDs) into JSON format, allows the student to prune the diagram by isolating a relationship, extracts relevant requirements for the selected relationship, and utilizes a large language model (LLM) to generate detailed feedback. Additionally, the system creates a tailored set of questions and answers to further aid student understanding. Our pilot implementation in a Database System course demonstrates effective feedback generation that helped the students improve their design skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1001–1007},
numpages = {7},
keywords = {conceptual design, database systems, educational technology, large language models, llm-generated feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701957,
author = {Basit, Nada and Floryan, Mark and Hott, John R. and Huo, Allen and Le, Jackson and Zheng, Ivan},
title = {ASCI: AI-Smart Classroom Initiative},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701957},
doi = {10.1145/3641554.3701957},
abstract = {The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students who were grouped using the tool were more likely to return to the queue more than twice as often (on average) than those who were not. However, while grouping in office hours has the potential to decrease student wait times, teaching assistants and students tend to favor one-on-one meetings over group meetings. This might be improved in the future with updates to the software, TA training, and incorporation of other supporting tools (e.g., LLM technology). The other, newer, tools will be more thoroughly evaluated in future semesters.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {81–87},
numpages = {7},
keywords = {computer science education, cosine similarity, group formation, office hours},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3737313.3737334,
author = {Fernandez, Amanda S. and Patrick, David and Gomez, Mauricio and Cornell, Kimberly A.},
title = {Incorporating LLM Activities into Established CS1 Curriculum: An Experience Report},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Large Language Models (LLMs), including Gemini, CoPilot, and ChatGPT, have experienced significant growth in usage and adoption in recent years. As these models become more sophisticated, particularly in code generation capabilities, educators need to adapt their CS1 courses. In this experience report, we share observations we made while designing and teaching LLM activities for CS1 students at two academic institutions during the spring 2024 term. Drawing on recent research, our activities consist of four short 10-15 minute exercises that guide students in how to properly utilize LLMs within their CS1 coursework. These activities can be easily added to the existing CS1 course curriculum to supplement the existing course materials. Post-activity surveys indicated a positive impact on students' understanding of CS concepts and indicated enthusiasm for learning how to use LLMs safely in programming.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {79–93},
numpages = {15}
}

@book{10.1145/3708897,
author = {Giacaman, Nasser and Terragni, Valerio},
title = {Empowering Computing Students with Large Language Models by Developing an Escape Room Game},
year = {2025},
isbn = {9798400714450},
abstract = {In this project, computing students learn to integrate large language models (LLMs) into a software system. Students develop a Java application with a basic graphical user interface (GUI) using JavaFX, gain practical experience with prompt engineering, and learn about the impact of LLM parameters and conversational roles. Students are provided with a Javabased API that connects with OpenAI's GPT model. The project emphasizes teaching students to manage LLM API calls, enhance GUI responsiveness, and improve the user experience all in the context of an AI-powered application. This experience equips them with critical skills in software development and AI application. It prepares them for advanced software development by learning how to create effective LLM prompts to create intelligent and user-friendly applications. We share the experience of using this project and provide guidelines for assessing it in a second-year software engineering undergraduate course, where students' prior programming experience is limited to the prerequisite CS2 course on object-oriented programming. In the case study we present, the project involved developing a riddle-solving escape room, which we called EscAIpe Room.},
numpages = {6}
}

@inproceedings{10.1145/3641555.3705074,
author = {Roy, Nimisha and Olufisayo, Omojokun and Horielko, Oleksandr},
title = {Empowering Future Software Engineers: Integrating AI Tools into Advanced CS Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705074},
doi = {10.1145/3641555.3705074},
abstract = {Artificial Intelligence (AI) tools have transformed software development, making it crucial to equip computer science (CS) students with the skills to leverage these technologies. This talk presents an innovative curriculum approach, integrating AI tools into an advanced CS capstone course at a stage where students possess foundational skills in software engineering. This strategic timing ensures students can critically engage with AI, recognizing biases and managing challenges like hallucinations in AI-generated outputs.Before redesigning the curriculum, independent research was conducted to understand the strengths and limitations of various AI tools, such as Lucidchart, Eraser.io for design documentation, and GitHub Copilot, GPT-4, Codeium, Claude, and Gemini for implementation tasks like code generation, code completion, UI design, error handling, and API integration. This research guided the curriculum by shaping assignment design and delivering foundational lectures on prompt engineering to ease the learning curve for students. Experiments during the capstone course included AI-enhanced assignments and projects, where students applied these tools for software design and implementation. Quantitative data-prompt refinement counts, error rates, code accuracy, and qualitative reflections revealed increased confidence in AI tools, enhanced productivity, and greater readiness for industry roles. Despite these benefits, students faced challenges with complex tasks that required iterative refinement and oversight, but they gained skills in managing biases and hallucinations in AI outputs. The curriculum's ''right-left'' approach enables a smooth transition to AI-assisted development, preparing students for the evolving tech landscape. This talk shares key findings, best practices, and insights into balancing manual skills with AI-enhanced learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1747},
numpages = {1},
keywords = {ai-enhanced learning, capstone courses, gen-ai tools in curriculum, iterative prompting., software engineering education, student preparedness},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701867,
author = {Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi},
title = {Bridging Novice Programmers and LLMs with Interactivity},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701867},
doi = {10.1145/3641554.3701867},
abstract = {While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1295–1301},
numpages = {7},
keywords = {cs1, generative ai, llms, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701953,
author = {Deb, Debzani and Taylor, Greg and Betz, Scott and Maddux, Bao Anh T. and Ebert, C. Edward and Richardson, Flourice W. and Couto, Jeanine Lino S. and Jarrett, Michael S. and Madjd-Sadjadi, Zagros},
title = {Enhancing University Curricula with Integrated AI Ethics Education: A Comprehensive Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701953},
doi = {10.1145/3641554.3701953},
abstract = {As AI technologies become more prevalent, it is crucial for students to develop responsible, ethical, and proactive AI engagement skills. Recent educational initiatives have focused on enhancing CS and engineering students' AI ethics education but have largely overlooked integrating these concepts across other disciplines. This paper presents and assesses a pioneering initiative that integrates AI ethics into university curricula through a collaborative framework between CS and domain educators. We introduced 1-3 week AI ethics modules in seven diverse courses from Art to Chemistry, incorporating case studies and hands-on activities using chat- or image-based Large Language Models (LLMs). Student surveys indicated significant gains in confidence regarding AI ethics discussions, application of principles, and reasoning skills. Our approach advocates for utilizing structured frameworks and faculty collaboration in embedding AI ethics into university curricula, enhancing students' practical skills and ethical understanding across diverse professional settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {248–254},
numpages = {7},
keywords = {ai ethics, computing education, ethics education, inclusive computing curricula and pedagogy, non-majors},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716657,
author = {Arora, Utkarsh and Garg, Anupam and Gupta, Aryan and Jain, Samyak and Mehta, Ronit and Oberoi, Rupin and Prachi and Raina, Aryaman and Saini, Manav and Sharma, Sachin and Singh, Jaskaran and Tyagi, Sarthak and Kumar, Dhruv},
title = {Analyzing LLM Usage in an Advanced Computing Class in India},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716657},
doi = {10.1145/3716640.3716657},
abstract = {This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys and interviews.Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {154–163},
numpages = {10},
keywords = {Large Language Models, Computing Education, User Study},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705183,
author = {Brockenbrough, Allan and Feild, Henry and Salinas, Dominic},
title = {Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705183},
doi = {10.1145/3641555.3705183},
abstract = {In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1401–1402},
numpages = {2},
keywords = {LLM, generative AI, large language model, user story},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706890.3707043,
author = {Chen, Yulin and Luo, Jing and Tu, Xinhui},
title = {React Agent-Based Question Answering Method for Biology in National College Entrance Examination},
year = {2025},
isbn = {9798400717826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706890.3707043},
doi = {10.1145/3706890.3707043},
abstract = {Recent advancements in large language models have led to significant improvements in various natural language processing tasks, including automated question answering. However, these models still struggle with providing accurate responses to complex biology questions, such as those found in the National College Entrance Examination. To address this issue, researchers have explored retrieval-augmented generation techniques, which incorporate external knowledge sources to enhance answer accuracy. While these methods have shown promise in improving efficiency, they often lack the ability to perform in-depth analysis of complex questions. In response to these limitations, the paper proposes a novel ReAct agent-based question answering method. This method combines biology textbook document libraries with Google search engine capabilities, leveraging the strengths of large language models. By integrating these components, this method can engage in autonomous decision-making and multi-step reasoning, allowing for a more thorough analysis of complex biology questions. Experimental results demonstrate the effectiveness of this new approach. When compared to responses generated directly by ChatGPT and GPT-4o models, the method showed significant improvements in accuracy for biology questions from the National College Entrance Examination. Specifically, the new method achieved accuracy increases of 11.1% and 4.64% over ChatGPT and GPT-4o, respectively.},
booktitle = {Proceedings of the 2024 5th International Symposium on Artificial Intelligence for Medicine Science},
pages = {892–897},
numpages = {6},
keywords = {Agent, Automated question answering, Large language models, Retrieval-augmented generation},
location = {
},
series = {ISAIMS '24}
}

@inproceedings{10.1145/3715669.3725868,
author = {Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban},
title = {Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3725868},
doi = {10.1145/3715669.3725868},
abstract = {As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {80},
numpages = {8},
keywords = {Code Summarization, Eye tracking, empirical study, code comprehension, Large Language Models, AI4SE},
location = {
},
series = {ETRA '25}
}

@inproceedings{10.1145/3706468.3706530,
author = {Thomas, Danielle R and Borchers, Conrad and Kakarla, Sanjit and Lin, Jionghao and Bhushan, Shambhavi and Guo, Boyuan and Gatz, Erin and Koedinger, Kenneth R},
title = {Does Multiple Choice Have a Future in the Age of Generative AI? A Posttest-only RCT},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706530},
doi = {10.1145/3706468.3706530},
abstract = {The role of multiple-choice questions (MCQs) as effective learning tools has been debated in past research. While MCQs are widely used due to their ease in grading, open response questions are increasingly used for instruction, given advances in large language models (LLMs) for automated grading. This study evaluates MCQs effectiveness relative to open-response questions, both individually and in combination, on learning. These activities are embedded within six tutor lessons on advocacy. Using a posttest-only randomized control design, we compare the performance of 234 tutors (790 lesson completions) across three conditions: MCQ only, open response only, and a combination of both. We find no significant learning differences across conditions at posttest, but tutors in the MCQ condition took significantly less time to complete instruction. These findings suggest that MCQs are as effective, and more efficient, than open response tasks for learning when practice time is limited. To further enhance efficiency, we autograded open responses using GPT-4o and GPT-4-turbo. GPT models demonstrate proficiency for purposes of low-stakes assessment, though further research is needed for broader use. This study contributes a dataset of lesson log data, human annotation rubrics, and LLM prompts to promote transparency and reproducibility.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {494–504},
numpages = {11},
keywords = {Tutoring, Generative AI, Human-AI tutoring, AI-assisted tutoring, Assessment},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3689187.3709614,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709614},
doi = {10.1145/3689187.3709614},
abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {300–338},
numpages = {39},
keywords = {artificial intelligence, computing education, genai, generative ai, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inbook{10.5555/3716662.3716748,
author = {Mueller, Felix B and G\"{o}rge, Rebekka and Bernzen, Anna K and Pirk, Janna C and Poretschkin, Maximilian},
title = {LLMs and Memorization: On Quality and Specificity of Copyright Compliance},
year = {2025},
publisher = {AAAI Press},
abstract = {Memorization in large language models (LLMs) is a growing concern. LLMs have been shown to easily reproduce parts of their training data, including copyrighted work. This is an important problem to solve, as it may violate existing copyright laws as well as the European AI Act. In this work, we propose a systematic analysis to quantify the extent of potential copyright infringements in LLMs using European law as an example. Unlike previous work, we evaluate instruction-finetuned models in a realistic end-user scenario. Our analysis builds on a proposed threshold of 160 characters, which we borrow from the German Copyright Service Provider Act and a fuzzy text matching algorithm to identify potentially copyright-infringing textual reproductions. The specificity of countermeasures against copyright infringement is analyzed by comparing model behavior on copyrighted and public domain data. We investigate what behaviors models show instead of producing protected text (such as refusal or hallucination) and provide a first legal assessment of these behaviors. We find that there are huge differences in copyright compliance, specificity, and appropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous perform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing a particularly low absolute number of potential copyright violations. Code can be found at github.com/felixbmuller/llms-memorization-copyright.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {984–996},
numpages = {13}
}

@inproceedings{10.1145/3641555.3705266,
author = {Hou, Irene and Nguyen, Hannah Vy and Man, Owen and MacNeil, Stephen},
title = {The Evolving Usage of GenAI by Computing Students},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705266},
doi = {10.1145/3641555.3705266},
abstract = {Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities ( n=95 ). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students ( n=47 ) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% ( n=48 ), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1481–1482},
numpages = {2},
keywords = {chatgpt, computing education, generative ai, help-seeking},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701913,
author = {Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh and Tamilselvam, Srikanth},
title = {Design and Evaluation of an AI-Assisted Grading Tool for Introductory Programming Assignments: An Experience Report},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701913},
doi = {10.1145/3641554.3701913},
abstract = {In a typical introductory programming course, grading student-submitted programs involves an autograder which compiles and runs the programs and tests their functionality with predefined test cases, with no attention to the source code. However, in an educational setting, grading based on inspection of the source code is required for two main reasons (1) awarding partial marks to 'partially correct' code that may be failing the testcase check (2) awarding marks (or penalties) based on source code quality or specific criteria that the instructor may have laid out in the problem statement (e.g. 'implement sorting using bubble-sort'). However, grading based on studying the source code can be highly time consuming when the course has a large enrollment. In this paper we present the design and evaluation of an AI Assistant for source code grading, which we have named TA Buddy. TA Buddy is powered by Code Llama, a large language model especially trained for code related tasks, which we fine-tuned using a graded programs dataset. Given a problem statement, student code submissions and a grading rubric, TA Buddy can be asked to generate suggested grades, i.e. ratings for the various rubric criteria, for each submission. The human teaching assistant (TA) can then accept or overrule these grades. We evaluated the TA Buddy-assisted manual grading against 'pure' manual grading and found that the time taken to grade reduced by 24% while maintaining grade agreement in the two cases at 90%.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {805–811},
numpages = {7},
keywords = {ai-assisted grading, cs education, grading, llms, programming assignments, rubric, source code evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701864,
author = {Zamfirescu-Pereira, J.D. and Qi, Laryn and Hartmann, Bj\"{o}rn and DeNero, John and Norouzi, Narges},
title = {61A Bot Report: AI Assistants in CS1 Save Students Homework Time and Reduce Demands on Staff. (Now What?)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701864},
doi = {10.1145/3641554.3701864},
abstract = {LLM-based chatbots enable students to get immediate, interactive help on homework assignments, but even a thoughtfully-designed bot may not serve all pedagogical goals. We report here on the development and deployment of a GPT-4-based interactive homework assistant ("61A Bot'') for students in a large CS1 course; over 2000 students made over 100,000 requests of our Bot across two semesters. Our assistant offers one-shot, contextual feedback within the command-line "autograder'' students use to test their code. Our Bot wraps student code in a custom prompt that supports our pedagogical goals and avoids providing solutions directly. Analyzing student feedback, questions, and autograder data, we find reductions in homework-related question rates in our course forum, as well as reductions in homework completion time when our Bot is available. For students in the 50th -80th percentile, reductions can exceed 30 minutes per assignment, up to 50% less time than students at the same percentile rank in prior semesters. Finally, we discuss these observations, potential impacts on student learning, and other potential costs and benefits of AI assistance in CS1.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1309–1315},
numpages = {7},
keywords = {ai assistant deployment, ai assistant evaluation, automated tutors, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3672608.3707736,
author = {Speiser, Sebastian},
title = {Assessing the Real-World Impact of Disagreement Between Human Graders and LLMs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707736},
doi = {10.1145/3672608.3707736},
abstract = {Applying artificial intelligence models to grade student answers is a popular application. Lately Large Language Models (LLMs) have shown promising results. However, the disagreement between human graders and LLMs is often considered too large for practical adoption. In this paper, we investigate the real-world impact of this disagreement on final grades. Instead of focusing on individual answers, we simulate the grading process of an entire exam. We use an unmodified LLM (OpenAI GPT-3.5 Turbo) with one-shot prompting for grading individual answers to short answer questions from computer science courses at a German university. Our main contributions are the evaluation of the real-world impact on examination grades in contrast to correctness of individual student answers, the simulation of grading strategies common in human grading practice, and the discussion of the results in the context of observed inter-rater variabilities among human graders. The findings confirm the natural expectation that the impact of the disagreement is lower for final grades than when looking at individual answers. We quantify this effect and compare it to a grading obtained by simulating a second human grader.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {48–53},
numpages = {6},
keywords = {LLMs, programming education, automated short answer grading},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@article{10.5555/3729849.3729853,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui and Dodds, Zachary},
title = {Adaptable Metrics to Inform Introductory CS},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {9},
issn = {1937-4771},
abstract = {Metrics have long been used to assess and guide successful software projects. Traditionally these metrics have measured software's professional rather than its educational suitability. This work proposes six adaptable, reproducible pedagogical metrics. With these metrics, we track an Introductory CS course's capstone projects, 2018--2024. The results suggest both year-over-year evolution and a more sudden, LLM-correlated impact on students' relationship with their early computing work. We have begun adapting our curriculum to these signals, and we foresee future refinements and broader applications to metrics-based reproducible curricular assessment.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {34–42},
numpages = {9}
}

@article{10.1145/3737885,
author = {Brown, Neil C. C. and Weill-Tessier, Pierre and Leinonen, Juho and Denny, Paul and K\"{o}lling, Michael},
title = {Howzat? Appealing to Expert Judgement for Evaluating Human and AI Next-Step Hints for Novice Programmers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737885},
doi = {10.1145/3737885},
abstract = {Motivation: Students learning to program often reach states where they are stuck and can make no forward progress – but this may be outside the classroom where no instructor is available to help. In this situation, an automatically generated next-step hint can help them make forward progress and support their learning. It is important to know what makes a good hint or a bad hint, and how to generate good hints automatically in novice programming tools, for example using Large Language Models (LLMs).Method and participants: We recruited 44 Java educators from around the world to participate in an online study. We used a set of real student code states as hint-generation scenarios. Participants used a technique known as comparative judgement to rank a set of candidate next-step Java hints, which were generated by Large Language Models (LLMs) and by five human experienced educators. Participants ranked the hints without being told how they were generated. The hints were generated with no explicit detail given to the LLMs/humans on what the target task was. Participants then filled in a survey with follow-up questions. The ranks of the hints were analysed against a set of extracted hint characteristics using a random forest approach.Findings: We found that LLMs had considerable variation in generating high quality next-step hints for programming novices, with GPT-4 outperforming other models tested. When used with a well-designed prompt, GPT-4 outperformed human experts in generating pedagogically valuable hints. A multi-stage prompt was the most effective LLM prompt. According to a fitted random forest model, the two most important factors of a good hint were length (80–160 words being best), and reading level (US grade nine or below being best). Offering alternative approaches to solving the problem was considered bad, and we found no effect of sentiment.Conclusions: Automatic generation of these hints is immediately viable, given that LLMs outperformed humans – even when the students’ task is unknown. Hint length and reading level were more important than several pedagogical features of hints. The fact that it took a group of experts several rounds of experimentation and refinement to design a prompt that achieves this outcome suggests that students on their own are unlikely to be able to produce the same benefit. The prompting task, therefore, should be embedded in an expert-designed tool.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = may,
keywords = {LLMs, AI, Java, Next-step hints, comparative judgement}
}

@inproceedings{10.1145/3641554.3701883,
author = {Haji Amin Shirazi, Shirin and Pang, Ashley and Knight, Allan and Salloum, Mariam and Vahid, Frank},
title = {Midterm Exam Outliers Efficiently Highlight Potential Cheaters on Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701883},
doi = {10.1145/3641554.3701883},
abstract = {The ubiquitous use of online tools, contractors and homework sites, has made plagiarism a concerning topic in computer science education. With the introduction of ChatGPT, it poses a threat now more than ever. Many cheating detection tools, such as similarity checkers and style anomaly checkers, help instructors decide whether a student has plagiarized. However, these are not scalable to large classes. Similarity tools can produce high rates of suspected cheating and thus ineffectively use an instructor's time in weeding out the actual cheating cases, especially in the early weeks of CS courses where programs can be small and student solutions can be very similar. We developed a new approach using outlier detection to filter inconsistent performers based on their lab scores throughout the course and their midterm exam scores. Instructors can then manually analyze a manageable amount of students even with large class sizes. We performed our experiment on two large course offerings of CS1 (a total of 177 students) using our algorithm and compared it to a manual analysis performed by an experienced CS1 instructor. The detection approach identified 11 students in the first offering (Winter 2019) and 12 students in the second offering (Spring 2023). With an average precision of 83%, our tool produces a list of concerning students with high precision. This significantly helps teachers efficiently allocate their time and pursue cheating early in the term in order to address and prevent further issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {437–442},
numpages = {6},
keywords = {academic integrity, cs1, plagiarism, programming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705195,
author = {Marwan, Samiha and Ibrahim, Mohamed and Morrison, Briana},
title = {How Good are Large Language Models at Generating Subgoal Labels?},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705195},
doi = {10.1145/3641555.3705195},
abstract = {The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1541–1542},
numpages = {2},
keywords = {large language models, subgoal labels, subgoals},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720291,
author = {Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh},
title = {Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720291},
doi = {10.1145/3706599.3720291},
abstract = {Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {LLMs, ChatGPT, Teaching Assistant, Data Structures and Algorithms Course, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701965,
author = {Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Ranade, Gireeja and Norouzi, Narges},
title = {Analyzing Pedagogical Quality and Efficiency of LLM Responses with TA Feedback to Live Student Questions},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701965},
doi = {10.1145/3641554.3701965},
abstract = {While Large Language Models (LLMs) have emerged as promising methods for automated student question-answering, guaranteeing consistent instructional effectiveness of the response remains a key challenge. Therefore, there is a need for fine-grained analysis of State-Of-The-Art (SOTA) LLM-powered educational assistants.  This work evaluates Edison: a Retrieval Augmented Generation (RAG) pipeline based on GPT-4. We determine the pedagogical effectiveness of Edison's responses through expert Teaching Assistant (TA) evaluation of the answers. After the TA edits and improves the response, we analyze the original LLM response, the TA-assigned ratings, and the TA's edits to ascertain the essential characteristics of a high-quality response. Some key insights of our evaluation are as follows: (1) Edison can give relevant and factual answers in an educational style for conceptual and assignment questions, (2) Most TA edits are deletions made to improve the style of the response, and finally (3) Our analysis indicates that Edison improves TAs' efficiency by reducing the effort required to respond to student questions.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {770–776},
numpages = {7},
keywords = {expert feedback, instructional technologies, language models, question answering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.5555/3716662.3716808,
author = {Xu, Zhihan and Mustafaraj, Eni},
title = {Tracing the Evolution of Information Transparency for OpenAI's GPT Models through a Biographical Approach},
year = {2025},
publisher = {AAAI Press},
abstract = {Information transparency, the open disclosure of information about models, is crucial for proactively evaluating the potential societal harm of large language models (LLMs) and developing effective risk mitigation measures. Adapting the biographies of artifacts and practices (BOAP) method (Hyysalo, Pollock, and Williams 2019) from science and technology studies, this study analyzes the evolution of information transparency within OpenAI's Generative Pre-trained Transformers (GPT) model reports and usage policies from its inception in 2018 to GPT-4, one of today's most capable LLMs. To assess the breadth and depth of transparency practices, we develop a 9-dimensional, 3-level analytical framework to evaluate the comprehensiveness and accessibility of information disclosed to various stakeholders. Findings suggest that while model limitations and downstream usages are increasingly clarified, model development processes have become more opaque. Transparency remains minimal in certain aspects, such as model explainability and real-world evidence of LLM impacts, and the discussions on safety measures such as technical interventions and regulation pipelines lack in-depth details. The findings emphasize the need for enhanced transparency to foster accountability and ensure responsible technological innovations.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1684–1695},
numpages = {12},
location = {San Jose, California, USA},
series = {AIES '24}
}

@article{10.1145/3704739,
author = {Le, Linh and Tran, Dung},
title = {A Metric-Based Detection System for Large Language Model Texts},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3704739},
doi = {10.1145/3704739},
abstract = {More efforts are being put into improving the capabilities of Large Language Models (LLM) than into dealing with their implications. Current LLMs are able to generate high-quality texts seemingly indistinguishable from those written by human experts. While offering great potential, such breakthroughs also pose new challenges for safe and ethical uses of LLMs in education, science, and a multitude of other areas. Thus, majority of current approaches in LLM text detection are either computationally expensive or need access to the LLMs’ internal computations, both of which hinder their public accessibility. With such motivation, this article presents a novel metric learning paradigm for detection of LLM-generated texts that is able to balance computational costs, accessibility, and performances. Specifically, the detection is based on learning a similarity function between a given text and an equivalent example generated by LLMs that outputs high values for LLM-LLM text pairs and low values for LLM-human text pairs. In terms of architecture, the detection framework includes a pre-trained language model for the text embedding task and a newly designed deep metric model. The metric component can be trained on triplets or pairs of same-context instances to signify the distances between human and LLM texts while reducing that among LLM texts. Next, we develop five datasets totaling more than 95,000 contexts and triplets of responses in which one is from humans and two are from GPT-3.5 TURBO or GPT-4 TURBO for benchmarking. Experiment studies show that our best architectures maintain F1 scores between 0.87 and 0.95 across the tested corpora in multiple experiment settings. The metric framework also demands significantly less time in training and inference compared to RoBERTa, LLaMA 3, Mistral v0.3, and Ghostbuster, while keeping 90% to 150% performance of the best benchmark.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {8},
numpages = {19},
keywords = {LLM text detection, contrastive learning, triplet learning, metric learning}
}

@inproceedings{10.1145/3641555.3704769,
author = {Sussman, Alan and Prasad, Sushil and Bunde, David P. and Spacco, Jaime and Gannod, Gerald and Crockett, April Renee and Vaidyanathan, Ramachandran},
title = {Modernizing the CS Introductory Sequence with Parallel and Distributed Computing (and some AI)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704769},
doi = {10.1145/3641555.3704769},
abstract = {Parallel and distributed computing (PDC) has become pervasive in all aspects of computing, so it is essential that students include parallelism and distribution in the computational thinking that they apply to problem solving, from the beginning of their computing education. With all computing devices that students use having multiple cores as well as a GPU in many cases, many students' favorite applications use multiple cores and/or distributed processors. However, we are still teaching them to solve problems using only sequential thinking. Why?This hands-on tutorial will demonstrate how easy it is to open students' eyes to exploiting concurrency in problem solving. You will participate in plugged and unplugged activities that will help students to recognize examples of PDC concepts and concurrency in the world around them. We introduce plugged and unplugged curriculum modules that have been successfully integrated in existing computing classes at multiple institutions. We will also discuss recent efforts at integrating AI methods, including LLMs, into introductory classes.A laptop capable of running a C/C++ compiler, a Java virtual environment, and a Python interpreter is needed to fully participate in activities. However, attendees may learn the core concepts without a laptop. The activities and curriculum modules have been used successfully to teach PDC concepts in early computing courses and will be available after the workshop. Participants will receive a stipend of 400 to defray their cost of registration and one-night hotel stay. The CDER center will also have a booth in the exhibition hall for additional support.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1775},
numpages = {1},
keywords = {acm/ieee-cs/aaai computer science curricula, ai, computing education, cs1/ cs2, early computing class, hpc education, undergraduate instruction, pdc education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705061,
author = {Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.},
title = {Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705061},
doi = {10.1145/3641555.3705061},
abstract = {The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1735},
numpages = {1},
keywords = {AI, LLMs, artificial intelligence, generative AI, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705189,
author = {Wang, Jiayi and Xiao, Ruiwei and Tseng, Ying-Jui},
title = {Generating AI Literacy MCQs: A Multi-Agent LLM Approach},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705189},
doi = {10.1145/3641555.3705189},
abstract = {Artificial intelligence (AI) is transforming society, making it crucial to prepare the next generation through AI literacy in K-12 education. However, scalable and reliable AI literacy materials and assessment resources are lacking. To address this gap, our study presents a novel approach to generating multiple-choice questions (MCQs) for AI literacy assessments. Our method utilizes large language models (LLMs) to automatically generate scalable, high-quality assessment questions. These questions align with user-provided learning objectives, grade levels, and Bloom's Taxonomy levels. We introduce an iterative workflow incorporating LLM-powered critique agents to ensure the generated questions meet pedagogical standards. In the preliminary evaluation, experts expressed strong interest in using the LLM-generated MCQs, indicating that this system could enrich existing AI literacy materials and provide a valuable addition to the toolkit of K-12 educators.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1651–1652},
numpages = {2},
keywords = {AI literacy, LLM-based agent, assessment, large language model, multi-agent workflow, question generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705252,
author = {Tadimalla, Sri Yash and Maher, Mary Lou},
title = {Sociotechnical AI Education Course Design for CS Majors and Non-Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705252},
doi = {10.1145/3641555.3705252},
abstract = {As generative AI increasingly integrates into society and education, the number of institutions implementing AI usage policies and offering introductory AI courses is rising. These introductory AI courses mustn't replicate the "gateway/weed-out" phenomenon observed in introductory computer science courses like CS1 and CS2. Literature in computer science education suggests that interventions such as summer camps, bridge courses, and socio-technical courses have improved the sense of belonging and retention among students from underrepresented groups, thereby broadening participation in computer science. Building on previous work to create a socio-technical curriculum for all ages and education levels, this paper presents a course for teaching introductory AI concepts that adopts a socio-technical approach, complete with weekly activities and content designed for broad access. The course has been taught as a 1-credit general education course, primarily for freshmen and first-year students from various majors, and a 3-credit course for CS majors at all levels.This paper provides a curriculum and resources to teach a socio-technical introductory AI course. This approach is important because it not only democratizes AI education across diverse student backgrounds but also equips all students with the critical socio-technical multidisciplinary perspective necessary to navigate and shape the future ethical landscape of AI technology.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1631–1632},
numpages = {2},
keywords = {AI curriculum, AI education, intro to AI, socio-technical AI literacy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701791,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul},
title = {Evaluating Language Models for Generating and Judging Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701791},
doi = {10.1145/3641554.3701791},
abstract = {The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {624–630},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, generative ai, large language models, llm-as-a-judge, open source, programming feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701853,
author = {Filcik, Daniel and Sobiesk, Edward and Matthews, Suzanne J.},
title = {Fostering Creativity: Student-Generative AI Teaming in an Open-Ended CS0 Assignment},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701853},
doi = {10.1145/3641554.3701853},
abstract = {The increasing ubiquity of web-based generative artificial intelligence technologies necessitates that all students experience teaming with such technologies -- exploring their strengths and limitations and learning how to create synergy with them. To aid in this effort, we designed an open-ended generative AI project for the freshmen taking our general-education introduction to computing course. Students were required to team with generative AI to create something beyond what they alone (or the AI alone) could accomplish. Upon completion, students submitted a short written critical analysis documenting their experiences and presented a three-minute demonstration of their project in class. Despite limited course coverage of AI and generative AI prior to this project, we were impressed by the creativity and sophistication of the submitted final products as well as the breadth of generative AI tools explored. Student reflections on the experience illustrated numerous insights into the strengths and limitations of the tools they employed. Our results underscore that students can learn about the benefits and limitations of generative AI in as little as a single assignment and that covering such topics need not require extensive amounts of course time and resources.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {339–345},
numpages = {7},
keywords = {computing education, cs0, final project, freshmen, generative artificial intelligence, human-ai teaming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3705734,
author = {George, Amrita and Storey, Veda Catherine and Hong, Shuguang},
title = {Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3705734},
doi = {10.1145/3705734},
abstract = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {4},
numpages = {30},
keywords = {ChatGPT, Large language model (LLM), technology self-efficacy, computer anxiety, goal orientation, computer playfulness, social support, technology anchors, generative AI, knowledge anchor, OpenAI, technology anchors, artificial intelligence (AI), achievement theory}
}

@inproceedings{10.5555/3712729.3712990,
author = {Leathrum, James F. and Shen, Yuzhong and Sosonkina, Masha},
title = {Investigating the Use of Generative AI in M&amp;S Education},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {Large Language Models (LLMs) are rapidly creating a place for themselves in society. There are numerous reports, both good and bad, of their use in business, academia, government and society. While some organizations are trying to limit, or eliminate, their use, it appears that it is inevitable they will become a common "tool". In education, there is a fear that students will not acquire critical thinking in the future, but we argue that LLMs will become a tool to assist students with critical thinking, giving guidance, feedback, and assessment. This paper investigates how the current state of LLMs can be integrated into modeling and simulation (M&amp;S) education. Example cases for modeling and simulation development are presented showing how an LLM can assist M&amp;S design and education in anticipation of LLMs becoming a common tool for M&amp;S practitioners. Current limitations are also highlighted, and where possible, short-term solutions are proposed.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3142–3153},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@article{10.5555/3737313.3737340,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {163–177},
numpages = {15}
}

@inproceedings{10.1145/3641555.3705076,
author = {Chen, Matt},
title = {Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705076},
doi = {10.1145/3641555.3705076},
abstract = {This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1739},
numpages = {1},
keywords = {custom AI integration, generative AI bots},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3709025.3712220,
author = {Doyle, Colin and Tucker, Aaron D.},
title = {If You Give an LLM a Legal Practice Guide},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709025.3712220},
doi = {10.1145/3709025.3712220},
abstract = {Large language models struggle to answer legal questions that require applying detailed, jurisdiction-specific legal rules. Lawyers also find these types of question difficult to answer. For help, lawyers turn to legal practice guides: expert-written how-to manuals for practicing a type of law in a particular jurisdiction. Might large language models also benefit from consulting these practice guides? This article investigates whether providing LLMs with excerpts from these guides can improve their ability to answer legal questions. Our findings show that adding practice guide excerpts to LLMs' prompts tends to help LLMs answer legal questions. But even when a practice guide provides clear instructions on how to apply the law, LLMs often fail to correctly answer straightforward legal questions - questions that any lawyer would be expected to answer correctly if given the same information. Performance varies considerably and unpredictably across different language models and legal subject areas. Across our experiments' different legal domains, no single model consistently outperformed others. LLMs sometimes performed better when a legal question was broken down into separate subquestions for the model to answer over multiple prompts and responses. But sometimes breaking legal questions down resulted in much worse performance. These results suggest that retrieval augmented generation (RAG) will not be enough to overcome LLMs' shortcomings with applying detailed, jurisdiction-specific legal rules. Replicating our experiments on the recently released OpenAI o1 and o3-mini advanced reasoning models did not result in consistent performance improvements. These findings cast doubt on claims that LLMs will develop competency at legal reasoning tasks without dedicated effort directed toward this specific goal.},
booktitle = {Proceedings of the 2025 Symposium on Computer Science and Law},
pages = {194–205},
numpages = {12},
keywords = {Large Language Models, Law, Propositional Logic, Reasoning Models, Retrieval Augmented Generation},
location = {Munich, Germany},
series = {CSLAW '25}
}

@inproceedings{10.1145/3677389.3702596,
author = {Chen, Yinlin and Xie, Zhiwu and Yang, Le},
title = {JCDL 2024 Workshop: Generative AI for Resource Discovery in Libraries},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702596},
doi = {10.1145/3677389.3702596},
abstract = {This workshop delves into the transformative role of Generative AI technologies in digital libraries, emphasizing advancements in resource discovery and user engagement. Participants will explore how cutting-edge large language models such as GPT-4 and Llama are leveraged to deliver highly personalized resource recommendations and improve the efficiency and precision of information retrieval processes. Through showcases of capstone projects developed as part of the AI Incubator Program, hands-on sessions, and collaborative discussions, attendees will gain practical insights into deploying AI-driven solutions that streamline library operations and elevate user experience.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {125},
numpages = {2},
keywords = {generative AI, large language model, retrieval-augmented generation},
location = {Hong Kong, China},
series = {JCDL '24}
}

@inproceedings{10.1145/3702386.3702388,
author = {Xu, Xiao},
title = {Comparative Analysis of GPT-4o and GPT-4.0 in Business Ethics Role-Play Simulations},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702388},
doi = {10.1145/3702386.3702388},
abstract = {The rapid advancement of artificial intelligence (AI) technologies has opened new frontiers in educational methodologies, particularly in enhancing interactive learning environments. This paper examines the integration of two AI-driven models, ChatGPT-4.0 and its advanced iteration, GPT-4o, into the teaching of complex subjects such as climate risk management within higher education. Utilizing role-play simulations, a method proven to effectively deepen understanding and engagement, we explore how these models enhance traditional educational approaches by providing dynamic, real-time interactions that mimic real-world decision-making processes. Our comparative analysis focuses on the performance of these models in terms of response time, emotional intelligence, and quality of engagement. The findings indicate that GPT-4o, with its quicker response times and enhanced emotional recognition capabilities, significantly improves learner engagement and the effectiveness of role-play simulations. This study highlights the potential of AI to not only complement but substantially enrich pedagogical practices, offering educators valuable insights into selecting appropriate AI tools for their instructional needs. Through this exploration, we advocate for a hybrid educational model that synergistically combines the strengths of both traditional and AI-enhanced learning, proposing a future where education is more adaptive, personalized, and aligned with the evolving demands of the digital age.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {57–63},
numpages = {7},
keywords = {ChatGPT, Large Language Model, Role-play, generative AI},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3641555.3705051,
author = {Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh},
title = {TA Buddy: AI-Assisted Grading Tool for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705051},
doi = {10.1145/3641555.3705051},
abstract = {In introductory programming courses, autograders typically evaluate student programs by running testcases without inspecting the source code. However, educational grading often requires manual code inspection for two key reasons: (1) to award partial marks for code that may fail test cases but is partially correct, and (2) to assign marks based on code quality or specific criteria set by the instructor, such as requiring a particular algorithm, e.g., bubble sort. Rubric-based subjective grading is beneficial for these reasons, but manual grading for large course enrollments is time consuming. This demo introduces TA Buddy, an AI assistant integrated with IIT Bombay's BodhiTree Evalpro platform, which is designed to streamline grading in introductory programming courses. It is powered by a pre-trained code LLM, which was fine-tuned with a dataset created here at IITB Bombay. Its key benefits include speeding up the grading process with AI-generated suggestions for ratings of the criteria of a grading rubric. Furthermore, it provides feedback with justifications for assigned grades, making it useful for large courses where manual grading is time-consuming. Note that TA-Buddy only suggests grades to TAs, TAs are still required to review the grades and accept or reject them. In that sense, TA-Buddy offers an AI-Assisted grading option to TAs. This hybrid approach reduces grading time by up to 45% while maintaining an average match of 90% (on a sample of six problems) with un-assisted manual grades.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1736},
numpages = {1},
keywords = {ai-assisted grading, cs education, llms, programming assignments, rubric, source code evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713728,
author = {Jones, Mirabelle and Griffioen, Nastasia and Neumayer, Christina and Shklovski, Irina},
title = {Artificial Intimacy: Exploring Normativity and Personalization Through Fine-tuning LLM Chatbots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713728},
doi = {10.1145/3706598.3713728},
abstract = {Fine-tuning Large Language Models (LLMs) is one response to the critique of LLMs being biased, erasing diversity, and raising ethical concerns. The Artificial Intimacy project employs artistic methods, taking personalization of chatbots to an extreme by fine-tuning LLMs on individual social media data. We find that regular GPT-3 chatbots attempt to circumvent value-laden content through flagging prompts and producing generic non-answers with variable success. While the transactional nature of such output allowed participants to make sense of responses with less personification, fine-tuned models presented value-laden, normative, and familiar personalities, resulting in strong personification as a way of making sense of the interactions. This mimicry of emotional connection resulted in a sense of artificial intimacy creating expectations for reciprocity and consideration that the models cannot express by design. As the commercialization of interactions with chatbots continues, we discuss the ethics of such emotional manipulation and its implications for personalization of LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {793},
numpages = {16},
keywords = {GPT-3, chatbots, normativity, value alignment, participatory artistic research},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641554.3701906,
author = {Hassan, Mohammed and Chen, Yuxuan and Denny, Paul and Zilles, Craig},
title = {On Teaching Novices Computational Thinking by Utilizing Large Language Models Within Assessments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701906},
doi = {10.1145/3641554.3701906},
abstract = {Novice programmers often struggle to develop computational thinking (CT) skills in introductory programming courses. This study investigates the use of Large Language Models (LLMs) to provide scalable, strategy-driven feedback to teach CT. Through think-aloud interviews with 17 students solving code comprehension and writing tasks, we found that LLMs effectively guided decomposition and program development tool usage. Challenges included students seeking direct answers or pasting feedback without considering suggested strategies. We discuss how instructors should integrate LLMs into assessments to support students' learning of CT.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {471–477},
numpages = {7},
keywords = {code comprehension, debuggers, execution, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706468.3706481,
author = {Ferreira Mello, Rafael and Pereira Junior, Cleon and Rodrigues, Luiz and Pereira, Filipe Dwan and Cabral, Luciano and Costa, Newarney and Ramalho, Geber and Gasevic, Dragan},
title = {Automatic Short Answer Grading in the LLM Era: Does GPT-4 with Prompt Engineering beat Traditional Models?},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706481},
doi = {10.1145/3706468.3706481},
abstract = {Assessing short answers in educational settings is challenging due to the need for scalability and accuracy, which led to the field of Automatic Short Answer Grading (ASAG). Traditional machine learning models, such as ensemble and embeddings, have been widely researched in ASAG, but they often suffer from generalizability issues. Recently, Large Language Models (LLMs) emerged as an alternative to optimize ASAG systems. However, previous research has failed to present a comprehensive analysis of LLMs’ performance powered by prompt engineering strategies and compare its capabilities to traditional models. This study presents a comparative analysis between traditional machine learning models and GPT-4 in the context of ASAG. We investigated the effectiveness of different models and text representation techniques and explored prompt engineering strategies for LLMs. The results indicate that traditional machine learning models outperform LLMs. However, GPT-4 showed promising capabilities, especially when configured with optimized prompt components, such as few-shot examples and clear instructions. This study contributes to the literature by providing a detailed evaluation of LLM performance compared to traditional machine learning models in a multilingual ASAG context, offering insights for developing more efficient automatic grading systems.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {93–103},
numpages = {11},
keywords = {Automatic short answer grading, Natural Language Processing, Assessment, LLM, GPT},
location = {
},
series = {LAK '25}
}

@article{10.1145/3722229,
author = {AlOmar, Eman Abdullah},
title = {Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722229},
doi = {10.1145/3722229},
abstract = {Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This article explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This article discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analyses reveal that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like “certainly” regarding bug fixing decisions, and apology phrases such as “apologize” when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {16},
numpages = {36},
keywords = {large language models, education, bugfix, static analysis, code quality}
}

@article{10.5555/3729857.3729874,
author = {Bandi, Ajay and Blackford, Benjamin and Fellah, Aziz and Linville, Diana and Meyer, Trevor C. and Voss, Robert J.},
title = {Prompting Collaboration: Development of an Multidisciplinary Applied AI Minor Program},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has rapidly transformed industries and research, becoming a driving force for technological innovation and development [1]. As AI continues to grow and change, it is reshaping the way we approach problem-solving, decision-making, and creative processes across various sectors. Northwest Missouri State University is developing a new multidisciplinary AI minor open to all undergraduate students on campus. The program is tailored for students from any discipline who want to explore how AI can be utilized and integrated into their fields such as computer science, humanities, business, sciences, healthcare, agriculture, and education, among others. The curriculum integrates topics such as foundational AI concepts, prompt engineering and writing processes, ethical considerations in AI, AI in the workplace, and a capstone project. This program also promotes interdisciplinary collaboration and emphasizes the ethical use of AI.By the end of the program, students will be able to use AI to enhance efficiency and accuracy in tasks, develop and evaluate effective prompts, apply generative AI tools across various input formats, and assess the ethical considerations of AI in real-world applications. The panel members are experts from diverse fields, including management, humanities, technical writing, and computer science. The panel discusses the development of the AI minor curriculum and explores opportunities to extend the AI curriculum by offering AI certificates for undergraduate and graduate online professional students. By attending this panel, the audience will gain valuable insights into developing comprehensive AI programs, fostering cross-disciplinary innovation, and preparing students to use AI ethically and effectively across diverse fields.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {129–132},
numpages = {4}
}

@inproceedings{10.1145/3641555.3705066,
author = {Rahman, Farzana},
title = {Leveraging or Limiting: Strategies and Implications of ChatGPT Use by Undergraduate TAs in Large CS2 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705066},
doi = {10.1145/3641555.3705066},
abstract = {As AI tools like ChatGPT become more prevalent in educational settings, their potential to assist undergraduate teaching assistants (uTAs) in large Computer Science 2 (CS2) courses presents both opportunities and challenges. This work focuses on how ChatGPT can be strategically utilized by uTAs during office hours to enhance student support, particularly in complex topics such as data structures, algorithm development, and object-oriented programming. We explored effective strategies for uTAs to use ChatGPT in ways that promote deeper student understanding without compromising the development of independent problem-solving skills. Key strategies include leveraging ChatGPT for real-time code debugging assistance, offering alternative approaches to solving coding problems, comparing and critiquing self and AI generated documentation, and code reviewing. This work also identifies potential challenges, such as the risk of students or uTAs becoming overly dependent on AI-generated solutions and the possibility of inaccurate or incomplete responses from the AI. Hence, our findings highlight the dual role of ChatGPT as both an asset and a potential hindrance, depending on how it is utilized. To mitigate these risks, we propose a set of best practices that ensure ChatGPT enhances, rather than replaces, the uTA's role as a facilitator of learning. The findings from this research provide valuable insights into how uTAs can integrate AI tools thoughtfully into office hours to offer more effective support, ultimately improving student engagement and learning outcomes in large-scale CS2 courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1745},
numpages = {1},
keywords = {ai tools, cs2, student engagement, ta training, undergraduate teaching assistants},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3715112,
author = {Betz, Stefanie and Penzenstadler, Birgit},
title = {With Great Power Comes Great Responsibility: The Role of Software Engineers},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3715112},
doi = {10.1145/3715112},
abstract = {The landscape of Software Engineering evolves rapidly amidst digital transformation and the ascendancy of AI, leading to profound shifts in the role and responsibilities of Software Engineers. This evolution encompasses both immediate changes, such as the adoption of Large Language Model-based approaches to coding, and deeper shifts driven by the profound societal and environmental impacts of technology. Despite the urgency, there persists a lag in adapting to these evolving roles. This roadmap article proposes 10 research challenges to develop a new generation of Software Engineers equipped to navigate the technical and social complexities as well as ethical considerations inherent in their evolving profession. Furthermore, the challenges target role definition, integration of AI, education transformation, standards evolution, and impact assessment to equip future Software Engineers to skillfully and responsibly handle the obstacles within their transforming discipline.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {136},
numpages = {21},
keywords = {Sustainability, Responsibility, Roles, Ethics}
}

@inproceedings{10.1145/3641555.3705208,
author = {Weber, Jason Lee and Park, Hyunjun and Song, Daniel J. and Apillanes, Jared and Martinez Neda, Barbara and Wong-Ma, Jennifer and Gago-Masague, Sergio},
title = {Investigating Autograder Usage in the Post- Pandemic and LLM Era},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705208},
doi = {10.1145/3641555.3705208},
abstract = {This work investigates the impact of Large Language Models (LLMs) and the COVID-19 pandemic on student behavior with autograder systems in three programming-heavy courses. We examine whether the release of LLMs like ChatGPT and GitHub Copilot, along with post-pandemic effects, has modified student interactions with autograders. Using data from student submissions over five years, totalling over 4,500 students across over 420,000 submissions, we analyze trends in submission behaviors before and after these events. Our methodology involves tracking submission patterns, focusing on timing, frequency, and score.Contrary to expectations, our findings reveal that metrics remain relatively consistent in the post-ChatGPT and post-pandemic era. Despite yearly fluctuations, no significant shift in student behaviors is attributable to these changes. Students continue to rely on a combination of manual debugging and autograder feedback without noticeable changes in their problem-solving approach.These findings highlight the resilience of the educational practices in these courses and suggest that integrating LLMs into mid-level CS curriculum may not necessitate the significant paradigm shift previously envisioned. Future work should extend these analyses to courses with different structures to determine if these results are generalizable. If not, the specific course aspects contributing to our observed ChatGPT and pandemic resilience should be identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1653–1654},
numpages = {2},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3737313.3737332,
author = {Chamberlain, Devin and Levine, David B. and Pitcairn, Abigail and Snow, Nicholas and Sweeney, Benjamin},
title = {Large Language Models and Introductory Lab Exercises: Susceptibility, Resistance, and Potential},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Three student personas were created, each representing a way in which current students interact with AI tools such as ChatGPT when completing introductory computer science assignments. Four undergraduate students assumed the role of each of the personas in turn and two semesters worth of current assignments were completed in each persona. The results and experiences were then analyzed to determine aspects of the assignments that made it more (or less) difficult to complete them using the AI tools, with an eye towards whether small changes in phrasing or requirements might result in significant changes in this metric.Three of the main takeaways were that LLMs are more difficult for students to use when assignments 1) consist of many small steps, 2) make use of external code libraries, or 3) involve spatial reasoning.Finally, the student/persona experiences helped to generate a list of opportunities for instructors to proactively include the use of AI tools in current assignments without sacrificing any of the current learning objectives.The initial phase involved labs from one institution and used only one AI tool, but follow-up work involving the use of other tools and labs from other institutions validated those core conclusions. A student survey (as well as other published literature) also validated the choice of personas.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {49–63},
numpages = {15}
}

@inproceedings{10.1145/3680256.3721324,
author = {Shawon, Ashadullah and Liscano, Ramiro and Azim, Akramul and Sundaresan, Vijay and Chang, Yee-Kang},
title = {Retrieval Augmented Generation Fine-Tuned LLM Model for Code Recommendations to Mitigate Lock Contention},
year = {2025},
isbn = {9798400711305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680256.3721324},
doi = {10.1145/3680256.3721324},
abstract = {Lock contention performance faults can lead to degradation in the performance of software applications. Unlike software bugs, per- formance faults do not lead to failures and application crashes but surface as a degradation in the response and execution of an ap- plication and can surface fairly late in the deployment life of an application. Tools exist for the identification and detection of lock performance faults but there is a lack of effective code refactor- ing recommendations for a developer to mitigate the performance degradation caused by lock-contention. Recent advances in Large Language Models (LLMs) have demonstrated positive results in code refactoring for fixing software bugs and mitigating run time faults. However, traditional LLM-based approaches often suffer from hal- lucination errors, where the generated code may not accurately reflect the context of the project or existing codebase. This thesis presents a novel approach that combines Retrieval Augmented Gen- eration (RAG) with a fine-tuned LLM model for refactored code recommendation aimed at reducing lock-contention performance faults in Java applications. The RAG fine-tuned model combines the strengths of contextual understanding from LLMs with the preci- sion of retrieval-based systems, thereby ensuring that the generated recommendations are relevant, accurate, and hallucination-free. Se- mantic and syntactic metrics of the recommendations generated by the combined RAG and LLM model show an accuracy of approxi- mately 90% compared to an accuracy of approximately 25% when a baseline LLM model is used.},
booktitle = {Companion of the 16th ACM/SPEC International Conference on Performance Engineering},
pages = {95–102},
numpages = {8},
keywords = {code smell, fine-tuning, large language model, lock contention, rag, refactored code recommendation},
location = {Toronto ON, Canada},
series = {ICPE '25}
}

@inproceedings{10.1145/3641554.3701972,
author = {Ahmed, Umair Z. and Sahai, Shubham and Leong, Ben and Karkare, Amey},
title = {Feasibility Study of Augmenting Teaching Assistants with AI for CS1 Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701972},
doi = {10.1145/3641554.3701972},
abstract = {With the increasing adoption of Large Language Models (LLMs), there are proposals to replace human Teaching Assistants (TAs) with LLM-based AI agents for providing feedback to students. In this paper, we explore a new hybrid model where human TAs receive AI-generated feedback for CS1 programming exercises, which they can then review and modify as needed. We conducted a large-scale randomized intervention with 185 CS1 undergraduate students, comparing the efficacy of this hybrid approach against manual feedback and direct AI-generated feedback.Our initial hypothesis predicted that AI-augmented feedback would improve TA efficiency and increase the accuracy of guidance to students. However, our findings revealed mixed results. Although students perceived improvements in feedback quality, the hybrid model did not consistently translate to better student performance. We also observed complacency among some TAs who over-relied on LLM generated feedback and failed to identify and correct inaccuracies. These results suggest that augmenting human tutors with AI may not always result in improved teaching outcomes, and further research is needed to ensure it is truly effective.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {11–17},
numpages = {7},
keywords = {cs1, gpt, hint, llm, programming, randomized trial, ta},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701945,
author = {Liu, Rongxin and Zhao, Julianna and Xu, Benjamin and Perez, Christopher and Zhukovets, Yuliia and Malan, David J.},
title = {Improving AI in CS50: Leveraging Human Feedback for Better Learning},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701945},
doi = {10.1145/3641554.3701945},
abstract = {In 2023, we developed and deployed AI-based tools in CS50 at Harvard University to provide students with 24/7 interactive assistance, approximating a 1:1 teacher-to-student ratio. These tools offer code explanations, style suggestions, and responses to course-related inquiries, emulating human educators to foster critical thinking. However, maintaining alignment with instructional goals is challenging, especially with frequent updates to the underlying large language models (LLMs). We thus propose a continuous improvement process for LLM-based systems using a collaborative human-in-the-loop approach. We introduce a systematic evaluation framework for assessing and refining the performance of AI-based tutors, combining human-graded and model-graded evaluations. Using few-shot prompting and fine-tuning, we aim to ensure our AI tools adopt pedagogically sound teaching styles. Fine-tuning with a small, high-quality dataset has shown significant improvements in aligning with teaching goals, as confirmed through multi-turn conversation evaluations. Additionally, our framework includes a model-evaluation backend that teaching assistants periodically review, ensuring the AI system remains effective and aligned with instructional objectives. This paper offers insights into our methods and the impact of these AI tools on CS50 and contributes to the discourse on AI in education, showcasing scalable, personalized learning enhancements.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {715–721},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705237,
author = {Mittal, Meenakshi and Bailey, Azalea and Phelps, Victoria and Miroyan, Mihran and Mitra, Chancharik and Jain, Rishi and Niousha, Rose and Ranade, Gireeja and Norouzi, Narges},
title = {Raising the Bar: Automating Consistent and Equitable Student Support with LLMs},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705237},
doi = {10.1145/3641555.3705237},
abstract = {Large Language Models (LLMs) can be used to automate many aspects of the educational field. In this paper, we look into the benefits of automating responses to student questions in course discussion forums using our Retrieval-Augmented Generation (RAG)-based LLM pipeline (Edison). Our research questions are:RQ1 How do the responses generated by Edison compare to those of TAs in terms of level of detail and use of examples?RQ2 How does the tone of responses generated by Edison compare to that of TA responses?RQ3 Are responses generated by Edison more self-consistent than TA responses?Our results suggest that Edison generates responses with more detail, examples, positive tone, and self-consistency than TAs. We envision Edison being used as a baseline for TAs to build responses on, reduce response times, and promote equitable feedback.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1549–1550},
numpages = {2},
keywords = {cs1, discussion forum, large language models, student feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3719287,
author = {Oh, Sunggyeol and Zhao, Jiacheng and Russo, Carson and Bolmer, Michael},
title = {Boosting Diary Study Outcomes with a Fine-Tuned Large Language Model},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719287},
doi = {10.1145/3706599.3719287},
abstract = {This study explores fine-tuned Large Language Models (LLMs) integration into diary studies within the Human-Computer Interaction (HCI) field to enhance data collection and analysis. Leveraging a Mistral 7B model fine-tuned with a curated dataset of over 1,000 diary entries, this research addresses challenges such as participant engagement and data richness. The fine-tuned model offers personalized feedback, facilitating deeper reflection and structured recording while reducing the cognitive load on participants. The DiaryQuest educational platform, enhanced with advanced visualization tools and semantic search capabilities, enables educators to efficiently analyze diary data, extract thematic insights, and provide targeted guidance. Results from user evaluations reveal that the optimized platform improves learning outcomes, teaching efficiency, and overall user experience. By bridging traditional diary methodologies with state-of-the-art LLMs, this study advances HCI education and establishes a scalable framework for applying AI in broader educational and research contexts.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {7},
keywords = {Diary Study, Large Language Model},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705171,
author = {Gonzaga, Justin T. and Jiang, Yuchao and Vassar, Alexandra},
title = {Empowering CS1 Educators: Enhancing Automated Feedback Instruction with Cognitive Load Theory},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705171},
doi = {10.1145/3641555.3705171},
abstract = {Delivering personalised and timely feedback is crucial for helping students address gaps in their understanding. However, the increasing demands of large class sizes make this task particularly challenging for CS1 educators, especially for casual teaching assistants who lack formal training and experience. Existing feedback training methods are often inconsistent and ineffective, leaving educators unprepared to handle diverse student needs.To address this, we designed an adaptive fading procedure based on Cognitive Load Theory (CLT) to support educators in delivering high-quality, personalised feedback. This pedagogical technique is integrated into FeedbackPulse-CLT, an automated tool that evaluates feedback in real-time and provides guidance for improvement. This paper outlines our approach to designing scalable, evidence-based feedback instruction using Generative AI and large language models (LLMs) to overcome feedback quality concerns in CS1 education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1461–1462},
numpages = {2},
keywords = {cognitive load theory, cs1, feedback, generative ai, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706599.3720203,
author = {Tang, Xiaohang and Wong, Sam and Huynh, Marcus and He, Zicheng and Yang, Yalong and Chen, Yan},
title = {SPHERE: Supporting Personalized Feedback at Scale in Programming Classrooms with Structured Review of Generative AI Outputs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720203},
doi = {10.1145/3706599.3720203},
abstract = {This paper introduces SPHERE, a system that enables instructors to effectively create and review personalized feedback for in-class coding activities. Comprehensive personalized feedback is crucial for programming learning. However, providing such feedback in large programming classrooms poses significant challenges for instructors. While Large Language Models (LLMs) offer potential assistance, how to efficiently ensure the quality of LLM-generated feedback remains an open question. SPHERE guides instructors’ attention to critical students’ issues, empowers them with guided control over LLM-generated feedback, and provides visual scaffolding to facilitate verification of feedback quality. Our between-subject study with 20 participants demonstrates SPHERE’s effectiveness in creating more high-quality feedback while not increasing the time spent on the overall review process compared to a baseline system. This work contributes a synergistic approach to scaling personalized feedback in programming education, addressing the challenges of real-time response, issue prioritization, and large-scale personalization.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {17},
keywords = {Generative AI, Large Language Model, Programming Education at Scale, Feedback, Computing Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3704765,
author = {Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug},
title = {Teaching with AI (GPT)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704765},
doi = {10.1145/3641555.3704765},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. In this tutorial, we share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's latest APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, collaboratively building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1773},
numpages = {1},
keywords = {AI, AI ethics, ChatGPT, GPT, generative AI, programming, prompt, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706468.3706500,
author = {Duan, Zhangqi and Fernandez, Nigel and Hicks, Alexander and Lan, Andrew},
title = {Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706500},
doi = {10.1145/3706468.3706500},
abstract = {Open-ended coding tasks, which ask students to construct programs according to certain specifications, are common in computer science education. Student modeling can be challenging since their open-ended nature means that student code can be diverse. Traditional knowledge tracing (KT) models that only analyze response correctness may not fully capture nuances in student knowledge from student code. In this paper, we introduce Test case-Informed Knowledge Tracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze and predict both open-ended student code and whether the code passes each test case. We augment the existing CodeWorkout dataset with the test cases used for a subset of the open-ended coding questions, and propose a multi-task learning KT method to simultaneously analyze and predict 1) whether a student’s code submission passes each test case and 2) the student’s open-ended code, using a large language model as the backbone. We quantitatively show that these methods outperform existing KT methods for coding that only use the overall score a code submission receives. We also qualitatively demonstrate how test case information, combined with open-ended code, helps us gain fine-grained insights into student knowledge.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {238–248},
numpages = {11},
keywords = {Computer Science Education, Large Language Models, Open-ended Coding Questions, Test Cases},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641554.3701810,
author = {Borela, Rodrigo and Liding, Zhixian and McDaniel, Melinda},
title = {Enhancing CS1 Education through Experiential Learning with Robotics Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701810},
doi = {10.1145/3641554.3701810},
abstract = {To address the challenges of generative AI in CS1 education, especially its misuse by students to bypass coding exercises, which undermines their engagement with foundational learning, CS1 curricula are evolving to emphasize higher-level problem-solving and systems thinking. In response, a novel experiential learning initiative grounded in High-Impact Practices was introduced to a CS1 course over the course of 2 semesters, involving 132 students. This initiative utilized robotics lab assignments to enhance computational thinking across various levels of granularity, from individual functional components to overall system behaviors, bridging conceptual understanding with real-world applications. The approach emphasized project-based learning, extended engagement time, and reflective practices to deepen students' understanding of core computing concepts and scaffold knowledge integration. The curriculum featured both individual and team-based lab assignments to build foundational skills followed by collaborative problem-solving. The initiative's impact was assessed against a control group of 427 students who completed traditional web development lab assignments. Evaluation methods included thematic analyses of student reflections, instructor opinion surveys, and statistical analysis of exam performances across the semester. Results revealed a substantial positive effect on self-efficacy and learning outcomes. Students in the experiential learning group reported increased confidence in applying their computing skills to real-world scenarios, heightened engagement, and greater improvements in technical proficiency. Notably, their exam scores demonstrated a statistically significant improvement compared to the control group. These findings highlight the effectiveness of integrating practical, interactive elements into computer science education to meet the demands of a rapidly evolving technological landscape.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {144–150},
numpages = {7},
keywords = {artificial intelligence, collaborative learning, cs1, experiential learning, robotics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705212,
author = {Baek, Jeonghun and Yamazaki, Tetsuro and Morihata, Akimasa and Mori, Junichiro and Yamakata, Yoko and Taura, Kenjiro and Chiba, Shigeru},
title = {Leveraging LLM for Detecting and Explaining LLM-generated Code in Python Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705212},
doi = {10.1145/3641555.3705212},
abstract = {As large language models (LLMs) have become more advanced, generating code to solve exercises in programming courses has become significantly easier. However, this convenience raises the concern of over-reliance on these tools, potentially hindering students from developing independent coding skills. To address this concern, we introduce an LLM-based detector that not only detects LLM-generated code but also explains the reasons for its judgments. These reasons provide insight into the characteristics of LLM-generated code, enhancing transparency in the detection process. We evaluate the detector in an introductory Python programming course, achieving over 99% accuracy. Additionally, instructors manually reviewed the reasons provided by the detector and verified that 64.7% of reasons for classifying code as LLM-generated were appropriate. These reasons can also serve as feedback, helping students improve their coding skills by understanding the characteristics of expert-level LLM-generated code.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1369–1370},
numpages = {2},
keywords = {detecting and explaining llm-generated code, large language model, llm-based detector, llm-generated code, python programming courses, reasons for judgment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3729857.3729868,
author = {Bandi, Ajay},
title = {Pedagogical Evaluation of Generative AI Course for Technologists},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Generative AI is a transformative technology that impacts various fields, including software development, data analytics, and cybersecurity. To address this, we have designed and developed a Generative AI course for technologists, integrating foundational knowledge of various Gen AI architecture models with hands-on practical experience using Python libraries, including HuggingFace. This paper discusses the detailed course structure and assessments. A pedagogical evaluation approach is followed to identify the challenges encountered in the course and how to overcome them. The results demonstrate that the Generative AI Course for Technologists effectively equips students with technical expertise and critical thinking skills through a balanced combination of theoretical concepts and practical exercises, such as chatbot development and prompt engineering. The course addresses challenges like hardware limitations and API integration by proposing future improvements, including a dedicated Python module and access to cloud-based GPU tools, ensuring learners are well-prepared to navigate and ethically apply Generative AI in real-world contexts.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {99–110},
numpages = {12}
}

@inproceedings{10.1145/3706599.3720278,
author = {Helgert, Andre and Weis, Latoya and Strassmann, Carolin},
title = {Prompt it Colorful with Rainbow Bot: Enhancing Video-Based Collaborative Learning by using a Multi-Party AI-Driven Chatbot},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720278},
doi = {10.1145/3706599.3720278},
abstract = {Multi-party AI-driven chatbots remain largely unexplored, despite their potential to enhance internal communication and coordination within student learning groups. These benefits are increasingly feasible with the advent of large language models (LLMs), which enable more efficient content generation and chatbot customization. To bridge this gap, we carried out an exploratory study to examine students’ perceptions, practical applications, and concerns regarding the use of multi-party AI-driven chatbots in video-based collaborative learning environments. Based on the findings, we designed the Rainbow Bot, an optimized multi-party AI-driven chatbot. It features an interactive reflection process to strengthen group dynamics, customization options to adjust response length and content focus, and a unique color scheme for visual clarity. By combining colors from group members in refined prompts, Rainbow Bot fosters collaboration and promotes shared understanding within teams. Future work will assess its effectiveness in real educational settings, with a focus on its impact on group dynamics and collaborative learning outcomes.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {7},
keywords = {Collaborative Learning, Multi-party AI-driven chatbots, AI-driven chatbots, Artifical Intelligence, Higher Education, Chatbot},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701974,
author = {P?durean, Victor-Alexandru and Denny, Paul and Singla, Adish},
title = {BugSpotter: Automated Generation of Code Debugging Exercises},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701974},
doi = {10.1145/3641554.3701974},
abstract = {Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {896–902},
numpages = {7},
keywords = {bugspotter, debugging, exercise generation, generative ai, llms, programming education, test cases},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705201,
author = {Bejarano, Andres and Dickey, Ethan and Setsma, Rhianna},
title = {Implementing the AI-Lab Framework: Enhancing Introductory Programming Education for CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705201},
doi = {10.1145/3641555.3705201},
abstract = {The advent of generative AI tools presents novel opportunities and challenges in computer science education, particularly in introductory programming courses. This study explores the implementation of AI-Lab, a framework designed to guide students in the effective and ethical use of generative AI, in this case ChatGPT, in academic settings without compromising skill development. Conducted during Spring 2024, our use of the intervention targeted over 500 Computer Science and Data Science majors enrolled in their major-specific Data Structures and Algorithms courses. The AI-Lab framework enabled students to develop both conceptual questions and c++ and Python programs by interacting with ChatGPT and iteratively correcting its errors. Focus groups and post-intervention surveys revealed a generally positive experience. Students appreciated the ability to leverage AI for tasks outside their major, recognizing the value of understanding correct solutions through AI-assisted programming. Moreover, the guided use of generative AI by professors alleviated concerns regarding academic dishonesty, fostering a supportive learning environment. Despite these benefits, students expressed awareness of the potential drawbacks of over-reliance on AI, noting the risk of impeding their professional growth. Nevertheless, they acknowledged the practical utility of AI for non-major related tasks. This study highlights the importance of incorporating structured AI training in curricula to balance skill development and ethical AI usage, offering insights for broader applications in higher education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1383–1384},
numpages = {2},
keywords = {ai lab, ai-assisted programming, ai-lab framework, ethical ai usage, generative ai in education, skill development with ai, structured ai training},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.5555/3716662.3716740,
author = {Locatelli, Marcelo Sartori and Miranda, Matheus Prado and Costa, Igor Joaquim da Silva and Prates, Matheus Torres and Thom\'{e}, Victor and Monteiro, Mateus Zaparoli and Lacerda, Tomas and Pagano, Adriana and Neto, Eduardo Rios and Meira, Wagner and Almeida, Virgilio},
title = {Examining the Behavior of LLM Architectures within the Framework of Standardized National Exams in Brazil},
year = {2025},
publisher = {AAAI Press},
abstract = {The Exame Nacional do Ensino M\'{e}dio (ENEM) is a pivotal test for Brazilian students, required for admission to a significant number of universities in Brazil. The test consists of four objective high-school level tests on Math, Humanities, Natural Sciences and Languages, and one writing essay. Students' answers to the test and to the accompanying socioeconomic status questionnaire are made public every year (albeit anonymized) due to transparency policies from the Brazilian Government. In the context of large language models (LLMs), these data lend themselves nicely to comparing different groups of humans with AI, as we can have access to human and machine answer distributions. We leverage these characteristics of the ENEM dataset and compare GPT-3.5 and 4, and MariTalk, a model trained using Portuguese data, to humans, aiming to ascertain how their answers relate to real societal groups and what that may reveal about the model biases. We divide the human groups by using socioeconomic status (SES), and compare their answer distribution with LLMs for each question and for the essay. We find no significant biases when comparing LLM performance to humans on the multiple-choice Brazilian Portuguese tests, as the distance between model and human answers is mostly determined by the human accuracy. A similar conclusion is found by looking at the generated text as, when analyzing the essays, we observe that human and LLM essays differ in a few key factors, one being the choice of words where model essays were easily separable from human ones. The texts also differ syntactically, with LLM generated essays exhibiting, on average, smaller sentences and less thought units, among other differences. These results suggest that, for Brazilian Portuguese in the ENEM context, LLM outputs represent no group of humans, being significantly different from the answers from Brazilian students across all tests. The appendices may be found at https://arxiv.org/abs/2408.05035.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {879–890},
numpages = {12}
}

@inproceedings{10.1145/3641554.3701934,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Becker, Brett A.},
title = {Exploring Student Reactions to LLM-Generated Feedback on Explain in Plain English Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701934},
doi = {10.1145/3641554.3701934},
abstract = {Code reading and comprehension skills are essential for novices learning programming, and explain-in-plain-English tasks (EiPE) are a well-established approach for assessing these skills. However, manual grading of EiPE tasks is time-consuming and this has limited their use in practice. To address this, we explore an approach where students explain code samples to a large language model (LLM) which generates code based on their explanations. This generated code is then evaluated using test suites, and shown to students along with the test results. We are interested in understanding how automated formative feedback from an LLM guides students' subsequent prompts towards solving EiPE tasks. We analyzed 177 unique attempts on four EiPE exercises from 21 students, looking at what kinds of mistakes they made and how they fixed them. We found that when students made mistakes, they identified and corrected them using either a combination of the LLM-generated code and test case results, or they switched from describing the purpose of the code to describing the sample code line-by-line until the LLM-generated code exactly matched the obfuscated sample code. Our findings suggest both optimism and caution with the use of LLMs for unmonitored formative feedback. We identified false positive and negative cases, helpful variable naming, and clues of direct code recitation by students. For most students, this approach represents an efficient way to demonstrate and assess their code comprehension skills. However, we also found evidence of misconceptions being reinforced, suggesting the need for further work to identify and guide students more effectively.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {575–581},
numpages = {7},
keywords = {eipe, explain in plain english, formative feedback, large language models, llm, misconceptions, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713731,
author = {Kang, Wenhui and Zhang, Lin and Peng, Xiaolan and Zhang, Hao and Li, Anchi and Wang, Mengyao and Huang, Jin and Tian, Feng and Dai, Guozhong},
title = {TutorCraftEase: Enhancing Pedagogical Question Creation with Large Language Models},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713731},
doi = {10.1145/3706598.3713731},
abstract = {Pedagogical questions are crucial for fostering student engagement and learning. In daily teaching, teachers pose hundreds of questions to assess understanding, enhance learning outcomes, and facilitate the transfer of theory-rich content. However, even experienced teachers often struggle to generate a large volume of effective pedagogical questions. To address this, we introduce TutorCraftEase, an interactive generation system that leverages large language models (LLMs) to assist teachers in creating pedagogical questions. TutorCraftEase enables the rapid generation of questions at varying difficulty levels with a single click, while also allowing for manual review and refinement. In a comparative user study with 39 participants, we evaluated TutorCraftEase against a traditional manual authoring tool and a basic LLM tool. The results show that TutorCraftEase can generate pedagogical questions comparable in quality to those created by experienced teachers, while significantly reducing their workload and time.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1076},
numpages = {22},
keywords = {large language models, intelligent tutoring systems, human-AI collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3705278,
author = {Jayaraman, Sharanya and Kolarkar, Ameya},
title = {Using Peer Tutoring to Bolster Retention Rates and Student Performance in CS1 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705278},
doi = {10.1145/3641555.3705278},
abstract = {Active Learning approaches have found success in CS1 and CS2 courses, consolidating instructional time on the practical, problem-solving aspects of programming. With the increasing availability of generative Artificial Intelligence Assistants, there is a renewed push to focus on higher-order skills beyond syntax and solving programming problems by matching sample outputs.This poster examines the impact of conceptual explanation-based exercises in introductory programming courses through the implementation of a scaffolded semi-flipped classroom. This method is currently in its third semester as a part of an ongoing, iterative, semi-experimental approach to support student resilience in entrance-level courses. This approach aimed to enhance student engagement, retention, and performance by integrating weekly practice sessions and "group-tutoring" sessions facilitated by peer learning assistants. In these sessions, students were encouraged to articulate their problem-solving strategies and the reasoning behind their solutions, fostering a deeper understanding of programming language paradigms and problem-solving techniques.The findings indicate that this method significantly increased classroom engagement, as students became more active participants in their learning journey. Retention rates improved as students became more confident in understanding and applying programming concepts. Overall, student performance saw a notable rise, with students demonstrating a better grasp of programming paradigms and problem-solving approaches beyond rote memorization and matching sample outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1495–1496},
numpages = {2},
keywords = {active learning, cs1/cs2, peer-based learning, self-assessment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713513,
author = {Bodonhelyi, Anna and Thaqi, Enkeleda and \"{O}zdel, S\"{u}leyman and Bozkir, Efe and Kasneci, Enkelejda},
title = {From Passive Watching to Active Learning: Empowering Proactive Participation in Digital Classrooms with AI Video Assistant},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713513},
doi = {10.1145/3706598.3713513},
abstract = {In online education, innovative tools are crucial for enhancing learning outcomes. SAM (Study with AI Mentor) is an advanced platform that integrates educational videos with a context-aware chat interface powered by large language models. SAM encourages students to ask questions and explore unclear concepts in real time, offering personalized, context-specific assistance, including explanations of formulas, slides, and images. We evaluated SAM in two studies: one with 25 university students and another with 80 crowdsourced participants, using pre- and post-knowledge tests to compare a group using SAM and a control group. The results demonstrated that SAM users achieved greater knowledge gains specifically for younger learners and individuals in flexible working environments, such as students, supported by a 97.6% accuracy rate in the chatbot’s responses. Participants also provided positive feedback on SAM’s usability and effectiveness. SAM’s proactive approach to learning not only enhances learning outcomes but also empowers students to take full ownership of their educational experience, representing a promising future direction for online learning tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {16},
numpages = {21},
keywords = {E-Learning, Real-Time Assistant, AI tutor, ChatGPT, User Study},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641555.3705040,
author = {Garcia, Frank Ley},
title = {LLM+RAG Driven Topic Modeling},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705040},
doi = {10.1145/3641555.3705040},
abstract = {This paper explores the use of Large Language Models (LLMs) combined with Retrieval-Augmented Generation (RAG) to assist instructors in identifying course-wide student challenges through topic modeling. Unlike previous studies that primarily generate personalized resources for individual students, this research focuses on analyzing reflections from an entire class to inform curriculum design and intervention strategies. Using the LLaMa-3.1-8B model, experiments across varying cosine similarity thresholds reveal both the strengths and limitations of integrating retrieval-based models. While RAG did not consistently outperform standalone LLMs, it offers key insights into the complexities of applying retrieval-augmented approaches in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1754},
numpages = {1},
keywords = {large language models, natural language processing, probabilistic modeling, retrieval-augmented generation, text analysis, topic modeling},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705044,
author = {Wiktor, Nicole},
title = {Optimizing Prompt Engineering for Automated Text Summarization of Student Reflections: A Comparative Study Using GPT-4 LLM},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705044},
doi = {10.1145/3641555.3705044},
abstract = {In the educational domain, extracting insights from student-written text has shown to be valuable for instructors. Efficiently summarizing students' reflections in a course offers instructors valuable insights to enhance students' learning experience. Therefore, quickly understanding students' impressions about the course could be very helpful to instructors for in-time and/or personalized one-on-one discussions. Achieving this often involves using natural language processing (NLP) techniques Understanding capabilities of LLMs through a series of comparative experiments involving prompt engineering is the goal of this work. We compare the summarization outputs of GPT-4 with an experimentally optimized temperature of 0.75 through a variety of experiments that include different levels of prompts, starting with base level and proceeding to increase context in the prompt. We evaluate and compare the outputs of these summaries based on a rubric from literature, evaluated by human annotators. Our findings suggest that providing more detailed context prompts help LLMs uncover less frequent and obvious student challenges and provide more detailed explanations. One notable finding showed how sensitive the LLM approach is to the distribution of the challenge types in students' reflections. In other words, all prompts regardless of their contextual details faced issues due to this misrepresenting of student challenges distributions, sometimes overstating their occurrence frequency. Therefore, further study is required to refine the data distribution impact. Despite this, the approach shows much potential to extract useful knowledge quickly. It offers valuable insights to instructors and could help in supporting students more effectively.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1764},
numpages = {1},
keywords = {GPT-4, large language models, natural language processing, prompt engineering, text summarization},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705253,
author = {Smith, Samantha Boatright and Wei, Heather and O'Neill, Abby and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges},
title = {Spotting AI Missteps: Students Take on LLM Errors in CS1},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705253},
doi = {10.1145/3641555.3705253},
abstract = {CS1 courses have rapidly adopted Large Language Model (LLM)- based assistance, promising quick and always-available support for homework help. However, it is challenging to ensure that the hints and guidance provided by these models are accurate and not based on hallucinated solutions. In this work, we study and categorize LLM behavior in cases where students believe an LLM-powered homework tutor gave an inaccurate hint. We then describe correlations between certain student behaviors (SB) and our suggested bot-behavior (BB) categories.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1627–1628},
numpages = {2},
keywords = {cs1, hallucination, homework help, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705187,
author = {O'Neill, Abby and Smith, Samantha and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges},
title = {From Code to Concepts: Textbook-Driven Knowledge Tracing with LLMs in CS1},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705187},
doi = {10.1145/3641555.3705187},
abstract = {Gauging a student's understanding of course concepts, at an arbitrary point during a course, can be challenging. Standardized exams offer only a snapshot of performance rather than a deep understanding of progress. However, with Large Language Models (LLMs) now deployed at scale in CS1 courses, we can track multiple attempts from each student for every homework problem. This data provides insights into how students learn and deploy concepts over time, presenting a unique opportunity to rethink how we track changes in individual student knowledge. Traditional Knowledge Tracing (KT) methods often lack explainability and are computationally expensive. In contrast, our framework leverages an LLM to identify student progress on labeled, problem-level concepts from a student homework code submission. Our initial results show that the student's knowledge state can be dynamically updated. This knowledge state can then be used to provide more targeted, effective feedback and create tailored study materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1565–1566},
numpages = {2},
keywords = {artificial intelligence/machine learning, cs1/cs2, instructional technologies, programming, tools and tool use},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3705300,
author = {Xu, Xiaodan and Ni, Chao and Guo, Xinrong and Liu, Shaoxuan and Wang, Xiaoya and Liu, Kui and Yang, Xiaohu},
title = {Distinguishing LLM-Generated from Human-Written Code by Contrastive Learning},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3705300},
doi = {10.1145/3705300},
abstract = {Large language models (LLMs), such as ChatGPT released by OpenAI, have attracted significant attention from both industry and academia due to their demonstrated ability to generate high-quality content for various tasks. Despite the impressive capabilities of LLMs, there are growing concerns regarding their potential risks in various fields, such as news, education, and software engineering. Recently, several commercial and open source LLM-generated content detectors have been proposed, which, however, are primarily designed for detecting natural language content without considering the specific characteristics of program code. This article aims to fill this gap by proposing a novel ChatGPT-generated code detector, CodeGPTSensor, based on a contrastive learning framework and a semantic encoder built with UniXcoder. To assess the effectiveness of CodeGPTSensor on differentiating ChatGPT-generated code from human-written code, we first curate a large-scale Human and Machine comparison Corpus (HMCorp), which includes 550k pairs of human-written and ChatGPT-generated code (i.e., 288k Python code pairs and 222k Java code pairs). Based on the HMCorp dataset, our qualitative and quantitative analysis of the characteristics of ChatGPT-generated code reveals the challenge and opportunity of distinguishing ChatGPT-generated code from human-written code with their representative features. Our experimental results indicate that CodeGPTSensor can effectively identify ChatGPT-generated code, outperforming all selected baselines.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {31},
keywords = {Large Language Model, ChatGPT, AI-generated Code Detection, Contrastive Learning}
}

@inproceedings{10.1145/3706468.3706479,
author = {R\"{u}dian, Sylvio and Podelo, Julia and Ku\v{z}\'{\i}lek, Jakub and Pinkwart, Niels},
title = {Feedback on Feedback: Student’s Perceptions for Feedback from Teachers and Few-Shot LLMs},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706479},
doi = {10.1145/3706468.3706479},
abstract = {Large language models (LLMs) can be a valuable resource for generating texts and performing various instruction-based tasks. In this paper, we explored the use of LLMs, particularly for generating feedback for students in higher education. More precisely, we conducted an experiment to examine students’ perceptions regarding LLM-generated feedback. This has the overall aim of assisting teachers in the feedback creation process. First, we examine the different student perceptions regarding the feedback that students got without being aware of whether it was created by their teacher or an LLM. Our results reveal that the feedback source has not impacted how it was perceived by the students, except in cases where repetitive content has been generated, which is a known limitation of LLMs. Second, students have been asked to identify whether the feedback comes from an LLM or the teacher. The results demonstrate, that students were unable to identify the feedback source. A small subset of indicators has been identified, that clearly revealed from whom the feedback comes from. Third, student perceptions are analyzed while knowing that feedback has been auto-generated. This examination indicates that generated feedback is likely to be met with resistance. It contradicts the findings of the first examination. This emphasizes the need of a teacher-in-the-loop approach when employing auto-generated feedback in higher education.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {82–92},
numpages = {11},
keywords = {Large Language Models, Prompt Engineering, Feedback Indicators, Language Learning},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706598.3713447,
author = {Falk, Jeanette and Chen, Yiyi and Rafner, Janet and Zhang, Mike and Bjerva, Johannes and Nolte, Alexander},
title = {How Do Hackathons Foster Creativity? Towards Automated Evaluation of Creativity at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713447},
doi = {10.1145/3706598.3713447},
abstract = {Hackathons have become popular collaborative events for accelerating the development of creative ideas and prototypes. There are several case studies showcasing creative outcomes across domains such as industry, education, and research. However, there are no large-scale studies on creativity in hackathons which can advance theory on how hackathon formats lead to creative outcomes. We conducted a computational analysis of 193,353 hackathon projects. By operationalizing creativity through usefulness and novelty, we refined our dataset to 10,363 projects, allowing us to analyze how participant characteristics, collaboration patterns, and hackathon setups influence the development of creative projects. The contribution of our paper is twofold: We identified means for organizers to foster creativity in hackathons. We also explore the use of large language models (LLMs) to augment the evaluation of creative outcomes and discuss challenges and opportunities of doing this, which has implications for creativity research at large.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {198},
numpages = {23},
keywords = {Hackathons, creativity, human-centered AI, large language models, quantitative methods},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708359.3712156,
author = {Chen, Chaoran and Zhou, Daodao and Ye, Yanfang and Li, Toby Jia-Jun and Yao, Yaxing},
title = {CLEAR: Towards Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation for Large Language Model Applications},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712156},
doi = {10.1145/3708359.3712156},
abstract = {The rise of end-user applications powered by large language models (LLMs), including both conversational interfaces and add-ons to existing graphical user interfaces (GUIs), introduces new privacy challenges. However, many users remain unaware of the risks. This paper explores methods to increase user awareness of privacy risks associated with LLMs in end-user applications. We conducted five co-design workshops to uncover user privacy concerns and their demand for contextual privacy information within LLMs. Based on these insights, we developed CLEAR (Contextual LLM-Empowered Privacy Policy Analysis and Risk Generation), a just-in-time contextual assistant designed to help users identify sensitive information, summarize relevant privacy policies, and highlight potential risks when sharing information with LLMs. We evaluated the usability and usefulness of CLEAR across two example domains: ChatGPT and the Gemini plugin in Gmail. Our findings demonstrated that CLEAR is easy to use and improves users’ understanding of data practices and privacy risks. We also discussed LLM’s duality in posing and mitigating privacy risks, offering design and policy implications.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {277–297},
numpages = {21},
keywords = {large language model, privacy awareness, privacy intervention, privacy literacy},
location = {
},
series = {IUI '25}
}

@article{10.1145/3712301,
author = {Ferreira, Gregorio and Amidei, Jacopo and Nieto, Rub\'{e}n and Kaltenbrunner, Andreas},
title = {Matching GPT-simulated Populations with Real Ones in Psychological Studies—The Case of the EPQR-A Personality Test},
year = {2025},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {2},
url = {https://doi.org/10.1145/3712301},
doi = {10.1145/3712301},
abstract = {This article analyzes how well OpenAI’s LLM GPT-4 can emulate different personalities and simulate populations to answer psychological questionnaires similarly to real population samples. For this purpose, we performed different experiments with the Eysenck Personality Questionnaire-Revised Abbreviated (EPQR-A) in three different languages (Spanish, English, and Slovak). The EPQR-A measures personality on four scales: extraversion (E: sociability), neuroticism (N: emotional stability), psychoticism (P: tendency to break social rules, and not having empathy), and lying (L: social desirability).We perform a comparative analysis of the answers of synthetic populations with those of two real population samples of Spanish students as well as the unconditioned baseline personality of GPT. Furthermore, the impact of time (what year the questionnaire is answered), questionnaire language, and student age and gender are analyzed.To our knowledge, this is the first time the EPQR-A test has been used to assess the GPT´s personality and the impact of different language versions and time are measured.Our analysis reveals that GPT-4 exhibits an extroverted, emotionally stable personality with low psychoticism levels and high social desirability. GPT-4 replicates some differences observed in real populations in terms of gender but only partially replicates the results for real populations.},
journal = {ACM Trans. Comput. Healthcare},
month = apr,
articleno = {26},
numpages = {33},
keywords = {Large Language Models, EPQR-A test, GPT, synthetic populations, personality test}
}

@inproceedings{10.1145/3641554.3701910,
author = {Gonzalez-Maldonado, David and Liu, Jonathan and Franklin, Diana},
title = {Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701910},
doi = {10.1145/3641554.3701910},
abstract = {Though the increased availability of Large Language Models (LLMs) presents significant potential for change in the way students learn to program, the text-based nature of the available tools currently preclude block-based languages from much of that innovation. In an attempt to remedy this, we identify the strengths and weaknesses of using a transpiler to leverage the existing learning in commercially available LLMs and Scratch, a visual block-based programming language.Using only prompt engineering, we evaluate an LLM's performance on two common classroom tasks in a Scratch curriculum. We evaluate the LLM's ability to: 1) Create project solutions that compile and satisfy project requirements and 2) Analyze student projects' completion of project requirements using natural language. In both cases, we find results indicating that prompt-engineering alone is insufficient to reliably produce high-quality results. For projects of medium complexity, the LLM-generated solutions consistently failed to follow correct syntax or, in the few instances with correct syntax, produce correct solutions. When used for auto-grading, we found a correlation between scores assigned by the official Scratch Encore autograder and those generated by the LLM, nevertheless the discrepancies between the 'real' scores and the scores assigned by the LLM remained too great for the tool to be reliable in a classroom setting.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {388–394},
numpages = {7},
keywords = {block based programming, generative ai, k-12, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.5555/3716662.3716671,
author = {Barnett, Julia and Kieslich, Kimon and Diakopoulos, Nicholas},
title = {Simulating Policy Impacts: Developing a Generative Scenario Writing Method to Evaluate the Perceived Effects of Regulation},
year = {2025},
publisher = {AAAI Press},
abstract = {The rapid advancement of AI technologies yields numerous future impacts on individuals and society. Policymakers are tasked to react quickly and establish policies that mitigate those impacts. However, anticipating the effectiveness of policies is a difficult task, as some impacts might only be observable in the future and respective policies might not be applicable to the future development of AI. In this work we develop a method for using large language models (LLMs) to evaluate the efficacy of a given piece of policy at mitigating specified negative impacts. We do so by using GPT-4 to generate scenarios both pre- and post-introduction of policy and translating these vivid stories into metrics based on human perceptions of impacts. We leverage an already established taxonomy of impacts of generative AI in the media environment to generate a set of scenario pairs both mitigated and non-mitigated by the transparency policy in Article 50 of the EU AI Act. We then run a user study (n = 234) to evaluate these scenarios across four risk-assessment dimensions: severity, plausibility, magnitude, and specificity to vulnerable populations. We find that this transparency legislation is perceived to be effective at mitigating harms in areas such as labor and well-being, but largely ineffective in areas such as social cohesion and security. Through this case study we demonstrate the efficacy of our method as a tool to iterate on the effectiveness of policy for mitigating various negative impacts. We expect this method to be useful to researchers or other stakeholders who want to brainstorm the potential utility of different pieces of policy or other mitigation strategies.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {82–93},
numpages = {12}
}

@inproceedings{10.1145/3641554.3701932,
author = {Farinetti, Laura and Cagliero, Luca},
title = {A Critical Approach to ChatGPT: An Experience in SQL Learning},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701932},
doi = {10.1145/3641554.3701932},
abstract = {ChatGPT potential value in education is broadly recognized and many studies report experiments of its use inside or outside the classroom by students and teachers. On the other hand, the use of ChatGPT rises lots of concerns about well-known problems such as hallucination, plagiarism, overreliance, or misinformation. It is of primary importance to teach students a correct and constructive use of ChatGPT and a critical approach to its returned outputs. The paper presents a classroom experience where students were asked to interact with ChatGPT in the context of a database course. The declared challenge for the students was, given a set of predefined relational database schemata, to invent questions for ChatGPT and try to force wrong SQL solutions. Students had to record the question, the ChatGPT solution, their solution, and the comments about the eventual ChatGPT syntactical and/or semantical errors. This gamification approach was meant to enhance students' motivation, but the main teachers' goal was to make them reflect critically (i) on ChatGPT output, experiencing that it does make mistakes, (ii) on the interpretation of ChatGPT errors, and (iii) on the possible strategies for forcing ChatGPT errors. The experiment involved 166 B.S. students in Engineering and the collected data have been analyzed under different points of view to get an insight into the approach and the critical attitude of the students. The paper reports the results of this analysis and discusses the impact of the activity on learning by analyzing the correlation between students' participation and exam performance.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {318–324},
numpages = {7},
keywords = {critical thinking, database education, human-computer interaction, large language model, sql},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705245,
author = {Roy, Nimisha and Olufisayo, Omojokun and Tu, Huaijin},
title = {Scaling Academic Decision-Making with NLP: Automating Transfer Credit Evaluations},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705245},
doi = {10.1145/3641555.3705245},
abstract = {Manual processes for evaluating external course syllabi for transfer credit in higher education are time-consuming, inconsistent, and prone to bias. This project leverages Natural Language Processing (NLP) and large language models (LLMs) to automate the transfer credit evaluation process. The system processes external syllabi by embedding course content, conducting similarity searches, and providing structured reasoning for each match. Using techniques such as chain-of-thought reasoning and reflection agents, the system generates similarity scores and detailed explanations to support informed, data-driven decision-making by faculty. Validated against faculty decisions, the system promises to significantly improve the efficiency, consistency, and fairness of transfer credit evaluations. Future directions include expanding the system for advanced standing test evaluations and allowing faculty to query specific course components for more targeted analysis.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1603–1604},
numpages = {2},
keywords = {academic decision support., automated decision-making cosine similarity, chain-of-thought reasoning, course syllabi analysis, large language models (llms), natural language processing (nlp), transfer credit evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3737313.3737341,
author = {Morales, Christopher},
title = {The Effectiveness of ChatGPT in Coding Novel Agent Classes for a Predator-Prey Model-Inspired Iterated Prisoner's Dilemma Model},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {I present a variant of the Iterated Prisoner's Dilemma incorporating elements of a predator-prey model, and assess whether the popular large language models (LLMs) ChatGPT-4o and ChatGPT-4o Mini should be recommended for use by pre-introductory-programming simulation and modeling students to help explore novel strategies for success in the model. I find that the LLMs' output is too unreliable to recommend to students for unsupervised use. However, LLMs may still be useful tools when used under the guidance of an instructor.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {178–185},
numpages = {8}
}

@article{10.1145/3732784,
author = {Xie, Shuyi and Yao, Wenlin and Dai, Yong and Wang, Shaobo and Xu, Zishan and Lin, Fan and Zhou, Donglin and Jin, Lifeng and Feng, Xinhua and Wei, Pengzhi and Lin, Yujie and Hu, Zhichao and Yu, Dong and Zhang, Zhengyou and Nie, Jing and Liu, Yuhong},
title = {TencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for Human-Aligned LLMs},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3732784},
doi = {10.1145/3732784},
abstract = {Large language models (LLMs) have shown impressive capabilities across various natural language tasks. However, evaluating their alignment with human preferences remains a challenge. To this end, we propose a comprehensive human evaluation framework to assess LLMs’ proficiency in following instructions on diverse real-world tasks. We construct a hierarchical task tree encompassing 7 major areas covering over 200 categories and over 800 tasks, which covers diverse capabilities such as question answering, reasoning, multiturn dialogue, and text generation, to evaluate LLMs in a comprehensive and in-depth manner. We also design detailed evaluation standards and processes to facilitate consistent, unbiased judgments from human evaluators. A test set of over 3,000 instances is released, spanning different difficulty levels and knowledge domains. Our work provides a standardized methodology to evaluate human alignment in LLMs for both English and Chinese. We also analyze the feasibility of automating parts of evaluation with a strong LLM (GPT-4). Our framework supports a thorough assessment of LLMs as they are integrated into real-world applications. We have made publicly available the task tree, TencentLLMEval dataset, and evaluation methodology which have been demonstrated as effective in assessing the performance of Tencent Hunyuan LLMs 1. By doing so, we aim to facilitate the benchmarking of advances in the development of safe and human-aligned LLMs.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
keywords = {human-aligned, LLMs, Evaluation}
}

@inproceedings{10.1145/3716640.3716656,
author = {Vadaparty, Annapurna and Geng, Francis and Smith, David H and Benario, Jamie Gorson and Zingaro, Daniel and Porter, Leo},
title = {Achievement Goals in CS1-LLM},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716656},
doi = {10.1145/3716640.3716656},
abstract = {Introduction: The emergence and widespread adoption of generative AI (GenAI) chatbots such as ChatGPT, and programming assistants such as GitHub Copilot, have radically redefined the landscape of programming education. This calls for replication of studies and reexamination of findings from pre-GenAI CS contexts to understand the impact on students. Objectives: Achievement Goals are well studied in computing education and can be predictive of student interest and exam performance. The objective in this study is to compare findings from prior achievement goal studies in CS1 courses with new CS1 courses that emphasize the use of human-GenAI collaborative coding. Methods: In a CS1 course that integrates GenAI, we use linear regression to explore the relationship between achievement goals and prior experience on student interest, exam performance, and perceptions of GenAI. Results: As with prior findings in traditional CS1 classes, Mastery goals are correlated with interest in computing. Contradicting prior CS1 findings, normative goals are correlated with exam scores. Normative and mastery goals correlate with students’ perceptions of learning with GenAI. Mastery goals weakly correlate with reading and testing code output from GenAI.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {CS1, CS1-LLM, Copilot, Achievement Goals, Large Language Models},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705025,
author = {Diaz, Marc and Karp, Dustin and Tuli, Prayuj and Kapoor, Amanpreet},
title = {Edugator: An AI-enabled Tool for Creating and Delivering Interactive Computing Content},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705025},
doi = {10.1145/3641555.3705025},
abstract = {Edugator is a browser-based, AI-enabled tool designed to help instructors of introductory computing courses create and deliver interactive educational content. It streamlines the content authoring process by incorporating generative AI models into both the creation and delivery stages. Instructors can create bespoke interactive computing lessons and programming problems by providing a prompt and a few clicks. They can also author templates and test cases in programming languages such as C++, Java, C, and Python. Additionally, instructors can validate programming problems by running them against an auto-generated solution, allowing them to refine the problems before releasing it to students, preventing misinformation or ambiguity. Students can complete lessons and solve programming problems in a browser-based text editor receiving immediate feedback. They can also interact with a large language model-powered AI chatbot that scaffolds a student on how to approach the problem without giving out solutions. Edugator is built using modern web frameworks and the goal of the tool is to accelerate the adoption of automated assessment tools by minimizing the challenges instructors face with such tools. It also supports Learning Tools Interoperability (LTI), allowing seamless integration with learning management systems (LMS). The demo will provide an overview of Edugator's features, including authoring programming problems and lessons using AI or remixing existing problems obtained from test banks, LTI integration, and AI-chatbot. More information about the tool can be found at https://edugator.app/ and https://github.com/edugatorlabs/resources},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {ai tutor, automated assessment tool, generative ai, introductory programming, learning by doing},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701801,
author = {Nelson, Connor and Doup\'{e}, Adam and Shoshitaishvili, Yan},
title = {SENSAI: Large Language Models as Applied Cybersecurity Tutors},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701801},
doi = {10.1145/3641554.3701801},
abstract = {The modern educational landscape faces the challenge of maintaining effective, personalized mentorship amid expanding class sizes. This challenge is particularly pronounced in fields requiring hands-on practice, such as cybersecurity education. Teaching assistants and peer interactions provide some relief, but the student-to-educator ratio often remains high, limiting individualized attention. The advent of Large Language Models (LLMs) offers a promising solution by potentially providing scalable and personalized guidance. In this paper, we introduce SENSAI, an AI-powered tutoring system that leverages LLMs to offer tailored feedback and assistance by transparently extracting and utilizing the learner's working context, including their active terminals and edited files. Over the past year, SENSAI has been deployed in an applied cybersecurity curriculum at a large public R1 university and made available to a broader online community of global learners, assisting 2,742 users with hundreds of educational challenges. In total 178,074 messages were exchanged across 15,413 sessions, incurring a total cost of 1,979--comparable to that of a single undergraduate teaching assistant but with a significantly wider reach. SENSAI demonstrates significant improvements in student problem-solving efficiency and satisfaction, offering insights into the future role of AI in education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {833–839},
numpages = {7},
keywords = {cybersecurity education, large language models, tutoring},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705141,
author = {Alba, Charles and Xi, Wang and Wang, Chenyu and An, Ruopeng},
title = {ChatGPT Comes to Campus: Unveiling Core Themes in AI Policies Across U.S. Universities with Large Language Models},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705141},
doi = {10.1145/3641555.3705141},
abstract = {The release of popular generative artificial intelligence (AI) tools like ChatGPT have prompted universities to introduce new policies or update existing ones. Currently, most institutions adapt their policies reactively as challenges arise, often without adopting a systematic framework, with minimal guidance and limited knowledge of the approaches taken by other institutions across the United States (U.S.). This study aims to bridge this gap by identifying core themes surrounding AI policies and guidelines across the top 50 U.S. universities. Given the labor- and time-intensive nature required to manually synthesize multiple policy documents across many institutions, we leverage large language models (LLMs) to identify common and prevalent themes. Our framework first summarizes AI policies at the institutional level, followed by the generation of multiple sets of themes through an iterative process of prompt chaining and self-refinement. Finally, the common themes from these distinct sets were consolidated. This framework is designed to address potential flaws in pre-trained LLMs, such as hallucinations. Seven distinct themes are uncovered: (1) academic integrity and responsible AI use, (2) communication of AI policies, (3) data privacy and security concerns, (4) ethical considerations in AI use, (5) continuous adaptation and policy evolution, (6) documentation and transparency in AI usage, and (7) instructor discretion in AI integration. Our work lays the foundation for future analyses or recommendations in developing comprehensive and equitable AI policies. Furthermore, leveraging LLMs allows us to respond swiftly to developments surrounding AI policies across universities.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1359–1360},
numpages = {2},
keywords = {AI policies at universities, ChatGPT, academic integrity, generative AI, generative AI use in classrooms, large language models, teaching with AI},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713773,
author = {Xu, Songlin and Wen, Hao-Ning and Pan, Hongyi and Dominguez, Dallas and Hu, Dongyin and Zhang, Xinyu},
title = {Classroom Simulacra: Building Contextual Student Generative Agents in Online Education for Learning Behavioral Simulation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713773},
doi = {10.1145/3706598.3713773},
abstract = {Student simulation supports educators to improve teaching by interacting with virtual students. However, most existing approaches ignore the modulation effects of course materials because of two challenges: the lack of datasets with granularly annotated course materials, and the limitation of existing simulation models in processing extremely long textual data. To solve the challenges, we first run a 6-week education workshop from N = 60 students to collect fine-grained data using a custom built online education system, which logs students’ learning behaviors as they interact with lecture materials over time. Second, we propose a transferable iterative reflection (TIR) module that augments both prompting-based and finetuning-based large language models (LLMs) for simulating learning behaviors. Our comprehensive experiments show that TIR enables the LLMs to perform more accurate student simulation than classical deep learning models, even with limited demonstration data. Our TIR approach better captures the granular dynamism of learning performance and inter-student correlations in classrooms, paving the way towards a “digital twin” for online education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {789},
numpages = {26},
keywords = {Student Simulation, Generative Agents, Classroom Digital Twin},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714261,
author = {Zhu, Yihao and Ye, Zhoutong and Yuan, Yichen and Tang, Wenxuan and Yu, Chun and Shi, Yuanchun},
title = {AutoPBL: An LLM-powered Platform to Guide and Support Individual Learners Through Self Project-based Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714261},
doi = {10.1145/3706598.3714261},
abstract = {Self project-based learning (SPBL) is a popular learning style where learners follow tutorials and build projects by themselves. SPBL combines project-based learning’s benefit of being engaging and effective with the flexibility of self-learning. However, insufficient guidance and support during SPBL may lead to unsatisfactory learning experiences and outcomes. While LLM chatbots (e.g., ChatGPT) could potentially serve as SPBL tutors, we have yet to see an SPBL platform with responsible and systematic LLM integration. To address this gap, we present AutoPBL, an interactive learning platform for SPBL learners. We examined human PBL tutors’ roles through formative interviews to inform our design. AutoPBL features an LLM-guided learning process with checkpoint questions and in-context Q&amp;A. In a user study where 29 beginners learned machine learning through entry-level projects, we found that AutoPBL effectively improves learning outcomes and elicits better learning behavior and metacognition by clarifying current priorities and providing timely assistance.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {584},
numpages = {26},
keywords = {AI for education, Project-based Learning, Large Language Model},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3720240,
author = {Shochcho, Muhtasim Ibteda and Rahman, Mohammad Ashfaq Ur and Rohan, Shadman and Islam, Ashraful and Heickal, Hasnain and Rahman, AKM Mahbubur and Amin, M. Ashraful and Ali, Amin Ahsan},
title = {Improving User Engagement and Learning Outcomes in LLM-Based Python Tutor: A Study of PACE},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720240},
doi = {10.1145/3706599.3720240},
abstract = {Large Language Models (LLMs) are increasingly being adopted for educational applications, but sometimes, limited internet access and budget constraints restrict their accessibility. Small Language Models (SLMs) have emerged as viable alternatives, capable of providing effective tutoring in resource-constrained contexts. This paper introduces PACE (Python AI Companion for Enhanced Engagement), a system leveraging SLMs to deliver step-by-step guidance and adaptive feedback for teaching Python. An evaluation with varying levels of learners showed PACE’s effectiveness, achieving a System Usability Scale (SUS) score of 77.28. While participants were generally satisfied with its clarity and personalized feedback, they identified some areas for improvement, such as loss of context during lengthy conversations. This study examines (1) the PACE system’s effectiveness in programming education according to learners, (2) learners’ trust in PACE versus traditional resources, and (3) design recommendations to enhance engagement and learning outcomes. PACE contributes to advancing cost-effective, scalable programming education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {12},
keywords = {LLM, SLM, PACE, Python, Tutor, Learning, Tutoring, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641554.3701806,
author = {Kannam, Suhas and Yang, Yuri and Dharm, Aarya and Lin, Kevin},
title = {Code Interviews: Design and Evaluation of a More Authentic Assessment for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701806},
doi = {10.1145/3641554.3701806},
abstract = {Generative artificial intelligence poses new challenges around assessment, increasingly driving introductory programming educators to employ invigilated exams. But exams do not afford more authentic programming experiences that involve planning, implementing, and debugging programs with computer interaction. In this experience report, we describe code interviews: a more authentic assessment method for take-home programming assignments. Through action research, we experimented with the number and type of questions as well as whether interviews were conducted individually or with groups of students. To scale the program, we converted most of our weekly teaching assistant (TA) sections to conduct code interviews on 5 major weekly take-home programming assignments. By triangulating data from 5 sources, we identified 4 themes. Code interviews (1) pushed students to discuss their work, motivating more nuanced but sometimes repetitive insights; (2) enabled peer learning, reducing stress in some ways but increasing stress in other ways; (3) scaled with TA-led sections, replacing familiar practice with an unfamiliar assessment; (4) focused on student contributions, limiting opportunities for TAs to give guidance and feedback. We reflect on the design of code interviews for student experience, academic integrity, and teacher workload.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {554–560},
numpages = {7},
keywords = {authentic assessment, introductory programming, oral exams},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705281,
author = {Li, Carol and Park, Su Min and Tsang, Jedidiah and Yan, Lisa},
title = {What Gets Them Talking? Identifying Catalysts for Student Engagement Within a Computing Ethics Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705281},
doi = {10.1145/3641555.3705281},
abstract = {The expansion of undergraduate CS programs brings different forms of student identity, sociotechnical perspectives, and intersectionality into the classroom. These background factors affect student understanding of the world, and, consequently, their work in computing ethic classes. Instructors of computing ethics courses therefore must facilitate topics that are not only pertinent to modern technologies but that are also interesting for students from a range of backgrounds. In this work, we introduce a low-overhead, natural language processing tool that can assist instructors in extracting student talking points from over 600 discussion forum posts in a large-scale undergraduate computing ethics course. When compared to large language model approaches, this n-gram-based scripting tool is more effective in selecting popular quotes and summarizing course discussion. This tool is simple in implementation and can be easily adapted by instructors to prepare for classroom discussion.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {computing ethics, llm-based tool, n-gram-based tool, open pedagogy, student engagement},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3677389.3702587,
author = {Meng, Jie and Zou, Dangyi and Mao, Jin and Li, Gang},
title = {DBRP: Decomposition and Branch Reasoning Improves Paper Source Tracing},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702587},
abstract = {Understanding the evolution of science from billions of publications has always been a challenge, with the key to solving it lying in paper source tracing (PST). Few-shot learners based on large language models (LLMs) offer a promising solution, yet they face two major challenges. First, tracing source papers requires a profound understanding of scientific texts and complex research logic reasoning, where existing chain-of-thought (CoT) methods struggle to fully grasp this complexity. Second, PST involves linking a target paper with multiple references, and when these texts are used for few-shot learning, the information-rich content of academic texts complicates the learning of reasoning patterns from contextual examples. To address these challenges, this paper presents a novel prompting framework, Decomposition and Branch Reasoning Prompting (DBRP). The core of our approach is the Decomposition-of-Thought (DoT) strategy, which decomposes texts into several components for easier analysis. Additionally, we introduce Branch Reasoning Demonstrations (BRD), a new few-shot learning method that enhances DoT. This approach enables LLMs to efficiently focus on crucial information and learn reasoning patterns. Our experimental results using the advanced language model (GPT-3.5) on the PST-benchmark show that: (1) the DBRP method significantly outperforms the state-of-the-art CoT method by up to 72.8% in mAP and 37% in NDCG; and (2) BRD surpasses standard in-context learning methods, achieving substantial improvements in DoT zero-shot performance. The DBRP method effectively extends the typical CoT paradigm, enabling highly accurate and interpretable automated paper tracing, even under constraints of annotated data. This advancement lays a solid foundation for precise analysis of knowledge trajectories and research lineage.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {64},
numpages = {14}
}

@inproceedings{10.1145/3641554.3701960,
author = {Sanchez, Edwin Antonio and Zheng, Muwei and Bishop, Matt and Zou, Xukai},
title = {Case Study 2: Mapping between an E-Voting Curriculum and the DHS/NSA CAE Knowledge Units},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701960},
doi = {10.1145/3641554.3701960},
abstract = {To become a DHS/NSA Center of Academic Excellence in Cyber Defense (CAE-CD), academic institutions must satisfy several specific Knowledge Units (KUs). How they achieve this is up to the institutions. In this case study, we follow the methodology of an earlier work to demonstrate how key parts of an electronic voting (E-voting)-oriented cybersecurity curriculum, proposed by Hostler et al. [4] in 2021, maps into the DHS/NSA KUs supporting the CAE-CD designation, from two aspects: E-voting principle based topics, i.e., from theory and a plug-and-play e-voting system's composing components, i.e., from practice. We grouped CAE-CD KUs into those required as prerequisites, closely related, related/supported, and not covered by the E-voting curriculum. Teachers can then choose which KUs they will use and teach using only the parts of the E-voting-oriented curriculum they deem relevant, and in a depth they find appropriate to their educational objectives, while meeting the requirements of the selected KUs. We conclude with a discussion of how LLMs (Large Language Models) and quantum computing might be added to the E-voting-oriented curriculum.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1022–1028},
numpages = {7},
keywords = {cae-cd, cybersecurity curriculum, cybersecurity education, electronic voting system},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716649,
author = {Prather, James and Reeves, Brent N and Denny, Paul and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Orvalho, Jo\~{a}o and Alipour, Amin and Alfageeh, Ali and Amarouche, Thezyrie and Kimmel, Bailey and Wright, Jared and Blake, Musa and Barbre, Gweneth},
title = {Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716649},
doi = {10.1145/3716640.3716649},
abstract = {Non-native English speakers (NNES) face multiple barriers to learning programming. These barriers can be obvious, such as the fact that programming language syntax and instruction are often in English, or more subtle, such as being afraid to ask for help in a classroom full of native English speakers. However, these barriers are frustrating because many NNES students know more about programming than they can articulate in English. Advances in generative AI (GenAI) have the potential to break down these barriers because state of the art models can support interactions in multiple languages. Moreover, recent work has shown that GenAI can be highly accurate at code generation and explanation. In this paper, we provide the first exploration of NNES students prompting in their native languages (Arabic, Chinese, and Portuguese) to generate code to solve programming problems. Our results show that students are able to successfully use their native language to solve programming problems, but not without some difficulty specifying programming terminology and concepts. We discuss the challenges they faced, the implications for practice in the short term, and how this might transform computing education globally in the long term.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {74–84},
numpages = {11},
keywords = {AI; Artificial Intelligence; Automatic Code Generation; Codex; Copilot; CS1; GenAI; GitHub; GPT; GPT-4; ChatGPT; HCI; Introductory Programming; Large Language Models; LLM; Non-Native English Speakers; Novice Programming; OpenAI; Prompt Problems},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705227,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement Over Just Showing LLM-Powered Solutions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705227},
doi = {10.1145/3641555.3705227},
abstract = {As generative AI products could generate code and assist students with programming learning seamlessly, integrating AI into programming education contexts has driven much attention. However, one emerging concern is that students might get answers without learning from the LLM-generated content. In this work, we deployed the LLM-powered personalized Parsons puzzles as scaffolding to write-code practice in a Python learning classroom (PC condition) and conducted an 80-minute randomized between-subjects study. Both conditions received the same practice problems. The only difference was that when requesting help, the control condition showed students a complete solution (CC condition), simulating the most traditional LLM output. Results indicated that students who received personalized Parsons puzzles as scaffolding engaged in practicing significantly longer than those who received complete solutions when struggling.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1483–1484},
numpages = {2},
keywords = {GPT, LLM, active learning, generative AI, parsons problems},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3676536.3699507,
author = {Liao, Yuchao and Adegbija, Tosiron and Lysecky, Roman},
title = {Are LLMs Any Good for High-Level Synthesis?},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3699507},
doi = {10.1145/3676536.3699507},
abstract = {The increasing complexity and demand for faster, energy-efficient hardware designs necessitate innovative High-Level Synthesis (HLS) methodologies. This paper explores the potential of Large Language Models (LLMs) to streamline or replace the HLS process, leveraging their ability to understand natural language specifications and refactor code. We survey the current research and conduct experiments comparing Verilog designs generated by a standard HLS tool (Vitis HLS) with those produced by LLMs translating C code or natural language specifications. Our evaluation focuses on quantifying the impact on performance, power, and resource utilization, providing an assessment of the efficiency of LLM-based approaches. This study aims to illuminate the role of LLMs in HLS, identifying promising directions for optimized hardware design in applications such as AI acceleration, embedded systems, and high-performance computing.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {29},
numpages = {8},
keywords = {high-level synthesis, hardware accelerator design, electronic design automation, large language models},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3722237.3722354,
author = {Han, Xue and Li, Zhixiang and Zhang, Wenchuan and Fan, Wentao},
title = {Generative AI in Education: Developing Personalized Learning Experiences with Hyperspherical Variational Self-Attention Autoencoder},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722354},
doi = {10.1145/3722237.3722354},
abstract = {With the advancement of artificial intelligence (AI) technology, content generation has sparked a transformative revolution in the field of education. In traditional education, teachers often spend a lot of time preparing lessons, because students have varying levels of proficiency, teachers need to consider whether the teaching content is suitable for everyone. Generative AI provides an effective solution to this problem by automatically generating personalized, high-quality educational content, which not only alleviates the burden on teachers but also enhances students' learning outcomes. This study focuses on a novel deep generative model—a framework based on Variational Autoencoders (VAE) and the self-attention mechanism (Transformer). We propose a model called the Hyperspherical Variational Self-Attention Autoencoder (HVSAE), which aims to generate personalized learning content based on students' learning situations, thereby reducing the burden on teachers and improving learning outcomes. The experimental results indicate that the model can generate high-quality educational resources, providing important support for achieving more personalized and efficient education.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {670–674},
numpages = {5},
keywords = {Generative artificial intelligence, HVSAE, Personalized education, Self-attention mechanism, VAE},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3709025.3712219,
author = {Zheng, Lucia and Guha, Neel and Arifov, Javokhir and Zhang, Sarah and Skreta, Michal and Manning, Christopher D. and Henderson, Peter and Ho, Daniel E.},
title = {A Reasoning-Focused Legal Retrieval Benchmark},
year = {2025},
isbn = {9798400714214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709025.3712219},
doi = {10.1145/3709025.3712219},
abstract = {As the legal community increasingly examines the use of large language models (LLMs) for various legal applications, legal AI developers have turned to retrieval-augmented LLMs ("RAG" systems) to improve system performance and robustness. An obstacle to the development of specialized RAG systems is the lack of realistic legal RAG benchmarks which capture the complexity of both legal retrieval and downstream legal question-answering. To address this, we introduce two novel legal RAG benchmarks: Bar Exam QA and Housing Statute QA. Our tasks correspond to real-world legal research tasks, and were produced through annotation processes which resemble legal research. We describe the construction of these benchmarks and the performance of existing retriever pipelines. Our results suggest that legal RAG remains a challenging application, thus motivating future research.},
booktitle = {Proceedings of the 2025 Symposium on Computer Science and Law},
pages = {169–193},
numpages = {25},
keywords = {benchmark, dataset, reasoning, retrieval},
location = {Munich, Germany},
series = {CSLAW '25}
}

@inproceedings{10.1145/3723010.3723036,
author = {B\"{o}hm, Karsten},
title = {Towards a Semantic Representation of Framework Recommendations for Curricular Specifications in Higher Education},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723036},
doi = {10.1145/3723010.3723036},
abstract = {Curricular specifications play an important role in the Higher Education sector and the domain of Computer Science and Software Engineering is characterized by a wide range of education programs with a broad range of topic. Therefore, recommendation frameworks play an important role and their usage is beneficial for a unification of education profiles in a systematic way. This  research is contributing to this development by exploring how a recommendation for the domain of Business Informatics in German speaking countries can be improved by formalizing the recommendations in a semantic model that relies on sophisticated European ontologies in the domain like the European Learning Model (ELM) and related data models. It employs Generative Artificial Intelligence Systems to create semantic models in an experimental way and evaluates the resulting model quality. The results show that a formalization using GenAI has a high potential, but currently also shows deficits in the correctness of the resulting models, requiring human oversight during the model creation.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {154–160},
numpages = {7},
keywords = {Business Informatics, Competence Specification, European Learning Model, Higher Education, Learning Framework, Semantic Web},
location = {
},
series = {ECSEE '25}
}

@article{10.5555/3737313.3737323,
author = {Barnard, Jakob and Braught, Grant and Davis, Janet and Holland-Minkley, Amanda and Schmitt, Karl and Tartaro, Andrea},
title = {Reviewing and Revising your Undergraduate CS Major: A Structured Design Process for Creating Distinctive Curricula},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Computer science (CS) programs have a variety of reasons for regularly reviewing and revising the curriculum for their undergraduate major. Some of these stem from the rapid pace of change in the discipline and corresponding changes in industry expectations for CS graduates. This has been most recently seen as departments consider how to adjust to advances in generative AI and respond to new international curricular guidelines in the form of CS2023 [1]. Programs also revise their CS major in response to contextual shifts at their institution, such as changes in the size and makeup of the student body, the resources and staffing of a program, assessment results, or new institutional priorities [6]. A shifting student body may come with changes in prior experience with computing and in the professional goals of the students. For smaller programs, staffing changes often affect the balance of expertise within subareas of CS. New institutional priorities such as enabling more study abroad experiences or embedding internship/service-learning into the curriculum can require majors to adjust to both accommodate and support these priorities.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {32–34},
numpages = {3}
}

@inproceedings{10.1145/3641555.3705180,
author = {Brilliantova, Angelina and Butler, Zack and Bez\'{a}kov\'{a}, Ivona},
title = {Exploring ChatGPT as a Qualitative Research Assistant},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705180},
doi = {10.1145/3641555.3705180},
abstract = {In many CS educational research studies, students are surveyed to understand their reactions to a particular pedagogical approach or tool. These surveys, as well as other types of evaluations, often invite students to provide open-ended feedback about their experiences. However, analyzing these comments can prove to be a challenge, especially to CS educators who may not have strong expertise in qualitative research methods. In addition, in a large study, evaluating all of the provided comments can consume a significant amount of researcher time. In this work, we undertook two separate conversations with ChatGPT in which we prompted it to perform qualitative analysis of a set of comments collected in an earlier study. This allowed us to begin to judge how effectively a modern large language model can serve as an assistant in qualitative analysis. We found that with the prompts we used, ChatGPT can reliably build a set of reasonable labels (codes) for a set of comments, but the application of its labels to specific comments may or may not be effective and human researchers still need to use care and their own understanding in interpreting its output.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1397–1398},
numpages = {2},
keywords = {chatgpt, grounded theory, large-language models, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3701716.3715199,
author = {Zhang, Yifan and Zhao, Xinkui and Wang, Zuxin and Zhou, Zhengyi and Cheng, Guanjie and Deng, Shuiguang and Yin, Jianwei},
title = {SortingHat: Redefining Operating Systems Education with a Tailored Digital Teaching Assistant},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715199},
doi = {10.1145/3701716.3715199},
abstract = {Operating Systems (OS) courses are among the most challenging in computer science education due to the complexity of internal structures and the diversity of running environments. Traditional teaching methods often fail to address the diverse backgrounds, learning speeds, and practical needs of students. To tackle these challenges, we present SortingHat, a personalized digital teaching assistant tailored specifically for OS education. SortingHat integrates advanced AI technologies, including a retrieval-augmented generation (RAG) framework and multi-agent reinforcement learning (MARL), to deliver adaptive, scalable, and effective educational support. SortingHat features a 3D digital human interface powered by large language models (LLMs) to provide personalized, empathetic, and context-aware guidance. It generates tailored exercises based on each student's learning history and academic performance, reinforcing weak areas and challenging advanced concepts. Additionally, the system incorporates a robust evaluation pipeline that ensures fair, consistent, and unbiased grading of student submissions while delivering personalized, actionable feedback for improvement. By combining personalized guidance, adaptive content creation, and automated assessment, SortingHat transforms OS education into an engaging, immersive, and scalable experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2951–2954},
numpages = {4},
keywords = {digital human, education, large language models, multi agent reinforcement learning, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3708359.3712104,
author = {Kazemitabaar, Majeed and Huang, Oliver and Suh, Sangho and Henley, Austin Z and Grossman, Tovi},
title = {Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712104},
doi = {10.1145/3708359.3712104},
abstract = {Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners’ perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {695–714},
numpages = {20},
keywords = {AI-Assisted Programming, Generative AI, Copilot, ChatGPT, Cognitive Engagement Enhancement, AI-Assisted Learning, Cognitive Forcing Functions, Task Decomposition, Learning Outcomes},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3641555.3705166,
author = {Demirta\c{s}, Mehmet Arif and Zheng, Claire and Cunningham, Kathryn},
title = {Detecting Programming Plans in Open-ended Code Submissions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705166},
doi = {10.1145/3641555.3705166},
abstract = {Open-ended code-writing exercises are commonly used in large-scale introductory programming courses, as they can be autograded against test cases. However, code writing requires many skills at once, from planning out a solution to applying the intricacies of syntax. As autograding only evaluates code correctness, feedback addressing each of these skills separately cannot be provided. In this work, we explore methods to detect which high-level patterns (i.e. programming plans) have been used in a submission, so learners can receive feedback on planning skills even when their code is not completely correct. Our preliminary results show that LLMs with few-shot prompting can detect the use of programming plans in 95% of correct and 86% of partially correct submissions. Incorporating LLMs into grading of open-ended programming exercises can enable more fine-grained feedback to students, even in cases where their code does not compile due to other errors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1435–1436},
numpages = {2},
keywords = {autograding, large language models, programming plans},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3723010.3723034,
author = {Mueller, Moritz and List, Corinna and Kipp, Michael},
title = {The Power of Context: An LLM-based Programming Tutor with Focused and Proactive Feedback},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723034},
doi = {10.1145/3723010.3723034},
abstract = {Current research aims to utilize Large Language Models (LLMs) for tutoring beginning programming students efficiently and at scale. Students often struggle to interact effectively with LLMs to obtain meaningful feedback. We introduce an LLM-based Intelligent Tutoring System (ITS) with a structured interface and prompts aligned with Hattie’s feedback model. To provide more focused feedback, we utilize the user interaction history for context. Additionally, we explore the question of proactivity.A user study with 9 participants compared history-based and current-state feedback methods using ChatGPT, showing a preference for history-based feedback in 69% of cases and with higher usefulness ratings (M = 7.57 vs. M = 4.1, p = 0.03 (statistically significant at p &lt; 0.05)). This effect became more pronounced in later learning stages. For proactivity, we collected user data from the study, where participants explicitly requested feedback, and trained a neural network (NN) to predict optimal feedback timing. While the model achieved 97% accuracy on test data, the small sample size (N = 10) and the use of oversampling limit its generalizability. Future work will refine history-based feedback with eye-tracking data and integrate NN-driven proactive behavior to further enhance the effectiveness of LLM-based ITS in programming education.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {1–10},
numpages = {10},
keywords = {CS in higher education, Large Language Models, intelligent tutoring, focused feedback, proactive feedback, neural networks},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3641555.3705272,
author = {Hooper, Kerrie and Lunn, Stephanie Jill},
title = {Traversing New Horizons: An Exploration of Educational Policies on Generative AI},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705272},
doi = {10.1145/3641555.3705272},
abstract = {Understanding how tertiary academic institutions approach the integration of generative AI (GAI) into their course policies is crucial since AI technologies are rapidly transforming society. AI is being used and applied across sectors and industries, and it is important to do so with regard to ethics. This exploratory study sought to examine how GAI policies were discussed across academic institutions. The policies were analyzed using NLP techniques and utilized existing publicly available datasets, which consisted of a collection of over 100 university policies and syllabi policies. Unsupervised clustering techniques were applied to analyze patterns in how different institutions may express their policies and best practices. These findings illuminate how universities and colleges may approach topics and challenges around AI, and specifically GAI.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1479–1480},
numpages = {2},
keywords = {NLP analysis, academic policies, generative AI},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713582,
author = {Lima, Maria R. and O'Connell, Amy and Zhou, Feiyang and Nagahara, Alethea and Hulyalkar, Avni and Deshpande, Anura and Thomason, Jesse and Vaidyanathan, Ravi and Matari\'{c}, Maja},
title = {Promoting Cognitive Health in Elder Care with Large Language Model-Powered Socially Assistive Robots},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713582},
doi = {10.1145/3706598.3713582},
abstract = {As the global population ages, there is increasing need for accessible technologies that promote cognitive health and detect early signs of cognitive decline. This research demonstrates the potential for in-residence monitoring and assessment of cognitive health using large language model (LLM)-powered socially assistive robots (SARs). We conducted a 5-week within-subjects study involving 22 older adults in retirement homes to investigate the feasibility of large language model (LLM)-powered socially assistive robots (SARs) for promoting and assessing cognitive health. We designed tasks that involved verbal dialogue based on clinically validated cognitive tools. Our findings reveal improved task performance after three robot-administered sessions, with significantly more detailed picture descriptions, fewer word repetitions in semantic fluency, and reduced need for hints. We found that older adults were more socially engaged in robot-administered tasks compared to those administered by a human, and they accepted and were willing to engage with socially assistive robots (SARs) in this context, which had not been tested before.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {317},
numpages = {22},
keywords = {socially assistive robotics, large language models, cognitive health, elder care},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708036.3708178,
author = {Niu, Hailong and Gong, Xinlu},
title = {The Role of Generative AI in Higher Education: A Decade of Current Status and Future Prospects},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708178},
doi = {10.1145/3708036.3708178},
abstract = {With the rapid development of Generative AI technology, particularly large language models like ChatGPT. Generative AI has brought profound transformations to teaching methods, learning experiences, and assessment models, but it also presents challenges related to academic integrity and educational equity. The purpose of this study is to analyze the current state of Generative AI applications in higher education over the past decade and its future development trends using a comprehensive bibliometric and scientometric approach. The study selects 620 papers from the Web of Science database, published between 2014 and 2024, related to Generative AI and higher education, and employs VOSviewer and CiteSpace software for data analysis and visualization. The results show a significant increase in research on the application of Generative AI in higher education since 2018, with a particular focus on personalized learning, teaching assessment, and interdisciplinary education, which have garnered widespread attention. Through network analyses of collaboration among authors, institutions. This study not only provides researchers with insights into the current status and development trends of Generative AI in higher education but also lays the foundation for deeper discussions on issues such as educational equity and academic integrity.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {848–852},
numpages = {5},
keywords = {generative AI, higher education, large language models},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3689050.3704429,
author = {Han, Kuntong and Tang, Keyang and Wang, Meng},
title = {Stage Wizard: Enhancing Tangible Storytelling with Multimodal LLMs},
year = {2025},
isbn = {9798400711978},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689050.3704429},
doi = {10.1145/3689050.3704429},
abstract = {This paper introduces a pipeline that integrates multimodal large language models (LLMs) for tangible storytelling, featuring flexible materials generation, intuitive hands-on performance, and easy finalization. The design system enables teachers, parents, and children to create stage elements through natural language interactions and generate paper-cut style images. These elements can be easily fabricated using standard printing paper and assembled into a reconfigurable cardstock stage, allowing children to craft various plotlines through manipulation. The storytelling process can be directly recorded as a short film or transformed into an elaborate storybook using styled image filters and refining LLMs. By introducing the role of the stage in both the design and manipulation processes, this pipeline offers intuitive guidance and affordance for free but organized creation. The flexibility introduced by LLMs supports educators in diverse course design and children in self-expression. Without the requirement for specific hardware, the system also has the potential to be applied more broadly in less developed areas.},
booktitle = {Proceedings of the Nineteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {37},
numpages = {13},
keywords = {Author Keywords},
location = {
},
series = {TEI '25}
}

@inproceedings{10.1145/3641554.3701959,
author = {Wu, Ylesia and Zheng, Qirui and Lau, Sam},
title = {How Novices Use Program Visualizations to Understand Code that Manipulates Data Tables},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701959},
doi = {10.1145/3641554.3701959},
abstract = {As data science and artificial intelligence continue to impact society, more and more people are learning how to manipulate data with code. To support these learners, program visualization tools automatically generate diagrams to show how code transforms data, in contrast to tools based on large language models (LLMs) that primarily focus on textual explanations. Although program visualization tools are popular among instructors, do novices find these tools usable and useful for data science programs that often manipulate datasets with many rows? To address this, we evaluate a popular, publicly available tool that generates diagrams for Python pandas code through a randomized, in-lab usability study with 17 data science novices. Despite minimal instruction on how to use the tool, novices found that program visualizations increased their confidence in comprehending and debugging code. In addition, even though the tool sometimes produced diagrams with many visual elements, participant performance on the study tasks was not negatively impacted. These findings suggest design guidelines for program visualization tools to help manage cognitive load for data science novices. To our knowledge, this is the first empirical study that investigates how novices use program visualization tools to understand code that manipulates data tables, and suggests a future where novices can use automatically generated diagrams as a complement to LLM tools for effectively understanding unfamiliar programs in data science.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1267–1273},
numpages = {7},
keywords = {data science education, novice programmers, program visualization tools},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3722237.3722310,
author = {Hwang, Min-Shiang and Fatima, Kanza and Chan, Chi-Shiang and Wu, Chia-Chun},
title = {Research on Steganography Course with Large Language Model ChatGPT Assisted Learning},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722310},
doi = {10.1145/3722237.3722310},
abstract = {In this study, by integrating practice-oriented teaching methods and combining large language models to assist learning and teaching situations, it is proposed that the Steganography course is practical-oriented and integrates ChatGPT with the Steganography language model teaching and teaching established by the applicant. In addition to focusing In addition to cultivating students with Steganography concepts and practical operational abilities, we hope to cultivate students' abilities of active observation, independent research, and critical thinking so that students can meet the technology industry's professional skills and requirements for Steganography studies. This research explores the pre-test and post-test, of course, students' use of large language models to learn to have higher learning attitudes and achievements towards Steganography theory and practice.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {422–425},
numpages = {4},
keywords = {ChatGPT, Social Media Learning, Independent Thinking Ability, Learning Effectiveness, Project-based Learning, Steganography, Information Security Theory and Practice},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3705754.3705758,
author = {Zhang, Wentao},
title = {Empowering Multimodal Large Language Models for Solving Cognitive Puzzles},
year = {2025},
isbn = {9798400710193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3705754.3705758},
doi = {10.1145/3705754.3705758},
abstract = {Multimodal Large Language Models have been showing their powerful ability for solving general vision-language tasks, such as image captioning, vision question answering, which usually on par with or even better than human does. However, when it comes to cognitive puzzles, we find it struggling for multimodal large language models to solve this type of tasks. In this paper, we study the capacity of MLLMs for solving cognitive puzzles. We experiments with cutting-edge open-sourced MLLMs such as Qwen2-VL and LLaMA 3.2 and compare their ability in solving cognitive puzzles at different aspects. After recognizing the shortcomings with careful examination, we develop a multi-step chain-of-thought based solution to enhance the MLLM to reasoning on the sophisticated image. To verify generalization, we include several sources of cognitive puzzles such as Raven’s Progressive Puzzles and CVR.},
booktitle = {Proceedings of the 2024 2nd International Conference on Electronics, Computers and Communication Technology},
pages = {22–25},
numpages = {4},
keywords = {Neural networks, MultiModal Large Language Models, Cognitive Puzzles},
location = {
},
series = {CECCT '24}
}

@inproceedings{10.1145/3706599.3720081,
author = {Patton, Evan W and Kim, David Y and Granquist, Ashley M and Liu, Robin and Scott, Arianna and Zamanova, Jennet and Abelson, Harold},
title = {Aptly: Making Mobile Apps from Natural Language},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720081},
doi = {10.1145/3706599.3720081},
abstract = {This paper introduces Aptly, a platform designed to democratize mobile app development, particularly for young learners. Aptly integrates a Large Language Model (LLM) with App Inventor, enabling users to create apps using their natural language. User’s description is translated into a programming language that corresponds with App Inventor’s visual blocks. A preliminary study with high school students demonstrated the usability and potential of the platform. Prior programming experience influenced how users interact with Aptly. Participants identified areas for improvement and expressed a shift in perspective regarding programming accessibility and AI’s role in creative endeavors.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {73},
numpages = {6},
keywords = {Computational Action, Large Language Model, Block Programming, Mobile Application},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706468.3706533,
author = {Ortega-Arranz, Alejandro and Topali, Paraskevi and Molenaar, Inge},
title = {Configuring and Monitoring Students' Interactions with Generative AI Tools: Supporting Teacher Autonomy},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706533},
doi = {10.1145/3706468.3706533},
abstract = {The widespread use of Generative Artificial Intelligence (GenAI) tools, such as ChatGPT, has come along with multiple benefits in education (e.g., 24h teacher, augmenting student monitoring). However, at the same time, these tools hinder teachers’ autonomy, limiting the capacity and freedom to exert control over students’ actions and their learning process. Additionally, the generic character of the GenAI output usually lacks contextualization (e.g., course curriculum, students’ age), thus hampering the successful attainment of the course goals. To address these issues, this paper proposes the development of a system mediating between the GenAI interfaces and their back-ends. This system allows teachers to monitor the students’ interactions and align the given answers with the course learning objectives and teaching methods. This research follows the Systems Development Research methodology, and within the first iteration, we developed a system prototype that was evaluated with 8 secondary-school teachers. Results showed a high perceived usefulness of the system for monitoring students’ interactions; for alerting the teachers to take specific actions (e.g., suspicious copy-paste behaviours), and for having control over the GenAI outputs. Additionally, while most teachers perceived a higher autonomy level within the given scenarios, some teachers did not. The evaluation also served to collect further requirements and usability features to keep improving the tool in the next methodological iterations.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {895–902},
numpages = {8},
keywords = {Generative AI, Learning Analytics, GenAI Analytics, Human-Centred Design, Teachers},
location = {
},
series = {LAK '25}
}

@inproceedings{10.5555/3721488.3721651,
author = {Ashok, Ashita and Bruno, Barbara and Helf, Tamara and Berns, Karsten},
title = {"Thanks for the Practice!": LLM-Powered Social Robot as Tandem Language Partner at University},
year = {2025},
publisher = {IEEE Press},
abstract = {Large language models (LLMs), when integrated into social robots, have the potential to transform robot-assisted language learning by offering personalized, interactive communication. However, there is limited research exploring their potential to simultaneously reduce anxiety and enhance language-speaking skills among international university students, who often feel anxious when speaking a foreign language. This study addresses this gap by evaluating the impact of a humanoid robot powered by the OpenChat-3.5 LLM as a tandem partner for German language learning. Using a between-subjects design with 22 multilingual participants, two interaction conditions were tested: immersive (German-only) and bilingual (German-English). Our findings indicate that participants in the immersive mode reported experiencing significantly reduced perceived judgment by the robot compared to the bilingual mode. Although female participants showed a trend of greater improvement in learning gain, no significant gender differences were found. Open-ended feedback highlighted the need for enhanced contextual responses, slower speech rate, faster response times, and error corrections to enhance language speaking support. This study aims to advance social robots for learning by demonstrating the usage of generative AI in creating non-judgmental language practice scenarios.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1221–1226},
numpages = {6},
keywords = {human-robot interaction, robot-assisted language learning, social robots},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3706598.3713460,
author = {Do, Tiffany D. and Shafqat, Usama Bin and Ling, Elsie and Sarda, Nikhil},
title = {PAIGE: Examining Learning Outcomes and Experiences with Personalized AI-Generated Educational Podcasts},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713460},
doi = {10.1145/3706598.3713460},
abstract = {Generative AI is revolutionizing content creation and has the potential to enable real-time, personalized educational experiences. We investigated the effectiveness of converting textbook chapters into AI-generated podcasts and explored the impact of personalizing these podcasts for individual learner profiles. We conducted a 3x3 user study with 180 college students in the United States, comparing traditional textbook reading with both generalized and personalized AI-generated podcasts across three textbook subjects. The personalized podcasts were tailored to students’ majors, interests, and self-described instructional preferences. Our findings show that students found the AI-generated podcast format to be more enjoyable than textbooks and that personalized podcasts led to significantly improved learning outcomes, although this was subject-specific. These results highlight that AI-generated podcasts can offer an engaging and effective modality transformation of textbook material, with personalization enhancing content relevance. We conclude with design recommendations for leveraging AI in education, informed by student feedback.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {896},
numpages = {12},
keywords = {artificial intelligence in education, personalized learning, large language models, content transformation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641554.3701942,
author = {Liu, Zifeng and Jiao, Xinyue and Xing, Wanli and Zhu, Wangda},
title = {Detecting AI-Generated Pseudocode in High School Online Programming Courses Using an Explainable Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701942},
doi = {10.1145/3641554.3701942},
abstract = {Despite extensive research on code plagiarism detection in higher education and for programming languages like Java and Python, limited work has focused on K-12 settings, particularly for pseudocode. This study aims to address this gap by building explainable machine learning models for pseudocode plagiarism detection in online programming education. To achieve this, we construct a comprehensive dataset comprising 7,838 pseudocode submissions from 2,578 high school students enrolled in an online programming foundations course, along with 6,300 pseudocode samples generated by three versions of generative pre-trained transformer (GPT) models. Utilizing this dataset, we develop an explainable model to detect AI-generated pseudocode across various assessments. The model not only identifies AI-generated content but also provides insights into its predictions at both the student and problem levels, thus enhancing our understanding of AI-generated pseudocode in K-12 education. Furthermore, we analyzed SHAP values and key features of the model to pinpoint student submissions that closely resemble AI-generated pseudocode. This research offers implications for developing robust educational technologies and methodologies to uphold academic integrity in online programming courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {701–707},
numpages = {7},
keywords = {ai-generated content, explainable ai, gpt model, online programming education, plagiarism detection, pseudocode},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3696410.3714768,
author = {Liu, Ben and Zhang, Jihai and Lin, Fangquan and Yang, Cheng and Peng, Min and Yin, Wotao},
title = {SymAgent: A Neural-Symbolic Self-Learning Agent Framework for Complex Reasoning over Knowledge Graphs},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714768},
doi = {10.1145/3696410.3714768},
abstract = {Recent advancements have highlighted that Large Language Models (LLMs) are prone to hallucinations when solving complex reasoning problems, leading to erroneous results. To tackle this issue, researchers incorporate Knowledge Graphs (KGs) to improve the reasoning ability of LLMs. However, existing methods face two limitations: 1) they typically assume that all answers to the questions are contained in KGs, neglecting the incompleteness issue of KGs, and 2) they treat the KG as a static repository and overlook the implicit logical reasoning structures inherent in KGs. In this paper, we introduce SymAgent, an innovative neural-symbolic agent framework that achieves collaborative augmentation between KGs and LLMs. We conceptualize KGs as dynamic environments and transform complex reasoning tasks into a multi-step interactive process, enabling KGs to participate deeply in the reasoning process. SymAgent consists of two modules: Agent-Planner and Agent-Executor. The Agent-Planner leverages LLM's inductive reasoning capability to extract symbolic rules from KGs, guiding efficient question decomposition. The Agent-Executor autonomously invokes predefined action tools to integrate information from KGs and external documents, addressing the issues of KG incompleteness. Furthermore, we design a self-learning framework comprising online exploration and offline iterative policy updating phases, enabling the agent to automatically synthesize reasoning trajectories and improve performance. Experimental results demonstrate that SymAgent with weak LLM backbones (i.e., 7B series) yields better or comparable performance compared to various strong baselines. Further analysis reveals that our agent can identify missing triples, facilitating automatic KG updates.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {98–108},
numpages = {11},
keywords = {knowledge graph, large language model agent, self-learning},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3696410.3714858,
author = {Zhu, Lixi and Huang, Xiaowen and Sang, Jitao},
title = {A LLM-based Controllable, Scalable, Human-Involved User Simulator Framework for Conversational Recommender Systems},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714858},
doi = {10.1145/3696410.3714858},
abstract = {Conversational Recommender System (CRS) leverages real-time feedback from users to dynamically model their preferences, thereby enhancing the system's ability to provide personalized recommendations and improving the overall user experience. CRS has demonstrated significant promise, prompting researchers to concentrate their efforts on developing user simulators that are both more realistic and trustworthy. The advent of Large Language Models (LLMs) has demonstrated capabilities that approach human-level intelligence across a diverse range of tasks. Research efforts have been made to utilize LLMs for building user simulators to evaluate the performance of CRS. Although these efforts showcase innovation, they are accompanied by certain limitations. In this work, we introduce a Controllable, Scalable, and Human-Involved (CSHI) simulator framework that manages the behavior of user simulators across various stages via a plugin manager. CSHI tailors behavioral simulations and interaction patterns to deliver authentic user-system engagement experiences. Through experiments and case studies in two conversational recommendation scenarios, we show that our framework can adapt to a variety of conversational recommendation settings and effectively simulate users' personalized preferences. Consequently, our simulator is able to generate feedback that closely mirrors that of real users. This facilitates a reliable assessment of existing CRS studies and promotes the creation of high-quality conversational recommendation datasets.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {4653–4661},
numpages = {9},
keywords = {conversational recommender systems, large language models, user simulator},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3708557.3716146,
author = {Szymanski, Annalisa},
title = {Evaluation Workflows for Large Language Models (LLMs) that Integrate Domain Expertise for Complex Knowledge Tasks},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716146},
doi = {10.1145/3708557.3716146},
abstract = {The growing use of Large Language Models (LLMs) in specialized fields such as healthcare, nutrition, and education has raised critical concerns regarding the accuracy, reliability, and contextual appropriateness of LLM outputs. However, evaluating LLMs is challenging due to the complexity of the information and the need for human input, which is often costly and resource-intensive. My dissertation addresses the challenges in integrating domain expertise into the evaluation of LLM outputs for complex knowledge tasks to build more efficient evaluation workflows. The main objectives of this research are: 1) to investigate when and at what stage domain expertise should be integrated into LLM evaluation 2) to explore the role of domain experts compared to other evaluators such as lay users and LLMs themselves in the evaluation process, and 3) to design evaluation frameworks and tools that guide both the optimal integration of domain experts and leverage the complementary strengths of other evaluation groups. The expected impact of this research includes advancing the design of LLM evaluation tools and workflows that assist developers in identifying where expertise is needed to effectively develop and deploy LLMs in real-world applications.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {215–217},
numpages = {3},
keywords = {Large Language Models, Evaluation Methods, LLM-as-a-Judge, Human-AI Interaction},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3706598.3713275,
author = {Chen, Jiaju and Tang, Minglong and Lu, Yuxuan and Yao, Bingsheng and Fan, Elissa and Ma, Xiaojuan and Xu, Ying and Wang, Dakuo and Sun, Yuling and He, Liang},
title = {Characterizing LLM-Empowered Personalized Story Reading and Interaction for Children: Insights From Multi-Stakeholder Perspectives},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713275},
doi = {10.1145/3706598.3713275},
abstract = {Personalized interaction is highly valued by parents in their story-reading activities with children. While AI-empowered story-reading tools have been increasingly used, their abilities to support personalized interaction with children are still limited. Recent advances in large language models (LLMs) show promise in facilitating personalized interactions, but little is known about how to effectively and appropriately use LLMs to enhance children’s personalized story-reading experiences. This work explores this question through a design-based study. Drawing on a formative study, we designed and developed StoryMate, an LLM-empowered personalized interactive story-reading tool for children, following an empirical study with children, parents, and education experts. Our participants valued the personalized features in StoryMate, and also highlighted the need to support personalized content, guiding mechanisms, reading context variations, and interactive interfaces. Based on these findings, we propose a series of design recommendations for better using LLMs to empower children’s personalized story reading and interaction.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1002},
numpages = {24},
keywords = {Children, AI, Large Language Model, Story-Reading, Interaction, Personalization, Guided Conversation, Design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713971,
author = {Ravi, Prerna and Masla, John and Kakoti, Gisella and Lin, Grace C. and Anderson, Emma and Taylor, Matt and Ostrowski, Anastasia K. and Breazeal, Cynthia and Klopfer, Eric and Abelson, Hal},
title = {Co-designing Large Language Model Tools for Project-Based Learning with K12 Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713971},
doi = {10.1145/3706598.3713971},
abstract = {The emergence of generative AI, particularly large language models (LLMs), has opened the door for student-centered and active learning methods like project-based learning (PBL). However, PBL poses practical implementation challenges for educators around project design and management, assessment, and balancing student guidance with student autonomy. The following research documents a co-design process with interdisciplinary K-12 teachers to explore and address the current PBL challenges they face. Through teacher-driven interviews, collaborative workshops, and iterative design of wireframes, we gathered evidence for ways LLMs can support teachers in implementing high-quality PBL pedagogy by automating routine tasks and enhancing personalized learning. Teachers in the study advocated for supporting their professional growth and augmenting their current roles without replacing them. They also identified affordances and challenges around classroom integration, including resource requirements and constraints, ethical concerns, and potential immediate and long-term impacts. Drawing on these, we propose design guidelines for future deployment of LLM tools in PBL.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {138},
numpages = {25},
keywords = {Generative AI, LLMs, AI for education, project-based learning, co-design, teachers, interviews},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3701716.3717527,
author = {Liu, Ben and Zhang, Jihai and Lin, Fangquan and Jia, Xu and Peng, Min},
title = {One Size doesn't Fit All: A Personalized Conversational Tutoring Agent for Mathematics Instruction},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717527},
doi = {10.1145/3701716.3717527},
abstract = {Large language models (LLMs) have been increasingly employed in various intelligent educational systems, simulating human tutors to facilitate effective human-machine interaction. However, previous studies often overlook the significance of recognizing and adapting to individual learner characteristics. Such adaptation is crucial for enhancing student engagement and learning efficiency, particularly in mathematics instruction, where diverse learning styles require personalized strategies to promote comprehension and enthusiasm. In this paper, we propose a PersonAlized Conversational tutoring agEnt (PACE) for mathematics instruction. PACE simulates students' learning styles based on the Felder and Silverman learning style model, aligning with each student's persona. In this way, our PACE can effectively assess the personality of students, allowing to develop individualized teaching strategies that resonate with their unique learning styles. To further enhance students' comprehension, PACE employs the Socratic teaching method to provide instant feedback and encourage deep thinking. By constructing personalized teaching data and training models, PACE demonstrates the ability to identify and adapt to the unique needs of each student, significantly improving the overall learning experience and outcomes. Moreover, we establish multi-aspect evaluation criteria and conduct extensive analysis to assess the performance of personalized teaching. Experimental results demonstrate the superiority of our model in personalizing the educational experience and motivating students compared to existing methods.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2401–2410},
numpages = {10},
keywords = {large language model agent, learning-style, personalized teaching},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@article{10.1145/3731445,
author = {Zhang, Haopeng and Yu, Philip S. and Zhang, Jiawei},
title = {A Systematic Survey of Text Summarization: From Statistical Methods to Large Language Models},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {0360-0300},
url = {https://doi.org/10.1145/3731445},
doi = {10.1145/3731445},
abstract = {Text summarization research has undergone several significant transformations with the advent of deep neural networks, pre-trained language models (PLMs), and recent large language models (LLMs). This survey thus provides a comprehensive review of the research progress and evolution in text summarization through the lens of these paradigm shifts. It is organized into two main parts: (1) a detailed overview of datasets, evaluation metrics, and summarization methods before the LLM era, encompassing traditional statistical methods, deep learning approaches, and PLM fine-tuning techniques, and (2) the first detailed examination of recent advancements in benchmarking, modeling, and evaluating summarization in the LLM era. By synthesizing existing literature and presenting a cohesive overview, this survey also discusses research trends, open challenges, and proposes promising research directions in summarization, aiming to guide researchers through the evolving landscape of summarization research.},
note = {Just Accepted},
journal = {ACM Comput. Surv.},
month = apr,
keywords = {Summarization, large language model, deep learning, dataset}
}

@inproceedings{10.1145/3641555.3705144,
author = {Gupta, Ishita and Bridgman, Maya and Wang, Sierra and Mitchell, John},
title = {Coding Pathfinder: A Platform for Creative, Self-Guided Mastery in Programming},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705144},
doi = {10.1145/3641555.3705144},
abstract = {We present Coding Pathfinder, a platform to help non-programmers learn to code for a specific purpose. This paper explores how we can scaffold generative AI to provide structure and ensure mastery in informal learning settings, introducing a new approach to coding education. In the current iteration of Pathfinder, a user describes the coding task that they are working on. After collecting some details and scoping the project, Pathfinder identifies the skills that the user will master upon successful completion of the project. It then assesses which of the skills our users already has, and designs a personalised learning journey. The guided journey consists of instructions, explanations, tasks and videos. We also incorporate a chat feature so users can ask questions and engage as if they are working with a tutor.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1465–1466},
numpages = {2},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3714054,
author = {Jin, Hyoungwook and Yoo, Minju and Park, Jeongeon and Lee, Yokyung and Wang, Xu and Kim, Juho},
title = {TeachTune: Reviewing Pedagogical Agents Against Diverse Student Profiles with Simulated Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714054},
doi = {10.1145/3706598.3714054},
abstract = {Large language models (LLMs) can empower teachers to build pedagogical conversational agents (PCAs) customized for their students. As students have different prior knowledge and motivation levels, teachers must review the adaptivity of their PCAs to diverse students. Existing chatbot reviewing methods (e.g., direct chat and benchmarks) are either manually intensive for multiple iterations or limited to testing only single-turn interactions. We present TeachTune, where teachers can create simulated students and review PCAs by observing automated chats between PCAs and simulated students. Our technical pipeline instructs an LLM-based student to simulate prescribed knowledge levels and traits, helping teachers explore diverse conversation patterns. Our pipeline could produce simulated students whose behaviors correlate highly to their input knowledge and motivation levels within 5% and 10% accuracy gaps. Thirty science teachers designed PCAs in a between-subjects study, and using TeachTune resulted in a lower task load and higher student profile coverage over a baseline.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1073},
numpages = {28},
keywords = {LLM-assisted evaluation, Simulated students, Pedagogical conversational agents},
location = {
},
series = {CHI '25}
}

@article{10.1145/3727877,
author = {Pu, Calton and Kim, Mirae and Derrick-Mills, Teresa and Faulk, Lewis},
title = {Challenges and Experiences in Data Integration to Support Research on Nonprofit Organizations},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1533-5399},
url = {https://doi.org/10.1145/3727877},
doi = {10.1145/3727877},
abstract = {Nonprofit organizations are important contributors to the US economy and social well-being. The Nonprofit Organization Research Panel Project (NORPP) Manager has been developing and sharing datasets and software tools to facilitate data-driven research on nonprofit organizations. The project has two major thrusts: (1) large-scale survey panels, e.g., the Annual National Survey of Nonprofit Trends and Impacts, from 2021 to the current (2024); and (2) NORPP Analytics Integration Platform (NAIP) to collect, process, and query a wide range of socioeconomic indicator datasets, such as IRS 990 form and census data. Technical challenges that include data heterogeneity, data quality, and protection of sensitive data have made the expansion and maintenance of NAIP datasets both labor-intensive and time-consuming. We are currently exploring new technologies, including Large Language Models such as GPT series, to automate database query generation, schema adaptation, and data quality assurance processes.},
note = {Just Accepted},
journal = {ACM Trans. Internet Technol.},
month = may,
keywords = {Nonprofit organization research}
}

@inproceedings{10.1145/3729605.3729648,
author = {Jiang, Mi and Gao, Junran and Pan, Zeyu and Wu, Yue and Wang, Zile},
title = {NexaNota: An AI-Powered Smart Linked Lecture Note-Taking System Leveraging Large Language Models},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729648},
doi = {10.1145/3729605.3729648},
abstract = {Taking lecture note is an essential pedagogical method for aiding memory and understanding. Compared to unstructured lecture notes, well-structured lecture notes are highly beneficial that students would read frequently for reviewing and organizing their idea. However, it can be challenging to effectively take notes while listen to the lecturer simultaneously in a lecture, not to mention recall the whole lecture content after class. Particularly when the lecture content involves complex topics and intricates connections between topics, students feel vulnerable to review the lecture. To solve these difficulties, we design and propose an automated note-taking system, NexaNota. The system leverages the advanced Large Language Model (LLMs) to generate smart linked and structured lecture notes by constructing topics network through knowledge graphs, and providing additional web resources to complement each topic. In a within-subjects study with 17 participants (12 students and 5 experts), we found that NexaNota generates highly organized notes with 97.7% accuracy in topic identification and 86.7% accuracy in the connections between topics. Our results suggest that NexaNota enhances student learning efficiency by providing smart-linked, high-quality lecture notes.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {242–248},
numpages = {7},
keywords = {AI Powered Learning, Large Language Models, Linked Note, NexaNota, Note-Taking Assistant},
location = {
},
series = {ICBDIE '25}
}

@inproceedings{10.1145/3641555.3704754,
author = {Bhattacharya, Sambit and Uma, Ravanasamudram and Deb, Debzani},
title = {Integrating Data Science for Social Justice: A Tutorial on Developing Non-Traditional Pathways for Non-CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704754},
doi = {10.1145/3641555.3704754},
abstract = {In response to the growing need for socially responsible computer scientists and data scientists, our team is developing a comprehensive data science certificate program specifically tailored for non-computing majors, with a focus on data science for social justice. This program aims to broaden participation in data science and create non-traditional pathways for diverse student populations. Each course in the program is designed to be accessible to non-computing majors, equipping them with the skills to analyze and address social justice issues through data science. Process Oriented Guided Inquiry Learning (POGIL) is employed as an instructional strategy promoting active learning, and real datasets related to social justice are utilized for hands-on activities and assignments, enhancing practical learning experiences. The courses are taught in a synchronous hybrid format, across multiple universities, accommodating both live online and in-person students.This tutorial will equip educators with the tools to incorporate data science for social justice in their courses. Attendees will have access to materials developed for these courses, enabling them to integrate similar content into their own curricula. A key focus is on recent challenges and opportunities created by generative AI. The presenters will share their experiences, course materials, and strategies for introducing computer science through a social justice lens. Participants will share ideas and strategies, which will be collated and made available in a shared repository. This initiative aims to enable educators to train future generations in data science while addressing social justice issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {certificate program, data science, non-computing majors, social justice},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713714,
author = {Prabhudesai, Snehal and Kasi, Ananya Prashant and Mansingh, Anmol and Das Antar, Anindya and Shen, Hua and Banovic, Nikola},
title = {"Here the GPT made a choice, and every choice can be biased": How Students Critically Engage with LLMs through End-User Auditing Activity},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713714},
doi = {10.1145/3706598.3713714},
abstract = {Despite recognizing that Large Language Models (LLMs) can generate inaccurate or unacceptable responses, universities are increasingly making such models available to their students. Existing university policies defer the responsibility of checking for correctness and appropriateness of LLM responses to students and assume that they will have the required knowledge and skills to do so on their own. In this work, we conducted a series of user studies with students (N=47) from a large North American public research university to understand if and how they critically engage with LLMs. Our participants evaluated an LLM provided by the university in a quasi-experimental setup; first by themselves, and then with a scaffolded design probe that guided them through an end-user auditing exercise. Qualitative analysis of participant think-aloud and LLM interaction data showed that students without basic AI literacy skills struggle to conceptualize and evaluate LLM biases on their own. However, they transition to focused thinking and purposeful interactions when provided with structured guidance. We highlight areas where current university policies may fall short and offer policy and design recommendations to better support students.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1015},
numpages = {23},
keywords = {End-user Audit, End-user Algorithmic Audit, User-Driven Algorithm Auditing, Algorithmic Audit, Auditing Algorithms, Algorithmic Bias, Algorithmic Harm, Large Language Models, LLMs, AI Literacy, AI Education, Responsible AI.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708036.3708256,
author = {Chen, Yinhong and Chen, Yuefeng},
title = {Visual analytics of the current status and trends in artificial intelligence education based on big data},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708256},
doi = {10.1145/3708036.3708256},
abstract = {More researchers are starting to focus on the intersection of artificial intelligence and education as a result of the technology's ongoing advancements. The paper conducts a thorough analysis of the research hotspots, and development lineage in international artificial intelligence education over the last ten years using the visualization analytic tools VOSviewer and CiteSpace. The following findings are obtained from the analysis of keyword co-occurrence and clusters: the flipped classroom, dropout prediction, and large language models are the main subjects of international research on artificial intelligence; the practical application of artificial intelligence in education, ethical and moral challenges, and the realization of the successful integration of intelligent technology and ideological and political education are the main research trends of future.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {1322–1326},
numpages = {5},
keywords = {artificial intelligence, bibliometrics, education, visual analytics},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3641555.3705175,
author = {Bouamor, Houda and Gongora-Svartzman, Gabriela and Heimann, Larry and Huang, Shihong},
title = {Evaluating GenAI's Effectiveness for Students with Varied Programming Backgrounds in a Software Development Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705175},
doi = {10.1145/3641555.3705175},
abstract = {Using Generative AI (GenAI) tools in education presents both opportunities and challenges to the traditional teaching methods and students' learning experience and outcomes, particularly in technical and programming courses. This experience report evaluates the impact of GenAI tools, specifically ChatGPT and GitHub CoPilot, in leveling the playing field for Information Systems students with varying technical backgrounds in an application design and development course. By integrating these tools into course labs and projects, this study aimed to determine whether they improve the success rates of less technically prepared and struggling students. Data were collected from five sessions of a semester-long course across two campuses, involving 162 students with five parallel sessions across two continents. The analysis of student performance metrics and surveys revealed that GenAI tools significantly helped students complete programming tasks. However, those who were less technically prepared and relied heavily on AI assistance struggled with more complex, transformative tasks, such as closed-book exams. These findings suggest that while GenAI tools can help close gaps in temporary programming skills, they are less effective - and may even exacerbate disparities - in fostering long-term deeper learning and developing transformative knowledge and critical thinking.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1395–1396},
numpages = {2},
keywords = {generative AI, impact of Genai tools in education, information systems education (IS), leveling playfield, programming background, student performance evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3729219,
author = {Edemacu, Kennedy and Wu, Xintao},
title = {Privacy Preserving Prompt Engineering: A Survey},
year = {2025},
issue_date = {October 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3729219},
doi = {10.1145/3729219},
abstract = {Pre-trained language models (PLMs) have demonstrated significant proficiency in solving a wide range of general natural language processing (NLP) tasks. Researchers have observed a direct correlation between the performance of these models and their sizes. As a result, the sizes of these models have notably expanded in recent years, persuading researchers to adopt the term large language models (LLMs) to characterize the larger-sized PLMs. The size expansion comes with a distinct capability called in-context learning (ICL), which represents a special form of prompting and allows the models to be utilized through the presentation of demonstration examples without modifications to the model parameters. Although interesting, privacy concerns have become a major obstacle in its widespread usage. Multiple studies have examined the privacy risks linked to ICL and prompting in general, and have devised techniques to alleviate these risks. Thus, there is a necessity to organize these mitigation techniques for the benefit of the community. In this survey, we provide a systematic overview of the privacy protection methods employed during ICL and prompting in general. We review, analyze, and compare different methods under this paradigm. Furthermore, we provide a summary of the resources accessible for the development of these frameworks. Finally, we discuss the limitations of these frameworks and offer a detailed examination of the promising areas that necessitate further exploration.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {255},
numpages = {36},
keywords = {Pre-trained language models, large language models, prompting, in-context learning}
}

@inbook{10.1145/3724504.3724635,
author = {He, Hao and Gao, Chaobang},
title = {Research on the Application of Artificial Intelligence in Basic Education: A Global Trend Analysis Based on Bibliometrics},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724635},
abstract = {Based on the bibliometric method, this study visually analyzed the application research literature of artificial intelligence (AI) in the domain of basic education in the Web of Science Core Collection from January 1, 2014 to November 1, 2024 with the help of VOSviewer and CiteSpace. A total of 344 valid articles were selected from 588 institutions and 1090 authors in 60 countries. They were published in 126 journals and cited 13855 references from 6922 journals. The study found that the number of papers published in China is the largest, and the quality recognition of papers in the United States is high. The journals with the greatest number of articles were mostly related to educational technology and computational intelligence, and Computers &amp; Education had the greatest number of citations per article. Keyword co-occurrence analysis shows that the study focuses on deep learning and the application of large language models (LLMs) has increased. The timeline analysis shows that the domain research has moved from the stage of data driven and educational technology application exploration to the stage of AI empowerment and personalized education. The co-citation analysis reveals that the interdisciplinary characteristics of educational technology research are obvious, and the literature co-citation network reflects the multi-dimensional application research type of AI in basic education. All in all, the popularity of AI application research in basic education is increasing, the research focus has changed, and generative AI is developing rapidly.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {799–806},
numpages = {8}
}

@inproceedings{10.1145/3722237.3722268,
author = {Dai, Ling and Jiang, Yuan-Hao and Chen, Yuanyuan and Guo, Zinuo and Liu, Tian-Yi and Shao, Xiaobao},
title = {Agent4EDU: Advancing AI for Education with Agentic Workflows},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722268},
doi = {10.1145/3722237.3722268},
abstract = {The vigorous development of artificial intelligence (AI) represented by large language models (LLMs) has rapidly promoted the updating and development of educational technology. Agentic workflows (AWs) built based on LLMs can realize complex tasks in the field of education, which allows the emergence of swarm intelligence (SI) through multi-agent collaboration[1]. This study introduces the Agent4EDU (agent for education) framework, which outlines 4 application models in education from the two dimensions of degree of agency and degree of interaction, including human-AI collaboration, AI assistant, instruction execution, and general type. The proposed Agent4EDU framework discusses the paradigm of educational applications of AI agents and promotes the development of the field of AI for education.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {180–185},
numpages = {6},
keywords = {AI agent, AI for education, agentic workflow, large language model, multi-agent system},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3706598.3714146,
author = {Prasad, Prajish and Balse, Rishabh and Balchandani, Dhwani},
title = {Exploring Multimodal Generative AI for Education through Co-design Workshops with Students},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714146},
doi = {10.1145/3706598.3714146},
abstract = {Multimodal large language models (MLLMs) are Generative AI models that take different modalities such as text, audio, and video as input and generate appropriate multimodal output. Since such models will be integrated into future educational tools, a human-centered design approach that takes students’ perspectives into account is essential while designing such applications.This paper describes two co-design workshops which were conducted with 79 student groups to examine how they design and prototype future educational tools integrated with MLLMs. Through various activities in the workshops, students discussed relevant educational problems, created journey maps, storyboards and low fidelity prototypes for their applications, and evaluated their applications based on relevant design principles. We found that students’ applications used MLLMs for important learning environment design features such as multimodal content creation, personalization, and feedback. Based on these findings, we discuss future research directions for the design of multimodality in generative AI educational applications.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {139},
numpages = {17},
keywords = {artificial intelligence, generative AI, large language models, multimodality, co-design, design principles, learning environment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3722237.3722245,
author = {Fan, Sun and Peng, Lu and Wu, Shaofeng and Yu, Xingmu},
title = {ChatGPT Empowers Higher Education: —Research Topics Hotspots and Quantitative Visual Analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722245},
doi = {10.1145/3722237.3722245},
abstract = {In order to deeply explore the current research hotspots and development trends of ChatGPT generative artificial intelligence in empowering higher education applications, this study conducted a detailed analysis of 178 articles related to ChatGPT+higher education in the knowledge Resource Database. By using software tools such as Power BI, SPSS, and Excel, this study conducted a visual analysis of core authors, research funding, research topics, author institutions, discipline areas, and related indicators in the literature. The aim of the study is to analyze the current status of ChatGPT research in higher education applications and to explore the hot issues surrounding ChatGPT empowerment in higher education.The study points out that current research in higher education in the era of artificial intelligence mainly focuses on introducing ChatGPT, the characteristics and connotations of large language models, and discussing the opportunities, challenges, coping strategies, and digital transformation research they bring. However, there is still a lack of in-depth exploration of the application of ChatGPT and other technologies in education, especially in areas such as personalized learning and precision teaching, the integration of virtual and actual teaching spaces, intelligent teaching facilities and resources, human-computer collaborative teaching methods, and interdisciplinary innovative research methods.We should actively respond to the opportunities and challenges brought by intelligent tools such as ChatGPT to higher education, and comprehensively and deeply explore how to integrate ChatGPT into key areas of digital education, including teaching design, teaching resource development, teaching organization and implementation, teaching evaluation and reflection, learning and personal knowledge management, innovation team building, and enhancing the digital literacy and professional capabilities of teachers and students. In addition, the impact of the application of ChatGPT and other technologies in education on educational equity, and how to ensure that all students can benefit from it through reasonable design and use, should also be of concern. The goal of this study is to further promote and drive the digital transformation of higher education by building a brand new higher education ecosystem based on ChatGPT.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {38–45},
numpages = {8},
keywords = {ChatGPT, Digital transformation, Empowers, higher education, hot topics, human-machine collaborative intelligence, trends, visualization},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3723178.3723268,
author = {Sadat Shanto, Shakib and Ahmed, Zishan and Jony, Akinul Islam},
title = {Generative AI for Programming Education: Can ChatGPT Facilitate the Acquisition of Fundamental Programming Skills for Novices?},
year = {2025},
isbn = {9798400713828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723178.3723268},
doi = {10.1145/3723178.3723268},
abstract = {Modern Generative AI (GAI) systems like ChatGPT have sparked much interest in their potential to revolutionize programming education, especially for beginners. However, the existing empirical data regarding the effectiveness of technologies like ChatGPT as autonomous programming tutors is presently limited. The present study investigates the capacity of ChatGPT to facilitate the acquisition of fundamental programming skills for novice programmers without human assistance. This study puts forth a conceptual framework (APEC - Adaptive Programming Education via ChatGPT) that integrates both bottom-up and top-down approaches, incorporating ChatGPT as the principal instructor for the study of programming. An empirical study was undertaken to assess the usefulness of ChatGPT as a tool for teaching novice programmers a new programming language. This empirical study was conducted on 20 undergraduate students. To provide an expert assessment of the quality of the responses, a survey was conducted with three programming experts proficient in Python. The survey findings indicate that ChatGPT is proficient in explaining core principles such as variables, data types, and control statements through conversational exchanges, adopting an intelligent and logical methodology. Nevertheless, certain constraints arise when dealing with increasingly complex topics.},
booktitle = {Proceedings of the 3rd International Conference on Computing Advancements},
pages = {685–692},
numpages = {8},
keywords = {Generative AI, ChatGPT, Programming Education, Educational Technology, Higher Education},
location = {
},
series = {ICCA '24}
}

@inproceedings{10.1145/3704137.3704182,
author = {M\o{}ller, Cecilie Grace and Ang, Ke En and de Lourdes Bongiovanni, Mar\'{\i}a and Khalid, Md Saifuddin and Wu, Jiayan},
title = {Metrics of Success: Evaluating User Satisfaction in AI Chatbots},
year = {2025},
isbn = {9798400718014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704137.3704182},
doi = {10.1145/3704137.3704182},
abstract = {The rapid advancement of Artificial Intelligence (AI), particularly through Large Language Models (LLMs), has catalysed a technological revolution, leading to the widespread adoption of AI-driven chatbots across industries. OpenAI’s customisable generative pre-trained transformer (GPT) offerings have popularised generative AI, enabling organisations of all sizes to implement chatbots for customer support. This development presents an opportunity for businesses to offer 24/7, cost-efficient customer service that can overcome the historical limitations of chatbots that lack a "human element." However, despite the proliferation of AI chatbots, there remains a crucial need to evaluate their effectiveness in meeting user needs and preferences for human-like interaction. Current service quality assessment tools, such as SERVQUAL and E-SERVQUAL, are unable to evaluate AI-specific capabilities like language intelligence and recognition. Existing research also lacks information on factors that affect user satisfaction and the continued use of AI chatbots. Based on a mixed-methods study, this paper proposes a new instrument for measuring user satisfaction with AI chatbots, specifically for customer support roles. Using the Stanford five-step Design Thinking Process, this study devised a customer support AI chatbot evaluation instrument through a literature review, Cheatstorming, and SCAMPER techniques, followed by testing in a Danish company. The research employs Prentice and Nguyen’s three-stage scale development process to ensure content, reliability, and construct validity, addressing gaps in current scholarship and advancing understanding of AI chatbot user satisfaction.},
booktitle = {Proceedings of the 2024 8th International Conference on Advances in Artificial Intelligence},
pages = {168–173},
numpages = {6},
keywords = {artificial intelligence, chatbots, user satisfaction, scale development, AI chatbot evaluation},
location = {
},
series = {ICAAI '24}
}

@inproceedings{10.1145/3716895.3716958,
author = {Xiang, Ziyu and Luo, Yinhui and Fu, Qiang and Xu, Wenhao},
title = {Civil Aviation Legal Retrieval and Analysis Based on RAG},
year = {2025},
isbn = {9798400718007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716895.3716958},
doi = {10.1145/3716895.3716958},
abstract = {Efficient research on civil aviation laws using a large language model (LMM) is a hot issue in current research In this paper, we build a RAG-based model of civil aviation laws and regulations by analyzing civil aviation law-related documents. We obtain high-quality civil aviation data on civil aviation laws by combining manual and the LLM approaches, and carefully categorize the samples according to the frequency of changes in the answers to the assessment indicators, in order to observe the capability of the LLM more accurately We also evaluate and analyze mainstream and advanced Chinese LLM on our dataset. Extensive experiments and valuable insights show that the use of RAG for retrieval of civil aviation LLM is challenging and deserves further research!},
booktitle = {Proceedings of the 5th International Conference on Artificial Intelligence and Computer Engineering},
pages = {351–357},
numpages = {7},
keywords = {LLM, LLM valuation, RAG, text chunking, vector search},
location = {
},
series = {ICAICE '24}
}

@article{10.1145/3711000,
author = {Kapania, Shivani and Wang, Ruiyi and Li, Toby Jia-Jun and Li, Tianshi and Shen, Hong},
title = { 'I'm Categorizing LLM as a Productivity Tool': Examining Ethics of LLM Use in HCI Research Practices},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711000},
doi = {10.1145/3711000},
abstract = {Large language models are increasingly applied in real-world scenarios, including research and education. These models, however, come with well-known ethical issues, which may manifest in unexpected ways in human-computer interaction research due to the extensive engagement with human subjects. This paper reports on research practices related to LLM use, drawing on 16 semi-structured interviews and a survey with 50 HCI researchers. We discuss the ways in which LLMs are already being utilized throughout the entire HCI research pipeline, from ideation to system development and paper writing. While researchers described nuanced understandings of ethical issues, they were rarely or only partially able to identify and address those ethical concerns in their own projects. This lack of action and reliance on workarounds was explained through the perceived lack of control and distributed responsibility in the LLM supply chain, the conditional nature of engaging with ethics, and competing priorities. Finally, we reflect on the implications of our findings and present opportunities to shape emerging norms of engaging with large language models in HCI research.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW102},
numpages = {26},
keywords = {hci research, large language models, research ethics, research practices}
}

@inproceedings{10.1145/3641555.3704762,
author = {Birillo, Anastasiia and Keuning, Hieke and Migut, Gosia and Dzialets, Katsiaryna and Golubev, Yaroslav},
title = {Creating in-IDE Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704762},
doi = {10.1145/3641555.3704762},
abstract = {The in-IDE learning format represents a novel way of teaching programming to students entirely within an industry-grade IDE, allowing them to learn both the language and the necessary tooling at the same time. In this tutorial, we will teach the audience everything they need to know to create in-IDE courses and analyze how the students are working in them. In the first part of the tutorial, the audience will get to know the JetBrains Academy plugin that allows creating courses for IntelliJ-based IDEs such as IntelliJ IDEA and PyCharm. The participants will develop their own simple courses with theory, programming tasks, and quizzes, as well as employ some LLM-based features like automatic test generation. In the second part, we will learn how to use another plugin to collect code snapshots and the usage of IDE features of students when they are solving the tasks. Finally, the participants will solve tasks in their own course while using the data gathering plugin, and we will show them how to process and analyze the collected data. As the outcome of the tutorial, the audience will know how to create in-IDE courses, track the students' performance and analyze it, and will already have their own simple course and a dataset that can be expanded or used for further research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {In-IDE learning, JetBrains academy, LLMs, MOOCs, activity tracking, course creation, generative AI, programming education, programming exercises},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3677389.3702578,
author = {Sarker, Shraboni and Hamad, Ahmad Tamim and Alshammari, Hulayyil and Grieco, Viviana and Rao, Praveen},
title = {Seventeenth-Century Spanish American Notary Records for Fine-Tuning Spanish Large Language Models},
year = {2025},
isbn = {9798400710933},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677389.3702578},
abstract = {Large language models (LLMs) have gained tremendous popularity in domains such as ecommerce, finance, healthcare, and education. Fine-tuning is a common approach to customize an LLM on a domain-specific dataset for a desired downstream task. In this paper, we present a valuable dataset for fine-tuning LLMs developed for the Spanish language to perform a variety of tasks such as classification, masked language modeling, clustering, and others. Our dataset is a collection of handwritten notary records from the seventeenth century obtained from the National Archives of Argentina. This collection contains a combination of original images and transcribed text (and metadata) of 160+ pages that were handwritten by two notaries, namely, Estenban Agreda de Vergara and Nicolas de Valdivia y Brisuela nearly 400 years ago. Our transcription is accurate as it was prepared by experts in 17th-century Spanish. Through empirical evaluation, we demonstrate that our dataset can be used to fine-tune Spanish LLMs for tasks such as classification and masked language modeling, and can outperform pretrained Spanish models and ChatGPT-3.5/ChatGPT-4o. Our dataset will be an invaluable resource for historical text analysis in the era of LLMs and is available via GitHub at https://github.com/raopr/SpanishNotaryCollection.},
booktitle = {Proceedings of the 24th ACM/IEEE Joint Conference on Digital Libraries},
articleno = {56},
numpages = {5}
}

@inproceedings{10.1145/3641554.3701823,
author = {Ali, Areej and Collier, Aayushi Hingle and Dewan, Umama and McDonald, Nora and Johri, Aditya},
title = {Analysis of Generative AI Policies in Computing Course Syllabi},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701823},
doi = {10.1145/3641554.3701823},
abstract = {Since the release of ChatGPT in 2022, Generative AI (GenAI) is increasingly being used in higher education computing classrooms across the United States. While scholars have looked at overall institutional guidance for the use of GenAI and reports have documented the response from schools in the form of broad guidance to instructors, we do not know what policies and practices instructors are actually adopting and how they are being communicated to students through course syllabi. To study instructors' policy guidance, we collected 98 computing course syllabi from 54 R1 institutions in the U.S. and studied the GenAI policies they adopted and the surrounding discourse. Our analysis shows that 1) most instructions related to GenAI use were as part of the academic integrity policy for the course and 2) most syllabi prohibited or restricted GenAI use, often warning students about the broader implications of using GenAI, e.g. lack of veracity, privacy risks, and hindering learning. Beyond this, there was wide variation in how instructors approached GenAI including a focus on how to cite GenAI use, conceptualizing GenAI as an assistant, often in an anthropomorphic manner, and mentioning specific GenAI tools for use. We discuss the implications of our findings and conclude with current best practices for instructors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {18–24},
numpages = {7},
keywords = {course syllabi, generative ai, policy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706468.3706487,
author = {Li, Ziqing and Cukurova, Mutlu and Bulathwela, Sahan},
title = {A Novel Approach to Scalable and Automatic Topic-Controlled Question Generation in Education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706487},
doi = {10.1145/3706468.3706487},
abstract = {The development of Automatic Question Generation (QG) models has the potential to significantly improve educational practices by reducing the teacher workload associated with creating educational content. This paper introduces a novel approach to educational question generation that controls the topical focus of questions. The proposed Topic-Controlled Question Generation (T-CQG) method enhances the relevance and effectiveness of the generated content for educational purposes. Our approach uses fine-tuning on a pre-trained T5-small model, employing specially created datasets tailored to educational needs. The research further explores the impacts of pre-training strategies, quantisation, and data augmentation on the model’s performance. We specifically address the challenge of generating semantically aligned questions with paragraph-level contexts, thereby improving the topic specificity of the generated questions. In addition, we introduce and explore novel evaluation methods to assess the topical relatedness of the generated questions. Our results, validated through rigorous offline and human-backed evaluations, demonstrate that the proposed models effectively generate high-quality, topic-focused questions. These models have the potential to reduce teacher workload and support personalised tutoring systems by serving as bespoke question generators. With its relatively small number of parameters, the proposals not only advance the capabilities of question generation models for handling specific educational topics but also offer a scalable solution that reduces infrastructure costs. This scalability makes them feasible for widespread use in education without reliance on proprietary large language models like ChatGPT.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {148–158},
numpages = {11},
keywords = {Educational Question Generation, Formative Assessment, Summative Assessment, Personalised Testing, Natural Language Processing},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3641555.3705037,
author = {Piech, Chris and Sahami, Mehran and Alonso, Yasmine and Liu, Katie and Arifov, Javokhir and Sreenivas, Anjali and Webber, Dan and Zheng, Tina and Nguyen, Ngoc and Mlauzi, Iddah and Woodrow, Juliette},
title = {Infinite Story},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705037},
doi = {10.1145/3641555.3705037},
abstract = {In Infinite Story, students build a choose-your-own-adventure game that integrates generative AI to create a dynamic, interactive "infinite story" experience. The game is powered by nested dictionary (JSON) objects that store pre-existing scenes. Each scene is a nested dictionary, containing user choices, descriptions, and more. Students are challenged to navigate and manipulate these deeply nested data structures, which helps them appreciate the utility and complexity of dictionary objects. When a user ventures into an undefined scene, the program makes an API call to ChatGPT to generate the next scene, allowing the adventure to continue seamlessly. To the best of our knowledge it is one of the first assignments in intro CS that uses ChatGPT. What makes this assignment truly nifty is how it teaches students to leverage generative AI in a creative, meaningful way. By blending generative storytelling with technical skills, students get to see the power of AI in extending their projects beyond predefined boundaries, creating an open-ended, exciting experience. Many students expanded on this assignment for their final projects, creating sophisticated programs like AI-driven Chess and Go games. Using the techniques from this assignment, they leveraged the course's OpenAI integration to build functional AI agents that enhanced gameplay. These projects showcased the flexibility of the assignment, inspiring students to think critically about the creative and practical applications of AI in real-world contexts.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1750},
numpages = {1},
keywords = {API, CS1, JSON, dictionaries, generative AI, nested structures, python, storytelling},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713832,
author = {Jain, Yoshee and Demirtas, Mehmet Arif and Cunningham, Kathryn Irene},
title = {PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713832},
doi = {10.1145/3706598.3713832},
abstract = {Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators’ plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors’ efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {21},
keywords = {programming plan, programming pattern, pattern identification, instructor support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3696673.3723069,
author = {Meda, Kavya Nikhita and Nara, Pavan Subhash Chandrabose and Bozenka, Svoboda and Zormati, Tarek and Turner, Seth and Worley, Wayne and Mitra, Reshmi},
title = {Integrating Prompt Structures Using LLM Embeddings for Cybersecurity Threats},
year = {2025},
isbn = {9798400712777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696673.3723069},
doi = {10.1145/3696673.3723069},
abstract = {This paper aims to develop a specialized Large Language Model (LLM) for cybersecurity training, designed to educate users on fundamental cybersecurity concepts. This paper focuses on creating an interactive system where users can ask questions about computer security and receive accurate, informative responses. By addressing cybersecurity as a critical national issue, the LLM empowers individuals and organizations to defend against malicious cyber threats. Our system was developed using Python, utilizing Google Sheets as a database, Gradio for the user interface, and Google Gemini's API for advanced language processing. The implementation followed a test-driven development approach, iterating between coding and testing to ensure functionality and reliability. Key technologies include Mistral's Large 2 model and embedding models for clustering related data. The Retrieval-Augmented Generation (RAG) framework was employed to integrate information retrieval with the LLM, enhancing its accuracy and relevance. Tools such as Google Suite, Colab, and Gradio contributed to creating a robust and user-friendly system. This paper highlights the potential of domain-specific LLMs, offering a practical solution to the growing need for accessible cybersecurity education and fostering awareness to mitigate the risks posed by malicious hackers.},
booktitle = {Proceedings of the 2025 ACM Southeast Conference},
pages = {180–187},
numpages = {8},
keywords = {large language model (LLM), embedding models, retrieval-augmented generation (RAG), information retrieval, cybersecurity education},
location = {Southeast Missouri State University, Cape Girardeau, MO, USA},
series = {ACMSE 2025}
}

@inproceedings{10.1145/3641555.3705031,
author = {Diaz, Nicolas and Roy, Saunak and Beltran, Jonathan},
title = {Exploring Undergraduate AI Perceptions: Knowledge, Enthusiasm, and Concerns},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705031},
doi = {10.1145/3641555.3705031},
abstract = {As Artificial Intelligence (AI) develops and grows its presence in society, college students are increasingly interacting with AI and utilizing tools like ChatGPT as part of their education. Particularly in STEM fields, educators themselves are incorporating AI by encouraging its use as an assistive tool for coursework or designing courses that teach about its inner workings. Understanding students' perceptions and knowledge of AI can help educators know whether students will embrace learning in AI-heavy environments, as well as which student concerns they should acknowledge. Our study uses both quantitative and qualitative data from undergraduate CMNS (College of Computer, Mathematical, and Natural Sciences) students at the University of Maryland, College Park to explore students' perceived knowledge, enthusiasm, and concerns over AI. Our data was collected via a survey administered via email to undergraduates and subsequent focus group interviews with these students about their relationship with AI. Survey findings indicated that students were confident in their knowledge of AI and related competencies, as well as enthusiastic about learning and using AI. Students also highly believed in the need for standards and testing for AI systems to curtail risks. There was a positive correlation between perceived knowledge and enthusiasm of AI, but no correlation between knowledge and concerns. In interviews, students' main uses of AI were summarizing information, creating practice problems, and writing assistance. Popular concerns included academic dishonesty, overreliance on AI tools, and fabricated information in outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1753},
numpages = {1},
keywords = {artificial intelligence, generative AI, higher education, learning environments, student perceptions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3672608.3707798,
author = {Ehl, Marco and Ahmadian, Amir Shayan and Gro\ss{}er, Katharina and Elsofi, Duaa Adel Ali and Herrmann, Marc and Specht, Alexander and Schneider, Kurt and J\"{u}rjens, Jan},
title = {Supporting Software Engineers in IT Security and Privacy through Automated Knowledge Discovery},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707798},
doi = {10.1145/3672608.3707798},
abstract = {Security and privacy are increasingly essential concepts in software engineering. New threats and corresponding countermeasures are continuously discovered. Concurrently, projects are becoming more complex and are exposed to a greater number of threats. This presents a significant challenge for software engineers. As a result, security and privacy are often neglected due to a lack of knowledge, limited time, and financial constraints. While systematic literature reviews exist to address the increasing volume of publications, software engineers still require up-to-date knowledge of current threats and measures. This paper presents an automated, time-efficient, and cost-effective method for discovering knowledge from state-of-the-art literature and project artifacts, such as design documents. The presented method utilizes Large Language Models (LLMs) for data extraction and is demonstrated through a prototypical implementation and evaluation. This evaluation involves security and privacy in open-access scientific publications and project documentation from European Union research and development projects. The extracted knowledge is used to populate a quality model that is specifically designed to provide software engineers with information that helps them apply the findings. This quality model offers software engineers valuable, up-to-date insights into security and privacy, bridging the gap between scientific research and practical applications.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1647–1656},
numpages = {10},
keywords = {security, privacy, quality model, knowledge discovery, large language model},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3701716.3717810,
author = {Syah, Riza Alaudin and Haryanto, Christoforus Yoga and Lomempow, Emily and Malik, Krishna and Putra, Irvan},
title = {EdgePrompt: Engineering Guardrail Techniques for Offline LLMs in K-12 Educational Settings},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717810},
doi = {10.1145/3701716.3717810},
abstract = {EdgePrompt is a prompt engineering framework that implements pragmatic guardrails for Large Language Models (LLMs) in the K-12 educational settings through structured prompting inspired by neural-symbolic principles. The system addresses educational disparities in Indonesia's Frontier, Outermost, Underdeveloped (3T) regions by enabling offline-capable content safety controls. It combines: (1) content generation with structured constraint templates, (2) assessment processing with layered validation, and (3) lightweight storage for content and result management. The framework implements a multi-stage verification workflow that maintains safety boundaries while preserving model capabilities in connectivity-constrained environments. Initial deployment targets Grade 5 language instruction, demonstrating effective guardrails through structured prompt engineering without formal symbolic reasoning components.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1635–1638},
numpages = {4},
keywords = {ai safety, content filtering, edge computing, educational technology, guardrails, k-12 education, large language models, offline ai, prompt engineering},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.5555/3709347.3743852,
author = {Wang, Peng-Yuan and Pang, Jing-Cheng and Wang, Chen-Yang and Liu, Xuhui and Liu, Tian-Shuo and Yang, Si-Hang and Qian, Hong and Yu, Yang},
title = {InCLET: Large Language Model In-context Learning can Improve Embodied Instruction-following},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Natural language-conditioned reinforcement learning (NLC-RL) empowers embodied agent to complete various tasks following human instruction. However, the unbounded natural language examples still introduce much complexity for the agent that solves concrete RL tasks, which can distract policy learning from completing the task. Consequently, extracting effective task representation from human instruction emerges as the critical component of NLC-RL. While previous methods have attempted to address this issue by learning task-related representation using large language models (LLMs), they highly rely on pre-collected task data and require extra training procedure. In this study, we uncover the inherent capability of LLMs to generate task representations and present a novel method, in-context learning embedding as task representation (InCLET). InCLET is grounded on a foundational finding that LLM in-context learning using trajectories can greatly help represent tasks. We thus firstly employ LLM to imagine task trajectories following the natural language instruction, then use in-context learning of LLM to generate task representations, and finally aggregate and project into a compact low-dimensional task representation. This representation is then used to train a human instruction-following agent. We conduct experiments on various embodied control environments and results show that InCLET creates effective task representations. Furthermore, this representation can significantly improve the RL training efficiency, compared to the baseline methods.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2134–2142},
numpages = {9},
keywords = {embodiment agent, in-context learning, reinforcement learning},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3702386.3702391,
author = {Zhang, Li and Li, Xiaohua and Kong, Xiangdan},
title = {Investigating AI-Integrated Ecological Civilization Education: Opportunities and Challenges in a Qualitative Study},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702391},
doi = {10.1145/3702386.3702391},
abstract = {This study aims to explore the opportunities and challenges of integrating artificial intelligence (AI) into ecological civilization education through a qualitative research approach. A 12-week ecological civilization course was developed using the flipped classroom model, leveraging ChatGPT to support instructional activities. The study involved interviews with eight students (four sophomores and four juniors) to investigate their usage, attitudes, and feedback on AI tools. The findings indicate that ChatGPT significantly enhances learning outcomes, improves assignment and project quality, and boosts creativity and innovation. However, students also highlighted issues with information accuracy and practical application challenges. Based on these findings, the study offers recommendations for optimizing AI tool usage in future courses and emphasizes the importance of AI-human collaboration in solving complex problems.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {70–75},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Ecological Civilization Education, Learning Outcomes, Student Feedback},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3708557.3716159,
author = {Turchi, Tommaso and Malizia, Alessio and Patern\`{o}, Fabio and Borsci, Simone and Chamberlain, Alan and Fish, Andrew},
title = {Adaptive XAI: Advancing Intelligent Interfaces for Tailored AI Explanations (2nd Edition)},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716159},
doi = {10.1145/3708557.3716159},
abstract = {As artificial intelligence becomes increasingly embedded in daily decision-making processes, the need for effective communication between humans and AI systems grows more crucial. The Adaptive XAI (AXAI) workshop, now in its second edition, focuses on developing intelligent interfaces that can adaptively explain AI’s decision-making processes. Building on the success of our inaugural event at IUI 2024, this workshop continues to explore the intersection of Explainable AI and adaptive user interfaces, emphasizing the development of interfaces that dynamically adapt to create explanations that resonate with diverse users. In line with the human-centric principles of the Future Artificial Intelligence Research (FAIR) project, we examine how emerging technologies such as conversational agents and Large Language Models can enhance AI explainability while ensuring explanations remain malleable and responsive to users’ evolving cognitive states and contextual needs.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {172–174},
numpages = {3},
keywords = {Explainable AI, Human-Centered AI, Adaptive Explainable AI},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3706598.3713589,
author = {Pan, Sitong and Schmucker, Robin and Garcia Bulle Bueno, Bernardo and Llanes, Salome Aguilar and Albo Alarc\'{o}n, Fernanda and Zhu, Hangxiao and Teo, Adam and Xia, Meng},
title = {TutorUp: What If Your Students Were Simulated? Training Tutors to Address Engagement Challenges in Online Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713589},
doi = {10.1145/3706598.3713589},
abstract = {With the rise of online learning, many novice tutors lack experience engaging students remotely. We introduce TutorUp, a Large Language Model (LLM)-based system that enables novice tutors to practice engagement strategies with simulated students through scenario-based training. Based on a formative study involving two surveys (N1 = 86, N2 = 102) on student engagement challenges, we summarize scenarios that mimic real teaching situations. To enhance immersion and realism, we employ a prompting strategy that simulates dynamic online learning dialogues. TutorUp provides immediate and asynchronous feedback by referencing tutor-students online session dialogues and evidence-based teaching strategies from learning science literature. In a within-subject evaluation (N = 16), participants rated TutorUp significantly higher than a baseline system without simulation capabilities regarding effectiveness and usability. Our findings suggest that TutorUp provides novice tutors with more effective training to learn and apply teaching strategies to address online student engagement challenges.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {20},
numpages = {18},
keywords = {Remote Tutoring, Tutor Training, Interactive Learning Environments, Conversational Agents, Large Language Models, Student Engagement},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3704289.3704302,
author = {Pan, Ruoqi and Chen, Liting and Ma, Shiming},
title = {Exploration of Engineering and Design Fusion in 3E of Digital Media Technology Major Empowered by AIGC},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704302},
doi = {10.1145/3704289.3704302},
abstract = {With the rapid advancement of generative artificial intelligence, its demonstrated intelligence, cognition, and other abilities have created new opportunities for the reform of education. This paper examines the core curriculum development of digital media technology, the situation of emerging engineering education(3E), and the application of AIGC in education. It concludes that the main bottlenecks in the fusion of engineering and design of digital media technology are curriculum development, assessment, and duration of practical training. Consequently, the study explores the application and facilitation of AIGC within digital media technology and how AIGC alleviates the bottlenecks of major development. Building on this, the paper presents a case study centered on the core curriculum of digital media technology that found AIGC can significantly improve course teaching efficiency. It aims to provide insights and recommendations for teaching practices in core digital media technology courses.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {36–41},
numpages = {6},
keywords = {AIGC, Curriculum Construction, Digital Media Technology, Engineering and Design Fusion},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3713081.3731745,
author = {He, Yiling and She, Hongyu and Qian, Xingzhi and Zheng, Xinran and Chen, Zhuo and Qin, Zhan and Cavallaro, Lorenzo},
title = {On Benchmarking Code LLMs for Android Malware Analysis},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731745},
doi = {10.1145/3713081.3731745},
abstract = {Large Language Models (LLMs) have demonstrated strong capabilities in various code intelligence tasks. However, their effectiveness for Android malware analysis remains underexplored. Decompiled Android malware code presents unique challenges for analysis, due to the malicious logic being buried within a large number of functions and the frequent lack of meaningful function names.This paper presents Cama, a benchmarking framework designed to systematically evaluate the effectiveness of Code LLMs in Android malware analysis. Cama specifies structured model outputs to support key malware analysis tasks, including malicious function identification and malware purpose summarization. Built on these, it integrates three domain-specific evaluation metrics—consistency, fidelity, and semantic relevance—enabling rigorous stability and effectiveness assessment and cross-model comparison.We construct a benchmark dataset of 118 Android malware samples from 13 families collected in recent years, encompassing over 7.5 million distinct functions, and use Cama to evaluate four popular open-source Code LLMs. Our experiments provide insights into how Code LLMs interpret decompiled code and quantify the sensitivity to function renaming, highlighting both their potential and current limitations in malware analysis.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {153–160},
numpages = {8},
keywords = {code LLM, malware analysis},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@article{10.1145/3711012,
author = {Liu, Yiren and Li, Yerong and Mayfield, Ryan and Huang, Yun},
title = {Improving Emotional Support Delivery in Text-Based Community Safety Reporting Using Large Language Models},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711012},
doi = {10.1145/3711012},
abstract = {Emotional support is a crucial aspect of communication between community members and police dispatchers during incident reporting. However, there is a lack of understanding about how emotional support is delivered through text-based systems, especially in various non-emergency contexts. In this study, we analyzed two years of chat logs comprising 57,114 messages across 8,239 incidents from 130 higher education institutions. Our empirical findings revealed significant variations in emotional support provided by dispatchers, influenced by the type of incident, service time, and a noticeable decline in support over time across multiple organizations. To improve the consistency and quality of emotional support, we developed and implemented a fine-tuned Large Language Model (LLM), named dispatcherLLM, designed to suggest replies through simulating human dispatchers' languages with appropriate emotional support. We evaluated dispatcherLLM by comparing its generated responses to those of human dispatchers and other off-the-shelf models using real chat messages. Additionally, we conducted a human evaluation to assess the perceived effectiveness of the support provided by dispatcherLLM. This study not only contributes new empirical understandings of emotional support in text-based dispatch systems but also demonstrates the significant potential of generative AI in improving service delivery.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW114},
numpages = {31},
keywords = {emotion classification, event argument extraction, large language models, live chat, safety reporting, text-based reporting system}
}

@article{10.1145/3711857,
author = {Hu, Linmei and Zhang, Xinyu and Song, Dandan and Zhou, Changzhi and He, Hongyu and Nie, Liqiang},
title = {Efficient and Effective Role Player: A Compact Knowledge-grounded Persona-based Dialogue Model Enhanced by LLM Distillation},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {3},
issn = {1046-8188},
url = {https://doi.org/10.1145/3711857},
doi = {10.1145/3711857},
abstract = {Incorporating explicit personas into dialogue models is critical for generating responses that fulfill specific user needs and preferences, creating a more personalized and engaging interaction. Early works on persona-based dialogue generation directly concatenate the persona descriptions and dialogue history into relatively small pre-trained language models (PLMs) for response generation, which leads to uninformative and inferior results due to the sparse persona information and the limited model generation capabilities. Recently, large language models (LLMs) have shown their surprising capabilities in language generation. Prompting the LLMs with the persona descriptions for role-playing dialogue generation has also achieved promising results. However, deploying LLMs is challenging for practical applications due to their large scale, spurring efforts to distill the generation capabilities into more concise and compact models through teacher-student learning. In this article, we propose an efficient compact Knowledge-grounded Persona-based Dialogue model enhanced by LLM Distillation (KPDD). Specifically, first, we propose to enrich the annotated persona descriptions by integrating external knowledge graphs (KGs) with a mixed encoding network, coupled with a mixture of experts (MoE) module for both informative and diverse response generation. The mixed encoding network contains multiple layers of modality interaction operations, enabling information from both modalities propagates to the other. Second, to fully exploit the generation capabilities of LLMs, we turn to the distillation technique to improve the generation capabilities of our model, facilitated by a natural language inference (NLI)-based filtering mechanism to extract high-quality information from LLMs. In addition, we employ a curriculum learning strategy to train our model on the high-quality filtered distilled data and progressively on the relatively noisy original data, enhancing its adaptability and performance. Extensive experiments show that KPDD outperforms state-of-the-art baselines in terms of both automatic and human evaluation.},
journal = {ACM Trans. Inf. Syst.},
month = feb,
articleno = {59},
numpages = {29},
keywords = {Persona-based Dialogue Generation, Knowledge Graph, MoE, Large Language Model, Distillation, Curriculum Learning}
}

@inproceedings{10.1145/3706599.3720099,
author = {Shanmugarasa, Yashothara and Pan, Shidong and Ding, Ming and Zhao, Dehai and Rakotoarivelo, Thierry},
title = {Privacy Meets Explainability: Managing Confidential Data and Transparency Policies in LLM-Empowered Science},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720099},
doi = {10.1145/3706599.3720099},
abstract = {As Large Language Models (LLMs) become integral to scientific workflows, concerns over the confidentiality and ethical handling of confidential data have emerged. This paper explores data exposure risks through LLM-powered scientific tools, which can inadvertently leak confidential information, including intellectual property and proprietary data, from scientists’ perspectives. We propose “DataShield", a framework designed to detect confidential data leaks, summarize privacy policies, and visualize data flow, ensuring alignment with organizational policies and procedures. Our approach aims to inform scientists about data handling practices, enabling them to make informed decisions and protect sensitive information. Ongoing user studies with scientists are underway to evaluate the framework’s usability, trustworthiness, and effectiveness in tackling real-world privacy challenges.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {448},
numpages = {8},
keywords = {Confidential data detection, Privacy management, Privacy policies, User study, Large language models},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3641555.3705263,
author = {Lee, Irene and Malyn-Smith, Joyce and Kam, Matthew and Miller, Cody and Wang, Miaoxin},
title = {The AI-Enhanced Software Engineer: A Snapshot of the Profession},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705263},
doi = {10.1145/3641555.3705263},
abstract = {Generative AI and other emerging technologies are significantly impacting the work of software engineers. This impact is not re- stricted to programming; rather it has permeated multiple phases in the software development pipeline. As such, it is increasingly important to understand and analyze the changing work of the AI-enabled software developers who work at the cutting edge of AI Integration. This poster shares the ''Profile of the AI-enhanced Software Engineer'' developed in collaboration between Education Development Center (EDC) and Google. The profile describes in detail the work goals and associated tasks; and the skills, knowledge and attributes needed to do that work effectively. The poster will also share a framework for prompting used by skilled AI-enhanced software engineers across a variety of tasks. Though rapid change is predicted for the field, the Profile can inform K-20 CS and AI education efforts as well as workforce development of the current state of the field and stimulate discussion of how best to prepare for and adapt to the future of work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1519–1520},
numpages = {2},
keywords = {ai-enhanced software engineer, attributes, knowledge, skills},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3672608.3707764,
author = {Heilala, Ville and Araya, Roberto and H\"{a}m\"{a}l\"{a}inen, Raija},
title = {Beyond Text-to-Text: An Overview of Multimodal and Generative Artificial Intelligence for Education Using Topic Modeling},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707764},
abstract = {Generative artificial intelligence (GenAI) can reshape education and learning. While large language models (LLMs) like ChatGPT dominate current educational research, multimodal capabilities—such as text-to-speech and text-to-image—are less explored. This study uses topic modeling to map the research landscape of multimodal and generative AI in education. An extensive literature search yielded 4175 articles. Employing a topic modeling approach, latent topics were extracted, resulting in 38 interpretable topics organized into 14 thematic areas. Findings indicate a predominant focus on text-to-text models in educational contexts, with other modalities underexplored, overlooking the broader potential of multimodal approaches. The results suggest a research gap, stressing the importance of more balanced attention across different AI modalities and educational levels. In summary, this research provides an overview of current trends in generative AI for education, underlining opportunities for future exploration of multimodal technologies to fully realize the transformative potential of artificial intelligence in education.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {54–63},
numpages = {10}
}

@inproceedings{10.1145/3704289.3704293,
author = {Duah, James Ewert and Lu, Xin and McGivern, Paul and Jing, Yanguo},
title = {Interdisciplinary Perspectives on Generative Artificial Intelligence Adoption in Higher Education: A Theoretical Framework Review},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704293},
doi = {10.1145/3704289.3704293},
abstract = {The ongoing integration of Generative Artificial Intelligence (GenAI) within higher education (HE) signifies a pivotal shift in pedagogical paradigms, demanding comprehensive theoretical and practical considerations. This paper critically examines the multifaceted adoption of GenAI in HE by reviewing interdisciplinary theoretical frameworks from psychology, computer science, and pedagogy. It highlights the insufficiency of traditional technology acceptance models, which predominantly address cognitive and rational decision-making processes, and advocates for the inclusion of emotional and ethical dimensions often overlooked in existing frameworks. By synthesizing research across various disciplines, this review identifies significant gaps and proposes an integrated theoretical model to effectively understand and guide GenAI adoption. The proposed framework emphasizes the need for robust, empirically supported methodologies that accommodate the complex, dynamic nature of GenAI applications. This paper not only contributes to academic discourse by providing a comprehensive review of existing literature but also sets a foundation for future empirical studies aimed at refining GenAI integration strategies in HE, ensuring they are ethically aligned and educationally effective.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {1–9},
numpages = {9},
keywords = {GenAI, Higher Education, Psychology, Theoretical Frameworks},
location = {
},
series = {ICBDE '24}
}

@inbook{10.1145/3672608.3707732,
author = {Raimondi, Bianca and Giallorenzo, Saverio and Gabbrielli, Maurizio},
title = {Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707732},
abstract = {In education, the capability of generating human-like text of Large Language Models (LLMs) inspired work on how they can increase the efficiency of learning and teaching. We study the affordability of these models for educators and students by investigating how LLMs answer multiple-choice questions (MCQs) with respect to hardware constraints and refinement techniques. We explore this space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming Languages (PL)—the MCQ dataset is a contribution of this work, which we make publicly available. Specifically, we dissect how different factors, such as using readily-available material—(parts of) the course's textbook—for fine-tuning and quantisation (to decrease resource usage) can change the accuracy of the responses. The main takeaway is that smaller textbook-based fine-tuned models outperform generic larger ones (whose pre-training requires conspicuous resources), making the usage of LLMs for answering MCQs resource- and material-wise affordable.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {32–39},
numpages = {8}
}

@inproceedings{10.1145/3704289.3704301,
author = {Chang, Chi In and Choi, Wan Chong and Choi, Iek Chong},
title = {A Systematic Literature Review of the Opportunities and Advantages for AIGC (OpenAI ChatGPT, Copilot, Codex) in Programming Course},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704301},
doi = {10.1145/3704289.3704301},
abstract = {This systematic literature review explored the opportunities and advantages of integrating Artificial Intelligence Generated Content (AIGC) tools like OpenAI's ChatGPT, Copilot, and Codex in programming education. From an initial pool of 1,173 papers, 24 were rigorously selected for detailed analysis. The findings highlighted the dominant use of ChatGPT, particularly versions 3/3.5 and 4, underscoring its effectiveness and accessibility. Python emerged as the most frequently studied language, followed by Java, C, R, and Scala. A notable research gap was identified in block-based programming languages and online/blended learning environments. Key opportunities and advantages identified included enhanced code review, where AIGC tools offer efficient and comprehensive assessments; personalized learning, with ChatGPT providing individualized feedback and improving student comprehension; and increased student engagement and motivation through interactive features. Additionally, AIGC tools significantly improved problem-solving and debugging support, effectively identifying and correcting coding errors. They also supported diverse learning styles by offering varied examples and solutions, facilitated innovative teaching strategies that improved educational outcomes, and reduced teacher workload by automating routine tasks. These insights demonstrated the transformative potential of AIGC tools in revolutionizing programming education.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {29–35},
numpages = {7},
keywords = {Advantages of AIGC, Artificial intelligence generated content, ChatGPT, Codex, Copilot, Opportunities of AIGC, Programming Course, Systematic literature review},
location = {
},
series = {ICBDE '24}
}

@article{10.5555/3729849.3729850,
author = {Kerney, William},
title = {Treachery and Deceit: Detecting and Dissuading AI Cheating},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {9},
issn = {1937-4771},
abstract = {Last semester, 75% of the author's data structures students were caught cheating at least once, with Generative AI technologies being the most common means by which they cheated. While it may be tempting to move back to in-person pen-and-paper evaluations to ensure students have retained material, the author has found is possible to detect and discourage the use of cheating via various tricky methods. Finally, the author looks at attempts by students to conceal their use of AI in cheating, and how successful off the shelf AI detection tools are at finding the use of AI in coding assignments before and after being rewritten by hand.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {10–17},
numpages = {8}
}

@inproceedings{10.1145/3641555.3705242,
author = {Caraco, Serena and Fabros, Melissa and Lojo, Nelson and Fox, Armando},
title = {Scaffolding Collaborative Software Design with Serious Games},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705242},
doi = {10.1145/3641555.3705242},
abstract = {An application's architecture is frequently refactored after deployment to accommodate its users' evolving needs. However, we currently lack a repeatable, consistent method to teach high-level collaborative design skills. Drawing on the serious play framework, we advance an existing analog exercise for scaffolding collaborative design using a new system: the LLM-managed application overview. From an instructor prompt, the system generates an overview detailing an entire application using CRC cards -- common industry design aids that forego any code or implementation detail. Students individually edit the cards to redesign the application's architecture, while the system simulates the effects of these edits by updating emulated code metrics and estimating redesign cost. Returning to their teams, students discuss the cost and complexity of their designs before selecting and refining a single solution. By the activity's end, the students will have practiced all the design skills necessary for a months-long cycle of development, without the students or the instructor manually managing any implementation details.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1405–1406},
numpages = {2},
keywords = {collaborative design, collaborative learning, serious play, teaching software design},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3696410.3714889,
author = {Gui, Yi and Li, Zhen and Wan, Yao and Shi, Yemin and Zhang, Hongyu and Chen, Bohua and Su, Yi and Chen, Dongping and Wu, Siyuan and Zhou, Xing and Jiang, Wenbin and Jin, Hai and Zhang, Xiangliang},
title = {WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714889},
doi = {10.1145/3696410.3714889},
abstract = {Automatically generating webpage code from webpage designs can significantly reduce the workload of front-end developers, and recent Multimodal Large Language Models (MLLMs) have shown promising potential in this area. However, our investigation reveals that most existing MLLMs are constrained by the absence of high-quality, large-scale, real-world datasets, resulting in inadequate performance in automated webpage code generation. To fill this gap, this paper introduces WebCode2M, a new dataset comprising 2.56 million instances, each containing a design image along with the corresponding webpage code and layout details. Sourced from real-world web resources, WebCode2M offers a rich and valuable dataset for webpage code generation across a variety of applications. The dataset quality is ensured by a scoring model that filters out instances with aesthetic deficiencies or other incomplete elements. To validate the effectiveness of WebCode2M, we introduce a baseline model based on the Vision Transformer (ViT), named WebCoder, and establish a benchmark for fair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure the structural hierarchy recall. The benchmarking results demonstrate that our dataset significantly improves the ability of MLLMs to generate code from webpage designs, confirming its effectiveness and usability for future applications in front-end design tools. Finally, we highlight several practical challenges introduced by our dataset, calling for further research. The code and dataset are publicly available at our project homepage: https://webcode2m.github.io.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {1834–1845},
numpages = {12},
keywords = {code generation, dataset, design to code, ui automation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3641555.3705038,
author = {Dzhumaliev, Mirbek and Musaev, Aibek and Pu, Calton},
title = {Leveraging Generative AI for Personalized Learning Experiences},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705038},
doi = {10.1145/3641555.3705038},
abstract = {This demo presents KimBilet.com, an educational platform that utilizes generative AI to create personalized educational content on demand. Catering to high-school and college students, instructors, job seekers, and lifelong learners, the system generates customized courses based on user prompts, covering any topic of interest. Each course may include a sequence of AI-created lessons and quizzes, providing detailed feedback for every quiz option to enhance understanding. The platform supports intuitive navigation through keyboard shortcuts and allows users to jump between course items seamlessly. It also maintains a history of completed quizzes to help users track their learning progress. Future enhancements include topic suggestions based on past interests, support for coding exercises, and multilingual support. This demo will showcase how KimBilet.com leverages AI to offer adaptive learning experiences, engage attendees through interactive exploration, and discuss its potential applications in educational settings. Participants will gain insights into integrating AI-driven tools into teaching and learning processes to address diverse educational needs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {AI in education, e-learning tools, educational technology, generative AI, personalized learning},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3717512.3717515,
author = {Anwar, Mubashir and Caesar, Matthew},
title = {Understanding Misunderstandings: Evaluating LLMs on Networking Questions},
year = {2025},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/3717512.3717515},
doi = {10.1145/3717512.3717515},
abstract = {Large Language Models (LLMs) have demonstrated impressive abilities in tackling tasks across numerous domains. The capabilities of LLMs could potentially be applied to various computer networking tasks, including network synthesis, management, debugging, security, and education. However, LLMs can be unreliable: they are prone to reasoning errors and may hallucinate incorrect information. Their effectiveness and limitations in computer networking tasks remain unclear. In this paper, we attempt to understand the capabilities and limitations of LLMs in network applications. We evaluate misunderstandings regarding networking related concepts across 3 LLMs over 500 questions. We assess the reliability, explain-ability, and stability of LLM responses to networking questions. Furthermore, we investigate errors made, analyzing their cause, detectability, effects, and potential mitigation strategies.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = feb,
pages = {14–24},
numpages = {11},
keywords = {characterization study, computer networking, large language models}
}

@inproceedings{10.1145/3706599.3706732,
author = {Reyes-Cruz, Gisela and Spors, Velvet and Muller, Michael and Ciolfi Felice, Marianela and Bardzell, Shaowen and Williams, Rua Mae and Hansson, Karin and Feldfeber, Ivana},
title = {Resisting AI Solutionism: Where Do We Go From Here?},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706732},
doi = {10.1145/3706599.3706732},
abstract = {The latest advances in Artificial Intelligence (AI), such as Large Language Models (LLMs), have provoked a massive expansion and adoption of AI applications across the board, with seemingly no sector left untouched by recent developments. Anywhere we look, from healthcare to the creative industries, from education to entertainment, from sustainability to knowledge work, AI is being adopted and adapted, funded and fundraised for, developed and designed for, researched and used for doing research. As AI continues to be treated as a necessary and unquestioned solution for a range of societal problems, we seek to ponder and challenge its perceived suitability and inevitability. Moreover, we wonder how we can go about resisting AI solutionism (i.e., the idea that technology provides solutions to complex social problems) and who gets to resist it, in particular if the structures that surround people and their specific positions constrain them from doing so. This workshop will focus on gathering and sharing lessons from experiences resisting, or attempting to resist, AI solutionism; taking stock and revisiting previous learnings from decades of work within and beyond HCI; and envisioning ways, perspectives, tools, and practices to orient ourselves and each other towards more pluralistic futures.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {797},
numpages = {6},
keywords = {artificial intelligence, ethics, data practices, human-centered AI, feminist AI, decolonial AI},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3701716.3715599,
author = {Liu, Zhiwei and Zhang, Xin and Yang, Kailai and Xie, Qianqian and Huang, Jimin and Ananiadou, Sophia},
title = {FMDLlama: Financial Misinformation Detection Based on Large Language Models},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715599},
doi = {10.1145/3701716.3715599},
abstract = {The emergence of social media has made the spread of misinformation easier. In the financial domain, the accuracy of information is crucial for various aspects of financial market, which has made financial misinformation detection (FMD) an urgent problem that needs to be addressed. Large language models (LLMs) have demonstrated outstanding performance in various fields. However, current studies mostly rely on traditional methods and have not explored the application of LLMs in the field of FMD. The main reason is the lack of FMD instruction tuning datasets and evaluation benchmarks. In this paper, we propose FMDLlama, the first open-sourced instruction-following LLMs for FMD task based on fine-tuning Llama3.1 with instruction data, the first multi-task FMD instruction dataset (FMDID) to support LLM instruction tuning, and a comprehensive FMD evaluation benchmark (FMD-B) with classification and explanation generation tasks to test the FMD ability of LLMs. We compare our models with a variety of LLMs on FMD-B, where our model outperforms other open-sourced LLMs as well as OpenAI's products. This project is available at https://github.com/lzw108/FMD.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1153–1157},
numpages = {5},
keywords = {evaluation benchmark, financial misinformation, large language model},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3641555.3705241,
author = {Jindal, Vasu},
title = {SAFARI-P: Swahili-Focused Adaptive Framework for Accelerated Reinforcement in Intelligent Python Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705241},
doi = {10.1145/3641555.3705241},
abstract = {This paper introduces SAFARI-P (Swahili-Focused Adaptive Framework for Accelerated Reinforcement in Intelligent Python Education), an innovative system that integrates Generative Adversarial Networks (GANs) and a Multi-Dimensional Learning Confidence (MDLC) system for Python programming education in Swahili. The framework comprises three key components: (1) an Adversarial Code Generation System (ACGS) for creating culturally relevant code snippets, (2) an MDLC Assessment Module that uses a tripartite confidence matrix system to evaluate concept understanding, problem-solving patterns, and code quality, and (3) a Cultural Context Integration Engine for incorporating local elements. By simultaneously tracking technical proficiency and cultural understanding through confidence matrices, SAFARI-P provides personalized learning paths that ensure students build strong foundational knowledge while maintaining cultural relevance. In a 16-week study conducted across Kenya, Tanzania, and Uganda, this mathematically rigorous approach to confidence tracking led to significant improvements: a 27% increase in Python proficiency (p &lt; 0.001) and a 32.6% improvement in problem-solving efficiency (p &lt; 0.001).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1499–1500},
numpages = {2},
keywords = {adaptive learning, ai in education, cultural computing, culturally relevant computing, generative adversarial networks},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3732285,
author = {Rocca, Michele and Darkner, Sune and Erleben, Kenny and Andrews, Sheldon},
title = {Policy-Space Diffusion for Physics-Based Character Animation},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {3},
issn = {0730-0301},
url = {https://doi.org/10.1145/3732285},
doi = {10.1145/3732285},
abstract = {Adapting motion to new contexts in digital entertainment often demands fast agile prototyping. State-of-the-art techniques use reinforcement learning policies for simulating the underlined motion in a physics engine. Unfortunately, policies typically fail on unseen tasks and it is too time-consuming to fine-tune the policy for every new morphological, environmental, or motion change. We propose a novel point of view on using policy networks as a representation of motion for physics-based character animation. Our policies are compact, tailored to individual motion tasks, and preserve similarity with nearby tasks. This allows us to view the space of all motions as a manifold of policies where sampling substitutes training. We obtain memory-efficient encoding of motion that leverages the characteristics of control policies such as being generative, and robust to small environmental changes. With this perspective, we can sample novel motions by directly manipulating weights and biases through a Diffusion Model. Our newly generated policies can adapt to previously unseen characters, potentially saving time in rapid prototyping scenarios. Our contributions include the introduction of Common Neighbor Policy regularization to constrain policy similarity during motion imitation training making them suitable for generative modeling; a Diffusion Model adaptation for diverse morphology; and an open policy dataset. The results show that we can learn non-linear transformations in the policy space from labeled examples, and conditionally generate new ones. In a matter of seconds, we sample a batch of policies for different conditions that show comparable motion fidelity metrics as their respective trained ones.},
journal = {ACM Trans. Graph.},
month = may,
articleno = {25},
numpages = {18},
keywords = {Character animation, physics-based control, motion retargeting, control policies, deep reinforcement learning, diffusion-transformer models}
}

@inproceedings{10.1145/3706598.3713724,
author = {Guo, Longjie and Fu, Yue and Lin, Xiran and Xu, Xuhai and Chang, Yung-Ju and Hiniker, Alexis},
title = {What Social Media Use Do People Regret? An Analysis of 34K Smartphone Screenshots with Multimodal LLM},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713724},
doi = {10.1145/3706598.3713724},
abstract = {Smartphone users often regret aspects of their phone use, especially social media use. However, pinpointing specific ways in which the design of an interface contributes to regrettable use can be challenging due to the complexity of social media app features and user intentions. We conducted a one-week study with 17 Android users, using a novel method where we passively collected screenshots every five seconds, which we analyzed via a multimodal large language model to understand participants’ usage activity at a fine-grained level. Triangulating this data with data from experience sampling, surveys, and interviews, we found that regret varies based on user intention, with non-intentional and social media use being especially regrettable. Regret also varies by social media activity; participants were most likely to regret viewing algorithmically recommended content and comments. Additionally, participants frequently deviated to browsing social media when their intention was direct communication, which slightly increased their regret. Our findings provide guidance to designers and policy-makers seeking to improve users’ experience and autonomy.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {972},
numpages = {23},
keywords = {screenshots, regret, digital well-being, multimodal large language model, social media},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714121,
author = {Atcheson, Alex and Khan, Omar and Siemann, Brian and Jain, Anika and Karahalios, Karrie},
title = {"I'd Never Actually Realized How Big An Impact It Had Until Now": Perspectives of University Students with Disabilities on Generative Artificial Intelligence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714121},
doi = {10.1145/3706598.3714121},
abstract = {Prior research on the experiences of students with disabilities in higher education has surfaced a number of barriers that prevent full inclusion. Generative artificial intelligence (GenAI) has begun to attract interest for its potential to address longstanding barriers to access. However, little is known about the impact of these tools on the living and learning experiences of post-secondary students with disabilities. As a mixed-abilities team, we investigated student experiences with GenAI tools by collecting survey and interview responses from 62 and 21 students with disabilities, respectively, across two universities to measure students’ use of GenAI tools and their perspectives on the impact of these tools in ways related to disability, university support, and sense of belonging. Despite concerns over potential risks of GenAI and unclear university policies, students described GenAI tools as a useful resource for personalizing learning, promoting self-care, and assisting with important self-advocacy work. Guidance demonstrating safe, acceptable uses of GenAI tools, along with clear policies and resources that acknowledge diverse student needs, were desired. We discuss implications of these tools for accessibility and inclusion in higher education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {42},
numpages = {22},
keywords = {Students with Disabilities, Higher Education, Generative Artificial Intelligence, Student Perspectives},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713109,
author = {Zhu, Zihao and Yu, Ao and Tong, Xin and Hui, Pan},
title = {Exploring LLM-Powered Role and Action-Switching Pedagogical Agents for History Education in Virtual Reality},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713109},
doi = {10.1145/3706598.3713109},
abstract = {Multi-role pedagogical agents can create engaging and immersive learning experiences, helping learners better understand knowledge in history learning. However, existing pedagogical agents often struggle with multi-role interactions due to complex controls, limited feedback forms, and difficulty dynamically adapting to user inputs. In this study, we developed a VR prototype with LLM-powered adaptive role-switching and action-switching pedagogical agents to help users learn about the history of the Pavilion of Prince Teng. A 2 x 2 between-subjects study was conducted with 84 participants to assess how adaptive role-switching and action-switching affect participants’ learning outcomes and experiences. The results suggest that adaptive role-switching enhances participants’ perception of the pedagogical agent’s trustworthiness and expertise but may lead to inconsistent learning experiences. Adaptive action-switching increases participants’ perceived social presence, expertise, and humanness. The study did not uncover any effects of role-switching and action-switching on usability, learning motivation and cognitive load. Based on the findings, we proposed five design implications for incorporating adaptive role-switching and action-switching into future VR history education tools.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1066},
numpages = {19},
keywords = {Pedagogical agents, Virtual reality, Large language models, History education},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3714111,
author = {Fan, Haoxiang and Zhou, Changshuang and Yu, Hao and Wu, Xueyang and Gu, Jiangyu and Peng, Zhenhui},
title = {LitLinker: Supporting the Ideation of Interdisciplinary Contexts with Large Language Models for Teaching Literature in Elementary Schools},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714111},
doi = {10.1145/3706598.3714111},
abstract = {Teaching literature under interdisciplinary (e.g., science, art) contexts that connect reading materials has become popular in elementary schools. However, constructing such contexts is challenging as it requires teachers to explore substantial amounts of interdisciplinary content and link it to the reading materials. In this paper, we develop LitLinker via an iterative design process involving 13 teachers to facilitate the ideation of interdisciplinary contexts for teaching literature. Powered by a large language model (LLM), LitLinker can recommend interdisciplinary topics and contextualize them with literary elements (e.g., paragraphs, viewpoints) in the reading materials. A within-subjects study (N=16) shows that compared to an LLM chatbot, LitLinker can improve the integration depth of different subjects and reduce workload in this ideation task. Expert interviews (N=9) also demonstrate LitLinker’s usefulness for supporting the ideation of interdisciplinary contexts for teaching literature. We conclude with concerns and design considerations for supporting interdisciplinary teaching with LLMs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {18},
numpages = {19},
keywords = {Interdisciplinary contexts, ideation, elementary schools, teachers, large language models},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708359.3712125,
author = {Wang, Xingyi and Wang, Xiaozheng and Park, Sunyup and Yao, Yaxing},
title = {Mental Models of Generative AI Chatbot Ecosystems},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712125},
doi = {10.1145/3708359.3712125},
abstract = {The capability of GenAI-based chatbots, such as ChatGPT and Gemini, has expanded quickly in recent years, turning them into GenAI Chatbot Ecosystems. Yet, users’ understanding of how such ecosystems work remains unknown. In this paper, we investigate users’ mental models of how GenAI Chatbot Ecosystems work. This is an important question because users’ mental models guide their behaviors, including making decisions that impact their privacy. Through 21 semi-structured interviews, we uncovered users’ four mental models towards first-party (e.g., Google Gemini) and third-party (e.g., ChatGPT) GenAI Chatbot Ecosystems. These mental models centered around the role of the chatbot in the entire ecosystem. We further found that participants held a more consistent and simpler mental model towards third-party ecosystems than the first-party ones, resulting in higher trust and fewer concerns towards the third-party ecosystems. We discuss the design and policy implications based on our results.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1016–1031},
numpages = {16},
keywords = {Mental Models, Generative AI Chatbots, Privacy and Security, Human Computer Interaction},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3701716.3715467,
author = {Rodrigues, Jos\'{e} Frederico and Lopes Cardoso, Henrique and Teixeira Lopes, Carla},
title = {Evaluating Llama 3 for Text Simplification: A Study on Wikipedia Lead Sections},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715467},
doi = {10.1145/3701716.3715467},
abstract = {Text simplification converts complex text into simpler language, improving readability and comprehension. This study evaluates the effectiveness of open-source large language models for text simplification across various categories. We created a dataset of 66,620 lead section pairs from English and Simple English Wikipedia, spanning nine categories, and tested Llama 3 for text simplification. We assessed its output for readability, simplicity, and meaning preservation. Results show improved readability, with simplification varying by category. Texts on Time were the most shortened, while Leisure-related texts had the greatest reduction of words/characters and syllables per sentence. Meaning preservation was most effective for the Objects and Education categories.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {1273–1277},
numpages = {5},
keywords = {large language models, llama, text simplification},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3676536.3676766,
author = {Liu, Shiwei and Tao, Guanchen and Zou, Yifei and Chow, Derek and Fan, Zichen and Lei, Kauna and Pan, Bangfei and Sylvester, Dennis and Kielian, Gregory and Saligane, Mehdi},
title = {ConSmax: Hardware-Friendly Alternative Softmax with Learnable Parameters},
year = {2025},
isbn = {9798400710773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676536.3676766},
doi = {10.1145/3676536.3676766},
abstract = {The self-attention mechanism distinguishes transformer-based large language models (LLMs) apart from convolutional and recurrent neural networks. Despite the performance improvement, achieving real-time LLM inference on silicon remains challenging due to the extensive use of Softmax in self-attention. In addition to the non-linearity, the low arithmetic intensity significantly limits processing parallelism, especially when working with longer contexts. To address this challenge, we propose Constant Softmax (ConSmax), a software-hardware co-design that serves as an efficient alternative to Softmax. ConSmax utilizes differentiable normalization parameters to eliminate the need for maximum searching and denominator summation in Softmax. This approach enables extensive parallelization while still executing the essential functions of Softmax. Moreover, a scalable ConSmax hardware design with a bitwidth-split look-up table (LUT) can achieve lossless non-linear operations and support mixed-precision computing. Experimental results show that ConSmax achieves a minuscule power consumption of 0.2mW and an area of 0.0008mm2 at 1250MHz working frequency in 16nm FinFET technology. For open-source contribution, we further implement our design with the OpenROAD toolchain under SkyWater's 130nm CMOS technology. The corresponding power is 2.69mW and the area is 0.007mm2. ConSmax achieves 3.35\texttimes{} power savings and 2.75\texttimes{} area savings in 16nm technology, and 3.15\texttimes{} power savings and 4.14\texttimes{} area savings with the open-source EDA toolchain. In the meantime, it also maintains comparable accuracy on the GPT-2 model and the WikiText103 dataset. The project is available at https://github.com/ReaLLMASIC/ConSmax.},
booktitle = {Proceedings of the 43rd IEEE/ACM International Conference on Computer-Aided Design},
articleno = {72},
numpages = {9},
keywords = {LLM, transformer, hardware-software co-design, softmax, consmax},
location = {Newark Liberty International Airport Marriott, New York, NY, USA},
series = {ICCAD '24}
}

@inproceedings{10.1145/3706599.3719708,
author = {Graves, Nora and Larrieu, Vitus and Zhang, Yingyue Trace and Peng, Joanne and Nagaraj Rao, Varun and Liu, Yuhan and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {GPTFootprint: Increasing Consumer Awareness of the Environmental Impacts of LLMs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719708},
doi = {10.1145/3706599.3719708},
abstract = {With the growth of AI, researchers are studying how to mitigate its environmental impact, primarily by proposing policy changes and increasing awareness among developers. However, research on AI end users is limited. Therefore, we introduce GPTFootprint, a browser extension that aims to increase consumer awareness of the significant water and energy consumption of LLMs, and reduce unnecessary LLM usage. GPTFootprint displays a dynamically updating visualization of the resources individual users consume through their ChatGPT queries. After a user reaches a set query limit, a popup prompts them to take a break from ChatGPT. In a week-long user study, we found that GPTFootprint increases people’s awareness of environmental impact, but has limited success in decreasing ChatGPT usage. This research demonstrates the potential for individual-level interventions to contribute to the broader goal of sustainable AI usage, and provides insights into the effectiveness of awareness-based behavior modification strategies in the context of LLMs.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {296},
numpages = {16},
keywords = {Eco-feedback systems, environmental awareness, large language models, behavior change},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3724393,
author = {Zhang, Xiaoyu and Zhang, Cen and Li, Tianlin and Huang, Yihao and Jia, Xiaojun and Hu, Ming and Zhang, Jie and Liu, Yang and Ma, Shiqing and Shen, Chao},
title = {JailGuard: A Universal Detection Framework for Prompt-based Attacks on LLM Systems},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3724393},
doi = {10.1145/3724393},
abstract = {The systems and software powered by Large Language Models (LLMs) and Multi-Modal LLMs (MLLMs) have played a critical role in numerous scenarios. However, current LLM systems are vulnerable to prompt-based attacks, with jailbreaking attacks enabling the LLM system to generate harmful content, while hijacking attacks manipulate the LLM system to perform attacker-desired tasks, underscoring the necessity for detection tools. Unfortunately, existing detecting approaches are usually tailored to specific attacks, resulting in poor generalization in detecting various attacks across different modalities. To address it, we propose JailGuard, a universal detection framework deployed on top of LLM systems for prompt-based attacks across text and image modalities. JailGuard operates on the principle that attacks are inherently less robust than benign ones. Specifically, JailGuard mutates untrusted inputs to generate variants and leverages the discrepancy of the variants’ responses on the target model to distinguish attack samples from benign samples. We implement 18 mutators for text and image inputs and design a mutator combination policy to further improve detection generalization. The evaluation on the dataset containing 15 known attack types suggests that JailGuard achieves the best detection accuracy of 86.14%/82.90% on text and image inputs, outperforming state-of-the-art methods by 11.81%-25.73% and 12.20%-21.40%.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = mar,
keywords = {LLM Security, Software and Application Security, Large Language Model System, LLM Defense}
}

@inproceedings{10.1145/3706468.3706501,
author = {Scarlatos, Alexander and Baker, Ryan S. and Lan, Andrew},
title = {Exploring Knowledge Tracing in Tutor-Student Dialogues using LLMs},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706501},
doi = {10.1145/3706468.3706501},
abstract = {Recent advances in large language models (LLMs) have led to the development of artificial intelligence (AI)-powered tutoring chatbots, showing promise in providing broad access to high-quality personalized education. Existing works have studied how to make LLMs follow tutoring principles, but have not studied broader uses of LLMs for supporting tutoring. Up until now, tracing student knowledge and analyzing misconceptions has been difficult and time-consuming to implement for open-ended dialogue tutoring. In this work, we investigate whether LLMs can be supportive of this task: we first use LLM prompting methods to identify the knowledge components/skills involved in each dialogue turn, i.e., a tutor utterance posing a task or a student utterance that responds to it. We also evaluate whether the student responds correctly to the tutor and verify the LLM’s accuracy using human expert annotations. We then apply a range of knowledge tracing (KT) methods on the resulting labeled data to track student knowledge levels over an entire dialogue. We conduct experiments on two tutoring dialogue datasets, and show that a novel yet simple LLM-based method, LLMKT, significantly outperforms existing KT methods in predicting student response correctness in dialogues. We perform extensive qualitative analyses to highlight the challenges in dialogueKT and outline multiple avenues for future work.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {249–259},
numpages = {11},
keywords = {Knowledge Components, Knowledge Tracing, Large Language Models, Tutoring dialogues},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3706598.3713456,
author = {Tan, Chek Tien and Atmosukarto, Indriyati and Tandianus, Budianto and Shen, Songjia and Wong, Steven},
title = {Exploring the Impact of Avatar Representations in AI Chatbot Tutors on Learning Experiences},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713456},
doi = {10.1145/3706598.3713456},
abstract = {Despite the growing prominence of Artificial Intelligence (AI) chatbots used in education, there remains a significant gap in our understanding of how interface design elements, particularly avatar representations, influence learning experiences. This paper explores the impact of different AI chatbot avatar representations on students’ learning experiences through a mixed-methods within-subjects study, where participants interacted with three distinct types of AI chatbot interfaces with a common large language model (LLM) over a 14-week university course. Our findings reveal that preferences vary according to factors such as learning habits and learning activities. Avatar design also exhibits affordances for specific prompting behaviors, while the perceived human touch influenced learning experiences in nuanced ways. Additionally, real-world relationships with the individuals behind deepfakes influence these experiences. These insights suggest that the thoughtful integration of diverse avatar representations in AI chatbot systems for different learners and settings can greatly enhance learning experiences.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1072},
numpages = {12},
keywords = {Chatbots, conversational agents, large language models, avatars},
location = {
},
series = {CHI '25}
}

@article{10.1145/3710947,
author = {Cuevas, Alejandro and Scurrell, Jennifer V. and Brown, Eva M. and Entenmann, Jason and Daepp, Madeleine I. G.},
title = {Collecting Qualitative Data at Scale with Large Language Models: A Case Study},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3710947},
doi = {10.1145/3710947},
abstract = {Chatbots have shown promise as tools to scale qualitative data collection. Recent advances in Large Language Models (LLMs) could accelerate this process by allowing researchers to easily deploy sophisticated interviewing chatbots. We test this assumption by conducting a large-scale user study (n=399) evaluating 3 different chatbots, two of which are LLM-based and a baseline which employs hard-coded questions. We evaluate the results with respect to participant engagement and experience, established metrics of chatbot quality grounded in theories of effective communication, and a novel scale evaluating ''richness'' or the extent to which responses capture the complexity and specificity of the social context under study. We find that, while the chatbots were able to elicit high-quality responses based on established evaluation metrics, the responses rarely capture participants' specific motives or personalized examples, and thus perform poorly with respect to richness. We further find low inter-rater reliability between LLMs and humans in the assessment of both quality and richness metrics. Our study offers a cautionary tale for scaling and evaluating qualitative research with LLMs.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW049},
numpages = {27},
keywords = {chatbots, gpt, language models, qualitative research}
}

@inproceedings{10.1145/3698204.3716446,
author = {Yang, Yuyu and Urgo, Kelsey and Arguello, Jaime and Capra, Robert},
title = {Search+Chat: Integrating Search and GenAI to Support Users with Learning-oriented Search Tasks},
year = {2025},
isbn = {9798400712906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698204.3716446},
doi = {10.1145/3698204.3716446},
abstract = {Generative AI (GenAI) technologies such as ChatGPT are changing the ways people interact with information. To illustrate, popular search engines (e.g., Google) have started integrating responses from GenAI tools with the traditional search results. In this paper, we explore the integration of GenAI technology with traditional search in the context of a learning-oriented task. We report on a between-subjects study (N = 40) in which participants completed a complex, learning-oriented search task. Participants were assigned to one of two conditions. In the SearchOnly condition, participants used a traditional web search system to gather information. In the Search+Chat condition, participants used an experimental system that combined a traditional web search component and an interactive GenAI-based chat component (Chat AI). The study investigated seven research questions. RQ1-RQ3 focused on differences between groups: (RQ1) post-task perceptions, (RQ2) search behaviors, and (RQ3) learning outcomes. To measure learning, participants completed a multiple-choice test before the search task, immediately after, and one week later (to measure retention). RQ4-RQ7 delved deeper into participants’ behaviors and experiences in the Search+Chat condition: (RQ4) motivations for (and gains from) engaging with the Chat AI; (RQ5) the phases during which participants engaged with the Chat AI; (RQ6) the types of queries issued to each component; and (RQ7) perceptions about the information returned by each component.},
booktitle = {Proceedings of the 2025 ACM SIGIR Conference on Human Information Interaction and Retrieval},
pages = {57–70},
numpages = {14},
keywords = {Generative AI, search-as-learning, search behavior, mixed-methods},
location = {
},
series = {CHIIR '25}
}

@inproceedings{10.1145/3702212.3702217,
author = {Maguire, Joseph and English, Rosanne and Cao, Qi and Seow, Chee Kiat},
title = {Themes in the Declared Use of Generative Artificial Intelligence in Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702217},
doi = {10.1145/3702212.3702217},
abstract = {Generative Artificial Intelligence use by students completing assessments has been an area of concern for academics. Some educators believe such use will undermine all assessment, while others think it has the potential to revolutionise assessments. This has resulted in some institutions and educators adopting various approaches to control the use of Generative Artificial Intelligence However, much of this is taking place without fully appreciating how students are already making use of such tools. In this paper a practice where an existing assessment is presented with the addition that students are not prevented from using Generative Artificial Intelligence but must declare and explain such use. These declarations and explanations are considered to better understand how students approached the assessment and how it could be refined in future.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {17–20},
numpages = {4},
keywords = {cyber security, research-led teaching, artificial intelligence},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3723420.3723428,
author = {Qiu, Xiaoming and Zhang, Shu},
title = {Application analysis of generative artificial intelligence in basic education},
year = {2025},
isbn = {9798400712876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723420.3723428},
doi = {10.1145/3723420.3723428},
abstract = {This paper makes a detailed analysis of the application of Generative ARTIFICIAL intelligence in the field of basic education, and clarifies the existing problems, including the alienation of teaching process, the adaptation of teachers and students to new technologies, and the accuracy of content generation. And the empirical research is carried out on its specific application in the field of basic education, including questionnaire survey, data analysis and so on. By evaluating the changes in learning interest, learning performance and learning interaction between the control group and the experimental group, the potential and problems of generative AI application in the field of basic education are clarified. On this basis, this research draws the conclusion that the application of generative AI in the field of basic education also requires teachers to strengthen the emotional input, strengthen the technical training for teachers and students, and improve the accuracy of high content of education, so as to better cope with the challenges brought by technological change.},
booktitle = {Proceedings of the 2024 7th International Conference on E-Business, Information Management and Computer Science},
pages = {41–46},
numpages = {6},
keywords = {basic education, educational development, generative artificial intelligence, problem, suggestion},
location = {
},
series = {EBIMCS '24}
}

@inproceedings{10.1145/3706599.3720266,
author = {Wang, Maggie and Colby, Ella and Okwara, Jennifer and Nagaraj Rao, Varun and Liu, Yuhan and Monroy-Hern\'{a}ndez, Andr\'{e}s},
title = {PolicyPulse: LLM-Synthesis Tool for Policy Researchers},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720266},
doi = {10.1145/3706599.3720266},
abstract = {Public opinion shapes policy, yet capturing it effectively to surface diverse perspectives remains challenging. This paper introduces PolicyPulse, an LLM-powered interactive system that synthesizes public experiences from online community discussions to help policy researchers author memos and briefs, leveraging curated real-world anecdotes. Given a specific topic (e.g., “Climate Change”), PolicyPulse returns an organized list of themes (e.g., “Biodiversity Loss” or “Carbon Pricing”), supporting each theme with relevant quotes from real-life anecdotes. We compared PolicyPulse outputs to authoritative policy reports. Additionally, we asked 11 policy researchers across multiple institutions in the Northeastern U.S to compare using PolicyPulse with their expert approach. We found that PolicyPulse’s themes aligned with authoritative reports and helped spark research by analyzing existing data, gathering diverse experiences, revealing unexpected themes, and informing survey or interview design. Participants also highlighted limitations including insufficient demographic context and data verification challenges. Our work demonstrates how AI-powered tools can help influence policy-relevant research and shape policy outcomes.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {439},
numpages = {17},
keywords = {policy research, large language models, text analysis, online discourse analysis, automated synthesis, human-AI interaction, qualitative analysis, prompt engineering},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3713081.3731731,
author = {Xie, Yuanmin and Xu, Zhenyang and Tian, Yongqiang and Zhou, Min and Zhou, Xintong and Sun, Chengnian},
title = {Kitten: A Simple Yet Effective Baseline for Evaluating LLM-Based Compiler Testing Techniques},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3731731},
doi = {10.1145/3713081.3731731},
abstract = {Compiler testing is critical and indispensable to improve the correctness of compilers. Spurred by recent advancements in Large Language Models (LLMs), LLM-based compiler testing techniques such as Fuzz4All, have demonstrated their potential in uncovering real bugs in diverse compilers and reducing the required engineering efforts in designing program generators. Given the continuous evolution of LLMs and the emergence of new LLM-based approaches, establishing robust baselines is crucial for rigorous evaluation and driving future advancements in this promising research direction.To this end, we introduce Kitten, a mutation-based, language-agnostic program generator. Kitten leverages a corpus of seed programs, analogous to the training set for LLMs, and utilizes the target language's syntax, akin to the knowledge learned by LLMs. Furthermore, Kitten's mutation operators can generate diverse test programs, demonstrating a behavior analogous to the ability of LLM inference to generate new code.Our evaluations demonstrate that, using existing compiler test suites as seed programs, Kitten outperforms Fuzz4All in terms of code coverage and bug detection capabilities. Within 24 hours, Kitten achieved 48.3%, 9.9%, and 33.8% higher coverage than Fuzz4All on GCC, LLVM, and Rustc, respectively, while identifying an average of 19.3, 20.3, and 15.7 bugs in these compilers across three runs. Over the course of nine months dedicated to Kitten's development and testing, we identified a total of 328 across the compilers GCC, LLVM, Rustc, Solc, JerryScript, scalac, and slang, of which 310 have been confirmed or fixed. We strongly believe that Kitten serves as an effective baseline, enabling the identification of limitations within existing LLM-based approaches and consequently driving advancements in this promising research direction.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {21–25},
numpages = {5},
keywords = {compiler testing, language-agnostic code generation, benchmarking},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@article{10.1145/3736408,
author = {Koyuncu, Anil},
title = {Exploring Fine-Grained Bug Report Categorization with Large Language Models and Prompt Engineering: An Empirical Study},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3736408},
doi = {10.1145/3736408},
abstract = {Accurate classification of issues is essential for effective project management and timely responses, as the volume of issue reports continues to grow. Manual classification is labor-intensive and error-prone, necessitating automated solutions. While large language models (LLMs) show promise in automated issue labeling, most research focuses on broad categorization (e.g., bugs, feature requests), with limited attention to fine-grained categorization. Understanding specific bug types is crucial, as different bugs require tailored resolution strategies.This study addresses this gap by evaluating LLMs and prompt engineering strategies for fine-grained bug report categorization. We analyze 221,184 fine-grained bug report category labels generated by selected LLMs using various prompt engineering strategies for 1,024 bug reports. We examine how LLMs and prompt engineering influence output characteristics, control over outputs, and categorization performance. Our findings highlight that LLMs and prompt engineering significantly impact output consistency and classification capability, with some yielding consistent results and others introducing variability. Based on these findings, we analyze the agreements and disagreements between LLM-generated labels and human annotations to assess category correctness. Our results suggest that examining label consistency and discrepancies can serve as a complementary method for validating bug report categories, identifying unclear reports, and detecting misclassifications in human annotations.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Prompt Engineering, Large Language Models, Automatic Bug Report Classification, Label correctness}
}

@inproceedings{10.1145/3711403.3711410,
author = {Wen, Jiacun and Lin, Yi and Si, Nian},
title = {Behavioral Analysis of Classroom Interactions Supported by Generative Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711410},
doi = {10.1145/3711403.3711410},
abstract = {Generative artificial intelligence, represented by Chatgpt, has been developing rapidly because of its superiority in form and process, covering almost all industries. In order to comply with the development of technology, some classroom teaching also incorporates it to build a generative artificial intelligence classroom. The classroom interaction behavior has an important reference value to help teachers reconstruct the teaching design and reform the teaching mode. The purpose of this paper is to derive significant behavioral sequence characteristics by coding and recording the actual video of generative artificial intelligence classrooms and analyzing the classroom interaction behaviors using lag sequence analysis. The study shows that the teacher-student interaction in the generative artificial intelligence classroom is more active, and the students' active participation in the classroom is very high, which will further promote the generative artificial intelligence classroom and realize the deep integration of the new technology and the classroom.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {49–54},
numpages = {6},
keywords = {Classroom interactive behavior, Generative artificial intelligence, lagged series analysis},
location = {
},
series = {ICETM '24}
}

@article{10.1145/3735635,
author = {Zhao, Zixiao and Fard, Fatemeh},
title = {Do Current Language Models Support Code Intelligence for R Programming Language?},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3735635},
doi = {10.1145/3735635},
abstract = {Recent advancements in developing Pre-trained Language Models for Code (Code-PLMs) have urged many areas of Software Engineering (SE) and brought breakthrough results for many SE tasks. Though these models have achieved the state-of-the-art performance for SE tasks for many popular programming languages, such as Java and Python, the Scientific Software and its related languages like R programming language have rarely benefited or even been evaluated with the Code-PLMs. Research has shown that R has many differences with other programming languages and requires specific techniques. In this study, we provide the first insights for code intelligence for R. For this purpose, we collect and open source an R dataset, and evaluate Code-PLMs for the two tasks of code summarization and method name prediction using several settings and strategies, including the differences in two R styles, Tidy-verse and Base R. Our results demonstrate that the studied models have experienced varying degrees of performance degradation when processing R programming language code, which is supported by human evaluation. Additionally, not all models show performance improvement in R-specific tasks even after multi-language fine-tuning. The dual syntax paradigms in R significantly impact the models’ performance, particularly in code summarization tasks. Furthermore, the project-specific context inherent in R codebases significantly impacts the performance when attempting cross-project training. Interestingly, even when Large Language Models like CodeLlama and StarCoder2 are used for code generation, the Pass@K ( (K=1,5,10) ) results lags signigicantly behind Python scores. Our research shows that R as a low resource language requires different techniques to collect a high quality data. Specifically separating the two R styles has a great impact on the results and the separate dataset could increase the performance of the models. Our research sheds light on the capabilities of Code-PLMs and opens new research directions for researchers and practitioners for developing code intelligence tools and techniques for R. With R's widespread use and popularity, the results of our study can potentially benefit a large community of R developers, both in research and industry.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
keywords = {Empirical Studies, Code Summarization, Method Name Prediction, R Programming Language, Code Generation in R, R programming Styles (Tidy-verse and Base)}
}

@inproceedings{10.1145/3711403.3711428,
author = {Guo, Peirong and Zhang, Qi and Tian, Chunwei and Xue, Wanli and Feng, Xiaocheng},
title = {Digital Human Techniques for Education Reform},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711428},
doi = {10.1145/3711403.3711428},
abstract = {The rapid evolution of artificial intelligence, big data, and generative AI models has ushered in significant transformations across various sectors, including education. Digital Human Technique, an innovative technology grounded in advanced computer science and artificial intelligence, is reshaping educational paradigms by enabling virtual humans to simulate human behavior, express emotions, and interact with users. This paper explores the application of Digital Human Technique in education reform, focusing on creating immersive, intelligent classroom experiences that foster meaningful interactions between teachers and students. We define Digital Human Technique and delve into its key technical components such as character modeling and rendering, natural language processing, computer vision, and augmented reality technologies. Our methodology involves analyzing the role of educational digital humans created through these technologies, assessing their impact on educational processes, and examining various application scenarios in educational reform. Results indicate that Digital Human Technique significantly enhances the learning experience by enabling personalized teaching, increasing engagement, and fostering emotional connections. Educational digital humans serve as virtual teachers, interactive learning aids, and facilitators of emotional interaction, effectively addressing the challenges of traditional educational methods. They also promote a deeper understanding of complex concepts through simulated environments and interactive digital content.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {173–178},
numpages = {6},
keywords = {Digital Human Techniques, Education Reform},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3708036.3708151,
author = {Yan, Erkai and Gao, Mengxiao and Tang, Mei},
title = {Analysis and Research on Generative Artificial Intelligence in the Field of International Library and Information Science},
year = {2025},
isbn = {9798400709999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708036.3708151},
doi = {10.1145/3708036.3708151},
abstract = {Generative artificial intelligence is an artificial intelligence technology based on deep learning whose core lies in leveraging computer algorithms and training data to generate new, practically valuable content, encompassing text, images, audio, videos, etc. This technology is poised to exert profound impacts on the transformation and development of libraries. Drawing on generative artificial intelligence research publications in the field of international library and information science included in the Scopus database as the data source, this paper employs CiteSpace software and SciVal tools to conduct a visual analysis of literature outputs, core authors, journal sources, and keywords. The results show that generative artificial intelligence research in the international library and information science field is applied primarily in areas such as reference services, information literacy education, and smart libraries. Recommendations are made to promote the application and development of generative artificial intelligence technology in libraries by strengthening technological research and application, boosting data analysis and data sharing, emphasizing information security and privacy protection, promoting cross-boundary integration and ecological development, etc.},
booktitle = {Proceedings of the 2024 5th International Conference on Computer Science and Management Technology},
pages = {679–686},
numpages = {8},
keywords = {ChatGPT, Generative artificial intelligence, library},
location = {
},
series = {ICCSMT '24}
}

@inproceedings{10.1145/3708557.3716358,
author = {Li, Lei and Duan, Manni and Wang, Yongheng},
title = {Interactive Visualization of LSST Quantum Graph},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716358},
doi = {10.1145/3708557.3716358},
abstract = {The Vera C. Rubin Observatory’s Legacy Survey of Space and Time (LSST) project generates vast amounts of data managed by its Pipeline System, built upon the Quantum Graph representing data processing tasks. Official visualization tools based on Graphviz have limitations, including size constraints, inflexible layouts, and difficulty in locating nodes. We propose a new visualization approach using the Dify framework to address these issues. Our contributions include: (1) a program to export Quantum Graph instances into Dify’s workflows, storing Quantum Graph node data in Dify’s CODE nodes with pop-up modals; (2) a more reasonable layout algorithm for Dify workflows that represents LSST’s data processing logic; and (3) a navigation agent based on Large Language Models (LLM) that enables users to locate specific nodes through natural language queries. These improvements enhance the understanding and efficiency of Quantum Graph analysis, offering a more interactive and user-friendly visualization experience for LSST users.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {152–154},
numpages = {3},
keywords = {LSST, pipeline system, visualization, Dify, workflow},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3706598.3714322,
author = {Hohendanner, Michel and Ullstein, Chiara and Onyekwelu, Bukola Abimbola and Katirai, Amelia and Kuribayashi, Jun and Babalola, Olusola and Ema, Arisa and Grossklags, Jens},
title = {Initiating the Global AI Dialogues: Laypeople Perspectives on the Future Role of genAI in Society from Nigeria, Germany and Japan},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714322},
doi = {10.1145/3706598.3714322},
abstract = {With the rapid development and release of generative AI (genAI) applications, policy discourses primarily take place on an expert level. Little space is given to laypeople – who have to adapt to and adopt the genAI innovations – to share their opinions and experiences. Addressing this gap, we organized 6h/3.5h laypeople dialogues in Nigeria, Japan, and Germany in July and August 2024. During the dialogues, participants discussed what a desirable future in light of genAI development could look like in one of three contexts: education, public service, and arts &amp; culture. Participants explored the consequences of technology deployment, assessed the risks, mapped stakeholders, and derived measures to achieve a desirable goal. This study contributes to policy debates on genAI by providing recommendations derived from participants’ identified requirements and suggested measures for genAI to create value and to foster a socially desirable future. We reflect on the results through a cross-national lens.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {571},
numpages = {35},
keywords = {citizen dialogue, civic participation, participatory AI, stakeholder involvement, public perception, generative artificial intelligence},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3719787,
author = {Ly, Carina and Peng, Eleanor and Liu, Katie and Qin, Anthony and Howe, Grace and Cheng, Alan Y. and Cuadra, Andrea},
title = {Museum in the Classroom: Engaging Students with Augmented Reality Museum Artifacts and Generative AI},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719787},
doi = {10.1145/3706599.3719787},
abstract = {Museum field trips provide a rich learning experience for children. However, they are complex and expensive for teachers to organize. Fortunately, digitization of museum artifacts makes it possible to use museum resources within the classroom. Museum in the Classroom (MITC) explores how augmented reality (AR) and generative artificial intelligence (AI) can create an interactive learning experience around museum artifacts. This iPad app allows educators to select historical topics from a curated artifact library, generating AR-based exhibits that students can explore. MITC engages students through interactive AR artifacts, AI-driven chatbots, and AI-generated quiz questions, based on a real exhibition at the Cantor Arts Center at Stanford University. A formative study with middle schoolers (N = 20) demonstrated that the app increased engagement compared to traditional learning methods. MITC also fostered a playful and comfortable environment to interact with museum artifacts. Our findings suggest that combining AR and AI has the potential to enrich classroom learning and offer a scalable alternative to traditional museum visits.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {409},
numpages = {8},
keywords = {Education/Learning; Children/Parents; Artifact or System},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3736720,
author = {Sethiya, Nivedita and Nair, Saanvi and Walia, Puneet and Maurya, Chandresh},
title = {Indic-ST: A Large-Scale Multilingual Corpus for Low-Resource Speech-to-Text Translation},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3736720},
doi = {10.1145/3736720},
abstract = {We introduce Indic-ST, a novel dataset for speech-to-text translation (ST) task from English to Indic languages to bridge the performance gap. ST involves converting spoken input in one language into written text in another, playing a key role in real-world applications like subtitling, lecture transcription, and multilingual communication systems. Despite several efforts like Meta’s seamless m4t, OpenAI’s Whisper, or Google USM model, the performance of ST models on low-resource languages lags to that of English (or high-resource languages like European languages). Indic-ST is compiled from four distinct domains: conversational audio, religious texts, education, and news, which combined results in the Indic-ST dataset. To the best of our knowledge, this is the largest low-resource ST data covering approximately 6800 hours of English speech in the real human voice and text in 15 Indic languages with diverse scripts totaling approximately 900GB in size. To assess the usefulness of the dataset, we present the baseline performance of individual language pairs using state-of-the-art ST models. We also present a unified multilingual English-to-Indic-ST model. The code and dataset are available at https://github.com/Nivedita5/Indic-ST.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
keywords = {Speech-to-Text Translation, Automatic Speech Recognition, Machine Translation, Indic Languages, Indo-Aryan Languages, Dravidian Languages, Under-Resourced Language, Under-Represented Language, Low-Resource Language, Language Resource, Multilingual, Multimodal, Cross-Lingual, Cross-Modal, Dataset, Corpus}
}

@inproceedings{10.1145/3708359.3712149,
author = {Sreedhar, Karthik and Cai, Alice and Ma, Jenny and Nickerson, Jeffrey V and Chilton, Lydia B},
title = {Simulating Cooperative Prosocial Behavior with Multi-Agent LLMs: Evidence and Mechanisms for AI Agents to Inform Policy Decisions},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712149},
doi = {10.1145/3708359.3712149},
abstract = {Human prosocial cooperation is essential for our collective health, education, and welfare. However, designing social systems to maintain or incentivize prosocial behavior is challenging because people can act selfishly to maximize personal gain. This complex and unpredictable aspect of human behavior makes it difficult for policymakers to foresee the implications of their designs. Recently, multi-agent LLM systems have shown remarkable capabilities in simulating human-like behavior, and replicating some human lab experiments. This paper studies how well multi-agent systems can simulate prosocial human behavior, such as that seen in the public goods game (PGG), and whether multi-agent systems can exhibit “unbounded actions” seen outside the lab in real world scenarios. We find that multi-agent LLM systems successfully replicate human behavior from lab experiments of the public goods game with three experimental treatments - priming, transparency, and varying endowments. Beyond replicating existing experiments, we find that multi-agent LLM systems can replicate the expected human behavior when combining experimental treatments, even if no previous study combined those specific treatments. Lastly, we find that multi-agent systems can exhibit a rich set of unbounded actions that people do in the real world outside of the lab – such as collaborating and even cheating. In sum, these studies are steps towards a future where LLMs can be used to inform policy decisions that encourage people to act in a prosocial manner.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {1272–1286},
numpages = {15},
keywords = {Social Simulations, Prosocial Behavior, Large Language Models, Multi-Agent LLM Systems},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3706599.3719841,
author = {Qu, Xiaodong and Sherwood, Joshua and Liu, Peiyan and Aleisa, Nawwaf},
title = {Generative AI Tools in Higher Education: A Meta-Analysis of Cognitive Impact},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719841},
doi = {10.1145/3706599.3719841},
abstract = {This meta-analysis examines the cognitive impact of Generative Artificial Intelligence (GenAI) tools on college students, focusing on various levels of Bloom’s taxonomy. As GenAI integration in higher education grows, understanding its influence on critical thinking, problem-solving, and creativity is essential. Using a mixed-effects model, we synthesized data from quantitative studies to explore two moderators: cognitive skill level (e.g., understanding, applying, analyzing) and instructional context (instructed vs. unguided use). Our findings indicate that GenAI tools significantly enhance lower-order cognitive outcomes, particularly in understanding and applying concepts, with instructed use producing stronger positive effects than unguided use. However, their impact on higher-order cognitive skills, such as creating and evaluating, was minimal. These results highlight the importance of tailoring GenAI integration to task complexity and underscore the value of guided instruction in maximizing its educational benefits. Educators should prioritize instructional strategies that encourage active engagement with GenAI tools, particularly for fostering critical thinking and creativity.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {302},
numpages = {9},
keywords = {Generative AI, GenAI in education, Bloom’s taxonomy, Education, Meta-analysis},
location = {
},
series = {CHI EA '25}
}

@inbook{10.5555/3716662.3716799,
author = {Wilson, Kyra and Caliskan, Aylin},
title = {Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval},
year = {2025},
publisher = {AAAI Press},
abstract = {Artificial intelligence (AI) hiring tools have revolutionized resume screening, and large language models (LLMs) have the potential to do the same. However, given the biases which are embedded within LLMs, it is unclear whether they can be used in this scenario without disadvantaging groups based on their protected attributes. In this work, we investigate the possibilities of using LLMs in a resume screening setting via a document retrieval framework that simulates job candidate selection. Using that framework, we then perform a resume audit study to determine whether a selection of Massive Text Embedding (MTE) models are biased in resume screening scenarios. We simulate this for nine occupations, using a collection of over 500 publicly available resumes and 500 job descriptions. We find that the MTEs are biased, significantly favoring White-associated names in 85.1% of cases and female-associated names in only 11.1% of cases, with a minority of cases showing no statistically significant differences. Further analyses show that Black males are disadvantaged in up to 100% of cases, replicating real-world patterns of bias in employment settings, and validate three hypotheses of intersectionality. We also find an impact of document length as well as the corpus frequency of names in the selection of resumes. These findings have implications for widely used AI tools that are automating employment, fairness, and tech policy.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {1578–1590},
numpages = {13}
}

@inproceedings{10.1145/3700794.3700817,
author = {Monteiro Santos, Mateus and Barros, Aristoteles and Rodrigues, Luiz and Dermeval, Diego and Primo, Tiago and Ibert, Ig and Isotani, Seiji},
title = {Near Feasibility, Distant Practicality: Empirical Analysis of Deploying and Using LLMs on Resource-Constrained Smartphones},
year = {2025},
isbn = {9798400710414},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700794.3700817},
doi = {10.1145/3700794.3700817},
abstract = {Artificial Intelligence (AI) systems, such as Large Language Models (LLMs), have the transformative potential to empower education. However, utilizing such systems often requires technological infrastructure, including computers and internet access, which are unavailable in many underserved regions, particularly in the Global South. Despite these limitations, research indicates that smartphones are increasingly accessible even in these areas, presenting an opportunity to deliver advanced systems like LLMs through resource-constrained devices. Nevertheless, the technical feasibility of deploying and using LLMs on disconnected smartphones remains unexplored to the best of our knowledge. This paper presents an empirical study that developed an LLM-powered mobile application, deployed it on a smartphone, and evaluated its performance in terms of response time, memory usage, and storage utilization based on three lightweight LLMs (Tinyllama, Redpajama, and Qwen2). The results show that the overall response time ranged from one to two minutes, and memory usage varied between three and nearly five GB. While these findings demonstrate the technical feasibility of deploying LLMs on disconnected smartphones, the significant waiting time and memory consumption highlight the challenges of this approach. Therefore, although LLMs can be deployed on resource-constrained devices to provide equitable access to advanced educational technology, there is an urgent need to develop optimized alternatives suitable for underserved educational settings so that exploring LLMs in such context becomes practically feasible.},
booktitle = {Proceedings of the 13th International Conference on Information &amp; Communication Technologies and Development},
pages = {224–235},
numpages = {12},
location = {
},
series = {ICTD '24}
}

@inproceedings{10.1145/3729605.3729620,
author = {Zhu, Siyi and Chen, Wenjie},
title = {Deep Learning Based Knowledge Tracing: A Review of the Literature},
year = {2025},
isbn = {9798400714405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3729605.3729620},
doi = {10.1145/3729605.3729620},
abstract = {This study presents new advances in knowledge tracing modeling with Deep Learning. Knowledge Tracing (KT) refers to assessing learners' mastery of knowledge points by analyzing their problem records. Now with deep learning techniques, DLKT models are well equipped to analyze students' complex learning processes. We divided the existing DLKT models into five categories: RNN-based models, attention-based models, GNN-based models, LLM-based models, and other innovative methods. This study compiles more than thirty DLKT models, compares their performance on seven commonly used datasets, and lists the test results for different metrics. We also discuss the main difficulties facing the knowledge tracing field and also predict future trends in this direction.},
booktitle = {Proceedings of the 2025 International Conference on Big Data and Informatization Education},
pages = {81–87},
numpages = {7},
keywords = {Deep Learning Models, Educational Data Mining, Knowledge Tracing, Model Comparison},
location = {
},
series = {ICBDIE '25}
}

@inproceedings{10.5555/3709347.3744043,
author = {Zhao, Yunfan and Boehmer, Niclas and Taneja, Aparna and Tambe, Milind},
title = {Towards Foundation-model-based Multiagent System to Accelerate AI for Social Impact},
year = {2025},
isbn = {9798400714269},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {AI for social impact (AI4SI) offers significant potential for addressing complex societal challenges in areas such as public health, agriculture, education, conservation, and public safety. However, existing AI4SI research is often labor-intensive and resource-demanding, limiting its accessibility and scalability; the standard approach is to design a (base-level) system tailored to a specific AI4SI problem. We propose the development of a novel meta-level multi-agent system designed to accelerate the development of such base-level systems, thereby reducing the computational cost and the burden on social impact domain experts and AI researchers. Leveraging advancements in foundation models and large language models, our proposed approach focuses on resource allocation problems providing help across the full AI4SI pipeline from problem formulation over solution design to impact evaluation. We highlight the ethical considerations and challenges inherent in deploying such systems and emphasize the importance of a human-in-the-loop approach to ensure the responsible and effective application of AI systems.},
booktitle = {Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems},
pages = {2901–2907},
numpages = {7},
keywords = {foundation models, multiagent systems, social impact},
location = {Detroit, MI, USA},
series = {AAMAS '25}
}

@inproceedings{10.1145/3706598.3713283,
author = {Mukhopadhyay, Anirban and Luther, Kurt},
title = {OSINT Clinic: Co-designing AI-Augmented Collaborative OSINT Investigations for Vulnerability Assessment},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713283},
doi = {10.1145/3706598.3713283},
abstract = {Small businesses need vulnerability assessments to identify and mitigate cyber risks. Cybersecurity clinics provide a solution by offering students hands-on experience while delivering free vulnerability assessments to local organizations. To scale this model, we propose an Open Source Intelligence (OSINT) clinic where students conduct assessments using only publicly available data. We enhance the quality of investigations in the OSINT clinic by addressing the technical and collaborative challenges. Over the duration of the 2023-24 academic year, we conducted a three-phase co-design study with six students. Our study identified key challenges in the OSINT investigations and explored how generative AI could address these performance gaps. We developed design ideas for effective AI integration based on the use of AI probes and collaboration platform features. A pilot with three small businesses highlighted both the practical benefits of AI in streamlining investigations, and limitations, including privacy concerns and difficulty in monitoring progress.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {868},
numpages = {22},
keywords = {OSINT, Cybersecurity Vulnerability Assessment, Co-Design, Matchmaking, Generative AI, Collaborative AI Platform},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3724504.3724537,
author = {Zhang, Wen-di and Dou, Huan-xin},
title = {Generation and Evaluation of International Chinese Teaching Resources by Generative Artificial Intelligence},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724537},
doi = {10.1145/3724504.3724537},
abstract = {Generative artificial intelligence has set off a new round of intelligent revolution and promoted the reform and development of the education industry. The development of international Chinese education also requires the digitalization and intelligence of international Chinese teaching resources. In this regard, this article utilizes the technology of ChatGPT platform to integrate teaching resources, constructs an artificial intelligence teaching resource generation framework consisting of demand analysis, intelligent generation, and quality assessment modules, as well as a quality evolution model of artificial intelligence international Chinese teaching resources. Based on this framework and resource quality evolution model, an experiment on the generation of artificial intelligence teaching resources was carried out, and inspections and evaluations were conducted from the perspectives of natural language processing technology, learners, and teachers. The results show that the teaching resources generated by artificial intelligence pass the inspection of natural language understanding technology and have good quality; learners and teachers are optimistic about the application of teaching resources in teaching and believe that most of these resources have reached a usable state; learners' overall experience in using teaching resources is positive and they believe that these resources can promote learning in many aspects. The application of artificial intelligence in generating teaching resources in this article helps to optimize the construction mode of international Chinese teaching resources and promote the high-quality development of international Chinese education.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {187–192},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, International Chinese Education, Teaching Resources},
location = {
},
series = {ICIEAI '24}
}

@inproceedings{10.1145/3711403.3711435,
author = {Yang, Qi},
title = {A Review of the Role and Impact of Generative Artificial Intelligence on Education},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711435},
doi = {10.1145/3711403.3711435},
abstract = {In order to ensure quality development in the age of intelligence, it is crucial to integrate intelligent technology with education. Artificial Intelligence (AI) and Generative Artificial Intelligence (GAI) are disruptive technologies in the area of education. While online education brings significant advantages in enhancing educational quality, promoting educational equity, and improving educational efficiency, it has also raised concerns among scholars around the world regarding students' moral ethics, cultivation of emotional values, technological dependence, thinking deprivation, privacy, and policy making. Using Cite Space software to analyze more than 50 articles from core journals in the field of educational technology at home and abroad, this paper comprehensively summarizes the role and impact of generative AI in education up to 2023, suggests the limitations of generative AI in empowering education at present, and predicts the direction scholars will tend to research in this field in the future.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {121–127},
numpages = {7},
keywords = {ChatGPT, Education informatization, Generative artificial intelligence},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3706598.3714051,
author = {Reza, Mohi and Anastasopoulos, Ioannis and Bhandari, Shreya and Pardos, Zachary A.},
title = {PromptHive: Bringing Subject Matter Experts Back to the Forefront with Collaborative Prompt Engineering for Educational Content Creation},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714051},
doi = {10.1145/3706598.3714051},
abstract = {Involving subject matter experts in prompt engineering can guide LLM outputs toward more helpful, accurate, and tailored content that meets the diverse needs of different domains. However, iterating towards effective prompts can be challenging without adequate interface support for systematic experimentation within specific task contexts. In this work, we introduce PromptHive, a collaborative interface for prompt authoring designed to better connect domain knowledge with prompt engineering through features that encourage rapid iteration on prompt variations. We conducted an evaluation study with ten subject matter experts in math and validated our design through two collaborative prompt writing sessions and a learning gain study with 358 learners. Our results elucidate the prompt iteration process and validate the tool’s usability, enabling non-AI experts to craft prompts that generate content comparable to human-authored materials while reducing perceived cognitive load by half and shortening the authoring process from several months to just a few hours.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {148},
numpages = {22},
keywords = {Prompt Engineering, LLMs, Human-Centered AI, Math Education, Content Generation},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713853,
author = {Zhang, Zihan and Sun, Black and An, Pengcheng},
title = {Breaking Barriers or Building Dependency? Exploring Team-LLM Collaboration in AI-infused Classroom Debate},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713853},
doi = {10.1145/3706598.3713853},
abstract = {Classroom debates are a unique form of collaborative learning characterized by fast-paced, high-intensity interactions that foster critical thinking and teamwork. Despite the recognized importance of debates, the role of AI tools, particularly LLM-based systems, in supporting this dynamic learning environment has been under-explored in HCI. This study addresses this opportunity by investigating the integration of LLM-based AI into real-time classroom debates. Over four weeks, 22 students in a Design History course participated in three rounds of debates with support from ChatGPT. The findings reveal how learners prompted the AI to offer insights, collaboratively processed its outputs, and divided labor in team-AI interactions. The study also surfaces key advantages of AI usage—reducing social anxiety, breaking communication barriers, and providing scaffolding for novices—alongside risks, such as information overload and cognitive dependency, which could limit learners’ autonomy. We thereby discuss a set of nuanced implications for future HCI exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {137},
numpages = {19},
keywords = {Debate, Collaborative learning, ChatGPT, Human-AI interaction, Classroom},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3722237.3722260,
author = {Wu, Yanan and Zeng, Xiaoping and Lin, Qibei},
title = {Generative AI Integrated Educational Model for User-Centered Design},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722260},
doi = {10.1145/3722237.3722260},
abstract = {The advent of artificial intelligence (AI) has profoundly transformed the educational landscape. Many educators are exploring how AI tools can enhance learning instructional programs. However, there is less focus on how its application within design education—particularly when teaching user-centered design. This study developed an educational model utilizing AI for user-centered design curriculum. Based on design thinking theory, this model integrates ChatGPT and Midjourney into the divergent and convergent design phases to facilitate the workflow. The empirical research showed that educational model can foster students’ creativity and problem-solving skills. The findings highlight the efficacy of AI integration in curricula design and instructional practices.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {129–135},
numpages = {7},
keywords = {Generative AI, design education, design thinking, instructional design, user-centered design},
location = {
},
series = {ICAIE '24}
}

@article{10.1145/3711026,
author = {Keppler, Samantha and Sinchaisri, Wichinpong Park and Snyder, Clare},
title = {Making ChatGPT Work for Me},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711026},
doi = {10.1145/3711026},
abstract = {Increasingly, work happens through human collaboration with generative AI (e.g., ChatGPT). In this paper, we present a qualitative study of this collaboration for real-life work tasks. We focus our study on US K12 public school teachers (N = 24) who regularly design and complete text-generation tasks such as creating quizzes, slide decks, word problems, reading passages, lesson plans, classroom activities, and projects. In one-on-one video- and audio-recorded virtual sessions, we observe each teacher using ChatGPT-4 for work tasks of their choosing for 15 minutes, then debrief their experience. Analyzing 201 prompts inputted by the 24 teachers, we uncover four main modes with which the teachers request support from ChatGPT: (1) make for me (55% of prompts), (2) find for me (15%), (3) jump-start for me (10.5%), and (4) iterate with me (15.5%). The first three modes (make, find, and jump-start) are often requests of generative AI to do something, whereas the fourth mode (iterate) is a request of generative AI to think. In a follow-up survey of the same 24 teachers, most report using multiple modes for their work, but infrequently. Our study contributes new data and knowledge about how teachers are coming to understand whether and how to integrate generative AI into their teaching preparation routines.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW128},
numpages = {23},
keywords = {K12 education, generative AI, human-computer interaction}
}

@inproceedings{10.1145/3706598.3713233,
author = {Naqvi, Syeda Masooma and He, Ruichen and Kaur, Harmanpreet},
title = {Catalyst for Creativity or a Hollow Trend?: A Cross-Level Perspective on The Role of Generative AI in Design},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713233},
doi = {10.1145/3706598.3713233},
abstract = {Generative AI image creation tools have the potential to transform design education and practice, but raise critical concerns for creativity and ownership. We leverage the 2022 launch of tools like Midjourney and DALL.E as a point dividing design enthusiasts into pre- and post-tool learners. In this paper, we conduct 28 artifact-based interviews with designers at varying levels of tool introduction, to understand how they perceive and use generative AI in their design roles. Our results indicate a rift in the value system of designers, with experienced designers being more circumspect about the loss of traditional creativity and foundational design skills. On the practical side, there exists a tension between the growing marketability of AI-related skills for design vs. the limited affordances of these tools for achieving meaningful designs. We discuss implications for the shifting definitions of design as a field, creativity and ownership, and AI in the design curriculum.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {194},
numpages = {16},
keywords = {Generative AI, Design, Creativity},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3701551.3705708,
author = {Rudra, Koustav and Ganguly, Niloy and Mifsud Bonnici, Jeanne and M\"{u}ller-Budack, Eric and Manuvie, Ritumbra},
title = {Disinformation and Misinformation in the Age of Generative AI},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3705708},
doi = {10.1145/3701551.3705708},
abstract = {The rapid rise of generative AI (GenAI) technologies has revolutionized the way content is created and disseminated. As a result, highly convincing human-like malicious content including disinformation, misinformation, and propaganda can now be easily produced and distributed across the web. The diversity of generation models combined with various manipulation strategies applied to different modalities presents significant challenges for fact-checking systems and content moderation. To address this issue, we organize a workshop that focuses on harmful content that has been created intentionally (disinformation) and unintentionally (misinformation) in the era of generative AI. The workshop features specialized tracks on multimodal solutions, investigating narratives, trustworthy AI systems, and policy interventions. By bringing together experts from computer science and law, the workshop offers a comprehensive framework for combating fake content online.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {1122–1123},
numpages = {2},
keywords = {digital services act, disinformation, generative ai, misinformation, multimodal data, narratives, policy},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3716554.3716575,
author = {Andreatos, Antonios},
title = {Using ChatGPT for developing and simulating a circuit in VHDL},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716575},
doi = {10.1145/3716554.3716575},
abstract = {This article describes the experience of using ChatGPT for developing and simulating an 8253/ 8254 counter/timer in VHDL without prior knowledge of the language. An 8253/ 8254 chip contains three counters/timers, each of which can work in six different modes of operation. The design is hierarchical and was developed in steps; initially a single counter was developed and simulated; next, a higher-level module containing three such timers was developed and a particular configuration was simulated. ChatGPT suggested the proper tools for the user’s platform, the VHDL code, the testbenches, the procedure (commands) and the troubleshooting. Manual interventions were necessary for fine-tuning. The quality and accuracy of the code generated by ChatGPT were found to be proportional to the user’s specifications, which implies that the specifications must be accurate. In order to get a satisfactory result, several trials (initial specifications, simulation, review, revised specifications) were needed. What made this experiment interesting was that the author did not have prior VHDL language know-how. The experience was interesting and leaded to the following findings: ChatGPT can produce code but it is not guaranteed that it won’t have syntactical or logical errors; the quality of the generated code is directly dependent on the clarity of the specifications, otherwise the user wastes a lot of time correcting errors and re-defining specifications; ChatGPT is a valuable self-learning tool for both students and teachers providing personalized and interactive learning.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {143–147},
numpages = {5},
keywords = {8253/8254 counter/timer, VHDL, ChatGPT, simulation, specifications, learning by example, pair programming},
location = {
},
series = {PCI '24}
}

@inproceedings{10.1145/3706599.3719878,
author = {Vella, Kellie and Dobson, Madeleine and Brereton, Margot},
title = {"Hello, Mr Tree": Toying with Playful Conversational AI in the Early Years},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719878},
doi = {10.1145/3706599.3719878},
abstract = {The use of generative AI is increasingly integrated into childhood education, primarily with text-to-image generation and older age ranges. This late-breaking work looks at the use of a prototype technology using voiced conversational AI (CAI) to engage young children’s interest in nature, through the role-play of a character: the ‘Talking Tree’. Using research-through-design, we conducted six interactive sessions with children aged 3 to 5 years. These drove the iterative development of the device and provided insight into how CAI might be applied within the context of early learning. We found that the device operated within children’s performative social interactions and within their imagination to prompt recollections of nature and fantastic diversions. We contribute insight into the use of conversational AI for learning in the busy environments of early childhood education centres and the use of CAI-performed fictional characters to build children’s connection with nature.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {8},
numpages = {6},
keywords = {Child-computer interaction, design, Early childhood education, Conversational agent, Voice recognition, Digital play, Play-based learning, LLM, AI},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3685680,
author = {Annapureddy, Ravinithesh and Fornaroli, Alessandro and Gatica-Perez, Daniel},
title = {Generative AI Literacy: Twelve Defining Competencies},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {1},
url = {https://doi.org/10.1145/3685680},
doi = {10.1145/3685680},
abstract = {This article introduces a competency-based model for generative artificial intelligence (AI) literacy covering essential skills and knowledge areas necessary to interact with generative AI. The competencies range from foundational AI literacy to prompt engineering and programming skills, including ethical and legal considerations. These 12 competencies offer a framework for individuals, policymakers, government officials, and educators looking to navigate and take advantage of the potential of generative AI responsibly. Embedding these competencies into educational programs and professional training initiatives can equip individuals to become responsible and informed users and creators of generative AI. The competencies follow a logical progression and serve as a roadmap for individuals seeking to become familiar with generative AI and for researchers and policymakers to develop assessments, educational programs, guidelines, and regulations.},
journal = {Digit. Gov.: Res. Pract.},
month = feb,
articleno = {13},
numpages = {21},
keywords = {Generative AI literacy, AI literacy, data literacy, generative AI, prompt engineering, AI competencies, AI skills}
}

@inproceedings{10.1145/3702163.3702409,
author = {Zylowski, Thorsten and Sautchuk-Patricio, Nathalia and Hettmann, Wladimir and Anderer, Katharina and Fischer, Karl and W\"{o}lfel, Matthias and Henning, Peter},
title = {User Study on the Trustworthiness, Usability and Explainability of Intent-based and Large Language Model-based Career Planning Conversational Agents},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702409},
doi = {10.1145/3702163.3702409},
abstract = {Choosing a career and educational path is a challenging decision for young people. Career planning conversational agents (CAs) can assist by identifying suitable occupations and educational paths. Trustworthiness is an important dimension for the acceptance of a career planning CA and is influenced by several factors. We conducted a user study with n=114 participants across three schools in Germany to explore the trustworthiness of different career planning CAs. We examined the correlation between trustworthiness and perceived competence, autonomy, and social relatedness from self-determination theory (SDT), as well as the explainability of interactions and several usability dimensions of the assistants. These dimensions included the ability to guide the conversation, onboarding quality, error tolerance, and information relevance. We tested three different variants of the career planning assistant: a form-based assistant, an intent-based CA, and a large language model (LLM)-based CA. The results showed that the LLM-based CA was on average significantly more trustworthy and was perceived as more explainable than the intent-based CA. Key trust factors included conversation flexibility, chatbot credibility, intent recognition, and maintenance of a secure conversation. Additionally, perceived autonomy was crucial for trust across all types of assistants and perceived relatedness for the two CAs. Our findings highlight key areas essential for developing trustworthy CAs.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {46–53},
numpages = {8},
keywords = {Career Planning Conversational Agents, Explainable Artificial Intelligence, Self-Determination Theory, Trustworthy Artificial Intelligence, Usability},
location = {
},
series = {ICETC '24}
}

@article{10.1145/3735548.3729174,
author = {Holbeck, Rick},
title = {Beyond Detection: Why faculty should focus on AI literacy, not AI policing},
year = {2025},
issue_date = {05-01-2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2025},
number = {5},
url = {https://doi.org/10.1145/3735548.3729174},
doi = {10.1145/3735548.3729174},
abstract = {As generative artificial intelligence (GenAI) tools become increasingly accessible, higher education institutions must address the challenge of maintaining academic integrity while preparing students for an AI-integrated future. Institutions that rely solely on AI-detection software risk fostering adversarial learning environments due to false positives and a punitive culture. Instead, a comprehensive approach that integrates AI literacy with institutional policy can foster ethical engagement with AI. Drawing on recent literature and best practices, this article examines the limitations of detection tools. Within are proposed actionable strategies to prepare students to become responsible users of AI and enable institutions to strike a balance between innovation and academic integrity.},
journal = {ELearn},
month = jun,
articleno = {3}
}

@article{10.1145/3742939.3742941,
author = {Vardanega, T.},
title = {It Is Time to Care for Ada!},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3742939.3742941},
doi = {10.1145/3742939.3742941},
abstract = {1 A rather strange introductionI confess, I am a voracious book reader, and being (luckily) versed in quite a few tongues, I enjoy reading books frequently (but not always) without needing translation. In fact, I find languages fascinating, for all they say about people's culture, history, and traits.As a student in Computer Science in the late 1980s, I was imbued with Noam Chomsky's linguistic ''generative grammar'' theory. That theory sees specific languages as second-order derivatives of a single universal grammar, innate in the human mind. That theory, with its hierarchy of formal grammars, has laid the foundation for the theory and practice of language compilers. The principal tenet of Chomsky's theory is that grammar precedes language.},
journal = {Ada Lett.},
month = jun,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3702163.3702185,
author = {Arones, Maritza and Chauca, Carmen and Phun-Pat, Yn\'{e}s and Curro-Urbano, Olga and De La Cruz-Arones, Maritza},
title = {Heutagogical Learning and the Use of ChatGPT in the pre-professional practice of university students},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702185},
doi = {10.1145/3702163.3702185},
abstract = {The objective of the study was to establish the relationship between heutagogical learning and the use of chatGPT in the pre-professional practice of university students of the professional career of Educational Sciences in Mathematics and Computer Science at the National University “San Luis Gonzaga”. The Self-Learning Strategies Questionnaire (CETA) was used for university students, which considers six dimensions: Extension Strategies, Collaboration Strategies, Conceptualization Strategies, Planning Strategies, Exam Preparation Strategies and Participation Strategies. The sample was made up of students enrolled in the IX and X semester of the aforementioned professional career. Through univariate correlation analysis and applying Spearman's Rho test (0.587&gt;0.344, p&lt;0.05), a significant correlation between the variables is confirmed, highlighting the importance of the self-directed approach in the training of educators supported in the use from chatGPT. Additionally, specific strategies, such as outreach, collaboration, conceptualization, planning, test preparation, and participation, were found to be related to preprofessional practice success. Consequently, it is recommended to actively promote heutagogical learning and the application of these strategies in the training of educators.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {155–160},
numpages = {6},
keywords = {chatGPT, heutagogical learning, learning strategy and pre-professional practice},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3708557.3716158,
author = {Mokryn, Osnat and Shaer, Orit and Geyer, Werner and Maher, Mary Lou and Weisz, Justin D. and Buschek, Daniel and Chilton, Lydia B},
title = {HAI-GEN 2025: 6th Workshop on Human-AI Co-Creation with Generative Models},
year = {2025},
isbn = {9798400714092},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708557.3716158},
doi = {10.1145/3708557.3716158},
abstract = {Generative Artificial Intelligence (GAI) models capable of complex tasks are revolutionizing areas previously considered to define humanity, such as creativity, design, and knowledge work. Research reports that Human-GAI co-creation processes can enhance creativity and even foster a sense of empowerment. A key innovation is the intent-based outcome specification, where users define desired results through natural language, sketches, or gestures, thus shifting control from users to AI models. This paradigm enables new forms of co-creation while presenting challenges in creating effective and safe outcome specifications.This workshop aims to investigate the design, implementation, and evaluation of intent-based co-creative experiences that boost human creativity in work, play, and education across text, images, audio, code, and video. Key questions focus on how creativity support can guide generative AI development and how to leverage generative models for positive user experiences. By uniting researchers and practitioners from Human-Computer Interaction (HCI) and AI, the workshop seeks to deepen understanding of human-AI co-creative interactions and explore opportunities and challenges in developing meaningful and safe generative systems.},
booktitle = {Companion Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {179–182},
numpages = {4},
keywords = {Generative modeling, artificial intelligence, generative design, user experience, co-creation, collaboration, creativity},
location = {
},
series = {IUI '25 Companion}
}

@inproceedings{10.1145/3701551.3703563,
author = {Sagtani, Hitesh and Mehrotra, Rishabh and Liu, Beyang},
title = {Improving FIM Code Completions via Context &amp; Curriculum Based Learning},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703563},
doi = {10.1145/3701551.3703563},
abstract = {Fill-in-the-Middle (FIM) models play a vital role in code completion tasks, leveraging both prefix and suffix context to provide more accurate and contextually relevant suggestions. This paper presents approaches to improve FIM code completion while addressing the challenge of maintaining low latency for real-time coding assistance. We enhance FIM code completion by incorporating context and curriculum examples in the training process. We identify patterns where completion suggestions fail more frequently, revealing complexities that smaller language models struggle with. To address these challenges, we develop a curriculum dataset by extracting hard-to-complete patterns from code repositories and generate context examples using semantic and static analysis tools (e.g. TSC compiler). We fine-tune various sized models, including StarCoder and DeepSeek, on this enhanced dataset. Our evaluation encompasses three key dimensions: the Santa Coder FIM task, the Amazon CCEval benchmark, and a new Multi-Line Infilling evaluation benchmark derived from SWE-bench. Comprehensive ablation studies across multiple model sizes reveal that while all fine-tuned models show improvements, the performance gains are more pronounced for smaller parameter models and that incorporating difficult-to-complete examples as part of curriculum learning improves completion performance. This finding is particularly sig- nificant given the latency constraints of code completion tasks. While larger models like GPT and Claude perform well in multi- line completions but are prohibitively challenging to use given high latency, and our fine-tuned models achieve a balance between per- formance and latency. Finally, we validate our approach through online A/B testing, demonstrating tangible improvements in Completion Acceptance Rate (CAR) and Completion Persistence Rate (CPR), with zero latency impact.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {801–810},
numpages = {10},
keywords = {a/b-testing, code completions, large language model},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.5555/3721488.3721731,
author = {Shaik, Khaja Ahmed and Xie, Shengyuan and Cruz, Francisco and Sandoval, Eduardo Benitez},
title = {A Fuzzy Supervisory Framework for Real-Time Optimization of Robot Output and LLM Performance in HRI},
year = {2025},
publisher = {IEEE Press},
abstract = {Human-robot interaction plays a vital role in pushing the capabilities of socially interactive robots by enabling them to deliver content with high emotional intelligence. This research focuses on a supervisory fuzzy framework for constantly evaluating and improving the content delivered by the robot utilizing multi-modal inputs and advanced intelligent algorithms. The main reason for using fuzzy logic is that it mimics human decision-making by providing a percentage-based measure of closeness. In this project, ARI Robot is being used with an LLM integration, which enables the user to communicate with the robot. Different algorithms were integrated for the classification of multimodal inputs, BERT (transfer-biased encoder representations) for the classification of content, Wav2Vec 2.0 for classifying the tone of the user while interacting with the robot, and OpenFace for classifying the facial expression of the user. All of these inputs are then supervised by a fuzzy system with predefined rules to evaluate the content delivered and provide feedback for refinement. The proposed framework ensures an overall evaluation of content delivery, providing intelligent feedback to the ARI robot to improve interaction quality. By integrating these advanced models with fuzzy logic, the system mimics human-like judgment in assessing the interaction of verbal and non-verbal indications, making the way for emotionally intelligent robots in a social world.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {1617–1620},
numpages = {4},
keywords = {fuzzy system, human robot interaction, multi-modality},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3702163.3702179,
author = {Mohd A'seri, Muhamad Safwan and Mahmud, Malissa Maria and Yaacob, Yazilimiwati and Ahmad, Rozaini and Nagasundram, Usha and Mustamam, Nur Izzati},
title = {Beyond the Textbook: A Study of ChatGPT Patterns of Use Perceptions and Experiences Among Students in Higher Education},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702179},
doi = {10.1145/3702163.3702179},
abstract = {This study investigates the utilization pattern, perception, and experience of Higher Education Institutes (HEIs) students towards the ChatGPT application in an academic context. It employs a quantitative approach utilizing a questionnaire as the research instrument. The study sample was selected using a simple random sampling method from Sunway University and Sunway College in Kuala Lumpur, Malaysia. The survey participants, enrolled in General Studies Subjects (MPU) during their short semester between September and December 2023, were selected using a simple random sampling method. Out of 150 students who received the survey via Google Forms, 119 provided complete responses suitable for analysis. The research primarily focused on calculating mean scores to assess three key dimensions: its use patterns of ChatGPT, perceptions and experiences among students towards its adoption in educational contexts. A descriptive analysis was conducted to determine student frequency and percentage values for ChatGPT usage. At the same time, mean scores were utilized to evaluate higher education institutes (HEIs) students' perceptions and experiences with the application in an academic context. This descriptive analysis revealed a spectrum of responses that ranged from low to very high levels across these dimensions. The findings of this study offer extensive insight into the current incorporation and perception of ChatGPT within Higher Education Institutions (HEIs), showcasing the diverse range of engagement and acceptance levels among students.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, Experiences, Higher education institutions, Perceptions, Use patterns},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3706598.3713748,
author = {Ma, Shuai and Wang, Junling and Zhang, Yuanhao and Ma, Xiaojuan and Wang, April Yi},
title = {DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713748},
doi = {10.1145/3706598.3713748},
abstract = {Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners’ decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners’ personalized construction of a step tree through a “learner-LLM co-decomposition” approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox’s impact on cognitive load, identified usage patterns, and analyzed learners’ strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {20},
keywords = {Programming Learning, Self-Paced Learning, Large Language Models, AI for Coding, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3711403.3711436,
author = {Jiang, Ruishuang and He, Xiangchun and Zhang, Shaojun and Zhou, Yaxin and Han, Yuqi},
title = {Generative Artificial Intelligence Enables Multiple Learning Environments and Implementation Paths},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711436},
doi = {10.1145/3711403.3711436},
abstract = {This paper explores the application of generative artificial intelligence in the field of education and its potential to enhance multiple learning environments. Generative AI is a powerful tool capable of simulating human creativity and imagination, and has demonstrated its potential across various fields. In the realm of education, generative AI can offer personalized learning support to students, addressing issues associated with traditional teaching models and unequal resource distribution. This paper delves into the specific application pathways and optimization strategies for generative AI in physical, resource-based, technical, and emotional learning environments. Additionally, it proposes policy recommendations, teacher training initiatives, student experience design considerations, and corporate responsibility measures aimed at implementing generative AI to enable diverse learning environments. These efforts are intended to ensure that the application of generative AI in education fully realizes its potential while addressing ethical, equity-related, and sustainability concerns.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {187–193},
numpages = {7},
keywords = {Generative artificial intelligence, Learning environment, Technology enabling},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3713081.3732931,
author = {Guo, Yongjian and Ma, Wanlun and Xiao, Xi and Wen, Sheng and Di, Peng and Zhu, Xiaogang},
title = {Patch the Leak: Strengthening CodeLLMs Against Privacy Extraction Threats},
year = {2025},
isbn = {9798400714740},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3713081.3732931},
doi = {10.1145/3713081.3732931},
abstract = {CodeLLMs tend to memorize their training data and can reconstruct personal information (PI) when given specific prompts. Despite the application of privacy anonymization methods to remove PI in foundational LLMs, the previous experiments using state-of-the-art PI extraction attacks like CODEBREAKER and CodexLeaks on multiple open-source and commercial CodeLLMs demonstrate that such information cannot be fully eliminated. Furthermore, we found that commercial models exhibit significantly lower leakage rates (approximately 20% lower) compared to open-source models, and we hypothesize this is related to the stronger model alignment. Addressing the lack of effective defenses against PI extraction, we treat PI leakage as a form of misalignment and propose PI-ALIGN, a novel framework inspired by adversarial learning. PI-ALIGN pairs CodeLLMs with the CODEBREAKER attack framework as an adversarial dual model and leverages the optimized GRPO (Group Relative Policy Optimization) process to realign the model during fine-tuning. This approach is expected to enhance the model's robustness against PI extraction attacks by adversarially training it against CODEBREAKER. We also outline our experimental evaluation framework to systematically validate PI-ALIGN's effectiveness, aiming to provide insights into countering PI extraction attacks on CodeLLMs.},
booktitle = {Proceedings of the 34th ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {195–199},
numpages = {5},
keywords = {extraction attacks, CodeLLMs, privacy protection, personal information},
location = {Clarion Hotel Trondheim, Trondheim, Norway},
series = {ISSTA Companion '25}
}

@article{10.1145/3716167,
author = {Le-Cong, Thanh and Nguyen, Thanh-Dat and Le, Bach and Murray, Toby},
title = {Towards Reliable Evaluation of Neural Program Repair with Natural Robustness Testing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3716167},
doi = {10.1145/3716167},
abstract = {Automated program repair (APR) has recently gained ground, with numerous research efforts being conducted in the area that have been adopted in the industry. One notable class of APR is neural program repair (NPR), which typically employs deep learning techniques that are trained on vast amounts of historical data to fix bugs that have not been seen in the past. To study the true effectiveness of NPR on existing limited datasets, recent work augments the evaluation data by employing semantics-preserving transformations to convert original buggy programs to semantically equivalent ones. Experiments show that NPR techniques are not robust; e.g., NPR cannot repair semantically equivalent counterparts of 20%-35% of bugs that they can repair in the original dataset. However, we found that many of these transformations are unnatural, that are unlikely to occur in real-world scenarios, leading to misleading conclusions about NPR effectiveness and misguide the improvement on unrobust behaviors, which have minimal real-world impact.In this paper, we propose shifting the focus of robustness evaluation for NPR techniques towards naturally occurring data transformations. To accomplish this, we first examine the naturalness of semantic-preserving transformations through a two-stage human study. This study includes: (i) interviews with senior software developers to establish concrete criteria for evaluating the naturalness of these transformations, and (ii) a survey involving 10 developers to assess the naturalness of 1,178 transformations, i.e., pairs of original and transformed programs, applied to 225 real-world bugs. Our findings show that only 60% of these transformations are considered natural, while 20% are considered unnatural, with strong agreement among the annotators. Moreover, the unnaturalness of these transformations significantly impacts both their applicability to benchmarks and the conclusions drawn from robustness testing.Next, we conduct natural robustness tests on NPR techniques to assess their true effectiveness against real-world data variations. Our experimental results reveal a substantial number of prediction changes in NPR techniques, leading to significant reductions in both plausible and correct patch rates when comparing performance on the original and transformed datasets. Furthermore, we observe notable differences in performance improvements between NPR techniques, suggesting potential biases in the evaluation of NPR introduced by limited datasets. Finally, we explore automating the assessment of transformation naturalness by developing a new naturalness metric, namely RNC, using Large Language Models. This metric effectively evaluates naturalness with an AUC of 0.7, offering a promising direction for automating the naturalness assessment of code transformations.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = feb,
keywords = {Automated Program Repair, Natural Robustness, Code Naturalness, Code Transformations}
}

@article{10.1145/3710953,
author = {Chen, Si and Cheng, Haocong and Su, Suzy and Patterson, Stephanie and Kushalnagar, Raja and Huang, Yun and Wang, Qi},
title = {Customizing Generated Signs and Voices of AI Avatars: Deaf-Centric Mixed-Reality Design for Deaf-Hearing Communication},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3710953},
doi = {10.1145/3710953},
abstract = {This study investigates innovative interaction designs for communication and collaborative learning between learners of mixed hearing and signing abilities, leveraging advancements in mixed reality technologies like Apple Vision Pro and generative AI for animated avatars. Adopting a participatory design approach, we engaged 15 d/Deaf and hard of hearing (DHH) students to brainstorm ideas for an AI avatar with interpreting ability (sign language to English and English to sign language) that would facilitate their face-to-face communication with hearing peers. Participants envisioned the AI avatars to address some issues with human interpreters, such as lack of availability, and provide affordable options to expensive personalized interpreting services. Our findings indicate a range of preferences for integrating the AI avatars with actual human figures of both DHH and hearing communication partners. The participants highlighted the importance of having control over customizing the AI avatar, such as AI-generated signs, voices, facial expressions, and their synchronization for enhanced emotional display in communication. Based on our findings, we propose a suite of design recommendations that balance respecting sign language norms with adherence to hearing social norms. Our study offers insights into improving the authenticity of generative AI in scenarios involving specific and sometimes unfamiliar social norms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW055},
numpages = {31},
keywords = {american sign language, facial expressions, interpreter, multi-modality, voice generation}
}

@inproceedings{10.1145/3706598.3714233,
author = {Earle, Sam and Parajuli, Samyak and Banburski-Fahey, Andrzej},
title = {DreamGarden: A Designer Assistant for Growing Games from a Single Prompt},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3714233},
doi = {10.1145/3706598.3714233},
abstract = {Coding assistants are increasingly leveraged in game design, both generating code and making high-level plans. To what degree can these tools align with developer workflows, and what new modes of human-computer interaction can emerge from their use? We present DreamGarden, an AI system capable of assisting with the development of diverse game environments in Unreal Engine. At the core of our method is an LLM-driven planner, capable of breaking down a single, high-level prompt—a dream, memory, or imagined scenario provided by a human user—into a hierarchical action plan, which is then distributed across specialized submodules facilitating concrete implementation. This system is presented to the user as a garden of plans and actions, both growing independently and responding to user intervention via seed prompts, pruning, and feedback. Through a user study, we explore design implications of this system, charting courses for future work in semi-autonomous assistants and open-ended simulation design.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {57},
numpages = {19},
keywords = {Game design assistants, 3D asset generation, large language models, visual feedback},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3720120,
author = {Zhang, He and Zha, Siyu and Cai, Jie and Wohn, Donghee Yvette and Carroll, John M.},
title = {Generative AI in Virtual Reality Communities: A Preliminary Analysis of the VRChat Discord Community},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720120},
doi = {10.1145/3706599.3720120},
abstract = {As immersive social platforms like VRChat increasingly adopt generative AI (GenAI) technologies, it becomes critical to understand how community members perceive, negotiate, and utilize these tools. In this preliminary study, we conducted a qualitative analysis of VRChat-related Discord discussions, employing a deductive coding framework to identify key themes related to AI-assisted content creation, intellectual property disputes, and evolving community norms. Our findings offer preliminary insights into the complex interplay between the community’s enthusiasm for AI-driven creativity and deep-rooted ethical and legal concerns. Users weigh issues of fair use, data ethics, intellectual property, and the role of community governance in establishing trust. By highlighting the tensions and trade-offs as users embrace new creative opportunities while seeking transparency, fair attribution, and equitable policies, this research offers valuable insights for designers, platform administrators, and policymakers aiming to foster responsible, inclusive, and ethically sound AI integration in future immersive virtual environments.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {305},
numpages = {11},
keywords = {Human-ai collaboration, AI assistant, user experience, online community},
location = {
},
series = {CHI EA '25}
}

@article{10.1145/3710911,
author = {Andrus, McKane and Ghoshal, Sucheta and Dasgupta, Sayamindu},
title = {From Data Activism to Activism in a Time of Data-Centrism: Affirming Epistemological Heterogeneity in Social Movements},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3710911},
doi = {10.1145/3710911},
abstract = {In this paper, we seek to understand how grassroots activists, operating within the hegemony of data-centrism, are often disempowered by data even as they appropriate it towards their own ends. We posit that the shift towards data-driven governance and organizing, by elevating a particular epistemology, can pave over other ways of knowing that are central to social movement practices. Building on Muravyov's [102] concept of ''epistemological ambiguity,'' we demonstrate how data-focused activism requires complex navigations between data-based epistemologies and the heterogeneous, experiential, and relational epistemologies that characterize social movements. Through three case studies (two drawn from existing literature and the third being an original analysis), we provide an analytical model of how generative epistemological refusals can support more value-aligned navigations of epistemological ambiguity that resist data-centrism. Finally, we suggest how these findings can inform pedagogy, research, and technology design to support communities navigating datafied political arenas.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW013},
numpages = {32},
keywords = {counter-data, critical data literacy, data activism, data epistemologies, data justice, grassroots social movements, housing justice, refusal}
}

@inproceedings{10.1145/3672608.3707909,
author = {Zambach, Sine},
title = {AI-Enhanced Learning: Comparing Outcomes in Introductory and Advanced Programming Courses},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707909},
doi = {10.1145/3672608.3707909},
abstract = {Generative AI chatbots have recently transformed education, necessitating new teaching methods for this paradigm. This study compares the impact of generative AI on introductory and advanced programming courses in fall 2023. Advanced students showed better outcomes, while the performance of introductory students remained unchanged or declined. This highlights the need for tailored AI integration strategies based on students' skill levels.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {104–105},
numpages = {2},
keywords = {teaching, higher education, chatbots, generative AI},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706599.3720244,
author = {Beaumont, Kimberley and Oravec, Martin and Emerson, Harry and Penton-Voak, Ian and Houghton, Conor},
title = {Can LLMs be used to Quantify the Emotional Salience of Text Statements using an Elo Rating System?},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720244},
doi = {10.1145/3706599.3720244},
abstract = {When studying mood or affective state it is useful to collect free-text input from participants relevant to their mood alongside traditional assessment batteries. Quantifying free-text data in relation to quantitative measures remains a challenge. We propose a novel application of an Elo rating system for analysing verbatim human text descriptions of emotionally salient experiences. By leveraging crowdsourced pairwise comparisons, our approach preserves the richness of free-text data while generating a quantitative representation. We apply the same approach to various LLMs to compare their performance against humans. Regression analyses indicate that rankings generated by LLMs significantly predict human rankings (p &lt; 0.001), demonstrating strong explanatory power across models (R2 = 0.760–0.803). Applying LLMs to this task offers the added advantages of greater efficiency and lower cost. We discuss the potential applications of this method in human research and explore critical considerations regarding the use of LLMs in emotionally relevant tasks.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {10},
keywords = {Large language model, Emotion Research, Pairwise Comparisons, Elo Rating, Crowdsourced, Life Events},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3711403.3711438,
author = {Zhang, Shaojun and He, Xiangchun and Zhou, Yaxin and Jiang, Ruishuang and Han, Yuqi and Guo, Xue},
title = {Artificial Intelligence Helps Teachers Personalise Their Teaching--Take ChatGPT as an Example},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711438},
doi = {10.1145/3711403.3711438},
abstract = {With the continuous development of science and technology, Artificial Intelligence (AI) has become an important driving force for innovation in the field of education, especially advanced AI language models such as ChatGPT, which shows great potential in assisting teachers to design, implement and evaluate personalised teaching due to its excellent language comprehension and generative ability. Nevertheless, how to use ChatGPT to help teachers carry out personalised teaching has yet to be explored. Therefore, this paper explores and analyses the ways in which ChatGPT can help teachers carry out personalised teaching based on the connotation of ChatGPT and personalised teaching, and discusses the challenges faced when using ChatGPT to assist teachers in carrying out personalised teaching, from the perspective of the three aspects of teaching: lesson planning, instruction, and evaluation and feedback. It also discusses the challenges faced when using ChatGPT to assist teachers in personalised teaching and proposes strategies to address them. The study shows that artificial intelligence can make teachers more scientific, precise, intelligent and diversified in the process of implementing personalised teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {200–205},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Personalised Teaching},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3702386.3702392,
author = {Maurat, John Ivan Curbano and Isip, Elsie Villareal and Lumabas, Aileen Gail Regala},
title = {A Comparative Study of Gender Differences in the Utilization and Effectiveness of AI-Assisted Learning Tools in Programming Among University Students},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702392},
doi = {10.1145/3702386.3702392},
abstract = {This comparative study examines gender differences in the use and efficacy of AI-assisted learning tools for programming among university students. A survey-based methodology was used to collect data from a varied sample of students across different academic years, ensuring representation from diverse demographic groups. The study sought to investigate the frequency of AI tool use and students' assessments of their efficacy in learning programming fundamentals. Notably, the findings reveal that students overwhelmingly prefer ChatGPT as the primary AI tool for learning programming concepts, with 312 mentions, making it the most popular and presumably the most useful tool among respondents. Following ChatGPT, Blackbox AI was the second most mentioned, with 74 students highlighting its utility. Gemini, Co-pilot, Assistguru, and Amazon Code Whisperer followed in popularity, with varying levels of student engagement and perceived usefulness. The study also found a substantial positive association (r = 0.296, p &lt; 0.05) between AI tool usage frequency and perceived effectiveness in programming education, indicating the potential benefits of increased interaction with AI tools. Gender disparities in tool preferences were identified, with male students showing a preference for specific instruments over their female counterparts. Despite these differences, there was little variation in the overall perceived efficacy of AI technology between genders. Furthermore, first-year students exhibited the highest frequency of AI tool usage, particularly on a weekly basis, emphasizing the importance of early exposure on usage patterns throughout students' academic careers. These findings underscore the necessity of considering gender preferences and demographics when developing and implementing AI-powered educational systems. The study recommends individualized approaches to enhance inclusivity and effectiveness in programming education, aiming to inform future advancements in educational technology and pedagogy.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {30–34},
numpages = {5},
keywords = {Educational Technology, Gender Differences, Learning Outcomes, Programming, User Preferences},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3708359.3712080,
author = {Shu, Xin and Shi, Lei and Cheng, Jiacheng and Ouyang, Lingling and Chu, Mengdi and Shu, Xinhuan},
title = {FretMate: ChatGPT-Powered Adaptive Guitar Learning Assistant},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712080},
doi = {10.1145/3708359.3712080},
abstract = {Learning to play the guitar poses significant challenges for beginners, who often choose to practice alone to avoid the embarrassment of making mistakes in front of others. This isolation leads to a lack of timely feedback and encouragement, resulting in frustration and decreased motivation. Traditional learning methods fail to provide personalized and immediate support. To address these issues, we propose a GPT-powered guitar learning assistant, FretMate, that provides immediate error correction, personalized learning paths, and emotional support. The design was informed by formative interviews with six guitar instructors and six learners. We evaluated our assistant against the traditional self-guided practice in a controlled two-week study with 16 participants. Results showed that participants using FretMate improved in skill acquisition, engagement, and motivation compared to the control group. We discuss the potential of integrating conversational AI into instrument learning to provide personalized instruction and emotional engagement.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {715–726},
numpages = {12},
keywords = {Guitar Education, AI-driven Feedback, Personalized Learning, Music Theory Integration, Emotional Support, ChatGPT},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3708359.3712134,
author = {Maiti, Pratyusha and Goel, Ashok},
title = {Can an AI Partner Empower Learners to Ask Critical Questions?},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712134},
doi = {10.1145/3708359.3712134},
abstract = {Jill Watson is an LLM-powered conversational AI partner integrated with instructor-provided courseware, offering learners contextually relevant and immediately applicable support. This study examines learner-generated questions as part of organic interactions with Jill embedded within classroom Learning Management System and investigates whether Jill empowers learners to ask higher-order questions. Leveraging Bloom’s Taxonomy to assess question complexity, we collected over 5500 student questions from classroom deployments across three academic semesters and two educational settings. Student questions were classified using a fine-tuned BERT model and regression models were used to analyze the trends of complexity of the questions over time. Our results reveal a significant proportion of higher-order questions being asked in our classrooms, exceeding typical educational distributions. We also found a statistically significant increase in higher-order questioning with sustained interaction with Jill. These findings demonstrate that Jill empowers learners to engage in critical questioning, thereby enhancing their educational experience by promoting depth, relevance, and application of course concepts. Further research is recommended with larger and more diverse samples to generalize these findings.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {314–324},
numpages = {11},
keywords = {Conversational AI Agents, Question Answering, Virtual Teaching Assistant},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3706599.3719736,
author = {Tan, Yugin and Soh, Kai Xin and Zhang, Renwen and Lee, Jungup and Meng, Han and Sen, Biswadeep and Lee, Yi-Chieh},
title = {Empowering Social Service with AI: Insights from a Participatory Design Study with Practitioners},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719736},
doi = {10.1145/3706599.3719736},
abstract = {In social service, administrative burdens and decision-making challenges often hinder practitioners from performing effective casework. Generative AI (GenAI) offers significant potential to streamline these tasks, yet exacerbates concerns about overreliance, algorithmic bias, and loss of identity within the profession. We explore these issues through a two-stage participatory design study. We conducted formative co-design workshops (n=27) to create a prototype GenAI tool, followed by contextual inquiry sessions with practitioners (n=24) using the tool with real case data. We reveal opportunities for AI integration in documentation, assessment, and worker supervision, while highlighting risks related to GenAI limitations, skill retention, and client safety. Drawing comparisons with GenAI tools in other fields, we discuss design and usage guidelines for such tools in social service practice.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {219},
numpages = {10},
keywords = {AI Decision-Making, Human-AI collaboration, LLM, Social Service},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3720032,
author = {Ko, Eunhye Grace and Nanayakkara, Shaini and Huff, Earl W},
title = {"We need to avail ourselves of [GenAI] to enhance knowledge distribution": Empowering Older Adults through GenAI Literacy},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720032},
doi = {10.1145/3706599.3720032},
abstract = {As generative AI (GenAI) becomes increasingly ubiquitous, it is crucial to equip users, particularly vulnerable populations like older adults (65+), with the knowledge to understand its benefits and potential risks. Older adults often face greater reservations about adopting emerging technologies and require tailored literacy support. Using a mixed methods approach, this study examines strategies for delivering GenAI literacy to older adults through a chatbot named Litti, evaluating its impact on their Al literacy (knowledge, safety, and ethical use). The quantitative data showed a trend toward improved AI literacy, though the results were not statistically significant. However, the qualitative interviews revealed diverse levels of familiarity with generative AI, along with a strong desire to learn more. Qualitative findings also show that although Litti provided a positive learning experience, it did not significantly enhance participants’ trust or sense of safety regarding GenAI. This exploratory case study highlights the challenges and opportunities in designing AI literacy education for the rapidly growing older adult population.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {34},
numpages = {7},
keywords = {generative artificial intelligence, AI literacy, older adults},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3711403.3711457,
author = {Zhao, Dong and Zhang, Dan and Ma, Xiujuan},
title = {The Application of Generative Artificial Intelligence in the Teaching of Engineering Courses in Chinese Universities},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711457},
doi = {10.1145/3711403.3711457},
abstract = {Generative Artificial Intelligence (GenAI) is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, the use of GenAI in education raises ethical concerns such as the potential impact on critical thinking skills and the unethical or dishonest use by students. This paper analyzed the main problems existing in engineering courses in Chinese universities firstly and then proposed corresponding teaching reform measures based on the comprehensive consideration of the benefits and threats of GenAI. We applied the proposed teaching reform measures in the teaching of engineering courses, which greatly improved the teaching quality.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {328–332},
numpages = {5},
keywords = {Chinese universities, Engineering courses, Generative Artificial Intelligence, Higher education, Teaching reform},
location = {
},
series = {ICETM '24}
}

@article{10.5555/3711988.3711989,
author = {Tham, Jason},
title = {Teaching UX: Amid the Hype of Generative AI},
year = {2025},
issue_date = {November 2024},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {20},
number = {1},
issn = {1931-3357},
abstract = {I am a faculty member in a technical communication program at a comprehensive research university. Recently, I have been inundated with questions, concerns, and critiques about the rise of augmentation technologies in writing and design processes, particularly generative artificial intelligence (AI) tools that support chat-based text generation and text-to-image production. I'm sure many UX researchers and designers face similar issues in their work. It remains unclear how generative AI should fit into existing workflow or design processes. Common questions include these:• How does AI work? What can it do? Is it free?• Is it cheating if I use AI to produce content?• Who is responsible for the quality of AI-generated content?• To what extent can I outsource my routine work to AI? In other words, what's an acceptable threshold for using AI before it is considered too much?Specific to UX is the value (cost and labor versus gains and effects) of generative AI in the research and design of user-centered products. Students in my UX courses are increasingly worried about the presence of AI and, consequently, the relevance of their developing skill sets in UX. Educators are growing wary about the presence of AI in the context of teaching and learning; many form partially informed decisions on academic policies for AI usage.},
journal = {J. User Exper.},
month = feb,
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/3706599.3719728,
author = {Park, Kieun and Song, Hyungwoo and Seo, Seungbae and Kim, Junghwan and Suh, Bongwon},
title = {"Ask Sir Oliver Ingham": LLM-based Social Simulations for History Education},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719728},
doi = {10.1145/3706599.3719728},
abstract = {Authentic historical inquiry supports deeper historical understanding, yet it is often underutilized due to time constraints and limited instructional tools. This study investigates the feasibility and potential of an LLM-based historical simulation platform designed to balance immersive student engagement with teacher-directed customization. We developed a prototype that provides interactive historical contexts, AI-driven character conversations, and structured quests, while allowing teachers to adapt maps, characters, and content. Fifteen elementary and middle school teachers evaluated its feasibility through think-aloud protocols and in-depth interviews. Participants reported high usability and indicated benefits such as flexible customization, multi-perspective learning, and self-paced inquiry. Although concerns over AI limitations emerged, participants noted that such challenges can be addressed through appropriate instructional strategies which are currently used in-practice. This study introduces a novel instructional tool, offers insights into teachers’ perspectives on LLM-based simulations and highlights opportunities to enhance historical thinking and AI literacy.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {2},
numpages = {13},
keywords = {Large Language Models, History Education, Social Simulation, Teacher Evaluation},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3713393,
author = {Adnin, Rudaiba and Pandkar, Atharva and Yao, Bingsheng and Wang, Dakuo and Das, Maitraye},
title = {Examining Student and Teacher Perspectives on Undisclosed Use of Generative AI in Academic Work},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713393},
doi = {10.1145/3706598.3713393},
abstract = {With the widespread adoption of Generative Artificial Intelligence (GenAI) tools, ethical issues are being raised around the disclosure of their use in publishing, journalism, or artwork. Recent research has found that college students are increasingly using GenAI tools; however, we know less about when, why, and how they choose to hide or disclose their use of GenAI in academic work. To address this gap, we conducted an online survey (n=97) and interviews with fifteen college students followed by interviews with nine teachers who had experience with students’ undisclosed use of GenAI. Our findings elucidate the strategies students employ to hide their GenAI use and their justifications for doing so, alongside the strategies teachers follow to manage such non-disclosure. We unpack students’ non-disclosure of GenAI through the lens of cognitive dissonance and discuss practical considerations for teachers and students regarding ways to promote transparency in GenAI use in higher education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1071},
numpages = {17},
keywords = {Generative AI, undisclosed use, college students, AI in education},
location = {
},
series = {CHI '25}
}

@article{10.1613/jair.1.17403,
author = {Phan, Thomy and Phan, Timy and Koenig, Sven},
title = {Generative Curricula for Multi-Agent Path Finding via Unsupervised and Reinforcement Learning},
year = {2025},
issue_date = {May 2025},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {82},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.17403},
doi = {10.1613/jair.1.17403},
abstract = {Multi-Agent Path Finding (MAPF) is the challenging problem of finding collision-free paths for multiple agents, which has a wide range of applications, such as automated warehouses, smart manufacturing, and traffic management. Recently, machine learning-based approaches have become popular in addressing MAPF problems in a decentralized and potentially generalizing way. Most learning-based MAPF approaches use reinforcement and imitation learning to train agent policies for decentralized execution under partial observability. However, current state-of-the-art approaches suffer from a prevalent bias to micro-aspects of particular MAPF problems, such as congestions in corridors and potential delays caused by single agents, leading to tight specializations through extensive engineering via oversized models, reward shaping, path finding algorithms, and communication. These specializations are generally detrimental to the sample efficiency, i.e., the learning progress given a certain amount of experience, and generalization to previously unseen scenarios. In contrast, curriculum learning offers an elegant and much simpler way of training agent policies in a step-by-step manner to master all aspects implicitly without extensive engineering. In this paper, we propose a generative curriculum approach to learning-based MAPF using Variational Autoencoder Utilized Learning of Terrains (VAULT). We introduce a two-stage framework to (I) train the VAULT via unsupervised learning to obtain a latent space representation of maps and (II) use the VAULT to generate curricula in order to improve sample efficiency and generalization of learning-based MAPF methods. For the second stage, we propose a bi-level curriculum scheme by combining our VAULT curriculum with a low-level curriculum method to improve sample efficiency further. Our framework is designed in a modular and general way, where each proposed component serves its purpose in a black-box manner without considering specific micro-aspects of the underlying problem. We empirically evaluate our approach in maps of the public MAPF benchmark set as well as novel artificial maps generated with the VAULT. Our results demonstrate the effectiveness of the VAULT as a map generator and our VAULT curriculum in improving sample efficiency and generalization of learning-based MAPF methods compared to alternative approaches. We also demonstrate how data pruning can further reduce the dependence on available maps without affecting the generalization potential of our approach.},
journal = {J. Artif. Int. Res.},
month = apr,
numpages = {64},
keywords = {human computer interaction, human rights, human rights risks}
}

@article{10.1145/3731756,
author = {Ma, Qianou and Peng, Weirui and Yang, Chenyang and Shen, Hua and Koedinger, Kenneth and Wu, Tongshuang},
title = {What Should We Engineer in Prompts? Training Humans in Requirement-Driven LLM Use},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1073-0516},
url = {https://doi.org/10.1145/3731756},
doi = {10.1145/3731756},
abstract = {Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot) needs humans to clearly articulate customized requirements (e.g., “start the response with a tl;dr”). However, existing prompt engineering instructions often lack focused training on requirement articulation and instead tend to emphasize increasingly automatable strategies (e.g., tricks like adding role-plays and “think step-by-step”). To address the gap, we introduce Requirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human attention on generating clear, complete requirements during prompting. We implement ROPE through an assessment and training suite that provides deliberate practice with LLM-generated feedback. In a randomized controlled experiment with 30 novices, ROPE significantly outperforms conventional prompt engineering training (20% vs. 1% gains), a gap that automatic prompt optimization cannot close. Furthermore, we demonstrate a direct correlation between the quality of input requirements and LLM outputs. Our work paves the way to empower more end-users to build complex LLM applications.},
note = {Just Accepted},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = apr,
keywords = {LLM, Human-AI Interaction, Prompt Engineering, Requirement Engineering, End-User Programming}
}

@inproceedings{10.1145/3706598.3713510,
author = {Tanksley, Tiera and Smith, Angela D. R. and Sharma, Saloni and Huff, Earl W},
title = {"Ethics is not neutral": Understanding Ethical and Responsible AI Design from the Lenses of Black Youth},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713510},
doi = {10.1145/3706598.3713510},
abstract = {The rise of generative AI has brought a host of challenges for historically marginalized groups, including increased surveillance, AI-mediated racism, and algorithmic inequity. While stakeholders emphasize ethical and responsible AI that is safe, anti-discriminatory, and “protects human dignity,” the centrality of anti-Blackness in the design, development, and deployment of AI systems coupled with race-evasive approaches to defining and advancing ethical, equitable, and ‘human-centered’ technologies have exacerbated racial oppression. We present three case studies of speculative technologies designed by Black youth in a college bridge, summer course that examine ethical and responsible AI in their everyday lives. From a bottom-up approach, we infringe upon this broader discourse to provide an initial grounding of responsible and ethical AI as well as discuss the criticality of Black, historically anchored, culturally-situated lenses to offer justice-oriented design principles that can guide the teaching, learning, and design of technology.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {200},
numpages = {20},
keywords = {Black youth, responsible AI, ethical AI, social justice, anti-racism, design principles, race},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3708394.3708455,
author = {Lv, Jiayan and Yao, Jinfang and Zhu, He},
title = {Research on the Cultivation of Teacher Candidates from the Perspective of AI Empowerment with Sentiment analysis},
year = {2025},
isbn = {9798400710650},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708394.3708455},
doi = {10.1145/3708394.3708455},
abstract = {Over the past decade, with the advancement of technology, chatbots have become a hotspot in the field of artificial intelligence (AI) and are widely used in consumer services, education, search engines, marketing, and other fields. Among them, the Chat Generative Pre-Trained Transformer (ChatGPT), composed of language models and optimization techniques, is leading a transformation in human-computer interaction methods. This study selects the social media platforms "REDnote" and "Weibo" as the research field to explore the role and impact of ChatGPT in education and industry ecosystems. This work examines public sentiment regarding the application of AI in educational ecosystems and talent development by analyzing social media discussions. The sentiment analysis conducted using advanced machine learning models, highlights the prevalence of positive emotions toward ChatGPT's role in enhancing teaching and learning experiences. Furthermore, this study introduces an AI-based dynamic talent cultivation model, rooted in the "3H" (Head, Hand, Heart) framework, which emphasizes cognitive skills, practical capabilities, and emotional intelligence.},
booktitle = {Proceeding of the 2024 International Conference on Artificial Intelligence and Future Education},
pages = {358–364},
numpages = {7},
keywords = {Artificial Intelligence, ChatGPT, Deep Learning, Machine Learning, Normal Education, Social Media, Talent Cultivation, User Experience},
location = {
},
series = {AIFE '24}
}

@article{10.1145/3701198,
author = {Wang, Tianjia and Wu, Tong and Liu, Huayi and Brown, Chris and Chen, Yan},
title = {Generative Co-Learners: Enhancing Cognitive and Social Presence of Students in Asynchronous Learning with Generative AI},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701198},
doi = {10.1145/3701198},
abstract = {Cognitive presence and social presence are crucial for a comprehensive learning experience. Despite the flexibility of asynchronous learning environments to accommodate individual schedules, the inherent constraints of asynchronous environments make augmenting cognitive and social presence particularly challenging. Students often face challenges such as a lack of timely feedback and support, an absence of non-verbal cues in communication, and a sense of isolation. To address this challenge, this paper introduces Generative Co-Learners, a system designed to leverage generative AI-powered agents, simulating co-learners supporting multimodal interactions, to improve cognitive and social presence in asynchronous learning environments. We conducted a study involving 12 student participants who used our system to engage with online programming tutorials to assess the system's effectiveness. The results show that by implementing features to support textual and visual communication and simulate an interactive learning environment with generative agents, our system enhances the cognitive and social presence in the asynchronous learning environment. These results suggest the potential to use generative AI to support student learning and transform asynchronous learning into a more inclusive, engaging, and efficacious educational approach.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP19},
numpages = {24},
keywords = {asynchronous learning, cognitive presence, generative AI, multimodal generative agent, social presence}
}

@inproceedings{10.1145/3672608.3707992,
author = {Michel, Shira},
title = {Generative AI in Rural High Schools: Challenges and Opportunities},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707992},
doi = {10.1145/3672608.3707992},
abstract = {Recent advancements in Artificial Intelligence (AI) and more recently, Generative AI (GenAI) approaches have introduced both new challenges and opportunities in educational settings; yet, its effect on rural schools, which already face educational inequities, remains unclear. This study employs a mixed-methods approach using surveys and interviews to explore the current and potential roles of GenAI in rural high school classrooms across three U.S. regions. Preliminary findings reveal mixed perceptions: rural teachers value GenAI's ability to personalize learning but worry about encountering misinformation and feel unprepared to mitigate these risks due to their current level of AI literacy. While GenAI offers potential to enhance students' tech skills and reduce resource disparities, barriers like unreliable internet access and a lack of students owning personal devices still hinder its effectiveness, leaving both teachers and students under-supported in fully leveraging the technology. Overall, this study aims to explore rural teachers' experiences with GenAI to help develop strategies for fair and effective integration that address their unique challenges.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {106–108},
numpages = {3},
keywords = {generative AI, K-9-12 education, artificial intelligence},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@article{10.1145/3721846,
author = {Bhargava, Hemant K. and Brown, Susan and Ghose, Anindya and Gupta, Alok and Leidner, Dorothy and Wu, D. J.},
title = {Exploring Generative AI’s Impact on Research: Perspectives from Senior Scholars in Management Information Systems},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3721846},
doi = {10.1145/3721846},
abstract = {This commentary reflects on insights from a panel discussion at the 2024 Annual MIS Academic Leadership Conference, where six senior MIS scholars discussed the impact of Generative AI on scholarly research and peer review. The discussion underscored the importance of responsible use, transparency, and ethical standards, as well as the irreplaceable role of human judgment in maintaining research integrity. This commentary explores the potential of Generative AI as a collaborative tool across various stages of the research lifecycle, highlighting the "human-in-the-loop" approach to harness AI's capabilities while preserving essential human insight. This commentary synthesizes the senior scholars’ perspectives on the responsible integration of Generative AI, emphasizing opportunities to enhance research efficiency and foster interdisciplinary collaboration, while advocating for policies that ensure AI supports—rather than substitutes—human intellectual contributions in academic research.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = may,
articleno = {19},
numpages = {9},
keywords = {Generative Artificial Intelligence (GenAI), Large Language Models (LLMs), research integrity, peer review}
}

@inproceedings{10.1145/3711403.3711445,
author = {Zhou, Yaxin and He, Xiangchun and Jiang, Ruishuang and Zhang, Shaojun and Han, Yuqi and Guo, Xue},
title = {An Exploration of the Impact of Generalized Big Model Programming Educational Applications of Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711445},
doi = {10.1145/3711403.3711445},
abstract = {The application of artificial intelligence in the field of education has gone through several stages, initially using machine learning technology to optimize the teaching process to achieve automation of the "storage and calculation" function. Subsequently, through deep learning technology, the education has been able to realize the "visual and auditory" perceptual function. Nowadays, with the application of generalized big model, the education field is moving towards the cognitive stage of "understanding and creation". The purpose of this paper is to deeply analyze the challenges and dilemmas brought to programming education by the Generalized Big Model of Artificial Intelligence, and put forward the thinking of adjusting the educational objectives and programming content output under the ChatGPT Big Model for specific teaching.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {246–251},
numpages = {6},
keywords = {Big Model, ChatGPT, Programming Education},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3706599.3706713,
author = {Ehsan, Upol and Watkins, Elizabeth A and Wintersberger, Philipp and Manger, Carina and Hubig, Nina and Savage, Saiph and Weisz, Justin D. and Riener, Andreas},
title = {New Frontiers of Human-centered Explainable AI (HCXAI): Participatory Civic AI, Benchmarking LLMs, XAI Hallucinations, and Responsible AI Audits},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706713},
doi = {10.1145/3706599.3706713},
abstract = {Explainable AI (XAI) is more than just “opening” the black box — who opens it matters just as much, if not more, as the ways of opening it. Human-centered XAI (HCXAI) advocates that algorithmic transparency alone is not sufficient for making AI explainable. In our fifth CHI workshop on Human-Centered XAI (HCXAI), we shift our focus to new, emerging frontiers of explainability: (1) participatory approaches toward explainability in civic AI applications; (2) addressing hallucinations in LLMs using explainability benchmarks; (3) connecting HCXAI research with Responsible AI practices, algorithmic auditing, and public policy; and (4) improving representation of XAI issues from the Global South. We have built a strong community of HCXAI researchers through our workshop series whose work has made important conceptual, methodological, and technical impact on the field. In this installment, we will push the frontiers of work in HCXAI with an emphasis on operationalizing perspectives sociotechnically.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {793},
numpages = {6},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3719957,
author = {Benner, Dennis and Rauch, Jannik and Janson, Andreas and Leimeister, Jan Marco},
title = {An Explorative Diary Study of AI-Generated Podcasts in University Education: Benefits, Challenges, and Future Directions},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719957},
doi = {10.1145/3706599.3719957},
abstract = {In this study, we explore the potential of AI-generated podcasts as an educational tool in the evolving landscape of learning media. Podcasts have grown increasingly relevant in education due to their accessibility and ability to integrate learning into everyday life. With the advent of generative artificial intelligence (AI), there is a unique opportunity for scalable and adaptable creation of learning media. However, with novel technology, there also come new challenges. Thus, we developed fine-tuned AI-generated podcasts using Google NotebookLM, our course materials, and a custom prompt. We conducted a one-month explorative evaluation in the field using a qualitative diary study. Our study reveals that students find the podcasts beneficial for flexible everyday learning but also point toward challenges like a lack of emotional engagement and technical non-English language issues. In sum, our study highlights the current benefits and challenges of AI-generated podcasts and presents an agenda for future research.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {70},
numpages = {8},
keywords = {AI-Generated Podcasts, NotebookLM, Diary Study, Explorative Study, Field Study, Digital Education, University Education, Research Agenda},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3713574,
author = {Ahmadpour, Naseem and Pillai, Ajit G. and Zhang, Wendy Qi and Loke, Lian and Sachathep, Thida and Zhou, Zhaohua and Gough, Phillip},
title = {Ethics Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713574},
doi = {10.1145/3706598.3713574},
abstract = {Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {ethics, ethical sensitivity, education work, educator, reflection, reflexivity, canvas},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706468.3706559,
author = {Li, Tongguang and Nath, Debarshi and Cheng, Yixin and Fan, Yizhou and Li, Xinyu and Rakovi\'{c}, Mladen and Khosravi, Hassan and Swiecki, Zachari and Tsai, Yi-Shan and Ga\v{s}evi\'{c}, Dragan},
title = {Turning Real-Time Analytics into Adaptive Scaffolds for Self-Regulated Learning Using Generative Artificial Intelligence},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706559},
doi = {10.1145/3706468.3706559},
abstract = {In computer-based learning environments (CBLEs), adopting effective self-regulated learning (SRL) strategies requires sophisticated coordination of multiple SRL processes. While various studies have proposed adaptive SRL scaffolds (i.e. real-time advice on adopting effective SRL processes) and embedded them in CBLEs to facilitate learners’ effective use of SRL strategies, two key research gaps remain. First, there is a lack of research on SRL scaffolds that are based on continuous assessment of both learners’ SRL processes and learning conditions (e.g., awareness of learning resources) to provide adaptive support. Second, current analytics-based scaffolding mechanisms lack the scalability needed to effectively address multiple learning conditions. Integration of analytics of SRL with generative artificial intelligence (GenAI) can provide scalable scaffolding for real-time SRL processes and evolving conditions. Yet, empirical studies implementing and evaluating effects of this integration remain scarce. To address these limitations, we conducted a randomized control trial, assigning participants to three groups (control, process only, and process with condition groups) to investigate the effects of using GenAI to turn insights from real-time analytics about students’ SRL processes and conditions into adaptive scaffolds. The results demonstrate that integrating real-time analytics with GenAI in adaptive SRL scaffolds – addressing both SRL processes and dynamic conditions – promotes more metacognitive learning patterns compared to the control and process-only groups. In addition, the learners showed varying levels of compliance with analytics-based GenAI scaffolds, and this was also reflected in how the learners coordinated their SRL processes, particularly in the performance phase of SRL. This study contributes to the literature by designing, implementing, and evaluating the impact of adaptive scaffolds on learners’ SRL processes using real-time analytics with GenAI.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {667–679},
numpages = {13},
keywords = {self-regulated learning, scaffolding compliance, GenAI, scaffolding, learning analytics},
location = {
},
series = {LAK '25}
}

@inbook{10.5555/3716662.3716698,
author = {Feffer, Michael and Sinha, Anusha and Deng, Wesley H. and Lipton, Zachary C. and Heidari, Hoda},
title = {Red-Teaming for Generative AI: Silver Bullet or Security Theater?},
year = {2025},
publisher = {AAAI Press},
abstract = {In response to rising concerns surrounding the safety, security, and trustworthiness of Generative AI (GenAI) models, practitioners and regulators alike have pointed to AI red-teaming as a key component of their strategies for identifying and mitigating these risks. However, despite AI red-teaming's central role in policy discussions and corporate messaging, significant questions remain about what precisely it means, what role it can play in regulation, and how it relates to conventional red-teaming practices as originally conceived in the field of cybersecurity. In this work, we identify recent cases of red-teaming activities in the AI industry and conduct an extensive survey of relevant research literature to characterize the scope, structure, and criteria for AI red-teaming practices. Our analysis reveals that prior methods and practices of AI red-teaming diverge along several axes, including the purpose of the activity (which is often vague), the artifact under evaluation, the setting in which the activity is conducted (e.g., actors, resources, and methods), and the resulting decisions it informs (e.g., reporting, disclosure, and mitigation). In light of our findings, we argue that while red-teaming may be a valuable big-tent idea for characterizing GenAI harm mitigations, and that industry may effectively apply red-teaming and other strategies behind closed doors to safeguard AI, gestures towards red-teaming (based on public definitions) as a panacea for every possible risk verge on security theater. To move toward a more robust toolbox of evaluations for generative AI, we synthesize our recommendations into a question bank meant to guide and scaffold future AI red-teaming practices.},
booktitle = {Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {421–437},
numpages = {17}
}

@inproceedings{10.1145/3708359.3712131,
author = {Bhat, Maalvika},
title = {How Dynamic vs. Static Presentation Shapes User Perception and Emotional Connection to Text-Based AI},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712131},
doi = {10.1145/3708359.3712131},
abstract = {This study investigates the influence of dynamic versus static presentation modes in text-based conversational AI on user perceptions and emotional connection. We conducted a controlled, within-subjects experiment (N=103) where non-technical users interacted with a LLM-powered chatbot in both dynamic (typing-simulation display) and static (non-incremental text display) modes. Results from ANOVA showed that dynamic interactions improved perceptions of AI’s competence, warmth, trustworthiness, engagement, adaptive behavior, supportiveness, personal connection, empathy, bias awareness, accountability, and emotional expressiveness. However, no significant differences were found in perceived effectiveness, bias, and learning support. These findings indicate that dynamic AI presentations can significantly enhance user experience by fostering deeper emotional connections and greater trust in the system, making AI interactions more human-like and increasing adoption of AI technologies. The paper discusses implications for human-AI interface design, emphasizing the need to mitigate risks of misinformation and manipulation of users through transparency, ethical considerations, and robust user education strategies.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {846–860},
numpages = {15},
keywords = {Conversational AI, Dynamic presentations, Static presentations, Human-Computer Interaction, AI trust, Social presence, Anthropomorphism, AI autonomy, Symbolic Interactionism, User perceptions, Empathy, AI engagement},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3706468.3706474,
author = {Yin, Stella Xin and Liu, Zhengyuan and Goh, Dion Hoe-Lian and Quek, Choon Lang and Chen, Nancy F.},
title = {Scaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706474},
doi = {10.1145/3706468.3706474},
abstract = {Pair programming is a collaborative activity that enhances students’ computational thinking (CT) skills. Analyzing students’ interactions during pair programming provides valuable insights into effective learning. However, interpreting classroom dialogues is a challenging and complex task. Due to the simultaneous interaction between interlocutors and other ambient noise in collaborative learning contexts, previous work heavily relied on manual transcription and coding, which is labor-intensive and time-consuming. Recent advancements in speech and language processing offer promising opportunities to automate and scale up dialogue analysis. Besides, previous work mainly focused on task-related interactions, with little attention to social interactions. To address these gaps, we conducted a four-week CT course with 26 fifth-grade primary school students. We recorded their discussions, transcribed them with speech processing models, and developed a coding scheme and applied LLMs for annotation. Our AI-driven pipeline effectively analyzed classroom recordings with high accuracy and efficiency. After identifying the dialogue patterns, we investigated the relationships between these patterns and CT performance. Four clusters of dialogue patterns have been identified: Inquiry, Constructive Collaboration, Disengagement, and Disputation. We observed that Inquiry and Constructive Collaboration patterns were positively related to students’ CT skills, while Disengagement and Disputation patterns were associated with lower CT performance. This study contributes to the understanding of how dialogue patterns relate to CT performance and provides implications for both research and educational practice in CT learning.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {47–57},
numpages = {11},
keywords = {Collaborative learning, Computational thinking, Dialogue analysis, Large language models, Pair programming, Speech and language processing},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3723498.3723817,
author = {Cox, Daniel and Murray, John and Salter, Anastasia},
title = {Routine, Twisty, and Queer: Pasts and Futures of Games Programming Pedagogy with No and Low Code Tools},
year = {2025},
isbn = {9798400718564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723498.3723817},
doi = {10.1145/3723498.3723817},
abstract = {This paper traces a history of platforms targeting no-code and low-code audiences. It connects historical moments addressing accessibility challenges related to computer programming up through the more recent adoption of generative AI in game engines. Across these moments, this paper identifies communities that claimed authoring platforms, establishing their identity by rejecting other, potentially more efficient or expressive options. We argue these community dynamics have shaped the evolution of current game development platforms. By contextualizing current efforts in pedagogy as part of larger shifts in computer programming and game engine practice, we present a better understanding of the origins of platforms targeting no and low code audiences as rooted in earlier pivots in computer programming and community engagement. These “twisty” and often queer adaptations aimed at smaller communities have led to major changes in how game development has evolved for larger audiences. We close on considerations of the uncertain futures and pedagogical implications of AI-generated code and visual scripting, as game engines increasingly serve as the primary interface between creators and their work.},
booktitle = {Proceedings of the 20th International Conference on the Foundations of Digital Games},
articleno = {47},
numpages = {8},
keywords = {Game Programming Pedagogy, Low code, No code},
location = {
},
series = {FDG '25}
}

@inproceedings{10.1145/3672608.3707842,
author = {Shaheryar, Muhammad and Lee, Jong Taek and Jung, Soon Ki},
title = {Unlearn and Protect: Selective Identity Removal in Diffusion Models for Privacy Preservation},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707842},
doi = {10.1145/3672608.3707842},
abstract = {Diffusion models are capable of generating high-quality synthesis images with intricate identity features, but this raises privacy concerns, as personal identities may be used without consent. What if we need to remove a specific identity from an already trained model without retraining it from scratch? Inspired by the success of concept removal from generative models, we propose an approach to address the under-explored challenge of identity removal in pretrained diffusion models. Our method achieves this by aligning the image distribution of the identity to be removed with that of a target identity, ensuring the model avoids generating the specified identity. Extensive experiments, including quantitative and qualitative analyses, demonstrate that our approach eliminates the specified identity while preserving the integrity of other identities within the model, achieving a low AccU = 1.50% and FIDR = 15.8. Additionally, we introduce a new Selective Removal and Keep (SRK) metric based on facial recognition (FR) models, incorporating the accuracy on unlearned and retained identities, for evaluating identity unlearning in generative models, providing a comprehensive assessment of the unlearning process and its impact on model performance.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {1172–1179},
numpages = {8},
keywords = {machine learning, machine unlearning, generative models, data privacy, identity removal},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3706598.3713804,
author = {Kiskola, Joel and Rydenfelt, Henrik and Olsson, Thomas and Haapanen, Lauri and V\"{a}nttinen, Noora and Nelimarkka, Matti and Vigren, Minna and Laaksonen, Salla-Maaria and Lehtiniemi, Tuukka},
title = {Generative AI and News Consumption: Design Fictions and Critical Analysis},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713804},
doi = {10.1145/3706598.3713804},
abstract = {The emergence of Generative AI features in news applications may radically change news consumption and challenge journalistic practices. To explore the future potentials and risks of this understudied area, we created six design fictions depicting scenarios such as virtual companions delivering news summaries to the user, AI providing context to news topics, and content being transformed into other formats on demand. The fictions, discussed with a multi-disciplinary group of experts, enabled a critical examination of the diverse ethical, societal, and journalistic implications of AI shaping this everyday activity. The discussions raised several concerns, suggesting that such consumer-oriented AI applications can clash with journalistic values and processes. These include fears that neither consumers nor AI could successfully balance engagement, objectivity, and truth, leading to growing detachment from shared understanding. We offer critical insights into the potential long-term effects to guide design efforts in this emerging application area of GenAI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {250},
numpages = {18},
keywords = {Design fiction, artificial intelligence, journalism, online news, speculative design},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713634,
author = {Perera, Minoli and Ananthanarayan, Swamy and Goncu, Cagatay and Marriott, Kim},
title = {The Sky is the Limit: Understanding How Generative AI can Enhance Screen Reader Users' Experience with Productivity Applications},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713634},
doi = {10.1145/3706598.3713634},
abstract = {Productivity applications including word processors, spreadsheets, and presentation tools are crucial in work, education, and personal settings. Blind users typically access these tools via screen readers (SRs) and face significant accessibility and usability challenges. Recent advancements in Generative AI (GenAI) may address these challenges by enabling natural language interactions and contextual task understanding. However, there is limited understanding of SR users’ needs and attitudes toward GenAI assistance in these applications. We surveyed 99 SR users to gain a holistic understanding of the challenges they face when using productivity applications, the impact of these challenges on their productivity and independence, and their initial perceptions of AI assistance. Driven by their enthusiasm, we conducted interviews with 16 SR users to explore their attitudes toward GenAI and its potential usefulness in productivity applications. Our findings highlight its need to support existing SR workflows and the importance of enabling customization and task verification.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1165},
numpages = {17},
keywords = {blind, accessibility, productivity applications, assistive technology, screen readers, AI assistants, Generative AI, virtual assistants},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3719971,
author = {Gu, Quan Connie and Hickey, Daniel and Ryokai, Kimiko},
title = {When AI Tells Their Story: Researchers’ Reactions to AI-Generated Podcasts as a Tool for Communicating Research},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719971},
doi = {10.1145/3706599.3719971},
abstract = {Podcasts have been recognized as an accessible and engaging medium for education and science communication. Recent advances in generative AI have led to the development of tools that transform science communication by summarizing complex research for broader audiences. However, little research has explored original authors’ perspectives and reactions to these tools, leaving gaps in understanding their views on accurate representation of their work. Through interviews with 10 authors from 9 different disciplines, our study examines authors’ perspectives on the accuracy, effectiveness, and role of AI-generated podcasts in engaging both academic and general audiences. The study also explores their reflections on the opportunities and risks these tools present, both for broader audiences and for authors themselves, along with their ideas for improving the design. By centering authors’ perspectives, this study aims to provide insights for designing AI-assisted science communication systems that respect the integrity of academic work while enhancing accessibility.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {597},
numpages = {6},
keywords = {science communication, generative AI, podcast},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3717867.3717891,
author = {Pessianzadeh, Aria and Rezapour, Rezvaneh},
title = {Exploring Stance on Affirmative Action Through Reddit Narratives},
year = {2025},
isbn = {9798400714832},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3717867.3717891},
doi = {10.1145/3717867.3717891},
abstract = {Affirmative Action (AA), is a controversial topic that aims to address historical inequalities in education and employment by considering race, gender, and ethnicity during the selection process. While some view AA as a necessary tool for promoting diversity and correcting systemic discrimination, others criticize it as reverse discrimination, arguing it unfairly favors certain groups. These conflicting views have led to heated debates, legal battles, and polarized public discourse. This study explores narratives of AA on social media, focusing on how people express their positions on this issue using stance analysis. After collecting 3,839 posts from 50 subreddits, we developed fine-grained stance categories to capture the nuances of this controversial discourse on Reddit and used LLM-based classifiers to identify stances in our data. Our results suggest that the majority of users on Reddit oppose AA in its current format, while many express skepticism or raise questions about it. Additionally, our topic modeling results highlight a broad range of themes related to societal, cultural, legal, and political aspects of AA. Finally, moral analysis indicates the prevalence of Fairness and Authority in AA narratives. Our work contributes to a better understanding of public attitudes toward AA and provides insights into people’s perspectives on social media. We also contribute to stance analysis methodologies, highlighting the complexities involved in detecting diverse opinions on highly charged topics. Warning: This paper includes language and content that may be offensive or triggering.},
booktitle = {Proceedings of the 17th ACM Web Science Conference 2025},
pages = {52–63},
numpages = {12},
keywords = {Affirmative Action, stance analysis, social media, natural language processing, large language models, Reddit},
location = {
},
series = {Websci '25}
}

@article{10.1145/3718098,
author = {Shi, Wenda and Wong, Waikeung and Zou, Xingxing},
title = {Generative AI in Fashion: Overview},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3718098},
doi = {10.1145/3718098},
abstract = {Generative Artificial Intelligence (GenAI) has recently gained immense popularity by offering various applications for generating high-quality and aesthetically pleasing content of image, 3D, and video data format. The innovative GenAI solutions have shifted paradigms across various design-related industries, particularly fashion. In this paper, we explore the incorporation of GenAI into fashion-related tasks and applications. Our examination encompasses a thorough review of more than 470 research papers and an in-depth analysis of over 300 applications, focusing on their contributions to the field. These contributions are identified as 13 tasks within four categories: multi-modal fashion understanding, and fashion synthesis of image, 3D, and dynamic (video and animatable 3D) formats We delve into these methods, recognizing their potential to propel future endeavours toward achieving state-of-the-art (SOTA) performance. Furthermore, we present a comprehensive overview of 53 publicly available datasets suitable for training and benchmarking fashion-centric models, accompanied by the relevant evaluation metrics. Finally, we review real-world applications, unveiling existing challenges and future directions. With comprehensive investigation and in-depth analysis, this paper is targeted to serve as a useful resource for understanding the current landscape of GenAI in fashion, paving the way for future innovations in this dynamic field. Papers discussed in this paper, along with public code and datasets links are available at: .},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = feb
}

@article{10.1145/3731754,
author = {Zhong, Renyi and Li, Yichen and Kuang, Jinxi and Gu, Wenwei and Huo, Yintong and Lyu, Michael R.},
title = {LogUpdater: Automated Detection and Repair of Specific Defects in Logging Statements},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3731754},
doi = {10.1145/3731754},
abstract = {Developers write logging statements to monitor software runtime behaviors and system state. However, poorly constructed or misleading log messages can inadvertently obfuscate actual program execution patterns, thereby impeding effective software maintenance. Existing research on analyzing issues within logging statements is limited, primarily focusing on detecting a singular type of defect and relying on manual intervention for fixes rather than automated solutions.To address the limitation, we initiate a systematic study that pinpoints four specific types of defects in logging statements (i.e., statement code inconsistency, static dynamic inconsistency, temporal relation inconsistency, and readability issues) through the analysis of real-world log-centric changes. We then propose LogUpdater, a two-stage framework for automatically detecting and updating logging statements for these specific defects. In the offline stage, LogUpdater constructs a similarity-based classifier on a set of synthetic defective logging statements to identify specific defect types. During the online testing phase, this classifier first evaluates logging statements in a given code snippet to determine the necessity and type of improvements required. Then, LogUpdater constructs type-aware prompts from historical logging update changes for an LLM-based recommendation framework to suggest updates addressing these specific defects.We evaluate the effectiveness of LogUpdater on a dataset containing real-world logging changes, a synthetic dataset, and a new real-world project dataset. The results indicate that our approach is highly effective in detecting logging defects, achieving an F1 score of 0.625. Additionally, it exhibits significant improvements in suggesting precise static text and dynamic variables, with enhancements of 48.12% and 24.90%, respectively. Furthermore, LogUpdater achieves a 61.49% success rate in recommending correct updates on new real-world projects. We reported 40 problematic logging statements and their fixes to GitHub via pull requests, resulting in 25 changes confirmed and merged across 11 different projects.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
keywords = {Logging Statement, Logging Practice, Large Language Model}
}

@INPROCEEDINGS{10893106,
  author={Reichert, Heidi and Tabarsi, Benyamin T. and Zang, Zifan and Fennell, Cheri and Bhandari, Indira and Robinson, David and Drayton, Madeline and Crofton, Catherine and Lococo, Matthew and Xu, Dongkuan and Barnes, Tiffany},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Empowering Secondary School Teachers: Creating, Executing, and Evaluating a Transformative Professional Development Course on ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Background and Context. This innovative practice full paper describes the development and implementation of a professional development (PD) opportunity for secondary teachers to learn about ChatGPT. Incorporating generative AI techniques from Large Language Models (LLMs) such as ChatGPT into educational environments offers unprecedented opportunities and challenges. Prior research has highlighted their potential to personalize feedback, assist in lesson planning, generate educational content, and reduce teachers' workload, alongside concerns such as academic integrity and student privacy. However, the rapid adoption of LLMs since ChatGPT's public release in late 2022 has left educators, particularly at the secondary level, with a lack of clear guidance on how LLMs work and can be effectively adopted. Objective. This study aims to introduce a comprehensive, free, and vetted ChatGPT course tailored for secondary teachers, with the objective of enhancing their technological competencies in LLMs and fostering innovative teaching practices. Method. We developed a five-session interactive course on ChatGPT capabilities, limitations, prompt-engineering techniques, ethical considerations, and strategies for incorporating ChatGPT into teaching. We introduced the course to six middle and high school teachers. Our curriculum emphasized active learning through peer discussions, hands-on activities, and project-based learning. We conducted pre- and post-course focus groups to determine the effectiveness of the course and the extent to which teachers' attitudes toward the use of LLMs in schools had changed. To identify trends in knowledge and attitudes, we asked teachers to complete feedback forms at the end of each of the five sessions. We performed a thematic analysis to classify teacher quotes from focus groups' transcripts as positive, negative, and neutral and calculated the ratio of positive to negative comments in the pre- and post-focus groups. We also analyzed their feedback on each individual session. Finally, we interviewed all participants five months after course completion to understand the longer-term impacts of the course. Findings. Our participants unanimously shared that all five of the sessions provided a deeper understanding of ChatGPT, featured enough opportunities for hands-on practice, and achieved their learning objectives. Our thematic analysis underlined that teachers gained a more positive and nuanced understanding of ChatGPT after the course. This change is evidenced quantitatively by the fact that quotes with positive connotations rose from 45% to 68% of the total number of positive and negative quotes. Participants shared that in the longer term, the course improved their professional development, understanding of ChatGPT, and teaching practices. Implications. This research underscores the effectiveness of active learning in professional development settings, particularly for technological innovations in computing like LLMs. Our findings suggest that introducing teachers to LLM tools through active learning can improve their work processes and give them a thorough and accurate understanding of how these tools work. By detailing our process and providing a model for similar initiatives, our work contributes to the broader discourse on teaching professional educators about computing and integrating emerging technologies in educational and professional development settings.},
  keywords={Technological innovation;Privacy;Computational modeling;Large language models;Education;Active learning;Position measurement;Chatbots;Market research;Planning;K-12;large language models;chatgpt;professional development;secondary education},
  doi={10.1109/FIE61694.2024.10893106},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10893096,
  author={Lejmbach, Karol and Mackay, Sean},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Using Chat-GPT to Create Multiple Choice CS Exams}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work in progress Innovative Practice paper presents our work evaluating how Large Language Models (LLMs) can be utilized to aid in the development of scalable and authentic programming exam questions for students in upper-division courses. Traditionally, students' understanding of computing concepts are often verified using written exams. This is especially the case in larger universities due to their overall enrollment sizes, making more authentic, involved assignments particularly hard to facilitate. Since the rise of Chat-GPT and other LLMs, the use of such exams has seen a resurgence in popularity in classrooms globally. Fears have recently grown that programming assignments, particularly those that are take home assignments, are not adequate assessments of students' understanding given the ease at which students can use LLMs such as Chat-GPT to obtain answers. multiple-choice exams have been a traditionally popular programming exam format, where-in students are required to choose the correct answer to a prompt or the segment of code that best fits within a larger block of code. Another form of exam question that has been traditionally popular is providing students with blocks of code and ask students to either interpret the code's meaning or find the errors in the code. Both of these styles of assignments provide opportunities for students to demonstrate a deep understanding of code syntax and structure, while also tasking them to demonstrate their understanding of what the intended purpose of the code is. However, the development of these exam problems has traditionally required a substantial amount of work for instructors and teaching assistants to develop. Our goal with this work was to determine if LLMs represent effective tools for developing exam questions. Additionally, we wanted to see if LLMs could effectively design problems based on learning outcomes, allowing the instructor to become the evaluator of the exam questions rather than the original author. Our motivation for this was to develop a reproducible and easier to implement methodology for developing exams at scale for instructors while alleviating the workload imposed on instructors during the development of exams. Our initial research has indicated the use of these LLMs for exam problem generation greatly reduces the workload for instructors while allowing for the creation of far richer programming questions for students that require them to apply more of their knowledge to individual problems. We have had a good amount of success in developing these problems for upper-division courses, as well as introductory-level courses. This work represents initial steps towards the use of these LLMs for generating exams and more work is needed to determine the actual efficacy and long-term benefits and reliability of these tools. Regardless, we are confident that LLMs in their current form represent incredibly powerful tools for instructors to utilize in the development of their course exams.},
  keywords={Codes;Large language models;Education;Syntactics;Reliability;Programming profession;large language models;exam development;computing education;Chat-GPT},
  doi={10.1109/FIE61694.2024.10893096},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578933,
  author={Frank, Lukas and Herth, Fabian and Stuwe, Paul and Klaiber, Marco and Gerschner, Felix and Theissler, Andreas},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging GenAI for an Intelligent Tutoring System for R: A Quantitative Evaluation of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The tremendous advances in Artificial Intelligence (AI) open new opportunities for education, with Intelligent Tutoring Systems (ITS) powered by Generative Artificial Intelligence (GenAI) proving to be a promising prospect. Because of this, our work explores state-of-the-art (SOTA) ITS approaches with the integration of Large Language Models (LLMs) to improve programming education. We investigate whether and how a GenAI-based ITS can effectively support students in learning R programming skills. We measured the performance of three current pairings of LLMs and user interfaces: GPT-3.5 via ChatGPT, PaLM 2 via Google Bard, and GPT-4 via Bing. Therefore, we evaluated the LLMs on four types of problem settings when learning/teaching programming. Our experimental results show that the use of generative AI, specifically LLMs for R programming, is promising, where GPT-3.5 yielded the most satisfactory results. Furthermore, the advantages and limitations of our approach are addressed and revealed. Finally, open research directions towards explainable AI (XAI) and integrated self-assessment are pointed out.},
  keywords={Generative AI;Explainable AI;Current measurement;Benchmark testing;Chatbots;Internet;Task analysis;Generative AI;AI in Education;Intelligent Tutoring Systems;R Programming;Student Support},
  doi={10.1109/EDUCON60312.2024.10578933},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10518103,
  author={Neyem, Andrés and González, Luis A. and Mendoza, Marcelo and Alcocer, Juan Pablo Sandoval and Centellas, Leonardo and Paredes, Carlos},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development}, 
  year={2024},
  volume={17},
  number={},
  pages={1599-1614},
  abstract={Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local “lessons learned” database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.},
  keywords={Software;Artificial intelligence;Task analysis;Software engineering;Codes;Chatbots;Knowledge engineering;Capstone courses;ChatGPT;context-aware learning;generative artificial intelligence (AI);large language models (LLMs);software engineering education},
  doi={10.1109/TLT.2024.3396735},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10554680,
  author={Cipriano, Bruno Pereira and Alves, Pedro},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={162-169},
  abstract={Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 show-cases promise, the deployment of these models in OOP education still mandates supervision.},
  keywords={Training;Codes;Object oriented modeling;Complexity theory;Object recognition;Object oriented programming;Programming profession;programming assignments;teaching;object-oriented programming;object-oriented design;OOP best practices;large language models;gpt-3;gpt-4;bard},
  doi={10.1145/3639474.3640052},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10664775,
  author={Li, Max Z},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Using Prompt Engineering to Enhance STEM Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={With the advent of large language models (LLMs), such as ChatGPT, Gemini and LLaMA, there is no doubt that AI will forever change how education works. However, there is a gap between K-12 students and the LLM. The prompts given to LLM need to be well designed to be effectively utilized for K-12 education. To use LLMs more appropriately for K-12 STEM educational purposes, the author developed a prototype tool with prompt engineering to fully utilize the educational potential of LLMs and reduce usage for academic dishonesty. The tool would have a student register by giving the grade that they're in, and then ask as the topic the student would like to learn more about. Using prompt engineering techniques, the tool can prompt LLMs to produce educational content such as a descriptions, question and answer, AI-generated quizzes, and reviews, as well as asking the LLM to simplifying complex topics further to aid in understanding. The AI-enabled tool, effectively a virtual and personal mentor, could help propel STEM education further and make STEM more interesting to students as it could help explain complex topics in a way that students can understand easily. The tool and AI can help students understand a topic through interactive practice instead of just memorizing facts and putting them on a sheet of paper. The tool present in this paper will enhance the STEP education by AI.},
  keywords={Reviews;Large language models;Education;Prototypes;Propulsion;Chatbots;Registers},
  doi={10.1109/ISEC61299.2024.10664775},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10834365,
  author={Alario-Hoyos, Carlos and Kemcha, Rebiha and Kloos, Carlos Delgado and Callejo, Patricia and Estévez-Ayres, Iria and Santín-Cristóbal, David and Cruz-Argudo, Francisco and López-Sánchez, José Luis},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Tailoring Your Code Companion: Leveraging LLMs and RAG to Develop a Chatbot to Support Students in a Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Students frequently rely on chatbots powered by generative Artificial Intelligence (GenAI), such as ChatGPT, Copilot, Gemini, and Claude, to assist with a wide range of academic tasks. However, these chatbots are not specifically designed for the context of particular courses, which can lead to responses that are sometimes inaccurate or insufficiently relevant. This paper introduces a chatbot specifically designed to support first-year engineering students in a Java programming course. Developed using the Retrieval-Augmented Generation (RAG) technique, the chatbot draws on course-specific resources such as videos, quizzes, programming exercises, and other materials, while using OpenAI’s Large Language Models (LLMs) GPT-4 and GPT-3.5 for information analysis and response generation. The data collected, consisting of logs from 1,059 messages sent by students to the chatbot and 30 responses to a survey, indicate that students primarily used the chatbot to clarify concepts and explain code snippets. Moreover, most of the students reported that the responses provided by the chatbot were well suited to the Java programming course.},
  keywords={Surveys;Java;Codes;Large language models;Retrieval augmented generation;Learning (artificial intelligence);Programming;Chatbots;Videos;Information analysis;Large Language Models (LLMs);Retrieval-Augmented Generation (RAG);Generative Artificial Intelligence (GenAI);Chatbots;and Programming Course},
  doi={10.1109/TALE62452.2024.10834365},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10893528,
  author={Nath, Sagnik and Yoon, So Yoon},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Beyond Code: Evaluating ChatGPT, Gemini, Claude, and Meta AI as AI Tutors in Computer Science and Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This Work-in-Progress research paper evaluates the validity of Large Language Models (LLMs) as conversational AI tutors for computer science learning. While current engineering education literature has predominantly emphasized the rapid evolution of LLMs as conversational AI tutors for programming languages, the exploration into their effectiveness within general STEM topics remains comparatively scarce. This WIP study thus centers on evaluating the potential of LLMs to facilitate understanding of core hardware design concepts critical to computer science and engineering (CSE) education. By cross-checking the responses from generative AI chatbots to an openended CSE-based question, we aimed to uncover how LLMs, such as ChatGPT-3.5, Claude, Gemini, and Meta AI, can contribute to teaching and learning of general CSE courses instead of a specifically coding-based one. Our method involved simulating a student query on the popular debate between CISC vs. RISC related to computer architecture and analyzing the chatbots' responses. This initial collection of data served as the foundation for a continual comparative analysis aimed at determining the inherent instructional value of each LLM and its validity and reliability. To systematically assess the responses, we introduced an evaluation framework focusing on metrics, such as response accuracy, persuasiveness, and depth of explanation. The current work anticipates not only enriching our understanding of how these advanced LLMs can support general CSE education but also identifying areas where further development is needed for a more holistic integration of LLM-based chatbots in assisting student comprehension in the overarching engineering education.},
  keywords={Computer science;Measurement;Reduced instruction set computing;Large language models;Computer architecture;Chatbots;Hardware;Reliability;Engineering education;STEM;Large Language Models (LLMs);computer engineering education;AI tutors;CISC;RISC;computer architecture;Instruction set architecture},
  doi={10.1109/FIE61694.2024.10893528},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10911947,
  author={Zaripova, Rinata R. and Danilov, Andrew V. and Salekhova, Leila L. and Fazliakhmetov, Timur R.},
  booktitle={2024 17th International Conference on Development in eSystem Engineering (DeSE)}, 
  title={The Development of Individualized Assignment Generator}, 
  year={2024},
  volume={},
  number={},
  pages={521-525},
  abstract={The article discusses the development of a system that uses artificial intelligence (AI) to generate individualized mathematics assignments for bilingual students in Tatarstan, Russia. The goal is to enhance learning by tailoring assignments to students’ linguistic preferences, cognitive styles, and knowledge levels. The system employs machine learning techniques and GPT-based models to create personalized tasks that align with curriculum goals while addressing linguistic diversity, particularly for Tatar-Russian bilinguals. The study evaluates several large language models (LLMs), including GPT-4, GPT-3.5 Turbo, YandexGPT, and GigaChat, based on their ability to generate math problems and content in the Tatar language. While GPT-4 and GPT-3.5 Turbo show superior performance in producing accurate and semantically correct problems, their proficiency in Tatar remains inconsistent. The research underscores the need for further development of LLMs to enhance content generation for bilingual educational contexts and highlights the potential of AI in advancing adaptive learning for mathematics education. Future directions include expanding the system’s functionality and testing its effectiveness across diverse educational settings.},
  keywords={Adaptive learning;Adaptation models;Large language models;Semantics;Machine learning;Linguistics;Mathematical models;Natural language processing;Optimization;Testing;Natural Language Processing;Bilingual Education;Adaptive Learning;Large Language Models;Tatar-Russian Bilingualism},
  doi={10.1109/DeSE63988.2024.10911947},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10852497,
  author={Brach, William and Košt’ál, Kristián and Ries, Michal},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Can Large Language Model Detect Plagiarism in Source Code?}, 
  year={2024},
  volume={},
  number={},
  pages={370-377},
  abstract={The issue of code plagiarism represents a significant challenge in the academic environment. This study examines the potential of large language models (LLMs) in improving the detection of code plagiarism. The performance of several LLMs, including GPT-4o, GPT-3.5 Turbo, LLaMA 3, and CodeLlama, is evaluated in comparison to conventional tools, such as JPlag, across a range of levels of code plagiarism. The findings of our study illustrate that state-of-the-art LLMs are able to outperform traditional methods, particularly in the detection of sophisticated forms of plagiarism. GPT-4o exhibited the highest overall accuracy (78.70%) and an F1 score of 86.97%. It is important to note that open-source models, such as LLaMA 3 (accuracy 71.53%, F1 score 82.75%), demonstrated the ability to detect the most complex forms of plagiarism with the same accuracy as GPT-4o. While these results demonstrate the promising potential of LLMs in code similarity analysis, it is also evident that higher false positive rates may be an inherent limitation, emphasizing the need for human oversight. This study contributes valuable insights into the application of AI in maintaining code integrity and academic honesty, paving the way for more effective, interpretable, and fair plagiarism detection systems in software development education and practice. For further information, source code, and updates on this project, please visit our GitHub at https://github.com/fiit-ba/llm-plagiarism-check.},
  keywords={Measurement;Computer languages;Codes;Accuracy;Reviews;Plagiarism;Large language models;Source coding;Education;Software development management;large language models;natural language processing;code similarity;code plagiarism},
  doi={10.1109/FLLM63129.2024.10852497},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10479881,
  author={Popov, Vladislav S.},
  booktitle={2024 6th International Youth Conference on Radio Electronics, Electrical and Power Engineering (REEPE)}, 
  title={ChatGPT and Unified State Exam in Computer Science}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, it is presented the obtained and studied statistics of solving tasks of demo versions of the Unified State Exam (USE) in Computer Science 2011-2023 using the GPT-3.5 language model and ChatGPT. The obtained results of the Unified State Examination in Computer Science are presented, their analysis and the results of solving individual tasks are shown, examples of successful solutions of the Unified State Exam tasks in Computer Science, limitations when working with ChatGPT are described. Based on the results of solving exam tasks, ChatGPT scored 47-57 test scores in 2011-2014 before the cancellation of the test part, and also slightly overcame the threshold score in 2015-2017, 2019, 2020, did not score the points necessary for passing the USE in Computer Science in 2018, 2021-2023. Based on the obtained research data, a gradual complication of the USE exam model in Computer Science is shown, in which the test part of the exam in 2015 is abandoned and the computer format of the exam is introduced in 2021. Using the example of the USE in Computer Science, it is shown that ChatGPT, GPT-3.5 and similar language models can serve tool for expert assessment of the complexity of examination tasks and examination model.},
  keywords={Computer science;Power engineering;Computational modeling;Unified modeling language;Chatbots;Data models;Complexity theory;ChatGPT;GPT-3.5;language model;ChatGPT exam;USE in Computer Science;artificial intelligence testing},
  doi={10.1109/REEPE60449.2024.10479881},
  ISSN={2831-7262},
  month={Feb},}@INPROCEEDINGS{10892934,
  author={Andersen-Kiel, Noah and Linos, Panagiotis Panos},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Using ChatGPT in Undergraduate Computer Science and Software Engineering Courses: A Students' Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper presents an empirical study aimed at evaluating the potential of ChatGPT, an advanced AI-driven chatbot, as a supplementary educational tool in undergraduate Computer Science and Software Engineering (CSSE) courses. The study, initiated in the summer of 2023, focused on assessing ChatGPT's capabilities in generating accurate and complete computer code, identifying and rectifying code defects (bugs), and its scalability in handling larger programs. To achieve this, we conducted a series of experiments with ChatGPT. In one experiment, we introduced bugs into small programs from introductory CSSE courses. ChatGPT was tasked with detecting these defects and providing recommendations for fixing them. We evaluated ChatGPT's effectiveness in bug detection, the quality of its recommendations, and the completeness of the proposed solutions. We sought answers to questions such as whether ChatGPT found all injected defects, provided appropriate recommendations, and delivered high-quality solutions based on criteria like code completeness, size, complexity, and readability. In another experiment, ChatGPT was asked to generate code for assignments from previous CSSE courses, including Intro to Computer Science and Programming in C++, Intro to Python Programming, and Object-Oriented Programming and Data Structures using Java. We assessed the generated code's correctness and quality in comparison to student-written code. Similarly, in a third experiment, we evaluated ChatGPT's ability to generate larger programs using requirement specifications from an upper-division CSSE course on Agile Software Engineering. Analyzing both qualitative and quantitative data from these experiments during the summer, we determined that ChatGPT showed promise as an educational tool. Consequently, we developed a plan to integrate ChatGPT into select CSSE courses for the fall semester of 2023. Specifically, ChatGPT was integrated into two of our introductory CSSE courses enabling students to utilize it for debugging assignments and generating practice questions for exam preparation. In addition, we encouraged student teams in our EPICS (Engineering Projects In Community Service) course to utilize ChatGPT as a supplementary aid to help them find and learn any new programming languages or technologies needed for their projects. Anonymous surveys were conducted at the beginning and at the end of these courses to collect feedback from students regarding their experiences with ChatGPT. Initial responses indicated that students were generally familiar with ChatGPT and expressed curiosity about its potential utility, although some skepticism was present. However, by the semester's end, students demonstrated a positive shift in perceptions. They appreciated ChatGPT's assistance in rectifying code bugs, especially after-hours. Additionally, students valued ChatGPT for generating practice questions for exams, despite some inconsistencies in its responses. In our EPICS course, students felt ChatGPT was useful for learning new technologies, though opinions varied on its project management benefits. Lastly, the majority of students felt that ChatGPT helped them adjust to their work progress, showing its potential utility in keeping pace with ongoing projects. Based on student feedback, we propose integrating ChatGPT into future CSSE courses. Finally, as AI -based tools become more integral to academic settings, we believe that disseminating our experiences could potentially enhance engineering and computing education.},
  keywords={Surveys;Codes;Scalability;Computer bugs;Project management;Chatbots;Object oriented programming;Programming profession;Software engineering;Python;AI;GenAl;Chatbot;ChatGPT;Software Engineering;Computer Science Education;EPICS},
  doi={10.1109/FIE61694.2024.10892934},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10673924,
  author={Lee, Jung X. and Song, Yeong-Tae},
  booktitle={2024 IEEE/ACIS 27th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)}, 
  title={College Exam Grader using LLM AI models}, 
  year={2024},
  volume={},
  number={},
  pages={282-289},
  abstract={By far, the most effective knowledge assessment in college education is to give students exam and grade their answers then assess their level of understanding. However, exam grading can be time-consuming, tedious, cumbersome, and sometimes the grading results are not consistent with the rubric. Here, we propose an AI based exam grader that can not only ease educators’ burden but also produce accurate, consistent, and precise grading results. We have used GPT-3.5, GPT-4.0, and Gemini-pro, respectively, as our grading engine. To verify the correctness, precision, and accuracy of our proposed grader, the results were compared with the instructor’s grading result and also with human grader such as teaching assistants. In our experiment, GPT-4.0 showed the most reliable and consistent results.},
  keywords={Accuracy;Education;Reliability engineering;Software reliability;Artificial intelligence;Engines;Software engineering;ChatGPT;Gemini;grading;college education;artificial intelligence;prompt engineering},
  doi={10.1109/SNPD61259.2024.10673924},
  ISSN={2693-8421},
  month={July},}@INPROCEEDINGS{10754661,
  author={Zabala, Eric and Narman, Husnu S.},
  booktitle={2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, 
  title={Development and Evaluation of an AI-Enhanced Python Programming Education System}, 
  year={2024},
  volume={},
  number={},
  pages={787-792},
  abstract={The integration of Artificial Intelligence (AI) in education has shown promising potential to enhance learning experiences and provide personalized assistance to students. However, existing AI-based educational tools often exhibit limitations, including inconsistent feedback, limited adaptability to diverse learning needs, and difficulties in delivering real-time and accurate assessments. These limitations restrict the full effectiveness of AI in supporting students’ educational journeys. In this paper, we present the development of an AI-based Python programming education system that integrates a Chatbot for student assistance, an automated grading system for feedback, and an entrance exam feature that suggests chapters and sections for review. The Chatbot and grading system employs GPT-3.5 Turbo, leveraging its extensive knowledge base, cost-effectiveness, time efficiency, and adaptability to various programming queries, which enhances student engagement. Although the system underwent interactive testing and continuous improvements, the development process encountered difficulties in maintaining consistent AI feedback and enhancing real-time performance. Users can take quizzes, receive grades, obtain personalized feedback, and get course recommendations. The grading system achieved 28/30 consistency with its output while the course recommendation system achieved $26 / 30$ consistency with its outputs. The results indicate that while the AI-based system aids in learning programming by providing instant feedback and recommendations for improvement, its effectiveness is limited. This project underscores the potential of AI to enhance educational tools and sets the stage for further advancements in AI-driven education systems.},
  keywords={Reviews;Education;Learning (artificial intelligence);Chatbots;Mobile communication;Real-time systems;Programming profession;Recommender systems;Python;Testing;Artificial Intelligence;Python;Education;Advanced Learning Technologies},
  doi={10.1109/UEMCON62879.2024.10754661},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10981398,
  author={Montoya Montoya, José Fabián and Lopez-Vargas, Jorge},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={DS Generative AI for Supporting Teaching Activities}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={Generative Artificial Intelligence (GAI) has become significant in education, particularly for creating content, resources, and automating repetitive and timeconsuming tasks. This project explores GAI’s potential to support teachers in analyzing low-to-medium complexity programs of student’s tasks, supporting the activities of teachers. The proposed solution includes an API and web application built based on the GPT-4o Large Language Model (LLM), specifically designed for teachers. The methodology begins with a review of relevant literature review to identify scenarios where GAI have shown their potential in the educational field. Subsequently, the performance of the GPT-4o model is evaluated in the context of review and analysis of student’s source code, using the Teaching Plans which the task proposals are extracted along with their respective evaluation rubrics, determining the quality and effectiveness of generative AI within this real application.},
  keywords={Generative AI;Source coding;Large language models;Refining;Prototypes;Reliability engineering;Proposals;Iterative methods;Programming profession;Systematic literature review;generative artificial intelligence;education;programming;source code analysis;gpt-4o;api;web application},
  doi={10.1109/EDUNINE62377.2025.10981398},
  ISSN={},
  month={March},}@INPROCEEDINGS{10946635,
  author={Wang, Yizhuo and Cui, Shiqi and Wan, Rongxin and Wang, Jingyi and Wang, Fanggang},
  booktitle={2024 IEEE 24th International Conference on Communication Technology (ICCT)}, 
  title={Large Language Models Based Communication Simulation Platform}, 
  year={2024},
  volume={},
  number={},
  pages={1891-1895},
  abstract={In recent years, Large Language Models (LLMs) have been widely used in various fields, including personalized education, data analysis, disease diagnosis, and engineering design. These advancements have opened new possibilities for wireless communication engineering. In this paper, we propose an LLM-based human-machine collaborative framework to generate a simulation platform for the communication system. The proposed framework effectively combines human experience with the powerful generative capabilities of LLMs through well-designed prompt engineering techniques, enhancing the design of wireless communication systems. Specifically, the proposed prompt engineering framework directs the LLM in tasks such as requirement elicitation, system modeling, and code generation for different modules of wireless communication systems. Parallel tests on the commercially mature LLMs like GPT-3.5 and Claude 3 further demonstrate that our approach can improve the efficiency, quality, and reliability of the design process.},
  keywords={Wireless communication;Codes;Large language models;Human-machine systems;Collaboration;Systems modeling;Reliability engineering;Prompt engineering;Medical diagnosis;Signal to noise ratio;Code generation;human-machine collaboration;large language models;prompt engineering;wireless communication},
  doi={10.1109/ICCT62411.2024.10946635},
  ISSN={2576-7828},
  month={Oct},}@INPROCEEDINGS{10892822,
  author={Pu, Cong},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Generative AI with Data Structures and Algorithm Analysis Course Homework}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper describes how to integrate generative Artificial Intelligence (AI) with Data Structures and Algorithm Analysis (CS2) homework at Oklahoma State University. Data Structures and Algorithm Analysis (CS2) course covers extremely important knowledge and skills of becoming a computer scientist. However, students might fail to meet the learning outcomes of CS2 course, somewhat due to the abstract nature of concepts but also because of a misunderstanding of concepts, the selection of inappropriate data structure and algorithm, a lack of effective debugging skills, and writing inefficient code. Currently we are in an Artificial Intelligence (AI) revolution, and generative AI (also widely known as AI chatbots) are already popular across college and university campuses. Generative AI that are designed to learn and mimic human conversation is capable of generating, translating, or paraphrasing text and answering questions in a way that is often indistinguishable from human-generated content. We investigate the above-mentioned potential challenges faced by students while learning CS2 course at Oklahoma State University (OSU) and redesign the course homework in Fall 2023 semester. The objectives of the redesigned course homework are to provide students with opportunities to use generative AI to support their learning in the CS2 course as well as measure the effectiveness of utilizing generative AI to improve student learning outcomes in the CS2 course. At the end of Fall 2023 semester, we conducted a student perception survey in the CS2 course and collected valuable feedback from 47 out of 61 students (77% response rate). In summary, 85.1%, 76.6%, 74.5%, 63.8%, and 70.2% respondents indicated that generative AI help to understand testing and debugging better, improve coding skills and code quality, design and implement efficient data structures and algorithms, select appropriate algorithms and data structures with the assistance of generative AI, and under-stand the importance of designing and implementing efficient data structures and algorithms, respectively. In this paper, we summarize the experience of redesigning CS2 course homework at OSU, share lessons learned, and provide candid suggestions for utilizing course homework in CS2 courses at other institutions.},
  keywords={Surveys;Codes;Translation;Generative AI;Debugging;Writing;Data structures;Chatbots;Encoding;Testing;Computer Science;Data Structures;Algorithm Analysis;CS2;Artificial intelligence (AI);Generative AI;AI Chatbots},
  doi={10.1109/FIE61694.2024.10892822},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016406,
  author={Wang, Karen D. and Wu, Zhangyang and Tufts, L'Nard and Wieman, Carl and Salehi, Shima and Haber, Nick},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Scaffold or Crutch? Examining College Students' Use and Views of Generative AI Tools for STEM Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Developing problem-solving competency is central to Science, Technology, Engineering, and Mathematics (STEM) education, yet translating this priority into effective approaches to problem-solving instruction and assessment has been a significant challenge. The recent proliferation of generative artificial intelligence (genAI) tools like ChatGPT in higher education introduces new considerations: how to define problem-solving competency in a genAI era, and how these tools can help or hinder students' development of STEM problem-solving competency. Our research takes steps in examining these considerations by studying how and why college students are currently using genAI tools in their STEM coursework, with a specific focus on how they employ these tools to support their problem-solving. We conducted an online survey of 40 STEM college students from diverse institutions across the US. In addition, we surveyed 28 STEM faculty to understand instructor views on effective and ineffective genAI tool use in STEM courses and their guidance for students. Our findings reveal high adoption rates and diverse applications of genAI tools among STEM students. The most common use cases of genAI tools in STEM coursework include finding explanations, exploring related topics, summarizing readings, and helping with problem-set questions. The primary motivation for using genAI tools in STEM coursework was to save time. Moreover, we found that over half of the student participants reported simply inputting a problem for AI to generate solutions, potentially bypassing their own problem-solving processes. These findings indicate that despite high adoption rates, students' current approaches to utilizing genAI tools often fall short in enhancing their own STEM problem-solving competencies. The study also explored students' and STEM instructors' perceptions of the benefits and risks associated with using genAI tools in STEM education. Our findings provide insights into how to guide students on appropriate genAI use in STEM courses and how to design genAI-based tools to foster students' problem-solving competency.},
  keywords={Surveys;Generative AI;Educational technology;Chatbots;Problem-solving;Engineering education;STEM;Generative AI;Educational Technology;STEM},
  doi={10.1109/EDUCON62633.2025.11016406},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10662984,
  author={Meißner, Niklas and Speth, Sandro and Becker, Steffen},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Automated Programming Exercise Generation in the Era of Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Lecturers are increasingly attempting to use large language models (LLMs) to simplify and make the creation of exercises for students more efficient. Efforts are also being made to automate the exercise creation process in software engineering (SE) education. This study explores the use of advanced LLMs, including GPT-4 and LaMDA, for automated programming exercise creation in higher education and compares the results with related work using GPT-3.5-turbo. Utilizing applications such as ChatGPT, Bing AI Chat, and Google Bard, we identify LLMs capable of initiating different exercise designs. However, manual refinement is crucial for accuracy. Common error patterns across LLMs highlight challenges in complex programming concepts, while specific strengths in various topics showcase model distinctions. This research underscores LLMs' value in exercise generation, emphasizing the critical role of human supervision in refining these processes. Our concise insights cater to educators, practitioners, and other researchers seeking to enhance SE education through LLM applications.},
  keywords={Large language models;Refining;Manuals;Chatbots;Internet;Usability;Engineering education;Programming profession;Software engineering;Graphical user interfaces;AI-Generated Exercises;Large Language Models;Programming Exercises;Software Engineering Education},
  doi={10.1109/CSEET62301.2024.10662984},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10578839,
  author={Duong, Ta Nguyen Binh and Meng, Chai Yi},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Automatic Grading of Short Answers Using Large Language Models in Software Engineering Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Short-answer based questions have been used widely due to their effectiveness in assessing whether the desired learning outcomes have been attained by students. However, due to their open-ended nature, many different answers could be considered entirely or partially correct for the same question. In the context of computer science and software engineering courses where the enrolment has been increasing recently, manual grading of short-answer questions is a time-consuming and tedious process for instructors. In software engineering courses, assessments concern not just coding but many other aspects of software development such as system analysis, architecture design, software processes and operation methodologies such as Agile and DevOps. However, existing work in automatic grading/scoring of text-based answers in computing courses have been focusing more on coding-oriented questions. In this work, we consider the problem of autograding a broader range of short answers in software engineering courses. We propose an automated grading system incorporating both text embedding and completion approaches based on recently introduced pre-trained large language models (LLMs) such as GPT-3.5/4. We design and implement a web-based system so that students and instructors can easily leverage autograding for learning and teaching. Finally, we conduct an extensive evaluation of our automated grading approaches. We use a popular public dataset in the computing education domain and a new software engineering dataset of our own. The results demonstrate the effectiveness of our approach, and provide useful insights for further research in this area of AI-enabled education.},
  keywords={Computer science;Training;Costs;Large language models;Focusing;Software;Encoding;automatic grading;large language models;embedding;software engineering courses;short answers},
  doi={10.1109/EDUCON60312.2024.10578839},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10904141,
  author={Haldar, Susmita and Pierce, Mary and Fernando Capretz, Luiz},
  journal={IEEE Access}, 
  title={Exploring the Integration of Generative AI Tools in Software Testing Education: A Case Study on ChatGPT and Copilot for Preparatory Testing Artifacts in Postgraduate Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={46070-46090},
  abstract={Software testing education is important for building qualified testing professionals. To ensure that software testing graduates are ready for real-world challenges, it is necessary to integrate modern tools and technologies into the curriculum. With the emergence of Large Language Models (LLMs), their potential use in software engineering has become a focus, but their application in software testing education remains largely unexplored. This study, conducted in the Capstone Project course of a postgraduate software testing program, was carried out over two semesters with two distinct groups of students. A custom-built Travel Application limited to a web platform was used in the first semester. In the second semester, a new set of students worked with an open-source application, offering a larger-scale, multi-platform experience across web, desktop, and mobile platforms. Students initially created preparatory testing artifacts manually as a group deliverable. Following this, they were assigned an individual assignment to generate the same artifacts using LLM tools such as ChatGPT 3.5 in the first semester and Microsoft Copilot in the second. This process directly compared manually created artifacts and those generated using LLMs, leveraging AI for faster outputs. After completion, they responded to a set of assigned questions. The students’ responses were assessed using an integrated methodology, including quantitative and qualitative assessments, sentiment analysis to understand emotions, and a thematic approach to extract deeper insights. The findings revealed that while LLMs can assist and augment manual testing efforts, they cannot entirely replace the need for manual testing. By incorporating innovative technology into the curriculum, this study highlights how Generative AI can support active learning, connect theoretical concepts with practical applications, and align educational practices with industry needs.},
  keywords={Software testing;Education;Generative AI;Industries;Chatbots;Software engineering;Sentiment analysis;Large language models;Accuracy;Systematic literature review;Capstone project;ChatGPT;generative AI;software testing education;Microsoft Copilot;sentiment analysis},
  doi={10.1109/ACCESS.2025.3545882},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10229357,
  author={Berrezueta-Guzman, Jonnathan and Krusche, Stephan},
  booktitle={2023 IEEE 35th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Recommendations to Create Programming Exercises to Overcome ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={147-151},
  abstract={Large language models, such as ChatGPT, possess the potential to revolutionize educational practices across various domains. Nonetheless, the deployment of these models can inadvertently foster academic dishonesty due to their facile accessibility. In practical courses like programming, where hands-on experience is crucial for learning, relying solely on ChatGPT can hinder students’ ability to engage with the exercises, consequently impeding the attainment of learning outcomes.This paper conducts an experimental analysis of GPT 3.5 and GPT 4, gauging their proficiencies and constraints in resolving a compendium of 22 programming exercises. We discern and categorize exercises based on ChatGPT’s ability to furnish viable solutions, alongside those that remain unaddressed. Moreover, an evaluation of the malleability of the solutions proposed by ChatGPT is undertaken. Subsequently, we propound a series of recommendations aimed at curtailing undue dependence on ChatGPT, thereby fostering authentic competency development in programming. The efficaciousness of these recommendations is underpinned by their integration into the design and delivery of an examination as part of the corresponding course.},
  keywords={Chatbots;Programming profession;interactive learning;online training;education;assessment;plagiarism;autograder;large language models},
  doi={10.1109/CSEET58097.2023.00031},
  ISSN={2377-570X},
  month={Aug},}@INPROCEEDINGS{10190438,
  author={Neumann, Michael and Rauschenberger, Maria and Schön, Eva-Maria},
  booktitle={2023 IEEE/ACM 5th International Workshop on Software Engineering Education for the Next Generation (SEENG)}, 
  title={“We Need To Talk About ChatGPT”: The Future of AI and Higher Education}, 
  year={2023},
  volume={},
  number={},
  pages={29-32},
  abstract={On November 30th, 2022, OpenAI released the large language model ChatGPT, an extension of GPT-3. The AI chatbot provides real-time communication in response to users’ requests. The quality of ChatGPT’s natural speaking answers marks a major shift in how we will use AI-generated information in our day-to-day lives. For a software engineering student, the use cases for ChatGPT are manifold: assessment preparation, translation, and creation of specified source code, to name a few. It can even handle more complex aspects of scientific writing, such as summarizing literature and paraphrasing text. Hence, this position paper addresses the need for discussion of potential approaches for integrating ChatGPT into higher education. Therefore, we focus on articles that address the effects of ChatGPT on higher education in the areas of software engineering and scientific writing. As ChatGPT was only recently released, there have been no peer-reviewed articles on the subject. Thus, we performed a structured grey literature review using Google Scholar to identify preprints of primary studies. In total, five out of 55 preprints are used for our analysis. Furthermore, we held informal discussions and talks with other lecturers and researchers and took into account the authors’ test results from using ChatGPT. We present five challenges and three opportunities for the higher education context that emerge from the release of ChatGPT. The main contribution of this paper is a proposal for how to integrate ChatGPT into higher education in four main areas.},
  keywords={Manifolds;Source coding;Education;Chatbots;Real-time systems;Internet;Proposals;ChatGPT;GPT-3;large language model;higher education;AI influences;position paper},
  doi={10.1109/SEENG59157.2023.00010},
  ISSN={},
  month={May},}@INPROCEEDINGS{10892956,
  author={Hammond, Emily and Faber, Courtney},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work in Progress: Integration of AI Tools on an Open-Ended Computer Programming Project}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress, innovative practice paper describes the design and implementation of a computer programming project that encouraged students to use artificial intelligence (AI) tools (e.g., ChatGPT). This innovative practice was implemented at a state university in an introduction to programming course. Course assessments included weekly homework assignments, an open-ended project, one quiz, and three midterm exams. Students were explicitly told in class and in the syllabus that no AI was allowed for weekly homework assignments; however, students were encouraged to use AI for the open-ended project. This decision was made because the problems on weekly assignments were more structured and could be easily solved by AI tools. In comparison, the learning objective of the project was focused on code design with open-ended requirements making it harder for AI to provide workable code. Students who reported using AI indicated that they used it to help start the project and/or a piece of the project and to aid in debugging or finding errors. Project grades were similar to grades seen in previous years for similar projects; however, grades on midterm two, which occurred after the project, were surprisingly higher than the grades for midterm one and higher than exam grades from previous years on similar topics. At this point, we do not know if/how the project contributed to these improved exam scores. Given the success of the project in its first implementation, Dr. E plans to use the assignment in future semesters. Additionally, Dr. C plans to collect data to begin exploring how the use of AI tools in this open-ended project supported students' learning and understanding of principles in the course.},
  keywords={Codes;Debugging;Chatbots;Artificial intelligence;Programming profession;undergraduate;learning technology;computational thinking},
  doi={10.1109/FIE61694.2024.10892956},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10734661,
  author={Dingle, Adam and Kruliš, Martin},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Tackling Students’ Coding Assignments with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={94-101},
  abstract={State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).CCS CONCEPTS• Computing methodologies → Natural language processing; • General and reference → Evaluation; • Applied computing→ Education.},
  keywords={Computer languages;Codes;Large language models;Computational modeling;Conferences;Education;Encoding;Natural language processing;Programming profession;LLM;large language model;coding;programming;student assignment;teaching},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{11015259,
  author={Liu, Shiqi and Liu, Sannyuya and Sha, Lele and Zeng, Zijie and Gašević, Dragan and Liu, Zhi},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Annotation Guideline-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Automated classification of learner-generated text to identify behavior, emotion, and cognition indicators, collectively known as learning engagement classification (LEC), has received considerable attention in fields such as NLP, learning analytics, and educational data mining. Recently, large language models (LLMs), such as ChatGPT, which are considered promising technologies for artificial general intelligence, have demonstrated remarkable performance in various NLP tasks. However, their capabilities in LEC tasks still lack comprehensive evaluation and improvement approaches. This study introduces a novel benchmark for LEC, encompassing six datasets that cover behavior classification (question and urgency level), emotion classification (binary and epistemic emotion), and cognition classification (opinion and cognitive presence). In addition, we propose the annotation guideline-based knowledge augmentation (AGKA) approach, which leverages GPT-4.0 to recognize and extract label definitions from annotation guidelines and applies random undersampling to select a representative set of examples. Experimental results demonstrate the following: AGKA enhances LLM performance compared to vanilla prompts, particularly for GPT-4.0 and Llama-3 70B; GPT-4.0 and Llama-3 70B with AGKA are comparable to fully fine-tuned models such as BERT and RoBERTa on simple binary classification tasks; for multiclass tasks requiring complex semantic understanding, GPT-4.0 and Llama-3 70B outperform the fine-tuned models in the few-shot setting but fall short of the fully fine-tuned models; Llama-3 70B with AGKA shows comparable performance to GPT-4.0, demonstrating the viability of these open-source alternatives; and the ablation study highlights the importance of customizing and evaluating knowledge augmentation strategies for each specific LLM architecture and task.},
  keywords={Annotations;Guidelines;Cognition;Text categorization;Chatbots;Benchmark testing;Prompt engineering;Tuning;Large language models;Training;Large language models (LLMs);text classification;learning engagement;prompt learning;knowledge augmentation},
  doi={10.1109/TLT.2025.3570775},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10457630,
  author={Hu, Yunwei and Goktas, Yavuz and Yellamati, David Deepak and De Tassigny, Catherine},
  booktitle={2024 Annual Reliability and Maintainability Symposium (RAMS)}, 
  title={The Use and Misuse of Pre-Trained Generative Large Language Models in Reliability Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative Large Language Models (LLMs) have garnered significant attention since the release of ChatGPT in November 2022. Researchers are actively exploring diverse applications to leverage the capabilities of these LLM systems. Within the field of reliability engineering there exists a potential for fruitful utilization of such models. In this paper, we delve into the applications of Large Language Models in reliability engineering, specifically focusing on their impressive language processing capabilities beyond traditional Natural Language Processing (NLP) tasks. Our study aims to evaluate the LLMs' potential in answering complex engineering questions and offering solutions to intricate problems. Additionally, we investigate the limitations of LLMs to understand their boundaries in providing accurate and reliable outputs. The paper emphasizes the significance of prompt engineering to enhance the accuracy and reliability of LLMs for improved performance in quantitative tasks. By incorporating minor prompt engineering techniques, the Large Language Models (LLMs), especially GPT-4, exhibited promising performance in answering Certified Reliability Engineer (CRE) exam questions. Our study involves an analysis of the errors made by the LLMs, allowing for a understanding of their limitations. Drawing from our findings, we provide recommendations on the appropriate application and areas to exercise caution when employing LLMs in the field of reliability engineering. These insights aim to guide practitioners in maximizing the benefits of LLMs while being mindful of their limitations and potential pitfalls. It is important to note that Generative AI and LLMs are rapidly evolving, and the evaluation conducted in this study reflects the test results at the time of writing. We anticipate that LLM responses may vary in the future. We are currently conducting research on developing applications based on LLMs to support the daily tasks of reliability engineers. We are excited about the possibilities and look forward to sharing our outcomes and contributing to the community.},
  keywords={Generative AI;Random access memory;Focusing;Writing;Reliability engineering;Chatbots;Task analysis;Large Language Model;Machine Learning;Reliability;FMEA},
  doi={10.1109/RAMS51492.2024.10457630},
  ISSN={2577-0993},
  month={Jan},}@INPROCEEDINGS{10578934,
  author={Murali, Ritwik and Dhanalakshmy, Dhanya M. and Avudaiappan, Veeramanohar and Sivakumar, Gayathri},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Towards Assessing the Credibility of Chatbot Responses for Technical Assessments in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The recent challenge in higher education is to convey the importance of understanding concepts over rote learning. This challenge has increased in complexity with the arrival of large language model (LLM) based chatbots. Students are increasingly looking to such AI based chatbots as “sources of wisdom” instead of utilizing the same as learning aids. Despite disclaimers by the LLM creators, many students turn to the chatbot for answers to almost all learning assignments. This research work explores the level to which the LLM responses can be utilized for student learning in technical education. By understanding the contradictions between student answers and the responses generated by the LLMs, this work explores the limitations of the LLM based environments towards providing acceptable answers for assessments - specifically within the computer science engineering domain. While numerous studies have concentrated on ChatGPT, it is essential to consider the diverse range of alternative chat-bots accessible online that students may also utilize. Therefore, this work considers 5 popular AI-based chatbots for the study. With the “prompt” being the prime factor that impacts the response from chat-bots, the responses of the chatbots were collected using 2 different prompting techniques. The chatbot responses were evaluated against actual student responses by multiple reviewers to gauge its effectiveness as appropriate student answers. Both students and all chatbots were given questions aligned with the Blooms taxonomy levels (BTL) 1 to 4 in three different subjects. Each of the courses included a diverse range of questions including text-based questions, mathematical problems, and programming questions. The results show that the chatbot responses were acceptable for low BT level questions but failed to answer convincingly when asked for an algorithm. Overall, the chatbot performance (across the tested LLMs) was below average when the question set covered the BTL range 1–4. However, since the answers up to BTL2 were acceptable, LLM based chatbot answers were able to barely pass 1–2 of the 3 subjects (with the best performers scoring near the pass mark). Based on these results, it is possible to conclude that LLM based chatbots cannot be depended on for higher order learning but can be used to aid students who are struggling to pass basic courses.},
  keywords={Technical management;Taxonomy;Grasping;Chatbots;Reliability;Problem-solving;Task analysis;AI Chat-bots;Large Language Models (LLMs);Education;Generative AI},
  doi={10.1109/EDUCON60312.2024.10578934},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10343171,
  author={Reynolds, Sarah and Pate, William C. and Ochoa, Omar},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Ontology and Management System for Learning Outcomes and Student Mastery}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Universities, faculty, and students use Learning Outcomes (LO) to create a shared understanding of the content provided in an individual course, known as Outcome-Based Education (OBE). One area of interest in OBE is evaluating whether the instructor and individual student performance have met the LO, which is integral to ensuring all invested parties are on the same page about class content and student performance. This work proposes a system for the management and evaluation of LO. Primarily, this work defines an ontology to support the management and evaluation of LO via Knowledge Graphs (KG). The KG links individual LO with individual assessment items. Two state-of-the-art Natural Language Processing models, BERT and ChatGPT, are evaluated in respect to their effectiveness in automating this linking. This data allows the educational professional to reflect on how well their assessments match the course's LO. The second part of this system harnesses student data to measure performance in relation to LO. In this Work-in-Progress paper, the system is prototyped and tested on the midterm results of a course in the Software Engineering curriculum. Student performance is documented in relation to each assessment question on the exams to measure student mastery of course material. Through this approach, courses can be evaluated and improved to deliver better quality education to all students. This includes improvements at the course level and possibilities for early intervention to ensure student success. This paper details the development of this system and through its implementation shows how it benefits engineering educators and their students.},
  keywords={Knowledge engineering;Taxonomy;Knowledge graphs;Ontologies;Market research;Chatbots;Software measurement;Learning outcomes;BERT;ontology;knowledge graph;assessment;Bloom's taxonomy},
  doi={10.1109/FIE58773.2023.10343171},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10967440,
  author={Tavasoli, Reza and VarastehNezhad, Arya and Masumi, Mostafa and Taghiyareh, Fattaneh},
  booktitle={2025 29th International Computer Conference, Computer Society of Iran (CSICC)}, 
  title={Analyzing the Mathematical Proficiency of Large Language Models in Computer Science Graduate Admission Tests}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This study evaluates the performance of six prominent Large Language Models (LLMs) on graduate entrance exam multiple-choice mathematics questions in computer science, computer engineering, and information technology programs, with a focus on their cross-lingual capabilities. The selected models, GPT-4o, Claude 3.5 Sonnet, Gemini 1.5 Pro, Llama 3.1 405B, Mistral Large 2, and Qwen 2.5 72B, were tested on 146 questions presented in both Persian and English, spanning four key mathematical domains. Results reveal significant variations in accuracy, with Gemini 1.5 Pro achieving the highest overall performance in English (63.70%) and Claude 3.5 leading in Persian (52.0%). However, some models struggled with maintaining consistent accuracy across languages, showing a cross-lingual performance gap. The findings underscore the potential of LLMs in addressing complex mathematical tasks but also highlight their current limitations, particularly in multilingual contexts. Notable disparities in model performance point to the importance of architectural innovations and multilingual training.},
  keywords={Training;Computer science;Adaptation models;Technological innovation;Accuracy;Large language models;Computational modeling;Mathematical models;Cognition;Multilingual;Large Language Models;Computer Science Education;Mathematical Reasoning;Graduate Entrance Exams;Generative AI;Large Language Models in Education},
  doi={10.1109/CSICC65765.2025.10967440},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10893343,
  author={Ramasamy, Vijayalakshmi and Ramamoorthy, Suganya and Walia, Gursimran Singh and Kulpinski, Eli and Antreassian, Aaron},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing User Story Generation in Agile Software Development Through Open AI and Prompt Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper explores the use of AI technologies in user story generation. With the emergence of agile software development, generating comprehensive user stories that capture all necessary functionalities and perspectives has become crucial for software development. Every computing program in the United States requires a semester-or year-long senior capstone project, which requires student teams to gather and document technical requirements. Effective user story generation is crucial for successfully implementing software projects. However, user stories written in natural language can be prone to inherent defects such as incompleteness and incorrectness, which may creep in during the downstream development activities like software designs, construction, and testing. One of the challenges faced by software engineering educators is to teach students how to elicit and document requirements, which serve as a blueprint for software development. Advanced AI technologies have increased the popularity of large language models (LLMs) trained on large multimodal datasets. Therefore, utilizing LLM-based techniques can assist educators in helping students discover aspects of user stories that may have been overlooked or missed during the manual analysis of requirements from various stakeholders. The main goal of this research study is to investigate the potential application of OpenAI techniques in software development courses at two academic institutions to enhance software design and development processes, aiming to improve innovation and efficiency in team project-based educational settings. The data used for the study constitute student teams generating user stories by traditional methods (control) vs. student teams using OpenAI agents (treatment) such as gpt-4-turbo for generating user stories. The overarching research questions include: RQ-l) What aspects of user stories generated using OpenAI prompt engineering differ significantly from those generated using the traditional method? RQ-2) Can the prompt engineering data provide insights into the efficacy of the questions/prompts that affect the quality and comprehensiveness of user stories created by software development teams? Industry experts evaluated the user stories created and analyzed how prompt engineering affects the overall effectiveness and innovation of user story creation, which provided guidelines for incorporating AI-driven approaches into software development practices. Overall, this research seeks to contribute to the growing body of knowledge on the application of AI in software engineering education, specifically in user story generation. Investigating the use of AI technologies in user story generation could further enhance the usability of prompt engineering in agile software development environments. We plan to expand the study to investigate the long-term effects of prompt engineering on all phases of software development.},
  keywords={Technical requirements;Technological innovation;Agile software development;Collaboration;Software;Prompt engineering;Stakeholders;Usability;Software engineering;Testing;Collaboration network;complex network analysis;structured collaboration network},
  doi={10.1109/FIE61694.2024.10893343},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10748200,
  author={Popescu, Diana M. and Joyner, David A.},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Novelty, Rigidity, and Complexity: Toward Developing AI-Resistant Assessments in an Introductory Computer Science Class}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Since the public launch of ChatGPT on November 20, 2022, there has been significant interest in its role in education. While some analyses focus on its potential to support student learning, a parallel line of investigation examines its potential to facilitate the false demonstration of competency on assessments. A broader underlying question is whether certain skills remain valuable to teach in the age of artificial intelligence, particularly in developing a new generation of computer programmers who continue to employ critical problem-solving skills in their work. The work presented in this paper examines the impact of large language models (LLMs), such as ChatGPT-4, on a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform. The study focuses on the strengths and limitations of LLMs in solving coding assignments while also aiming to identify problems that are resistant to LLM solutions, so these types of specific categories could be employed by other instructors in their MOOC courses to provide a better experience for students. The paper explores GPT’s proficiency in various areas, including pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. The goal is to create a robust framework that discourages over-reliance on AI assistance from some students while preserving the scalability of the course. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
  keywords={Resistance;Computer aided instruction;Electronic learning;Scalability;Large language models;Education;Chatbots;Rigidity;Problem-solving;Programming profession;E-learning;Artificial Intelligence;Applied Computing},
  doi={10.1109/DEMOcon63027.2024.10748200},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10260931,
  author={Laato, Samuli and Morschheuser, Benedikt and Hamari, Juho and Björne, Jari},
  booktitle={2023 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={AI-Assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education}, 
  year={2023},
  volume={},
  number={},
  pages={226-230},
  abstract={The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.},
  keywords={Computer science;Codes;Education;Chatbots;Internet;Artificial intelligence;ChatGPT;Bard;GPT-4;generative language models;large language models;higher education;learning},
  doi={10.1109/ICALT58122.2023.00072},
  ISSN={2161-377X},
  month={July},}@ARTICLE{10628100,
  author={Allen, Mia and Naeem, Usman and Gill, Sukhpal Singh},
  journal={IEEE Transactions on Education}, 
  title={Q-Module-Bot: A Generative AI-Based Question and Answer Bot for Module Teaching Support}, 
  year={2024},
  volume={67},
  number={5},
  pages={793-802},
  abstract={Contributions: In this article, a generative artificial intelligence (AI)-based Q&A system has been developed by integrating information retrieval and natural language processing techniques, using course materials as a knowledge base and facilitating real-time student interaction through a chat interface. Background: The rise of advanced AI exemplified by ChatGPT developed by OpenAI, has sparked interest in its application within higher education. AI has the potential to reshape education delivery through chatbots and related tools, improving remote learning and mitigating challenges, such as student isolation and educator administrative burdens. Yet, ChatGPT’s practical applications in education remain uncertain, potentially due to its novel and enigmatic nature. Additionally, current e-learning chatbot systems often suffer from development complexity and a lack of input from key stakeholders, leading to developer-focused solutions rather than user-centered ones. Intended Outcomes: In this manuscript, we introduce a practical implementation of AI in education by creating a system called Q-Module-Bot that is accessible for both technical and nontechnical educators to harness e-learning benefits and demystify generative pretraining transformer (GPT). Application Design: The proposed Q-Module-Bot system has utilized pretrained large language models (LLMs) to build a Q&A system that helps students with their queries and supports education delivery using content extracted from a virtual learning environment (VLE). Findings: The prototype and system evaluation confirm the effectiveness of a scalable cross-departmental tool featuring source attribution and real-time responses. While successful in encouraging wider acceptance of GPT use cases in higher education, refinements are needed for full integration into the VLE and expansion to other modules/courses.},
  keywords={Chatbots;Education;Artificial intelligence;Stakeholders;Electronic learning;Real-time systems;Plagiarism;Artificial intelligence (AI);chatbots;ChatGPT;e-learning;generative AI;information retrieval (IR);virtual learning environment (VLE)},
  doi={10.1109/TE.2024.3435427},
  ISSN={1557-9638},
  month={Oct},}@INPROCEEDINGS{10893452,
  author={Browning, Jonathan W. and Bustard, John and Anderson, Neil and Galway, Leo},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A Data Science Course Utilizing GenAI}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This innovative practice full paper describes an indepth analysis of the pedagogical implications of incorporating generative artificial intelligence (genAI) tools, specifically Chat-GPT, into a data science course for postgraduate masters computing students. This research is grounded in the implementation of ChatGPT in a data analysis course, aiming to evaluate its effectiveness in fostering students' analytical and decision-making capabilities. The study employs a qualitative methodology to assess the educational outcomes of integrating ChatGPT, focusing on its impact on student engagement, learning efficiency, and the development of critical thinking skills in the context of data science. Through a combination of interviews, and analysis of students' project outcomes, we gather insights into the challenges and opportunities presented using genAI in the data science course. A notable innovation of our approach is the introduction of a dual-report assessment method, which not only evaluates the students' project results but also their proficiency in prompt engineering - a crucial skill for effective interaction with genAI tools. Our findings suggest that while students demonstrate enhanced data analysis skills, they also face difficulties in accurately framing queries to yield useful results from genAI, highlighting an essential area for further curriculum development. Further-more, the work delves into the pedagogical strategies that can optimize the benefits of genAI tools in education. It emphasizes the importance of a structured framework that guides students in the ethical use of genAI, encourages critical reflection on AI-generated content, and fosters a deeper understanding of the underlying algorithms and their implications for data science. The implications of this research extend beyond the classroom, offering valuable insights for instructors, curriculum developers, and policymakers on integrating AI technologies into educational practices. By providing a comprehensive overview of the benefits and challenges associated with the use of ChatGPT in data science education, this paper contributes to the ongoing dialogue on preparing students for a future where genAI might a significant role. In conclusion, this work highlights the potential of genAI to revolutionize data science education by enhancing analytical skills and decision-making capabilities. Continued exploration of effective strategies for integrating AI tools into learning environments, such as data science, is required to ensure that students are equipped with the knowledge and skills necessary to navigate the complexities of genAI for future employment.},
  keywords={Knowledge engineering;Technological innovation;Navigation;Education;Decision making;Data science;Chatbots;Reflection;Prompt engineering;Interviews;computer engineering;data science;education;generative artificial intelligence;student experience},
  doi={10.1109/FIE61694.2024.10893452},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016399,
  author={Romão, Artur C. and Ribeiro, Fabianne and Sousa, Lúcia M. and Neves, António J. R.},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Mapping of Educational Course Descriptions to ESCO Competences Using Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The business sector currently faces a challenge in linking the descriptions of training offers with the actual skills acquired by participants at the time of its completion, posing a barrier for both workers when choosing job offers and companies when selecting candidates based on their skills. To address this issue, the European Union recently made available a database containing the multilingual taxonomy of European Qualifications, Competences, and Occupations (ESCO), which aims to be the fundamental reference for professional integration and mobility within Europe. This taxonomy works as a dictionary that categorizes and describes more than 3000 occupations and 13,900 competences. Consequently, the objective of this research was to develop a computational system capable of processing educational information from course descriptions and mapping it to ESCO competencies. Large Language Models (LLMs), specifically GPT-4, were used to assist in this task. In terms of implementation, the user can interact with the system based on an interface with a chat-like appearance and an API that integrates and communicates with the ESCO API and GPT-4 through Flowise, a workflow framework for LLMs. To validate the system's effectiveness, an experiment was conducted with professors coordinating various courses. They tested the platform and provided feedback on its performance in mapping course descriptions to the appropriate ESCO competences. The ultimate goal of this system is to benefit universities, students, and companies. For universities, it assists in mapping course descriptions to ESCO competencies. For students, it provides a clearer understanding of the skills they will gain from a specific course, assisting in career planning and personal development. For companies, it offers a reliable way to assess the skills of graduates, which improves hiring decisions.},
  keywords={Visualization;Accuracy;Large language models;Taxonomy;Europe;Companies;Reliability;Usability;Software engineering;Qualifications;taxonomies;training and educational offers;skills;information systems;large language models;artificial intelligence},
  doi={10.1109/EDUCON62633.2025.11016399},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10892816,
  author={Mazzone, Samuel B and Forden, Jack and Brylow, Dennis},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring the Potential of Locally Run Large Language (AI) Models for Automated Grading in Introductory Computer Science Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper describes the effectiveness of self-hosted large language models (LLMs) in assisting with the automatic grading of CSI assignments. Educators often rely on automated review of student code submissions in larger courses. Despite recent advancements, current systems primarily focus on assessing functionality, with important aspects such as code structure, efficiency, and style often relegated to secondary foci. LLMs provide an increasingly attractive addition to these systems to enhance those overlooked areas. Prior research has shown LLM's capable of assisting students in understanding and resolving programmer error messages, correcting syntax errors, providing enhanced explanations of code segments, or even generating code. The absence of freely available, purpose-designed LLMs for grading and providing feedback on code submissions prevents widespread adoption by educators. Remotely-hosted systems, such as fine-tuned GPT models, have shown promise, yet the associated risks of privacy breaches, ethical considerations, and recurring costs make this approach unfeasible as a universal solution. To mitigate these concerns, self-hosted open-source models are an alternative that can operate on consumer-grade hardware and prevent some privacy and security concerns. While no purpose-built solution yet exists, it is unclear if any existing models are powerful enough to facilitate automated grading. To explore these questions, we present a two-phase analysis, leveraging real grading data from a semester length, introductory CSI course with 124 students and nine programming projects. Nine stable LLM models were selected and repeatedly prompted to grade student submissions using the same context that a human teaching assistant (TA) was given. This paper analyzes 1,172,383 API requests, totaling 33.4 days of active runtime, evaluating model consistency, ability to adhere to specified constraints, and comparison to human-generated grades. The results show various models' inability to consistently grade assignments, albeit with some exceptions. The importance of providing comprehensive context to models was highlighted, as incomplete contexts resulted in worse performance. Other models struggled with longer prompts, delivering less consistent results. Despite disparities between AI-generated and human-assigned grades, the potential for refinement is clear; improved rubrics or selective fine-tuning could enhance model output. Future work will focus on analyzing models' qualitative justifications for grades, refining rubrics, training on domain-specific datasets, and fine-tuning the highest performing models to potentially improve grading accuracy.},
  keywords={Training;Analytical models;Codes;Runtime;Computational modeling;Large language models;Syntactics;Complexity theory;Security;Context modeling;Large language model (LLMs);automated assessment tools (AATs);CSI},
  doi={10.1109/FIE61694.2024.10892816},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10837624,
  author={Timcenko, Olga},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Case Study: Using Artificial Intelligence as a Tutor for a Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Artificial Intelligence (AI) has emerged as a key tool in reshaping education, particularly in programming courses. This paper presents a case study where second-semester Media Technology students used GitHub Copilot as a coding tutor throughout their coursework and for a three-day Game-jam, during which they developed 2D mobile games as part of their final exam. Students were encouraged to use Copilot to assist with homework assignments and game development, leading to significantly higher-quality projects compared to previous years. The study explores the impact of AI on student performance, the resulting shift in learning dynamics, and potential recommendations for enhancing curriculum and assessment methods in light of AI integration. This paper discusses the benefits, challenges, and recommendations for integrating AI in non-computer science education, emphasizing its role as a tutor for programming courses.},
  keywords={Training;Games;Media;Encoding;Artificial intelligence;Information technology;Programming profession;Software development management;Land mobile radio;Artificial Intelligence in Education;GitHub Copilot;Programming Education;Game Development;Unity;C#;AI Tutoring},
  doi={10.1109/ITHET61869.2024.10837624},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{11016293,
  author={Galatro, Daniela and Chakraborty, Sourojeet},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Strategies to Map Education 5.0 and Industry 5.0 in the Context of a Modernized Undergraduate Program in Chemical Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Education 5.0 is the direct application of novel technologies to consciously create a humanized, holistic teaching experience, to directly target the requirements of Industry 5.0. This work describes the design and implementation of a set of pedagogical strategies systematically employed to comprehensively map Education 5.0 and Industry 5.0, within the context of modernization of the undergraduate Chemical Engineering & Applied Chemistry program, clustered by (i) core courses such as Heat & Mass Transfer, (ii) electives such as Petroleum Processing, and (iii) 500level (undergraduate/graduate) advanced courses, such as Data Based Modelling for Prediction and Control. Implementation strategies include consciously integrating sustainability and engineering safety practices for chemical process design, using Generative Artificial Intelligence (Generative AI) in class to augment student self-learning, data-driven causation and machine learning versus first-principle-based phenomena analysis by employing dynamic process simulation and computational fluid dynamics tools, industry standards, codes and recommended practices, to instill active learning among students, and circularity indicators for process design and description. Examples of active learning initiatives embedded within our strategies include (i) the Petroleum Processing Lab, where students combine chatbots use and Machine Learning (ML) and/or simulation tools to analyze oil price market trends, mass balances crude distillation units, and risk assessments in oil refineries; and (ii) the Heat and Mass Transfer Lab, where students combine data analysis, machine learning and first-principles to describe and analyze heat convection relationships during the lectures. Chatbots assisted activities are qualitatively assessed for accuracy via a novel APC-EPE approach (Assumptions, Process description, and Calculations, with Effective Prompt Engineering); and we have successfully employed the APC-EPE framework to enhance the chances of chatbots providing accurate and reliable results aligned with students' expectations. Vertical integration of such strategies, right from sophomore to final years of our undergraduate program is implemented in tandem with standalone 'practices' in courses; and dedicated process design / capstone courses which combine several of these practices are offered. Our strategies are currently being assessed via anonymized student surveys, thereby attesting towards their effectiveness and high receptivity, as the department gradually transitions to a more modernized curriculum in upcoming years. Student and faculty feedback is identified as critical towards iteratively improving the course/curriculum design process in future, to ensure that the department's teaching approach towards realizing Education 5.0 is perceived as valuable to Industry 5.0 requirements and demands that employers seek from undergraduates. Our efforts are thus impactful towards creating future generations of the industry workforce trained in Education 5.0 to match Industry 5.0's requirements.},
  keywords={Process design;Industries;Accuracy;Computational fluid dynamics;Chemical engineering;Active learning;Machine learning;Chatbots;Fifth Industrial Revolution;Petroleum;Mapping Education 5.0 and Industry 5.0;curriculum modernization;Generative AI;simulation},
  doi={10.1109/EDUCON62633.2025.11016293},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10554757,
  author={Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Let's ask AI About Their Programs: Exploring ChatGPT's Answers to Program Comprehension Questions}, 
  year={2024},
  volume={},
  number={},
  pages={221-232},
  abstract={Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
  keywords={Training;Codes;Storms;Source coding;Writing;Data models;Task analysis;QLCs;large language models;artificial intelligence;introductory programming;program comprehension},
  doi={},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10342898,
  author={Tran, Andrew and Angelikas, Kenneth and Rama, Egi and Okechukwu, Chiku and Smith, David H. and MacNeil, Stephen},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generating Multiple Choice Questions for Computing Courses Using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Generating high-quality multiple-choice questions (MCQs) is a time-consuming activity that has led practitioners and researchers to develop community question banks and reuse the same questions from semester to semester. This results in generic MCQs which are not relevant to every course. Template-based methods for generating MCQs require less effort but are similarly limited. At the same time, advances in natural language processing have resulted in large language models (LLMs) that are capable of doing tasks previously reserved for people, such as generating code, code explanations, and programming assignments. In this paper, we investigate whether these generative capabilities of LLMs can be used to craft high-quality M CQs more efficiently, thereby enabling instructors to focus on personalizing MCQs to each course and the associated learning goals. We used two LLMs, GPT-3 and GPT-4, to generate isomorphic MCQs based on MCQs from the Canterbury Question Bank and an Introductory to Low-level C Programming Course. We evaluated the resulting MCQs to assess their ability to generate correct answers based on the question stem, a task that was previously not possible. Finally, we investigate whether there is a correlation between model performance and the discrimination score of the associated MCQ to understand whether low discrimination questions required the model to do more inference and therefore perform poorly. GPT-4 correctly generated the answer for 78.5% of MCQs based only on the question stem. This suggests that instructors could use these models to quickly draft quizzes, such as during a live class, to identify misconceptions in real-time. We also replicate previous findings that GPT-3 performs poorly on answering, or in our case generating, correct answers to MCQs. We also present cases we observed where LLMs struggled to produce correct answers. Finally, we discuss implications for computing education.},
  keywords={Codes;Correlation;Computational modeling;Education;Real-time systems;Natural language processing;Recycling;large language models;generative AI;multiple-choice questions;computing education},
  doi={10.1109/FIE58773.2023.10342898},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10343296,
  author={Chan, Miguel Morales and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael and De La Roca, Mónica},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={The potential role of AI-based Chatbots in Engineering Education. Experiences from a teaching perspective}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The irruption of Artificial Intelligence (AI) based chatbot tools is undoubtedly at the frontiers of education. AI chatbots in education has emerged as a promising solution to enhance the quality of education and to improve learning outcomes. As all new technology does, it has begun to generate news about prohibition, ethical aspects, anti-plagiarism detection tools, and a series of policies from different educational systems. However, we should not deny the positive aspects of these tools if they are well used. AI-based chatbots have interesting potential to help both teachers and students, who must learn to use them well for their own benefit. This article provides an overview of AI-based chatbots, particularly ChatGPT, an artificial intelligence language model developed by OpenAI. GPT, or “Generative Pre-Training Transformer” is a neural network trained to generate “human-like text” by predicting the next word in a sequence given a large dataset of examples. ChatGPT uses the neural network model and is used to generate responses to students' questions in real time, in the sense of a personal teacher assistant. Chatbots are designed to be able to carryon a natural conversation by understanding the context of the conversation, generating appropriate responses, and engaging in active interaction. Nowadays, this type of tool can generate more than just text; for example, the use of LaTeX code (using TeXGPT) or tools for coding and debugging programming exercises. This work explores the potential role that AI-based chatbots can have in engineering education, by examining the answers of a group of teachers' about how the use of AI-based chatbots can improve the learning process of the students in engineering education. The questions that teachers had to answer, from a pedagogical and technological perspective, are related to how chatbots can be integrated into the curriculum to enhance the efficiency of engineering education, their potential impact on the learning process, and actual examples of possible learning activities using AI-based chatbots in their courses.},
  keywords={Training;Education;Neural networks;Oral communication;Chatbots;Transformers;Real-time systems;AI-based education;Engineering education;Natural Language Processing},
  doi={10.1109/FIE58773.2023.10343296},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10976353,
  author={Gong, Liuying and Chen, Jingyuan and Wu, Fei},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Is ChatGPT a Competent Teacher? Systematic Evaluation of Large Language Models on the Competency Model}, 
  year={2025},
  volume={18},
  number={},
  pages={530-541},
  abstract={The capabilities of large language models (LLMs) in language comprehension, conversational interaction, and content generation have led to their widespread adoption across various educational stages and contexts. Given the fundamental role of education, concerns are rising about whether LLMs can serve as competent teachers. To address the challenge of comprehensively evaluating the competencies of LLMs as teachers, a systematic quantitative evaluation based on the competency model has emerged as a valuable approach. Our study, grounded in the teacher competency model and drawing from 14 existing scales, constructed an evaluation framework called TeacherComp. Based on TeacherComp, we evaluated six LLMs from OpenAI across four dimensions: knowledge, skills, values, and traits. Through comparisons between LLMs’ responses and human norms, we found that: 1) with each successive update, LLMs have shown overall improvements in knowledge, while their skills dimension scores have increasingly aligned with human norms; 2) there are both commonalities and differences in the performance of various LLMs regarding values and traits. For instance, while they all tend to exhibit more negative traits than humans, their morals can vary; and 3) LLMs with reduced security, constructed using jailbreak techniques, exhibit values and traits more closely aligned with human norms. Building on these findings, we provided interpretations and suggestions for the application of LLMs in various educational contexts. Overall, this study helps teachers and students use LLMs in appropriate contexts and provides developers with guidance for future iterations, thereby advancing the role of LLMs in empowering education.},
  keywords={Education;Ethics;Chatbots;Systematics;Standards;Security;Psychology;Large language models;Generative AI;Ciphers;Evaluation;large language models (LLMs);teacher competency},
  doi={10.1109/TLT.2025.3564177},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10663001,
  author={Jacobs, Sven and Jaschke, Steffen},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper presents the use of Retrieval Augmented Generation (RAG) to improve the feedback generated by Large Language Models for programming tasks. For this purpose, corresponding lecture recordings were transcribed and made available to the Large Language Model GPT-4 as external knowledge source together with timestamps as metainformation by using RAG. The purpose of this is to prevent hallucinations and to enforce the use of the technical terms and phrases from the lecture. In an exercise platform developed to solve programming problems for an introductory programming lecture, students can request feedback on their solutions generated by GPT-4. For this task GPT-4 receives the students' code solution, the compiler output, the result of unit tests and the relevant passages from the lecture notes available through the use of RAG as additional context. The feedback generated by GPT-4 should guide students to solve problems independently and link to the lecture content, using the time stamps of the transcript as meta-information. In this way, the corresponding lecture videos can be viewed immediately at the corresponding positions. For the evaluation, students worked with the tool in a workshop and decided for each feedback whether it should be extended by RAG or not. First results based on a questionnaire and the collected usage data show that the use of RAG can improve feedback generation and is preferred by students in some situations. Due to the slower speed of feedback generation, the benefits are situation dependent.},
  keywords={Codes;Large language models;Conferences;Recording;Programming profession;Videos;Programming Education;Feedback;Large language Models;GPT-4;Retrieval Augmented Generation},
  doi={10.1109/CSEET62301.2024.10663001},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{11016495,
  author={Brieven, Géraldine and Malcev, Lev and Donnet, Benoit},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={How to Automate Feedback on Diagrammatic Reasoning with a Relevant Degree of Freedom?}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper considers Café 2.0, an Automated Feedback system designed to support students' diagrammatic reasoning in STEM disciplines. Café 2.0 relies on a predefined error library, metamodels, and rules to correct students' solutions and deliver formative feedback. Implementing such a system requires a balance between constraining the solution syntax to enable AF and leaving freedom to students to reflect on their solution. This paper aims to evaluate whether the level of freedom provided by our AF system sufficiently prepares students for exams. In the exam, they must reason and construct solutions starting with a blank page. This study is conducted in an introductory programming course (CS1), based on two semesters (in 2022 and 2023), where Café 2.0 supports online homework. Findings reveal a discrepancy between students' performance in online homework and their success on exams. While many students feel comfortable with fill-in-the-blank diagrams in their homework, they struggle with the open-ended nature of exam tasks. Our results show that, among the students who succeeded in their online homework in 2023, $20\%$ were still unable to produce any diagram in the exam. Additionally, $70\%$ of them could not correctly provide a text description of their solution. To overcome this limitation, this paper proposes an enhanced system that integrates predefined rules with Large Language Models (LLMs). In this framework, LLMs serve as translators. Students can freely create their diagrams and annotate them with their own textual descriptions using a drawing editor. The LLM then maps these representations into a more structured format that aligns with predefined rules. In this way, Café 2.0 can generate accurate feedback. This transformed representation retains the same informational content as the original, differing only in format. This feature will offer students greater flexibility in constructing their solutions while ensuring that feedback remains precise and consistent by limiting the role of LLMs to translation rather than feedback generation.},
  keywords={Hands;Translation;Limiting;Large language models;Symbols;Metamodeling;Syntactics;Programming;Cognition;Libraries;automated feedback;diagrammatic reasoning;metamodeling;error detection;large language model},
  doi={10.1109/EDUCON62633.2025.11016495},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10663045,
  author={Vierhauser, Michael and Groher, Iris and Antensteiner, Tobias and Sauerwein, Clemens},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Towards Integrating Emerging AI Applications in SE Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial Intelligence (AI) approaches have been incorporated into modern learning environments and software engineering (SE) courses and curricula for several years. However, with the significant rise in popularity of large language models (LLMs) in general, and OpenAI's LLM-powered chatbot ChatGPT in particular in the last year, educators are faced with rapidly changing classroom environments and disrupted teaching principles. Examples range from programming assignment solutions that are fully generated via ChatGPT, to various forms of cheating during exams. However, despite these negative aspects and emerging challenges, AI tools in general, and LLM applications in particular, can also provide significant opportunities in a wide variety of SE courses, supporting both students and educators in meaningful ways. In this early research paper, we present preliminary results of a systematic analysis of current trends in the area of AI, and how they can be integrated into university-level SE curricula, guidelines, and approaches to support both instructors and learners. We collected both teaching and research papers and analyzed their potential usage in SE education, using the ACM Computer Science Curriculum Guidelines CS2023. As an initial outcome, we discuss a series of opportunities for AI applications and further research areas.},
  keywords={Systematics;Large language models;Learning (artificial intelligence);Chatbots;Market research;Artificial intelligence;Engineering education;AI;Roadmap;Software Engineering Education},
  doi={10.1109/CSEET62301.2024.10663045},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10465292,
  author={Butgereit, Laurie and Abugosseisa, Muna Mahmoud},
  booktitle={2023 First International Conference on the Advancements of Artificial Intelligence in African Context (AAIAC)}, 
  title={Final Results: Prof Pi and GPT-4 Tutoring Mathematics in Arabic through Whatsapp}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Mathematics is an ancillary subject in many fields of study. At a university level, mathematics courses are often required of students whose primary course of study might be medicine or computer science. This paper presents the final results of a project which used OpenAI’s GPT-4 API to tutor mathematics to university level students studying at a university in Khartoum, Sudan. The tutoring was done in Arabic. The authors were curious not only of the quality of the mathematics tutoring provided by GPT-4 but also by the quality of the Arabic language input to GPT-4 and output from GPT-4. The GPT-4 API was accessible to students as a Whatsapp bot and students could use the bot 24 hours per day. The Whatsapp bot was named Prof Pi. Although Prof Pi as an artifact has been previously reported by the authors, a brief description of how Prof Pi works is provided in this paper for the convenience of the reader. The primary goal of this paper, however, is to present the final results from questionnaires filled by the students who took part in the research.},
  keywords={Computer science;Freeware;Urban areas;Chatbots;Mathematics;Internet telephony;Interviews;GPT-4;chatGPT;Whatsapp;Mathematics;Tutoring},
  doi={10.1109/AAIAC60008.2023.10465292},
  ISSN={},
  month={Nov},}@BOOK{10522552,
  author={Bodungen, Clint and Crow, Aaron},
  booktitle={ChatGPT for Cybersecurity Cookbook: Learn practical generative AI recipes to supercharge your cybersecurity skills},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master ChatGPT and the OpenAI API and harness the power of cutting-edge generative AI and large language models to revolutionize the way you perform penetration testing, threat detection, and risk assessment.Key FeaturesEnhance your skills by leveraging ChatGPT to generate complex commands, write code, and create toolsAutomate penetration testing, risk assessment, and threat detection tasks using the OpenAI API and Python programmingRevolutionize your approach to cybersecurity with an AI-powered toolkitPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionAre you ready to unleash the potential of AI-driven cybersecurity? This cookbook takes you on a journey toward enhancing your cybersecurity skills, whether you’re a novice or a seasoned professional. By leveraging cutting-edge generative AI and large language models such as ChatGPT, you'll gain a competitive advantage in the ever-evolving cybersecurity landscape. ChatGPT for Cybersecurity Cookbook shows you how to automate and optimize various cybersecurity tasks, including penetration testing, vulnerability assessments, risk assessment, and threat detection. Each recipe demonstrates step by step how to utilize ChatGPT and the OpenAI API to generate complex commands, write code, and even create complete tools. You’ll discover how AI-powered cybersecurity can revolutionize your approach to security, providing you with new strategies and techniques for tackling challenges. As you progress, you’ll dive into detailed recipes covering attack vector automation, vulnerability scanning, GPT-assisted code analysis, and more. By learning to harness the power of generative AI, you'll not only expand your skillset but also increase your efficiency. By the end of this cybersecurity book, you’ll have the confidence and knowledge you need to stay ahead of the curve, mastering the latest generative AI tools and techniques in cybersecurity.What you will learnMaster ChatGPT prompt engineering for complex cybersecurity tasksUse the OpenAI API to enhance and automate penetration testingImplement artificial intelligence-driven vulnerability assessments and risk analysesAutomate threat detection with the OpenAI APIDevelop custom AI-enhanced cybersecurity tools and scriptsPerform AI-powered cybersecurity training and exercisesOptimize cybersecurity workflows using generative AI-powered techniquesWho this book is forThis book is for cybersecurity professionals, IT experts, and enthusiasts looking to harness the power of ChatGPT and the OpenAI API in their cybersecurity operations. Whether you're a red teamer, blue teamer, or security researcher, this book will help you revolutionize your approach to cybersecurity with generative AI-powered techniques. A basic understanding of cybersecurity concepts along with familiarity in Python programming is expected. Experience with command-line tools and basic knowledge of networking concepts and web technologies is also required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805125112},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10522552},}@INPROCEEDINGS{10722841,
  author={Akbar Khan, Muhammad Fawad and Ramsdell, Max and Nguyen, Ha and Karimi, Hamid},
  booktitle={2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Human Evaluation of GPT for Scalable Python Programming Exercise Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Online coding platforms (OCPs) often offer a limited selection of exercises, which can restrict the scope of Computer Science (CS) education. This study investigates the capabilities of Large Language Models (LLMs), particularly GPT-4 Turbo, in broadening this scope by autonomously generating Python programming exercises. These exercises are tailored to the CS1 curriculum-an introductory course in computer science. Utilizing curriculum-driven prompt engineering, we developed a dataset of 11,700 exercises, characterized by a variety of cate-gories, types, and difficulty levels. These exercises are distributed across 78 unique topics, which were derived from the CS1 course catalogs of leading universities and supplemented with online educational resources. To evaluate the effectiveness of GPT-4 Turbo in generating CSI Python programming exercises, we conducted a user study involving both students and instruc-tors. The study focused on several metrics: exercise quality, curriculum relevance, understandability, appropriate difficulty level, and the generation of useful hints. Our findings indicate that GPT-4 Turbo can produce high-quality, educationally effective programming exercises at scale, provided that the prompts are systematically crafted. Based on insights from the user study, adjustments to prompt design are recommended to optimize exercise generation. Our research concludes that GPT-4 Turbo can be seamlessly integrated into AI-driven OCPs, offering a scalable, cost and time-effective method to enhance CS edu-cation. This is achieved through targeted prompt engineering and thorough data preprocessing to mitigate inconsistencies. The code is available online: https://github.com/DSAatUSU/GPT_CS1400_Exercise_Generation},
  keywords={Measurement;Large language models;Education;Data science;Encoding;Computer science education;Prompt engineering;Programming profession;Standards;Python;Large Language Models;GPT;Python Exercises Generation;Human Evaluation Computer Science Education},
  doi={10.1109/DSAA61799.2024.10722841},
  ISSN={2766-4112},
  month={Oct},}@ARTICLE{10553643,
  author={Karnouskos, Stamatis},
  journal={IEEE Open Journal of the Industrial Electronics Society}, 
  title={The Relevance of Large Language Models for Project Management}, 
  year={2024},
  volume={5},
  number={},
  pages={758-768},
  abstract={The rise of artificial intelligence, particularly the emergence of large language models (LLMs) like ChatGPT, continuously reveals numerous advantages across various domains. However, the area of project management has not yet been sufficiently explored. This study fills the research gap by conducting an empirical evaluation of three well-known LLMs: OpenAI's ChatGPT-3.5 and ChatGPT-4, as well as Google's Bard. The evaluation involves subjecting these LLMs to tests designed to prepare professionals for project management certification by the Project Management Institute. The findings cast a positive light on all three LLMs, with each model achieving scores exceeding 82%. Key insights acquired include: LLMs demonstrate the ability to effectively answer project management certification exam questions; LLMs and project managers should be viewed as a dynamic and complementary partnership; and project management certification should evolve to include an assessment of how project managers collaborate with LLMs to enhance project management.},
  keywords={Project management;Certification;Chatbots;Best practices;Generative AI;Artificial intelligence;Large language models;Bard;ChatGPT;Generative artificial intelligence (AI);large language models (LLMs);project management},
  doi={10.1109/OJIES.2024.3412222},
  ISSN={2644-1284},
  month={},}@INPROCEEDINGS{10343037,
  author={Maher, Mary Lou and Tadimalla, Sri Yash and Dhamani, Dhruv},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Exploratory Study on the Impact of AI tools on the Student Experience in Programming Courses: an Intersectional Analysis Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress paper presents a study that sheds light on the concerns that students may not develop sufficient programming skills and as a result, be less competent with the use of ChatGPT. The potential benefits for students are significant: Access to ChatGPT increases the ability for students to work constructively on their own schedule. The ease of use of ChatGPT may engage students who might otherwise hesitate in asking for support. Before these tools can be meaningfully introduced into a course, work must be done to study the impact of these AI tools on a student's ability to learn. In this study, participants are recruited from introductory Java programming courses at a large public university in the United States. This paper presents preliminary findings from a mixed method study design that consists of a pre-task assessment quiz; and a programming task in one of three conditions: (1) with no external help, (2) with the help of an AI chatbot, or (3) with the help of a generative AI tool like GitHub Copilot; followed by a post-task assessment and an interview on their experience and perceptions of the tools. Our preliminary findings describe our data collection, thematic analysis of the students' prompts and chatGPT responses, and a summary of the experience for 3 students. Our findings demonstrate a range of students' attitudes and behaviors towards chatGPT that provides insight for future research and plans for incorporating such AI tools in a course.},
  keywords={Java;Schedules;Data collection;Chatbots;Behavioral sciences;Artificial intelligence;Task analysis;ChatGPT;CS education;Student Experience;Intersectionality},
  doi={10.1109/FIE58773.2023.10343037},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10467740,
  author={Butgereit, Laurie and Abugosseisa, Muna Mahmoud and Elbashir, Mohammed},
  booktitle={2024 International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA)}, 
  title={Dynamic Reconfiguring of GPT-4 Based Tutors to Become GPT-4 Based Teachers in Underserved Areas in Africa and the Environs}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The popular GPT-4 API boasts excellent academic records of passing a number of standardized tests. As such it is used in a number of tutoring systems providing students and pupils with access to artificially intelligent tutors when help is not easily available. Tutoring and teaching, however, are different. In many underserved areas in Africa and the environs, students and pupils may attend formal school but then after hours no tutors are nearby to assist them with their studies and homework. Previous research by the authors has described mobile tutoring artifacts linking the popular Whatsapp mobile chat app with GPT-4 to provide that tutoring. In other underserved areas (especially in war torn areas), however, there may not be even teachers to provide the initial classroom instruction or Zoom based instruction. In such case these mobile tutoring artifacts need to be dynamically reconfigured to act as full teachers to these students. This paper describes the research to dynamically reconfigure GPT-4 based mobile tutors to become GPT-4 based mobile teachers wheGPT-4, chatGPT, Whatsapp, Tutoring, Java Programmingn necessary.},
  keywords={Freeware;Java;Education;Africa;Chatbots;Pupils;Internet telephony;component;formatting;style;styling;insert},
  doi={10.1109/ACDSA59508.2024.10467740},
  ISSN={},
  month={Feb},}@BOOK{10769215,
  author={Meyer, Lucas A.},
  booktitle={Building AI Applications with Microsoft Semantic Kernel: Easily integrate generative AI capabilities and copilot experiences into your applications},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Unlock the power of GenAI by effortlessly linking your C# and Python apps with cutting-edge models, orchestrating diverse AI services with finesse, and crafting bespoke applications through immersive, real-world examplesKey FeaturesLink your C# and Python applications with the latest AI models from OpenAICombine and orchestrate different AI services such as text and image generatorsCreate your own AI apps with real-world use case examples that show you how to use basic generative AI, create images, process documents, use a vector databasePurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced world of AI, developers are constantly seeking efficient ways to integrate AI capabilities into their apps. Microsoft Semantic Kernel simplifies this process by using the GenAI features from Microsoft and OpenAI. Written by Lucas A. Meyer, a Principal Research Scientist in Microsoft’s AI for Good Lab, this book helps you get hands on with Semantic Kernel. It begins by introducing you to different generative AI services such as GPT-3.5 and GPT-4, demonstrating their integration with Semantic Kernel. You’ll then learn to craft prompt templates for reuse across various AI services and variables. Next, you’ll learn how to add functionality to Semantic Kernel by creating your own plugins. The second part of the book shows you how to combine multiple plugins to execute complex actions, and how to let Semantic Kernel use its own AI to solve complex problems by calling plugins, including the ones made by you. The book concludes by teaching you how to use vector databases to expand the memory of your AI services and how to help AI remember the context of earlier requests. You’ll also be guided through several real-world examples of applications, such as RAG and custom GPT agents. By the end of this book, you'll have gained the knowledge you need to start using Semantic Kernel to add AI capabilities to your applications.What you will learnWrite reusable AI prompts and connect to different AI providersCreate new plugins that extend the capabilities of AI servicesUnderstand how to combine multiple plugins to execute complex actionsOrchestrate multiple AI services to accomplish a taskLeverage the powerful planner to automatically create appropriate AI callsUse vector databases as additional memory for your AI tasksDeploy your application to ChatGPT, making it available to hundreds of millions of usersWho this book is forThis book is for beginner-level to experienced .NET or Python software developers who want to quickly incorporate the latest AI technologies into their applications, without having to learn the details of every new AI service. Product managers with some development experience will find this book helpful while creating proof-of-concept applications. This book requires working knowledge of programming basics.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835469590},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769215},}@INPROCEEDINGS{10602701,
  author={Luen William, Cheong Weng and Lim, Tong Ming},
  booktitle={2024 IEEE 4th International Conference on Electronic Communications, Internet of Things and Big Data (ICEIB)}, 
  title={Comparative Studies: Leveraging Large Language Model In Theoritical and Practical Assessment Sample Question-Answer Bank on Programming Related Subjects}, 
  year={2024},
  volume={},
  number={},
  pages={331-335},
  abstract={Practical Code Assessment has been important in assessing students' level of understanding, coding, and assessing/evaluating. One of the challenges faced by lecturers is the difficulty in producing questions and answers creatively. To address this issue, an experimental proof-of-concept (POC) prototype was developed using Natural Language Processing (NLP) and Prompt Engineering techniques in the Large Language Model (LLM) to generate practical and high-quality questions and answers. Two Large Language Models, namely LLaMa2-7b and Mixtral-7b were compared to provide a scalable POC solution. Through evaluation and benchmarking, the prototype was tested based on Human-level Performance (HLP) standards. This prototype enhanced the work efficiency of the lecturers as it shortened the time to create questions and answers for assessments, which eventually enhanced learning outcomes and the educational, learning, and teaching experience.},
  keywords={Training;Codes;Large language models;Prototypes;Natural language processing;Encoding;Prompt engineering;large language model (LLM);natural language processing (NLP);prompt engineering;practical code assessment},
  doi={10.1109/ICEIB61477.2024.10602701},
  ISSN={},
  month={April},}@INPROCEEDINGS{10825505,
  author={Le, Linh and Tran, Dung},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={On Text Granularity and Metric Frameworks for Large Language Model Content Detection}, 
  year={2024},
  volume={},
  number={},
  pages={8301-8308},
  abstract={Breakthroughs in Large Language Models (LLMs) have allowed Artificial Intelligence (AI) assistant systems to provide quality information with conveniences. An issue is paralleling the advantages, however. One among the problems of LLM generated content is that they seem indistinguishable from that of human which leads to numerous issues in areas like science, education, information security, etc. Furthermore, approaches in LLM content detection are either computationally expensive or need the LLMs’ internal computations which make them more difficult to be used by the public. Addressing the research gap, we present a metric learning framework for LLM text detection that is balanced for resources, accessibility, and performance. Specifically, the detection framework relies on metric learning to evaluate the similarity between a given text to an equivalent example from LLMs and verify whether the former is from human or AI. The framework can be trained in triplets or pairs of text instances from the same contexts at either the full-text or the sentence granularity levels. For benchmarking, five corpora totalling over 95,000 contexts and responses from human and GPT-3.5 TURBO or GPT-4 TURBO are developed. In term of performance, our architectures maintain 0.87 to 0.95 F1 scores throughout multiple experiment settings. Our framework also requires much less time in training and inference compared to RoBERTa, LLaMA 3, and Ghostbuster, while having 90% to 150% performances of the best benchmark.},
  keywords={Measurement;Training;Computational modeling;Large language models;Training data;Text detection;Computer architecture;Benchmark testing;Transformers;Vectors;LLM text detection;metric learning;text granularity;triplet learning;contrastive learning},
  doi={10.1109/BigData62323.2024.10825505},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10893501,
  author={Chan, Rosanna Yuen-Yan and Chan, Cecilia Ka Yuk and Jong, Morris Siu-Yung and Hu, Zihao and Zhang, Yuming},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Engineering Class Students' Epistemic Cognition when Interacting with Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work in progress belongs to the innovative practice category. Nowadays, generative AI (also known as GenAI) can produce novel data samples that closely resemble authentic datasets. The advent of large language models (LLMs), in particular, has caused a huge interest in utilizing GenAI within and beyond the realm of higher education. However, little about engineering students' views and behaviours related to knowing and knowledge when using GenAI, such as ChatGPT, is known. In this WIP, we have engaged a class of N = 37 engineering students taking a postgraduate course titled “Social Media Analytics”. They were required to write essays related to their course learning in the form of blog posts. They were required to use LLM tools, such as ChatGPT, to assist their writing processes. Their GenAI usage was guided by the cognitive-agent approach, Search Tree, Analyze and Repair, and Selection (STARS), while STARS was proposed by Kirk et al. in AAAI 2024 to extend and complement prompt engineering. In addition, the participants were invited to fill in the Epistemic Cognition Inventory (ECI) questionnaire to associate five aspects of epistemic cognition (EC) with their writing experience. It is confirmed in our results that students' EC, i.e., their beliefs related to knowledge and knowing, significantly predict their prompting engagement and academic performance. However, students' academic performance is found to be significantly and negatively associated with their preference for GenAI usage. Here, we have uncovered engineering students' EC when interacting with generative AI, an area where little has been known so far. Our findings also suggest that proper use of GenAI prompting might promote engineering students' EC and, therefore, engineering learning.},
  keywords={Social networking (online);Education;Stars;Writing;Maintenance engineering;Chatbots;Cognition;Reliability;Prompt engineering;Engineering students},
  doi={10.1109/FIE61694.2024.10893501},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10343457,
  author={Kiesler, Natalie and Lohr, Dominic and Keuning, Hieke},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring the Potential of Large Language Models to Generate Formative Programming Feedback}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Ever since the emergence of large language models (LLMs) and related applications, such as ChatGPT, its performance and error analysis for programming tasks have been subject to research. In this work-in-progress paper, we explore the potential of such LLMs for computing educators and learners, as we analyze the feedback it generates to a given input containing program code. In particular, we aim at (1) exploring how an LLM like ChatGPT responds to students seeking help with their introductory programming tasks, and (2) identifying feedback types in its responses. To achieve these goals, we used students' programming sequences from a dataset gathered within a CS1 course as input for ChatGPT along with questions required to elicit feedback and correct solutions. The results show that ChatGPT performs reasonably well for some of the introductory programming tasks and student errors, which means that students can potentially benefit. However, educators should provide guidance on how to use the provided feedback, as it can contain misleading information for novices.},
  keywords={Analytical models;Codes;Error analysis;Computational modeling;Chatbots;Task analysis;Programming profession;ChatGPT;large language models;feedback;feedback types;introductory programming},
  doi={10.1109/FIE58773.2023.10343457},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578596,
  author={Weber, Jason L and Neda, Barbara Martinez and Juarez, Kitana Carbajal and Wong–Ma, Jennifer and Gago–Masague, Sergio and Ziv, Hadar},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Beyond the Hype: Perceptions and Realities of Using Large Language Models in Computer Science Education at an R1 University}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={With the mainstream adoption of Large Language Models (LLMs) over the last year, members of both academia and the media have raised concerns around the potential impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption and perception of LLMs among the CS education community in an R1 University to distinguish reality from hype. To this end, we conduct a large survey study targeting three populations participating in computing courses at the university: intro-sequence students (ISS), experienced students (ES), and faculty. Our survey seeks to gather insight around the different populations' perceptions of LLMs in education, as well as how these perceptions may be changing as LLMs improve. Our results show several significant differences across the views of 760 respondents. Most students report LLMs' un-paralleled potential for quick information access, yet many harbor concerns about their reliability and impact on academic integrity. Additionally, while ES rapidly integrate LLMs into their learning, ISS and faculty remain cautious, highlighting a stark contrast in adoption rates. Faculty are unconvinced of LLMs' educational benefits and are concerned about potential challenges in evaluating students' learning outcomes. LLMs are reshaping pedagogical approaches and student engagement. However, with the notable reservations expressed by certain segments, particularly by faculty and ISS, there is an imperative for careful, informed, and ethical integration to ensure that these tools enhance rather than compromise the educational experience.},
  keywords={Surveys;Ethics;Accuracy;Atmospheric measurements;Sociology;Media;Particle measurements;Large Language Models (LLMs);Generative AI;Academic Integrity;Student Perception;Faculty Perception;ChatGPT;AI Tools},
  doi={10.1109/EDUCON60312.2024.10578596},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10843532,
  author={Alidadi, Marzieh and Taghiyareh, Fattaneh and Shahhoseini, Narges},
  booktitle={2024 11th International Symposium on Telecommunications (IST)}, 
  title={Evaluating LLM-Generated Persian Questions for Teaching Conditional Programming Using Bloom’s Taxonomy}, 
  year={2024},
  volume={},
  number={},
  pages={726-730},
  abstract={The use of Large Language Models (LLMs) to generate educational content is increasingly becoming popular, but we still need to learn more about their effectiveness in non-English languages, especially for professional areas such as teaching computational concepts. Using Bloom’s taxonomy as a framework of assessment, this study evaluates the ability of LLMs to author Persian (Farsi) Learning Objects (LOs) for teaching conditional programming. We provided four LLMs (BloomGPT, Code Tutor, Copilot, and LLaMa) with a prompt in Persian to create educational questions and exercises to teach conditional programming structures to novice learners. A group of experts was asked to evaluate questions generated by LLMs based on their alignment with the specified level of Bloom’s cognitive domain, suitability for teaching conditional programming structures, and clarity in using Persian language. Results show almost no agreement among experts in language clarity and fair agreement on other aspects of the study. BloomGPT proves itself to be dominant overall in Bloom’s Taxonomy, especially at the “Analyze” level. Meanwhile, Copilot closely followed Code Tutor in most aspects of the study. Our findings provide insights into the ability of LLMs to design high-quality Persian learning resources in computer programming.},
  keywords={Codes;Large language models;Taxonomy;Education;Telecommunications;Programming profession;Large Language Models (LLMs);Artificial Intelligence (AI);Learning Objects (LOs);Educational Contents;Persian;Question Generation;Bloom’s Taxonomy},
  doi={10.1109/IST64061.2024.10843532},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10664825,
  author={Simaremare, Mario E. S. and Pardede, Chandro and Tampubolon, Irma N. I. and Simangunsong, Daniel A. and Manurung, Putri E.},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={The Penetration of Generative AI in Higher Education: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Context: The global teacher shortage crisis is a severe challenge. The crisis also rises in Indonesia, where the problem extends to unequal teaching quality and learning facilities. This situation seriously threatens the Indonesian 2045 vision of being a developed country with knowledgeable human resources. The advancement of AI brings opportunities to address the challenges. In recent years, there has been a wave of generative AI (GenAI) technologies and their adoption in education. However, there is no research on the penetration of such technology in our learning environment. Objective: In this study, we investigate the penetration of GenAI by students in a higher education setting. Method: We surveyed 1,157 students of Institut Teknologi Del, a private university in western Indonesia, and developed local knowledge based on the responses. Results: Our results show that most students are well aware of GenAI technologies (70.96%) and have used them to support their learning (98.96%). The top five most used GenAI tools are GitHub Copilot, OpenAI ChatGPT, Codex, Grammarly, and ChatPDF. Conclusion: GenAI is already part of the daily learning process. We believe that, sooner or later, GenAI will be one of many deciding factors in our future education systems, and we must be ready to adapt to it.},
  keywords={Surveys;Ethics;Generative AI;Source coding;Education;Knowledge based systems;Chatbots;education;generative AI;student;survey},
  doi={10.1109/ISEC61299.2024.10664825},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10343215,
  author={Hallan Graven, Olaf and MacKinnon, Lachlan},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Developing Higher Education – Post-Pandemic – Influenced by AI}, 
  year={2023},
  volume={},
  number={},
  pages={01-08},
  abstract={The impact of the recent pandemic on Higher Education has been widely discussed in terms of the effects on students and the loss of the normal educational experience, accompanied by discussions of how to return to normality. However, in this paper the authors challenge the reality of that previous so-called normality and propose a number of changes to academic practices to take advantage of the opportunities offered by this break in existing practice. Additionally, new developments in AI technology, particularly in chatbots, present significant challenges to existing assessment practices, which were already under challenge from existing research. This also presents significant opportunities to introduce new, academically focused and effective assessment practices and instruments, taken from existing research, to improve the quality of evaluation of student learning in higher education. So, this paper has two main considerations: the development of better student engagement models to enhance cohort effects in the student experience; and the introduction of improved assessment practices and instruments from existing research, in particular focusing on student ownership of evaluation models. It discusses a number of existing research outputs, several of them produced by the authors, and some current initiatives, and looks at the pros and cons of each, in terms of effectiveness and staff and student responses. It has been widely reported that the student experience across a wide range of subjects, and in the whole range of higher education institutions, has been very badly affected by lockdowns and other changes brought about by the pandemic. In the engineering/computing community the authors have experienced first-hand the changes occasioned during this period, and have seen students become isolated, disaffected, anti-social and, in many cases, disengaged from their studies. It can be argued that one key criterion of the student experience that online delivery of learning does not support well is cohort-formation, and that developing entry-level cohort-based learning experiences, both online and face-to-face, offers a route more effective student engagement and retention. The authors discuss a number of such initiatives reported in existing research, and also describe a new initiative being developed at their own institution, based on early immersion in advanced technologies to spark interest and creativity, and thence engagement, in entry-level technology students. With regard to assessment and evaluation practices, there is a huge body of existing research questioning the widely used examination and coursework processes, arguing that these are only retained for administrative and cost efficiencies, not for any academic benefit. The recent release of ChatGPT by OpenAI has added considerable flame to the fire of essay-mills, code-farms, and bespoke thesis-writing, which has supported students cheating in assessment processes for many years. The authors take this opportunity to reconsider assessment practices, in the light of many successful models reported in the existing research, and to develop a new model of assessment, where students take responsibility for the ownership and evaluation of their own learning, mediated by academic processes.},
  keywords={Pandemics;Publishing;Instruments;Education;Force;Focusing;Fires;Assessment;AI;Cohort building;student engagement},
  doi={10.1109/FIE58773.2023.10343215},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10196869,
  author={Feng, Yunhe and Vanam, Sreecharan and Cherukupally, Manasa and Zheng, Weijian and Qiu, Meikang and Chen, Haihua},
  booktitle={2023 IEEE 47th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data}, 
  year={2023},
  volume={},
  number={},
  pages={876-885},
  abstract={The recent advancements in Artificial Intelligence, particularly in large language models and generative models, are reshaping the field of software engineering by enabling innovative ways of performing various tasks, such as programming, debugging, and testing. However, few existing works have thoroughly explored the potential of AI in code generation and users’ attitudes toward AI-assisted coding tools. This knowledge gap leaves it unclear how AI is transforming software engineering and programming education. This paper presents a scalable crowdsourcing data-driven framework to investigate the code generation performance of generative large language models from diverse perspectives across multiple social media platforms. Specifically, we utilize ChatGPT, a popular generative large language model, as a representative example to reveal its insights and patterns in code generation. First, we propose a hybrid keyword word expansion method that integrates words suggested by topic modeling and expert knowledge to filter relevant social posts of interest on Twitter and Reddit. Then we collect 316K tweets and 3.2K Reddit posts about ChatGPT’s code generation, spanning from Dec. 1, 2022 to January 31, 2023. Our data analytics show that ChatGPT has been used in more than 10 programming languages, with Python and JavaScript being the two most popular, for a diverse range of tasks such as code debugging, interview preparation, and academic assignment solving. Surprisingly, our analysis shows that fear is the dominant emotion associated with ChatGPT’s code generation, overshadowing emotions of happiness, anger, surprise, and sadness. Furthermore, we construct a ChatGPT prompt and corresponding code dataset by analyzing the screen-shots of ChatGPT code generation shared on social media. This dataset enables us to evaluate the quality of the generated code, and we have released this dataset to the public. We believe the insights gained from our work will provide valuable guidance for future research on AI-powered code generation.},
  keywords={Codes;Social networking (online);Debugging;Chatbots;Software;Task analysis;Interviews;ChatGPT;Coding Generation;Software Engineering;Large Language Models (LLMs);Generative Models;Social Media},
  doi={10.1109/COMPSAC57700.2023.00117},
  ISSN={0730-3157},
  month={June},}@INPROCEEDINGS{10893102,
  author={Oh, Sunggyeol and Cao, Yi and Katz, Andrew and Zhao, Jialu},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Explore Public's Perspectives on Generative AI in Computer Science (CS) Education: A Social Media Data Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice full paper aims to analyze the public's comments on generative artificial intelligence (GAI) in computer science (CS) education, by the BERT-based model and Large Language Model (LLM) approaches to sentiment analysis and contextualize the results within broader educational and technological landscapes. Artificial intelligence (AI) has played a crucial role in advancing technical development throughout many areas. Evidence points toward the likelihood of major developmental breakthroughs unfolding soon in those sectors. Education is one such area. While there is certainly a possibility for hype and unfulfilled promises, the advent of available GAI platforms, such as ChatGPT, has caused a surge of scholarly interest in the impact of these technologies on CS education. Amid the growing debate, both the potential benefits and concerns of GAI in this sector are increasingly coming to the fore as people grapple with the tradeoffs associated with these technologies when applied in education settings. One can imagine the range of conversations around the topic, but that is difficult to use as input for policymakers and administrators without a more concrete understanding. To wit, there remain open questions about which benefits and concerns people tend to focus on when discussing GAI in education. This large-scale qualitative study addresses that gap by exploring the public's perspectives on GAI in CS education. We engage in this work by collecting and analyzing data from social media platforms, specifically Reddit comments. The social media dataset was analyzed using machine learning (ML) techniques to identify topics based on sentiment analysis. The study's objective was to document and characterize the public's perspectives concerning the general characteristics of GAI, its features related to learning, and its usability in educational settings. Through sentiment analysis using Large Language Models (LLM), the study revealed an overall positive public perception toward using generative AI in CS education, with over 57% of comments being favorable, while also identifying prominent topics of interest and concerns, such as the potential benefits of personalized learning support and automated grading, as well as issues like academic dishonesty, perpetuation of biases, over-reliance on AI hindering critical thinking, displacement of human instructors, and the need for updated curricula. The insights gleaned from the analysis will be instrumental in computing educators gaining a more profound comprehension of GAI 'srole in education and the subsequent development of GAI -enriched curricula.},
  keywords={Computer science;Bridges;Sentiment analysis;Ethics;Social networking (online);Generative AI;Large language models;Education;Problem-solving;Artificial intelligence;Generative AI;computer science education;social media dataset;sentiment analysis},
  doi={10.1109/FIE61694.2024.10893102},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10893046,
  author={Liu, Yi},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Conversational Large Language Models into Student Learning: A Case Study of ChatGPT in Software Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper describes a pilot study exploring the integration of ChatGPT, a Conversational Large Language Model (LLM), into the student learning process in software engineering education, which emphasizes principles and methodologies in software development. Focused on a software engineering class, the study examines ChatGPT as a tool for problem clarification, modeling assistance, system design feedback, and implementation support in a project on modeling, designing, and implementing a solution using finite state processes and concurrent programming in Java. A survey designed for the case study collects insights into students' experiences with ChatGPT at different stages of the project. Student feedback on using ChatGPT and their performance on the project are analyzed to understand the impact of conversational LLMs on learning outcomes and to address whether there is room for improvement in enhancing the use of conversational LLMs in software engineering education.},
  keywords={Surveys;Java;Software design;Large language models;Education;Programming;Chatbots;System analysis and design;Software engineering;Software development management;Conversational LLMs;ChatGPT;Software en-gineering education},
  doi={10.1109/FIE61694.2024.10893046},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10977933,
  author={Luo, Xiao and O'Connell, Sean and Mithun, Shamima},
  booktitle={2025 IEEE Symposium on Computational Intelligence in Natural Language Processing and Social Media (CI-NLPSoMe Companion)}, 
  title={Assessing Personalized AI Mentoring with Large Language Models in the Computing Field}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper provides an in-depth evaluation of three state-of-the-art Large Language Models (LLMs) for personalized career mentoring in the computing field, using three distinct student profiles that consider gender, race, and professional levels. We evaluated the performance of GPT-4, LLaMA 3, and Palm 2 using a zero-shot learning approach without human intervention. A quantitative evaluation was conducted through a custom natural language processing analytics pipeline to highlight the uniqueness of the responses and to identify words reflecting each student's profile, including race, gender, or professional level. The analysis of frequently used words in the responses indicates that GPT-4 offers more personalized mentoring compared to the other two LLMs. Additionally, a qualitative evaluation was performed to see if human experts reached similar conclusions. The analysis of survey responses shows that GPT-4 outperformed the other two LLMs in delivering more accurate and useful mentoring while addressing specific challenges with encouragement languages. Our work establishes a foundation for developing personalized mentoring tools based on LLMs, incorporating human mentors in the process to deliver a more impactful and tailored mentoring experience.},
  keywords={Surveys;Accuracy;Social networking (online);Engineering profession;Large language models;Zero shot learning;Pipelines;Natural language processing;Mentoring;Computational intelligence;AI mentoring;Natural Language Processing;Large Language Models;Computing Education},
  doi={10.1109/CI-NLPSoMeCompanion65206.2025.10977933},
  ISSN={},
  month={March},}@INPROCEEDINGS{10391549,
  author={Hajj, Jana Al and Sah, Melike},
  booktitle={2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS)}, 
  title={Assessing the Impact of ChatGPT in a PHP Programming Course}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={ChatGPT changed the way of learning for both instructors and students. Since its introduction, it has attracted a lot of attention from learners as well as instructors. In this paper, the impact of ChatGPT in a PHP programming course using user studies was investigated. User studies were conducted in two different universities in North Cyprus with a total of 50 students. Students were divided into two groups and asked to perform two quizzes; (a) manually alone and (b) with the assistance of ChatGPT. To remove the learning effect, quizzes were swapped; the first student performed the quiz manually first, then perform the second quiz with the help of ChatGPT with similar questions. Subsequently, the second student performed the quiz using ChatGPT first, then perform the second quiz manually next. Swapping continued for all students. Furthermore, to understand the impact of ChatGPT on different question types in a programming course, the quizzes were designed with different question categories: Classical, True/False, multiple choices, and coding. After completing each quiz (manual or assistance of ChatGPT), post-questionnaires were also given to assess the attitudes of learners to the exams. Results of the user study were analyzed in terms of scores (correct answers), post-questionnaires as user attitudes and statistical paired t-tests. Results indicated that ChatGPT had statistically significant positive effect on coding questions, as well as, statistically moderate positive effect on classical and True/False questions. However, for multiple choice questions, there is no significant difference between the results of manual exam and exam with the assistance of ChatGPT for the programming course. User ratings for post-questionnaires also confirm these results.},
  keywords={Manuals;Programming;Chatbots;Encoding;Artificial intelligence;AI chatbot;ChatGPT;technology for teaching;user study;questionnaire;artificial intelligence},
  doi={10.1109/ISAS60782.2023.10391549},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10911129,
  author={Gomes, Roseline Florence and Thomas, Lijo},
  booktitle={2024 IEEE 4th International Conference on ICT in Business Industry & Government (ICTBIG)}, 
  title={DIP AI-Driven Architecture for Enhanced Project Management Using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The integration of Large Language Models (LLMs), such as GPT-4, Claude, and Gemini AI, into project management systems has revolutionized how tasks are automated, tracked, and optimized. This paper presents a comparative analysis of LLMs in the context of project management, evaluating their performance in scheduling, resource allocation, and decision support. By leveraging both primary data from real-world simulations and secondary data from literature, the study highlights GPT-4’s superior accuracy, task completion speed, and scalability over other models. The findings suggest that AI-based systems can enhance efficiency and reduce human error in complex project management workflows.},
  keywords={Automation;Accuracy;Generative AI;Large language models;Scalability;Government;Project management;Data models;Resource management;Electronics packaging;Large Language Models;Project Management;GPT-4;Claude;Gemini AI;Automation;AI-based Scheduling;Resource Allocation;Generative AI},
  doi={10.1109/ICTBIG64922.2024.10911129},
  ISSN={},
  month={Dec},}@ARTICLE{10636140,
  author={Pirzado, Farman Ali and Ahmed, Awais and Mendoza-Urdiales, Román Alejandro and Terashima-Marin, Hugo},
  journal={IEEE Access}, 
  title={Navigating the Pitfalls: Analyzing the Behavior of LLMs as a Coding Assistant for Computer Science Students—A Systematic Review of the Literature}, 
  year={2024},
  volume={12},
  number={},
  pages={112605-112625},
  abstract={In recent years, large language models (LLMs) have been employed significantly in different domains of computing education. Nevertheless, these models have been focused on essential adherence to their integration as coding assistants in computing education. However, attention has been switched to thoroughly examining and analyzing LLM behavior, particularly in computing education for programming tasks such as code generation, code explanation, and programming error message explanation. Therefore, it becomes imperative to understand their behavior to examine potential pitfalls. This article addresses this gap systematically and details how different LLM-based coding chatbots, such as ChatGPT, Codex, Copilot, and others, react to various coding inputs within computing education. To achieve this objective, we collected and analyzed articles from 2021 to 2024, and 72 studies were thoroughly examined. These objectives include investigating the existing limitations and challenges associated with utilizing these systems for coding tasks, assessing their responses to prompts containing coding syntax, examining the impact of their output on student learning, and evaluating their performance as debugging tools. The findings of this review highlight that it is premature to incorporate these systems into computing education due to their limitations that may limit their effectiveness as comprehensive coding assistants for computer science students. These limitations include issues with handling prompts containing code snippets, potential negative impacts on student learning, limited debugging capabilities, and other ineffectiveness. The finding also reports multiple research directions that can be considered in future research related to LLMs in computing education.},
  keywords={Codes;Encoding;Chatbots;Programming profession;Task analysis;Surveys;Large language models;Computer science education;Error analysis;Large language models;computing education;code generation;code explanation;programming error messages explanation},
  doi={10.1109/ACCESS.2024.3443621},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10976127,
  author={Chen, Enfan},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Enhancing Teaching Quality Through LLM: An Experimental Study on Prompt Engineering}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the application of Large Language Models Artificial Intelligence (LLM AI) in the assessment of course teaching quality, aiming to overcome the limitations of traditional teaching evaluation. Taking the experimental courses in School G as an example, we propose CORE, a framework to support generating feedback from student assessment during the course. Through the Solomon four-group design experiment, it validates the significant effectiveness of the teaching quality evaluation feedback generated by LLM in enhancing teachers' teaching quality. This feedback can help teachers improve teaching strategies, boost teaching effects, effectively make up for the limitations of traditional teaching assessment methods, and offer a new perspective and tool for teaching quality evaluation.},
  keywords={Large language models;Education;Prompt engineering;Information technology;Prompt engineering;Large Language Models (LLM);Teaching evaluation;Prompt framework;Large Language Models},
  doi={10.1109/ICEIT64364.2025.10976127},
  ISSN={},
  month={March},}@INPROCEEDINGS{10892858,
  author={Couder, Juan Ortiz and Pate, William C. and Machado, Daniel A. and Ochoa, Omar},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Incorporating AI in the Teaching of Requirements Tracing Within Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={During the Software Development Lifecycle (SDLC), the first stage entails the Requirement Engineering phase. In this phase, engineers gather, analyze, and specify the requirements for a software system. Requirements playa crucial role in the SDLC as they establish the foundation for the entire system by defining the expected behaviors of the software system to be built. The resulting specifications are captured in a Software Requirement Specification (SRS) document. As part of the validation process, requirement specifications are traced. Requirement tracing involves linking the requirement to the artifacts where the customer requested the high-level requirement. Teaching proper requirements tracing can be challenging in a traditional classroom setting. It is essential to educate future software engineers on the proper process of developing an SRS document and of tracing requirements back to the originating artifact, which is also challenging due to the complexity and large scope of applying the complete requirements engineering process. Understanding how changes in customer needs can impact requirements is an imperative learning opportunity. In this work, we aim to incorporate the use of AI in the teaching of requirements tracing using Large Language Models. In this experiment, both GPT -3.5 and GPT -4 are provided the transcript of an interview between the customer and the engineering team, as well as the subsequent requirements elicited from that meeting and other customer provided artifacts. The GPTs are then instructed to determine which requirements can be traced back to the interview transcript. At the same time, the students (the requirements engineering team) conduct their own effort to trace requirements back to the original interview. The experiment was taken one step further to assess students' and the GPTs abilities to address requirements modifications. After another interview with the customer, where some needs were changed, some requirements were modified, and students, and GPTs were asked to trace the modified requirements to the new interview. The results proved that students are better than both GPT versions at tracing modified requirements, yet GPTs again identified requirements that students didn't trace back. The findings, illustrate that AI can help in the teaching of requirement tracing; these results suggest that while no AI model is currently capable of replacing real requirement engineers as they don't outperform students, it can be used as a tool to test the completeness of the requirement tracing process. We posit that GPT can be a tool for students to self-assess the degree to which their own requirements tracing is exhaustive.},
  keywords={Training;Visualization;Atmospheric modeling;Prototypes;Software systems;Requirements engineering;Interviews;Artificial intelligence;Software engineering;Software development management;AI;Requirement Tracing;Education;Software Requirement Specification;Large Language Models},
  doi={10.1109/FIE61694.2024.10892858},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10554703,
  author={Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Does ChatGPT Help With Introductory Programming? An Experiment of Students Using ChatGPT in CS1}, 
  year={2024},
  volume={},
  number={},
  pages={331-341},
  abstract={Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey. With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
  keywords={Training;Ethics;Generative AI;Unified modeling language;Chatbots;Recording;Computer science education;CS education;CS1;Generative AI;ChatGPT;OOP},
  doi={10.1145/3639474.3640076},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10710677,
  author={Örpek, Zeynep and Tural, Büşra and Destan, Zeynep},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={The Language Model Revolution: LLM and SLM Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={As technology develops day by day, significant developments have been made in the field of artificial intelligence (AI). In particular, machine learning (ML) and deep learning (DL), as the main technologies that form the basis of artificial intelligence, have offered revolutionary innovations and laid the foundation for future technologies. Traditional artificial intelligence models are based on algorithms that show high performance in certain tasks such as classification, scoring, prediction, and pattern recognition. These algorithms are developed to best perform a specific task, making it difficult for artificial intelligence to be sufficiently effective in areas that require flexibility. Generative artificial intelligence, which has become widespread in recent years, has the ability to produce certain types of content in addition to the competencies of traditional artificial intelligence models. This has revolutionized the field of productivity in artificial intelligence. Generative artificial intelligence language models have gone beyond the limitations and started a new era in artificial intelligence applications. Where traditional artificial intelligence models are limited, language models have come into play, especially with their natural language processing (NLP) capabilities. Rather than just analyzing data, language models can learn the rules of the language and provide human-like responses, produce text, and offer a wider range of applications. In this way, artificial intelligence systems have become more flexible, extensible, and dynamic. With the rise of language models in this field, concepts such as large language models (LLM) and small language models (SLM) have emerged. Large language models have come to the fore as systems that can provide deep knowledge and language production on a wide variety of topics by being trained on huge data sets. Large language models such as ChatGPT are one of the most common and impressive examples in this field. However, small language models, which are smaller and specialized language models, have begun to be used as an alternative to large language models in certain areas because they require less data and processing power. Small language models stand out with their lighter but targeted performance, offering effective solutions, especially in situations where there are resource limitations. At this point, using both large and small versions of language models in the right scenarios provides great advantages in terms of sustainability and efficiency. This study aims to reveal the transformative effect of technology on artificial intelligence and the critical role of language models in this process by evaluating language models and the issues to be considered in the selection of these models.},
  keywords={Productivity;Analytical models;Technological innovation;Generative AI;Large language models;Prediction algorithms;Data models;Classification algorithms;Artificial intelligence;Sustainable development;artificial intelligence;large language models;small language models},
  doi={10.1109/IDAP64064.2024.10710677},
  ISSN={},
  month={Sep.},}@ARTICLE{11008781,
  author={Ge, Chuyan and Wang, TianTian and Yang, XiaoTian and Treude, Christoph},
  journal={IEEE Transactions on Software Engineering}, 
  title={Cross-Level Requirements Tracing Based on Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-23},
  abstract={Cross-level requirements traceability, linking high-level requirements (HLRs) and low-level requirements (LLRs), is essential for maintaining relationships and consistency in software development. However, the manual creation of requirements links necessitates a profound understanding of the project and entails a complex and laborious process. Existing machine learning and deep learning methods often fail to fully understand semantic information, leading to low accuracy and unstable performance. This paper presents the first approach for cross-level requirements tracing based on large language models (LLMs) and introduces a data augmentation strategy (such as synonym replacement, machine translation, and noise introduction) to enhance model robustness. We compare three fine-tuning strategies—LoRA, P-Tuning, and Prompt-Tuning—on different scales of LLaMA models (1.1B, 7B, and 13B). The fine-tuned LLMs exhibit superior performance across various datasets, including six single-project datasets, three cross-project datasets within the same domain, and one cross-domain dataset. Experimental results show that fine-tuned LLMs outperform traditional information retrieval, machine learning, and deep learning methods on various datasets. Furthermore, we compare the performance of GPT and DeepSeek LLMs under different prompt templates, revealing their high sensitivity to prompt design and relatively poor result stability. Our approach achieves superior performance, outperforming GPT-4o and DeepSeek-r1 by 16.27% and 16.8% in F1 score on cross-domain datasets. Compared to the baseline method that relies on prompt engineering, it achieves a maximum improvement of 13.8%.},
  keywords={Feature extraction;Semantics;Deep learning;Information retrieval;Data augmentation;Software;Vectors;Training;Large language models;Accuracy;Requirements Tracing;Large Language Models;Fine-tuning;Data Augmentation;Software Requirements},
  doi={10.1109/TSE.2025.3572094},
  ISSN={1939-3520},
  month={},}@INPROCEEDINGS{10229416,
  author={Speth, Sandro and Meißner, Niklas and Becker, Steffen},
  booktitle={2023 IEEE 35th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Investigating the Use of AI-Generated Exercises for Beginner and Intermediate Programming Courses: A ChatGPT Case Study}, 
  year={2023},
  volume={},
  number={},
  pages={142-146},
  abstract={In recent years, artificial intelligence (AI) has been increasingly used in education and supports teachers in creating educational material and students in their learning progress. AI-driven learning support has recently been further strengthened by the release of ChatGPT, in which users can retrieve explanations for various concepts in a few minutes through chat. However, to what extent the use of AI models, such as ChatGPT, is suitable for the creation of didactically and content-wise good exercises for programming courses is not yet known. Therefore, in this paper, we investigate the use of AI-generated exercises for beginner and intermediate programming courses in higher education using ChatGPT. We created 12 exercise sheets with ChatGPT for a beginner to intermediate programming course focusing on the objects-first approach. We report our process, prompts, and experience using ChatGPT for this task and outline good practices we identified. The generated exercises are assessed and revised, primarily using ChatGPT, until they met the requirements of the programming course. We assessed the quality of these exercises by using them in our external teaching assignment course at the University of Education Ludwigsburg and let the students evaluate them. Results indicate the quality of the generated exercises and the time-saving for creating them using ChatGPT. However, our experience showed that while it is fast to generate a good version of an exercise, almost every exercise requires minor manual changes to improve its quality.},
  keywords={Java;Software architecture;Education;Focusing;Manuals;Learning (artificial intelligence);Chatbots;AI-Generated Exercises;SE Education;Automatic Question Generation;Programming Course;ChatGPT},
  doi={10.1109/CSEET58097.2023.00030},
  ISSN={2377-570X},
  month={Aug},}@INPROCEEDINGS{10893585,
  author={Jemetz, Michael and Motschnig, Renate},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Teachers' Development of Competence in Managing Generative AI Technology: Findings from a Qualitative Interview Series}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research full paper strives to shed light on educators' ways of dealing with the rapid advances in generative AI tools, which have opened up new challenges and opportunities for learners and educators alike. Both are confronted with the opportunity of supporting themselves in the completion of a wide range of tasks in this new reality. The study presented here aims to identify different strategies teachers use to develop their competences in responding to students' AI usage and in utilizing this new technology for their own professional tasks. Strategies are identified through a series of semi-structured qualitative interviews with a diverse group of nineteen teachers from two vocational and three general education secondary schools in urban and rural areas of Austria. The participants are mainly teaching technical and language subjects and range from technical experts teaching IT to general education teachers who are faced with the need to quickly adapt to learners with different levels of digital and AI competences. The findings of a qualitative content analysis of the gathered data are contextualized with previous work on educators' digital competence development and comparisons are drawn. It was found that a major contribution to the educators' skills in handling generative AI technology was made through self-regulated learning facilitated by various resources ranging from academic literature to social media and experimentation, as was the case with general digital skills. Nevertheless, the desire to be formally supported in further developing AI competence through training was voiced with requirements for this training being that the content is up-to-date, contains practical examples, and is delivered by experts. In addition, open, inclusive forms of seminars were suggested. These findings aim to inform curriculum designers, teacher educators, professional development trainers and administrators. Furthermore, struggling educators will find a starting point for self-organized work on their AI competences and pointers to potentially useful resources both for their teaching and their own learning in the field.},
  keywords={Training;Seminars;Content management;Generative AI;Social networking (online);Distance measurement;Interviews;AI competence;GenAI;teacher's competence;competence development;self-regulated learning;LLMs},
  doi={10.1109/FIE61694.2024.10893585},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10487568,
  author={Kupershtein, Ethan and Kumar, Yulia and Manikandan, Anjana and Morreale, Patricia and Li, J. Jenny},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={ChatGPT as a Game-Changer for Embedding Emojis in Faculty Feedback}, 
  year={2023},
  volume={},
  number={},
  pages={1039-1046},
  abstract={This study explores the potential of integrating emojis, and digital pictographs, into faculty feedback to augment student learning outcomes. This additional layer of expressiveness, encouragement, and involvement adds a personal touch to the often distant and virtual student-educator communications, fostering motivation. The study focuses on the impact of emojis on the learning process within the scrutinized Computer Science (CS) Department. Capitalizing on the capabilities of OpenAI's Large Language Model (LLM) ChatGPT-4, its Application Programming Interface (API), and associated tools and third-party plugins, a system that translates text into corresponding emojis and vice versa has been developed. The proposed application offers direct benefits to educators by simplifying the provision of detailed and extensive feedback to students. The primary research question is: Can the appropriate use of emojis, matched with the sentiment of the feedback text, contribute to enhanced student learning outcomes, higher retention rates, and boost the reputation of the educators providing it? Two surveys on the impact of emojis across selected course sections were conducted to answer the question: a pre-survey and a post-survey involving 175 active participants. The results were analyzed, and it was concluded that integrating emojis in faculty feedback, particularly when grading student work, could potentially enhance student learning outcomes and their overall course experience.},
  keywords={Surveys;Computer science;Chatbots;Emojis;Application programming interfaces;emojis;Feedback Emojifier;ChatGPT;computer science education;text-to-emoji translation},
  doi={10.1109/CSCE60160.2023.00173},
  ISSN={},
  month={July},}@INPROCEEDINGS{10665141,
  author={Kumar, Yulia and Manikandan, Anjana and Li, J. Jenny and Morreale, Patricia},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Optimizing Large Language Models for Auto-Generation of Programming Quizzes}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study analyzes the use of Large Language Models (LLMs) like ChatGPT in creating quizzes for Java programming courses, specifically Object-Oriented Programming (CS1) and Data Structures (CS2). It aims to evaluate the accuracy of LLM-generated assessments, understand the benefits and drawbacks of using LLMs in CS education from educators' viewpoints, and identify effective prompt engineering strategies to enhance the quality of educational materials. The research compares quizzes made by LLMs against human-created content to assess their consistency with Java programming principles, alignment with CS1 and CS2 learning goals, and their impact on student engagement and comprehension, providing insights into LLMs' effectiveness in academic assessment creation for computer science education.},
  keywords={Java;Accuracy;Large language models;Education;Data structures;Chatbots;Computer science education;Java programming instruction;AI-Supplemental Instructor (AI-SI);use of LLMs in CS education},
  doi={10.1109/ISEC61299.2024.10665141},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10398297,
  author={Hu, Minjie and Assadi, Tony and Mahroeian, Hamid},
  booktitle={2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Explicitly Introducing ChatGPT into First-year Programming Practice: Challenges and Impact}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT has recently emerged to aid in computer programming education due to its cutting-edge functionality of generating program code, debugging, etc. This research firstly focused on what the ethical considerations and solutions are for the first-year IT students who use ChatGPT to write computer programs in an integrated assignment. And then it turned to investigate what impact ChatGPT has on the programming competencies and learning outcomes of students compared to those who do not use ChatGPT. To ensure students use ChatGPT ethically, guidance was provided together with a declaration form of ethically using ChatGPT in each phase of the assignment. Next, we collected and analyzed a survey and their declaration from students and compared student effort, time spent, and performance outcomes from those who were using and without using ChatGPT. Based on the findings, we concluded that although ChatGPT provides an opportunity to the first-year students to learn programming in the way of analysis, synthesis, and evaluation, many students still prefer the conventional way of learning programming in terms of comprehension and application. We argued that since our students in the programming course are always from different academic background levels, we would continue to use both ChatGPT and conventional eLearning resources to meet different learning requirements.},
  keywords={Surveys;Ethics;Electronic learning;Education;Taxonomy;Chatbots;Programming profession;ChatGPT;divide-and-conquer;Bloom’s taxonomy},
  doi={10.1109/TALE56641.2023.10398297},
  ISSN={},
  month={Nov},}@ARTICLE{11024014,
  author={Dahal, Rajashree and Murray, Greg and Chataut, Robin and Hefeida, Mohamed and Srivastava, Anurag and Gyawali, Prashnna},
  journal={IEEE Access}, 
  title={AutoTA: A Dynamic Intent-Based Virtual Teaching Assistant for Students Using Open Source LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Large Language Models (LLMs) are explored for their potential to transform education by serving as virtual teaching assistants, offering personalized support through human-like responses to tasks such as content-related questions and coursework guidance. In this study, we present a novel framework that leverages intent classification to enhance the effectiveness of LLMs in this role. Our framework, AutoTA, categorizes student queries into distinct topics— lecture discussions, homework assistance, and syllabus questions—triggering specific conversation chains tailored to each intent. Additionally, we incorporate a custom vector-space filter that refines responses based on filename tracking after intent identification. To evaluate the framework, we used course materials from the undergraduate-level CS course, Computer Incident Response, and compared the performance of several open-source LLMs, including Llama 3.1. Our results show that the framework accurately classifies intent and provides appropriate guidance, measured through quantitative and qualitative metrics. These findings highlight the potential of the proposed framework to enhance personalized learning and improve student engagement. While tested in a computer science course, the framework incorporates diverse assessment types that suggest potential for broader application.},
  keywords={Education;Intent recognition;Oral communication;Large language models;Programming profession;Measurement;Information retrieval;Virtual assistants;Real-time systems;History;Education;Large language models (LLMs);prompting;teaching assistant},
  doi={10.1109/ACCESS.2025.3576329},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10837667,
  author={Speiser, Sebastian and Weng, Annegret},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Enhancing Short Answer Grading with OpenAI APIs}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Automated short-answer grading can accelerate and standardize the assessment of tests in higher education. The topic has received a significant boost due to the rapid development of powerful LLM models in recent years. We examine the performance of the OpenAI models GPT-3.5 and GPT-4o on the CSSAG dataset and demonstrate that GPT-4o, in particular, achieves an accuracy that falls within the range observed in assessments by different human evaluators. We pay special attention to cases where there are significant deviations from the reference assessment. Additionally, we discuss the practical implications.},
  keywords={Training;Accuracy;Life estimation;Information technology;Few shot learning;Overfitting;LLMs;Automated Grading;Short Answer Grading},
  doi={10.1109/ITHET61869.2024.10837667},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{11012850,
  author={Lin, Yadanar and Ferdous Khan, M. Fahim and Sakamura, Ken},
  booktitle={2025 1st International Conference on Consumer Technology (ICCT-Pacific)}, 
  title={Athena: A GenAI-Powered Programming Tutor Based on Open-Source LLM}, 
  year={2025},
  volume={},
  number={},
  pages={1-4},
  abstract={With the rapid growth of generative artificial intelligence (GenAI), it is important to find ways to utilize them for academic advantage. GenAI tools embody immense potential in providing personalized feedback to students any time anywhere, and hence can provide a reliable helping hand to teachers who often experience burnout in large classes and are burdened with administrative tasks. While current GenAI tools like ChatGPT are helpful, they occasionally offer misinformation - a phenomenon known as hallucination, undermine critical thinking by providing direct answers to questions, and, as paid services, can further widen the digital divide. Against the backdrop of these problems, this research introduces Athena, a GenAI programming mentor based on an open-source large language model (LLM), constructed to guide programming learners to think critically and provide reliable information leveraging retrieval augmented generation. Its impact on learning outcomes was measured by feedback from programming students. Most students have given a positive response, saying that their motivation to keep learning and their confidence in their abilities have increased. These results imply that having a reliable AI mentor that can guide students at all times can have a positive impact in self-directed learning process.},
  keywords={Hands;Generative AI;Large language models;Retrieval augmented generation;Education;Chatbots;Reliability;Digital divide;Fake news;Programming profession;Generative artificial intelligence (GenAI);programming education;large language model (LLM);retrieval augmented generation (RAG);educational chatbot},
  doi={10.1109/ICCT-Pacific63901.2025.11012850},
  ISSN={},
  month={March},}@INPROCEEDINGS{10837650,
  author={Dobre, Stefania-Carmen and Popescu, Elvira},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Exploring Students' Perception and Experience with ChatGPT and Critical Thinking in a Higher Education Context}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT (Chat Generative Pre-trained Transformer) is a chatbot based on a large language model that enables users to engage in conversations with it in a human-like way. The adoption of ChatGPT in education has generated significant interest because of its potential to enhance students' learning experience. By delivering personalised and prompt responses, ChatGPT can meet individual student needs, provide immediate feedback, and aid comprehension of difficult concepts. In this paper, we investigate students' experience with ChatGPT, focusing on the topic of critical thinking skills in a higher education context. Data was collected by means of an opinion survey applied to 122 students from the University of Craiova, Romania. The paper reports and discusses the survey findings, with respect to the following issues: students' perceptions of ChatGPT's role in the learning process; the potential benefits and challenges that learners may encounter when using ChatGPT for educational purposes; students' trust in ChatGPT's responses; and students' critical evaluation of the content generated by ChatGPT.},
  keywords={Surveys;Training;Navigation;Large language models;Focusing;Oral communication;Chatbots;Transformers;Information technology;Interviews;ChatGPT;large language model;AI in education;student survey;learning experience;critical thinking},
  doi={10.1109/ITHET61869.2024.10837650},
  ISSN={2473-2060},
  month={Nov},}@ARTICLE{10753620,
  author={Song, Tian and Zhang, Hang and Xiao, Yijia},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A High-Quality Generation Approach for Educational Programming Projects Using LLM}, 
  year={2024},
  volume={17},
  number={},
  pages={2242-2255},
  abstract={High-quality programming projects for education are critically required in teaching. However, it is hard to develop those projects efficiently and artificially constrained by the lecturers' experience and background. The recent popularity of large language models (LLMs) has led to a great number of applications in the field of education, but concerns persist that the output might be unreliable when dealing with intricate requirements. In this study, we design a customized role-based agent (CRBA), which can be configured for different roles specializing in specific areas of expertise, making the LLM yield content of higher specialization. An iterative architecture of multi-CRBAs is proposed to generate multistep projects, where CRBAs automatically criticize and optimize the LLM's intermediate outputs to enhance quality. We propose ten evaluation metrics across three aspects to assess project quality through expert grading. Further, we conduct an A/B test among 60 undergraduate students in a programming course and collect their feedback through a questionnaire. According to the students' rating results, the LLM-generated projects have comparable performance to man-made ones in terms of project description, learning step setting, assistance to students, and overall project quality. This study effectively integrates LLM into educational scenarios and enhances the efficiency of creating high-quality and practical programming exercises for lecturers.},
  keywords={Programming profession;Codes;Education;Iterative methods;Computer architecture;Prompt engineering;Measurement;Chatbots;Python;Logic;Automatic generation;generative pretrained transformer (GPT);large language models (LLMs);programming education;programming projects},
  doi={10.1109/TLT.2024.3499751},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10893211,
  author={Rachha, Ashwin and Seyam, Mohammed},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={LLM-Enhanced Learning Environments for CS: Exploring Data Structures and Algorithms with Gurukul}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In this Innovative Practice full paper, we introduce Gurukul, an innovative coding platform designed to support teaching Data Structures and Algorithm (DSA) course by integrating advanced Large Language Models (LLMs). LLMs have emerged as powerful tools in Computer Science Education (CSEd), offering unparalleled opportunities for enhancing student comprehension and engagement. However, their use in educational settings presents challenges, including tendencies toward hallucination, contextual inaccuracies, and the risk of undermining critical thinking by providing explicit solutions. To address these challenges, and to explore how specialized LLMs can bolster learner engagement, we present Gurukul, a platform featuring dual innovations: Retrieval-Augmented Generation (RAG) and Guardrails. Gurukul offers a hands-on practice feature where students can solve DSA problems within a code editor, supported by a dynamically Guardrailed LLM that prevents the delivery of explicit solutions. Additionally, the platform's study feature utilizes RAG, drawing from OpenDSA as a trusted source, to ensure accurate and contextually relevant information is provided. To assess the platform's effectiveness, we conducted a User Study with students, and a User Expert Review with faculty from a U.S. public state university specializing in DSA courses. Our analysis of student usage patterns and perceptions, along with insights from instructors, reveal that Gurukul positively impacted student engagement and learning in DSA, demonstrating the potential of specialized LLMs to enhance educational outcomes in this field.},
  keywords={Technological innovation;Codes;Reviews;Large language models;Retrieval augmented generation;Education;Data structures;Encoding;Data models;Computer science education;Large Language Models;Retrieval Augmented Generation;Guardrails;Computer Science Education;ChatGPT;AI in Education},
  doi={10.1109/FIE61694.2024.10893211},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10837649,
  author={Ilić, Jelena and Ivanović, Mirjana and Klašnja-Milićević, Aleksanda},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The Impact of ChatGPT on Student Learning Experience in Higher STEM Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper aims to analyse the significance and utilisation of artificial intelligence, with a particular focus on ChatGPT, in learning systems. Integrating AI tools like ChatGPT has become a prominent trend in education. This study examines the impact of ChatGPT in higher STEM education, drawing on scientific articles published between 2020 and 2024. It explores whether ChatGPT produces positive learning outcomes, the potential approaches for its application now and in the future, and its effectiveness as a teaching tool. Findings from this literature review highlight the numerous benefits of using ChatGPT in higher STEM education. These benefits include improved opportunities for students to engage with AI technology, the provision of personalised support that meets individual learning needs, and an overall increase in the quality of the learning experience. Furthermore, ChatGPT enables greater accessibility of information, which encourages deeper learning and better knowledge retention. Despite these advantages, it is crucial to acknowledge the ethical considerations and biases inherent in AI models that must be addressed. Empirical evidence suggests that ChatGPT significantly improves student engagement by delivering personalised responses tailored to individual learning needs, offering timely and constructive feedback and making information more easily accessible. Together, these factors contribute to improved educational outcomes and encourage the development of students' critical thinking skills. The inclusion of ChatGPT in educational contexts marks a transformative shift in teacher roles, moving away from traditional content delivery methods. This evolution fosters a personalised and differentiated learning environment, allowing teachers to respond more effectively to the diverse needs of their students. There are obvious limitations that require further study. The reason for the insufficient number of empirical research is that ChatGPT in education is a relatively new AI tool.},
  keywords={Training;Accuracy;Navigation;Education;Transforms;Chatbots;Market research;Artificial intelligence;Systematic literature review;STEM;ChatGPT;artificial intelligence;higher education;STEM education;systematic literature review},
  doi={10.1109/ITHET61869.2024.10837649},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10734434,
  author={Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project}, 
  year={2024},
  volume={},
  number={},
  pages={111-118},
  abstract={Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student’s perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.CCS CONCEPTS• Software and its engineering → Software development techniques; • Applied computing → Education.},
  keywords={Productivity;Codes;Large language models;Conferences;Education;Debugging;Syntactics;Software;Software engineering;Software development management;LLM for Code Generation;Software Engineering},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10893442,
  author={Scholl, Andreas and Kiesler, Natalie},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={How Novice Programmers Use and Experience ChatGPT when Solving Programming Exercises in an Introductory Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper contributes to the computing education research community's understanding of Generative AI (GenAI) in the context of introductory programming, and specifically, how students utilize related tools, such as ChatGPT. An increased understanding of students' use is mandatory for educators and higher education institutions, as GenAI is here to stay, and its performance is likely to improve rapidly in the near future. Learning about students' use patterns is not only crucial to support their learning, but to develop adequate forms of instruction and assessment. With the rapid advancement of AI, its broad availability, and ubiquitous presence in educational environments, elaborating how AI can enhance learning experiences, especially in courses such as introductory programming is important. To date, most studies have focused on the educator's perspective on GenAI, its performance, characteristics, and limitations. However, the student perspective, and how they actually use GenAI tools in course contexts, has not been subject to a great number of studies. Therefore, this study is guided by the following research questions: (1) What do students report on their use pattern of ChatGPT in the context of introductory programming exercises? and (2) How do students perceive ChatGPT in the context of introductory programming exercises? To address these questions, computing students at a large German university were asked to solve programming tasks with the assistance of ChatGPT as part of their introductory programming course. Students (n=298) provided information regarding the use of ChatGPT, and their evaluation of the tool via an online survey. This research provides a comprehensive evaluation of ChatGPT-3.5's application by novice programmers in a higher education context. The findings reveal that while students widely adopt GenAI, their use varies significantly, ranging from acceptance of generated solutions to dynamic, and critical engagement. Therefore, this work has implications for educators designing guardrails or forms of instructions on the use of GenAI tools in the classroom.},
  keywords={Surveys;Generative AI;Education;Chatbots;Distance measurement;Programming profession;ChatGPT;generative AI;large language models;students;application;introductory programming},
  doi={10.1109/FIE61694.2024.10893442},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016577,
  author={Liu, ShuChang and Pan, MingHui and Yang, YeHan},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={I-LEAD: A Digital-Intelligence-Powered Ecosystem for Innovation and Entrepreneurship Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative artificial intelligence and large model agents are revolutionizing the higher education, influencing everything from talent development frameworks and teaching methodologies to knowledge acquisition processes and research paradigms. Meanwhile, in the context of digital transformation and technological innovation, data as a production factor and emerging productive forces are reshaping the requirements and demands for cultivating high-level interdisciplinary engineering talents. This paper draws on the joint educational achievements between Beijing University of Posts and Telecommunications and Queen Mary University of London, focusing on the coconstruction and sharing of experimental resources, as well as innovation-driven entrepreneurship education. It introduces a digital-intelligence-powered educational platform aimed at fostering internationally-minded, innovative, and outstanding talents. The platform's core philosophy, development strategy, functional modules, and technical framework are detailed. The wide recognition and interest among stakeholders further validate its potential to support the development of a cross-disciplinary, cross-professional, and cross-national ecosystem for innovation and entrepreneurship education. As a key outcome of the 20th Anniversary Development Conference of Joint Education of our two universities, I-LEAD is a platform designed to cultivate students' comprehensive innovative capabilities. Leveraging large language models (LLMs) and multi-agent technology, we have developed BUPT iMentor, an intelligent agent for innovation and entrepreneurship guidance; and BUPT EnPower, a cultivation assistant for personalized longlife learning. By LLMs with a robust knowledge based augmented generation and fine tuning, this tool effectively addresses common student challenges during innovation & entrepreneurship projects, such as idea generation and validation, access to relevant learning resources. I-LEAD provides comprehensive support, including customized course creation, problem-solving guidance, real-time interactive Q&A, and learning progress monitoring. This empowers students to independently plan their learning journeys and holistically enhance their academic and innovative skills. The effectiveness and practicality of the platform have been validated through a questionnaire survey. Therefore, we are extensively gathering feedback and continuously optimizing the platform's services. The teacher-student collaborative learning represents the future of higher education. This student-centered education system provides a platform for that.},
  keywords={Technological innovation;Large language models;Knowledge acquisition;Education;Ecosystems;Entrepreneurship;Production;Real-time systems;Telecommunications;Monitoring;innovation and entrepreneurship education;large language model agents;interdisciplinary talent cultivation;digital and intelligent empowerment},
  doi={10.1109/EDUCON62633.2025.11016577},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10663055,
  author={Pereira, Juanan and López, Juan-Miguel and Garmendia, Xabier and Azanza, Maider},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Leveraging Open Source LLMs for Software Engineering Education and Training}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative AI, particularly Large Language Models (LLMs), presents innovative opportunities to enhance software engineering education. Open source LLMs such as LLaMA and Mistral leverage the potential of generative AI offering distinct advantages over proprietary options including transparency, customizability, collaboration, and cost savings. This paper de-velops a catalog of LLM prompt examples tailored for software engineering training, mapped to knowledge areas from the Soft-ware Engineering Body of Knowledge (SWEBoK) framework. Example prompts demonstrate LLMs' capabilities in eliciting requirements, diagram generation, API simulation, effort esti-mation through role-playing, and other areas. The methodology involves evaluating prompt responses from ChatGPT, Mistral, and LLaMA on representative tasks. Quantitative and qualitative analysis assesses quality, usefulness, and correctness. Findings show ChatGPT and Mistral outperforming LLaMA overall, but no model perfectly executes complex interactions. We examine implications and challenges of integrating open source LLMs into classrooms, emphasizing the need for oversight, verification, and prompt design aligned with pedagogical objectives.},
  keywords={Training;Knowledge engineering;Costs;Generative AI;Large language models;Collaboration;Chatbots;Software Engineering Education;Open Source AI Models;Large Language Models;Prompt Engineering},
  doi={10.1109/CSEET62301.2024.10663055},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10893118,
  author={Kusam, Venkata Alekhya and Shrestha, Summit and Kattan, Khalid and Maxim, Bruce and Song, Zheng},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A PBL-Based Mini Course Module for Teaching Computer Science Students to Utilize Generative AI for Enhanced Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice paper introduces a mini-course module designed to teach computer science students how to interact more efficiently with Generative AI(GAI). The rapid rise of GAI is transforming education by providing students with easy access to knowledge and answers to their questions, acting as a personal tutor. Particularly in the field of computer science, where GAI can easily generate code based on specific requirements, many instructors struggle to prevent students from using tools like ChatGPT for completing assigned programming assignments and homeworks. However, we argue that 1) the use of GAI is inevitable, necessitating a redesign of courses so that students cannot merely rely on GAI without actual learning; and 2) students' learning can be enhanced if they learn to use GAI more effectively. In this paper, we demonstrate how we integrate Project-Based Learning to design the course module in a concise yet effective manner, which not only facilitates students' learning of GAI but also enriches their learning in relation to the host course where this mini-course module is embedded. In particular, the goal of this module is to teach CS students: 1) the basic principles and workflow of GAI; 2) Prompt Engineering: how to craft questions to interact more effectively with GAI; and 3) Extending GAI: how to create interactive tools by training customized GAI models. Designed to be completed within two weeks, the mini-course module can easily be incorporated into host courses. This mini-course module was integrated into a graduate-level Artificial Intelligence course with 42 students in Winter 2024. To assess the module's impact on student learning and engagement, we conducted pre- and post-course surveys as well as student interviews. The results from the surveys and interviews highlighted key areas for improving the design of educational modules to better teach essential GAI skills. These insights focused on enhancing student engagement and learning efficiency within a concise time frame.},
  keywords={Surveys;Training;Codes;Navigation;Chatbots;Prompt engineering;Interviews;Programming profession;Generative AI;Course Module Design;Project Based Learning(PBL)},
  doi={10.1109/FIE61694.2024.10893118},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10936806,
  author={Mi, Chunqiao and Xiao, Hongbo and Deng, Qingyou and Zhao, Changhua and Tang, Bo},
  booktitle={2024 International Conference on Information Technology, Comunication Ecosystem and Management (ITCEM)}, 
  title={Research on the Effectiveness of Human-Machine Collaborative Teaching Based on Data Analysis in the Era of Digital Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={233-237},
  abstract={In the era of digital intelligence, the integration of artificial intelligence (AI) into educational practices has the potential to transform traditional teaching methods. Human-machine collaborative teaching (HMCT) is a new paradigm that leverages the strengths of both human educators and AI tools to enhance learning outcomes. This study investigates the effectiveness of three human-machine collaborative teaching strategies—directive, guided, and collaborative-implemented in a university—level software engineering course. The experiment involved 99 third-year students and aimed to evaluate the impact of these teaching strategies on creativity and academic performance. The results show that the collaborative teaching method, enhanced by generative AI tools, led to the highest performance in final exams and overall academic achievement, as well as increased participation in extracurricular innovation activities in homework. While directive teaching produced consistent results, it did not foster the same level of engagement or creativity. Guided teaching demonstrated moderate success, but the greatest benefits were observed in the collaborative approach, where students took an active role in their learning. This study suggests that integrating AI into collaborative learning environments can enhance both academic outcomes and student creativity, and recommends expanding the use of AI-supported strategies in higher education. Future research should explore the scalability of these findings across disciplines and investigate long-term impacts on student development and career readiness.},
  keywords={Technological innovation;Data analysis;Generative AI;Federated learning;Education;Collaboration;Transforms;Digital intelligence;Creativity;Software engineering;human-machine collaborative teaching;collaborative learning;generative AI;data analysis;effectiveness evaluation},
  doi={10.1109/ITCEM65710.2024.00050},
  ISSN={},
  month={Dec},}@ARTICLE{10004013,
  author={Wu, Zhengyang and Deng, Ke and Qiu, Judy and Tang, Yong},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={ExamGAN and Twin-ExamGAN for Exam Script Generation}, 
  year={2023},
  volume={35},
  number={11},
  pages={11354-11367},
  abstract={Nowadays, the learning management system (LMS) has been widely used in different educational stages from primary to tertiary education for student administration, documentation, tracking, reporting, and delivery of educational courses, training programs, or learning and development programs. Towards effective learning outcome assessment, the exam script generation problem has attracted many attentions recently. But the research in this field is still in its early stage. Two essential issues have been ignored largely by existing solutions. First, given a course, it is unknown yet how to generate an quality exam script which concurrently has (i) the proper difficulty level, (ii) the coverage of essential knowledge points, (iii) the capability to distinguish academic performances between students, and (iv) the student scores in normal distribution. Second, while frequently encountered in practice, it is unknown so far how to generate a pair of high quality exam scripts which are equivalent in assessment (i.e., the student scores are comparable by taking either of them) but have significantly different sets of questions. To fill the gap, this paper proposes ExamGAN (Exam Script Generative Adversarial Network) to generate high quality exam scripts, and then extends ExamGAN to T-ExamGAN (Twin-ExamGAN) to generate a pair of high quality exam scripts. Based on extensive experiments on three benchmark datasets, it has verified the superiority of proposed solutions in various aspects against the state-of-the-art. Moreover, we have conducted a case study which demonstrated the effectiveness of proposed solution in the real teaching scenarios.},
  keywords={Hidden Markov models;Generative adversarial networks;Knowledge engineering;Training;Gaussian distribution;Task analysis;Databases;Deep knowledge tracing;educational data mining;exam script generation;generative adversarial network},
  doi={10.1109/TKDE.2022.3233046},
  ISSN={1558-2191},
  month={Nov},}@INPROCEEDINGS{10962520,
  author={Chandrasekaran, Jaganmohan and Patel, Ankita Ramjibhai and Lanus, Erin and Freeman, Laura J.},
  booktitle={2025 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={Evaluating Large Language Model Robustness using Combinatorial Testing}, 
  year={2025},
  volume={},
  number={},
  pages={300-309},
  abstract={Recent advancements in large language models (LLMs) have demonstrated remarkable proficiency in understanding and generating human-like text, leading to widespread adoption across domains. Given LLM’s versatile capabilities, current evaluation practices assess LLMs across a wide variety of tasks, including answer generation, sentiment analysis, text completion, and question and answers, to name a few. Multiple choice questions (MCQ) have emerged as a widely used evaluation task to assess LLM’s understanding and reasoning across various subject areas. However, studies from the literature have revealed that LLMs exhibit sensitivity to the ordering of options in MCQ tasks, with performance variations based on option sequence, thus underscoring the robustness concerns in LLM performance.This work presents a combinatorial testing-based framework for systematic and comprehensive robustness assessment of pre-trained LLMs. By leveraging the sequence covering array, the framework constructs test sets by systematically swapping the order of options, which are then used in ascertaining the robustness of LLMs. We performed an experimental evaluation using the Measuring Massive Multitask Language Understanding (MMLU) dataset, a widely used MCQ dataset and evaluated the robustness of GPT 3.5 Turbo, a pre-trained LLM. Results suggest the framework can effectively identify numerous robustness issues with a relatively minimal number of tests.},
  keywords={Sentiment analysis;Systematics;Sensitivity;Large language models;Combinatorial testing;Conferences;Robustness;Cognition;Testing AI;Combinatorial Testing;Testing LLM;LLM Robustness;LLM Evaluation;Option Order Swapping},
  doi={10.1109/ICSTW64639.2025.10962520},
  ISSN={2159-4848},
  month={March},}@ARTICLE{10689494,
  author={Chen, Zixin and Wang, Jiachen and Xia, Meng and Shigyo, Kento and Liu, Dingdong and Zhang, Rong and Qu, Huamin},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={StuGPTViz: A Visual Analytics Approach to Understand Student-ChatGPT Interactions}, 
  year={2025},
  volume={31},
  number={1},
  pages={908-918},
  abstract={The integration of Large Language Models (LLMs), especially ChatGPT, into education is poised to revolutionize students' learning experiences by introducing innovative conversational learning methodologies. To empower students to fully leverage the capabilities of ChatGPT in educational scenarios, understanding students' interaction patterns with ChatGPT is crucial for instructors. However, this endeavor is challenging due to the absence of datasets focused on student-ChatGPT conversations and the complexities in identifying and analyzing the evolutional interaction patterns within conversations. To address these challenges, we collected conversational data from 48 students interacting with ChatGPT in a master's level data visualization course over one semester. We then developed a coding scheme, grounded in the literature on cognitive levels and thematic analysis, to categorize students' interaction patterns with ChatGPT. Furthermore, we present a visual analytics system, StuGPTViz, that tracks and compares temporal patterns in student prompts and the quality of ChatGPT's responses at multiple scales, revealing significant pedagogical insights for instructors. We validated the system's effectiveness through expert interviews with six data visualization instructors and three case studies. The results confirmed StuGPTViz's capacity to enhance educators' insights into the pedagogical value of ChatGPT. We also discussed the potential research opportunities of applying visual analytics in education and developing AI-driven personalized learning solutions.},
  keywords={Data visualization;Chatbots;Oral communication;Education;Visual analytics;Artificial intelligence;Data collection;Visual analytics for education;ChatGPT for education;student-ChatGPT interaction},
  doi={10.1109/TVCG.2024.3456363},
  ISSN={1941-0506},
  month={Jan},}@ARTICLE{10938596,
  author={Pwanedo Amos, Joanah and Ahmed Amodu, Oluwatosin and Azlina Raja Mahmood, Raja and Bolakale Abdulqudus, Akanbi and Zakaria, Anies Faziehan and Rhoda Iyanda, Abimbola and Ali Bukar, Umar and Mohd Hanapi, Zurina},
  journal={IEEE Access}, 
  title={A Bibliometric Exposition and Review on Leveraging LLMs for Programming Education}, 
  year={2025},
  volume={13},
  number={},
  pages={58364-58393},
  abstract={The world is experiencing an AI revolution, with large language models (LLMs) transforming various industries, including education. Academics are striving to harness the potential of LLMs while also contending with their risks. This paper presents the first bibliometric analysis focused on LLM research in programming education, identifying leading countries, authors, and institutions while analyzing key terms and popular keywords in this field. Additionally, it highlights influential studies on topics such as introductory programming, computer science, computing, programming education, and prompt engineering, discussing key insights from these works. Findings indicate that LLMs could play a significant role in programming education and may be integrated into computer science curricula. However, careful consideration is needed to ensure their benefits outweigh their risks across various use cases. This study specifically examines ChatGPT as a representative LLM, exploring its benefits and limitations as both a learning aid for students and a support tool for professionals. It also evaluates the quality of ChatGPT-generated code and its effectiveness in simplifying programming concepts for beginners. Furthermore, the ethical implications of increasing reliance on LLMs for programming tasks, including concerns about dependency, plagiarism, and potential effects on critical thinking, are addressed. By contributing to the ongoing discourse on integrating AI tools like ChatGPT in programming education, this research emphasizes the importance of responsible and ethical usage to maximize benefits for students, educators, and the broader educational community.},
  keywords={Chatbots;Programming profession;Education;Bibliometrics;Market research;Large language models;Codes;Ethics;Requirements engineering;Mathematics;ChatGPT;code generation;ethical concerns;large language models (LLMs);introductory programming;programming education;prompt engineering},
  doi={10.1109/ACCESS.2025.3554627},
  ISSN={2169-3536},
  month={},}@ARTICLE{10706931,
  author={Neumann, Alexander Tobias and Yin, Yue and Sowe, Sulayman and Decker, Stefan and Jarke, Matthias},
  journal={IEEE Transactions on Education}, 
  title={An LLM-Driven Chatbot in Higher Education for Databases and Information Systems}, 
  year={2025},
  volume={68},
  number={1},
  pages={103-116},
  abstract={Contribution: This research explores the benefits and challenges of developing, deploying, and evaluating a large language model (LLM) chatbot, MoodleBot, in computer science classroom settings. It highlights the potential of integrating LLMs into LMSs like Moodle to support self-regulated learning (SRL) and help-seeking behavior. Background: Computer science educators face immense challenges incorporating novel tools into LMSs to create a supportive and engaging learning environment. MoodleBot addresses this challenge by offering an interactive platform for both students and teachers. Research Questions: Despite issues like bias, hallucinations, and teachers’ and educators’ resistance to embracing new (AI) technologies, this research investigates two questions: (RQ1) To what extent do students accept MoodleBot as a valuable tool for learning support? (RQ2) How accurately does MoodleBot churn out responses, and how congruent are these with the established course content? Methodology: This study reviews pedagogical literature on AI-driven chatbots and adopts the retrieval-augmented generation (RAG) approach for MoodleBot’s design and data processing. The technology acceptance model (TAM) evaluates user acceptance through constructs like perceived usefulness (PU) and Ease of Use. Forty-six students participated, with 30 completing the TAM questionnaire. Findings: LLM-based chatbots like MoodleBot can significantly improve the teaching and learning process. This study revealed a high accuracy rate (88%) in providing course-related assistance. Positive responses from students attest to the efficacy and applicability of AI-driven educational tools. These findings indicate that educational chatbots are suitable for integration into courses to improve personalized learning and reduce teacher administrative burden, although improvements in automated fact-checking are needed.},
  keywords={Chatbots;Education;Computer science;Databases;Accuracy;Mentoring;Information technology;Information systems;Adaptation models;Vectors;Chatbots;higher education;large language model (LLM);moodle;moodlebot},
  doi={10.1109/TE.2024.3467912},
  ISSN={1557-9638},
  month={Feb},}@INPROCEEDINGS{10893499,
  author={Nguyen, Thomas and Sayadi, Hossein},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={ChatGPT vs. Gemini: Comparative Evaluation in Cybersecurity Education with Prompt Engineering Impact}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={The advent of Large Language Models (LLMs) has revolutionized numerous domains, notably education, by offering powerful tools for personalized learning and automated assistance. These models have the potential to significantly enhance the educational experience, particularly in the field of Computer Science (CS), where the complexity and rapidly evolving nature of topics present unique challenges and opportunities. In this study, we present a comparative evaluation into the transformative potential of LLMs in CS education, with a specific focus on cybersecurity. Our study centers on two leading LLMs: Ope-nAI's ChatGPT and Google's Gemini Pro, employing a three-fold assessment methodology. Firstly, we analyze the subject matter within cybersecurity education to identify key topics and challenges for examination. Secondly, we meticulously assess and compare the efficacy of ChatGPT and Gemini across various factors in producing satisfactory responses. Lastly, we explore the impact of leveraging prompt engineering on enhancing the quality of responses generated by these AI tools. Through this holistic approach, our research aims to provide insights into the strengths, limitations, and potential avenues for enhancement of these models, thereby enriching the ongoing discourse on LLMs integration in higher education.},
  keywords={Computer science;Large language models;Computational modeling;Education;Chatbots;Internet;Complexity theory;Prompt engineering;Computer security;Artificial Intelligence;ChatGPT;Education;Gemini;Large Language Models;Prompt Engineering},
  doi={10.1109/FIE61694.2024.10893499},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10366692,
  author={Hanifi, Khadija and Cetin, Orcun and Yilmaz, Cemal},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security (QRS)}, 
  title={On ChatGPT: Perspectives from Software Engineering Students}, 
  year={2023},
  volume={},
  number={},
  pages={196-205},
  abstract={ChatGPT, an increasingly popular Large Language Model (LLM), has found widespread acceptance, especially among the younger generation, who rely on it for various tasks, such as comprehending complex course materials and tackling homework assignments. This surge in interest has drawn the attention of researchers, leading to numerous studies that delve into the advantages and disadvantages of the upcoming LLM dominant era. In our research, we explore the influence of ChatGPT and similar models on the field of software engineering, specifically from the perspective of software engineering students. Our main objective is to gain valuable insights into their usage habits and opinions through a comprehensive survey. The survey encompassed diverse questions, addressing the specific areas where ChatGPT was utilized for assistance and gathering students’ reflections on each aspect. We found that ChatGPT has garnered widespread acceptance among software engineering students, with 93% of them utilizing it for their projects. These students expressed satisfaction with the level of assistance provided, and most intend to continue using it as a valuable tool in their work. During our investigation, we also assessed the students’ awareness of the underlying technologies behind ChatGPT. Approximately half of the students demonstrated awareness of these technologies, while 38.7% had made extra efforts to explore prompt engineering to enhance ChatGPT’s productivity. However, an important finding was that 90.6% of the students reported experiencing hallucinations during their interactions with ChatGPT. These hallucinations were shared as examples, raising significant concerns that warrant further exploration and mitigation. Moreover, we delved into potential improvements and gathered valuable recommendations, which could help ChatGPT to become even more effective and dependable in its applications.},
  keywords={Surveys;Software quality;Chatbots;Reliability engineering;Reflection;Software reliability;Security;ChatGPT;software engineering;academic education;generative AI;Large Language Models},
  doi={10.1109/QRS60937.2023.00028},
  ISSN={2693-9177},
  month={Oct},}@INPROCEEDINGS{10663054,
  author={Sah, Chandan Kumar and Xiaoli, Lian and Islam, Muhammad Mirajul and Islam, Md Kamrul},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Navigating the AI Frontier: A Critical Literature Review on Integrating Artificial Intelligence into Software Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The swift development of Artificial Intelligence (AI), namely the introduction of Large Language Models (LLMs), is drastically altering various industries and necessitating a major change in the way software engineering is taught. To equip upcoming software engineers with the knowledge and abilities to function in this AI-powered environment, curriculum and pedagogical techniques must be critically reevaluated. To better understand the integration of AI and LLMs into software engineering education, this study gives a thorough and critical analysis of the literature, looking at existing models, pedagogical frameworks, and enduring issues. We explore various approaches utilized by educational establishments, including as specialized AI and LLM courses, incorporating modules into pre-existing curricula, and utilizing open-source LLM materials. Our analysis, which is based on case studies and research data, thoroughly assesses how well these strategies enable software engineers to comprehend, make use of, and ethically create AI and LLMs. Key obstacles to the successful integration of AI and LLM are also identified by our analysis, including the inexperienced status of LLM educators, resource limitations, potential biases in AI and LLM algorithms, and insufficient instructor knowledge. Building on these discoveries, we provide solid answers to these problems and suggest interesting avenues for further study to improve the integration of AI and LLM. In the end, this study advocates for a multimodal strategy to get future software engineers ready for the impending AI and LLM future and secure their place in this quickly changing field.},
  keywords={Ethics;Reviews;Navigation;Large language models;Education;Software algorithms;Solids;large language models (LLMs);software engineering education;artificial intelligence (AI);Pedagogical frame-works;curriculum integration;successful strategies;problems and solutions;Instructor Skill;Resource Limitations;LLM Bias;AI Bias;Open-Source LLM Resources},
  doi={10.1109/CSEET62301.2024.10663054},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10592785,
  author={Dhar, Rudra and Vaidhyanathan, Karthik and Varma, Vasudeva},
  booktitle={2024 IEEE 21st International Conference on Software Architecture (ICSA)}, 
  title={Can LLMs Generate Architectural Design Decisions? - An Exploratory Empirical Study}, 
  year={2024},
  volume={},
  number={},
  pages={79-89},
  abstract={Architectural Knowledge Management (AKM) involves the organized handling of information related to architectural decisions and design within a project or organization. An essential artefact of AKM is the Architecture Decision Records (ADR), which documents key design decisions. ADRs are documents that capture decision context, decision made and various aspects related to a design decision, thereby promoting transparency, collaboration, and understanding. Despite their benefits, ADR adoption in software development has been slow due to challenges like time constraints and inconsistent uptake. Recent advancements in Large Language Models (LLMs) may help bridge this adoption gap by facilitating ADR generation. However, the effectiveness of LLM for ADR generation or understanding is something that has not been explored. To this end, in this work, we perform an exploratory study which aims to investigate the feasibility of using LLM for the generation of ADRs given the decision context. In our exploratory study, we utilize GPT and T5-based models with 0-shot, few-shot, and fine-tuning approaches to generate the Decision of an ADR given its Context. Our results indicate that in a 0-shot setting, state-of-the-art models such as GPT-4 generate relevant and accurate Design Decisions, although they fall short of human-level performance. Additionally, we observe that more cost-effective models like GPT-3.5 can achieve similar outcomes in a few-shot setting, and smaller models such as Flan-T5 can yield comparable results after fine-tuning. To conclude, this exploratory study suggests that LLM can generate Design Decisions, but further research is required to attain human-level generation and establish standardized widespread adoption.},
  keywords={Software architecture;Large language models;Standards organizations;Collaboration;Organizations;Computer architecture;Knowledge management;ADR;LLM},
  doi={10.1109/ICSA59870.2024.00016},
  ISSN={2835-7043},
  month={June},}
@INPROCEEDINGS{10500042,
  author={Woerner, Jan H.R. and Turtova, Aleksandra P. and Lang, Andrew S.I.D.},
  booktitle={SoutheastCon 2024}, 
  title={Transformative Potentials and Ethical Considerations of AI Tools in Higher Education: Case Studies and Reflections}, 
  year={2024},
  volume={},
  number={},
  pages={510-515},
  abstract={This paper examines the transformative impact of Artificial Intelligence (AI) tools, especially Large Language Models like ChatGPT, on higher education. Focusing on how AI can enhance and challenge the learning environment, it navigates through the benefits and ethical concerns, such as privacy issues, overreliance on the technology itself, and potential biases. The article's core comprises two practical case studies-one in computer science, where ChatGPT aids in teaching programming, and another in English composition, exploring its role in developing writing skills. In the computer science context, ChatGPT shows how AI can introduce diverse problem-solving approaches and elevate student engagement, with notable improvements in students' comprehension and application of programming techniques. In English composition, the integration of ChatGPT assists in crafting texts, highlighting the balance needed between AI assistance and human critical thinking. Concluding with a call for a balanced approach, the study emphasizes that AI should complement, not substitute, traditional teaching methods. It advocates for a responsible and ethical application of AI in education, underlining the need to integrate technological advancements with fundamental core literacies to elevate the academic experience of all students.},
  keywords={Ethics;Privacy;Navigation;Education;Writing;Chatbots;Reflection;AI;Artificial Intelligence;classroom;teacher;exploration;concerns;strategies;computer-mediated;learning},
  doi={10.1109/SoutheastCon52093.2024.10500042},
  ISSN={1558-058X},
  month={March},}@ARTICLE{10105236,
  author={Shoufan, Abdulhadi},
  journal={IEEE Access}, 
  title={Exploring Students’ Perceptions of ChatGPT: Thematic Analysis and Follow-Up Survey}, 
  year={2023},
  volume={11},
  number={},
  pages={38805-38818},
  abstract={ChatGPT has sparked both excitement and skepticism in education. To analyze its impact on teaching and learning it is crucial to understand how students perceive ChatGPT and assess its potential and challenges. Toward this, we conducted a two-stage study with senior students in a computer engineering program ( $n=56$ ). In the first stage, we asked the students to evaluate ChatGPT using their own words after they used it to complete one learning activity. The returned responses (3136 words) were analyzed by coding and theme building (36 codes and 15 themes). In the second stage, we used the derived codes and themes to create a 27-item questionnaire. The students responded to this questionnaire three weeks later after completing other activities with the help of ChatGPT. The results show that the students admire the capabilities of ChatGPT and find it interesting, motivating, and helpful for study and work. They find it easy to use and appreciate its human-like interface that provides well-structured responses and good explanations. However, many students feel that ChatGPT’s answers are not always accurate and most of them believe that it requires good background knowledge to work with since it does not replace human intelligence. So, most students think that ChatGPT needs to be improved but are optimistic that this will happen soon. When it comes to the negative impact of ChatGPT on learning, academic integrity, jobs, and life, the students are divided. We conclude that ChatGPT can and should be used for learning. However, students should be aware of its limitations. Educators should try using ChatGPT and guide students on effective prompting techniques and how to assess generated responses. The developers should improve their models to enhance the accuracy of given answers. The study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
  keywords={Chatbots;Education;Codes;Encoding;Performance evaluation;Oral communication;ChatGPT;students’ perceptions;education},
  doi={10.1109/ACCESS.2023.3268224},
  ISSN={2169-3536},
  month={},}@ARTICLE{10418595,
  author={Safari, Pegah and Shamsfard, Mehrnoush},
  journal={IEEE Access}, 
  title={Data Augmentation and Preparation Process of PerInfEx: A Persian Chatbot With the Ability of Information Extraction}, 
  year={2024},
  volume={12},
  number={},
  pages={19158-19180},
  abstract={In this paper, we describe data preparation for our proposed chatbot PerInfEx (Persian Information Extraction chatbot). It aims to interactively chit-chat with users in Persian and by asking the least number of direct questions, extract as much personal information as possible such as user’s age or occupation. Collecting data in considerable size and aligned with our system’s specifics is a crucial step to train data-hungry modules of Natural Language Understating (NLU) and Natural Language Generating (NLG). Initially, for NLU module, we collect 99 free-discussion dialogues and crawl 74 English training conversations as more-general datasets while also manually translate 72 dialogues of ConvAI2 corpus. Moreover, we gamify collection by implementing a chatting website results in 94 dialogues. It detects direct questions and assigns random profiles to participants. They should guess the opponents profile. Also, we propose two augmentation methods: a semi-automatic and a novel fully automatic method, comprehensively evaluated on NLU benchmarks and applied on our datasets. Also, by prompting OpenAI’s GPT-3.5 model, we automatically generate 304 dialogues. The first part of these datasets is manually annotated while we use an active learning method for annotating rest of them. Next, to evaluate data quality, we assess them extrinsically using NLU baseline which results in intent-accuracy = 88.64, slot-F1 = 83.68 and exact-match = 78.22. Also, for NLG module, we automatically translate almost the rest of ConvAI2 corpus (16,217 dialogues) and paraphrase previously sets for its fine-tuning using GPT-3.5 model. Their assessment using our NLG baseline results in perplexity of 15.74 on train and 52.17 on test set.},
  keywords={Chatbots;Oral communication;Training;Data augmentation;Semantics;Data mining;Natural languages;Data collection;Data augmentation;data collection;dialogue generation;direct question;Persian open-domain chatbot;paraphrasing;personal information extraction},
  doi={10.1109/ACCESS.2024.3360863},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10967301,
  author={Simaremare, Mario and Pardede, Chandro and Tampubolon, Irma and Manurung, Putri and Simangunsong, Daniel},
  booktitle={2024 31st Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Pair Programming in Programming Courses in the Era of Generative AI: Students' Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={507-511},
  abstract={Context: The emergence of Generative AI (GenAI) technology presents an opportunity to enhance students' learning experience in programming courses using pair programming. GenAI can take the navigator role in student-GenAI pairing as an alternative to traditional student-student pairing. Objective: This study explored various use cases, challenges, and learning experiences IT students faced when using the student-GenAI pairing approach. Method: We integrated GenAI into CS1 and CS2 courses in one semester split into two halves: in the first half, students worked in student-GenAI pairs, while in the second half students worked in traditional student-student pairing with GenAI as an additional reinforcement. At the end of the semester, we interviewed 12 students purposefully selected out of 103 enrollments and employed a thematic analysis approach to synthesize the qualitative data. Results: We identified five distinct GenAI use cases confirming the existing studies and matching how software practitioners utilize GenAI in the industry, indicating an alignment between education and industry practice. Furthermore, we identified six challenges. One novel challenge related to the consequence of the technology is narrowing the students' learning horizons. The students also expressed a lack of engagement and empathy in student-GenAI pairing. They preferred the traditional pairing with GenAI as additional support, providing a better learning experience. Conclusion: Integrating GenAI into programming courses can enhance the learning experience, but new challenges emerge, provoking further studies to address them.},
  keywords={Industries;Generative AI;Navigation;Education;Chatbots;Software;Programming profession;Software engineering;Software development management;Generative AI;pair programming;programming course;ChatGPT;GitHub Copilot},
  doi={10.1109/APSEC65559.2024.00069},
  ISSN={2640-0715},
  month={Dec},}@ARTICLE{10530940,
  author={Kalluri, Balaji and Prasad, Prajish and Sharma, Prakrati and Chippa, Divyaansh},
  journal={IEEE Transactions on Education}, 
  title={Developing Future Computational Thinking in Foundational CS Education: A Case Study From a Liberal Education University in India}, 
  year={2024},
  volume={67},
  number={6},
  pages={944-953},
  abstract={Contribution: This article proposes a new theoretical model with a goal to develop future human computational thinking (CT) in foundational computer science (CS) education. The model blends six critical types of thinking, i.e., logical thinking, systems thinking, sustainable thinking, strategic thinking, creative thinking, and responsible thinking into the design of a first-year undergraduate programming course. The study describes a creative blended pedagogy that embeds the proposed model into the course plan.Background: The emergence of artificial intelligent systems such as large language models from a knowledge provider perspective, coupled with a gradual change in post-pandemic outlook of education challenge the relevance and raises concerns about the future of education. The 21st-century human CT requirements, viz., learning to code (skill) and thinking computationally (competency), will be inadequate in the future. Moreover, there is substantial evidence which shows that most introductory programming courses fail to integrate critical elements like ethics and responsibility as part of the course.Intended Outcomes: The authors anticipate experiential learning models such as this has immense potential to future-proof CS education, as well as make future software engineers responsible citizens.Application Design: The proposed model blends six types of thinking into the design and activities of the course. The underlying theoretical basis of these activities revolve around three key principles: 1) experiential learning; 2) self-reflection; and 3) peer learning.Findings: This case study from a liberal educational institution in India qualitatively shows evidence of students developing six critical elements of thinking that shapes their future CT ability.},
  keywords={Education;Sustainable development;Computational modeling;Systems thinking;Programming profession;Software systems;Green products;21st-century skills;computer science (CS);creative pedagogy;foundational education;future thinking},
  doi={10.1109/TE.2024.3394060},
  ISSN={1557-9638},
  month={Dec},}@INPROCEEDINGS{10893333,
  author={Tuzmen, Ayca},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Use of Generative Artificial Intelligence in the Education of Software Verification and Validation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Since the introduction of generative artificial intelligence (GenAI), education in computer science has prompted efforts to incorporate it into the educational curriculum. This innovative practice full paper presents a study into using GenAI to enhance student learning of software engineering. It outlines the initiatives to introduce GenAI into a graduate-level software engineering course in Software Verification and Validation (SV&V). The paper presents the educational goals, methodologies and findings of these endeavors in this course. The primary education goal of this course is that students have a solid understanding of principles and practices of software quality assurance and seek to introduce students to diverse techniques employed for SV&V. The study presented in this paper centers on the practical application of GenAI within the domain of testing strategies. The paper introduces the findings of an exercise where GenAI was used to apply testing strategies for unit testing. The exercise consisted of the use of GenAI in the development of unit tests for an algorithm. Rigorous assessments were conducted to gauge the effectiveness of the unit tests developed for validating the accurate implementation of the algorithm. This exploration shed light on the tangible impact of GenAI on the precision and efficiency of unit testing procedures. The findings underscore the significance of encouraging students to actively explore emerging trends and methodologies in the realm of software verification and validation. By incorporating GenAI into the educational framework, students not only gain insights into the capabilities and limitations of this technology but also foster a mindset of continuous learning in software quality assurance. The paper demonstrates that it is not sufficient to use the test cases developed by GenAI for software validation since test cases recommended by GenAI do not cover corner cases which causes gaps in coverage in unit testing. The majority of the students were able to understand the limitation of GenAI in SV&V but appreciated its support in suggesting test cases for the most common cases. This exercise allowed students to enhance their creative problem-solving through human-guided AI partnership which is pivotal in cultivating a new generation of professionals capable of contributing to the ongoing evolution of software quality.},
  keywords={Technological innovation;Codes;Generative AI;Education;Software algorithms;Software quality;Solids;Problem-solving;Testing;Software engineering;generative artificial intelligence;software verification and validation;unit testing},
  doi={10.1109/FIE61694.2024.10893333},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10502959,
  author={Vijaya, J. and Swati, Ch and Satya, Swastika},
  booktitle={2024 IEEE International Conference on Interdisciplinary Approaches in Technology and Management for Social Innovation (IATMSI)}, 
  title={Ikigai: Artificial Intelligence-Based Virtual Desktop Assistant}, 
  year={2024},
  volume={2},
  number={},
  pages={1-6},
  abstract={The AI Desktop Assistant project aims to create an advanced virtual assistant inspired by cinematic intelligent systems to enhance user interactions with computers by integrating natural language voice commands into daily tasks. The project harnesses existing techniques, offering users the ability to interact with the assistant through voice commands for tasks like sending emails and scheduling while also automating routine activities such as file organization. However, despite its promising features, the existing project may have some drawbacks. One Potential limitation could be its reliance on pre-defined voice commands, which may limit the flexibility and naturalness of interactions. Additionally, the system’s ability to understand and respond accurately to various user accents and speech patterns may need further refinement to ensure inclusivity. Furthermore, as the project aims to automate routine tasks, user privacy and data security concerns might require careful consideration and mitigation. Addressing These challenges and continuously improving the project will be essential to deliver a robust and user-friendly desktop assistant. To overcome project drawbacks, we’ll enhance NLP for natural interactions, improve adaptive voice recognition, prioritize user-centric design, deploy machine learning for command understanding, enable personalization and accessibility, and provide user education. We Would Utilize advanced NLP models like BERT or GPT-3.5 for language understanding. Fine-tune these models on diverse text data to enhance natural language interactions. We will collect speech and text data from reputable sources such as Kaggle and other open-source datasets. We are additionally integrating the NASA navigator (which gives news related to space) so that users can stay informed about space-related events and missions, fostering their curiosity and interest in space exploration. Success metrics include user satisfaction and the assistant’s efficiency in executing tasks. Continuous user feedback fuels improvements, promising a seamless and intelligent desktop assistant experience.},
  keywords={Adaptation models;Technological innovation;Navigation;Virtual assistants;NASA;Speech recognition;Organizations;Virtual Assistant;UI;Artificial Intelligence;Python Library;Natural Language Process},
  doi={10.1109/IATMSI60426.2024.10502959},
  ISSN={},
  month={March},}@ARTICLE{10521640,
  author={Bengesi, Staphord and El-Sayed, Hoda and Sarker, MD Kamruzzaman and Houkpati, Yao and Irungu, John and Oladunni, Timothy},
  journal={IEEE Access}, 
  title={Advancements in Generative AI: A Comprehensive Review of GANs, GPT, Autoencoders, Diffusion Model, and Transformers}, 
  year={2024},
  volume={12},
  number={},
  pages={69812-69837},
  abstract={The launch of ChatGPT in 2022 garnered global attention, marking a significant milestone in the Generative Artificial Intelligence (GAI) field. While GAI has been in effect for the past decade, the introduction of ChatGPT sparked a new wave of research and innovation in the Artificial Intelligence (AI) domain. This surge has led to the development and release of numerous cutting-edge tools, such as Bard, Stable Diffusion, DALL-E, Make-A-Video, Runway ML, and Jukebox, among others. These tools exhibit remarkable capabilities, encompassing tasks ranging from text generation and music composition, image creation, video production, code generation, and even scientific work. They are built upon various state-of-the-art models, including Stable Diffusion, transformer models like GPT-3 (recent GPT-4), variational autoencoders, and generative adversarial networks. This advancement in GAI presents a wealth of exciting opportunities across various sectors, such as business, healthcare, education, entertainment, and media. However, concurrently, it poses unprecedented challenges such as impersonation, job displacement, privacy breaches, security vulnerabilities, and misinformation. To addressing these challenges requires a new direction for research to develop solutions and refine existing products. In our endeavor to contribute profound insights to society and advance research on GAI, we present a comprehensive journal which explores the theoretical and mathematical foundations of GAI state-of-the-art models, exploring the diverse spectrum of tasks they can perform, examining the challenges they entail, and discussing the promising prospects for the future of GAI.},
  keywords={Decoding;Mathematical models;Task analysis;Vectors;Codes;Transformers;Neural networks;Generative AI;Generative adversarial networks;Artificial intelligence;Chatbots;Encoding;Generative AI;GPT;bard;ChatGPT;diffusion model;transformer;GAN;autoencoder;artificial intelligence},
  doi={10.1109/ACCESS.2024.3397775},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10578917,
  author={Duvignau, Romaric},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT Has Eaten My Assignment: A Student-Centric Experiment on Supervising Writing Processes in the AI Era}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={AI-powered text generation tools have brought about a profound shift in students' approaches to writing assignments, prompting the need for writing supervisors to gain a deeper understanding of how these tools can effectively tackle conventional university assignments. This ongoing work presents a documented and student-centered experiment where such tools are used for crafting the final assignment in a higher education course. Through the lens of a reflective essay, the study provides insights into the experiment's nuances and offers practical considerations that can prove invaluable to writing supervisors. Despite being introduced in late 2022, ChatGPT, a prominent AI language model, has quickly become a focal point in higher education research. This work distinguishes itself from existing literature by presenting a practical guide tailored for writing supervisors involved in overseeing diverse writing processes. By documenting a student's firsthand experience using ChatGPT to generate a self-assessment plan within the context of a university writing supervision course, the study not only explores the benefits and challenges of integrating AI tools but also underscores the importance of responsible usage. In particular, this work furnishes valuable insights for writing supervisors navigating the evolving landscape of AI-driven writing tools, offering a nuanced understanding of their practical implications.},
  keywords={Navigation;Writing;Chatbots;Educational courses;Artificial intelligence;Engineering education;Lenses;ChatGPT;AI;assignment;writing supervision},
  doi={10.1109/EDUCON60312.2024.10578917},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10893139,
  author={Lauren, Paula},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work-in-Progress: Course-based Undergraduate Research Experience (CURE) with Generative AI in a Computer Science Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress innovative practice paper describes a novel integration of Generative AI with Course-based Undergraduate Research Experiences (CUREs). CUREs integrate research activities into the curriculum, allowing all students in a course to participate in inquiry-based research projects. Generative Artificial Intelligence (AI) applications are advanced AI designed to generate human-like responses by processing natural language inputs. These applications leverage machine learning models to produce outputs that can assist users in a variety of tasks from writing to coding. The integration of Generative AI with CURE had been adopted in a text-based machine learning course during the Fall 2023 semester. A comparative analysis had been conducted on student survey responses from Fall 2022 and Fall 2023 to evaluate the effectiveness of Generative AI in a CURE integrated course. Descriptive statistics and statistical tests were conducted to assess differences in student perceptions between the two semesters. Although the differences were not statistically significant, the results indicate a promising trend towards improved student perceptions of both the overall course effectiveness and the benefits of Generative AI in enhancing various aspects of the research process, especially the literature review.},
  keywords={Surveys;Computer science;Generative AI;Natural languages;Machine learning;Writing;Market research;Encoding;Systematic literature review;Course-based Undergraduate Research Experiences (CUREs);Generative AI;Artificial Intelligence in Education (AIEd)},
  doi={10.1109/FIE61694.2024.10893139},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10343474,
  author={Liu, Yunkai},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Leveraging the Power of AI in Undergraduate Computer Science Education: Opportunities and Challenges}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The paper analyzes the potential opportunities and challenges of incorporating advanced AI tools, such as ChatGPT, into undergraduate computer science education. Through a literature review, the current research on the use of AI in computer science education is summarized and gaps in the current literature are identified. The paper argues that with proper planning and support, the integration of AI tools in computer science education can enhance the curriculum and prepare students for both programming education and literature education. The limitations of ChatGPT and related AI tools are also discussed, including ethical implications and potential effects on teaching style and undergraduate research. The results of a simple survey show the current level of knowledge and usage of ChatGPT among faculty and undergraduate students in computer science majors. The paper concludes that while there are challenges to overcome, such as ethical concerns, an optimistic attitude towards the integration of AI into undergraduate computer science education can lead to positive outcomes and prepare students for the workforce.},
  keywords={Surveys;Ethics;Bibliographies;Education;Chatbots;Computer science education;Planning;ChatGPT;Artificial Intelligence;Computer Science Education;Nature Language Processing},
  doi={10.1109/FIE58773.2023.10343474},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10923833,
  author={Lee, John S. Y. and Liu, Fengkai and Cai, Tianyuan},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Code Debugging with LLM-Generated Explanations of Programming Error Messages}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Programming is an essential part of the curriculum for electrical, computer and software engineering students. Since one inevitably makes coding mistakes, it is important for programmers to develop debugging skills. However, it could be challenging for beginners to repair a non-compiling program, since programming error messages tend to be opaque, and might not directly address the error. This paper investigates the use of Large Language Models to generate plain, novice-friendly explanations of programming error messages. In an introductory course on Natural Language Processing, We evaluate the extent to which these explanations help students debug Python code with six common programming error categories. Experimental results suggest that explanations generated with zero-shot GPT-4 are effective in raising the code revision success rate.},
  keywords={Codes;Large language models;Debugging;Maintenance engineering;Encoding;Logic;Engineering education;Programming profession;Software engineering;Python;computer science;computer engineering;software engineering;Python;debugging;Large Language Model;Programming Error Message},
  doi={10.1109/ICEED62316.2024.10923833},
  ISSN={},
  month={Nov},}@ARTICLE{10546497,
  author={Shaer, Orit and Cooper, Angelora},
  journal={IEEE Pervasive Computing}, 
  title={Integrating Generative Artificial Intelligence to a Project-Based Tangible Interaction Course}, 
  year={2024},
  volume={23},
  number={1},
  pages={63-69},
  abstract={Generative Artificial Intelligence (AI), including large language and image models, have created new opportunities for pervasive computing education. How do we integrate emerging AI models and tools into our courses in a way that fosters critical engagement? How do we teach students to use AI models and tools responsibly, thoughtfully, and ethically, while being aware of their capabilities and limitations? In this article, we share insights from integrating generative AI tools and machine learning (ML) models into a project-based undergraduate tangible and embodied interaction (TEI) course by employing co-creation processes. TEI is an evolving area within human–computer interaction, which focuses on integrating computation into our daily physical environments and objects, thus fostering an embodied, multisensory, and often collaborative interaction experience. We use the term co-creation to describe a process, where humans and AI work together to create new artifacts or solve a problem. We integrated structured co-creation activities into various phases of the project including ideation, conceptual design, and prototyping. We describe practical ways and learning goals for integrating emerging generative AI tools and ML models into the project design process, provide insight on how novice interaction designers iterate and collaborate with generative AI and ML models, and reflect on the merits and limitations of using generative AI tools and ML models for project-based interaction design courses for pervasive computing.},
  keywords={Pervasive computing;Ethics;Generative AI;Computational modeling;Education;Collaboration;Machine learning;Large language models;Artificial intelligence;Machine learning;Educational courses},
  doi={10.1109/MPRV.2023.3346548},
  ISSN={1558-2590},
  month={Jan},}@INPROCEEDINGS{10838104,
  author={Sedilla, Raymond B. and Beley, Rafael Joseph T. and Gamboa, John Jeremie D. and Liu, Bon Pin M. and Mariano, Jules and Samonte, Mary Jane C.},
  booktitle={2024 IEEE 7th International Conference on Computer and Communication Engineering Technology (CCET)}, 
  title={Assessment of Machine Translation in Addressing Communication Barriers on the Perception of College Students}, 
  year={2024},
  volume={},
  number={},
  pages={262-266},
  abstract={As tools powered by Artificial Intelligence (AI) continue to advance, more specifically large language models, as they continue to develop improvements in machine translation. 59.9% of the student respondents say they use AI for machine translation daily. Google Translate is still the majority of the AI tools used in machine translation by students with 22% followed by Chat-GPT with 21%. Amongst the three criteria asked in the survey, there is an ongoing pattern that a huge majority of the students are satisfied with the accuracy, adequacy, and fluency of the translated text. The findings illuminate a widespread reliance on AI tools, with Google Translate and ChatGPT leading the preferences. The study underscores the importance of these tools across diverse academic disciplines, from engineering to language training, revealing a nuanced landscape of AI integration in education. The satisfaction levels reported by the students regarding accuracy, adequacy, and fluency highlight the positive impact of AI in facilitating language-related tasks.},
  keywords={Training;Surveys;Translation;Accuracy;Navigation;Collaboration;Chatbots;Internet;Machine translation;Artificial intelligence;machine translation;language barrier;communication},
  doi={10.1109/CCET62233.2024.10838104},
  ISSN={2836-5992},
  month={Aug},}@INPROCEEDINGS{10959426,
  author={Alashwal, May},
  booktitle={2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)}, 
  title={Generative AI in Computer Science Education: Insights from Topic Modeling and Text Network Analysis}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={The rapid evolution of generative artificial intelligence (AI) is reshaping educational landscapes., particularly in computer science education. This study investigates research trends in generative AI applications through text network and topic modeling analyses. A comprehensive literature review across IEEE Xplore., Scopus., and Web of Science identified 151 studies published between 2023 and 2024. Text network analysis revealed that “AI.,” “student.,” “education.,” “learning.,” and “performance” were the most frequently occurring terms., highlighting key research themes. Ego-network analysis demonstrated strong interconnectivity between educational AI tools and student learning outcomes. Using Latent Dirichlet Allocation (LDA)., four major research topics emerged: educational chatbots (35.1 %)., AI literacy (25.8%)., exam performance (21.8%)., and technology integration (17.2%). Findings indicate a dominant focus on chatbots for student engagement., while ethical concerns and multimodal AI applications remain underexplored. The study underscores the necessity of addressing AI literacy gaps and enhancing interdisciplinary AI integration in educational settings. Despite its potential., generative AI adoption is hindered by privacy risks., uneven technological access., and the lack of standardized policies. Future research should focus on ethical AI frameworks., multimodal AI tools., and long-term learning outcomes. This study provides a data-driven foundation for understanding the evolving role of generative AI in education and its implications for educators., policymakers., and researchers.},
  keywords={Ethics;Analytical models;Privacy;Generative AI;Computational modeling;Education;Network analyzers;Chatbots;Market research;Computer science education;Generative AI;Computer Science Education;AI Literacy;Educational Chatbots;Topic Modeling Analysis},
  doi={10.1109/ICAISC64594.2025.10959426},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10342963,
  author={Dehbozorgi, Nasrin and Kunuku, Mourya Teja},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Affective Computing: A Topic-Based SER Approach on Collaborative Discussions in Academic Setting}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={One of the biggest concerns in the modern day especially in the educational domain centers on the student's mental health. High rates of anxiety and depression have especially brought the attention of researchers in engineering education to apply affective computing to help with students' academic performance. It is known that a person's emotional states cause physiological and physical changes in the body. Emotions may impact facial expression, tone of speech, blood pressure, pulse, etc. Since visual and auditory signals are two variables that can be measured without the need to attach any physical device to the individuals, they are most studied in this field. Speech in particular has been known as a means that transfers much information about the mental and emotional states of the person. Speech Emotion Recognition (SER) is a growing field that has been applied in several domains including engineering education. Recent advancements in AI, Natural Language Understanding (NLU), and Large Language Models (LLM) have significantly streamlined this line of research. In this work which is a continuation of our prior work, we propose a speech analysis model that extracts both the emotions and topics from verbal discussions in a computer science classroom to understand if the expressed emotions were mostly about the course related topics or not. The goal of this research is to develop a tool that helps educators gain insights into the students' emotional states in teamwork and also understand the context of their conversations. We further analyze if the expressed emotions in the verbal class discussions are mostly about the course content or other subjects outside class setting. To expand the emotion analysis module we added a new layer to our developed pipeline by passing the speech data into the ChatGPT API to generate summarized scripts and extract additional classes of emotion. The preliminary results from this study are promising, indicating the potential value of this research direction and its prospects for further development. Application of this model in the educational domain can greatly benefit both educators and students and allows the instructors to make necessary interventions needed to maximize students' positive experiences in team settings while considering their emotional states.},
  keywords={Computer science;Analytical models;Emotion recognition;Affective computing;Computational modeling;Pipelines;Chatbots;Speech Emotion Recognition (SER);Large Language Models (LLM);NLP;Topic modeling;Affective computing;ChatGPT API;Teamwork;Engineering education},
  doi={10.1109/FIE58773.2023.10342963},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10870136,
  author={Lang, Qi and Wang, Minjuan and Yin, Minghao and Liang, Shuang and Song, Wenzhuo},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Transforming Education With Generative AI (GAI): Key Insights and Future Prospects}, 
  year={2025},
  volume={18},
  number={},
  pages={230-242},
  abstract={Generative artificial intelligence (GAI) has demonstrated remarkable potential in both educational practice and research, particularly in areas, such as personalized learning, adaptive assessment, innovative teaching methods, and cross-cultural communication. However, it faces several significant challenges, including the comprehension of complex domain knowledge, technological accessibility, and the delineation of AI's role in education. Addressing these challenges necessitates collaborative efforts from educators and researchers. This article summarizes the state-of-the-art large language models (LLMs) developed by various technology companies, exploring their diverse applications and unique contributions to primary, higher, and vocational education. Furthermore, it reviews recent research from the past three years, focusing on the challenges and solutions associated with GAI in educational practice and research. The aim of the review is to provide novel insights for enhancing human–computer interaction in educational settings through the utilization of GAI. Statistical analysis reveals that the current application of LLMs in the education sector is predominantly centered on the ChatGPT series. A key focus for future research lies in effectively integrating a broader range of LLMs into educational tasks, with particular emphasis on the interaction between multimodal LLMs and educational scenarios.},
  keywords={Education;Artificial intelligence;Large language models;Transformers;Chatbots;Technological innovation;Enthalpy;Collaboration;Visualization;Videos;Artificial intelligence (AI)-assisted learning;educational technologies;generative artificial intelligence (GAI);large language models (LLMs);survey research},
  doi={10.1109/TLT.2025.3537618},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10811132,
  author={Thaqi, Alba and Musa, Arbena and Rexha, Blerim},
  booktitle={2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES)}, 
  title={Leveraging AI for CTF Challenge Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Capture the Flag (CTF) competitions have become integral to developing cybersecurity skills, providing participants with real-world scenarios that challenge their problem-solving abilities. However, the complexity of these challenges often creates barriers for participants, especially those with less experience. This paper explores the potential of leveraging Artificial Intelligence (AI), specifically OpenAI’s Large Language Models (LLMs), to optimize the CTF challenge-solving process. By conducting a comparative study, we analyze how AI can assist participants by offering intelligent hints and personalized suggestions without compromising the integrity of the challenge. Our approach focuses on using pre-trained models to enhance learning outcomes, improve engagement, and streamline problem-solving across different difficulty levels. The results show that AI-driven solutions significantly improve the accessibility and effectiveness of CTF challenges, particularly for novice participants, by creating a more collaborative learning environment. The paper concludes that the integration of AI in CTF competitions can revolutionize cybersecurity education by making it more inclusive and adaptable to a wide range of learners.},
  keywords={Surveys;Statistical analysis;Federated learning;Large language models;Complexity theory;Problem-solving;Artificial intelligence;Intelligent systems;Optimization;Testing;capture the flag;OpenAI;cyber security},
  doi={10.1109/CIEES62939.2024.10811132},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10590238,
  author={Wang, Kevin and Akins, Seth and Mohammed, Abdallah and Lawrence, Ramon},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Student Mastery or AI Deception? Analyzing ChatGPT's Assessment Proficiency and Evaluating Detection Strategies}, 
  year={2023},
  volume={},
  number={},
  pages={1615-1621},
  abstract={Generative AI systems such as ChatGPT have a disruptive effect on learning and assessment. Computer science requires practice to develop skills in problem solving and programming that are traditionally developed using assignments. Generative AI has the capability of completing these assignments for students with high accuracy, which dramatically increases the potential for academic integrity issues and students not achieving desired learning outcomes. This work investigates the performance of ChatGPT by evaluating it across three courses (CS1,CS2,databases). ChatGPT completes almost all introductory assessments perfectly. Existing detection methods, such as MOSS and JPlag (based on similarity metrics) and GPTzero (AI detection), have mixed success in identifying AI solutions. Evaluating instructors and teaching assistants using heuristics to distinguish between student and AI code shows that their detection is not sufficiently accurate. These observations emphasize the need for adapting assessments and improved detection methods.},
  keywords={Measurement;Accuracy;Codes;Generative AI;Scientific computing;Education;Programming;ChatGPT;generative AI;performance;detection;plagarism;CS1;CS2;database},
  doi={10.1109/CSCI62032.2023.00268},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{11016417,
  author={Rachmat, Agatha and Watterson, Craig and Lundqvist, Karsten},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Impact of Chatbots on Students' Reflective Thinking in Introductory Programming Course}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This study investigated New Zealand students' views on utilising chatbots and the impact of using ChatGPT or similar chatbots with suggested prompts on the reflective thinking skills of university students. The research was conducted in an introductory computer programming course (COMP102) in the School of Engineering and Computer Science. This introductory course uses a flipped classroom approach. The students were introduced to an approach to use a generative AI-based chatbot as an intervention. The intervention consisted of a brief explanation of chatbot training and utilisation, along with a specifically designed prompt intended to support learning. An example of prompt usage was demonstrated. Students' feedback was collected through two instruments: a Reflective Thinking Scale questionnaire, which measured students' reflective thinking abilities, and an open-ended student guide questionnaire designed to gather qualitative insights into their views and experiences using chatbots. Employing a mixed-methods research approach, we incorporated quantitative (Reflective Thinking Scale questionnaire) and qualitative (open-ended student guide questionnaire) data collection instruments within an experimental pre-test and post-test control group design. The pretest yielded 86 completed responses, while the post-test had 49 participants out of over 400 students enrolled in the course. The pre-test and posttest results did not yield quantitatively significant results in students' reflective thinking after the intervention. However, 21 out of 29 qualitative post-test respondents who utilise chatbots indicated that their interactions with the chatbot showed evidence of reflective thinking that improved their learning processes. The results revealed that students initially had doubts about using a chatbot for their learning, as they felt it might hinder their learning process or be unnecessary. Students perceived chatbots to be unreliable due to providing wrong answers, inaccurate code snippets, hallucinations, and plagiarised content. Therefore, students preferred to be self-reliant and not dependent on chatbots. Following the intervention, students demonstrated an increase of confidence in utilising chatbots as a learning tool, especially those who also used the suggested prompt. Students found that chatbots and the suggested prompt could be used to support learning and not only to provide answers. The chatbot was beneficial as a learning tool, providing additional information to clarify their understanding and reasoning behind providing simple explanations of programming concepts. Future work will focus on an intervention study in a more controlled environment to isolate the features of generative AI tools' impact and minimise external factors.},
  keywords={Training;Knowledge engineering;Electronic learning;Generative AI;Instruments;Data collection;Chatbots;Online services;Engineering education;Programming profession;Reflective Thinking;Chatbots;Introductory programming;ChatGPT;Generative AI;Higher Education},
  doi={10.1109/EDUCON62633.2025.11016417},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10691721,
  author={Qiu, Siyu and Tan, Benjamin and Pearce, Hammond},
  booktitle={2024 IEEE LLM Aided Design Workshop (LAD)}, 
  title={LLM-aided explanations of EDA synthesis errors}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Training new engineers in digital design is a challenge, particularly when it comes to teaching the complex electronic design automation (EDA) tooling used in this domain. Learners will typically deploy designs in the Verilog and VHDL hardware description languages to Field Programmable Gate Arrays (FPGAs) from Altera (Intel) and Xilinx (AMD) via proprietary closed-source toolchains (Quartus Prime and Vivado, respectively). These tools are complex and difficult to use—yet, as they are the tools used in industry, they are an essential first step in this space. In this work, we examine how recent advances in artificial intelligence may be leveraged to address aspects of this challenge. Specifically, we investigate if Large Language Models (LLMs), which have demonstrated text comprehension and question-answering capabilities, can be used to generate novice-friendly explanations of compile-time synthesis error messages from Quartus Prime and Vivado. To perform this study we generate 936 error message explanations using three OpenAI LLMs over 21 different buggy code samples. These are then graded for relevance and correctness, and we find that in approximately 71% of cases the LLMs give correct & complete explanations suitable for novice learners.},
  keywords={Training;Industries;VHDL;Design automation;Large language models;Conferences;Computer bugs;Logic gates;Hardware;Field programmable gate arrays;EDA;CAD;AI;LLM;Bug Explanation},
  doi={10.1109/LAD62341.2024.10691721},
  ISSN={},
  month={June},}@INPROCEEDINGS{10892995,
  author={Barlowe, Scott and Aoulou, Daniel and Ponce-Castillo, Alex},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Generative AI as an Instructional Resource in a Computer Science Ethics Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress research paper reports our initial attempt at integrating generative artificial intelligence (Gen AI) into our two credit hour ethics course required for computer science majors. Course content includes ethical frameworks, presentations, current event and stakeholder analysis, formal debates, job seeking, and codes of conduct. Given the wide applicability of computer ethics and the crowded schedule in the course, our inquiry seeks to find ways of utilizing Gen AI to streamline content delivery, to provide opportunities for independent student exploration, and to aid students during preparation for class activities. In this paper, we first describe a novel assignment integrating Gen AI given to students enrolled in the Spring 2024 offering of our computer science ethics course. The findings from a survey addressing student use of Gen AI before and during the assignment and the analysis of assignment artifacts submitted by students are then reported. Finally, we present additional student data and results from our separate experimentation, both of which focus on the use of Gen AI for debate preparation. Our efforts reveal that Gen AI can be a useful instructional tool for a computer science ethics course but should be integrated carefully.},
  keywords={Computer science;Surveys;Ethics;Schedules;Codes;Generative AI;Stakeholders;Springs;ethics;professional skills;computer science},
  doi={10.1109/FIE61694.2024.10892995},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10577164,
  author={Hang, Ching Nam and Wei Tan, Chee and Yu, Pei-Duo},
  journal={IEEE Access}, 
  title={MCQGen: A Large Language Model-Driven MCQ Generator for Personalized Learning}, 
  year={2024},
  volume={12},
  number={},
  pages={102261-102273},
  abstract={In the dynamic landscape of contemporary education, the evolution of teaching strategies such as blended learning and flipped classrooms has highlighted the need for efficient and effective generation of multiple-choice questions (MCQs). To address this, we introduce MCQGen, a novel generative artificial intelligence framework designed for the automated creation of MCQs. MCQGen uniquely integrates a large language model (LLM) with retrieval-augmented generation and advanced prompt engineering techniques, drawing from an extensive external knowledge base. This integration significantly enhances the ability of the LLM to produce educationally relevant questions that align with both the goals of educators and the diverse learning needs of students. The framework employs innovative prompt engineering, combining chain-of-thought and self-refine prompting techniques, to enhance the performance of the LLM. This process leads to the generation of questions that are not only contextually relevant and challenging but also reflective of common student misconceptions, contributing effectively to personalized learning experiences and enhancing student engagement and understanding. Our extensive evaluations showcase the effectiveness of MCQGen in producing high-quality MCQs for various educational needs and learning styles. The framework demonstrates its potential to significantly reduce the time and expertise required for MCQ creation, marking its practical utility in modern education. In essence, MCQGen offers an innovative and robust solution for the automated generation of MCQs, enhancing personalized learning in the digital era.},
  keywords={Education;Knowledge engineering;Testing;Knowledge based systems;Task analysis;Semantics;Problem-solving;Large language models;Information retrieval;Data augmentation;Large language models;multiple-choice questions;personalized learning;prompt engineering;retrieval-augmented generation},
  doi={10.1109/ACCESS.2024.3420709},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10892891,
  author={Ghimire, Aashish and Pather, James and Edwards, John},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research full paper delves into university in-structors' experiences and attitudes toward AI language models, filling a gap in the literature by analyzing educators' perspectives on AI's role in the classroom and its potential impacts on teaching and learning. The rapid advancement of artificial intelligence (AI) and the expanding integration of large language models (LLMs) have ignited a debate about their application in education. The objective of this research is to investigate the level of awareness, overall sentiment towards adoption, and the factors influencing these attitudes for LLMs and generative AI-based tools in higher education. Data was collected through a survey using a Likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. The collected data was processed using statistical and thematic analysis techniques. Our findings reveal that educators are increasingly aware of and generally positive towards these tools. We find no correlation between teaching style and attitude toward generative AI. Finally, while CS educators show far more confidence in their technical understanding of generative AI tools and more positivity towards them than educators in other fields, they show no more confidence in their ability to detect AI-generated work.},
  keywords={Surveys;Training;Uncertainty;Generative AI;Shape;Navigation;Large language models;Education;Artificial intelligence;Interviews;LLM;Chatbot;ChatGPT;AI in Education;Teachers' attitude},
  doi={10.1109/FIE61694.2024.10892891},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10765070,
  author={Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Li, Ge and Sun, Zian and Li, Zhongqi and Ma, Yuchi},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={669-680},
  abstract={Providing personalized and timely feedback for student’s programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM’s attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67× compared to the autoregressive decoding algorithm.CCS CONCEPTS• Software and its engineering; • Computing methodologies → Artificial intelligence;},
  keywords={Large language models;Computer bugs;Software algorithms;Education;Maintenance engineering;Inference algorithms;Software;Decoding;Programming profession;Software engineering;Automated Program Repair;Large Language Models;Programming Education;Inference Acceleration},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{11016317,
  author={Matobobo, Courage and Ncube, Prince Daughin Ngqabutho and Ngesimani, Nomputumo Linah and Dzvapatsva, Godwin Pedzisai and Chinhamo, Edmore},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing Computational Thinking and Problemsolving in Programming Education Through Generative AI: A Scoped Review}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This study assesses how generative artificial intelligence tools enhance computational thinking and problemsolving skills in the context of programming education. Generative AI (GenAI) has ushered in a new era in programming education, offering immediate, personalised support through tools like ChatGPT and GitHub Copilot. Although generative AI tools have shown promise in enhancing immediate problem-solving abilities, there is a lack of research on their long-term effects on students' computational thinking and professional programming skills development. This study conducted a scoped evaluation of previously published papers using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) standard, and the data was analysed using a thematic approach. The findings from the study indicate that integrating GenAI can potentially enhance computational thinking and problem-solving for programming students. On the flipside, our study highlighted some significant ethical challenges associated with using GenAI in academia, particularly regarding issues of originality in student work. Contrary to expectations on how GenAI tools enhance learners' decomposition, abstraction, and algorithm design skills, most of the findings concentrated on students' completion of tasks. From a practical perspective, it is evident that GenAI has changed the learning landscape therefore, there is a need from a policy perspective to start thinking about the transformational roles of educators. Future studies should be carried out over a long period and should start by assessing students' levels of problem-solving at a particular age before the immersive use of GenAI and then check the results after the use of these tools.},
  keywords={Measurement;Ethics;Generative AI;Inhibitors;Chatbots;Problem-solving;Programming profession;Standards;Systematic literature review;Software development management;Computational Thinking;Generative Artificial Intelligence;Programming Education;Problem Solving Skills;ChatGPT},
  doi={10.1109/EDUCON62633.2025.11016317},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10349057,
  author={Arista, Artika and Shuib, Liyana and Ismail, Maizatul Akmar},
  booktitle={2023 International Conference on Informatics, Multimedia, Cyber and Informations System (ICIMCIS)}, 
  title={A Glimpse of chatGPT: An Introduction of Features, Challenges, and Threads in Higher Education}, 
  year={2023},
  volume={},
  number={},
  pages={694-698},
  abstract={When used in conjunction with education, ChatGPT is a helpful tool for teaching and understanding fundamental concepts. Students who struggle to find study partners or lack the time to attend tutoring sessions may discover that reviewing and studying with the chatGPT are helpful. Students' access to material and completion of assignments can be accelerated using this technology in research and education. More than one-third of university students who participated in a poll said that they used the ChatGPT for writing assessments. Professors have referred to these technologies as a "threat" and a "plague on education," and ChatGPT has been prohibited from several educational institutions. Thus, this research focuses on the introduction of Features, Challenges, and Threads chatGPT in Higher Education. This study is conducted using the literature review method. According to this research result, this tool can boost student engagement by providing immersive, dynamic, and customized learning environments. However, there are some related issues that need to be considered such as integrity, accuracy and reliability, information bias, and privacy issues. We can therefore infer that there may be benefits as well as drawbacks to employing AI in education that need to be taken into account.},
  keywords={Context;Privacy;Multimedia systems;Instruction sets;Education;Chatbots;Data structures;chatGPT;Features;Challenges;Threads;Higher Education},
  doi={10.1109/ICIMCIS60089.2023.10349057},
  ISSN={2837-5203},
  month={Nov},}@ARTICLE{10993361,
  author={Kuo, Ming-Mu and Li, Xiangfang and Obiomon, Pamela and Qian, Lijun and Dong, Xishuang},
  journal={IEEE Access}, 
  title={Improving Student Learning Outcome Tracing at HBCUs Using Tabular Generative AI and Deep Knowledge Tracing}, 
  year={2025},
  volume={13},
  number={},
  pages={82407-82420},
  abstract={Historically Black Colleges and Universities in the United States serve a vital role in providing educational opportunities and training, particularly for underrepresented students, facing a challenge of lower retention and graduation rates compared to other institutions. To overcome this challenge, this study explores the application of generative artificial intelligence models to generate synthetic data, augmenting real datasets to improve student learning outcome tracing at these colleges and universities using Deep Knowledge Tracing techniques, which potentially offers actionable insights to identify at-risk students and enables proactive interventions to enhance retention and graduation rates in Science, Technology, Engineering and Math education. Utilizing two years of educational data from Prairie View A&M University, it applied data augmentation with tabular generative artificial intelligence models. The experimental results indicate that augmenting training data with synthetic samples generated by these models improved tracing performance measured by AUC and accuracy by approximately 5% and 3%, respectively, underscoring the potential of synthetic data to enhance the monitoring of student learning outcomes in diverse educational contexts. These findings highlight the critical role of data augmentation through generative artificial intelligence in improving the student learning outcome tracing, offering valuable insights for strategies to enhance retention and graduation rates.},
  keywords={Data models;Synthetic data;Predictive models;Accuracy;Generative AI;Numerical models;Education;Training;Knowledge engineering;Adaptation models;Generative AI;student learning outcome tracing;historically black colleges and universities;STEM education},
  doi={10.1109/ACCESS.2025.3568171},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10663028,
  author={AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Cultivating Software Quality Improvement in the Classroom: An Experience with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Large Language Models (LLMs), like ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including programming, testing, code review, and program comprehension. However, their effectiveness in improving software quality in the classroom remains uncertain. In this paper, our aim is to shed light on our experience in teaching the use of Programming Mistake Detector (PMD) to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. This paper discusses the results of an experiment involving 102 submissions that carried out a code review activity of 1,230 rules. Our quantitative and qualitative analysis reveals that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. We envision our findings to enable educators to support students with code review strategies to raise students' awareness about LLMs and promote software quality in education.},
  keywords={Codes;Reviews;Large language models;Education;Software quality;Detectors;Chatbots;large language models;education;bugfix;code quality},
  doi={10.1109/CSEET62301.2024.10663028},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10722016,
  author={Mehnen, Lars and Pohn, Birgit},
  booktitle={2024 International Conference on Software, Telecommunications and Computer Networks (SoftCOM)}, 
  title={Supporting Academic Teaching with Integrating AI in Learning Management Systems: Introducing a Toolchain for Students and Lecturers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Artificial Intelligence (AI) is transforming educational technology by enhancing both teaching and learning processes. This paper examines the “LearnStreamAI” project at Technikum Wien, which integrates an AI-driven chatbot within the Moodle LMS to support real-time student interactions. Utilizing advanced AI technologies like OpenAI’s ChatGPT-4, Google Gemini, and Anthropic Claude3, the chatbot adapts to individual students’ knowledge levels, provides tailored feedback, and enhances engagement through interactive elements in quizzes. Multilingual subtitles using OpenAI’s Whisper technology further improve accessibility for diverse student bodies. In parallel, a toolchain has been developed that automates the creation of academic materials using a PowerShell script and the OpenAI API, based on an easily maintainable Excel input file. This includes generating PowerPoint slides, Moodlecompatible questions, and detailed topic descriptions, all exported into Moodle XML format. The approach ensures accessibility and ease of use for lecturers across various disciplines. The results indicate significant time savings and improved consistency in material preparation. Feedback from pilot studies shows that the AI-generated content is clear, relevant, and well-aligned with academic goals. The system also aids lecturers in quickly acquiring new knowledge by explaining, translating, and summarizing literature. This paper discusses the design, implementation, benefits, and potential improvements of this AI-driven tool, highlighting its role in modern academic teaching and the associated challenges and ethical considerations.},
  keywords={Learning management systems;Ethics;XML;Learning (artificial intelligence);Chatbots;Software;Real-time systems;Telecommunications;Internet;Materials preparation;Artificial Intelligence;Teaching;Learning;ChatGPT},
  doi={10.23919/SoftCOM62040.2024.10722016},
  ISSN={1847-358X},
  month={Sep.},}@INPROCEEDINGS{10527886,
  author={Li, Haoyuan},
  booktitle={2023 3rd International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology (CEI)}, 
  title={The Potential of Large Language Models as Tools for Analyzing Student Textual Evaluation: A Differential Analysis Between CS and Non-CS Students}, 
  year={2023},
  volume={},
  number={},
  pages={225-230},
  abstract={Research on the analysis of Student Textual Evaluation encounters ongoing challenges. Large language models, as emerging tools in natural language processing, have garnered extensive attention. This study explores the potential of large-scale language models as tools for analyzing student course evaluations on the Coursera platform and compares Computer Science (CS) and non-Computer Science (non-CS) course reviews to investigate variations in student sentiment and thematic content between these two domains. The study adopts a systematic approach to review and analyze student reviews, identifying common sentiments and patterns, and categorizing reviews into relevant evaluation themes. Additionally, the study assesses inter-annotator agreement to validate the accuracy of manual analyses. Experimental findings reveal a strong correlation between large language models and actual course ratings as well as human-analyzed results, suggesting their potential as tools for assessing student course evaluations. Results from the analysis of CS and non-CS course reviews indicate significant disparities in the distribution of thematic content between these two academic domains.},
  keywords={Computer science;Analytical models;Systematics;Correlation;Reviews;Computational modeling;Natural language processing;Sentiment;Large Language Model;Student Textual Evaluation;Computer Science;Course Reviews},
  doi={10.1109/CEI60616.2023.10527886},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11016446,
  author={Martinez-Romo, Juan and Araujo, Lourdes and Plaza, Laura and López-Ostenero, Fernando},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI for Education: A Retrieval-Augmented System for Effective Feedback in Self-Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={The application of generative AI in education has shown significant potential to enhance learning outcomes by providing personalized, adaptive feedback to students. In this work, we present a novel Retrieval-Augmented Generation (RAG) system designed to improve the explanations and feedback provided to students during self-assessment activities. The system we developed is grounded in the course's reference material, ensuring that the feedback remains accurate, consistent, and contextually relevant to the student's curriculum. The system retrieves information directly from the textbook, reducing ambiguity and interpretation errors, and generates responses tailored to the specific needs of each student. The feedback is not only designed to correct misconceptions but also to reinforce key concepts, making the system a valuable tool for self-guided learning. In this study, we also explore the importance of prompt engineering in creating effective AI-generated feedback. We detail the iterative process used to optimize the prompts and the strategies employed to ensure high-quality, interpretable responses. The findings from this work suggest that generative AI, when integrated with subject-specific textbooks and careful prompt engineering, can significantly enhance the educational experience by providing dynamic, and contextually accurate feedback. This approach opens new possibilities for AI-driven education tools, contributing to more personalized and effective learning experiences.},
  keywords={Computer science;Accuracy;Retrieval augmented generation;Prompt engineering;Iterative methods;Engineering education;Self-assessment tools;formative feedback;computer science;generative IA;Retrieval augmented generation},
  doi={10.1109/EDUCON62633.2025.11016446},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016298,
  author={Naeem, Usman and Styve, Arne and Virkki, Outi T.},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Stimulating Critical Thinking in a Web Programming Module with Generative AI Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Web frameworks have significantly changed how developers create web applications for the Internet. Thanks to pre-defined libraries, these frameworks not only accelerate development time but also reduce the amount of code developers need to write. However, to get the most out of the frameworks and libraries, developers need to have a deep understanding of core web programming languages. This allows them to write efficient code, troubleshoot effectively, and push the boundaries of what the frameworks can achieve. The same principle applies to Generative Artificial Intelligence (AI) tools, as they have the potential to enhance a developer's toolkit. However, they will only be useful if the developer has sound fundamental knowledge to verify the output from these tools. Educators in higher education face a similar predicament with the widespread use of Generative AI tools by learners. Many learners rely on these tools as a go-to solution without being able to verify or fully comprehend the output, leading to shallow understanding. The work in this paper outlines an approach used in a first-year web programming module within the School of Electronic Engineering and Computer Science at Queen Mary University of London, where learners were encouraged to use Generative AI tools to stimulate critical thinking when conducting assessments. Specifically, GitHub CoPilot was used as a pair programmer, and ChatGPT served as a peer reviewer. In this context, the peer reviewer's role was to help the learner reflect on the tool's output. The aim of this study was to explore the design of active learning activities that incorporate Generative AI tools for web programming to foster critical thinking practices among learners. To evaluate our approach, we employed a critical thinking self-evaluation questionnaire instrument, where learners' opinions and customs were surveyed before and after both of the assignments.},
  keywords={Codes;Generative AI;Instruments;Active learning;Chatbots;Libraries;Internet;Programming profession;Faces;Software development management;Generative AI;critical thinking;ChatGPT;GitHub CoPilot;web programming},
  doi={10.1109/EDUCON62633.2025.11016298},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016571,
  author={Zönnchen, Benedikt and Hobelsberger, Martin and Socher, Gudrun and Thurner, Veronika and Ottinger, Sarah},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Exploring the Role of Large Language Models as Artificial Tutors}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={As large language models (LLMs) become increasingly integrated into learning environments, their potential to enhance or hinder the acquisition of computational skills remains debated. This study investigates the role of generative AI (GenAI) tools, particularly Harvard's CS50 Duck, in supporting programming education. Through a mixed-methods approach, we examine students' perceptions, engagement, and practical application of the CS50 Duck within our Computational Thinking course. Our results indicate that while proficient students use GenAI tools to reinforce problem-solving skills, struggeling students may over-rely on them, potentially bypassing critical learning processes. Survey and assignment data suggest that students value the non-judgmental feedback provided by the CS50 Duck, yet express nuanced views on GenAI's role in formal assessments and programming education. We show that analysing chat histories can serve as a qualitative framework for examining the interactions between students and artificial tutors, while simultaneously offering critical insights into students' learning processes and the challenges they encounter. This study also underscores the need for instructional strategies that guide responsible GenAI use and highlights the importance of educator involvement in integrating these tools effectively.},
  keywords={Surveys;Hands;Generative AI;Large language models;Learning (artificial intelligence);Solids;Problem-solving;History;Engineering education;Programming profession;artificial intelligence;generative artificial intelligence;large language models;computing education;programming courses;artificial tutor},
  doi={10.1109/EDUCON62633.2025.11016571},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10734610,
  author={Chusap, Krerkkiat and Liu, Chang},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Gauging Tech Community Acceptance of Rapid Prototyping in Unfamiliar Programming Languages using LLM Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={8-13},
  abstract={Large Language Model (LLM) chatbots such as ChatGPT possess information not only about human languages but also computer languages. It is now possible to perform programming and software design tasks with assistance from ChatGPT. We are particularly interested in how the software development community views the use of LLM chatbots in rapid prototyping using unfamiliar programming languages. In four different tech events, several example scenarios of how a tech-savvy engineer could use ChatGPT to prototype apps in unfamiliar programming languages were demonstrated, including a health education app. The four events include an IEEE chapter workshop, an IEEE WIE (Woman In Engineering) meeting, an IEEE joint chapter talk, and a university-level Computer Science class. The responses from the tech audience showed that the majority perceived value in the use of LLM chatbots in these contexts, even though there were subtle differences among different groups. This shows the need for further research on how to effectively incorporate LLM chatbots into traditional software design workflow to better serve the software development community.CCS CONCEPTS• Software and its engineering → Software design engineering.},
  keywords={Computer languages;Software design;IEEE Chapters;Conferences;Large language models;Chatbots;Rapid prototyping;Software;Programming profession;Software development management;Software Engineering;Software Design;Rapid Prototyping;LLMs;ChatGPT},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10305701,
  author={Wang, Tianjia and Díaz, Daniel Vargas and Brown, Chris and Chen, Yan},
  booktitle={2023 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Exploring the Role of AI Assistants in Computer Science Education: Methods, Implications, and Instructor Perspectives}, 
  year={2023},
  volume={},
  number={},
  pages={92-102},
  abstract={The use of AI assistants, along with the challenges they present, has sparked significant debate within the community of computer science education. While these tools demonstrate the potential to support students' learning and instructors' teaching, they also raise concerns about enabling unethical uses by students. Previous research has suggested various strategies aimed at addressing these issues. However, they concentrate on introductory programming courses and focus on one specific type of problem. The present research evaluated the performance of ChatGPT, a state-of-the-art AI assistant, at solving 187 problems spanning three distinct types that were collected from six undergraduate computer science. The selected courses covered different topics and targeted different program levels. We then explored methods to modify these problems to adapt them to ChatGPT's capabilities to reduce potential misuse by students. Finally, we conducted semi-structured interviews with 11 computer science instructors. The aim was to gather their opinions on our problem modification methods, understand their perspectives on the impact of AI assistants on computer science education, and learn their strategies for adapting their courses to leverage these AI capabilities for educational improvement. The results revealed issues ranging from academic fairness to long-term impact on students' mental models. From our results, we derived design implications and recommended tools to help instructors design and create future course material that could more effectively adapt to AI assistants' capabilities.},
  keywords={Visualization;Shape;Computational modeling;Education;Chatbots;Distance measurement;Computer science education;Computer science education;Large language model;ChatGPT;Interview},
  doi={10.1109/VL-HCC57772.2023.00018},
  ISSN={1943-6106},
  month={Oct},}@INPROCEEDINGS{10448947,
  author={Suryavanshi, Deepali Prakash and Kaveri, Parag Ravikant and Kadlag, Poonam Sachin},
  booktitle={2023 Intelligent Computing and Control for Engineering and Business Systems (ICCEBS)}, 
  title={Advancing Digital Transformation in Indian Higher Education Institutions}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper focuses on advancing the use of Digital Transformation in Indian Higher Education Institutions, although India being a developing country it is important for the educational institution to practice transformation in various forms. The paper covers the detail literature study and conclude with various opinions that have been generated through primary data collection. The objective of the study is to identify the need of digital transformation for education environment by two major methods literature study and stakeholder data analysis. Technological expectation was also studied using questionnaires. The study also analyzed related studies that had been done in the past using the Vosviewer programme for the years 1980 to 2004 for Scopus dataset in order to understand the year-by-year publications, research articles, and book chapters in the subject of Digital Transformation in Higher Education. The majority of stakeholders concur that using digital transformation technologies like IoT, AI & ChatGpt, Generative AI, Augmented reality in higher education is essential for implementing NEP 2020 and successfully integrating digital technologies. The paper covers a detail discussion including literature review on various aspects of digital transformation in education institutes. It also covers opinion from various stakeholders to understand actual outcomes expected from the study which was conducted. The current study uses a mixed research methodology because the questionnaire includes both quantitative and qualitative questions. A sample of 40 respondents was collected, representing the four main stakeholders in education: students, faculty, businesspeople, and educationalists. The responses were analysed using the SPSS Percentage and mean. The newly adopted educational policy NEP 2020 encourages the use of technology and skill-based learning. The importance of technology in teaching and learning processes has been emphasized in numerous research papers in order to improve the teaching-learning process and its outcomes. The thorough assessment of the literature was carried out utilizing the VOS viewer to evaluate the pertinent studies and pinpoint any gaps.},
  keywords={Industries;Reviews;Digital transformation;Education;Stakeholders;Object recognition;Standards;Digital Transformation;Data Analysis;Digital revolution;Educational Institution;Technology Adoption;Stakeholders},
  doi={10.1109/ICCEBS58601.2023.10448947},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10260964,
  author={Fantechi, Alessandro and Gnesi, Stefania and Passaro, Lucia and Semini, Laura},
  booktitle={2023 IEEE 31st International Requirements Engineering Conference (RE)}, 
  title={Inconsistency Detection in Natural Language Requirements using ChatGPT: a Preliminary Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={335-340},
  abstract={With the rapid advancement of tools based on Artificial Intelligence, it is interesting to assess their usefulness in requirements engineering. In early experiments, we have seen that ChatGPT can detect inconsistency defects in natural language (NL) requirements, that traditional NLP tools cannot identify or can identify with difficulties even after domain-focused training. This study is devoted to specifically measuring the performance of ChatGPT in finding inconsistency in requirements. Positive results in this respect could lead to the use of ChatGPT to complement existing requirements analysis tools to automatically detect this important quality criterion. For this purpose, we consider GPT-3.5, the Generative Pretrained Transformer language model developed by OpenAI. We evaluate its ability to detect inconsistency by comparing its predictions with those obtained from expert judgments by students with a proven knowledge of RE issues on a few example requirements documents.},
  keywords={Training;Codes;Natural languages;Refining;Manuals;Chatbots;Transformers;ChatGPT;Natural Language Requirements;Inconsistency Detection},
  doi={10.1109/RE57278.2023.00045},
  ISSN={2332-6441},
  month={Sep.},}@INPROCEEDINGS{10772819,
  author={Farkas, Imre and Kovari, Attila and Rajcsanyi-Molnar, Mónika},
  booktitle={2024 IEEE 7th International Conference and Workshop Óbuda on Electrical and Power Engineering (CANDO-EPE)}, 
  title={The Emergence of Artificial Intelligence in Education and its Impact on Individual Literacy in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={83-88},
  abstract={In the last three years, a new partner has emerged for teachers and educators in the field of education. The mushrooming of applications based on large language models has greatly shaped the educational development fields of the present era. The use of various AI applications has become commonplace among students and teachers alike. Many questions are being raised by researchers in this field. What does the rapid development of AI applications bring to the field of pedagogy? Should the products of such applications be compared with human performance? The form presented in this thesis seeks to answer similar questions. What is the impact of frequent use of these applications on the literacy level of individuals? In which areas do students tend to use these applications? The results indicate that half of the students believe their literacy levels will decrease with the mass emergence of AI applications, while 36% feel it will not change. However, 88 % of students have already dealt with AI-based applications, with 64 % using them several times or more, suggesting a high level of integration into their educational processes.},
  keywords={Ethics;Power engineering;Large language models;Education;Collaboration;Learning (artificial intelligence);Reliability;Artificial intelligence;Monitoring;Guidelines;artificial intelligence;literacy;LLM;artificial intelligence hallucination},
  doi={10.1109/CANDO-EPE65072.2024.10772819},
  ISSN={2831-4506},
  month={Oct},}@INPROCEEDINGS{10743009,
  author={Astudillo, Gabriel and Ponce, Victor},
  booktitle={2024 11th International Conference on Future Internet of Things and Cloud (FiCloud)}, 
  title={Hybrid Platforms for IoT in the Classroom – A Competency Analysis and Performance Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={104-108},
  abstract={The Internet of Things (IoT) has been increasingly deployed in the last decade. It can now integrate faster new technologies such as Large Language Models (LLMs) into the IoT layers. IoT applications, frameworks, and tools are becoming accessible through on-premises implementations or using cloud providers such as Amazon Web Services (AWS). As a result, IoT is a mature approach to support computer science (CS) education. This paper presents how IoT is applied to College education to achieve CS competencies in Quebec, Canada. We present our experience in IoT teaching with on-premises and cloud deployments and describe a performance assessment framework for IoT platforms to simplify their selection process. Specifically, it examines the scalability (measured by throughput and average response time) of the ThingsBoard and AWS IoT Core platforms. Our findings show that a hybrid infrastructure that combines the best features of both platforms is the best suited solution for the proposed learning scenario.},
  keywords={Cloud computing;Protocols;Web services;Scalability;Education;Throughput;Time measurement;Internet of Things;Time factors;Programming profession;CS education;Internet of Things;learning;performance;evaluation},
  doi={10.1109/FiCloud62933.2024.00024},
  ISSN={2996-1017},
  month={Aug},}@INPROCEEDINGS{10773849,
  author={Wray, Tom and Wang, Ying},
  booktitle={MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)}, 
  title={5G Specifications Formal Verification with Over-the-Air Validation: Prompting is All You Need}, 
  year={2024},
  volume={},
  number={},
  pages={412-418},
  abstract={The critical role of 5G and other complex systems in infrastructure necessitates rigorous protocol verification and system validation to ensure security and reliability. This paper explores the application of applying Large Language Model enabled auto Formal Verification with Real-world Prompting on Large Language Models (LLMs) for 5G and NextG protocols, addressing ambiguities and security concerns in network infrastructure protocol and specification design. By leveraging generative transformer-based LLMs, we present a formal approach to prompt engineering that validates complex specifications and implements formal verification techniques to detect and eliminate hallucinations. Our approach is agnostic to specific LLMs, with performance comparisons across currently popular models. We thoroughly examine the human processes involved to identify entry points where Prompt Engineering can reduce process overhead. We have developed a novel framework for iterative prompting and self-monitoring to aid in formal verification using 5G reasoner, enabling closed-loop automatic 5G protocol verification. Focusing on the RRC layer of 5G release 17, specifically sections 5.3.3.3, 5.3.3.4, and 5.3.5.3, we examined the liveness properties and detected a total of seven vulnerabilities, including variations of Null Cipher, Denial of Service (DoS), Lullaby, and Incarceration attacks. Further, we established a general testing framework that spans conception, virtualization, and over-the-air testing, providing a holistic approach to security assessment. This comprehensive framework underscores the importance of robust protocol verification and system validation in the deployment of critical infrastructure technologies.},
  keywords={Protocols;5G mobile communication;Wireless networks;Security;Reliability;Prompt engineering;System validation;Virtualization;Formal verification;Testing;5G;Artificial Intelligence;Prompt Engineering;Large Language Models;Security},
  doi={10.1109/MILCOM61039.2024.10773849},
  ISSN={2155-7586},
  month={Oct},}@INPROCEEDINGS{10764812,
  author={Yu, Xiao and Zhang, Zexian and Niu, Feifei and Hu, Xing and Xia, Xin and Grundy, John},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={What Makes a High-Quality Training Dataset for Large Language Models: A Practitioners’ Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={656-668},
  abstract={Large Language Models (LLMs) have demonstrated remarkable performance in various application domains, largely due to their self-supervised pre-training on extensive high-quality text datasets. However, despite the importance of constructing such datasets, many leading LLMs lack documentation of their dataset construction and training procedures, leaving LLM practitioners with a limited understanding of what makes a high-quality training dataset for LLMs. To fill this gap, we initially identified 18 characteristics of high-quality LLM training datasets, as well as 10 potential data pre-processing methods and 6 data quality assessment methods, through detailed interviews with 13 experienced LLM professionals. We then surveyed 219 LLM practitioners from 23 countries across 5 continents. We asked our survey respondents to rate the importance of these characteristics, provide a rationale for their ratings, specify the key data pre-processing and data quality assessment methods they used, and highlight the challenges encountered during these processes. From our analysis, we identified 13 crucial characteristics of high-quality LLM datasets that receive a high rating, accompanied by key rationale provided by respondents. We also identified some widely-used data pre-processing and data quality assessment methods, along with 7 challenges encountered during these processes. Based on our findings, we discuss the implications for researchers and practitioners aiming to construct high-quality training datasets for optimizing LLMs.CCS CONCEPTS• Software and its engineering → Software implementation planning.},
  keywords={Training;Surveys;Data integrity;Large language models;Documentation;Software;Planning;Continents;Interviews;Software engineering;Large Language Models;High-Quality Data;Practitioners’ Perspective;Empirical Study},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10578646,
  author={Vishnumolakala, Sai Krishna and C, Sobin C and Subheesh, N P and Kumar, Prabhat and Kumar, Randhir},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI-Based Research Companion (ARC): An Innovative Tool for Fostering Research Activities in Undergraduate Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The engineering education today emphasizes the need to combine book learning with real-world application. However, much of the research done by undergraduates, which could be very valuable, is scattered and not fully used. To address this, a new tool called “AI-based Research Companion (ARC)” has been developed. ARC leverages advanced Generative AI technology, including GPT-4, to systematically organize, enhance, and offer personalized recommendations for undergraduate research projects. This platform is more than a simple tool; it aims to inspire undergraduates to dive into research by making the process approachable and engaging, thus increasing participation in research activities. Initial assessments of ARC have revealed an encouraging rise in student engagement with research, indicating a shift towards more research-oriented projects. The integration of GPT-4 within ARC stands out significantly; it precisely addresses the detailed demands of undergraduate research by providing a tailored, intelligent exploration pathway. By incorporating GPT-4's advanced features with a user-centric design, ARC emerges as an innovative platform, emphasizing the pivotal role of Generative AI in enhancing and expanding undergraduate research initiatives.},
  keywords={Technological innovation;Generative AI;Information age;Research initiatives;Engineering education;Testing;AI-based Research Companion (ARC);Dynamic recommendations;Engineering education;Generative AI;GPT-4;Undergraduate research},
  doi={10.1109/EDUCON60312.2024.10578646},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10317226,
  author={Tan, Chi Wee and Lim, Khai Yin},
  booktitle={2023 Asia Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={Revolutionizing Formative Assessment in STEM Fields: Leveraging AI and NLP Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={1357-1364},
  abstract={Artificial intelligence (AI) has been extensively studied in science, technology, engineering, and mathematics (STEM), but there is a disparity between AI-generated and human-written scientific content. To bridge this gap, a prototype utilizing Natural Language Processing (NLP) techniques and a large language model (LLM) generates assessment questions and evaluates student answers. This formative assessment system offers a user-friendly and scalable solution for higher education educators. It tailors’ assessments to individual students, accommodates varying capabilities, and facilitates performance analysis. Through rigorous evaluation and benchmarking, the prototype ensures alignment with High-Level Performance (HLP) standards. This AI-assisted formative assessment system enhances efficiency and efficacy by providing accurate and timely feedback. It has the potential to significantly improve STEM education through scalable and personalized formative assessment experiences. AI and NLP enable educators to access tailored assessment options, enhancing learning outcomes and the overall educational experience.},
  keywords={Training;Scalability;Education;Prototypes;Optimized production technology;Natural language processing;Time factors},
  doi={10.1109/APSIPAASC58517.2023.10317226},
  ISSN={2640-0103},
  month={Oct},}@INPROCEEDINGS{10487465,
  author={Taylor, Zachary and Blair, Cy and Glenn, Ethan and Devine, Thomas Ryan},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Plagiarism in Entry-Level Computer Science Courses Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1135-1139},
  abstract={Recent advances in AI-generated code could potentially be plagiarized by students in entry-level programming courses. This paper examines the use of ChatGPT for generating code to solve a programming project for an entry-level computer science course. We analyzed 59 anonymized student samples along with 75 regular generations of ChatGPT code and 75 samples of ChatGPT code prompted directly for obfuscation. Results showed that 44% of ChatGPT-generated code did not compile in three or fewer manual fixes. Additionally, plagiarism detection software was not easily able to flag AI-generated code. However, the results showed that AI -generated code was more dissimilar in comparison to student-generated code, which could potentially aid in automated detection.},
  keywords={Codes;Plagiarism;Manuals;Programming;Syntactics;Chatbots;Software;ChatGPT;AI;Plagiarism Detection},
  doi={10.1109/CSCE60160.2023.00189},
  ISSN={},
  month={July},}@INPROCEEDINGS{10125121,
  author={Qadir, Junaid},
  booktitle={2023 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engineering Education in the Era of ChatGPT: Promise and Pitfalls of Generative AI for Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Engineering education is constantly evolving to keep up with the latest technological developments and meet the changing needs of the engineering industry. One promising development in this field is the use of generative artificial intelligence technology, such as the ChatGPT conversational agent. ChatGPT has the potential to offer personalized and effective learning experiences by providing students with customized feedback and explanations, as well as creating realistic virtual simulations for hands-on learning. However, it is important to also consider the limitations of this technology. ChatGPT and other generative AI systems are only as good as their training data and may perpetuate biases or even generate and spread misinformation. Additionally, the use of generative AI in education raises ethical concerns such as the potential for unethical or dishonest use by students and the potential unemployment of humans who are made redundant by technology. While the current state of generative AI technology represented by ChatGPT is impressive but flawed, it is only a preview of what is to come. It is important for engineering educators to understand the implications of this technology and study how to adapt the engineering education ecosystem to ensure that the next generation of engineers can take advantage of the benefits offered by generative AI while minimizing any negative consequences.},
  keywords={Training;Productivity;Biological system modeling;Training data;Chatbots;Artificial intelligence;Engineering education;Generative AI;ChatGPT;Engineering Education},
  doi={10.1109/EDUCON54358.2023.10125121},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11016616,
  author={Elhayany, Mohamed and Meinel, Christoph},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Empowering Educators: Towards a GPT-Based Approach to Automate Unit Test Generation}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Assessing code automatically is a significant challenge in distance learning, especially in large online courses with limited teaching resources. Although auto-gradable programming exercises address scalability, creating enough high-quality exer-cises-particularly designing comprehensive unit tests-remains time-consuming and labor-intensive. To address this, we introduce a GPT-based feature that automates unit test generation for customized exercises. With a single button press, instructors can adapt existing exercises to meet specific teaching objectives while preserving auto-gradability. The AI-generated tests comprehensively cover potential edge cases that might otherwise be overlooked, thus reducing the need for manual oversight. An empirical evaluation with eight experienced educators showed these tests to be both thorough and time-efficient, achieving an average System Usability Scale (SUS) score of 81.79. Participants, who reported intermediate to advanced proficiency in designing manual unit tests and intermediate familiarity with AI tools like ChatGPT, praised the feature's ease of use and seamless workflow integration. Their combined expertise in teaching, coding, and AI-informed course development allowed them to provide insightful feedback on the practicality and reliability of our GPT-based solution. Our study includes a small participant pool ($\mathrm{n}=8$) and primarily focuses on Python, a language wellsupported by GPT. Future research will involve expanding the participant group, exploring additional programming languages, and assessing long-term tool performance and adaptability in diverse educational contexts. By harnessing GPT's language modeling capabilities, our approach addresses the gap between generic, limited-coverage test generation and the need for robust, domain-specific tests. Early reports from participants suggest that specialized exercises-such as those involving advanced data structures-can also benefit from automated unit test generation, though further evaluation is necessary. By leveraging artificial intelligence, this method streamlines exercise customization and enhances the overall usability and effectiveness of programming education tools. It has the potential to revolutionize auto-gradable exercise creation at scale, empowering educators to deliver high-quality instruction while tackling both the technical and pedagogical challenges in programming education.},
  keywords={Technological innovation;Codes;Education;User centered design;Manuals;Test pattern generators;Artificial intelligence;Usability;Programming profession;Testing;Unit testing;Programming Education;GPT-4omini;System Usability},
  doi={10.1109/EDUCON62633.2025.11016616},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10810629,
  author={Niranon, Panuwat and Triyason, Tuul},
  booktitle={2024 8th International Conference on Information Technology (InCIT)}, 
  title={The Efficiency of ChatGPT Vs Google Against Self-Learning of Undergraduate Students}, 
  year={2024},
  volume={},
  number={},
  pages={382-386},
  abstract={ChatGPT has sparked excitement across various domains, especially in education. It has been applied in various contexts such as homework assignments and essay writing, igniting both excitement and curiosity, particularly regarding ChatGPT's effectiveness in self-learning methods. This study aims to compare the effectiveness of ChatGPT and Google Search in self-learning among undergraduate students. The sample groups consisted of 20 English language students and 20 physical education students, totaling 40 participants selected through Purposive Sampling and Randomized Controlled Trial (RCT). They were divided into two groups: Group A using ChatGPT and Group B using Google Search for self-learning on predetermined topics. The research instrument is a skill training sets for using ChatGPT and Google Search for self-learning on ethics and laws related to information use. The study found that overall, ChatGPT had an average score higher than the sample group using Google Search.},
  keywords={Training;Ethics;Electronic learning;Reviews;Instruments;Games;Chatbots;Internet;Grammar;Information technology;ChatGPT;Self-learning;Undergraduate students},
  doi={10.1109/InCIT63192.2024.10810629},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10811263,
  author={Andročec, Darko},
  booktitle={2024 5th International Conference on Communications, Information, Electronic and Energy Systems (CIEES)}, 
  title={Using Large Language Models for Students’ Essays Plagiarism Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Large language models are used and fine-tuned today for different tasks. In educational environment, one problematic usage of this technology is for creation of plagiarism work. The focus of this work is to use large language models to detect plagiarised student essays. The recent relevant Kaggle competition "Detect AI Generated Text" is analysed. The top most accurate solutions in this competition used the ensembles of various large language models. In the efficiency track of the competition, winning solutions used more classical machine learning methods. We also analyse the main datasets used to finetune the LLM and machine learning models for students’ essays plagiarism detection. The most accurate models use comprehensive set of essay data and ensemble of different large language models.},
  keywords={Accuracy;Codes;Plagiarism;Large language models;Computational modeling;Machine learning;Data models;Hardware;Servers;Interoperability;plagiarism detection;large language models;machine learning;AI-generated text},
  doi={10.1109/CIEES62939.2024.10811263},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10672225,
  author={Yuan, Yuan and Xu, Haoyang and Si, Liming},
  booktitle={2024 International Conference on Microwave and Millimeter Wave Technology (ICMMT)}, 
  title={ChatGPT as an Artificial Intelligence (AI) Tool for Assisting Undergraduate Talent Cultivation Program in Major of Microelectronic Science and Engineering}, 
  year={2024},
  volume={1},
  number={},
  pages={1-3},
  abstract={As one of the important higher education universities in China, Beijing Institute of Technology (BIT) takes a significant responsibility in cultivating students in the field of integrated circuits. This paper takes the School of Integrated Circuits and Electronics at BIT as an example to delve into the application of the artificial intelligence (AI) tool ChatGPT in undergraduate talent cultivation programs in Microelectronic Science and Engineering. ChatGPT should provide many advantages, including personalized learning assistance, problem-solving guidance, and extensive knowledge resources. By using the capabilities of ChatGPT, teachers and educators can improve student engagement, promote understanding of complex concepts, and help students for career planning in the major of microelectronics. The results indicate that integrating ChatGPT into undergraduate cultivation programs offers valuable insights into the future of engineering education.},
  keywords={Pediatrics;Microwave integrated circuits;Plagiarism;Millimeter wave technology;Chatbots;Microelectronics;Planning},
  doi={10.1109/ICMMT61774.2024.10672225},
  ISSN={2994-3124},
  month={May},}@INPROCEEDINGS{10852455,
  author={Michelutti, Chiara and Eckert, Jens and Monecke, Milko and Klein, Julian and Glesner, Sabine},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={A Systematic Study on the Potentials and Limitations of LLM-assisted Software Development}, 
  year={2024},
  volume={},
  number={},
  pages={330-338},
  abstract={In the field of software engineering, Large Language Models like GPT have gained enormous interest in recent times. With its expanding area of application, ChatGPT has become an essential tool for code generation. Several studies have shown that the quality of generated code depends on the underlying dataset and the quality of the provided prompts. However, its precise capabilities and limitations remain uncertain, as does the extent of assistance required for effective code generation. We present the results of our systematic study in which we investigate the potential of ChatGPT, based on GPT-4, in solving assignments of an introductory-level programming class. We examine the impact of programming language choice, different prompting strategies, and the results of the model compared to those of real students. Our results show that ChatGPT cannot solve the assignments independently, but outperforms the average student with human assistance.},
  keywords={Computer languages;Java;Sequential analysis;Codes;Systematics;Large language models;Chatbots;Testing;Software engineering;Software development management;Large Language Models;Software Development;ChatGPT;Code Generation;Haskell;Java;Functional Programming;Object Oriented Programming;Prompt Engineering},
  doi={10.1109/FLLM63129.2024.10852455},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10469472,
  author={R, Prasanna Kumar and M, Rithani and G, Bharathi Mohan and R, Venkatakrishnan},
  booktitle={2024 Fourth International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT)}, 
  title={Empirical Evaluation of Large Language Models in Resume Classification}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The study’s primary objective is to investigate the effectiveness of Large Language Models (LLMs) in the specialized field of resume classification, a critical aspect of talent acquisition and human resource management. The research aims to overcome the limitations of conventional approaches that often rely on basic Natural Language Processing (NLP) techniques by introducing a more efficient alternative through the utilization of LLMs. In pursuit of this goal, a comprehensive empirical assessment was undertaken, encompassing multiple LLMs, including various iterations of Text Davinci and GPT models. The research methodology employed was rigorous, incorporating data preprocessing and text normalization techniques to ensure the robustness and credibility of the results. The study’s outcomes include a comparative analysis of the chosen LLMs, with a focus on essential performance metrics such as accuracy, precision, recall, and the F1-Score. The results obtained from this analysis demonstrate a significant enhancement in the performance of LLMs compared to traditional methods in the context of resume classification. In conclusion, this research provides invaluable insights into the applicability and effectiveness of LLMs within the realm of resume classification. It not only addresses existing limitations but also serves as a foundational work that paves the way for future research in this domain. Moreover, it underscores the transformative potential of LLMs in reshaping the landscape of talent acquisition and human resource management processes.},
  keywords={Measurement;Knowledge engineering;Electric potential;Computational modeling;Data preprocessing;Natural language processing;Robustness;Large Language Models;Resume Classification;Talent Acquisition;Text Davinci;GPT Models},
  doi={10.1109/ICAECT60202.2024.10469472},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10814750,
  author={Wightman, Pedro},
  booktitle={2024 IEEE Latin American Conference on Computational Intelligence (LA-CCI)}, 
  title={Twisted Games: A First Experience of Inclusion of AI tools in First Year Programming Classes}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The recent rapid advancements in Large Language Models (LLMs) and the increasing availability of AI-powered tools have underscored the need for the current generation of programmers to learn how to effectively collaborate with AI from the early stages of their university education. This paper explores the integration of AI tools into a first-year programming course through the implementation of modified classic games (4 in a row with L-shapes, 3-player Battleship, etc.). The primary objective of this study was to assess the impact of AI assistance on students’ ability to define and adapt requirements for novel software applications, while also fostering an understanding of the power and limitations of AI in the classroom. The results reveal a positive student experience, with participants reporting increased confidence in utilizing AI tools for requirements elicitation and recognizing the potential benefits for their future careers. In addition, it highlighted the need to train students in developing skills for requirement identification, prompt creation, and testing and debugging the code.},
  keywords={Codes;Education;Layout;Debugging;Games;Encoding;Software;Artificial intelligence;Programming profession;Testing;Artificial intelligence;Large Language Models;Software development;Game development},
  doi={10.1109/LA-CCI62337.2024.10814750},
  ISSN={2769-7622},
  month={Nov},}@INPROCEEDINGS{11016469,
  author={Haider, Sami Ahmed and Ahmad, Khwaja Mutahir and Akbar, Jehan and Soni, Mukesh and Keshta, Ismail and AlGhamdi, Azzah and Shahzadi, Hafiza Mahrukh},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI as a Catalyst for Transforming Transnational Engineering Education: Opportunities, Challenges, and Future Directions}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative Artificial Intelligence (GAI) is emerging as a transformative force that empowers transnational education (TNE) in engineering. Recent trends indicate a significant shift in the application of generative AI in engineering policies, academic research, business practices, and educational settings throughout TNE. Governments and organizations are transitioning from restrictive stances to developing guiding frameworks for its application, enabling cross-border collaboration in TNE. Numerous universities have permitted and even promoted the utilization of GAI. Furthermore, academic research around the world is looking into the pros and cons of GAI in engineering education, focusing on how it can help teachers and keep students interested. Industrial applications are diversifying, extending across disciplines, and TNE is occurring in engineering contexts, including cross-border programs. GAI possesses the capacity to transform TNE by revolutionizing talent development, reformulating engineering models, and facilitating scientific assessment across multinational frameworks. However, problems like the generative illusion, ethical and ideological risks, lack of trust between teachers and students, and new threats to TNE in engineering equity in global settings require substantial focus. This study examines these concerns and outlines potential strategies to leverage GAI for transnational education in engineering, offering stakeholders the opportunity to prioritize AI literacy among educators and learners. This work emphasizes that cross-disciplinary and collaborative R&D, following national and international standards, should tackle application hurdles while guaranteeing safety and inclusion. This study also addresses several future directions that can contribute to creating a unified framework and cost-effective solutions. These solutions, integrated with platforms like the National Smart Education Platform, can bridge digital divides, ensuring equitable access and enabling global TNE stakeholders to capitalize on the GAI revolution. We also provide several statistics and case studies to show the effectiveness of GAI over TNE in engineering and provide practical solutions for the incorporation of GAI into TNE within engineering frameworks, guaranteeing inclusivity and equity.},
  keywords={Ethics;Generative AI;Catalysts;Collaboration;Transforms;Market research;Safety;Stakeholders;Engineering education;Research and development;Transnational Education;Generative AI;ChatGPT;Technological Factors;Intelligent Computing;Artificial Intelligence},
  doi={10.1109/EDUCON62633.2025.11016469},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10765410,
  author={Gao, Hong and Huai, Haochuan and Yildiz-Degirmenci, Sena and Bannert, Maria and Kasneci, Enkelejda},
  booktitle={2024 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
  title={DataliVR: Transformation of Data Literacy Education through Virtual Reality with ChatGPT-Powered Enhancements}, 
  year={2024},
  volume={},
  number={},
  pages={120-129},
  abstract={Data literacy is essential in today’s data-driven world, emphasizing individuals’ abilities to effectively manage data and extract meaningful insights. However, traditional classroom-based educational approaches often struggle to fully address the multifaceted nature of data literacy. As education undergoes digital transformation, innovative technologies such as Virtual Reality (VR) offer promising avenues for immersive and engaging learning experiences. This paper introduces DataliVR, a pioneering VR application aimed at enhancing the data literacy skills of university students within a contextual and gamified virtual learning environment. By integrating Large Language Models (LLMs) like ChatGPT as a conversational artificial intelligence (AI) chatbot embodied within a virtual avatar, DataliVR provides personalized learning assistance, enriching user learning experiences. Our study employed an experimental approach, with chatbot availability as the independent variable, analyzing learning experiences and outcomes as dependent variables with a sample of thirty participants. Our approach underscores the effectiveness and user-friendliness of ChatGPT-powered DataliVR in fostering data literacy skills. Moreover, our study examines the impact of the ChatGPT-based AI chatbot on users’ learning, revealing significant effects on both learning experiences and outcomes. Our study presents a robust tool for fostering data literacy skills, contributing significantly to the digital advancement of data literacy education through cutting-edge VR and AI technologies. Moreover, our research provides valuable insights and implications for future research endeavors aiming to integrate LLMs (e.g., ChatGPT) into educational VR platforms.},
  keywords={Electronic learning;Digital transformation;Large language models;Education;Data visualization;Learning (artificial intelligence);Data collection;Chatbots;User experience;Data mining;Virtual reality;data literacy;LLMs;ChatGPT;digital transformation;immersive learning},
  doi={10.1109/ISMAR62088.2024.00026},
  ISSN={2473-0726},
  month={Oct},}@INPROCEEDINGS{10578883,
  author={Pérez-Colado, Iván J. and Freire-Morán, Manuel and Calvo-Morata, Antonio and Pérez-Colado, Víctor M. and Fernández-Manjón, Baltasar},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI Asyet Another Tool in Undergraduate Student Projects: Preliminary Results}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={How do students use artificial intelligence tools in coursework projects when given the liberty to do so, with the only requirement of documenting how, where and why? We describe experiences with two groups of undergraduates in courses related to serious game authoring and human-computer interaction, both carried out in the second semester of 2023. In the serious games course, students were given the option of following a teacher-developed methodology for generating graphical assets for their serious games using a set of generative AI tools. This methodology was explained in the class but not hands on lab was carried out. In the interaction course, students were free to choose which AI tools to use when designing their system or in the development of their project documentation. Despite the limited number of participants (41 in total) we can see very different views and degrees of involvement: while some tried to use AI for as many tasks as possible, others considered that the learning curve for those tools was too steep to be worthwhile. Both experiences included a free-text survey at the end, and taken together, provide insights into how both supervised and unsupervised generative AI use could impact undergraduate projects in similar subjects. In addition to describing how students chose to use the tools, and the main takeaways from their survey response, we also discuss some of the ethical aspects about the access to the tools and what should be the minimal conditions to be met to allow the equitable use of AI in the classroom.},
  keywords={Surveys;Human computer interaction;Generative AI;Games;Documentation;Task analysis;Engineering education;AI in education;generative artificial intelligence;game development;serious games authoring;goal-driven design},
  doi={10.1109/EDUCON60312.2024.10578883},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11016382,
  author={Chen, Yue and Chai, Kok Keong and Loo, Jonathan and Moosaei, Reza and Obstfeld, Joel},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={GenAI-Empowered Group-Based Authentic Assessment for Network Engineering Courses}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The emergence of generative artificial intelligence (GenAI) has brought both challenges and opportunities for education. In this paper, we propose a GenAI-empowered, group-based authentic assessment for a Network Engineering course. This group assignment promotes challenge-based learning (CBL) and leverages GenAI to enhance students' creativity, critical thinking, collaboration, and technical problem-solving skills, while also improving students' GenAI literacy through fostering their ability to effectively engage with GenAI tools. The authenticity of this assignment is reflected in two folds: 1) students engage in a real-world engineering challenge, roleplaying as network engineers, and 2) they develop essential skills for co-creating solutions using GenAI tools, a key competency for future engineers. The group assignment is structured into five stages, each aligned with Bloom's Taxonomy to progressively develop cognitive skills from understanding foundational knowledge to synthesis, evaluation, and creation. To mitigate challenges such as overreliance on GenAI tools and varying levels of digital literacy, we provide guidance on the responsible and ethical use of GenAI, design reflective assessment tasks with constructive feedback, and establish clear marking criteria that emphasise both the learning process and the final outputs of the assignment. Initial evaluation and feedback from trials have highlighted the effectiveness of using GenAI tools in addressing complex engineering challenges and the value of collaborating in a real-world engineering context. This innovative approach demonstrates the potential of GenAIempowered authentic assessments to enhance learning experiences in technical fields like Network Engineering.},
  keywords={Ethics;Generative AI;Taxonomy;Documentation;Data collection;Teamwork;Problem-solving;Digital intelligence;Engineering education;Creativity;GenAI;Authentic Assessment;ChallengedBased Learning;Group-Based Learning;Network Engineering},
  doi={10.1109/EDUCON62633.2025.11016382},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016572,
  author={Lindsay, Euan D and Zhang, Mike and Johri, Aditya and Bjerva, Johannes},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Responsible Development of Automated Student Feedback with Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Providing rich, constructive feedback to students is essential for supporting and enhancing their learning. Recent advancements in Generative Artificial Intelligence (AI), particularly with large language models (LLMs), present new opportunities to deliver scalable, repeatable, and instant feedback, effectively making abundant a resource that has historically been scarce and costly. From a technical perspective, this approach is now feasible due to breakthroughs in AI and Natural Language Processing (NLP). While the potential educational benefits are compelling, implementing these technologies also introduces a host of ethical considerations that must be thoughtfully addressed. One of the core advantages of AI systems is their ability to automate routine and mundane tasks, potentially freeing up human educators for more nuanced work. However, the ease of automation risks a “tyranny of the majority”, where the diverse needs of minority or unique learners are overlooked, as they may be harder to systematize and less straightforward to accommodate. Ensuring inclusivity and equity in AI-generated feedback, therefore, becomes a critical aspect of responsible AI implementation in education. The process of developing machine learning models that produce valuable, personalized, and authentic feedback also requires significant input from human domain experts. Decisions around whose expertise is incorporated, how it is captured, and when it is applied have profound implications for the relevance and quality of the resulting feedback. Additionally, the maintenance and continuous refinement of these models are necessary to adapt feedback to evolving contextual, theoretical, and student-related factors. Without ongoing adaptation, feedback risks becoming obsolete or mismatched with the current needs of diverse student populations. Addressing these challenges is essential not only for ethical integrity but also for building the operational trust needed to integrate AI-driven systems as valuable tools in contemporary education. Thoughtful planning and deliberate choices are needed to ensure that these solutions truly benefit all students, allowing AI to support an inclusive and dynamic learning environment.},
  keywords={Ethics;Automation;Generative AI;Navigation;Machine learning;Turning;Planning;Maintenance;Artificial intelligence;Lenses;Educational Technology;Artificial Intelligence;Ethics;Natural Language Processing;Human-Computer Interaction;Generative AI},
  doi={10.1109/EDUCON62633.2025.11016572},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10665196,
  author={Kumar, Yulia and Manikandan, Anjana and Kupershtein, Ethan and Li, J. Jenny and Morreale, Patricia},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Assessing the Impact of Professional Development on K-12 CS Education: A One-Year Follow-Up Survey Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The paper presents the findings from a one-year follow-up survey analyzing the impact of a targeted professional development (PD) program conducted by a state Computer Science (CS) hub on K-12 CS education. It scrutinizes the long-term effects of the PD initiative on educators' pedagogical strategies and students' readiness for college-level CS coursework. The study focuses on integrating the introductory course CS0, which shapes educational strategies and outcomes. Through the lens of three research questions, the analysis delves into the enhancements in educators' instructional approaches following PD, the ongoing influence of PD on the integration of interdisciplinary methods within CS curricula, and the correlation between PD and student engagement and achievement in CS disciplines. The survey of thirty educators reveals a sustained implementation of acquired pedagogical practices and a positive influence on student college readiness in CS. Moreover, the study underscores the pivotal role of PD in elevating educators’ proficiency in delivering advanced CS concepts, ultimately benefiting student learning trajectories. The concluding remarks advocate including Large Language Models (LLMs) as a supplementary tool to enrich the CS educational paradigm. The recommendations provided serve as a strategic roadmap for stakeholders aiming to elevate the standard of CS education through PD and curricular development.},
  keywords={Surveys;Computer science;Shape;Large language models;Education;Trajectory;Stakeholders;computer science education;curriculum development;educator professional development;pedagogical strategies},
  doi={10.1109/ISEC61299.2024.10665196},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10834357,
  author={Tang, Shan and Lei, Chi-Un and Wang, Hongren},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Revealing Vocational Training on Achieving UN’s Sustainable Development Goals: Analysis Through Machine Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Vocational training plays a crucial role in supporting the achievement of the United Nations Sustainable Development Goals (SDGs), outlined explicitly in SDG Targets 4.3, 4.4, and 4.5. However, there is a lack of comprehensive studies examining the teaching of knowledge in state-level vocational training programs to support the attainment of SDGs. The primary objective of this study is to investigate the connection between SDG education and vocational training. To achieve this, we analyzed the curricula of i) four vocational training courses and ii) three applied technological and applied studies courses adopted by the government of New South Wales in Australia. The classification was based on a public training dataset from OSDG and subject descriptions via logistic regression (LR) and a generative pre-trained transformer (GPT) model. The findings from the subject-level analysis demonstrate the effectiveness of the adopted approach. Across all curricula, SDG 9 is the most prominently incorporated SDG. However, policymakers should be aware of the limited SDG representation related to social equality in vocational training. To evaluate the classification's performance, the authors have also manually classified each module of a course. While there is substantial agreement between human reviewers, the agreement between human reviewers, LR and GPT approach is only fair, indicating less consistency in the SDG classifications between human, LR, and GPT assessments.},
  keywords={Surveys;Logistic regression;Generative Pre-trainer transformer;Writing;Vocational training;Transformers;Solids;Australia;Reliability;Sustainable development;sustainable development goals;classification;curriculum analysis;vocational training;machine learning;GPT},
  doi={10.1109/TALE62452.2024.10834357},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10487436,
  author={Deshpande, Sanjay and Szefer, Jakub},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Analyzing ChatGPT's Aptitude in an Introductory Computer Engineering Course}, 
  year={2023},
  volume={},
  number={},
  pages={1034-1038},
  abstract={ChatGPT has recently gathered attention from the general public and academia as a tool that is able to generate plausible and human-sounding text answers to various questions. While recent works have explored the use of ChatGPT in the context of humanities, business school, or medical school, this work explores how ChatGPT performs in the context of an introductory computer engineering course. This work assesses ChatGPT's aptitude in answering quizzes, homework, and laboratory questions in an introductory-level computer engineering course. This work finds that ChatGPT can do well on questions asking about generic concepts. However, predictably, as a text- only tool, it cannot handle questions with diagrams or figures, nor can it generate diagrams and figures. Further, also clearly, the tool cannot do hands-on lab experiments, breadboard assembly, etc., but can generate plausible answers to some laboratory manual questions. One of the key observations presented in this work is that the ChatGPT tool could not be used to pass all components of the course. Nevertheless, it does well on quizzes and short-answer questions. On the other hand, plausible, human-sounding answers could confuse students when generating incorrect but still plausible answers.},
  keywords={Humanities;Codes;Manuals;Breadboard;Chatbots;Assembly;Business;Computer Engineering;Education;ChatGPT;GPT-3;OpenAI},
  doi={10.1109/CSCE60160.2023.00172},
  ISSN={},
  month={July},}@INPROCEEDINGS{10779794,
  author={Butgereit, Laurie and Zhou, Helper},
  booktitle={2024 International Conference on Next Generation Computing Applications (NextComp)}, 
  title={Using GPT-4 to Tutor Python Programming in Shona and Ndebele in Zimbabwe}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In many post-Colonial African countries, English is the medium of instruction at schools and universities. Many, if not most of the students, however, are not home language English speakers. In the specific situation of Zimbabwe, approximately eighty percent of the population is Shona speaking and approximately ten percent of the population is Ndebele speaking. Existing research shows that when learners or students are forced to learn technical subjects (such as mathematics and computer programming) in their non-home language, they are doing double work. Not only do they need to learn the new subject domain, they also need to translate these new terms to and from their home language. This paper investigates the use of an GPT-4 based artificially intelligent tutoring bot configured to tutor the subject of Python Programming in both Shona and Ndebele. This paper is the first step of a multi-step research project which has the final goal of helping Zimbabwean learners and students learn Python Programming in their home language. This first step, however, reports on language evaluations of the GPT-4 based tutoring bot operating in Shona and Ndebele.},
  keywords={Oral communication;Africa;Programming;Chatbots;Mathematics;Next generation networking;Python;GPT-4;chatGPT;Shona;Ndebele;Python;Tutoring},
  doi={10.1109/NextComp63004.2024.10779794},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10132255,
  author={Jalil, Sajed and Rafi, Suzzana and LaToza, Thomas D. and Moran, Kevin and Lam, Wing},
  booktitle={2023 IEEE International Conference on Software Testing, Verification and Validation Workshops (ICSTW)}, 
  title={ChatGPT and Software Testing Education: Promises & Perils}, 
  year={2023},
  volume={},
  number={},
  pages={4130-4137},
  abstract={Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the ad-vent of general purpose "large language models", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAI and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users.The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.},
  keywords={Software testing;Codes;Limiting;Conferences;Natural languages;Predictive models;Chatbots;ChatGPT;testing;education;case study},
  doi={10.1109/ICSTW58534.2023.00078},
  ISSN={2159-4848},
  month={April},}@INPROCEEDINGS{10892932,
  author={Bego, Campbell R. and Crockett, Cenetria L. and Danovitch, Judith H. and Martinez, Liliana G. and Rajkumar, Alwin K. and Thomas, Elisabeth L. and Thompson, Angela K. and Tran, Alvin and Valavala, Benarji},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={First-Year Engineering Students' Expertise and Trust in GenAl}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This full-length research study investigated first-year engineering students “trust in generative artificial intelligence (GenAl) before and after course instruction. Pre-and post-surveys were conducted with questions on students” experience with GenAl tools as well as trust in GenAl. The trust questions had students evaluate the likelihood of GenAl generating a correct response to various prompts such as “explain the unit circle” (correct response likely) to “solving this system of equations …” (correct response unlikely for tools available in Fall 2023). Within-subjects analyses indicated that lessons in the course significantly increased trust in ChatGPT for correct-response-likely items. In addition, the lessons significantly decreased students “trust in ChatGPT for correct-response-unlikely items. There were no significant interactions between prior experience level and change in trust. These results show that guided exposure to GenAl helped first-year engineering students begin to understand capabilities and limitations of GenAl. These results are promising because student trust in GenAl output will directly impact decisions to engage with it for different tasks. More work is needed to optimize instruction and understand students” use of the tool beyond the classroom integration, including their full ethical decision-making process, but the malleability of trust at this level is an indication that engineering educators can impact student perspectives of GenAl.},
  keywords={Ethics;Accuracy;Generative AI;Decision making;Chatbots;Reliability engineering;Engineering students;Generative AI;engineering education;trust},
  doi={10.1109/FIE61694.2024.10892932},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10873911,
  author={Pratama, Bacharuddin Adieb and Wiharja, Kemas Rahmat Saleh and Wulandari, Gia Septiana},
  booktitle={2023 International Conference on Artificial Intelligence Robotics, Signal and Image Processing (AIRoSIP)}, 
  title={Knowledge Acquisition from Student Lecture Reflection Data: Leveraging Large Language Models and Tacit Knowledge}, 
  year={2023},
  volume={},
  number={},
  pages={388-392},
  abstract={This research paper addresses a pertinent challenge encountered by lecturers in higher education institutions efficiently managing and analyzing the substantial volume of student lecture reflection data. To overcome this issue, we propose a novel knowledge acquisition system that amalgamates the capabilities of Large Language Models (LLM) with the invaluable tacit knowledge possessed by lecturers, enabling the inference of solutions. The process involves meticulously extracting textual information from student reflections and applying a multilingual BERT model for precise categorization. The acquired knowledge is subsequently stored within a sophisticated web-based platform, yielding an impressive acquisition rate of 73.85%, with 13.07% attributed to LLM and 60.78% emanating from lecturers' tacit knowledge. This study effectively showcases the potential of synergizing cutting-edge language models with human expertise, augmenting knowledge acquisition in educational environments. Furthermore, the proposed system furnishes a comprehensive and easily accessible resource, presenting insights into frequently encountered challenges and corresponding resolutions, benefiting students and lecturers.},
  keywords={Image resolution;Knowledge acquisition;Large language models;Education;Reflection;Data models;Multilingual;Data mining;Signal resolution;Robots;knowledge acquisition;student lecture reflections;text extraction;BERT;Large Language Model},
  doi={10.1109/AIRoSIP58759.2023.10873911},
  ISSN={},
  month={Aug},}@ARTICLE{10478015,
  author={Haindl, Philipp and Weinberger, Gerald},
  journal={IEEE Access}, 
  title={Students’ Experiences of Using ChatGPT in an Undergraduate Programming Course}, 
  year={2024},
  volume={12},
  number={},
  pages={43519-43529},
  abstract={Increasing use of artificial intelligence tools in programming education calls for a deeper understanding of their effect on students’ learning. This paper presents a study that investigates the experiences of part-time undergraduate students using ChatGPT in a five-week Java programming course. After each exercise, students provided feedback via anonymous surveys in which they rated different suitability aspects of ChatGPT. The majority viewed ChatGPT positively and suitable for learning programming concepts. However, its suitability for specific implementation tasks received mixed reviews. Students found it easy to adapt ChatGPT’s generated code to the exercises’ implementation tasks. The students primarily used it for acquiring background knowledge, learning syntax and programming concepts and suggesting suitable algorithms. Yet, some abstained from using it due to concerns to not garner sufficient programming proficiency, retrieving partially incorrect or misleading generated code, preferring an independent working style, or general skepticism about its benefits. Finally, in response to our findings, we also discuss three perspective directions for improving the suitability of LLM chatbots for students in programming education.},
  keywords={Chatbots;Codes;Programming profession;Task analysis;Education;Artificial intelligence;Surveys;Programming education;ChatGPT;generative AI;large language models},
  doi={10.1109/ACCESS.2024.3380909},
  ISSN={2169-3536},
  month={},}@ARTICLE{11028593,
  author={Tatar, Moosa and Farokhi, Soheila and Foumani, Arash Azizian and Uzunlar, Emirhan and Araz, Ozgur M.},
  journal={IEEE Engineering Management Review}, 
  title={Application of Gemini in Public Health Amid the Artificial Intelligence Era}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={In December 2023, Google DeepMind unveiled its large language model, Gemini, which is shown to be capable of understanding and processing multimodal information. This article explores the applications of Gemini in public health. Unlike traditional models, Gemini integrates and analyzes information through diverse modalities (text, image, video, etc.) fostering new applications. Notably, Google Gemini is presented as the first model to surpass human experts on the Massive Multitask Language Understanding (MMLU) benchmark, which combines multiple subjects including science, technology, engineering, and mathematics (STEM), humanities, and others to test the knowledge and problem-solving abilities of artificial intelligence (AI) models. While Gemini's capabilities are claimed to surpass established models such as ChatGPT, offering improved accuracy, efficiency, and interdisciplinary research integration, its utilization in research is still limited. A wide range of applications, including healthcare communication and delivery, medical diagnosis and decision-making, early disease diagnosis, public health surveillance, interventions, and education, drug research, and adverse effects prevention can benefit from Gemini's features. By extracting insights from sizable datasets and comprehending complex medical information, Gemini enables researchers and practitioners. However, responsible use with expert oversight is crucial. Overall, Gemini's capabilities offer new opportunities for improving public health research, practice, and ultimately, population health outcomes.},
  keywords={Public healthcare;Artificial intelligence;Medical diagnostic imaging;Chatbots;Accuracy;Internet;Data mining;Training;Medical services;Medical diagnosis;Artificial Intelligence for Technology Management;Human Information and Knowledge Processing;Public Health;Gemini;Multimodal AI},
  doi={10.1109/EMR.2025.3577913},
  ISSN={1937-4178},
  month={},}@INPROCEEDINGS{10343337,
  author={Ilic, Peter and Carr, Nicholas},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work in Progress: Safeguarding Authenticity: Strategies for Combating AI-Generated Plagiarism in Academia}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress (WiP) research explores the role of rubrics in mitigating the negative impact of generative AI, such as ChatGPT, on writing assessment practices in STEM. This approach addresses the growing need for innovative methods of ensuring student academic integrity and authenticity in the rapidly expanding ecosystem of AI tools. A rubric consisting of five criteria is employed to rate the students' deconstruction of written text into language frames for the purpose of differentiating between human-written and AI-generated content. The language frames are common English language sentence patterns used for expressing five academic written functions: compare/contrast, cause/effect, classification, chronological order, and spatial order. By evaluating the performance of student deconstruction of one paragraph written by the student and a second paragraph produced by ChatGPT, it is anticipated that the rubric will enable the instructor to differentiate between the two by capturing any gaps in knowledge required to identify, deconstruct, and reproduce previously learned sentence frames. This assumes that the student will be more familiar with a self-written text than an unfamiliar AI produced one. This difference may then be employed by educators to aid in the identification of AI-generated plagiarism submitted by students. The key insights from this pilot study include: The need for a rubric threshold level of between 70% and 80% to differentiate between human and AI texts. Students appear to score higher at the identification of language frames than the production of the same frames. They were equal or better at identifying sentence frames from the AI generated text. Also, students scored very low on critical thinking questions that required the selection of alternative sentence frames. This WiP paper details the rubric design, research methodology, and preliminary insights from a small pilot study, which informs the evolution towards a larger future implementation.},
  keywords={Plagiarism;Design methodology;Ecosystems;Production;Writing;Chatbots;Artificial intelligence;AI;Assessment;Rubric;Writing;Cheating;Plagiarism;ChatGPT;EFL;STEM},
  doi={10.1109/FIE58773.2023.10343337},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10628428,
  author={Jahić, Jasmin and Sami, Ashkan},
  booktitle={2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C)}, 
  title={State of Practice: LLMs in Software Engineering and Software Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={311-318},
  abstract={Large Language Models (LLMs) are finding their way into Software Engineering by assisting with tasks such as code generation. Furthermore, LLMs might have a potential to perform even more complex tasks, such as suggesting architectural design. However, there is a lack of empirical surveys on how software engineering companies use (and plan to use) LLMs and if LLMs truly can provide benefits to software architects. To understand the state of practice considering adoption of LLMs in software engineering, existing challenges, and future trends, we have surveyed 15 different software engineering companies. To understand the ability of LLMs to perform more complex tasks, we report on our experiments with LLM-assisted architectural design. We applied ChatGPT on 5 software projects and in total performed 50 different experiments. Our results capture the state of the practice of LLMs in software engineering and demonstrate how LLMs perform when assisting with (more complex task such as) architectural design. Engineers, architects, and project managers should profit from these results to guide their decision towards targeted adoption of LLMs in their business and engineering domains.},
  keywords={Surveys;Codes;Software architecture;Large language models;Companies;Market research;Chatbots;Architecture;AI;Design Space Exploration;ChatGPT},
  doi={10.1109/ICSA-C63560.2024.00059},
  ISSN={2768-4288},
  month={June},}@INPROCEEDINGS{10825051,
  author={Tihanyi, Norbert and Bisztray, Tamas and Dubniczky, Richard A. and Toth, Rebeka and Borsos, Bertalan and Cherif, Bilel and Jain, Ridhi and Muzsai, Lajos and Ferrag, Mohamed Amine and Marinelli, Ryan and Cordeiro, Lucas C. and Debbah, Merouane and Mavroeidis, Vasileios and Jøsang, Audun},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Dynamic Intelligence Assessment: Benchmarking LLMs on the Road to AGI with a Focus on Model Confidence}, 
  year={2024},
  volume={},
  number={},
  pages={3313-3321},
  abstract={As machine intelligence evolves, the need to test and compare the problem-solving abilities of different AI models grows. However, current benchmarks are often simplistic, allowing models to perform uniformly well and making it difficult to distinguish their capabilities. Additionally, benchmarks typically rely on static question-answer pairs that the models might memorize or guess. To address these limitations, we introduce Dynamic Intelligence Assessment (DIA), a novel methodology for testing AI models using dynamic question templates and improved metrics across multiple disciplines such as mathematics, cryptography, cybersecurity, and computer science. The accompanying dataset, DIA-Bench, contains a diverse collection of challenge templates with mutable parameters presented in various formats, including text, PDFs, compiled binaries, visual puzzles, and CTF-style cybersecurity challenges. Our framework introduces four new metrics to assess a model’s reliability and confidence across multiple attempts. These metrics revealed that even simple questions are frequently answered incorrectly when posed in varying forms, highlighting significant gaps in models’ reliability. Notably, API models like GPT-4o often overestimated their mathematical capabilities, while ChatGPT-4o demonstrated better performance due to effective tool usage. In self-assessment OpenAI’s o1-mini proved to have the best judgement on what tasks it should attempt to solve. We evaluated 25 state-of-the-art LLMs using DIA-Bench, showing that current models struggle with complex tasks and often display unexpectedly low confidence, even with simpler questions. The DIA framework sets a new standard for assessing not only problem-solving, but also a model’s adaptive intelligence and ability to assess its limitations. The dataset is publicly available on the project’s page: https://github.com/DIA-Bench.},
  keywords={Measurement;Adaptation models;Computational modeling;Benchmark testing;Reliability engineering;Mathematical models;Data models;Reliability;Problem-solving;Computer security;Artificial Intelligence;Large Language Models;Dynamic Benchmarking;Performance Metrics;Reliability},
  doi={10.1109/BigData62323.2024.10825051},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10662994,
  author={Brockenbrough, Allan and Salinas, Dominic},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Using Generative AI to Create User Stories in the Software Engineering Classroom}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={A user story is used in agile methodology to describe functionality that is valuable to the user and may include criteria to determine if the developer has completed the story. This study investigates undergraduate computer science students using ChatGPT to create user stories from user feedback. The study compares aspects of the user stories created by students using ChatGPT with those not using ChatGPT. Are user stories written by students with AI assistance of higher or lower quality? How does the time spent writing the user story change with the use of ChatGPT? We evaluate student user stories using a modified INVEST story rating system. Evaluated user story properties include structure, independence, value, testability, and grammar. The results show that ChatGPT-assisted students produce higher-quality user stories than unassisted students. However, using ChatGPT to write user stories does not guarantee high quality. ChatGPT can fail to recognize dependencies between user feedback and create structurally incorrect user stories. We see a need for students to be trained in effectively using this tool by carefully examining AI-assisted output and making revisions.},
  keywords={Computer science;Generative AI;Chatbots;Grammar;Software engineering;user stories;ChatGPT;GPT-Generative AI;INVEST;software engineering education;LLM},
  doi={10.1109/CSEET62301.2024.10662994},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10465435,
  author={Butgereit, Laurie and Egu, Asaminew Gizaw},
  booktitle={2023 First International Conference on the Advancements of Artificial Intelligence in African Context (AAIAC)}, 
  title={Using GPT-4 to Tutor Java Programming in Amharic}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Education is associated with economic development. Higher levels of education creates better likelihoods of employment. Technical education is growing even more important in the modern world. In Africa and other developing areas, there are many barriers to education. One such barrier is non-home language education. When students are forced to learn technical subjects in a second language, then they are doing double work. Not only are they learning a new technical subject; they are also translating all the new terms and concepts in and out of their home language. This paper specifically looks at using an artificial intelligence to help tutor the technical subject of Java Programming in the Amharic language. A Java tutoring system was developed which used GPT-4 as its artificial intelligence. The system was configured (or prompted) to act as a tutor in the Java programming language and to assist students using the Amharic language. The results of this research showed that although GPT-4 did make some language errors in Amharic, the language evaluation showed that at university level, students could easily recognize the language errors and still benefit from the Amharic Java Programming tutor.},
  keywords={Economics;Java;Computer languages;Education;Employment;Africa;Chatbots;Java;GPT-4;Tutoring;Amharic},
  doi={10.1109/AAIAC60008.2023.10465435},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10494274,
  author={Wu, Wennan and Liu, Ruisi and Chu, Junjie},
  booktitle={2023 16th International Symposium on Computational Intelligence and Design (ISCID)}, 
  title={How important is Trust: Exploring the Factors Influencing College Students' Use of Chat GPT as a Learning Aid}, 
  year={2023},
  volume={},
  number={},
  pages={67-70},
  abstract={With the rapid development of artificial intelligence technology, its functions have become increasingly powerful. Large Language Models such as ChatGPT have solved various tasks such as text creation and code debugging, and the impact in the field of education has caused close attention from many scholars. Therefore, by establishing an extended TAM, we conducted a questionnaire survey on 470 college students to explore their acceptance of using ChatGPT as an auxiliary learning tool. Structural equation modeling (SEM) was used to analyze the data. The results showed that trust, facilitating conditions, perceived usefulness, and perceived ease of use have a positive impact on college students' use intention of ChatGPT. Hence, by improving the credibility of generated content and providing appropriate auxiliary resources will help promote students' acceptance of ChatGPT. The research results provide suggestions and directions for future design.},
  keywords={Surveys;Technology acceptance model;Numerical analysis;Computational modeling;Education;Debugging;Chatbots;technology acceptance model (TAM);structural equation modeling (SEM);ChatGPT},
  doi={10.1109/ISCID59865.2023.00024},
  ISSN={2473-3547},
  month={Dec},}@ARTICLE{10478897,
  author={Rodriguez-Echeverría, Roberto and Gutiérrez, Juan D. and Conejero, José M. and Prieto, Álvaro E.},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Analysis of ChatGPT Performance in Computer Engineering Exams}, 
  year={2024},
  volume={19},
  number={},
  pages={71-80},
  abstract={The appearance of ChatGPT at the end of 2022 was a milestone in the field of Generative Artificial Intelligence. However, it also caused a shock in the academic world. For the first time, a simple interface allowed anyone to access a large language model and use it to generate text. These capabilities have a relevant impact on teaching-learning methodologies and assessment methods. This work aims to obtain an objective measure of ChatGPT’s possible performance in solving exams related to computer engineering. For this purpose, it has been tested with actual exams of 15 subjects of the Software Engineering branch of a Spanish university. All the questions of these exams have been extracted and adapted to a text format to obtain an answer. Furthermore, the exams have been rewritten to be corrected by the teaching staff. In light of the results, ChatGPT can achieve relevant performance in these exams; it can pass many questions and problems of different natures in multiple subjects. A detailed study of the results by typology of questions and problems is provided as a fundamental contribution, allowing recommendations to be considered in the design of assessment methods. In addition, an analysis of the impact of the non-deterministic aspect of ChatGPT on the answers to test questions is presented, and the need to use a strategy to reduce this effect for performance analysis is concluded.},
  keywords={Chatbots;Education;Artificial intelligence;Guidelines;Oral communication;Computational modeling;Generative AI;Computer science education;Testing;Performance evaluation;Learning systems;Artificial intelligence;ChatGPT;education;experiment},
  doi={10.1109/RITA.2024.3381842},
  ISSN={1932-8540},
  month={},}@INPROCEEDINGS{10569779,
  author={Santos, Patricia and Urgel, Keysha and Moreno, Verónica},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Generative Artificial Intelligence in Teaching and Learning of ICT Engineering Education: A Literature Review and Illustrative Scenarios}, 
  year={2024},
  volume={},
  number={},
  pages={1338-1343},
  abstract={This paper presents a comprehensive literature review on the integration of Generative Artificial Intelligence (Gen AI) in the teaching and learning processes within Information and Communication Technologies (ICT) engineering education. The study delves into the potential of Gen AI technologies to enhance educational practices in engineering contexts. Through synthesizing existing literature, this review analyzes the impact of Gen AI on pedagogical strategies, curriculum development, and student engagement in the realm of ICT engineering education. The paper presents authentic teaching cases, including applications and experiments with students, from various studies conducted at higher education institutions worldwide. The illustrative scenarios primarily focus on showcasing the practical applications of Gen AI in two key areas: programming skills and ethics within ICT engineering education. The exploration of these cases provides valuable insights and discussion into the effective implementation of Gen AI in higher education, recognizing the importance of integrating the learning of these technologies into the curriculum. This research provides a valuable resource for ICT engineering educators, researchers, and policymakers aiming to harness AI technologies for transformative progress in engineering education.},
  keywords={Generative AI;Reviews;Bibliographies;Soft sensors;Training data;Learning (artificial intelligence);Information and communication technology;Generative Artificial Intelligence;Engineering education;programming;tools;ethics},
  doi={10.1109/MIPRO60963.2024.10569779},
  ISSN={2623-8764},
  month={May},}@ARTICLE{11006075,
  author={Oprea, Simona-Vasilica and Bâra, Adela},
  journal={IEEE Access}, 
  title={Transforming Education With Large Language Models: Trends, Themes, and Untapped Potential}, 
  year={2025},
  volume={13},
  number={},
  pages={87292-87312},
  abstract={Our research focuses on the transformative intersection of Large Language Models (LLMs) and education in the last six years (2019–2024), examining their potential to modernize educational systems and enhance learning outcomes. Leveraging a comprehensive methodological framework, we analyzed 9,598 publications from Web of Science (WoS), extracting 25,381 education-related terms and mapping academic trends across diverse research areas. Educational research involving LLMs focuses heavily on learning, research and training, with terms such as “education” (1546), “learning” (4828), “research” (4438) and “training” (327) frequently appearing in the analyzed dataset. Specific applications such as grading (121) and tutoring (82) are less emphasized, presenting potential areas for further exploration. Key elements include annual publication patterns, institutional collaborations, citation dynamics and keyword co-occurrence maps. Advanced topic modeling techniques, such as LDA, LDA-BERT and BERT-Clustering, reveal a spectrum of themes, from foundational AI concepts in education to domain-specific applications in fields like legal and financial contexts. The findings highlight major educational themes such as “AI in education”, “medical education” and “programming education”, alongside subfields like “computer science education” and “software engineering education” underscoring a strong focus on technology-driven learning.},
  keywords={Education;Chatbots;Artificial intelligence;Bibliometrics;Market research;Ethics;Collaboration;Focusing;Large language models;Systematic literature review;Large language models;artificial intelligence;education;topic modeling},
  doi={10.1109/ACCESS.2025.3570649},
  ISSN={2169-3536},
  month={},}@ARTICLE{10777837,
  author={Cui, Xiao and Qin, Yulei and Gao, Yuting and Zhang, Enwei and Xu, Zihan and Wu, Tong and Li, Ke and Sun, Xing and Zhou, Wengang and Li, Houqiang},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={SinKD: Sinkhorn Distance Minimization for Knowledge Distillation}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Knowledge distillation (KD) has been widely adopted to compress large language models (LLMs). Existing KD methods investigate various divergence measures including the Kullback–Leibler (KL), reverse KL (RKL), and Jensen–Shannon (JS) divergences. However, due to limitations inherent in their assumptions and definitions, these measures fail to deliver effective supervision when a distribution overlap exists between the teacher and the student. In this article, we show that the aforementioned KL, RKL, and JS divergences, respectively, suffer from issues of mode-averaging, mode-collapsing, and mode-underestimation, which deteriorates logits-based KD for diverse natural language processing (NLP) tasks. We propose the Sinkhorn KD (SinKD) that exploits the Sinkhorn distance to ensure a nuanced and precise assessment of the disparity between distributions of teacher and student models. Besides, thanks to the properties of the Sinkhorn metric, we get rid of sample-wise KD that restricts the perception of divergences inside each teacher–student sample pair. Instead, we propose a batch-wise reformulation to capture the geometric intricacies of distributions across samples in the high-dimensional space. A comprehensive evaluation of GLUE and SuperGLUE, in terms of comparability, validity, and generalizability, highlights our superiority over state-of-the-art (SOTA) methods on all kinds of LLMs with encoder-only, encoder–decoder, and decoder-only architectures. Codes and models are available at https://github.com/2018cx/SinKD.},
  keywords={Minimization;Encoding;Bidirectional control;Temperature measurement;Costs;Adaptation models;Transformers;Training;Sun;Robustness;Knowledge distillation (KD);Sinkhorn distance;Wasserstein distance},
  doi={10.1109/TNNLS.2024.3501335},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10662990,
  author={Frankford, Eduard and Höhn, Ingo and Sauerwein, Clemens and Breu, Ruth},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={A Survey Study on the State of the Art of Programming Exercise Generation Using Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This paper analyzes Large Language Models (LLMs) with regard to their programming exercise generation capabilities. Through a survey study, we defined the state of the art, extracted their strengths and weaknesses and finally proposed an evaluation matrix, helping researchers and educators to decide which LLM is the best fitting for the programming exercise generation use case. We also found that multiple LLMs are capable of producing useful program-ming exercises. Nevertheless, there exist challenges like the ease with which LLMs might solve exercises generated by LLMs. This paper contributes to the ongoing discourse on the integration of LLMs in education.},
  keywords={Surveys;Data privacy;Navigation;Large language models;Education;Fitting;Transforms;Programming Education;Programming Exercise Generation;Large Language Models;Artificial Intelligence;ChatGPT;Programming Exercise Generation Benchmark},
  doi={10.1109/CSEET62301.2024.10662990},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10837662,
  author={Jang, Wunmin and Hou, Ruikun and Gao, Hong and Kasneci, Enkelejda},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Analyzing Communication Logs in Pair Programming: A Comparison of Human- and LLM-Based Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Communication challenges have often been a significant b arrier t o e ffective P air Programming (PP), especially for novices in higher education. A deep understanding of communication patterns can enhance learning outcomes during PP. To explore this, we conducted an experiment involving 19 participants engaged in debugging tasks at a university, grouped into three pairing configurations: e xpert p airs, student pairs, and mixed pairs. We manually transcribed and coded the participants' verbal interactions based on nine predefined communication patterns. Considering that manual coding is cost-intensive, we also explored an automated annotation approach by leveraging recent Large Language Models (LLMs) with zero-shot capabilities for multi-label classification. Our findings revealed distinct differences in communication patterns. Integration, extension, feedback request, and critique were the most common patterns, while completion, justification request, clarification,j uxtaposition, a nd p araphrase w ere r are a cross all groups. These insights highlight the importance of fostering a comfortable and supportive environment that encourages agreement and idea expansion during PP, particularly those that require collaborative programming practices. Furthermore, our model evaluation indicates that the advanced GPT-4o model performs best, achieving a F1-score of 0.59. This study suggests that encouraging diverse transactive interactions can enhance the effectiveness of PP. Additionally, the LLM-based automated annotation approach shows promise as a substitute for human observers, prompting large-scale communication research.},
  keywords={Training;Annotations;Large language models;Collaboration;Multi label classification;Manuals;Observers;Encoding;Problem-solving;Programming profession;communication analysis;higher education;pair programming;LLMs zero-shot annotation},
  doi={10.1109/ITHET61869.2024.10837662},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10837661,
  author={Abid, Abir and Somai, Meriem and Kammoun, Habib M. and Kallel, Ilhem},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The NAJEH Effect: How ChatGPT is Shaping the Future of Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In the digital era, Artificial Intelligence is increasingly developing. In recent years, one of the promising development in this field is ChatGPT which has sparked considerable interest. ChatGPT is a language model developed by OpenAI that allows people to interact with a computer in a more natural and conversational way. It offers students and educators personalized learning experiences Linked to ChatGPt open AI API. Therefore, we present in this paper a virtual tutor, named NAJEH, integrated into the student engagement portal and mobile application (MYU) and have access to the Student Information System (SIS) and Learning Management System (LMS) of the Honoris United Universities11https://honoris.net/, which includes 6 institutions in Tunisia. Around five thousand students from the Université Centrale had the learning experience with NAJEH. A survey was carried out in order to explore students satisfaction and acceptance of NAJEH. Thus, with a 76% response rate, results show that more than 80 % of students find this chatbot tutor very useful, easy and use it at least once a day. As perspective, we propose to investigate on the impact of these interactions on the students' academic performance and teaching efficiency. In fact, an in-depth study requires more data available over a longer period, even several years.},
  keywords={Training;Surveys;Learning management systems;Computational modeling;Chatbots;Mobile applications;Artificial intelligence;Information technology;Portals;Information systems;NAJEH;ChatGPT API;OpenAI;E-learning;Higher Education;Students' Feedback},
  doi={10.1109/ITHET61869.2024.10837661},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10295122,
  author={Hernandez, Alexander A. and Padilla, Jay Rhald C. and Montefalcon, Myron Darrel L.},
  booktitle={2023 IEEE 13th International Conference on System Engineering and Technology (ICSET)}, 
  title={Information Seeking Behavior in ChatGPT: The Case of Programming Students from a Developing Economy}, 
  year={2023},
  volume={},
  number={},
  pages={72-77},
  abstract={ChatGPT is a promising emerging technology that could revolutionize the programming-related activities of students in universities throughout their academic programs. However, to date, academics need understanding on information-seeking behavior of students in programming courses, its potential role, and benefits to learning and assessment. To answer this gap, this study develops a conceptual framework with hypotheses tested through a survey of higher education students to examine the use of ChatGPT for searching programming-related information. Results show that perceived ease of use, usefulness, social influence, herding, trustworthiness, convenience, and ethical considerations positively influenced the use of ChatGPT to search for programming-related information. Likewise, using ChatGPT is positively correlated with information-seeking behavior. Thus, ChatGPT is a promising tool that may bring forward programming activities to students and instructors. Practical and research implications are provided to broaden the conversation on ChatGPT further.},
  keywords={Surveys;Ethics;Education;Oral communication;Chatbots;Systems engineering and theory;Behavioral sciences;artificial intelligence;ChatGPT;developing country;use behavior;information-seeking behavior;technology acceptance model;technology adoption},
  doi={10.1109/ICSET59111.2023.10295122},
  ISSN={2470-640X},
  month={Oct},}@INPROCEEDINGS{10481602,
  author={Prajapati, Manish and Baliarsingh, Santos Kumar and Dora, Chinmayee and Bhoi, Ashutosh and Hota, Jhalak and Mohanty, Jasaswi Prasad},
  booktitle={2024 International Conference on Emerging Systems and Intelligent Computing (ESIC)}, 
  title={Detection of AI-Generated Text Using Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={735-740},
  abstract={A large language model (LLM) is a trained deep-learning model that understands and generates text in a human-like fashion. Due to the significant advancements of LLM, it becomes a challenging task to distinguish human-written content from artificial intelligence (AI) generated content. In this work, we leverage the machine learning (ML) models to reliably identify whether an essay is authored by a human being or by an LLM. Concerns about LLMs replacing human tasks, especially in education persist. However, optimism remains for their potential as tools to enhance writing skills. An academic worry is LLMs facilitating plagiarism due to their extensive training in text and code datasets. Using diverse texts and unknown generative models, we replicate typical scenarios to encourage feature learning across models. In a study involving human subjects, we demonstrate that the annotation scheme offered by generative textual likelihood ratio (GLTR) enhances the human detection rate of fake text from 74% to 99% without requiring any previous training. GLTR is open source and publicly deployed, already finding widespread use in detecting generated outputs.},
  keywords={Training;Representation learning;Generative AI;Current measurement;Plagiarism;Text detection;Writing;LLM;AI;Machine Learning;ChatGPT;text detection},
  doi={10.1109/ESIC60604.2024.10481602},
  ISSN={},
  month={Feb},}@ARTICLE{10820047,
  author={Huang, Yuheng and Song, Jiayang and Wang, Zhijie and Zhao, Shengming and Chen, Huaming and Juefei-Xu, Felix and Ma, Lei},
  journal={IEEE Transactions on Software Engineering}, 
  title={Look Before You Leap: An Exploratory Study of Uncertainty Analysis for Large Language Models}, 
  year={2025},
  volume={51},
  number={2},
  pages={413-429},
  abstract={The recent performance leap of Large Language Models (LLMs) opens up new opportunities across numerous industrial applications and domains. However, the potential erroneous behavior (e.g., the generation of misinformation and hallucination) has also raised severe concerns for the trustworthiness of LLMs, especially in safety-, security- and reliability-sensitive industrial scenarios, potentially hindering real-world adoptions. While uncertainty estimation has shown its potential for interpreting the prediction risks made by classic machine learning (ML) models, the unique characteristics of recent LLMs (e.g., adopting self-attention mechanism as its core, very large-scale model size, often used in generative contexts) pose new challenges for the behavior analysis of LLMs. Up to the present, little progress has been made to better understand whether and to what extent uncertainty estimation can help characterize the capability boundary of an LLM, to counteract its undesired behavior, which is considered to be of great importance with the potential wide-range applications of LLMs across industry domains. To bridge the gap, in this paper, we initiate an early exploratory study of the risk assessment of LLMs from the lens of uncertainty. In particular, we conduct a large-scale study with as many as twelve uncertainty estimation methods and eight general LLMs on four NLP tasks and seven programming-capable LLMs on two code generation tasks to investigate to what extent uncertainty estimation techniques could help characterize the prediction risks of LLMs. Our findings confirm the potential of uncertainty estimation for revealing LLMs’ uncertain/non-factual predictions. The insights derived from our study can pave the way for more advanced analysis and research on LLMs, ultimately aiming at enhancing their trustworthiness.},
  keywords={Uncertainty;Estimation;Codes;Hidden Markov models;Adaptation models;Artificial intelligence;Training;Risk management;Electronic mail;Transformers;Large language models;deep neural networks;uncertainty estimation;software reliability},
  doi={10.1109/TSE.2024.3519464},
  ISSN={1939-3520},
  month={Feb},}@ARTICLE{10485416,
  author={Jeong, Yongwoo and Song, Jae-Jun and Yang, Jiseon and Kang, Sungmin},
  journal={IEEE Access}, 
  title={Advancing Tinnitus Therapeutics: GPT-2 Driven Clustering Analysis of Cognitive Behavioral Therapy Sessions and Google T5-Based Predictive Modeling for THI Score Assessment}, 
  year={2024},
  volume={12},
  number={},
  pages={52414-52427},
  abstract={Cognitive Behavioral Therapy (CBT) for tinnitus alleviates psychological discomfort caused by severe tinnitus symptoms. During CBT, the patients will have various homework assignments, including writing daily diaries and self-monitoring. Most of these homework assignments are hand-written, textual data. This paper proposes that tinnitus therapeutics can utilize Large Language Models (LLMs) to analyze CBT and predict the outcomes of CBT treatments to manage high caseloads. We anonymized patient data and examined it with GPT-2-based-embedding, dimensionality reduction, and clustering process to observe how patients themselves changed their misconceptions and developed less unnecessary excessive emotional discomfort and how their Tinnitus Handicap Inventory (THI) scores were improved after the CBT treatment. We also discussed clustering results as a part of the demonstrations that LLMs can give us insights into the CBT. Then, we augmented textual patient data in three ways to minimize augmentation bias with a corresponding penalty to overcome the constraints of limitation of the number of datasets. We trained the Google T5 Transformer with the augmented data to predict the THI score outcomes at the end of the CBT sessions. We measured the performance using the ROUGE-L metric during the training and validation. The generated THI scores by Google T5 were converted from strings to floats to measure RMSE performance, which proved that the LLM could predict the outcome of CBT treatment with CBT data. Even though there is a risk of overfitting issues, this work demonstrated that tinnitus therapeutics experts can employ LLMs to manage caseloads.},
  keywords={Medical treatment;Internet;Depression;Clustering algorithms;Transformers;Support vector machines;Principal component analysis;Social networking (online);Cognition;Behavioral sciences;Ear;Patient monitoring;Writing;Large language models;Augmentation;cognitive;CBT;GPT-2;Google;tinnitus;T5;RMSE;ROUGE-L},
  doi={10.1109/ACCESS.2024.3383020},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11016290,
  author={Horne, Christopher},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging AI Chatbots to Enhance Student Understanding of Electric Circuits}, 
  year={2025},
  volume={},
  number={},
  pages={1-3},
  abstract={This work-in-progress (WIP) examines the potential of AI-powered chatbots, especially ChatGPT, as instructional tools to support student learning in an introductory electric circuits course. AI chatbots are becoming increasingly prominent in educational settings due to their capabilities in providing immediate, natural language-based explanations that support both procedural and conceptual understanding. In this WIP, electrical engineering students engaged with ChatGPT to solve problems related to fundamental topics such as Voltage and Current Division, as well as Nodal Analysis. Through structured assignments, students compared traditional problem-solving methods with chatbot-assisted approaches. Key findings indicate mixed outcomes, with students demonstrating improved comprehension of conceptual topics but facing challenges in accuracy due to prompting errors and limitations in ChatGPT's analytical processing. On average, 82 % of students expressed positive feedback on ChatGPT, with 48 % reporting improved confidence and understanding in electric circuits. However, for Nodal Analysis, only 22 % of students who provided accurate prompts received correct solutions from ChatGPT that closely matched their hand calculations.},
  keywords={Hands;Electric potential;Accuracy;Generative AI;Circuits;Voltage;Chatbots;Problem-solving;Engineering education;Equivalent circuits;Electric Circuits;Circuit Analysis;ChatGPT;Engineering education;Generative AI;GPT-4},
  doi={10.1109/EDUCON62633.2025.11016290},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10638538,
  author={Haindl, Philipp and Weinberger, Gerald},
  journal={IEEE Access}, 
  title={Does ChatGPT Help Novice Programmers Write Better Code? Results From Static Code Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={114146-114156},
  abstract={In the realm of AI-enhanced programming education, there is growing interest in using such tools to help students understand good coding principles. This study investigates the impact of ChatGPT on code quality among part-time undergraduate students in introductory Java programming courses, who lack prior Java experience. The source code of 16 students from the control group (without ChatGPT) and 22 students from the treatment group (with ChatGPT) who completed identical programming exercises focused on coding conventions was analyzed. Static code analysis tools assessed adherence to a common coding convention ruleset and calculated cyclomatic and cognitive complexity metrics. The comparative analysis shows that the ChatGPT-assisted group significantly improved code quality, with fewer rule violations and reduced cyclomatic and cognitive complexities. The treatment group adhered more closely to coding standards and produced less complex code. Violations primarily occurred in line length, final parameters, and the extensibility of object-oriented programming (OOP). These findings suggest that ChatGPT can be beneficial in programming education by helping students write cleaner, less complex code and adhere to coding conventions. However, the study’s limitations, such as the small sample size and novice status of participants, call for further research with larger, more diverse populations and different educational contexts.},
  keywords={Codes;Chatbots;Programming;Programming profession;Education;Complexity theory;Java;Programming education;ChatGPT large language models;static code analysis},
  doi={10.1109/ACCESS.2024.3445432},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10913535,
  author={Watanabe, Rei and Okada, Satoshi and Watarai, Koki and Mitsunaga, Takuho},
  booktitle={2024 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Cloud SecNavigator: RAG Approach to Bridge Gaps and Strengthen Cloud Security Practices with RAGAS Assessment}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, many cyber incidents have resulted from misconfigurations of AWS. Although AWS provides exten-sive security guidelines, the sheer volume of documentation makes it difficult for developers to read and apply them completely. To address this, we propose a development support tool, Cloud SecNavigator. This tool uses Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) to extract relevant content and accurately respond to user queries based on AWS documentation. Our evaluation measures Cloud SecNavigator's output accuracy using two approaches: (1) Retrieval-Augmented Generation Assessment (RAGAS) and (2) a comparative accuracy assessment between Cloud SecNavigator-generated responses and a non-RAG LLM (GPT-40). The results indicate that Cloud Sec-Navigator achieves superior accuracy, highlighting its potential as an effective development support tool.},
  keywords={Accuracy;Large language models;Cloud computing security;Retrieval augmented generation;Documentation;Medical services;User interfaces;Internet;Security;Usability;Cloud Security;Retrieval-Augmented Generation (RAG);LLM (Large Language Models);RAGAS},
  doi={10.1109/ICEET65156.2024.10913535},
  ISSN={2831-3682},
  month={Dec},}@ARTICLE{10840322,
  author={Zhou, Bohao and Zhan, Yibing and Wang, Zhonghai and Li, Yanhong and Zhang, Chong and Yu, Baosheng and Ding, Liang and Jin, Hua and Liu, Weifeng and Wang, Xiongbin and Tao, Dapeng},
  journal={IEEE Transactions on Emerging Topics in Computational Intelligence}, 
  title={Benchmarking Medical LLMs on Anesthesiology: A Comprehensive Dataset in Chinese}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={With the recent success of large language models (LLMs), interest in developing them for medical domains has increased. However, due to the lack of benchmark datasets, evaluating the capabilities of medical LLMs remains challenging, particularly in highly specialized fields such as anesthesiology. To address this gap, we introduce a comprehensive anesthesiology benchmark dataset in Chinese, known as the Chinese Anesthesiology Benchmark (CAB). This benchmark facilitates the evaluation of medical LLMs for anesthesiology across three crucial dimensions: knowledge, application, and safety. Specifically, the CAB provides more than 8 k questions collected from examinations and books for knowledge-level evaluation; more than 2 k questions collected from online anesthesia consultations and hospitals for application-level evaluation; and 136 tests from seven anesthesia medical care scenarios for safety-level evaluation. With the proposed CAB dataset, we conducted a thorough evaluation of six medical LLMs, such as Bianque-2 and HuatuoGPT-13B, and eleven general LLMs, such as Qwen-7B-Chat and GPT-4. The evaluation results revealed that there are still clear gaps in the capacities of medical LLMs for anesthesiology compared with those of medical students in the field of anesthesia. We hope that the proposed CAB dataset can facilitate the development of medical LLMs for anesthesiology.},
  keywords={Anesthesiology;Anesthesia;Accuracy;Safety;Benchmark testing;Question answering (information retrieval);Data collection;Tag clouds;Physiology;Hospitals;Anesthesiology;benchmark;dataset;evaluation;large language model;medicine},
  doi={10.1109/TETCI.2024.3502465},
  ISSN={2471-285X},
  month={},}@INPROCEEDINGS{10578820,
  author={He, Zhangying and Nguyen, Thomas and Miari, Tahereh and Aliasgari, Mehrdad and Rafatirad, Setareh and Sayadi, Hossein},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The AI Companion in Education: Analyzing the Pedagogical Potential of ChatGPT in Computer Science and Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Artificial Intelligence (AI), with ChatGPT as a prominent example, has recently taken center stage in various domains including higher education, particularly in Computer Science and Engineering (CSE). The AI revolution brings both convenience and controversy, offering substantial benefits while lacking formal guidance on their application. The primary objective of this work is to comprehensively analyze the pedagogical potential of ChatGPT in CSE education, understanding its strengths and limitations from the perspectives of educators and learners. We employ a systematic approach, creating a diverse range of educational practice problems within CSE field, focusing on various subjects such as data science, programming, AI, machine learning, networks, and more. According to our examinations, certain question types, like conceptual knowledge queries, typically do not pose significant challenges to ChatGPT, and thus, are excluded from our analysis. Alternatively, we focus our efforts on developing more in-depth and personalized questions and project-based tasks. These questions are presented to ChatGPT, followed by interactions to assess its effectiveness in delivering complete and meaningful responses. To this end, we propose a comprehensive five-factor reliability analysis framework to evaluate the responses. This assessment aims to identify when ChatGPT excels and when it faces challenges. Our study concludes with a correlation analysis, delving into the relationships among subjects, task types, and limiting factors. This analysis offers valuable insights to enhance ChatGPT's utility in CSE education, providing guidance to educators and students regarding its reliability and efficacy.},
  keywords={Systematics;Limiting;Focusing;Machine learning;Chatbots;Reliability;Task analysis;ChatGPT;Computer Science and Engineering;Education;Generative Artificial Intelligence;Reliability Analysis},
  doi={10.1109/EDUCON60312.2024.10578820},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10672220,
  author={Helal, Manal and Holthaus, Patrick and Wood, Luke and Velmurugan, Vignesh and Lakatos, Gabriella and Moros, Silvia and Amirabdollahian, Farshid},
  booktitle={2024 5th International Conference on Artificial Intelligence, Robotics and Control (AIRC)}, 
  title={When the Robotic Maths Tutor is Wrong - Can Children Identify Mistakes Generated by ChatGPT?}, 
  year={2024},
  volume={},
  number={},
  pages={83-90},
  abstract={This study delves into integrating Large Language Models (LLMs), particularly ChatGPT-powered robots, as educational tools in primary school mathematics. Against the backdrop of Artificial Intelligence (AI) increasingly permeating educational settings, our investigation focuses on the response of young learners to errors made by these LLM-powered robots. Employing a user study approach, we conducted an experiment using the Pepper robot in a primary school classroom environment, where 77 primary school students from multiple grades (Year 3 to 5) took part in interacting with the robot. Our statistically significant findings highlight that most students, regardless of the year group, could discern between correct and incorrect responses generated by the robots, demonstrating a promising level of understanding and engagement with the AI-driven educational tool. Additionally, we observed that students' correctness in answering the Maths questions significantly influenced their ability to identify errors, underscoring the importance of prior knowledge in verifying LLM responses and detecting errors. Additionally, we examined potential confounding factors such as age and gender. Our findings underscore the importance of gradually integrating AI-powered educational tools under the guidance of domain experts following thorough verification processes. Moreover, our study calls for further research to establish best practices for implementing AI-driven pedagogical approaches in educational settings,},
  keywords={Brain;Large language models;Atmospheric modeling;Education;Learning (artificial intelligence);Chatbots;Mathematical models;Large Language Models;LLM Mathematical Correctness;Educational Robots;Cognition;Social Robotics},
  doi={10.1109/AIRC61399.2024.10672220},
  ISSN={},
  month={April},}@INPROCEEDINGS{11016463,
  author={Bhatt, Vishwa and Yu, Zhixin and Hou, Yunfei and Jin, Jennifer},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT as a Programming Tutor: Student Perceptions, Effectiveness, and Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This research examines the impact of ChatGPT on computer science education, focusing on its application in learning programming languages like SQL, C++, Python, and C#. Through a survey of 149 university students, the study identifies both the advantages and challenges of using ChatGPT as a virtual lab assistant. The results show that ChatGPT offers considerable assistance to students, especially in providing prompt feedback, facilitating debugging, and clarifying complex programming concepts. However, the research also points out significant challenges, including the potential for over-reliance on AI tools and worries about the accuracy of the responses generated by AI. Several students reported experiencing misleading or incomplete information from ChatGPT, indicating a need for enhancements in its accuracy and dependability. To address these challenges, the study proposes a transition from assignments focused on theory to personalized, project-based activities that foster independent problem-solving. In summary, this research sheds light on the advantages and obstacles of incorporating ChatGPT into computer science courses. Although ChatGPT provides beneficial support for learning, its function should be supplementary rather than central to programming education. The results highlight the necessity of thoughtful integration, promoting self-directed learning while utilizing AI's capabilities to foster engagement and offer immediate assistance.},
  keywords={Training;Surveys;Accuracy;Systematics;Debugging;Chatbots;Prompt engineering;Problem-solving;Artificial intelligence;Programming profession;ChatGPT;Generative AI;Programming education;AI dependency;AI accuracy;Programming Tutor},
  doi={10.1109/EDUCON62633.2025.11016463},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10663035,
  author={Yabaku, Mounika and Ouhbi, Sofia},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={University Students' Perception and Expectations of Generative AI Tools for Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Adopting Generative Artificial Intelligence (AI) tools in software engineering represents a shift in how tasks like coding and idea generation are approached. This paper investigates uni-versity students' perceptions and expectations regarding the use of Generative AI tools such as ChatGPT and Copilot in software engineering. To achieve this, we conducted a questionnaire study with volunteer participants studying at Uppsala University in Sweden, resulting in a total of 127 responses. These responses were about the usage preferences, motivations for adoption, per-ceived benefits, encountered challenges, and suggested improve-ment of these tools. The findings reveal that 16 % of participants have never used a Generative AI tool, while of those who have used such tools predominantly use ChatGPT3.5. Among users of Generative AI, respondents reported benefits such as code optimization and idea generation, alongside challenges such as inaccuracies in generated content and understanding user intent. Despite these challenges, participants perceive the integration of Generative AI tools as transformative for traditional software engineering practices. The results of this paper offer insights into the practical use of AI tools and suggestions for improving their functionality, thereby influencing the future direction of software engineering education.},
  keywords={Industries;Training;Productivity;Ethics;Technological innovation;Generative AI;Refining;Generative AI;software engineering;university students;perception;expectation;questionnaire},
  doi={10.1109/CSEET62301.2024.10663035},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10734623,
  author={Troussas, Christos and Krouska, Akrivi and Papakostas, Christos and Mylonas, Phivos and Sgouropoulou, Cleo},
  booktitle={2024 9th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)}, 
  title={Assessing the Impact of Integrating ChatGPT as an Advice Generator in Educational Software}, 
  year={2024},
  volume={},
  number={},
  pages={127-133},
  abstract={This paper reports on the study of the integration of ChatGPT as an advice generator in custom educational software developed for Java programming. The software, in cooperation with ChatGPT API, pursues providing real-time, context-specific advice to students for better learning. This work adopted a two-fold evaluation approach to evaluating this integration. First, this study examines the effectiveness of this integration with the help of the Interrupted Time Series Analysis methodology to measure possible improvement in the performance metrics of the students in terms of error rates and task completion times. Second, this work presents a custom-designed questionnaire used to get student perceptions regarding the clarity, usefulness, and impact of ChatGPT’s advice, and the level of student satisfaction with the user interface. The key takeaways from this research study are the substantial improvements in performance metrics that were noted quantitatively, with students achieving lower error rates and faster completion times after the intervention of ChatGPT. Qualitatively, learners express their satisfaction with the clarity of advice, which gives them an understanding that works on their learning and confidence in Java programming. These findings point toward the promise of integrating such advanced AI solutions in educational software toward a significant improvement in learning outcomes and the necessity of human-aided continuous user feedback for system refinement.},
  keywords={Java;Error analysis;Time series analysis;User interfaces;Chatbots;Software;Generators;Time measurement;Artificial intelligence;Programming profession;ChatGPT in Education;Advice generator;Educational Software;Java Programming Learning;Artificial Intelligence in Education;Interrupted Time Series Analysis;User Experience Evaluation;AI-Powered Tutoring Systems;Programming Education;Technology-Enhanced Learning;Custom Questionnaire Assessment},
  doi={10.1109/SEEDA-CECNSM63478.2024.00031},
  ISSN={},
  month={Sep.},}@ARTICLE{10833612,
  author={Banerjee, P. and Srivastava, Anurag K. and Adjeroh, Donald A. and Reddy, Ramana and Karimian, Nima},
  journal={IEEE Access}, 
  title={Understanding ChatGPT: Impact Analysis and Path Forward for Teaching Computer Science and Engineering}, 
  year={2025},
  volume={13},
  number={},
  pages={11049-11069},
  abstract={Large Language Models (LLMs) like ChatGPT have become the most popular regenerative AI applications, used for obtaining responses for queries in different domains. The responses of ChatGPT are already becoming mainstream and are challenging conventional methods of learning. This article focuses on the application of ChatGPT for academic instructional purposes in the field of computer engineering and related majors. The capability of ChatGPT for instructional purposes is evaluated based on the responses to different questions about these engineering streams. This article explores different opportunities (with use cases), that ChatGPT can provide in augmenting the learning experience. It also provides scenarios of limitations and modifying the evaluation process to prevent the use of ChatGPT, which may lead to an inaccurate dissemination of accepted facts. In this paper, common classroom problems and their respective responses from ChatGPT in the domains of Computer Science, Cyber Security, Data Science, and Electrical Engineering are analyzed to determine the categories of queries for which ChatGPT offers reliable responses and those for which it may be factually incorrect. A student survey is performed to demonstrate that students must be made aware that ChatGPT may not be suitable for certain types of queries and means of upgrading the evaluation process.},
  keywords={Chatbots;Artificial intelligence;Measurement;Education;Computer science;Writing;Object recognition;Electrical engineering;Translation;Robot sensing systems;ChatGPT;education;LLM;computer science and engineering;electrical engineering},
  doi={10.1109/ACCESS.2024.3524102},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10893514,
  author={De La Hoz, Jose L. and Restrepo, David and Vieira, Camilo},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Supporting Student Understanding of Finite Element Analysis and Computational Science: Classroom Scaffolding and ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress research paper presents the preliminary results of a study exploring the effectiveness of using computational notebooks to enhance student learning in a Finite Element Analysis (FEA) course for undergraduate Mechanical Engineering students. Our previous work has shown that students often face difficulties in grasping abstract concepts from mechanics of materials while simultaneously learning computational modeling. However, students recognized several advantages of using MATLAB for FEA compared to manual calculations, including significant time savings, increased efficiency, and reduced errors. Nevertheless, they also faced challenges, including a steep learning curve for MATLAB and concerns about how this limitation hinders their conceptual understanding. Despite these drawbacks, they recognized the importance and value of developing computational skills for their future careers. In this study, we extended the scaffolds and changed the sequence of activities to address the challenges the students faced in the previous iteration of our work. Specifically, we provided worked examples that students needed to use, self-explain, and modify before they engaged in programming from scratch. Also, after developing a basic understanding of how to implement FEA in MATLAB, the students used ChatGPT to generate a code that would do the same task. This activity required them to evaluate and refine automatically generated MATLAB code, as ChatGPT may provide alternative solutions that might not always work correctly. We explore three main topics to understand student experiences with and perceptions of this approach: (1) the value of using computational methods compared to manual completion for FEA; (2) the challenges and support of using MATLAB for FEA; and (3) the effectiveness of simulation tools to learn FEA. The goal of this project is two-fold: (1) supporting student learning of intricate phenomena explored in mechanics of materials, like distribution of stress, and stiffness, and (2) fostering essential computational thinking skills through practical disciplinary coding experience. By implementing these elements, the study anticipates a substantial improvement in students' understanding of FEA principles and their ability to translate them into solutions for real-world engineering challenges.},
  keywords={Codes;Scientific computing;Manuals;Transforms;Chatbots;Encoding;Finite element analysis;MATLAB;Programming profession;Stress;Mechanics of materials;computational thinking;threshold concepts;Finite Element Analysis;ChatGPT;Scaffolding},
  doi={10.1109/FIE61694.2024.10893514},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10398408,
  author={Chan, Henry C. B.},
  booktitle={2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Grading Generative AI-based Assignments Using a 3R Framework}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={With the advent of generative artificial intelligence (GenAI), there is a strong need to revisit the grading or assessment mechanism. In this paper, we present a 3R framework to facilitate the grading of GenAI-based assignments. Basically, there are three essential components: Report, Revise and Reflect. Students should report on how they use GenAI tool(s). They should also revise its output by providing their own input or contributions. Last but not least, they should provide a learning reflection. We also present a 3R rubric for evaluation purposes and propose a GPT formula for determining an effective grade. For illustration purposes, we discuss two cases, covering essay assignments and programming assignments. Furthermore, to evaluate the 3R framework from the student perspective, we present and discuss student survey results. The 3R framework can provide the basis for further research study as well.},
  keywords={Surveys;Systematics;Generative AI;Education;Programming;Reflection;generative AI;ChatGPT;assessment},
  doi={10.1109/TALE56641.2023.10398408},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10578680,
  author={Zönnchen, Benedikt and Thurner, Veronika and Böttcher, Axel},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={On the Impact of ChatGPT on Teaching and Studying Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={AI -systems that are based on large language models, such as ChatGPT, have quickly increased their prowess over the last year, and at the same time became readily available. As of now, many disciplines gain experience in using tools such as ChatGPT in a professional setting - and software engineering is no exception. Just as with any new kind of tooling, it is to be expected that in the era of ChatGPT, some traditional skills of the discipline will become rather obsolete, while at the same time new skill sets emerge that will be required from future professionals. Therefore, as educators we must reconsider the skill set we aim at fostering in our software engineering students, and adapt our intended learning outcomes accordingly. Furthermore, we need to adapt both assessment strategies and the teaching and learning methods we employ, in order to provide our students with a study experience that adheres to the principle of constructive alignment.},
  keywords={Learning systems;Taxonomy;Chatbots;Engineering education;Programming profession;Software engineering;software engineering education;learning objectives;teaching methods;assessment;large language models},
  doi={10.1109/EDUCON60312.2024.10578680},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10989326,
  author={Alshammari, Mohammad T.},
  booktitle={2025 4th International Conference on Computing and Information Technology (ICCIT)}, 
  title={An Investigation into ChatGPT-Based Instructional Feedback on Programming Projects}, 
  year={2025},
  volume={},
  number={},
  pages={624-628},
  abstract={Providing high-quality instructional feedback is essential for enhancing learning and motivation. However, the large number of learners and time constraints of instructors can hinder this process. Automating instructional feedback through online learning environments presents a potential solution, but current systems may not adequately address complex learning assignments. Artificial intelligence technologies like ChatGPT can offer an opportunity to deliver feedback efficiently, especially for complex learning tasks. Despite its potential, relatively few studies have examined the distinctions between ChatGPT-generated and expert-based feedback and learners' perceptions of these feedback sources. This study stands among the limited research efforts that seek to compare instructional feedback produced by ChatGPT and that provided by experts, shedding light on learners' subjective assessment of such feedback in the context of programming projects. The findings showed that experts consistently rated programming projects higher than ChatGPT. However, ChatGPT demonstrated strengths in providing more comprehensive textual feedback on the learners' work. Notably, the learners rated ChatGPT feedback more favorably than feedback from domain experts. The study's findings are thoroughly discussed, and future research avenues are outlined.},
  keywords={Codes;Accuracy;Education;Focusing;Learning (artificial intelligence);Writing;Chatbots;Time factors;Information technology;Programming profession;ChatGPT;programming;education;feedback},
  doi={10.1109/ICCIT63348.2025.10989326},
  ISSN={},
  month={April},}@INPROCEEDINGS{10898626,
  author={Lui, Richard Wing Cheung and Bai, Haoran and Zhang, Aiden Wen Yi and Chu, Elvin Tsun Him},
  booktitle={2024 International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)}, 
  title={GPTutor: A Generative AI-powered Intelligent Tutoring System to Support Interactive Learning with Knowledge-Grounded Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={702-707},
  abstract={With increasing popularity of artificial intelligence (AI) in the education industry, intelligent tutoring system (ITS) powered by AI have been widely adopted to optimize the learning experience. However, the relationship between students’ engagement level of Generative AI (GenAI) and their academic performance is still under exploration. Also current popular GenAI products like ChatGPT suffer from the hallucination problem, which includes factuality, faithfulness, and maliciousness issues in the generated answer. This paper presents GPTutor, an ITS leveraging GenAI to support students' learning processes. GPTutor integrates a Retrieval-Augmented Generation (RAG) pipeline to deliver actual and contextually rich answers aligned to student questions and intended learning outcomes (ILO). A pilot evaluation involving undergraduate and postgraduate students assessed the system’s association with user experience, engagement, and academic performance. Results demonstrated that students generally recognize the effectiveness of GPTutor. Some students also provided insightful feedback on the benefits of GPTutor in improving learning efficiency and some limitations to be addressed. Notably, students with higher engagement levels showed significantly better academic performance on the final exam. This study proposed GPTutor to provide an interactive and knowledge-grounded learning experience and showed the strong association between students’ engagement in GPTutor and academic performance.},
  keywords={Industries;Electrical engineering;Generative AI;Retrieval augmented generation;Pipelines;Education;Learning (artificial intelligence);Computer applications;User experience;Question answering (information retrieval);intelligent tutoring system;generative AI;interactive learning;knowledge-grounded question-answering;retrieval-augmented generation},
  doi={10.1109/AEECA62331.2024.00124},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10499744,
  author={Perera, K. G. D. K. and Wijayanayake, J. and Prasadika, J.},
  booktitle={2024 4th International Conference on Advanced Research in Computing (ICARC)}, 
  title={Factors Affecting the Effectiveness of Generative Artificial Intelligence Apps on University Students' Programming Language Learning in Sri Lanka: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={276-281},
  abstract={In today's era, technology has become pervasive worldwide, significantly facilitating access to learning resources. Notably, the emergence of Generative Artificial Intelligence (AI) has garnered rapid attention and interest in a short period with the introduction of ChatGPT. Many individuals have extensively discussed and evaluated this AI-powered language model, from researchers to casual internet users. Importantly, Generative AI applications are increasingly recognized for their potential in educational contexts. In the realm of education, AI has the potential to significantly broaden and improve teaching and learning in higher education. However, while numerous studies have explored the effectiveness of Generative AI applications in programming language learning, an absence of research examining their impact comprehensively exists. Hence, this study aims to identify the factors that affect the successful utilization of Generative AI applications in the context of undergraduate programming language learning, with a particular emphasis on the viewpoints of university students. A systematic literature review was undertaken to obtain the research objectives, adhering to the Prisma 2020 guidelines, which involved selecting and analyzing 47 prior studies. Mainly this study utilized a systematic literature review to comprehend the factors influencing the effective utilization of Generative AI apps by undergraduate students in their programming learning experiences. Furthermore, the study discusses the advantages and challenges university students face when learning programming using generative AI applications.},
  keywords={Computer languages;Systematics;Generative AI;Bibliographies;Face recognition;Education;Learning (artificial intelligence);Generative AI Apps;Learning;Programming Language Learning;Technologies},
  doi={10.1109/ICARC61713.2024.10499744},
  ISSN={},
  month={Feb},}
@INPROCEEDINGS{10975909,
  author={Huang, Min and Ma, Jiarui and Bo, Sun},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Design and Implementation of a Multi-Level Personalized Teaching Framework Based on LLM}, 
  year={2025},
  volume={},
  number={},
  pages={8-14},
  abstract={Personalized teaching is a key focus in modern education, aiming to meet individual student needs and improve learning efficiency. Traditional teaching methods struggle to address student differences in large-scale settings, leading to suboptimal personalized instruction. Recent advancements in generative artificial intelligence (GAI) and large language models (LLMs) offer significant support for the design and implementation of personalized teaching. This paper proposes a multilevel personalized teaching framework that integrates the core elements of the educational system, supporting personalized learning for students, optimizing teaching tasks for teachers, and enhancing resource management for higher education institutions. The framework operates from three perspectives: student, teacher, and institution, offering personalized services throughout the teaching process, including lesson planning, real-time adjustments, and post-class evaluations. The paper discusses the implementation approach based on technologies such as Mixture of Experts (MoE), Chain-of-Thought (CoT) reasoning, and dynamic prompting techniques, along with scenario examples and a validation scheme. The proposed framework provides theoretical support and practical guidance for universities to implement more effective personalized teaching based on AI technologies.},
  keywords={Emotion recognition;Adaptation models;Large language models;Scalability;Education;Transforms;Cognition;Resource management;Testing;Software engineering;Personalized Teaching;Artificial Intelligence;Large Language Models (LLMs);Multi-level;Teaching Framework},
  doi={10.1109/ICEIT64364.2025.10975909},
  ISSN={},
  month={March},}@INPROCEEDINGS{10536194,
  author={Fiore, Marco and Gattullo, Michele and Mongiello, Marina},
  booktitle={2024 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={First Steps in Constructing an AI-Powered Digital Twin Teacher: Harnessing Large Language Models in a Metaverse Classroom}, 
  year={2024},
  volume={},
  number={},
  pages={939-940},
  abstract={This study proposes a ground-breaking idea at the intersection of Artificial Intelligence and virtual education: the creation of an AI-powered Digital Twin instructor in a Metaverse-based classroom using Large Language Models. We aim to build a teacher avatar capable of dynamic interactions with students, tailored teaching approaches, and contextual response inside a virtual world. The research aims to address two major issues for both students and teachers: the Digital Twin can provide feedbacks to resolve doubts about course content and material; also, it can improve student management and allow teachers to answer the trickiest questions raised by students.},
  keywords={Three-dimensional displays;Metaverse;Conferences;Avatars;Education;User interfaces;Digital twins;Social and professional topics—Professional topics—Computer education programs—Software engineering education;Computing methodologies—Artificial intelligence—Natural language processing—Discourse, dialogue and pragmatics Applied computing—Education—Computer-assisted instruction},
  doi={10.1109/VRW62533.2024.00266},
  ISSN={},
  month={March},}@INPROCEEDINGS{10401713,
  author={Ayman, Shehab Eldeen and El-Seoud, Samir A. and Nagaty, Khaled and Karam, Omar H.},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={The Influence of ChatGPT on Student Learning and Academic Performance}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This study delves into the integration of ChatGPT, an artificial intelligence-driven language model, within undergraduate education. The research scrutinizes the potential advantages, obstacles, and ethical dimensions linked to including ChatGPT in educational practices. It assesses how ChatGPT may impact student engagement, critical thinking, problem-solving abilities, writing proficiency, and the delivery of personalized learning experiences. A survey administered to university faculty members captures their perspectives on ChatGPT usage, encompassing its influence on learning outcomes and academic performance. An internal inquiry at the British University in Egypt found high plagiarism rates in various faculties, with mass media having the highest at 66%, while political science had the lowest at 28%. A survey has been conducted on teaching staff at the university. 75% of teaching staff believes that ChatGPT should be integrated into teaching. However, they are still undecided about whether ChatGPT has affected the teaching and learning process. The study underscores the significance of responsible implementation, faculty training, and continuous assessment to optimize ChatGPT’s benefits while adhering to ethical standards in education. In conclusion, this paper illuminates ChatGPT’s potential as a valuable tool in undergraduate education, underscoring the imperative of preserving critical thinking skills and human interaction in the learning journey.},
  keywords={Surveys;Ethics;Plagiarism;Education;Media;Chatbots;Artificial intelligence;ChatGPT;AI;Education;Plagiarism;Assessment},
  doi={10.1109/ICCA59364.2023.10401713},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10925748,
  author={Sarkar, Sneha and Kushwaha, Suresh Prasad and Sharma, Vandana and Mishra, Nilamadhab and Alkhayyat, Ahmed},
  booktitle={2024 International Conference on Intelligent & Innovative Practices in Engineering & Management (IIPEM)}, 
  title={A Novel LLM enabled Code Snippet Generation Framework}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Large Language Models (LLMs) represent a breakthrough in natural language processing (NLP), leveraging deep learning techniques to achieve exceptional proficiency in code generation, analysis and modification of human languages. These models, characterized by their vast scale and parameter count, like Bidirectional Encoder Representations from Transformers (BERT by Google) and the Generative Pre-trained Transformer series (by OpenAI’s GPT), have revolutionized various applications including text generation, translation, summarization, and question answering. In our paper we investigate the practicality,complications, and significance of using LLMs for code generation. We provide a review analysis of existing LLM models in use and compare their proficiency for code generation. This paper examines the underlying mechanisms of LLMs, specially their ability to grasp the code syntax, semantics, and programming logic from large-scale repositories and their documentations. The models’ training techniques include fine-tuning programming-specific datasets and enhancing the models' competency to generate code snippets that are syntactically correct and contextually relevant.},
  keywords={Training;Codes;Translation;Reviews;Semantics;Syntactics;Transformers;Throughput;Software development management;Context modeling;Large Language Models (LLMs);Code Generation;Natural Language Processing (NLP);Code Quality;Software Development},
  doi={10.1109/IIPEM62726.2024.10925748},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10578564,
  author={Israilidis, John and Chen, Wen-Yuan and Tsakalerou, Mariza},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Software Development and Education: Transitioning Towards AI Enhanced Teaching}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper investigates the impact of large language model (LLM) AI tools, such as ChatGPT and Copilot, on software development education, focusing on usability, efficiency, and effectiveness in real-world scenarios. The research employs a quantitative approach, utilizing a survey of 50 software developers with varying levels of experience. Preliminary findings suggest that AI tools have a positive influence on expediting coding tasks and automating text generation, particularly in the early stages of product development. Challenges related to customization, accuracy, and transparency, as well as concerns about their potential impacts on employment, personal privacy, and ethical boundaries, have been identified. Pointers and initial recommendations for transitioning to AI-enhanced teaching and optimizing interactions between learners and generative AI practices are provided.},
  keywords={Surveys;Privacy;Ethics;Generative AI;Focusing;Software;Product development;AI tools;software development;education},
  doi={10.1109/EDUCON60312.2024.10578564},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10893407,
  author={Crandall, Aaron S. and Fischer, Bryan J. and Crandall, Johannah L.},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: ARTful Insights from a Pilot Study on GPT-Based Automatic Code Reviews in Undergraduate Computer Science Programs}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work in progress research paper describes a pilot study using a Large Language Model (LLM) Generative Pre-Trained Transformer-based (GPT) system that generates industry-style code reviews for student feedback on software development projects in Computer Science 2nd, 3rd, and 4th+ semester classes (CS2, CS3, CS4+) at an ABET accredited baccalaureate institution. Code reviews are a valuable, but work-intensive, component of the software engineering process and provide important training to undergraduate students in the form of mentor-peer knowledge transfer. Participants in this study engaged in iterative experiential learning using the Automatic Review Tool (ART), an artificial intelligence tool to support software engineering as an Automatic Static Analysis Tool in the Continuous Integration pipeline alongside software testing harnesses and code style checkers. This pilot study was based on earlier results from a full computer science second semester (CS2) class $(\mathrm{n}=74)$ to develop an ART-generated code review intervention pilot study with a small group of students in CS2 / 3 and CS4. The project underway uses an experiential learning and iterative feedback process to answer research questions including “Does ART provide accurate and actionable code reviews for students” and “Which levels of students are best prepared to receive and use ART-based code reviews?” During this pilot study, the project used a mixed methods research approach with a series of surveys, code review interventions, and numerical analysis of the code reviews' accuracy. Results showed a reasonable degree of code review accuracy by ART and the students learned code review skills from interaction with the ART-based reviews they received. Ongoing work includes increasing the scale of data collection, using this work to refine and focus the ART-based reviews onto the categories of feedback that students find the most valuable, and building out a more modular tool for wider release in the academic community.},
  keywords={Computer science;Training;Surveys;Codes;Accuracy;Reviews;Subspace constraints;Transformers;Iterative methods;Software engineering;Adaptive computer learning;Computer science;Qualitative;Mixed methods research;Code Reviews;Software Engineering Education},
  doi={10.1109/FIE61694.2024.10893407},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10304857,
  author={Li, Jingyue and Meland, Per Håkon and Notland, Jakob Svennevik and Storhaug, André and Tysse, Jostein Hjortland},
  booktitle={2023 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)}, 
  title={Evaluating the Impact of ChatGPT on Exercises of a Software Security Course}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Along with the development of large language models (LLMs), e.g., ChatGPT, many existing approaches and tools for software security are changing. It is, therefore, essential to understand how security-aware these models are and how these models impact software security practices and education. In exercises of a software security course at our university, we ask students to identify and fix vulnerabilities we insert in a web application using state-of-the-art tools. After ChatGPT, especially the GPT-4 version of the model, we want to know how the students can possibly use ChatGPT to complete the exercise tasks. We input the vulnerable code to ChatGPT and measure its accuracy in vulnerability identification and fixing. In addition, we investigated whether ChatGPT can provide a proper source of information to support its outputs. Results show that ChatGPT can identify 20 of the 28 vulnerabilities we inserted in the web application in a white-box setting, reported three false positives, and found four extra vulnerabilities beyond the ones we inserted. ChatGPT makes nine satisfactory penetration testing and fixing recommendations for the ten vulnerabilities we want students to fix and can often point to related sources of information.},
  keywords={Codes;Education;Chatbots;Software;Security;Software measurement;Task analysis;Software security;artificial intelligence;large language models;ChatGPT;IT education},
  doi={10.1109/ESEM56168.2023.10304857},
  ISSN={},
  month={Oct},}@ARTICLE{10507034,
  author={Kong, Siu-Cheung and Yang, Yin},
  journal={IEEE Transactions on Learning Technologies}, 
  title={A Human-Centered Learning and Teaching Framework Using Generative Artificial Intelligence for Self-Regulated Learning Development Through Domain Knowledge Learning in K–12 Settings}, 
  year={2024},
  volume={17},
  number={},
  pages={1562-1573},
  abstract={The advent of generative artificial intelligence (AI) has ignited an increase in discussions about generative AI tools in education. In this study, a human-centered learning and teaching framework that uses generative AI tools for self-regulated learning development through domain knowledge learning was proposed to catalyze changes in educational practices. The framework illustrates how generative AI tools can revolutionize educational practices and transform the processes of teaching and learning to become human-centered. It emphasizes the evolving roles of teachers, who increasingly become skillful facilitators and humanistic storytellers who craft differentiated instructions and attempt to develop students’ individualized learning. Drawing upon insights from neuroscience, the framework guides students to employ generative AI tools to augment their attentiveness, stimulate active engagement in learning, receive immediate feedback, and encourage self-reflection. The pedagogical approach is also reimagined; teachers equipped with generative AI tools and AI literacy can refine their teaching strategies to better equip students to meet future challenges. The practical application of the framework is demonstrated in a case study involving the development of Chinese language writing ability among primary students within a K–12 educational context. This article also reports the results of a 60-h development programme for teachers. Specifically, providing in-service teachers with cases involving uses of the proposed framework helped them to better understand the generative AI concepts and integrate them into their teaching and learning and increased their perceived ability to design AI-integrated courses that would enhance students’ attention, engagement, confidence, and satisfaction.},
  keywords={Generative AI;Education;Artificial intelligence;Learning (artificial intelligence);Guidelines;Task analysis;Transformers;Generative artificial intelligence;human-centered;learning and teaching framework;pedagogical design;self-regulated learning (SRL)},
  doi={10.1109/TLT.2024.3392830},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10578884,
  author={Ambikairajah, Eliathamby and Sirojan, Tharmakulasingam and Thiruvaran, Tharmarajah and Sethu, Vidhyasaharan},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in the Classroom: A Shift in Engineering Design Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial intelligence tools like ChatGPT are increasingly being incorporated into our education paradigm. This paper explores how ChatGPT was used in an Electrical Engineering Design Proficiency course at the University of New South Wales in Sydney. The course is a term-long laboratory-based class that centres on independent student work in system design, implementation, and validation. Students were encouraged to consult ChatGPT for design solutions, explanations, and suggestions, with the requirement that they declare any use of AI tools. The assessment process was carefully designed to determine whether responses originated from AI tools or the students' own understanding. Notably, 70% of the fifty students in the class utilised ChatGPT to enhance their understanding of the subject. The paper will also discuss the specific design tasks given to students, the assessment process, and explore ChatGPT's potential as a supportive educational tool in other courses.},
  keywords={Industries;Electrical engineering;Codes;Debugging;Chatbots;Artificial intelligence;Task analysis;Generative AI;ChatGPT;Engineering Education;Engineering Design;Learning and Teaching},
  doi={10.1109/EDUCON60312.2024.10578884},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10923772,
  author={Browning, Jonathan W. and Bustard, John and Anderson, Neil and Galway, Leo},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Evaluating the Impact of Unrestricted GenAI Usage on Experiential-Based Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This work examines the usage and experience of students using generative AI (genAl) in a engineering entrepreneurship experiential-based learning course. It utilizes a project-based learning approach, where students are in teams of five. The course takes place over a full academic year, i.e., the fall and spring semesters. One of the aims of the course is to be as realistic as possible within an academic setting, with the students trying to create a new technology-based business, in the hopes that they will continue their ventures after the course concludes. Therefore, the teams were allowed to and encouraged to use any genAI they wish throughout the course to assist them. Outside of academia, it would be expected that a start-up founder would use genAl to speed up many aspects of starting their business. Therefore, we want to examine how the students use genAI without there being any constraints. As part of the summative assessment for the course each student peer assesses the members of their team. Included within that they also “peer assess” genAI as though it were another team member, which is a critical reflection of their genAI usage. This work addresses how students use genAI, in experiential-based learning courses when they are allowed to use it any way possible to assist them. The study uses a quantitative and qualitative approach with student data from their “peer assessment” (i.e., critical reflection) of their genAI usage from the academic year 2023/24. Within the peer assessment of the genAI team member the students answer Likert-scale statements to be rated on a five-point semantic differential scale. The results indicate a varied adoption and value of genAI across different project phases. While some students appreciated genAI for speeding up specific tasks, its contribution to creative processes like ideation was less impactful.},
  keywords={Training;Electrical engineering;Generative AI;Soft sensors;Semantics;Project management;Entrepreneurship;Reflection;Springs;Engineering education;computer engineering;critical reflection;electrical engineering;experiential learning;student experience},
  doi={10.1109/ICEED62316.2024.10923772},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893294,
  author={Ramasamy, Vijayalakshmi and Kulpinski, Eli and Beaupre, Thomas and Antreassian, Aaron and Jeong, Yunhwan and Clarke, Peter J. and Aiello, Anthony and Ray, Charles},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing CS Education with LAs Using AI-Empowered AIELA Program}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice full paper delves into the transformative role of Learning Assistants (LAs) in Computer Science education, focusing on enhancing student engagement and improving learning outcomes. The LA model, which aligns with Vygotsky's Social Constructivist Learning Theory, fosters an environment of student-centered learning and social interaction. In a pilot study conducted in Spring 2024 at a public university, the LA program is implemented in two computer science courses. A quasi-experimental design has been used to evaluate the impact of LA-facilitated team activities on student learning outcomes. The study compares a control group receiving traditional instruction with an experimental group participating in LA-facilitated team activities. The experimental group engaged in weekly team-based activities, guided by LAs and faculty, to reinforce class concepts and promote collaboration among team members. Student engagement and learning have been evaluated using feedback from students and LAs collected through Discussion Boards (DBs). Preliminary findings suggest that LA-facilitated in-class activities promote active learning and enhance problem-solving skills. LAs provide valuable support and guidance to students, particularly those struggling to understand complex concepts. The study tested a working model of AIELA, an innovative AI-powered chatbot that assists human LAs in supporting students through knowledge-reinforcing questions and multimodal data analysis, powered by OpenAI API's gpt-4-turbo model. This research is a step towards embracing the challenges of modern CS education, inspiring further innovation in this critical field. The findings will benefit educators seeking innovative strategies to enrich student engagement and learning in engineering and computing disciplines.},
  keywords={Technological innovation;Analytical models;Computational modeling;Education;Active learning;Collaboration;Prototypes;Data models;Problem-solving;Springs;Learning Assistant model;active learning strategies;Artificial Intelligence-enabled chatbot;student engagement},
  doi={10.1109/FIE61694.2024.10893294},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10684453,
  author={Bai, Yu and Li, Jun and Shen, Jun and Zhao, Liang},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Investigating the Efficacy of ChatGPT-3.5 for Tutoring in Chinese Elementary Education Settings}, 
  year={2024},
  volume={17},
  number={},
  pages={2102-2117},
  abstract={The potential of artificial intelligence (AI) in transforming education has received considerable attention. This study aims to explore the potential of large language models (LLMs) in assisting students with studying and passing standardized exams, while many people think it is a hype situation. Using primary education as an example, this research investigates whether ChatGPT-3.5 can achieve satisfactory performance on the Chinese Primary School Exams and whether it can be used as a teaching aid or tutor. We designed an experimental framework and constructed a benchmark that comprises 4800 questions collected from 48 tasks in Chinese elementary education settings. Through automatic and manual evaluations, we observed that ChatGPT-3.5’s pass rate was below the required level of accuracy for most tasks, and the correctness of ChatGPT-3.5’s answer interpretation was unsatisfactory. These results revealed a discrepancy between the findings and our initial expectations. However, the comparative experiments between ChatGPT-3.5 and ChatGPT-4 indicated significant improvements in model performance, demonstrating the potential of using LLMs as a teaching aid. This article also investigates the use of the trans-prompting strategy to reduce the impact of language bias and enhance question understanding. We present a comparison of the models' performance and the improvement under the trans-lingual problem decomposition prompting mechanism. Finally, we discuss the challenges associated with the appropriate application of AI-driven language models, along with future directions and limitations in the field of AI for education.},
  keywords={Education;Artificial intelligence;Benchmark testing;Standards;Training;Question answering (information retrieval);Proposals;ChatGPT-3.5;educational intelligence (EI);large language models (LLMs);primary education},
  doi={10.1109/TLT.2024.3464560},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10714575,
  author={Kim, Nam Wook and Ko, Hyung-Kwon and Myers, Grace and Bach, Benjamin},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={ChatGPT in Data Visualization Education: A Student Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={109-120},
  abstract={Unlike traditional educational chatbots that rely on pre-programmed responses, large-language model-driven chatbots, such as ChatGPT, demonstrate remarkable versatility to serve as a dynamic resource for addressing student needs from understanding advanced concepts to solving complex problems. This work explores the impact of such technology on student learning in an interdisciplinary, project-oriented data visualization course. Throughout the semester, students engaged with ChatGPT across four distinct projects, designing and implementing data visualizations using a variety of tools such as Tableau, D3, and Vega-lite. We collected conversation logs and reflection surveys after each assignment and conducted interviews with selected students to gain deeper insights into their experiences with ChatGPT. Our analysis examined the advantages and barriers of using ChatGPT, students’ querying behavior, the types of assistance sought, and its impact on assignment outcomes and engagement. We discuss design considerations for an educational solution tailored for data visualization education, extending beyond ChatGPT’s basic interface.},
  keywords={Surveys;Visualization;Knowledge based systems;Education;Data visualization;Oral communication;Chatbots;Dynamic scheduling;Reflection;Interviews;ChatGPT;large language model;data visualization;education;project-based learning},
  doi={10.1109/VL/HCC60511.2024.00022},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{10893214,
  author={Haldar, Susmita and Pierce, Mary and Capretz, Luiz Fernando},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Assessing the Effectiveness of ChatGPT in Preparatory Testing Activities}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This innovative practice WIP paper describes a research study that explores the integration of ChatGPT into the software testing curriculum and evaluates its effectiveness compared to human-generated testing artifacts. In a Capstone Project course, students were tasked with generating preparatory testing artifacts using ChatGPT prompts, which they had previously created manually. Their understanding and the effectiveness of the Artificial Intelligence generated artifacts were assessed through targeted questions. The results, drawn from this in-class assignment at a North American community college indicate that while ChatGPT can automate many testing preparation tasks, it cannot fully replace human expertise. However, students already familiar with Information Technology at the postgraduate level, found the integration of ChatGPT into their workflow to be straightforward. The study suggests that AI can be gradually introduced into software testing education to keep pace with technological advancements.},
  keywords={Software testing;Chatbots;Artificial intelligence;North America;Information technology;Software Testing Education;ChatGPT;Black-box Testing;Product Testing;Higher Education},
  doi={10.1109/FIE61694.2024.10893214},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10427187,
  author={Ma'ruf, Harry and Aditya, Bayu Rima and Hernawati, Elis and Gunawan, Tedi and Wijayanto, Pikir Wisnu},
  booktitle={2023 8th International Conference on Information Technology and Digital Applications (ICITDA)}, 
  title={Usability Testing of ChatGPT Website as a Medium for Task Collaboration Using the System Usability Scale Method (SUS)}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={This study aims to determine the level of usability of the ChatGPT website for students at Telkom University Bandung as a means of collaborating on student assignments. ChatGPT is an Artificial Intelligence application that uses a chatbot to have human-like conversations. ChatGPT is widely used by students to help with their academic assignments, such as scientific papers, explaining the answer to a question, and even the programming language of an application. With the various uses of ChatGPT, many students at Telkom University Bandung use ChatGPT to help do their assignments. To conduct this research, the method used is System Usability Scale. This method is done by distributing questionnaires to Telkom University Bandung students totaling 102 respondents who have used ChatGPT. Consists of 15 questions for analysis. The SUS score results got 71.17, these results got the predicate “GOOD” in the Adjective Ratings assessment and “Acceptable” in the Acceptable Range. The SUS score results indicate that the ChatGPT usability level is good and can be well received by students. The analyzed questionnaire received an average answer of 3.65 which indicates that ChatGPT functions well and provides appropriate answers to student tasks. This explains that the ChatGPT website can be used well by Telkom University students in its use to assist with student assignments. This research data can be used as empirical data to develop student assignment collaboration.},
  keywords={Collaboration;Oral communication;Chatbots;Usability;Task analysis;Information technology;Testing;system usability scale;ChatGPT;student assignment},
  doi={10.1109/ICITDA60835.2023.10427187},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893132,
  author={Dickey, Ethan and Bejarano, Andres},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={GAIDE: A Framework for Using Generative AI to Assist in Course Content Development}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Contribution: This research-to-practice full paper presents “GAIDE: Generative AI for Instructional Development and Education,” introducing a pragmatic and systematic framework for employing Generative AI (GenAI) in the development of educational content. Unlike existing frameworks, GAIDE emphasizes practical applicability for educators, facilitating the creation of diverse, engaging, and academically sound materials. The novel aspect of our approach lies in its detailed methodology for integrating GenAI into curriculum design processes, thereby reducing instructors' workload and improving the quality of educational materials. Through GAIDE, we contribute a distinct, adaptable model for leveraging technological advancements in education, providing a foundational step towards more efficient and effective instructional material development. Background: The motivation for our study emerges from the increasing demand for innovative and engaging educational content, coupled with the notable rise in Generative AI (GenAI) utilization among students for academic tasks. Our investigations reveal that nearly half of students engage with GenAI tools for completing homework assignments, highlighting a significant shift in study behaviors and the potential for technology to shape educational practices. This scenario presents a dual challenge for educators: to adapt to and incorporate these emerging technologies into their teaching methodologies, not merely to keep pace with technological advancements but to leverage them in fostering a more dynamic and inclusive learning environment. This research addresses these challenges by offering a concrete, adaptable solution, aiming to reshape the landscape of educational content creation and its application across diverse learning settings. Intended Outcomes: The primary objectives of introducing GAIDE are to: 1) Streamline the course content development process for educators, 2) Foster the creation of dynamic, engaging, and varied educational materials, and 3) Demonstrate the practical utility of GenAI in enhancing instructional design, potentially setting a precedent for its adoption in diverse educational contexts. Application Design: GAIDE was conceived out of a necessity to efficiently harness GenAI's potential in education. The application design is rooted in constructivist learning theory and TPCK, emphasizing the importance of integrating technology in a manner that complements pedagogical goals and content knowledge. Our Outcomes-Based Course Design approach aids educators in crafting effective GenAI prompts and guides them through interactions with GenAI tools, both of which are critical for generating high-quality, contextually appropriate content. Findings: Preliminary evaluation of GAIDE indicates its effectiveness in mitigating the instructional challenges associated with content creation. Educators reported a significant reduction in the time and effort required to develop course materials, without compromising on the breadth or depth of the content. Moreover, the use of GenAI has shown promise in deterring conventional cheating methods, suggesting a positive impact on academic integrity and student engagement.},
  keywords={Adaptation models;Systematics;Generative AI;Shape;Education;Aerodynamics;Pragmatics;─Generative AI (GenAI);course content development;content generation framework;instructional workload reduction;instructional design;course design;faculty development},
  doi={10.1109/FIE61694.2024.10893132},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10590395,
  author={Ogunleye, Olalekan Samuel},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={ChatGPT Implications on Higher Education: Educational Apocalypse or Educational Reboot? A Developing Countries Perspective}, 
  year={2023},
  volume={},
  number={},
  pages={1685-1690},
  abstract={Artificial intelligence has disrupted many industries, and education is no exception. ChatGPT, a Large Language Model (LLM), has emerged as a promising tool for boosting learning experiences and altering traditional teaching methods in higher education. ChatGPT can be considered a combination of chat and a language model. This article investigates ChatGPT's effects on higher education, focusing on the opportunities and obstacles that may arise. This paper tries to answer whether ChatGPT will lead to an educational apocalypse or a much-needed reboot in higher education by assessing the influence of ChatGPT on educators' usage, student involvement, individualised learning, and administrative operations. In its conclusion, the article explores the prospects of incorporating ChatGPT into higher education and offers some ideas on how to do so successfully.},
  keywords={Industries;Scientific computing;Large language models;Education;Focusing;Developing countries;Chatbots;ChatGPT;Artificial Intelligence;Higher Education},
  doi={10.1109/CSCI62032.2023.00278},
  ISSN={2769-5654},
  month={Dec},}@ARTICLE{10813359,
  author={Abdelgadir Mohamed, Yasir and Mohamed, Abdul Hakim H. M. and Khanan, Akbar and Bashir, Mohamed and Adiel, Mousab A. E. and Elsadig, Muawia A.},
  journal={IEEE Access}, 
  title={Navigating the Ethical Terrain of AI-Generated Text Tools: A Review}, 
  year={2024},
  volume={12},
  number={},
  pages={197061-197120},
  abstract={This review examines the ethical, social, and technical challenges posed by AI-generated text tools, focusing on their rapid advancement and widespread adoption. An exhaustive literature search across many databases, strict inclusion/exclusion criteria, and a rigorous analysis procedure are all parts of our systematic review technique. This guarantees an impartial and complete study of the current status of AI-generated text tools. The study analyzes prominent language models, including GPT-3, GPT-4, LaMDA, PaLM, Claude, Jasper, and Llama 2, evaluating their capabilities in natural language processing and generation. The analysis reveals significant advancements, with GPT-3 demonstrating a 92% accuracy rate on standard natural language understanding benchmarks, outperforming LaMDA (88%) and PaLM (85%). To illustrate real-world implications, the review presents a case study of ChatGPT’s application in healthcare, where it achieved 80% consistency with expert opinions in assessing acute ulcerative colitis. This case highlights both the potential benefits and ethical concerns of AI in critical domains. Quantitative bias analysis shows that GPT-3 generated biased content in 15% of test cases involving sensitive topics, a higher rate than LaMDA (12%) and PaLM (10%). We provide an in-depth analysis of fairness and bias issues, particularly in image generation tasks depicting professional roles. Our research synthesizes insights from technical advancements, ethical considerations, and real-world applications across healthcare, education, and creative sectors. We address critical privacy concerns and data protection challenges, noting struggles in AI-generated text detection and investigating AI’s potential in enabling cyberattacks. We underscore the need for comprehensive governance systems and multidisciplinary cooperation. To provide a cohesive analysis of the ethical considerations surrounding AI-generated text tools, we employ a multifaceted ethical framework drawing on established theories. Utilitarianism, which seeks to maximize happiness for everyone; deontology, which places an emphasis on right and wrong; and Virtue Ethics, which analyzes the moral nature of deeds and actors, are all included in this framework. In this article, we use this approach to investigate AI ethics from a variety of angles, including privacy, prejudice, and social implications, as well as concerns of justice and fairness. Moreover, the study critically examines existing and proposed legal frameworks addressing AI ethics, identifying regulatory gaps and proposing adaptive policy recommendations to address the unique challenges posed by AI-generated text tools. Our review contributes a critical analysis of AI-generated text tools, their impacts, and the need for responsible innovation. The study provides precise guidelines for the ethical development and implementation of AI, highlighting the need to strike a balance between technical progress and ethical concerns to guarantee that AI technologies have a beneficial effect on society while protecting human values. The emergence of generative artificial intelligence (AI) signifies a substantial revolution in our methods of interacting with language and information.},
  keywords={Ethics;Artificial intelligence;Reviews;Generative AI;Analytical models;Privacy;Object recognition;Technological innovation;Search problems;Industries;Generative AI;text generation;ethics},
  doi={10.1109/ACCESS.2024.3521945},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10555768,
  author={Idialu, Oseremen Joy and Mathews, Noble Saji and Maipradit, Rungroj and Atlee, Joanne M. and Nagappan, Meiyappan},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Whodunit: Classifying Code as Human Authored or GPT-4 generated- A case study on CodeChef problems}, 
  year={2024},
  volume={},
  number={},
  pages={394-406},
  abstract={Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT, built on large language models like GPT-4, are revolutionizing how programming tasks are performed, raising questions about whether code is authored by generative AI models. Such questions are of particular interest to educators, who worry that these tools enable a new form of academic dishonesty, in which students submit AI-generated code as their work. Our research explores the viability of using code stylometry and machine learning to distinguish between GPT-4 generated and human-authored code. Our dataset comprises human-authored solutions from CodeChef and AI-authored solutions generated by GPT-4. Our classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A variant of our classifier that excludes gameable features (e.g., empty lines, whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We also evaluated our classifier on the difficulty of the programming problem and found that there was almost no difference between easier and intermediate problems, and the classifier performed only slightly worse on harder problems. Our study shows that code stylometry is a promising approach for distinguishing between GPT-4 generated code and human-authored code.},
  keywords={Codes;Focusing;Machine learning;Software;Robustness;Regulation;Task analysis;code stylometry;chatgpt;AI code;GPT-4 generated code;authorship profiling;software engineering},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{10795589,
  author={Tona, Claudia and Juárez-Ramírez, Reyes and Jiménez, Samantha and Durán, Mayra},
  booktitle={2024 12th International Conference in Software Engineering Research and Innovation (CONISOFT)}, 
  title={Exploring LLM Tools Through the Eyes of Industry Experts and Novice Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={313-321},
  abstract={At present, Large Language Models (LLM) and Generative AI models have emerged and impacted industry and society. LLMs are Artificial intelligence (AI) systems designed to understand and generate human language. The rise in popu-1arity of LLM-based systems has motivated research into their use in education, including code generation tools, automated feedback systems, and support for student software projects. The release of ChatGPT™ marked a significant milestone, providing an accessible tool for IA interaction. ChatGPT™ has gained popularity among students, not only in software areas. This study analyzes the perspectives of software engineering students and software engineers on using LLM tools such as ChatGPT™ for software development projects. In this study, we use a questionnaire to analyze different viewpoints and graphics to show the experiment results between these groups. The findings of this study are expected to provide valuable contributions to the understanding of how LLM tools are perceived in the context of software development and their potential implications for educational practices and industry standards.},
  keywords={Industries;Graphics;Technological innovation;Generative AI;Large language models;Software;Standards;Programming profession;Software engineering;Software development management;Programming Education;Generative AI;Large Language Models;Software Engineering},
  doi={10.1109/CONISOFT63288.2024.00048},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10578855,
  author={Zdravkova, Katerina and Dalipi, Fisnik and Ahlgren, Fredrik and Ilijoski, Bojan and Olsson, Tobias},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Unveiling the Impact of Large Language Models on Student Learning: A Comprehensive Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Large language models (LLMs) have achieved planetary popularity and have become accepted in higher education. On the basis of face-to-face interviews, a survey examining students' attitudes about the integration of LLM into education, and our own academic experience, we defined a realistic solution for creating assignments. It embraces essay writing as well as various aspects of computer programming. The experiments were carried out during the winter semester of academic 2023/24 at two universities from two different countries. This paper presents the experience gained in the creation of two different computer science assignments with and without the use of LLM. Comparative analysis refers on three approaches: traditional or manual assignment preparation without using any LLM; full reliance on LLMs; and a hybrid mode, depending on the amount of application of the LLM in the preparation of the assignment. The proposed solution was evaluated quantitatively, with the aim of becoming a benchmark for examining the integration of LLM studies into higher education. Findings reveal the importance of hybrid mode, as the most preferred approach among students.},
  keywords={Surveys;Large language models;Manuals;Writing;Benchmark testing;Interviews;Engineering education;Programming profession;AI learning tool;ChatGPT;large language models;higher education;practical implementation},
  doi={10.1109/EDUCON60312.2024.10578855},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10342970,
  author={Lauren, Paula and Watta, Paul},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work-in-Progress: Integrating Generative AI with Evidence-based Learning Strategies in Computer Science and Engineering Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative AI assistants are AI-powered applications that can provide personalized responses to user queries or prompts. A variety of AI assistants have recently been released, and among the most popular is OpenAI's ChatGPT. In this work-in-progress in innovative practice, we explore evidence-based learning strategies and the integration of Generative AI for computer science and engineering education. We expect this research will lead to innovative pedagogical approaches to enhance undergraduate computer science and engineering education. In particular, we describe how ChatGPT was used in two computing-based courses: a Junior-level course in database systems and a Senior-level class in mobile application development. We identify four evidence-based learning strategies: well-defined learning goals, authentic learning experiences, structured learning progression, and strategic assessment. We align these strategies with the two aforementioned courses and evaluate the usefulness of ChatGPT specifically in achieving the learning goals. Combining Generative AI with evidence-based learning has the potential to transform modern education into a more personalized learning experience.},
  keywords={Computer science;Transforms;Chatbots;Mobile communication;Database systems;Artificial intelligence;Engineering education;Generative AI;Artificial Intelligence in Education (AIEd);pedagogy},
  doi={10.1109/FIE58773.2023.10342970},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10747947,
  author={Rush, Libby and Fogle, Eli and Eden, Sarah and Urban, Alexandra D. and Tijare, Harshal and Mooney, Shannon},
  booktitle={2024 IEEE Digital Education and MOOCS Conference (DEMOcon)}, 
  title={Generative Artificial Intelligence Driving More Efficient and Effective Course Optimizations}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The purpose of this study was to explore the efficacy of Generative Artificial Intelligence (GenAI) in optimizing online degree courses to enhance student retention and performance. Within the context of online learning platforms, there is a challenge in efficiently and effectively updating course content, which can impact the quality and relevance of the experience. The aim of this pilot was to utilize GenAI to create and augment educational resources, thus improving the clarity, scaffolding, and engagement of the online degree coursework. The methods employed in this pilot study included a quasi-experimental design where a Performance-Based Admissions (PBA) degree course was selected, its content was optimized using GenAI, and the impact was measured using a Difference-in-Differences (DID) analysis comparing optimized and non-optimized courses. The results indicate a 6% increase in course pass rates and significant improvements in midterm pass rates, average final grades, and the percentage of assignments submitted on time within the optimized course. Given these results, we estimate a 3% to 13% positive impact on second term persistence if all first-term courses received a similar GenAI optimization. The impact of this study is significant, demonstrating the potential of GenAI to revolutionize educational practices by providing quickly-produced, high-quality, low-cost content that enhances student learning outcomes. It supports the shift towards student-centered learning approaches and can be particularly beneficial in resource-constrained environments. In conclusion, the study underscores the transformative role of GenAI in education and emphasizes the need for ethical and responsible use to empower students and improve learning outcomes.},
  keywords={Measurement;Ethics;Computer aided instruction;Electronic learning;Generative AI;Navigation;Engineering profession;Education;Problem-solving;Optimization;GenAI;online teaching;degrees;performance-based admissions;content optimization},
  doi={10.1109/DEMOcon63027.2024.10747947},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016479,
  author={Qadir, Junaid},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Generative AI in Undergraduate Classrooms: Lessons from Implementing a Customized GPT Chatbot for Learning Enhancement}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The advent of Generative Artificial Intelligence (GenAI) has sparked significant interest in education, offering ways to support learning, personalize student experiences, and boost engagement. Generative AI holds the promise of transforming education with personalized learning, instant feedback, and assistance with complex problem-solving. However, its integration into classrooms requires careful management due to ethical concerns, misinformation risks, and potential misuse. While many articles explore the potential of generative AI in education, empirical studies on its real-world classroom use are limited. This paper presents an experience report on deploying a customized GPT-powered chatbot at Qatar University to support learning in two undergraduate courses: Data and Computer Communications Networks (technical) and Computer Ethics. Working across these diverse courses allows a thorough analysis of generative AI's strengths and weaknesses in different academic contexts, offering a comprehensive evaluation of its applicability and effectiveness. We used a mixed-methods approach with over 100 students, collecting quantitative and qualitative data via questionnaires to assess the chatbot's impact. Findings are analyzed with established theoretical frameworks to contextualize the pedagogical impact of generative AI, aligned with UNESCO guidelines for ethical integration. This paper details the chatbot's technical customization to meet course-specific needs, provides evidence-based insights into practical challenges and opportunities, and offers strategic recommendations for effective AI-assisted pedagogy. Directions for further research are also outlined to explore and refine the role of generative AI in classroom settings. By examining two distinct courses, this study demonstrates how generative AI can be adapted across academic disciplines for more nuanced applications in education.},
  keywords={Ethics;Generative AI;Terminology;Learning (artificial intelligence);Chatbots;Reflection;Real-time systems;Problem-solving;Fake news;Guidelines;ChatGPT;generative AI;pedagogy;education},
  doi={10.1109/EDUCON62633.2025.11016479},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10410383,
  author={Shaikh, Sarang and Daudpota, Sher Muhammad and Yayilgan, Sule Yildirim and Sindhu, Sindhu},
  booktitle={2023 International Conference on Frontiers of Information Technology (FIT)}, 
  title={Exploring the potential of large-language models (LLMs) for student feedback sentiment analysis}, 
  year={2023},
  volume={},
  number={},
  pages={214-219},
  abstract={Large-language models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing (NLP) tasks, including synthetic text generation, classification, question answering, and language translation. In this paper, we explore the potential of leveraging these LLMs for sentiment analysis or opinion mining of students’ feedback about their teachers, typically collected at the end of a course. Analyzing students’ sentiments is crucial for academic decision-making. We conducted our study by employing ChatGPT, a popular LLM, to perform sentiment classification on a diverse dataset of student feedback. This dataset was collected and scientifically labeled with sentiment annotations by our experienced annotators team. Our findings demonstrate the immense promise of using LLMs in accurately classifying students’ feedback into positive, negative, or neutral sentiments. The ChatGPT model achieved an impressive overall F1-score of 88%, outperforming state-of-the-art deep learning and transformer-based models. These results show the significance of LLMs in advancing sentiment analysis in educational contexts and provide valuable insights for educators and administrators to enhance the learning experience.},
  keywords={Deep learning;Sentiment analysis;Analytical models;Chatbots;Transformers;Data models;Task analysis;chatgpt;large language models;transformers;sentiment analysis;student feedback;deep learning},
  doi={10.1109/FIT60620.2023.00047},
  ISSN={2473-7569},
  month={Dec},}@INPROCEEDINGS{10605325,
  author={Liu, Zhengyuan and Yin, Stella Xin and Lee, Carolyn and Chen, Nancy F.},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions}, 
  year={2024},
  volume={},
  number={},
  pages={1258-1265},
  abstract={Intelligent tutoring systems (ITSs) that imitate human tutors and aim to provide immediate and customized instructions or feedback to learners have shown their effectiveness in education. With the emergence of generative artificial intelligence, large language models (LLMs) further entitle the systems to complex and coherent conversational interactions. These systems would be of great help in language education as it involves developing skills in communication, which, however, drew relatively less attention. Additionally, due to the complicated cognitive development at younger ages, more endeavors are needed for practical uses. Scaffolding refers to a teaching technique where teachers provide support and guidance to students for learning and developing new concepts or skills. It is an effective way to support diverse learning needs, goals, processes, and outcomes. In this work, we investigate how pedagogical instructions facilitate the scaffolding in ITSs, by conducting a case study on guiding children to describe images for language learning. We construct different types of scaffolding tutoring systems grounded in four fundamental learning theories: knowledge construction, inquiry-based learning, dialogic teaching, and zone of proximal development. For qualitative and quantitative analyses, we build and refine a seven-dimension rubric to evaluate the scaffolding process. In our experiment on GPT-4V, we observe that LLMs demonstrate strong potential to follow pedagogical instructions and achieve self-paced learning in different student groups. Moreover, we extend our evaluation framework from a manual to an automated approach, paving the way to benchmark various conversational tutoring systems.},
  keywords={Statistical analysis;Generative AI;Large language models;Education;Manuals;Benchmark testing;Intelligent Tutoring Systems;Scaffolding;Multimodal Language Models},
  doi={10.1109/CAI59869.2024.00223},
  ISSN={},
  month={June},}@INPROCEEDINGS{10386291,
  author={Gan, Wensheng and Qi, Zhenlian and Wu, Jiayang and Lin, Jerry Chun-Wei},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Large Language Models in Education: Vision and Opportunities}, 
  year={2023},
  volume={},
  number={},
  pages={4776-4785},
  abstract={With the rapid development of artificial intelligence technology, large language models (LLMs) have become a hot research topic. Education plays an important role in human social development and progress. Traditional education faces challenges such as individual student differences, insufficient allocation of teaching resources, and assessment of teaching effectiveness. Therefore, the applications of LLMs in the field of digital/smart education have broad prospects. The research on educational large models (EduLLMs) is constantly evolving, providing new methods and approaches to achieve personalized learning, intelligent tutoring, and educational assessment goals, thereby improving the quality of education and the learning experience. This article aims to investigate and summarize the application of LLMs in smart education. It first introduces the research background and motivation of LLMs and explains the essence of LLMs. It then discusses the relationship between digital education and EduLLMs and summarizes the current research status of educational large models. The main contributions are the systematic summary and vision of the research background, motivation, and application of large models for education (LLM4Edu). By reviewing existing research, this article provides guidance and insights for educators, researchers, and policy-makers to gain a deep understanding of the potential and challenges of LLM4Edu. It further provides guidance for further advancing the development and application of LLM4Edu, while still facing technical, ethical, and practical challenges requiring further research and exploration.},
  keywords={Ethics;Analytical models;Systematics;Machine vision;Education;Educational technology;Big Data;artificial intelligence;LLMs;smart education;vision;opportunities},
  doi={10.1109/BigData59044.2023.10386291},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11023957,
  author={Kumar, Abhishek and Sankar, Sandhya and Haiduc, Sonia and Das, Partha Pratim and Chakrabarti, Partha Pratim},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={LLMs as Evaluators: A Novel Approach to Commit Message Quality Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={111-115},
  abstract={Evaluating the quality of commit messages is a challenging task in software engineering. Existing evaluation approaches, such as automatic metrics like BLEU, ROUGE and METEOR, as well as manual human assessments have notable limitations. Automatic metrics often overlook semantic relevance and context, while human evaluations are time consuming and costly. To address these challenges, we explore the potential of using Large Language Models (LLMs) as an alternative method for commit message evaluation. We conducted two tasks using state-of-the-art LLMs, GPT-4o, LLaMA 3.1 (70B and 8B), and Mistral Large, to assess their capability in evaluating commit messages. Our findings show that LLMs can effectively identify relevant commit messages and align well with human judgment, demonstrating their potential to serve as reliable automated evaluators. This study provides a new perspective on utilizing LLMs for commit message assessment, paving the way for scalable and consistent evaluation methodologies in software engineering.},
  keywords={Measurement;Large language models;Semantics;Manuals;Software reliability;Quality assessment;Meteors;Software engineering;Large Language Models;Commit Messages;Evaluation;Human Judgement},
  doi={10.1109/ICSE-NIER66352.2025.00028},
  ISSN={2832-7632},
  month={April},}@INPROCEEDINGS{10663042,
  author={Datta, Soma},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Using Generative Artificial Intelligence Tools in Software Engineering Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={This pilot study focuses on allowing students to use generative Artificial intelligence (AI) tools for their learning and assignments. Therefore, the study looks to improve the assignments to assess their learning. Students in their course have both formative and summative assessments. Both these assessments consist of writing, quizzes, and presentations. These students are both from the undergraduate and graduate levels. The study seeks to make the assessments sustainable for all teaching levels. The change in writing assessment would help to assess students better. The assignments are tested on ChatGPT and Bard to check if a student gets a passing grade using an AI tool.},
  keywords={Generative AI;Education;Learning (artificial intelligence);Writing;Chatbots;Software engineering;Generative Artificial Intelligence;Software Engineering;Assessment;AI tools},
  doi={10.1109/CSEET62301.2024.10663042},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10935410,
  author={Zhao, Lili and Yuan, Feng and Miao, Long},
  booktitle={2024 14th International Conference on Information Technology in Medicine and Education (ITME)}, 
  title={Exploration of the Reform of Programming Courses Based on Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={869-873},
  abstract={With the rapid development of artificial intelligence technology, the application of Generative AI in the field of education is becoming increasingly widespread. This article uses CiteSpace to visually analyze the development trajectory, hot trends, and cutting-edge research of artificial intelligence applications in the field of education in China. It clarifies the necessity and feasibility of integrating generative AI with education and proposes a programming course teaching reform model based on generative AI. The aim is to explore how to use generative AI technology to reform programming courses, solve many problems in traditional teaching models through student portraits, intelligent generation of teaching content, automatic evaluation of student assignments, and providing personalized learning suggestions, in order to improve education quality and students' learning efficiency.},
  keywords={Adaptive learning;Data analysis;Accuracy;Generative AI;Education;Learning (artificial intelligence);Market research;Trajectory;Information technology;Programming profession;generative AI;programming courses;curriculum reform},
  doi={10.1109/ITME63426.2024.00174},
  ISSN={2474-3828},
  month={Sep.},}@INPROCEEDINGS{10651492,
  author={Ardimento, Pasquale and Bernardi, Mario Luca and Cimitile, Marta},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Teaching UML using a RAG-based LLM}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Teaching the Unified Modelling Language (UML) is a critical task in the frame of Software Engineering courses. Teachers need to understand the students’ behavior along with their modeling activities to provide suggestions and feedback to avoid more frequent mistakes and improve their capabilities. This paper presents a novel approach for teaching the UML in Software Engineering courses, focusing on understanding and improving student behavior and capabilities during modeling activities. It introduces a cloud-based tool that captures and analyzes UML diagrams created by students during their interactions with a UML modeling tool. The key aspect of the proposal is the integration of a Retrieval Augmented Generation Large Language Model (RAG-based LLM), which generates insightful feedback for students by leveraging knowledge acquired during the modeling process.The effectiveness of this method is demonstrated through an experiment involving a substantial dataset comprising 5,120 labeled UML models. The validation process confirms the performance of the UML RAG-based LLM in providing relevant feedback related to entities and relationships in the students’ models. Additionally, a qualitative analysis highlights the user satisfaction, underscoring its potential as a valuable tool in enhancing the learning experience in software modeling education.},
  keywords={Analytical models;Accuracy;Statistical analysis;Unified modeling language;Education;Software;Robustness;Deep Learning;Generative AI;LLMs;Computing Education;UML;Software Modelling},
  doi={10.1109/IJCNN60899.2024.10651492},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10548827,
  author={Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={Using an LLM to Help with Code Understanding}, 
  year={2024},
  volume={},
  number={},
  pages={1184-1196},
  abstract={Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domainspecific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.},
  keywords={Codes;Navigation;Prototypes;Documentation;Task analysis;Web search;Software engineering;User study;LLM;Program comprehension;Information support;Developer tool},
  doi={10.1145/3597503.3639187},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10683837,
  author={Dumitran, Adrian Marius and Badea, Adrian Cǎtǎlin and Muscalu, Stefan-Gabriel},
  booktitle={2024 International Conference on INnovations in Intelligent SysTems and Applications (INISTA)}, 
  title={Evaluating the Performance of Large Language Models in Competitive Programming: A Multi-Year, Multi-Grade Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the performance of large language models (LLMs) in solving competitive programming problems from the Romanian Informatics Olympiad at the county level. Romania, a leading nation in computer science competitions, provides an ideal environment for evaluating LLM capabilities due to its rich history and stringent competition standards. We collected and analyzed a dataset comprising 304 challenges from 2002 to 2023, focusing on solutions written by LLMs in C++ and Python for these problems. Our primary goal is to understand why LLMs perform well or poorly on different tasks. We evaluated various models, including closed-source models like GPT-4 and open-weight models such as CodeLlama and RoMistral, using a standardized process involving multiple attempts and feedback rounds. The analysis revealed significant variations in LLM performance across different grades and problem types. Notably, GPT-4 showed strong performance, indicating its potential use as an educational tool for middle school students. We also observed differences in code quality and style across various LLMs.},
  keywords={Technological innovation;Codes;Large language models;Focusing;History;Intelligent systems;Informatics;Large Language Models (LLMs);Benchmark;IOI;Code Generation;AI in Education;C++;Python},
  doi={10.1109/INISTA62901.2024.10683837},
  ISSN={2768-7295},
  month={Sep.},}@INPROCEEDINGS{10684637,
  author={Liu, Yangtao and Liu, Hengyuan and Yang, Zezhong and Li, Zheng and Liu, Yong},
  booktitle={2024 IEEE 24th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={Empirical Evaluation of Large Language Models for Novice Program Fault Localization}, 
  year={2024},
  volume={},
  number={},
  pages={180-191},
  abstract={Integrating Large Language Models (LLMs) into software fault localization represents a significant advancement in improving debugging efficiency for programmers. However, novice program fault localization, which is essential for computer science education, has not been thoroughly investigated in previous studies. In contrast to industrial programs target practical functionality, novice programs primarily deal with individual algorithmic issues. The distinct logic structures between novice and industrial programs can impact how effectively LLM understand and process them. Moreover, this difference reveals the inapplicability of the Competent Programmer Hypothesis, a fundamental assumption in industrial fault localization, to novice program fault localization. Therefore, industrial methodologies are unsuitable for novice programming, emphasizing the need for our empirical studies. To fill this gap, we evaluate LLMs’ effectiveness in localizing faults for novice programs in statement level. Using the widely used novice programs dataset Codeflaws and Condefects, we compare the performance of two commercial LLMs (i.e., ChatGPT-3.5 and ChatGPT-4) and three open-source LLMs (i.e., ChatGLM3, Llama2, and Code Llama) against traditional fault localization methods, examining their accuracy and overlap. Additionally, we investigate how prompt engineering improves localization precision. Our findings show ChatGPT-4’s overall superior performance, with ChatGPT-3.5 exhibiting minor advantages in certain cases. ChatGPT-4 outperforms the traditional methods with best performance by 592% and 137% on Codeflaws and Condefects. Specifically, each method exhibits unique strengths in localizing novice programming faults. Moreover, carefully crafted prompts can improve LLMs’ precision. These insights underscore the promising potential of utilizing LLMs for fault localization in novice programming.},
  keywords={Location awareness;Codes;Accuracy;Large language models;Software algorithms;Software quality;Reliability engineering;Large Language Model;Fault Localization;Empirical Study;Novice Programming;Prompt Engineering},
  doi={10.1109/QRS62785.2024.00027},
  ISSN={2693-9177},
  month={July},}@INPROCEEDINGS{10734431,
  author={Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={102-110},
  abstract={Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4’s scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.CCS CONCEPTS• Software and its engineering → Software maintenance tools; • Applied computing → Computer-assisted instruction.},
  keywords={Software maintenance;Accuracy;Codes;Large language models;Conferences;Computational modeling;Feature extraction;Chatbots;Prompt engineering;Functional programming;ChatGPT;Education;Generative AI;Large Language Models;Prompt Engineering;Automated Grading},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10914617,
  author={Zhang, Jingying and Liu, Kang},
  booktitle={2024 8th International Symposium on Computer Science and Intelligent Control (ISCSIC)}, 
  title={JavaLLM: A Fine-Tuned LLM for Java Programming Education}, 
  year={2024},
  volume={},
  number={},
  pages={276-280},
  abstract={The integration of Large Language Models (LLMs) into education marks a significant advancement toward personalized and adaptive learning environments, particularly in programming education. Addressing the limitations of existing LLMs in specialized domains like Java programming, this paper introduces JavaLLM — a model specifically tailored for Java programming education. Built upon a robust codeLLM and fine-tuned using extensive, high-quality Java-focused datasets, JavaLLM demonstrates superior performance in code generation and Java-specific question answering. Through rigorous evaluation and iterative refinement, JavaLLM facilitates a transformative classroom experience, enhancing the quality of teaching and enabling a personalized learning journey for students in Java programming courses. This innovation paves the way for smarter, more tailored educational approaches, leveraging AI’s generative capabilities to meet the evolving demands of modern education.},
  keywords={Java;Adaptation models;Technological innovation;Codes;Large language models;Education;Question answering (information retrieval);Iterative methods;Programming profession;Intelligent control;Large Language Model;Java Education;Fine-tuning},
  doi={10.1109/ISCSIC64297.2024.00064},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10893137,
  author={Sinha, Anvit and Goyal, Shruti and Sy, Zachary and Kuperus, Rhianna and Dickey, Ethan and Bejarano, Andres},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={BoilerTAI: A Platform for Enhancing Instruction Using Generative AI in Educational Forums}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Contribution: This Full paper in the Research Category track describes a practical, scalable platform that seamlessly integrates Generative AI (GenAI) with online educational forums, offering a novel approach to augment the instructional capabilities of staff. The platform empowers instructional staff to efficiently manage, refine, and approve responses by facilitating interaction between student posts and a Large Language Model (LLM). Background: This study is anchored in Vygotsky's socio- cultural theory, with a particular focus on the concept of the More Knowledgeable Other (MKO). It examines how GenAI can augment the instructional capabilities of course staff in educational environments, acting as an auxiliary MKO to facilitate an enriched educational dialogue between students and instructors. This theoretical backdrop is important for understanding the integration of AI within educational contexts, suggesting a balanced collaboration between human expertise and artificial intelligence to enhance the learning and teaching experience. Research Question: How effective is GenAI in reducing the workload of instructional staff when used to pre-answer student questions posted on educational discussion forums? Methodology: Employing a mixed-methods approach, our study concentrated on select first and second-year computer programming courses with significant enrollments. The investigation involved the use of an AI -assisted platform by designated (human) Teaching Assistants (AI- TAs) to pre-answer student queries on educational forums. Our analysis includes a qualitative examination of feedback and interactions, focusing on the AI-TAs' experiences and perceptions. While we primarily analyzed efficiency indicators such as the frequency of modifications required to AI generated responses, we also explored broader qualitative aspects to understand the impact and reception of AI -generated responses within the educational context. This approach allowed us to gather insights into both the quantitative engagement with AI -assisted posts and the qualitative sentiments expressed by the instructional staff, laying the groundwork for further in-depth analysis. Findings: The findings indicate no significant difference in student reception to responses generated by AI - TAs compared to those provided by human instructors. This suggests that GenAl can effectively meet educational needs when adequately managed. Moreover, AI - TAs experienced a reduction in the cognitive load required for responding to queries, pointing to GenAI's potential to enhance instructional efficiency without compromising the quality of education.},
  keywords={Generative AI;Large language models;Education;Focusing;Collaboration;Learning (artificial intelligence);Programming;Cognitive load;Cultural differences;Artificial intelligence;─Educational technology [syn;E-learning];Computer science;Social cognitive theories [syn: Social learning the- ory];Instructional change;Online discussions;GenAI;Generative AI;AI-Lab;ChatGPT;More Knowledgeable Other;AI- TA},
  doi={10.1109/FIE61694.2024.10893137},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10923798,
  author={Rafiee, Gholamreza and Ahmadli, Firuza and Collins, Matthew},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Fostering Personalized Learning in Data Science: Integrating Innovative Tools and Strategies for Diverse Pathways}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper introduces an innovative teaching approach in data science tailored for students in non-computer science pathways, specifically Business Information Technology (BIT) and Computing and Information Technology (CIT). Over a five-year period, a unique teaching approach has been developed incorporating a virtual reality (VR) game event and ChatGPT-4 as a generative artificial intelligence (AI) tool. To address the inherent complexities of learning data science, particularly the diverse prerequisite skills, this study introduces a framework including a diagnostic assessment centered around a specific education research question: “How can the learning experiences of individual students be customized to address the multifaceted challenges of data science education?” Through a diagnostic assessment process, conducted via a survey completed by students, this framework identifies students' unique requirements and skill areas facilitating the delivery of personalized content recommendations within the initial week of teaching. By fostering a culture of self-directed learning, the approach aims to enable students to concentrate on essential customized learning materials. This paper also highlights the overall student satisfaction with the module averaged 4.5 out of 5 with a standard deviation of 0.9 indicating a high level of contentment with the teaching approach. The discussion encompasses the framework's implications for teaching and its alignment with educational theories. This paper contributes to the computing education field by addressing the research question and offering insights for future research and teaching practices.},
  keywords={Surveys;Generative AI;Education;Virtual reality;Games;Data science;Complexity theory;Information technology;Engineering education;Standards;Content recommendation;data science education;individualized learning experience framework;prerequisite skill identification;self-directed learning;ChatGPT-4;Virtual Reality},
  doi={10.1109/ICEED62316.2024.10923798},
  ISSN={},
  month={Nov},}@ARTICLE{10883995,
  author={Álvarez Ariza, Jonathan and Benitez Restrepo, Milena and Hernández Hernández, Carola},
  journal={IEEE Access}, 
  title={Generative AI in Engineering and Computing Education: A Scoping Review of Empirical Studies and Educational Practices}, 
  year={2025},
  volume={13},
  number={},
  pages={30789-30810},
  abstract={Since the release of diverse generative AI (GenAI) tools such as ChatGPT, Google Gemini, DALL $\cdot $ E, and GitHub Copilot, there has been much debate around the impacts and implications of these tools on education. Currently, extant literature remarks on the affordances, challenges, and opportunities of GenAI, but few studies report and analyze empirical studies and educational practices coming up by GenAI usage in learning settings. Then, in this Scoping Review (ScR) based on 146 studies retrieved from the databases SCOPUS, Web of Science (WoS), and ERIC, we analyzed the implications of integrating GenAI in engineering and computing education from K-12 to tertiary levels. We adopted an approach starting from the bibliometric features of the studies in terms of authors, cites, years, or cluster topics, and navigating to the identification of methodologies, strategies, AI literacy instruments and guidelines, learning outcomes, and students’ and teachers’ perceptions, among other features. We advocate that current educational practices in engineering and computing with GenAI can indicate to us a roadmap of its potentialities, uses, and risks from the standpoint of both teachers and students, and this could help us to create more reflexive methodologies that enhance the teaching-learning process based on the evidence. Our purpose with the outcomes and conclusions of this scoping review is to support educators, faculty members, and other stakeholders in engineering and computing education to co-create educational methodologies that articulate GenAI with curricula, AI literacy, and prompt engineering encompassing students’ learning domains such as cognitive, affective, or behavioral.},
  keywords={Artificial intelligence;Education;Ethics;Chatbots;Systematic literature review;Computational modeling;Affordances;Privacy;Plagiarism;Training;Generative AI;GenAI;GAI;artificial intelligence;AI;computer science education;engineering education;computing education;prompt engineering;AI literacy},
  doi={10.1109/ACCESS.2025.3541424},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10764896,
  author={Zhao, Jiuang and Yang, Donghao and Zhang, Li and Lian, Xiaoli and Yang, Zitian and Liu, Fang},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Enhancing Automated Program Repair with Solution Design}, 
  year={2024},
  volume={},
  number={},
  pages={1706-1718},
  abstract={Automatic Program Repair (APR) endeavors to autonomously rectify issues within specific projects, which generally encompasses three categories of tasks: bug resolution, new feature development, and feature enhancement. Despite extensive research proposing various methodologies, their efficacy in addressing real issues remains unsatisfactory. It’s worth noting that, typically, engineers have design rationales (DR) on solution— planed solutions and a set of underlying reasons—before they start patching code. In open-source projects, these DRs are frequently captured in issue logs through project management tools like Jira. This raises a compelling question: How can we leverage DR scattered across the issue logs to efficiently enhance APR?To investigate this premise, we introduce DRCodePilot, an approach designed to augment GPT-4-Turbo’s APR capabilities by incorporating DR into the prompt instruction. Furthermore, given GPT-4’s constraints in fully grasping the broader project context and occasional shortcomings in generating precise identifiers, we have devised a feedback-based self-reflective framework, in which we prompt GPT-4 to reconsider and refine its outputs by referencing a provided patch and suggested identifiers. We have established a benchmark comprising 938 issue-patch pairs sourced from two open-source repositories hosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot achieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is utilized directly. Additionally, the CodeBLEU scores also exhibit promising enhancements. Moreover, our findings reveal that the standalone application of DR can yield promising increase in the full-match ratio across CodeLlama, GPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot initiative heralds a novel human-in-the-loop avenue for advancing the field of APR.CCS CONCEPTS• Software and its engineering → Maintaining software.},
  keywords={Solution design;Computer bugs;Project management;Grasping;Maintenance engineering;Benchmark testing;Software;Human in the loop;Software engineering;Software development management;Design rationale;Issue logs;Developer discussion;Automated program repair},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10578838,
  author={Jacobs, Sven and Jaschke, Steffen},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Evaluating the Application of Large Language Models to Generate Feedback in Programming Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This study investigates the application of large language models, specifically GPT-4, to enhance programming education. The research outlines the design of a web application that uses GPT-4 to provide feedback on programming tasks, without giving away the solution. A web application for working on programming tasks was developed for the study and evaluated with 51 students over the course of one semester. The results show that most of the feedback generated by GPT-4 effectively addressed code errors. However, challenges with incorrect suggestions and hallucinated issues indicate the need for further improvements.},
  keywords={Fault diagnosis;Codes;Large language models;Task analysis;Engineering education;Programming profession},
  doi={10.1109/EDUCON60312.2024.10578838},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10937513,
  author={Moazzez, Ava and Barman, Aditya and Liang, Sarah and Katikaneni, Vibhav and Nuli, Achyut and Kandala, Vineel and Kamat, Kashi and Boicu, Mihai},
  booktitle={2024 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={Assessing the Consistency of Open-Source Large Language Models for Algorithm Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The grading of open-ended questions in education is labor-intensive and subject to human error, making it an attractive target for automation through artificial intelligence. This work explores the grading consistency of four open-source large language models (LLMs) in rubric grading algorithms on design, completeness, clarity & readability, and logic. Statistical methods revealed that Anthropic Claude was the most consistent scorer, with an average normalized standard deviation (SD) of 0.17 points and an intraclass correlation coefficient of 0.828, while Microsoft Copilot was the least consistent. The “completeness” rubric category had the lowest average SD, indicating it was graded the most consistently.},
  keywords={Hands;Codes;Statistical analysis;Large language models;Education;Internet;Logic;Time factors;Standards;Testing;large language model;consistency;rubric},
  doi={10.1109/URTC65039.2024.10937513},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10486710,
  author={Haensch, Anna-Carolina and Ball, Sarah and Herklotz, Markus and Kreuter, Frauke},
  booktitle={2023 Big Data Meets Survey Science (BigSurv)}, 
  title={Seeing ChatGPT Through Students’ Eyes: An Analysis of TikTok Data}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Advanced large language models like ChatGPT have gained considerable attention recently, including among students. However, while the debate on ChatGPT in academia is making waves, more understanding is needed among lecturers and teachers on how students use and perceive ChatGPT. To address this gap, we analyzed the content on ChatGPT available on TikTok in February 2023. TikTok is a rapidly growing social media platform popular among individuals under 30. Specifically, we analyzed the content of the 100 most popular videos in English tagged with #chatgpt, which collectively garnered over 250 million views. Most of the videos we studied promoted the use of ChatGPT for tasks like writing essays or code. In addition, many videos discussed AI detectors, with a focus on how other tools can help to transform ChatGPT output to fool these detectors. This also mirrors the discussion among educators on how to treat ChatGPT as lecturers and teachers in teaching and grading. What is, however, missing from the analyzed clips on TikTok are videos that discuss ChatGPT producing content that is nonsensical or unfaithful to the training data.},
  keywords={Surveys;Video on demand;Training data;Detectors;Transforms;Writing;Chatbots},
  doi={10.1109/BigSurv59479.2023.10486710},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10893099,
  author={Reeping, David and Shah, Aarohi},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Work-in-Progress: Students' Prompting Strategies When Solving an Engineering Design Task}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress research paper investigates how students prompt generative AI while tackling an engineering design challenge. As tools like ChatGPT become common in education, we must understand how to incorporate them into our teaching and guide students on their proper use. Although the existing literature focuses on understanding what students use generative AI tools for, less work has been done to examine students' prompting strategies when engaging with these systems. We leveraged a new brainstorming assignment in a first-year engineering course at a large Midwest public university, where students ideated collaboratively using ChatGPT for the design of their term project - a semiautonomous robot (n = 97 teams, 589 prompts). Most prompts (~50%) ranged between 55 and 95 characters, or approximately 8 to 19 words. Our initial qualitative findings suggest that their approaches center on seeking information, much like how they would use a search engine. Others directly ask the chatbot to provide alternatives for their design without providing the appropriate criteria or constraints. A subset of prompts had an evaluative component, asking ChatGPT to weigh ideas against one another. We found that 11 % of prompts included instructing ChatGPT to produce the “best” solution instead of generating multiple ideas, suggesting students focus on using the chatbot in a more convergent design process - unlike divergent thinking in brainstorming.},
  keywords={Generative AI;Heuristic algorithms;Education;Curriculum development;Search engines;Chatbots;Data mining;Particle swarm optimization;Robots;first year experience;ideation;prompting;generative AI;ChatGPT},
  doi={10.1109/FIE61694.2024.10893099},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10893324,
  author={Wiktor, Sandra and Dorodchi, Mohsen and Wiktor, Nicole},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={AI Can Help Instructors Help Students: An LLM-Supported Approach to Generating Customized Student Reflection Responses}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice paper presents an LLM-supported technique to help instructors respond effectively to periodic students' reflections. Efficient communication between instructors and students is integral to supporting a productive learning environment. Recognizing the significance of understanding students' perceptions and challenges, we present the initial implementation of a system to help instructors analyze and respond to students' feedback promptly and effectively. This research is inspired by and extends prior works where instructors sent progress check emails to students, with some works finding that such communication increased students' motivation. To collect feedback, we administer regular student reflections throughout the semester that capture how students feel about the course and uncover the challenges they face. This regular feedback-gathering approach allows instructors to better track their students' progress and respond to comments throughout the semester to provide guidance. However, reading and responding to each reflection manually in the context of their overall learning experience can be time consuming. To address this challenge, we introduce an LLM-based automated approach that generates tailored, performance-contextualized responses to student reflections that can be used to guide first-contact interventions. The generated reflection responses (GRRs) address issues discussed in student reflections and provide advice, support, course information, and follow-up questions to the students. Additionally, they provide feedback to students based on their accomplishments and behavioral data within the learning management system (LMS), such as submission patterns. In this work, we discuss our method of generating responses based on students' reflections and their LMS behavior. We also present example scenarios of the proposed approach. Preliminary results indicate that this approach can help instructors facilitate positive educational interactions with students and that the participating students view the interventions favorably, fostering a constructive learning environment. This work provides an initial presentation of our large language model-based response generation method to motivate further investigation into AI-assisted student support mechanisms},
  keywords={Learning management systems;Face recognition;Reflection;Artificial intelligence;student experience;reflection},
  doi={10.1109/FIE61694.2024.10893324},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10345949,
  author={Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Is ChatGPT Beneficial to Education? A Holistic Evaluation Framework Based on Intelligent Tutoring Systems}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The recent launch of ChatGPT by OpenAI has created a profound global impact, initiating deep questions among educators about how it might affect education, syllabi and teaching methods. Currently, the full scope of potential benefits and risks associated with ChatGPT in education remains unclear, given that its impact surpasses the level of preparation educators and institutions may have had for such a pre-trained generative AI tool. While Artificial Intelligence in Education has long been a subject of research, with a particular focus on developing Intelligent Tutoring Systems, the emergence of ChatGPT marks a distinctive advancement in this field. Unlike dedicated Intelligent Tutoring Systems, ChatGPT is readily available to a diverse spectrum of educational stakeholders, including teachers, students, schools, universities, and educational institutions. Scholars have initiated assessments of ChatGPT's effectiveness across various educational disciplines, even though ChatGPT was not explicitly designed for educational purposes. However, the widespread accessibility of ChatGPT, coupled with its extensive knowledge base, necessitates the development of comprehensive evaluation frameworks. In this paper, we introduce a holistic evaluation framework tailored for ChatGPT. This framework takes into account both soft and hard skills, and it is designed to seamlessly incorporate ChatGPT into Intelligent Tutoring Systems, making it suitable for a wide range of educational fields. By establishing a connection between ITS and ChatGPT, as they are both AI tools, we can benefit from the substantial background work achieved by previous research in ITSs to evaluate the educational influence of ChatGPT.},
  keywords={Ethics;Education;Knowledge based systems;Chatbots;Cognition;Stakeholders;ChatGPT;AI in Education;Intelligent Tutoring Systems;e-learning;Educational Evaluation Frameworks;educational software;large language models;generative AI},
  doi={10.1109/IISA59645.2023.10345949},
  ISSN={},
  month={July},}@INPROCEEDINGS{10893284,
  author={Song, Isabel Hyo Jung and Wang, Jingyi and Sunico, Rafael and Dahlstrom, Andrew},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP: Enhancing Career Preparedness Through a Software Engineering Capstone Course Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This research to practice WIP paper describes capstone projects in software engineering which effectively combine theoretical education with practical skills, fostering career development in alignment with Career Construction Theory (CCT). This paper introduces a course designed to enhance students' career readiness by incorporating Agile methodologies for soft skills development, proficiency in modern technologies like Large Language Models (LLMs), and targeted career preparation such as resume building. The course's effectiveness, evaluated through CCT adaptability for 42 students, shows a positive impact on career preparedness in three of the four dimensions. This is the first attempt to measure the impact of a capstone course on career development using CCT adaptability. While the initial results are promising, further research is crucial to fully enhance all dimensions of CCT adaptability and to explore the scalability of this study across other engineering fields, potentially transforming engineering education and career preparation on a broader scale.},
  keywords={Training;Career development;Engineering profession;Scalability;Large language models;Buildings;Project management;Engineering education;Software engineering;career development;software engineering education;capstone course;Career Construction Theory;Agile methodology;Large Language Model (LLM)},
  doi={10.1109/FIE61694.2024.10893284},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10851491,
  author={Kerimbayev, Nurassyl and Menlibay, Zhanbota and Garvanova, Magdalena and Djaparova, Saltanat and Jotsov, Vladimir},
  booktitle={2024 International Conference Automatics and Informatics (ICAI)}, 
  title={A Comparative Analysis of Generative AI Models for Improving Learning Process in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={271-276},
  abstract={This study comprehensively analyses ten advanced generative AI models including GPT-4, Microsoft Copilot, Claude, DeepSeek, Pi and others to assess their applicability in higher education for computer science students. The study uses a mixed-method approach involving qualitative and quantitative analyses to evaluate these models across four key groups: architecture, content quality, adaptability, and performance. The results show that while each model has certain strengths - such as GPT-4’s content creation capabilities and Pi’s adaptability - none is the optimal choice across all clusters. The study emphasizes the importance of aligning the choice of AI tool with specific educational goals and needs. It also emphasizes the need for continuous evaluation of AI technologies to ensure their effectiveness in dynamic educational environments. The study contributes to the growing discourse on AI in education by offering a sound framework for evaluating AI models and guiding their implementation in educational environments.},
  keywords={Computer science;Training;Adaptation models;Analytical models;Accuracy;Generative AI;Computational modeling;Education;Data models;Context modeling;generative AI;higher education;computer science;educational technologies;Evaluation of AI models},
  doi={10.1109/ICAI63388.2024.10851491},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016505,
  author={Böttcher, Axel and Thurner, Veronika and Zönnchen, Benedikt},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Concepts for Teaching Software Development in the Age of AI-Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={LLM-based tools such as ChatGPT, GitHub Copilot, and the like have already arrived in software development practice, and continue to change the way of how software is created. Students use Generative AI tools for any purpose, whether we agree with the use or not. In this paper, we argue that in order to appropriately prepare our students for professional life, we educators need to incorporate the use of these tools explicitly into the teaching and learning process, so that students will learn a systematic and professional usage of these tools. Teaching basic software development concepts to students with only little or no prior knowledge has always been a challenge. Incorporating GenAI-based tools into software development education requires some careful rethinking of teaching concepts, especially with respect to constructive alignment, i. e. aligning learning objectives, teaching and learning methods, and exams to address GenAI-based support. Based upon first observations on the usage of GenAI tools in class, in this paper we suggest and compare concepts for teaching and learning basic software development that integrate GenAI tools at different levels of intensity and at different points during a semester. From these observations, we derive recommendations both for teaching and learning settings and for corresponding assessments, for teaching software development in a constructively aligned way in the age of GenAI tools.},
  keywords={Learning systems;Systematics;Generative AI;Education;Chatbots;Software;Engineering education;Programming profession;Software development management;Generative AI;programming education;student struggle;constructive alignment},
  doi={10.1109/EDUCON62633.2025.11016505},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10893117,
  author={Simmons, Archer and Holanda, Maristela and Chamon, Christiana and Da Silva, Dilma},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={AI Generated Code Plagiarism Detection in Computer Science Courses: A Literature Mapping}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This is a full research paper. Integrity in the detection of plagiarism in students' source codes in university programming courses is a research topic for instructors and institutions seeking to improve the quality of their teaching. In particular, introductory courses such as CS1, are of paramount importance, as this is when students gain fundamental knowledge to build their future on. With the latest developments in Large Language Models (LLM) such as ChatGPT, GitHub Copilot, etc., methods of plagiarism have evolved, however methods of detection may not be capable of accurately differentiating between code generated by human and artificial intelligence (AI). In this context, this paper seeks to answer the research question: What does the current literature report on AI generated code plagiarism detection in higher education? To expand on and formulate a comprehensive answer to our research question (RQ), we have formulated six sub-questions: RQ1) How many papers were published per year by country?; RQ2) Which conferences and journals have published most papers on this subject?; RQ3) Which plagiarism detection tools were most often used prior to common AI use?; RQ4) How are educators adapting assignments to minimize the use of AI?; RQ5) Which modern methods are being deployed to specifically detect AI?; RQ6) Which data sources and languages are most prevalent in the literature? The methodology was based on a systematic literature review. Initially, we confined our search for literature to Scopus and Web of Science, however additional literature was included from Google Scholar. Inclusion criteria were applied to include documents from the years 2023 and 2024 (after the launch of ChatGPT), and only published by conferences and journals. Exclusion criteria: papers that do not focus on plagiarism and programming courses; papers that are not about the undergraduate-level; papers not written in English. We found 165 papers via Scopus and WebScience, from which the metadata were collected, resulting in 17 relevant papers selected for this work. The second step was a search in Google Scholar, where we analyzed 200 documents from 2023 (100 relevant documents) and 2024 (100 relevant documents). We used the same inclusion and exclusion criteria, however, we included the ArXiv papers, and found 9 more papers. Following this process, we have identified 26 papers to include in this literary mapping. In this paper we present the answers to these research questions and discussions about this research topic.},
  keywords={Technological innovation;Codes;Plagiarism;Source coding;Education;Chatbots;Internet;Artificial intelligence;Programming profession;Systematic literature review;programming;plagiarism detection;code;AI;academia;education;similarity;mapping},
  doi={10.1109/FIE61694.2024.10893117},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016587,
  author={Yee-King, Matthew and Fiorucci, Andrea},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Deploying Language Model-Based Assessment Support Technology in a Computer Science Degree: How Do the Academics Feel About It?}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={We present two contrasting case studies wherein we used large language model (LLM) technology to support critical elements of our work in the context of a large scale online undergraduate computer science degree. Firstly we used semantic embeddings to identify student-student collusion in exam answers. Secondly we used LLMs to generate starter drafts for exam question papers. We gathered academic staff responses to the two systems through structured interviews. We describe and use a novel, LLM-powered inductive thematic analysis methodology to tag and identify themes in the interviews. All analysis was carried out on locally hosted language models. We identified 26 themes, some shared across the two systems, others unique. The academics were largely comfortable with the use of LLM technology in assessment, the exam generator system helped to kick-start exam writing and the collusion detection tool found otherwise invisible cases. Academics emphasised the need for human oversight of such systems, but were prepared to use them as they perceived that they improved the efficiency of exam processes.},
  keywords={Computer science;Analytical models;Large language models;Computational modeling;Semantics;Writing;Question generation;Generators;Interviews;Engineering education;Large Language Models (LLMs);Student Collusion Detection;Exam Question Generation;Inductive Thematic Analysis;Assessment Efficiency;Human Oversight in AI Systems;Locally Hosted AI Models},
  doi={10.1109/EDUCON62633.2025.11016587},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10555866,
  author={Deo, Soham and Hinge, Divya and Chavan, Omkar Sandip and Olivia Wang, Yaxuan and Mkaouer, Mohamed Wiem},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Analyzing Developer-ChatGPT Conversations for Software Refactoring: An Exploratory Study}, 
  year={2024},
  volume={},
  number={},
  pages={207-211},
  abstract={In recent years, Large Language Models (LLMs) have witnessed a remarkable ascent, with OpenAI’s ChatGPT, introduced in 2022, garnering substantial attention. ChatGPT’s rapid adoption in the software development community has opened up new avenues for exploring its qualitative and quantitative impact on Developer-ChatGPT conversations. In this paper, we delve into a rich dataset from GitHub and Hacker News to perform a thorough analysis. Our objectives include characterizing the nature of these interactions and evaluating the use of ChatGPT in refactoring. To achieve these goals, we employ a combination of exploratory data analysis and data annotation, utilizing relevant keyword filters to extract pertinent information. Our examination encompasses the identification and analysis of code refactorings facilitated by ChatGPT. Through a meticulous exploration of these conversations, our goal is to illuminate the potential of ChatGPT to enhance software development practices. This research promises to provide valuable insights into the evolving role of ChatGPT in the world of software development.CCS CONCEPTS• Software Engineering → Software Quality; Refactoring.},
  keywords={Codes;Filters;Focusing;Oral communication;Software quality;Chatbots;Data mining;Refactoring documentation;ChatGPT;mining software repositories},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{11016372,
  author={Bourguet, Marie-Luce},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Decoding Student Approaches: Navigating Complex Open-Ended Engineering Problems with Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The resolution of complex open-ended problems is a core aspect of engineering practice. This study aims to explore students' approaches to using large-language models (LLM) to tackle such problems in engineering. LLMs are highly versatile tools with immense potential in education; however, their effective use to solve open-ended problems requires students to evaluate and analyse information, consider diverse perspectives, and make informed decisions. This raises important questions about students' readiness to critically and responsibly use LLMs for these tasks, as well as the role of educators in fostering critical thinking skills while integrating LLMs into engineering courses. Using a mixed inductive and deductive coding approach to analyse dialogue records with LLMs from nine students and their responses in semi-structured interviews, this study uncovers several misconceptions about LLMs that hinder their effective use. Furthermore, we propose practical strategies for designing problem-solving tasks that enhance students' understanding of LLM capabilities and guide them toward responsible, critical engagement with these tools.},
  keywords={Ethics;Accuracy;Navigation;Large language models;Cultural differences;Problem-solving;Reliability;Mirrors;Interviews;Engineering education;Large language models;Engineering education;Complex open-ended problems;Critical thinking},
  doi={10.1109/EDUCON62633.2025.11016372},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10287345,
  author={Niu, Yanmin and Xue, Han},
  journal={IEEE Access}, 
  title={Exercise Generation and Student Cognitive Ability Research Based on ChatGPT and Rasch Model}, 
  year={2023},
  volume={11},
  number={},
  pages={116695-116705},
  abstract={In the context of generative artificial intelligence (AI), AIGCP (content generation-based AI products), represented by ChatGPT, have attracted extensive attention in the field of education. This study focuses on the discipline of university operating systems and adopts the Rasch model as the theoretical foundation. By combining ChatGPT with existing question banks and using the bidirectional fine-grained table method, it compiles questions that match the corresponding abilities for three different levels of student groups. This aims to explore personalized question matching and student cognitive ability analysis methods to support personalized teaching. The research findings indicate that ChatGPT is capable of matching exercises of similar difficulty under the Rasch model, but its accuracy in generating exercise content is relatively low, and the variety of exercise content is limited. Students’ performance in overall competency requires improvement. This study aims to leverage the combined strengths of ChatGPT and traditional educational assessment methods to introduce an innovative approach to support personalized instruction. It aims to establish the routine utilization of exercise creation by ChatGPT and personalized analysis of student cognitive abilities, thereby better fulfilling the demands of education within the classroom setting.},
  keywords={Computational modeling;Chatbots;Mathematical models;Education;Analytical models;Testing;Operating systems;Generative adversarial networks;Artificial intelligence;Question answering (information retrieval);Generative artificial intelligence;Rasch model;personalized question matching;cognitive ability;operating system exercises},
  doi={10.1109/ACCESS.2023.3325741},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10734619,
  author={Kumar, Smitha S and Lones, Michael Adam and Maarek, Manuel and Zantout, Hind},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={88-93},
  abstract={Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feed-back for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.CCS CONCEPTS• Applied computing → Computer-assisted instruction; • Computing methodologies → Machine translation; Natural language generation.},
  keywords={Java;Codes;Large language models;Natural language generation;Benchmark testing;Maintenance engineering;Chatbots;Machine translation;Programming profession;Python;Large language models (LLM);GPT-4;Feedback;Java Programming;Program Repair},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10837605,
  author={Boubakri, Meryem and Nafil, Khalid},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Enhancing Student Learning in Scrum Projects with Generative AI Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This article focuses on integrating generative AI tools, particularly ChatGPT and Bard, into Scrum framework education to enhance student learning and collaboration. Drawing from feedback obtained from students, the study compares the effectiveness of these tools, highlighting ChatGPT's detailed responses and Bard's conciseness. Despite students' overall satisfaction with GAI integration, they highlighted the irreplaceable role of human educators. Areas for improvement include addressing technical issues and enhancing GAI adaptability. The students' recommendations include utilizing GAI for various tasks and providing clearer prompts and training. Moving forward, the focus should be on improving GAI tools to better comprehend context and adaptability, and exploring collaborative learning approaches. To evaluate the impact of GAI integration on student outcomes, long-term studies must be conducted. In summary, while generative AI has potential to enhance Scrum education, its incorporation should be balanced with human guidance to create dynamic and effective learning environments.},
  keywords={Training;Surveys;Technological innovation;Generative AI;Federated learning;Reviews;Instruments;Collaboration;Project management;Chatbots;Education;Scrum;ChatGPT;Bard;Generative AI;Prompting},
  doi={10.1109/ITHET61869.2024.10837605},
  ISSN={2473-2060},
  month={Nov},}@ARTICLE{10111520,
  author={Ibrahim, Hazem and Asim, Rohail and Zaffar, Fareed and Rahwan, Talal and Zaki, Yasir},
  journal={IEEE Intelligent Systems}, 
  title={Rethinking Homework in the Age of Artificial Intelligence}, 
  year={2023},
  volume={38},
  number={2},
  pages={24-27},
  abstract={The evolution of natural language processing techniques has led to the development of advanced conversational tools such as ChatGPT, capable of assisting users with a variety of activities. Media attention has centered on ChatGPT’s potential impact, policy implications, and ethical ramifications, particularly in the context of education. As such tools become more accessible, students across the globe may use them to assist with their homework. However, it is still unclear whether ChatGPT’s performance is advanced enough to pose a serious risk of plagiarism. We fill this gap by evaluating ChatGPT on two introductory and two advanced university-level courses. We find that ChatGPT receives near-perfect grades on the majority of questions in the introductory courses but has not yet reached the level of sophistication required to pass in advanced courses. Moreover, adding a few full stops or typos may fool a machine learning algorithm designed to detect ChatGPT-generated text. These findings suggest that, at least for some courses, current artificial intelligence tools pose a real threat that can no longer be overlooked by educational institutions.},
  keywords={Ethics;Machine learning algorithms;Plagiarism;Education;Media;Chatbots;Intelligent systems;Artificial intelligence},
  doi={10.1109/MIS.2023.3255599},
  ISSN={1941-1294},
  month={March},}@INPROCEEDINGS{10645934,
  author={Bakharia, Aneesha and Abdi, Solmaz},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Shaping Programming and Data Science Education: Insights from GenAI Technical Book Trends}, 
  year={2024},
  volume={},
  number={},
  pages={116-120},
  abstract={As GenAI technologies, particularly Large Language Models (LLMs), continue to revolutionize programming and data science, it is increasingly vital for educators to adapt computer science curricula. This paper presents a review of recent technical books on AI-Assisted programming and utilizes the findings to guide curriculum changes in higher education. Our analysis underscores the necessity for novel teaching strategies, emphasizing skills like problem decomposition, top-down design, and advanced debugging. Furthermore, it emphasizes the crucial expansion of curricula to encompass courses on developing applications based on LLMs, utilizing libraries such as LangChain and incorporating Retrieval Augmented Generation functionality. Our analysis reveals a significant gap in technical literature regarding the ethical and societal impacts of GenAI, highlighting the urgent need for programming curricula to evolve and equip students with the skills required to ethically develop AI-enhanced software products. This paper advocates for curriculum development that not only aligns with the latest industry trends but also contributes to research on AI-assisted coding and its future impact.},
  keywords={Ethics;Reviews;Education;Debugging;Data science;Market research;Encoding;AI-assisted programming;Programming curriculum development;Programming education;Data science education},
  doi={10.1109/ICALT61570.2024.00040},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{11016653,
  author={Mushtaq, Abdullah and Naeem, Rafay and Ghaznavi, Ibrahim and Taj, Imran and Hashmi, Imran and Qadir, Junaid},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Harnessing Multi-Agent LLMs for Complex Engineering Problem-Solving: A Framework for Senior Design Projects}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Multi-Agent Large Language Models (LLMs) are gaining attention for their ability to harness collective intelligence in complex problem-solving, decision-making, and planning tasks. This aligns with the wisdom of crowds concept, where diverse agents collectively generate effective solutions, making them well-suited for educational settings. Senior design projects, pivotal in engineering education, integrate theoretical knowledge with practical application, fostering critical thinking, teamwork, and real-world problem-solving skills. These projects often involve multidisciplinary considerations and conflicting objectives, such as optimizing technical performance while addressing ethical, social, and environmental concerns. In this paper, we explore a framework where distinct LLM agents embody expert perspectives, including problem formulation, system complexity, societal and ethical considerations, and project management. These agents engage in rich, collaborative dialogues, leveraging multi-agent system principles like coordination, cooperation, and negotiation. Prompt engineering is employed to create diverse personas, simulating human engineering teams and incorporating swarm AI principles to balance contributions efficiently. To evaluate the framework, we analyzed six senior capstone project proposals from engineering and computer science, comparing Multi-Agent and single-agent LLMs using metrics developed with engineering faculty and widely used NLP-based measures. These metrics assess technical quality, ethical considerations, social impact, and feasibility, aligning with the educational objectives of engineering design. Our findings suggest that Multi-Agent LLMs can provide a richer, more inclusive problem-solving environment compared to single-agent systems with 89% alignment with engineering-faculty scores, offering a promising tool for enhancing the educational experience of engineering and computer science students by simulating the complexity and collaboration of real-world engineering and computer science practice. By supporting senior design projects, this tool not only aids in achieving academic excellence but also prepares students for the multifaceted challenges they will face in their professional engineering careers. We have open-sourced our framework for further development and adaptation on GitHub11Copilot is available at GitHub Repository: https://github.com/AbdullahMushtaq78/Multi-Agent-SDP-Copliot.},
  keywords={Measurement;Computer science;Ethics;Large language models;Complexity theory;Teamwork;Problem-solving;Stakeholders;Engineering education;Multi-agent systems;Large Language Models;Gen AI;LLM Agents;LLM-Based Multi-Agent Systems;Multi-Agent Collaboration;Agentic AI},
  doi={10.1109/EDUCON62633.2025.11016653},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10893159,
  author={Tadimalla, Sri Yash and Maher, Mary Lou},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={AI Literacy for All: Adjustable Interdisciplinary Socio-technical Curriculum}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice paper presents a curriculum, “AI Literacy for All,” to promote an interdisciplinary under-standing of AI, its socio-technical implications, and its practical applications for all levels of education. With the rapid evolution of artificial intelligence (AI), there is a need for AI literacy that goes beyond the traditional AI education curriculum. AI literacy has been conceptualized in various ways, including public literacy, competency building for designers, conceptual understanding of AI concepts, and domain-specific upskilling. Most of these conceptualizations were established before the public release of Generative AI (Gen-AI) tools such as ChatGPT. AI education has focused on the principles and applications of AI through a technical lens that emphasizes the mastery of AI principles, the mathematical foundations underlying these technologies, and the programming and mathematical skills necessary to implement AI solutions. The non-technical component of AI literacy has often been limited to social and ethical implications, privacy and security issues, or the experience of interacting with AI. In AI Literacy for all, we emphasize a balanced curriculum that includes technical as well as non-technical learning outcomes to enable a conceptual understanding and critical evaluation of AI technologies in an interdisciplinary socio-technical context. The paper presents four pillars of AI literacy: understanding the scope and technical dimensions of AI, learning how to interact with Gen-AI in an informed and responsible way, the socio-technical issues of ethical and responsible AI, and the social and future implications of AI. While it is important to include all learning outcomes for AI education in a Computer Science major, the learning outcomes can be adjusted for other learning contexts, including, non-CS majors, high school summer camps, the adult workforce, and the public. This paper advocates for a shift in AI literacy education to offer a more interdisciplinary socio-technical approach as a pathway to broaden participation in AI. This approach not only broadens students' perspectives but also prepares them to think critically about integrating AI into their future professional and personal lives.},
  keywords={Ethics;Privacy;Navigation;Generative AI;Education;Chatbots;Security;Artificial intelligence;Programming profession;Lenses;AI literacy;AI education;Active learning;Responsible AI;Democratizing AI},
  doi={10.1109/FIE61694.2024.10893159},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10917294,
  author={Kim, Mark and Puder, Arno and Hayward, Craig and Yang, Hui},
  booktitle={2024 IEEE International Conference on Data Mining Workshops (ICDMW)}, 
  title={Foundation Models for Course Equivalency Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={300-306},
  abstract={This study investigates the potential of Large Language Models (LLMs) for evaluating course equivalency in higher education. We introduce an innovative approach that utilizes publicly available course descriptions and unmodified LLMs for pairwise course comparison. We selected Google PaLM2 and its successor, Gemini Pro v1.0, due to their accessible free-tier API and their ability to reliably generate structured data.The most challenging aspect of our methodology was extracting data from course descriptions. Nonetheless, Gemini Pro v1.0 demonstrated a serviceable ability to comprehend the context of unprocessed descriptions and effectively categorize their components. Notably, classification t asks u sing r aw text yielded better results compared to those based on extracted topics, indicating potential improvements in topic extraction.Our findings reveal that the model tends to exhibit a conservative bias, often leaning towards non-equivalence judgments. We introduced additional categories such as "unsure" and "inadequate data," which enhanced the statistical performance of the model in the equivalent/nonequivalent classes and simulated the possible decision-making processes of human advisors in ambiguous cases.This study underscores both the challenges and opportunities presented by LLMs in course equivalency evaluation. Key considerations include prompt sensitivity, computational costs, and API limitations. Future research will focus on comparing results across different models and prompt designs, exploring alternative techniques such as embeddings and instruction fine-tuning, and striving to develop a more precise and reliable course equivalency assessment system.},
  keywords={Sensitivity;Foundation models;Large language models;Computational modeling;Education;Decision making;Reliability engineering;Information retrieval;Internet;Data mining;Higher Education;Educational Data Mining;Information Extraction;Large Language Models;Course Equivalency Evaluation},
  doi={10.1109/ICDMW65004.2024.00045},
  ISSN={2375-9259},
  month={Dec},}@INPROCEEDINGS{10343247,
  author={Dos Santos, Otávio Lube and Cury, Davidson},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Challenging the Confirmation Bias: Using ChatGPT as a Virtual Peer for Peer Instruction in Computer Programming Education}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper proposes the implementation of Chat-GPT, a large language model, as a virtual peer for peer instruction in computer programming courses. The authors argue that AI tools, including ChatGPT, can bring benefits such as personalized learning, instant feedback, and active engagement to the classroom. An experiment was conducted with two groups of programming students: one receiving traditional instruction and the other utilizing the ChatGPT-based peer instruction model. Both groups were given the same programming assignments and assessments. The results indicated that the ChatGPT group outperformed the traditionally instructed group, demonstrating better programming skills and a deeper understanding of concepts. The ChatGPT group also reported higher engagement and satisfaction. However, some difficulties were observed when using ChatGPT for more abstract problems. Overall, the study highlights the effectiveness of using ChatGPT as a virtual peer to enhance active learning and student outcomes in computer programming courses, challenging biases regarding AI's potential benefits in education. The authors hope this study encourages educators to embrace AI tools in the classroom and overcome confirmation biases about their impact.},
  keywords={Codes;Computational modeling;Education;Learning (artificial intelligence);Chatbots;Encoding;Data models;peer instruction;pair programming;artificial intelligence;chatgpt},
  doi={10.1109/FIE58773.2023.10343247},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10830556,
  author={Zhang, Liang and Lin, Jionghao and Sabatini, John and Borchers, Conrad and Weitekamp, Daniel and Cao, Meng and Hollander, John and Hu, Xiangen and Graesser, Arthur C.},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Data Augmentation for Sparse Multidimensional Learning Performance Data Using Generative AI}, 
  year={2025},
  volume={18},
  number={},
  pages={145-164},
  abstract={Learning performance data, such as correct or incorrect answers and problem-solving attempts in intelligent tutoring systems (ITSs), facilitate the assessment of knowledge mastery and the delivery of effective instructions. However, these data tend to be highly sparse (80%$\sim$90% missing observations) in most real-world applications. This data sparsity presents challenges to using learner models to effectively predict learners' future performance and explore new hypotheses about learning. This article proposes a systematic framework for augmenting learning performance data to address data sparsity. First, learning performance data can be represented as a 3-D tensor with dimensions corresponding to learners, questions, and attempts, effectively capturing longitudinal knowledge states during learning. Second, a tensor factorization method is used to impute missing values in sparse tensors of collected learner data, thereby grounding the imputation on knowledge tracing (KT) tasks that predict missing performance values based on real observations. Third, data augmentation using generative artificial intelligence models, including generative adversarial network (GAN), specifically vanilla GANs and generative pretrained transformers (GPTs, specifically GPT-4o), generate data tailored to individual clusters of learning performance. We tested this systemic framework on adult literacy datasets from AutoTutor lessons developed for adult reading comprehension. We found that tensor factorization outperformed baseline KT techniques in tracing and predicting learning performance, demonstrating higher fidelity in data imputation, and the vanilla GAN-based augmentation demonstrated greater overall stability across varying sample sizes, whereas GPT-4o-based augmentation exhibited higher variability, with occasional cases showing closer fidelity to the original data distribution. This framework facilitates the effective augmentation of learning performance data, enabling controlled, cost-effective approach for the evaluation and optimization of ITS instructional designs in both online and offline environments prior to deployment, and supporting advanced educational data mining and learning analytics.},
  keywords={Data models;Imputation;Data augmentation;Generative adversarial networks;Predictive models;Tensors;Analytical models;Generative Pre-trainer transformer;Computational modeling;Adaptation models;Data augmentation;data sparsity;generative artificial intelligence (GenAI);intelligent tutoring system (ITS);learning performance data},
  doi={10.1109/TLT.2025.3526582},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10343052,
  author={Jamieson, Peter and Bhunia, Suman and Rao, Dhananjai M.},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={With ChatGPT, Do We have to Rewrite Our Learning Objectives - CASE Study in Cybersecurity}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={With the emergence of Artificial Intelligent chatbot tools such as ChatGPT and code writing AI tools such as GitHub Copilot, educators need to question what and how we should teach our courses and curricula in the future. In reality, automated tools may result in certain academic fields being deeply reduced in the number of employable people. In this work, we make a case study of cybersecurity undergrad education by using the lens of “Understanding by Design” (UbD). First, we provide a broad understanding of learning objectives (LOs) in cybersecurity from a computer science perspective. Next, we dig a little deeper into a curriculum with an undergraduate emphasis on cybersecurity and examine the major courses and their LOs for our cybersecurity program at Miami University. With these details, we perform a thought experiment on how attainable the LOs are with the above-described tools, asking the key question “what needs to be enduring concepts?” learned in this process. If an LO becomes something that the existence of automation tools might be able to do, we then ask “what level is attainable for the LO that is not a simple query to the tools?”. With this exercise, we hope to establish an example of how to prompt ChatGPT to accelerate students in their achievements of LOs given the existence of these new AI tools, and our goal is to push all of us to leverage and teach these tools as powerful allies in our quest to improve human existence and knowledge.},
  keywords={Computer science;Vocabulary;Taxonomy;Education;Writing;Chatbots;Computer security},
  doi={10.1109/FIE58773.2023.10343052},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578821,
  author={Strachan, Rebecca and Oguna, Cynthia and Oruche, Ugochukwu},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={The Postgraduate Student Perspective on Academic Misconduct in the Era of Essay Mills and Generative AI: A Case Study from Northeast England}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Globally the number of students at university has been growing with UNESCO reporting in 2023, that there are now 235 million university students across the world, double the number from 20 years ago. Higher education is now a key area of economic growth for many countries and thus has also become a target for exploitation, evidenced by the growing numbers of essay mills and similar services, and even more recently by some of the generative Artificial Intelligence (AI) tools. The UK has also seen a growth in student numbers, particularly at postgraduate and for international students. In computing for example, UK PGT student numbers have increased rapidly with the UK Higher Education Statistics Agency reporting 25,225 computing PGT students in 2019/2020 rising to 47,410 in 2021/22, with 69% of these students being classed as international. These students can find it challenging to adapt to education in the UK and can have differing levels of abilities including digital literacy. Alongside this growth, the variety/incidence of student academic misconduct (AM) has also been rising. Previous research has tended to focus on plagiarism but there is an increasing need to explore the implications arising from the widespread availability of essay mills and generative AI tools. This study aims to provide a greater understanding of AM from the perspective of the computing PGT student. Adopting a case study approach, computing PGT students (n=358) were surveyed at one UK university in Spring 2023 with a follow up focus group. The study employed two PG students as researchers and this enabled a more trusted and student-centered approach to the survey, focus group and analysis. Thematic analysis of the data from the survey (responses n=26) and focus group (n=7) show students believe AM affects academic standards and understand the reasons behind this. They believe the university is providing clear AM guidance, but have more mixed opinions on whether they think the AM process is appropriate/fair. The analysis demonstrates the need for a holistic and concerted effort between staff and students based around six main areas: assessment; educational provision; staff attitudes/support; student opportunity/motivation; student belonging/engagement; and student-friendly AM guidance/resources. Future work is building on these recommendations to create a framework and set of practical interventions to promote academic integrity, and address the current AM challenges.},
  keywords={Surveys;Economics;Generative AI;Target recognition;Engineering profession;Plagiarism;Buildings;Academic integrity;academic misconduct;student perspective;essay mills;generative AI},
  doi={10.1109/EDUCON60312.2024.10578821},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10628487,
  author={Wei, Bingyang},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Requirements are All You Need: From Requirements to Code with LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={416-422},
  abstract={The pervasive use of textual formats in the documentation of software requirements presents a great opportunity for applying large language models (LLMs) to software engineering tasks. High-quality software requirements not only enhance the manual software development process but also position organizations to fully harness the potential of the emerging LLMs technology. This paper introduces a tailored LLM for automating the generation of code snippets from well-structured requirements documents. This LLM is augmented with knowledge, heuristics, and instructions that are pertinent to the software development process, requirements analysis, object-oriented design, and test-driven development, effectively emulating the expertise of a seasoned software engineer. We introduce a “Progressive Prompting” method that allows software engineers to engage with this LLM in a stepwise manner. Through this approach, the LLM incrementally tackles software development tasks by interpreting the provided requirements to extract functional requirements, using these to create object-oriented models, and subsequently generating unit tests and code based on the object-oriented designs. We demonstrate the LLM's proficiency in comprehending intricate user requirements and producing robust design and code solutions through a case study focused on the development of a web project. This study underscores the potential of integrating LLMs into the software development workflow to significantly enhance both efficiency and quality. The tailored LLM is available at https://chat.openai.com/g/g-bahoiKzkB-software-engineer-gpt.},
  keywords={Knowledge engineering;Codes;Software design;Object oriented modeling;Refining;Software;Requirements engineering;Requirements Engineering;Large Language Models (LLMs);ChatGPT;Code Generation;Use Cases;Software Specification;Automated Software Engineering},
  doi={10.1109/RE59067.2024.00049},
  ISSN={2332-6441},
  month={June},}@BOOK{10162340,
  author={Rothman, Denis and Gulli, Antonio},
  booktitle={Transformers for Natural Language Processing: Build, train, and fine-tune deep neural network architectures for NLP with Python, Hugging Face, and OpenAI's GPT-3, ChatGPT, and GPT-4},
  year={2022},
  volume={},
  number={},
  pages={},
  abstract={OpenAI’s GPT-3, ChatGPT, GPT-4 and Hugging Face transformers for language tasks in one book. Get a taste of the future of transformers, including computer vision tasks and code writing and assistance. Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesImprove your productivity with OpenAI’s ChatGPT and GPT-4 from prompt engineering to creating and analyzing machine learning modelsPretrain a BERT-based model from scratch using Hugging FaceFine-tune powerful transformer models, including OpenAI's GPT-3, to learn the logic of your dataBook DescriptionTransformers are...well...transforming the world of AI. There are many platforms and models out there, but which ones best suit your needs? Transformers for Natural Language Processing, 2nd Edition, guides you through the world of transformers, highlighting the strengths of different models and platforms, while teaching you the problem-solving skills you need to tackle model weaknesses. You'll use Hugging Face to pretrain a RoBERTa model from scratch, from building the dataset to defining the data collator to training the model. If you're looking to fine-tune a pretrained model, including GPT-3, then Transformers for Natural Language Processing, 2nd Edition, shows you how with step-by-step guides. The book investigates machine translations, speech-to-text, text-to-speech, question-answering, and many more NLP tasks. It provides techniques to solve hard language problems and may even help with fake news anxiety (read chapter 13 for more details). You'll see how cutting-edge platforms, such as OpenAI, have taken transformers beyond language into computer vision tasks and code creation using DALL-E 2, ChatGPT, and GPT-4. By the end of this book, you'll know how transformers work and how to implement them and resolve issues like an AI detective.What you will learnDiscover new techniques to investigate complex language problemsCompare and contrast the results of GPT-3 against T5, GPT-2, and BERT-based transformersCarry out sentiment analysis, text summarization, casual speech analysis, machine translations, and more using TensorFlow, PyTorch, and GPT-3Find out how ViT and CLIP label images (including blurry ones!) and create images from a sentence using DALL-ELearn the mechanics of advanced prompt engineering for ChatGPT and GPT-4Who this book is forIf you want to learn about and apply transformers to your natural language (and image) data, this book is for you. You'll need a good understanding of Python and deep learning and a basic understanding of NLP to benefit most from this book. Many platforms covered in this book provide interactive user interfaces, which allow readers with a general interest in NLP and AI to follow several chapters. And don't worry if you get stuck or have questions; this book gives you direct access to our AI/ML community to help guide you on your transformers journey!},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803243481},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10162340},}@INPROCEEDINGS{10933867,
  author={Meza, Federico and Acevedo, Oscar and González, Matías},
  booktitle={2024 IEEE 42nd Central America and Panama Convention (CONCAPAN XLII)}, 
  title={Improving the Efficacy of an Automated Judging System in an Introductory Programming Class using a Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={There is evidence supporting that extensive practice in programming learning improves learning outcomes. Automated judging systems are commonly used as a tool to allow programming students to have access to a vast pool of exercises to improve their skills. These systems help students by assessing the correctness of their solutions. However, the feedback received is binary and limited to indicating whether the solution is correct, depending on whether the program passes all the provided test cases. Also, creating new exercises and test cases remains a demanding task for instructors.Large Language Models have recently gained popularity due to their remarkable ability to learn and generate highly proficient human language. These systems are being used in various contexts, including education.This paper presents our efforts to extend the automated judging system used in the Introduction to Programming class at the Universidad Técnica Federico Santa María in Chile. We used a commercial system supported by a Large Language Model to incorporate new functionalities into our platform. The extended system can create new programming exercises for each unit in the course and guide students’ learning by recommending exercises based on their demonstrated performance. It also provides enhanced feedback on students’ solutions to help them identify and correct their errors. In the early stages of problem-solving, the system asks students questions to ensure they fully understand the problem statement and the desired behavior of the solution. Additionally, the platform collects information that allows for a deeper analysis of students’ common mistakes and learning patterns.A preliminary evaluation of the extended system’s features shows promising results regarding the effectiveness of the mechanisms for exercise generation, guided learning, automatic verification of problem understanding, and enhanced feedback. An improvement in students’ self-efficacy was also observed.},
  keywords={Adaptive learning;Large language models;Learning automata;Problem-solving;Programming profession;automated judging system;large language model;feedback;formative evaluation;adaptive learning},
  doi={10.1109/CONCAPAN63470.2024.10933867},
  ISSN={2687-7244},
  month={Nov},}@INPROCEEDINGS{10893028,
  author={Mohammed, Crista and Sarjusingh, Wayne},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={WIP Productive Uses of Generative AI: Preliminary Findings from an Electrical and Computer Engineering Capstone Course}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={This work-in-progress, research-to-practice paper examines how students have used generative AI (GAI) productively and with permission to complete their senior capstone course in an undergraduate electrical and computer engineering program. Data were extracted from two sources: faculty lists of permissible use and student feedback. Data show that GAI was used to clarify concepts; generate bibliographies; summarize literature; write code; classify phenomena; edit written work; and produce models. Similar student use has been reported in other engineering education contexts. One striking finding is that some students elected not to use GAI. They reasoned that the capstone project was too high stakes a task to risk submitting incorrect work as they were uncertain about their command of the subject matter to confidently vet the AI's outputs. This study is part of a larger discussion on how to productively deploy GAI in classrooms. It proposes a preliminary cache of uses specific to electrical and computer engineering and it may prove useful to engineering instructors who wish to create assessment tasks that leverage GAI.},
  keywords={Codes;Generative AI;Scholarships;Computational modeling;Bibliographies;Distance measurement;Data models;Data mining;Probes;Engineering education;assessment;capstone course;electrical engineering education;generative AI},
  doi={10.1109/FIE61694.2024.10893028},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10903317,
  author={WeiminZhao and Mahmoud, Qusay H.},
  booktitle={2024 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Evaluating the Efficacy of Large Language Models in Automating Academic Peer Reviews}, 
  year={2024},
  volume={},
  number={},
  pages={1208-1213},
  abstract={This paper explores the application of large language models (LLMs) in automating the peer review process for academic papers, a critical area for enhancing the efficiency and consistency of scholarly publication. We utilized GPT-4-0125 to automatically generate reviews for 20 papers sourced from openreview.net and analyzed the AI-generated peer reviews for quality and effectiveness. The analysis includes a detailed assessment of the text properties of the reviews, such as sentiment, revealing that LLM-generated reviews tend to be more uniformly positive than their human-written counterparts. In addition, we conducted a user survey in which participants attempted to distinguish between AI-generated and human-written reviews. The survey results indicated a low correct identification rate, suggesting that participants often could not discern the origin of the review, thereby highlighting the potential of LLMs to mimic human-like review qualities. However, the study also identifies limitations in LLM's performance, particularly concerning the variability in review quality, which appears to correlate with the model's vocabulary usage of the generated content.},
  keywords={Surveys;Vocabulary;Reviews;Large language models;Machine learning;Transformers;Large language model;machine learning;peer review;generative pre-trained transformer},
  doi={10.1109/ICMLA61862.2024.00187},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{11006172,
  author={Shahriary, Amirali and Sedighi, Mohammadsaeid and Tajik, Nima and Shahinfar, Mohammadali and Asiyabar, Amirhossein Rahati},
  booktitle={2025 11th International Conference on Web Research (ICWR)}, 
  title={Assessing Large Language Models as Agile Scrum Masters: A Comparative Study of Project Planning Efficiency}, 
  year={2025},
  volume={},
  number={},
  pages={150-156},
  abstract={Agile project management has become a cornerstone of modern software development, with Scrum Masters playing a critical role in ensuring project success. The advent of large language models (LLMs) has introduced new possibilities for automating project planning tasks, raising questions about their effectiveness compared to human expertise. This study aims to evaluate the feasibility of LLMs in Agile project planning by comparing their performance against human Scrum Masters. A standardized project planning template was used to ensure uniformity across all generated plans, focusing on key Scrum principles such as task breakdown, sprint organization, and risk management. The project plans produced by both LLMs and human Scrum Masters were assessed by software engineering faculty members from the University of Tehran based on predefined evaluation criteria. The results revealed that certain LLMs, including ChatGPT and Gemini Flash 1.5, outperformed human Scrum Masters in terms of operational feasibility, task clarity, and sprint organization. However, the findings also highlighted significant variability in the effectiveness of different models, emphasizing the critical role of prompt engineering in optimizing output quality. While LLMs demonstrated their potential to enhance efficiency and scalability in structured environments, they lacked the human-centric qualities necessary for dynamic project adaptation, risk identification, and team management. This study concludes that LLMs can serve as valuable augmentation tools for Agile project management, complementing human expertise rather than replacing it. Future works should focus on integrating LLMs into dynamic, real-world Agile environments and exploring hybrid approaches that leverage both AI capabilities and human intuition.},
  keywords={Electric breakdown;Large language models;Scalability;Standards organizations;Agile project management;Organizations;Planning;Complexity theory;Prompt engineering;Scrum (Software development);Agile Project Management;Scrum;Large Language Model;Software Development;Project Planning},
  doi={10.1109/ICWR65219.2025.11006172},
  ISSN={2837-8296},
  month={April},}@INPROCEEDINGS{10343189,
  author={Morsy, Mohamed and Farraj, Abdallah and Reavis, David},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={On the Challenges and Opportunities of Using ChatGPT in Academia}, 
  year={2023},
  volume={},
  number={},
  pages={01-06},
  abstract={When it comes to advanced language models, ChatGPT, created by OpenAI, is a standout chatbot that proves to be highly effective in various academic settings. Its ability to generate responses that resemble human ones and offer detailed answers makes it a valuable resource for educational purposes. While its use has potential drawbacks, such as the risk of academic dishonesty, this paper investigates the pros and cons of implementing ChatGPT in educational settings, particularly in engineering and computer science. Through an in-depth evaluation of its effectiveness, the article suggests measures to minimize the likelihood of cheating. ChatGPT presents a promising tool for enhancing students' learning experiences in these fields. ChatGPT's implementation in academia faces many challenges as it becomes essential to consider its pros, cons, and limitations. On the positive side, students can significantly benefit from its ability to help them understand complex concepts, generate questions, and find detailed solutions for their assignments. Educators can also use ChatGPT to provide personalized learning experiences, including immediate feedback and context-based questions. However, a significant concern is the potential for academic dishonesty. Since ChatGPT can produce responses that resemble human-generated ones, students may be tempted to misuse it to cheat on their work, such as writing essays or exam answers. This poses a challenge for educators in identifying plagiarism. Additionally, there is a risk that ChatGPT could be used to create false references or provide inaccurate information. To mitigate the risk of cheating, professors can take several approaches. A possible solution is to educate students about the appropriate use of ChatGPT and incorporate it into the classroom to emphasize its educational value. Another method is to use anti-plagiarism software that can detect if ChatGPT generates the student's work. However, anti-plagiarism software may have varying degrees of success in detecting ChatGPT-generated text. Since ChatGPT creates text that can be very similar to human-generated text, it may be challenging for the software to differentiate between the two. However, some anti-plagiarism software may be designed to recognize patterns in the text that are indicative of machine-generated content, and they may flag such content as potentially plagiarized. Nevertheless, the effectiveness of anti-plagiarism software depends on the type of software being used, its capabilities, and the sophistication of the methods used to generate the text. Additionally, since ChatGPT can generate context-based and original text, it may be more challenging for anti-plagiarism software to detect plagiarism. A new transformation is required for anti-plagiarism software to detect AI-generated texts effectively. Therefore, while anti-plagiarism software may be helpful in detecting some instances of plagiarism, it may not be a foolproof method of detecting ChatGPT-generated text. In Conclusion, while ChatGPT has the potential to be a valuable tool in academia, there are potential negative implications, such as the risk of cheating. Educators must be aware of these risks and take measures to mitigate them.},
  keywords={Text recognition;Plagiarism;Grasping;Writing;Chatbots;Software;Mathematical models;ChatGPT;AI;AI detectors;Engineering Education},
  doi={10.1109/FIE58773.2023.10343189},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10838799,
  author={Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.},
  booktitle={2024 Winter Simulation Conference (WSC)}, 
  title={Understanding Optimal Interactions Between Students and A Chatbot During A Programming Task}, 
  year={2024},
  volume={},
  number={},
  pages={3106-3117},
  abstract={This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.},
  keywords={Analytical models;Large language models;Computational modeling;Education;Chatbots;Computer science education;Programming profession;Guidelines},
  doi={10.1109/WSC63780.2024.10838799},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10470521,
  author={Dean, Max and Bond, Raymond R. and McTear, Michael F. and Mulvenna, Maurice D.},
  booktitle={2023 31st Irish Conference on Artificial Intelligence and Cognitive Science (AICS)}, 
  title={ChatPapers: An AI Chatbot for Interacting with Academic Research}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={A growing and significant number of computer science related papers are being published; hence it is challenging to keep up with the latest research. This paper describes the development of a large language model (LLM) augmentation chatbot and user interface that provides responses to research queries in the domain of computer science. Around 200,000 computer science research papers from arXiv were embedded, resulting in ~11 million vectors (based on ‘chunks’ from the papers). Each vector is comprised of 384 numbers/dimensions. Technologies used include Langchain, a Vector Database, and Semantic Searching with document / query embeddings. The chatbot was tested using 30 sample questions that could be asked by computer science students across several topics and from different education levels (i.e., BSc, MSc and PhD level). The responses from this chatbot were compared with those from GPT-4. The responses with and without prompting were also compared. Readability metrics (Flesch-Kincaid and Coleman-Liau) were used to compare the responses from this LLM with GPT-4. Retrieval Augmented Generation Assessment (RAGAS), a novel LLM self-evaluation method was used to evaluate the system. We observed that the developed system provides more suitable responses to the user based on the readability level at which the questions were asked.},
  keywords={Computer science;Databases;Semantics;Knowledge based systems;Education;User interfaces;Chatbots;large language model;chatbot;retrieval augmented generation;Langchain;vector database;semantic search;GPT-4;Retrieval Augmented Generation Assessment;Readability metrics;Flesch-Kincaid;Coleman-Liau},
  doi={10.1109/AICS60730.2023.10470521},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10423681,
  author={Zdravkova, Katerina and Dalipi, Fisnik and Ahlgren, Fredrik},
  booktitle={2023 International Symposium on Computers in Education (SIIE)}, 
  title={Integration of Large Language Models into Higher Education: A Perspective from Learners}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Large language models (LLMs) are being criticized for copyright infringement, inadvertent bias in training data, a danger to human innovation, the possibility of distributing incorrect or misleading information, and prejudice. Due to their popularity among students, the introduction of many comparable apps, and the inability to resist unfair and fraudulent student usage, their educational use needs to be adapted and harmonized. The incorporation of LLMs should be defined not only by pedagogues and educational institutions, but also by students who will actively utilize them to learn and prepare assignments. In order to find out what students from two universities think and suggest about LLMs use in education, they were asked to give their contribution by answering the survey that was conducted at the beginning of the spring semester of academic 2022/23. Their feedback was quantitatively and qualitatively analyzed, showing in a better light what students think about LLMs and how and why they would use them. Based on the analysis, the authors propose an original strategy for integrating LLMs into education. The proposed approach is also adapted for those students who are not interested in using LLMs and for those who prefer the hybrid mode by combining their own research with LLMs generated recommendations. The authors expect that by implementing the proposed strategy, schools will benefit from a better education in which research, creativity, academic honesty, recognition of false information, and the ability to improve knowledge will prevail.},
  keywords={Surveys;Technological innovation;Computational modeling;Education;Training data;Resists;Springs;AI learning tool;ChatGPT;large language models;academic integrity;students’ feedback;higher education},
  doi={10.1109/SIIE59826.2023.10423681},
  ISSN={2476-2172},
  month={Nov},}@INPROCEEDINGS{10915427,
  author={Meeradevi and PJ, Sriraksha and Vishal, Rahul K and Kulkarni, Pooja S},
  booktitle={2025 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE)}, 
  title={Quantales: Bridging Realms with Quantum Generative Adversarial Networks and Transformers in Educational Content Creation}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Traditional teaching methods in Indian schools often lack engaging elements, hindering students’ full comprehension of concepts and fostering a tendency to memorize rather than understand. Existing solutions fail to provide effective visualization-based interactive learning. To address these issues, we propose an interactive application-based solution utilizing generative AI image generation models that can be used by students and teachers. Our application employs interactive story generation, allowing students to prompt creative texts and gain a deeper understanding of concepts. Trained on the school curriculum, this tool facilitates self-study, empowering students to understand complex topics independently. The application extends to classroom use, enabling teachers to incorporate interactive and application-based learning alongside traditional methods. Leveraging Quantum Generative Adversarial Networks (QGANs) and transformer-based models, the system analyses user input, extracts key elements, and creates dynamic story graphs for engaging narrative experiences. The integration of quantum computing enhances the application's capabilities, providing a novel approach to education through dynamic storytelling.In conclusion, the proposed solution seeks to bridge the gap in traditional teaching methods by introducing an innovative and interactive approach to education using Quantum Generative Adversarial Networks. This holistic solution addresses the limitations of current educational practices, offering a transformative learning experience for students and teachers alike.},
  keywords={Solid modeling;Visualization;Quantum computing;Image synthesis;Computational modeling;Education;Generative adversarial networks;Transformers;Solids;System analysis and design;Quantum Generative Adversarial Network(QGAN);Quantum Generative Learning Models(QGLMs)},
  doi={10.1109/IITCEE64140.2025.10915427},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10605388,
  author={Zhu, Gaoxia and Sudarshan, Vidya and Kow, Jason Fok and Soon Ong, Yew},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Human-Generative AI Collaborative Problem Solving Who Leads and How Students Perceive the Interactions}, 
  year={2024},
  volume={},
  number={},
  pages={680-686},
  abstract={This research investigates distinct human-generative AI collaboration types and students’ interaction experiences when collaborating with generative AI (i.e., ChatGPT) for problem-solving tasks and how these factors relate to students’ sense of agency and perceived collaborative problem solving. By analyzing the surveys and reflections of 79 undergraduate students, we identified three human-generative AI collaboration types: even contribution, human leads, and AI leads. Notably, our study shows that 77.21% of students perceived they led or had even contributed to collaborative problem-solving when collaborating with ChatGPT. On the other hand, 15.19% of the human participants indicated that the collaborations were led by ChatGPT, indicating a potential tendency for students to rely on ChatGPT. Furthermore, 67.09% of students perceived their interaction experiences with ChatGPT to be positive or mixed. We also found a positive correlation between positive interaction experience and a sense of positive agency. The results of this study contribute to our understanding of the collaboration between students and generative AI and highlight the need to study further why some students let ChatGPT lead collaborative problem-solving and how to enhance their interaction experience through curriculum and technology design.},
  keywords={Surveys;Ethics;Generative AI;Federated learning;Collaboration;Lead;Chatbots;Human-generative AI collaboration;ChatGPT;problem-solving;agency;overreliance;higher education},
  doi={10.1109/CAI59869.2024.00133},
  ISSN={},
  month={June},}@INPROCEEDINGS{10664407,
  author={Wang, Beian and Wang, Chong and Liang, Peng and Li, Bing and Zeng, Cheng},
  booktitle={2024 IEEE International Conference on Software Services Engineering (SSE)}, 
  title={How LLMs Aid in UML Modeling: An Exploratory Study with Novice Analysts}, 
  year={2024},
  volume={},
  number={},
  pages={249-257},
  abstract={Since the emergence of GPT-3, Large Language Models (LLMs) have caught the eyes of researchers, practitioners, and educators in the field of software engineering. However, there has been relatively little investigation regarding the performance of LLMs in assisting with requirements analysis and UML modeling. This paper explores how LLMs can assist novice analysts in creating three types of typical UML models: use case models, class diagrams, and sequence diagrams. For this purpose, we designed the modeling tasks of these three UML models for 45 undergraduate students who participated in a requirements modeling course, with the help of LLMs. By analyzing their project reports, we found that LLMs can assist undergraduate students as novice analysts in UML modeling tasks, but LLMs also have shortcomings and limitations that should be considered when using them.},
  keywords={Analytical models;Atmospheric modeling;Large language models;Unified modeling language;Software;Software engineering;Large Language Model;Generative AI;Require-ments Analysis;UML Modeling;ChatGPT},
  doi={10.1109/SSE62657.2024.00046},
  ISSN={},
  month={July},}@ARTICLE{11018865,
  author={Pei, Dashuai and Wu, Yiwen and He, Jianhua and Liu, Kezhong and Chen, Mozi and Xiao, Xuedou and Zhang, Shengkai and Zheng, Jiawei},
  journal={IEEE Transactions on Intelligent Transportation Systems}, 
  title={Methodology and Benchmark for Automated Driving Theory Test of Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Large Language Models (LLMs), with their strong generalization and inference capabilities, have been increasingly leveraged to address the challenges of handling corner cases in autonomous driving (AD). However, a critical unresolved issue remains: the lack of a comprehensive understanding and formal assessment of LLMs’ driving theory knowledge and practical skills. To address this issue, we propose the first dedicated driving theory test framework and benchmark for LLMs. That is a crucial yet unexplored area in the literature, particularly for safety-critical applications in autonomous driving and driver assistance. Our framework systematically evaluates LLMs’ competence in driving theory and hazard perception, akin to the official UK driving theory test, ensuring their qualification for critical driving-related tasks. To facilitate rigorous benchmarking, we construct a comprehensive dataset comprising over 700 multiple-choice questions (MCQs) and 54 hazard perception video tests sourced from the official UK driving theory examination. Additionally, we incorporate two standardized MCQ sets from the UK’s Driver and Vehicle Standards Agency (DVSA). For these two types of theoretical test items, we design tailored assessment methodologies and evaluation metrics, including accuracy, recall, precision, F1-score, real-time performance, and computational efficiency. The experimental results reveal that among all LLMs tested, only GPT-4o achieved an accuracy of 88. 21% in the MCQs test, successfully passing this component. However, in hazard perception testing, none of the evaluated models met the passing criteria under the given settings, highlighting the substantial improvements required before these models can be practically deployed for real-world driving applications. Our key insight is that the specific test questions LLMs fail to answer correctly directly reflect their deficiencies in understanding and flexibly applying traffic regulations, as well as in analyzing and responding to complex driving scenarios. This provides clear directions for future improvements.},
  keywords={Autonomous vehicles;Decision making;Hazards;Vehicles;Pipelines;Benchmark testing;Computational modeling;Navigation;Large language models;Heavily-tailed distribution;Autonomous driving;large language model;driving theory test;hazard perception test;remote driving;mobile computing},
  doi={10.1109/TITS.2025.3571213},
  ISSN={1558-0016},
  month={},}@INPROCEEDINGS{10235793,
  author={Ashraf, A. and Imam, A.},
  booktitle={8th International Conference on Computing in Engineering and Technology (ICCET 2023)}, 
  title={ChatGPT's use case for software engineers}, 
  year={2023},
  volume={2023},
  number={},
  pages={487-492},
  abstract={The chat-bot GPT-3 has been a boom in the field of tech education for the recent times. Seeing it's growth in a large scale we have tried to direct it towards seeking the ethical help of ChatGPT in our work with respect to a software student's career. In this article we have focused our study on the use of ChatGPT for software engineering students casting light upon how they can use this chat-bot to advance their careers. To do so we analyze three studies that focuses on ChatGPT's functioning in solving coding questions, potential of bug fixing and accessing logic for various mathematical problems. While many articles have already researched ChatGPT and its connection to the field of education, we have differentiated us by analyzing different studies and giving a simple yet effective conclusion to its performance in a single study which makes it easy for software engineers to understand how to best use ChatGPT to boost their careers.},
  keywords={},
  doi={10.1049/icp.2023.1537},
  ISSN={},
  month={July},}@INPROCEEDINGS{10685663,
  author={Li, Yishu and Keung, Jacky and Ma, Xiaoxue},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Integrating Generative AI in Software Engineering Education: Practical Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={49-53},
  abstract={The transformative influence of generative artificial intelligence (AI), notably large language models (LLMs), has significantly reshaped the software engineering (SE) landscape, impacting various aspects of software development within industry and academia. The imperative to integrate generative AI into educational programs arises from the necessity to furnish graduates with contemporary methodologies that enhance software quality and streamline development processes. Nevertheless, a research gap exists concerning the systematic integration of established SE education guidelines with specific course contexts to strengthen SE education through incorporating generative AI. In response to this gap, our study presents a vision for integrating generative AI into SE education, with a particular emphasis on practical integration strategies aimed at endowing students with essential competencies tailored for contemporary software development. Aligning our vision with the knowledge domains within SE education, we delineate its application across specific areas such as code generation, auto test case completion, and others. The overall objective of these proposed initiatives is to furnish students in SE with an updated and immersive learning experience, thereby addressing the evolving demands of the field.},
  keywords={Industries;Systematics;Generative AI;Large language models;Software quality;Educational technology;Software engineering;software engineering;education;generative AI;large language models;code generation;auto test case completion},
  doi={10.1109/ISET61814.2024.00019},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10628461,
  author={Krishna, Madhava and Gaur, Bhagesh and Verma, Arsh and Jalote, Pankaj},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Using LLMs in Software Requirements Specifications: An Empirical Evaluation}, 
  year={2024},
  volume={},
  number={},
  pages={475-483},
  abstract={The creation of a Software Requirements Specification (SRS) document is important for any software development project. Given the recent prowess of Large Language Models (LLMs) in answering natural language queries and generating sophisticated textual outputs, our study explores their capability to produce accurate, coherent, and structured drafts of these documents to accelerate the software development lifecycle. We assess the performance of GPT-4 and CodeLlama in drafting an SRS for a university club management system and compare it against human benchmarks using eight distinct criteria. Our results suggest that LLMs can match the output quality of an entry-level software engineer to generate an SRS, delivering complete and consistent drafts. We also evaluate the capabilities of LLMs to identify and rectify problems in a given requirements document. Our experiments indicate that GPT-4 is capable of identifying issues and giving constructive feedback for rectifying them, while CodeLlama's results for validation were not as encouraging. We repeated the generation exercise for four distinct use cases to study the time saved by employing LLMs for SRS generation. The experiment demonstrates that LLMs may facilitate a significant reduction in development time for entry-level software engineers. Hence, we conclude that the LLMs can be gainfully used by software engineers to increase productivity by saving time and effort in generating, validating and rectifying software requirements.},
  keywords={Productivity;Accuracy;Large language models;Impedance matching;Natural languages;Benchmark testing;Software;Requirements engineering;software requirements specifications;empirical research;large language models},
  doi={10.1109/RE59067.2024.00056},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10664905,
  author={Wang, Yang and McCoey, Margaret and Hu, Qian and Jalalitabar, Maryam},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Teaching Security in the Era of Generative AI: A Course Design of Security + ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={The 2023 CS curriculum by ACM, IEEE, and AAAI identifies security as an independent knowledge area that develops the “security mindset” so that students are ready for the “continual changes” in computing. Likewise, the curriculum emphasises the coverage of “uses”, and “shortcomings/pitfalls” of practical AI-tools like ChatGPT. This paper presents our endeavors to approach those goals with the design of an Information Security course. Our course design bears the following distinct features: Certificate-readiness, where we align the knowledge areas with major security/ethical hacking certificates; Coverage of ChatGPT, where the uses of ChatGPT for assisting security tasks and security issues caused by ChatGPT usage are both addressed for the first time in the teaching; “Learn defending from attackers' perspective”, where labs of both offensive and defensive natures are developed to equally sharpen ethical hacking and hardening skills, and to facilitate the discussion on legal/ethical implications; Current and Representative, where ajust-enough set of representative and/or current security topics are selected in order and covered in respective modules in the most current form. In addition, we generalize our design principles and strategies, with the hope to shed lights on similar efforts in other institutions.},
  keywords={Ethics;Generative AI;Education;Information security;Chatbots;Security;Computer crime;Security;Generative AI;ChatGPT},
  doi={10.1109/ISEC61299.2024.10664905},
  ISSN={2473-7623},
  month={March},}@BOOK{10769246,
  author={Guilmette, Aaron and Miles, Steve and Tender, Peter De},
  booktitle={Microsoft Azure AI Fundamentals AI-900 Exam Guide: Gain proficiency in Azure AI and machine learning concepts and services to excel in the AI-900 exam},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Get ready to pass the certification exam on your first attempt by gaining actionable insights into AI concepts, ML techniques, and Azure AI services covered in the latest AI-900 exam syllabus from two industry experts Key FeaturesDiscover Azure AI services, including computer vision, Auto ML, NLP, and OpenAIExplore AI use cases, such as image identification, chatbots, and moreWork through 145 practice questions under chapter-end self-assessments and mock examsPurchase of this book unlocks access to web-based exam prep resources, including mock exams, flashcards, and exam tipsBook DescriptionThe AI-900 exam helps you take your first step into an AI-shaped future. Regardless of your technical background, this book will help you test your understanding of the key AI-related topics and tools used to develop AI solutions in Azure cloud. This exam guide focuses on AI workloads, including natural language processing (NLP) and large language models (LLMs). You’ll explore Microsoft’s responsible AI principles like safety and accountability. Then, you’ll cover the basics of machine learning (ML), including classification and deep learning, and learn how to use training and validation datasets with Azure ML. Using Azure AI Vision, face detection, and Video Indexer services, you’ll get up to speed with computer vision-related topics like image classification, object detection, and facial detection. Later chapters cover NLP features such as key phrase extraction, sentiment analysis, and speech processing using Azure AI Language, speech, and translator services. The book also guides you through identifying GenAI models and leveraging Azure OpenAI Service for content generation. At the end of each chapter, you’ll find chapter review questions with answers, provided as an online resource. By the end of this exam guide, you’ll be able to work with AI solutions in Azure and pass the AI-900 exam using the online exam prep resources.What you will learnDiscover various types of artificial intelligence (AI)workloads and services in AzureCover Microsoft's guiding principles for responsible AI development and useUnderstand the fundamental principles of how AI and machine learning workExplore how AI models can recognize content in images and documentsGain insights into the features and use cases for natural language processingExplore the capabilities of generative AI servicesWho this book is forWhether you're a cloud engineer, software developer, an aspiring data scientist, or simply interested in learning AI/ML concepts and capabilities on Azure, this book is for you. The book also serves as a foundation for those looking to attempt more advanced AI and data science-related certification exams (e.g. Microsoft Certified: Azure AI Engineer Associate). Although no experience in data science and software engineering is required, basic knowledge of cloud concepts and client-server applications is assumed. },
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835885673},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769246},}@INPROCEEDINGS{10981409,
  author={Verdicchio, Michael},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Adapting Program Assessment for the Age of Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Program assessment practices not designed to account for student use of generative AI have the potential to mislead as to the perceived degree of student outcome attainment in all STEM fields. Understanding how AI tools like Chat-GPT and GitHub Copilot have impacted student approaches to problem-solving will allow us to design and deploy more effective assessment instruments and collect more meaningful data. An assessment plan structured according to ABET accreditation criteria has opportunities at several levels to make meaningful adjustments. This work summarizes recent literature and best practices in program assessment. Next, it offers suggestions for adaptations from the assessment perspective, along with the course-level perspective. Finally, a brief experience report is provided that describes efforts to account for student use of generative AI, along with example assignments, which are described from the perspective of the instructor and student. The experience is then generalized for ETC education with recommendations for other programs to follow.},
  keywords={Generative AI;Instruments;Accreditation;Problem-solving;Engineering education;Best practices;Software development management;assessment;accreditation;ABET;generative AI;performance indicators},
  doi={10.1109/EDUNINE62377.2025.10981409},
  ISSN={},
  month={March},}@INPROCEEDINGS{10554752,
  author={Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={AI-Tutoring in Software Engineering Education: Experiences with Large Language Models in Programming Assessments}, 
  year={2024},
  volume={},
  number={},
  pages={309-319},
  abstract={With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences. In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.},
  keywords={Training;Surveys;Analytical models;Scalability;Education;User interfaces;Data collection;Programming Education;Automated Programming Assessment Systems;Artificial Intelligence;ChatGPT;OpenAI;ChatBots},
  doi={10.1145/3639474.3640061},
  ISSN={2832-7578},
  month={April},}@ARTICLE{10329992,
  author={Schäfer, Max and Nadi, Sarah and Eghbali, Aryaz and Tip, Frank},
  journal={IEEE Transactions on Software Engineering}, 
  title={An Empirical Evaluation of Using Large Language Models for Automated Unit Test Generation}, 
  year={2024},
  volume={50},
  number={1},
  pages={85-105},
  abstract={Unit tests play a key role in ensuring the correctness of software. However, manually creating unit tests is a laborious task, motivating the need for automation. Large Language Models (LLMs) have recently been applied to various aspects of software development, including their suggested use for automated generation of unit tests, but while requiring additional training or few-shot learning on examples of existing tests. This paper presents a large-scale empirical evaluation on the effectiveness of LLMs for automated unit test generation without requiring additional training or manual effort. Concretely, we consider an approach where the LLM is provided with prompts that include the signature and implementation of a function under test, along with usage examples extracted from documentation. Furthermore, if a generated test fails, our approach attempts to generate a new test that fixes the problem by re-prompting the model with the failing test and error message. We implement our approach in TestPilot, an adaptive LLM-based test generation tool for JavaScript that automatically generates unit tests for the methods in a given project's API. We evaluate TestPilot using OpenAI's gpt3.5-turbo LLM on 25 npm packages with a total of 1,684 API functions. The generated tests achieve a median statement coverage of 70.2% and branch coverage of 52.8%. In contrast, the state-of-the feedback-directed JavaScript test generation technique, Nessie, achieves only 51.3% statement coverage and 25.6% branch coverage. Furthermore, experiments with excluding parts of the information included in the prompts show that all components contribute towards the generation of effective test suites. We also find that 92.8% of TestPilot's generated tests have $\leq$≤ 50% similarity with existing tests (as measured by normalized edit distance), with none of them being exact copies. Finally, we run TestPilot with two additional LLMs, OpenAI's older code-cushman-002 LLM and StarCoder, an LLM for which the training process is publicly documented. Overall, we observed similar results with the former (68.2% median statement coverage), and somewhat worse results with the latter (54.0% median statement coverage), suggesting that the effectiveness of the approach is influenced by the size and training set of the LLM, but does not fundamentally depend on the specific model.},
  keywords={Training;Test pattern generators;Documentation;Codes;Source coding;Software;Electronic mail;Test generation;JavaScript;language models},
  doi={10.1109/TSE.2023.3334955},
  ISSN={1939-3520},
  month={Jan},}@INPROCEEDINGS{10942198,
  author={Chau, Michelle and Veny and Kurniawan, Priscilla Anthonio and Gui, Anderes},
  booktitle={2024 Beyond Technology Summit on Informatics International Conference (BTS-I2C)}, 
  title={Analyzing Student Ethical Perception on ChatGPT Usage in Indonesian Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={566-571},
  abstract={This study explores the ethical implications and factors influencing ChatGPT adoption in Indonesian higher education. Indonesia presently leads Southeast Asia in ChatGPT usage due to younger generations who are quick to adopt new technology into their daily life. ChatGPT's growing role in education has resulted in numerous benefits, such as intelligent tutoring systems, personalized help, and adaptable learning experiences that have reshaped the learning process. However, students may become overly dependent on this tool, which could undermine the goal of education by weakening higher-level cognitive abilities like creativity, problem-solving, and critical thinking. This research, therefore, set out to evaluate students' knowledge, attitudes, perspectives, concerns, and ethical considerations around ChatGPT usage. Using a quantitative approach, data were collected via an online questionnaire from 512 student respondents and analysed with Partial Least Squares Structural Equation Modeling (PLS-SEM). Results showed that four of the five proposed hypotheses were supported and revealed that knowledge of ChatGPT has no significant impact on its usage, whereas students' attitudes did play a critical role. Moreover, ChatGPT usage significantly influenced students' views, concerns, and their perceptions of ethical considerations. This study provides a novel, student-centered perspective on the ethical considerations of AI in education and sparks discussion on establishing appropriate, accountable use of ChatGPT in Indonesia's higher education system.},
  keywords={Training;Ethics;Education;Chatbots;Mathematical models;Sparks;Problem-solving;Artificial intelligence;Informatics;Guidelines;AI Usage;Artificial Intelligence;ChatGPT;Indonesia Higher Education;Perceived Ethics},
  doi={10.1109/BTS-I2C63534.2024.10942198},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10398310,
  author={Chen, Li and Shimada, Atsushi},
  booktitle={2023 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Designing Worksheet for Using ChatGPT: Towards Enhancing Information Retrieval and Judgment Skills}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={This study introduces a worksheet to support students using ChatGPT for information retrieval and understanding. ChatGPT is a powerful tool; however, its value in education largely depends on how it is used. Therefore, this study aims to provide a design of a worksheet to help students assess the credibility of information through source checks, expertise, and consensus assessment alongside ChatGPT. Scoring criteria are established to determine how students use information judgment strategies through the worksheet. The worksheet and the use of ChatGPT have been introduced in computer science courses at the authors' university. Future work involves refining worksheet scoring and exploring students' use of ChatGPT and its impact on comprehension. This study proposes a potential positive use of ChatGPT in education.},
  keywords={Statistical analysis;Education;Refining;Oral communication;Chatbots;Information retrieval;Reliability;AI in education;ChatGPT;information retrieval;information judgment},
  doi={10.1109/TALE56641.2023.10398310},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10500634,
  author={do Amaral, Inês},
  booktitle={2024 IEEE World Engineering Education Conference (EDUNINE)}, 
  title={Reflection on the use of Generative Language Models as a Tool for Teaching Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Design education is undergoing a technological revolution with the integration of Chat GPT into the learning process being one of the most promising innovations. This article explores how this revolutionary technology can have an impact on the teaching of design, providing students and professors with a tool to improve creativity, efficiency and the quality. The aim of this article is to reflect on the importance of using chat GPT in the teaching of design methodology so that in the future we can outline some strategies for effectively incorporating it into the curriculum for teaching design, giving some examples of how teachers can guide students to use the technology ethically and efficiently in their processes. This represents an exciting opportunity to transform the way students learn design. With due caution, it can become a valuable tool for inspiring the next generation of designers and driving innovation in the field of design.},
  keywords={Technological innovation;Ethics;Design methodology;Education;Learning (artificial intelligence);Transforms;Reflection;Chat GPT;Design;Methodologies;Generative Artificial Intelligence Models},
  doi={10.1109/EDUNINE60625.2024.10500634},
  ISSN={},
  month={March},}@INPROCEEDINGS{10923780,
  author={Ismail, Shereen and Lynch, Jenice and Alghazo, Runna},
  booktitle={2024 IEEE 13th International Conference on Engineering Education (ICEED)}, 
  title={Enhancing STEM Education with ChatGPT: A Case Study on Developing Practice Assessments for C Programming}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={ChatGPT has proven its effectiveness as an assistance tool in the learning process for students. In this paper, an experiment was designed using ChatGPT to generate practice problems aligned with specific course objectives for a Computer Science (CS) introductory programming course, focusing on assessment questions in the form of short answer questions (SAQ) and multiple choice questions (MCQ). The paper aims to investigate how ChatGPT can assist educators in generating high quality assessment questions that align with course objectives. The evaluation is done by specialized educators. The findings demonstrate that ChatGPT offers valuable support for teachers in establishing coherent practice exam items that align with course objectives; however, caution must be used when utilizing ChatGPT to create assessment questions to ensure they are error-free and match the evaluation rubric.},
  keywords={Measurement;Electronic learning;Codes;Focusing;Chatbots;Encoding;Quality assessment;Reliability;Engineering education;Programming profession;ChatGPT;Education;C Programming Course;Computer Science;Student Assessment;E-learning},
  doi={10.1109/ICEED62316.2024.10923780},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10893530,
  author={Farhana, Effat and Wu, Fan and Shahriar, Hossain and Karmaker Santu, Shubhra Kanti and Rahman, Akond},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Challenges and Preferences of Learning Machine Learning: A Student Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper systematically identifies the perceptions of learning machine learning (ML) topics. To keep up with the ever-increasing need for professionals with ML expertise, for-profit and non-profit organizations conduct a wide range of ML-related courses at undergraduate and graduate levels. Despite the availability of ML-related education materials, there is lack of understanding how students perceive ML-related topics and the dissemination of ML-related topics. A systematic categorization of students' perceptions of these courses can aid educators in understanding the challenges that students face, and use that understanding for better dissemination of ML-related topics in courses. The goal of this paper is to help educators teach machine learning (ML) topics by providing an experience report of students' perceptions related to learning ML. We accomplish our research goal by conducting an empirical study where we deploy a survey with 83 students across five academic institutions. These students are recruited from a mixture of undergraduate and graduate courses. We apply a qualitative analysis technique called open coding to identify challenges that students encounter while studying ML-related topics. Using the same qualitative analysis technique we identify quality aspects do students prioritize ML-related topics. From our survey, we identify 11 challenges that students face when learning about ML topics, amongst which data quality is the most frequent, followed by hardware-related challenges. We observe the majority of the students prefer hands-on projects over theoretical lectures. Furthermore, we find the surveyed students to consider ethics, security, privacy, correctness, and performance as essential considerations while developing ML-based systems. Based on our findings, we recommend educators who teach ML-related courses to (i) incorporate hands-on projects to teach ML-related topics, (ii) dedicate course materials related to data quality, (iii) use lightweight virtualization tools to showcase computationally intensive topics, such as deep neural networks, and (iv) empirical evaluation of how large language models can be used in ML-related education.},
  keywords={Surveys;Privacy;Ethics;Systematics;Data integrity;Education;Machine learning;Security;Virtualization;Faces;artifical intelligence;empirical study;machine learning;perception},
  doi={10.1109/FIE61694.2024.10893530},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578869,
  author={Palacios-Alonso, Daniel and Urquiza-Fuentes, Jaime and Velázquez-Iturbide, J. Ángel and Guillén-García, Julio},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Experiences and Proposals of Use of Generative AI in Advanced Software Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={The last year, we have witnessed the popularization of generative artificial intelligence. Its output includes text, code, image, audio, speech, voice, music, and video. Therefore, it impacts education courses where students are required to elaborate on any of these artifacts. In particular, the generation of code affects informatics courses, where assignments usually ask students to develop and deliver programming code. The impact of generative artificial intelligence on informatics courses has been mainly studied for introductory programming courses. These studies have shown that generative artificial intelligence is able to produce highly sophisticated programs, but also that its results and rationale can be inaccurate. Moreover, the impact of generative artificial intelligence has not been studied for other informatics subjects. In this paper, we present our preliminary experience and proposals on three advanced software courses, namely video games, advanced algorithms and language processors. For the video games course, we present the opportunities of use of generative artificial intelligence and the results of a survey conducted with students on their use to obtain different media products. For the algorithms course, we present the result of a session driven by the instructor on different design techniques, showing the merits and demerits of the answers generated. For the language processors course, a proposal of use of generative artificial intelligence is presented, broken down into the parts of a typical language processor. The paper concludes with some suggestions for instructors.},
  keywords={Surveys;Video games;Program processors;Codes;Generative AI;Software algorithms;Software;informatics education;generative artificial intelligence;video games;advanced algorithms;language processors},
  doi={10.1109/EDUCON60312.2024.10578869},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10578746,
  author={Styve, Arne and Virkki, Outi T. and Naeem, Usman},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Developing Critical Thinking Practices Interwoven with Generative AI Usage in an Introductory Programming Course}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={Software development has evolved significantly. In the past, developers were required to have comprehensive understanding of programming languages, algorithms, and computer architecture. However, with the emergence of the Internet, software libraries, frameworks, and forums became widely available, which utilize reusable software components that can reduce development time and costs. The advent of Generative Artificial Intelligence (AI) tools, such as ChatGPT, GitHub Copilot, and Amazon CodeWhisperer, has further enhanced the developer's toolkit, as these tools can be used for a wide variety of tasks such as code generation, documentation, commenting and reviewing. As programming is often slow and requires trial and error, novice programmers can be tempted to apply the first solution found on the Internet or proposed by an AI tool without much critical reflection or notion of responsibility. Hence, the advances of AI have raised both excitement and concerns among Information Technology (IT)/Computer Science (CS) students and educators. Yet, AI tools are here to stay, and students must learn to use them responsibly. The aim of this paper is to investigate how to design learning activities that introduce Generative AI tools (GitHub Copilot and ChatGPT) for programming while promoting critical thinking practices among students in an introductory programming course in the first semester. Students' opinions and customs were surveyed before and after the AI-based programming assignment. The results indicate that students' awareness of the possibilities and limitations of AI, as well as practices of critical thinking in programming increased. This is encouraging as critical thinking is an integral part of best programming practices.},
  keywords={Software libraries;Generative AI;Software algorithms;Chatbots;Software;Reflection;Internet;Generative AI;Critical Thinking;Higher Education;CS1},
  doi={10.1109/EDUCON60312.2024.10578746},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10094133,
  author={Kovačević, Darko},
  booktitle={2023 22nd International Symposium INFOTEH-JAHORINA (INFOTEH)}, 
  title={Use of ChatGPT in ESP Teaching Process}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The emergence of ChatGPT, a chatbot launched by OpenAI in November 2022, opened a large amount of opportunities for using the artificial intelligence (AI) for dealing with creation and processing of textual materials, including the use in teaching and learning of foreign languages at all educational and age levels. In terms of the teaching process regarding English for Specific Purposes (ESP), Chat GPT can be used as an effective and time-saving tool for various aspects of preparation and implementation of teaching units and evaluation of students’ written assignments, and that is the topic that will be presented end elaborated in the central part of the paper. Before that, an introduction regarding AI, its use in education and language teaching and learning, ESP and ChatGPT will be made. The final part of the paper will contain the conclusions relating the overall use of this AI tool in teaching ESP.},
  keywords={Vocabulary;Navigation;Education;Machine learning;Learning (artificial intelligence);Chatbots;Software;English for Specific Purposes (ESP);ChatGPT;artificial intelligence (AI);teaching process;text},
  doi={10.1109/INFOTEH57020.2023.10094133},
  ISSN={2767-9470},
  month={March},}@INPROCEEDINGS{10578748,
  author={Martins Ferreira, José Manuel},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Strategy for AI-Supplemented Teaching and Learning}, 
  year={2024},
  volume={},
  number={},
  pages={01-10},
  abstract={This paper presents a strategy designed to evaluate AI-supplemented teaching and learning in a course belonging to a master program in Computer Science at the University of South-Eastern Norway. The strategy was closely related to the delivery format adopted in this program, where students take only one course at a time. Each course lasts for 6 weeks, comprising an initial “reading week”, an “intensive lectures” week, a 3-week “project assignment”, and one “assessment week”. The university supported the cost of OpenAI Plus account subscriptions offered to each student while the course was running, and specific activities were proposed to the class exploring the different ways in which AI tutoring could be used during each one of the 4 phases included in the course work plan. The strategy can be adapted to other program delivery formats by redistributing the proposed activities in accordance with the planned sequence of learning activities. It is also independent of which generative AI tool is selected, although OpenAI Plus accounts allow access to specific features that offer relevant pedagogical benefits, e.g., a simple process to create private language models that are easily customizable to each course subject.},
  keywords={Costs;Generative AI;Operating systems;Education;Intellectual property;Writing;Chatbots;generative AI;teaching and learning model},
  doi={10.1109/EDUCON60312.2024.10578748},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10578789,
  author={Balart, Trini and Shryock, Kristi J.},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Work in Progress: Empowering Engineering Education With ChatGPT: A Dive into the Potential and Challenges of Using AI for Tutoring}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This research explores the integration of ChatGPT, an advanced AI language model, in engineering and computer science education. It investigates ChatGPT's effectiveness in enhancing learning outcomes, engagement, and skill development among first-year engineering students. Utilizing a mixed-method approach in an introductory programming course, the study compares the impact of ChatGPT, traditional teaching assistant support, and a combined method on student performance and perceptions. Anticipated findings aim to illuminate the benefits and challenges of AI tutoring, focusing on personalized learning experiences and ethical considerations in AI integration. This research contributes to the discourse on AI in education, highlighting its potential to transform educational practices and outcomes in engineering and computer science fields.},
  keywords={Ethics;Generative AI;Computational modeling;Scalability;Focusing;Transforms;Chatbots;Engineering education;Artificial intelligence;Computer science education;Educational technology;Intelligent tutoring system;Educational programs;Curriculum development},
  doi={10.1109/EDUCON60312.2024.10578789},
  ISSN={2165-9567},
  month={May},}@ARTICLE{10681094,
  author={Ahmed, Zishan and Shanto, Shakib Sadat and Rime, Most. Humayra Khanom and Morol, Md. Kishor and Fahad, Nafiz and Hossen, Md. Jakir and Abdullah-Al-Jubair, Md.},
  journal={IEEE Access}, 
  title={The Generative AI Landscape in Education: Mapping the Terrain of Opportunities, Challenges, and Student Perception}, 
  year={2024},
  volume={12},
  number={},
  pages={147023-147050},
  abstract={Generative AI (GAI) technologies like ChatGPT are permanently changing academic education. Their integration opens up vast opportunities for bespoke learning and better student interaction but also brings about academic honesty issues and the application of real-life educators. This study aims to fill the literature gap regarding the use of multiple GAI tools and their effect on academic outcomes via a comprehensive review. A systematic literature review was performed following PRISMA guidelines to synthesize results on the potential and drawbacks of GAI in educational domains. We included theoretical and empirical papers that used qualitative, quantitative, or mixed-methods study designs. We have also explored conceptual frameworks and the most creative AI applications with a special emphasis on uniqueness and practicability. Experiences, and Perceptions Concerning To compile the information needed we gathered insights into what students were going through by conducting the survey which contains 200 respondents of undergraduate university students gathering insights into the college students’ experiences and perceptions related to GAI used for educational purposes. At the basic level, GAI comprises areas like personalization, task automation, teacher assistance, and efficiency among others, and respective solutions for the immersion of a learner in learning processes to reform directions. However, it generates plenty of challenges such as the question of assessment integrity, the risk that too much automated grading could overwhelm educational value, and relevantly the veracity of AI-generated content as well as the potential disruption to skills like critical thinking, in addition to data privacy and ethical issues. Student Perception Survey the text also indicates that most students, as per the student perception survey found AI systems useful in academic support. However, they also know the other side of the coin and are very familiar with the technology constraints and challenges.},
  keywords={Education;Generative AI;Artificial intelligence;Surveys;Chatbots;Ethics;Market research;Chatbots;education;generative AI;opportunities and challenges;student perception},
  doi={10.1109/ACCESS.2024.3461874},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10633247,
  author={Orenstrakh, Michael Sheinman and Karnalim, Oscar and Suárez, Carlos Aníbal and Liut, Michael},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Detecting LLM-Generated Text in Computing Education: Comparative Study for ChatGPT Cases}, 
  year={2024},
  volume={},
  number={},
  pages={121-126},
  abstract={Due to the recent improvements and wide availability of Large Language Models (LLMs), they have posed a serious threat to academic integrity in education. Modern LLM-generated text detectors attempt to combat the problem by offering educators with services to assess whether some text is LLM-generated. In this work, we have collected 124 submissions from computer science students before the creation of ChatGPT. We then generated 40 ChatGPT submissions. We used this data to evaluate eight publicly-available LLM-generated text detectors through the measures of accuracy, false positives, and resilience. Our results find that Copy Leaks is the most accurate LLM-generated text detector, G PTKit is the best LLM-generated text detector to reduce false positives, and GLTR is the most resilient LLM-generated text detector. We note that all LLM-generated text detectors are less accurate with code, other languages (aside from English), and after the use of paraphrasing tools.},
  keywords={Measurement;Accuracy;Plagiarism;Large language models;Education;Detectors;Chatbots;Large Language Models;ChatGPT;GPT;AI Detectors;Plagiarism;Academic Integrity},
  doi={10.1109/COMPSAC61105.2024.00027},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{9998298,
  author={Aydın, Nazif and Erdem, O. Ayhan},
  booktitle={2022 3rd International Informatics and Software Engineering Conference (IISEC)}, 
  title={A Research On The New Generation Artificial Intelligence Technology Generative Pretraining Transformer 3}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In the digitalizing world, Artificial Intelligence (AI) paves the way for the automation of routine work done by humans and makes life easier. Recently, there is no area where AI and its applications are not used in daily life, from health to education, from transportation to energy, and from agriculture to tourism. AI applications are making rapid progress in the direction of important and current developments, especially in Natural Language Processing (NLP) and Deep Learning (DL). A concrete example of progress in these areas is the GPT-3 (Generative Pre-trained Transformer 3) language model. AI-assisted GPT-3 technology is the DL model that is effectively used in many NLP fields, which can produce long and consistent content similar to the texts written by people using pre-trained algorithms. The GPT-3 architecture has reached a level that can compete with people in many areas by producing optimum solutions for all kinds of inputs by using the Transformer-based language model, which is an attention-based deep learning technique. This article aims to convey the efficiency, structure and potential of the Transformer-assisted GPT-3 model, which is one of the most up-to-date NLP technologies, to the reader. Since the number of Turkish studies in the field of GPT-3 AI is quite limited, it is considered that this study will contribute to the literature in terms of both quantity and quality. In addition, the performance parameters of the model were examined by making a customized fine-tuned sample application in the beta version of the GPT-3 model.},
  keywords={Deep learning;Automation;Education;Transportation;Computer architecture;Transformers;Natural language processing;Artificial Intelligence;Natural Language Processing;Deep Learning;Transformer;GPT-3},
  doi={10.1109/IISEC56263.2022.9998298},
  ISSN={},
  month={Dec},}
@INPROCEEDINGS{10850830,
  author={Kormaník, Tomáš and Gabonai, Michal Gabonai and Porubän, Jaroslav},
  booktitle={2024 International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={Using Machine Learning Concepts with ControlNet for Educational Advancements}, 
  year={2024},
  volume={},
  number={},
  pages={350-355},
  abstract={Machine learning has become recognized as an important field that is rapidly changing the entire world. Machine learning education primarily targets older students, with little consideration paid to their motivation or participation. This research project considers the integration of ControlNet, a neural network framework for picture production, into Python machine learning applications to enhance student learning via immediately apparent visual feedback. By leveraging ControlNet together with the generative model Stable Diffusion, students can observe the immediate effects of changes in source code on generated images, thereby reducing the gap between theoretical understanding and practical application. This approach promotes student engagement and offers a dynamic platform for studying fundamental machine learning principles, including classification, regression, and model training. The research presented here explains the implementation process, technical obstacles, and advantages of integrating ControlNet into learning environments, giving insights into its potential as an innovative pedagogical instrument. Student feedback and testing reveal that visualbased learning can enhance comprehension and retention of machine learning concepts, rendering this method of teaching an interesting direction for a further look in informatics education.},
  keywords={Training;Visualization;Instruments;Source coding;Scalability;Education;Machine learning;Rendering (computer graphics);Problem-solving;Testing;Education;ControlNet;Stable Diffusion;Machine Learning},
  doi={10.1109/ICETA63795.2024.10850830},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11016556,
  author={Theissler, Andreas and Klaiber, Marco and Gerschner, Felix and Ritzer, Philip and Wang, Jie},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engaging Students in Scientific Writing: The STRaWBERRY Checklist Framework with LLM-based Paper Draft Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Writing scientific papers is essential for advancing any given research field, yet undergraduate and graduate students often struggle with this task, facing challenges in clearly presenting their ideas and results. Valuable scientific contributions described in papers that are not well-structured and not easy to follow may not get published. This paper addresses these challenges by proposing a framework called STRaWBERRY, which provides a checklist-based guide to help evaluate individual components of paper drafts against essential quality criteria. Additionally, we propose the use of Large Language Models (LLMs) to automate the assessment based on these criteria. The LLM evaluation process encourages active learning (in the educational sense) and allows the drafts to be iteratively refined through feedback from the LLM. We evaluate the STRaWBERRY framework by its use in lectures and the corresponding outcome: STRaWBERRY has been successfully used in 10 university courses, leading to multiple student pub-lications. Furthermore, we evaluate the LLM-based approach by assessing its accuracy in evaluating a selection of sample papers, demonstrating its potential to supplement and enhance traditional proofreading cycles.},
  keywords={Visualization;Accuracy;Large language models;Conferences;Active learning;Buildings;Writing;Engineering education;Guidelines;scientific writing;guidelines;student engagement;educational active learning;large language models},
  doi={10.1109/EDUCON62633.2025.11016556},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11013578,
  author={Abu-Arqoub, Mohammad and Alkarim Banna, Abed and El-Khalili, Nuha and Al-Shaikh Hasan, Mohammad},
  booktitle={2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)}, 
  title={Design and Implementation of a Comprehensive RAG-Driven Dashboard Within the ILO System for Data Visualization and Query Support: A Case Study of the University of Petra}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This article presents a comprehensive study on designing and implementing a dashboard for enhanced data visualization and query support at the University of Petra. The system leverages retrieval-augmented generation (RAG) and large language models (LLMs) to support diverse document types, including curricula, course descriptions, and program outcomes, alongside intended learning outcome (ILO)-related files. Our implementation demonstrates significant improvements in data accessibility and query response times while maintaining high accuracy in information retrieval and visualization. Through extensive evaluation, we show that this innovative approach transforms data management processes in higher education by enabling natural language interactions with educational data systems, building upon established business intelligence frameworks while introducing advanced AI capabilities.},
  keywords={Large language models;Retrieval augmented generation;Natural languages;Data visualization;Transforms;Educational technology;Information retrieval;Data systems;Business intelligence;Time factors;RAG;Learning Analytics;Data Visualization;Educational Technology;ILO System;Business Intelligence},
  doi={10.1109/ICCIAA65327.2025.11013578},
  ISSN={},
  month={April},}@INPROCEEDINGS{10869067,
  author={Liu, Longfei and Zhang, Dengbo and Yan, Binger and Wu, Dan},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={EduGuard-LLM: An AI-Generated Content Detector Using Large Language Models for Safeguarding Educational Integrity}, 
  year={2024},
  volume={},
  number={},
  pages={102-105},
  abstract={In response to the widespread use of AI-generated tools by students to complete assignments, which poses significant challenges to educational integrity and fairness, this study proposes a novel detection model called EduGuard-LLM. EduGuard-LLM leverages the powerful text recognition capabilities of large language models to accurately distinguish between student-authored content and AI-generated content across different educational stages. By deeply analyzing text content and identifying AI-generated features, this model can effectively detect the authenticity of student submissions in primary, middle, high school, and university levels. In our experiments, we utilized 21 publicly available datasets, comprising a total of 164,543 text samples, covering various types of texts from elementary to university levels. The model achieved an accuracy of 93.96% on the pre-training dataset, and accuracies of 95.01%, 94.64%, 93.97%, and 94.94% on four external validation sets, respectively. The experimental results demonstrate that EduGuard-LLM has high detection accuracy across different educational stages, effectively ensuring the authenticity of student submissions. This provides strong technical support for educational institutions, maintaining educational integrity.},
  keywords={Adaptation models;Accuracy;Large language models;Soft sensors;Training data;Educational technology;Feature extraction;Data models;Standards;Faces;Educational Integrity;AI-Generated Content Detection;Large Language Model;Text Authenticity Verification},
  doi={10.1109/ICET62460.2024.10869067},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11024507,
  author={Paloniemi, Teemu and Setälä, Manu and Mikkonen, Tommi},
  booktitle={2025 IEEE/ACM 22nd International Conference on Software and Systems Reuse (ICSR)}, 
  title={Porting an LLM based Application from ChatGPT to an On-Premise Environment}, 
  year={2025},
  volume={},
  number={},
  pages={78-83},
  abstract={Given the data-intensive nature of Machine Learning (ML) systems in general, and Large Language Models (LLM) in particular, using them in cloud based environments can become a challenge due to legislation related to privacy and security of data. Taking such aspects into consideration implies porting the LLMs to an on-premise environment, where privacy and security can be controlled. In this paper, we study this porting process of a real-life application using ChatGPT, which runs in a public cloud, to an on-premise environment. The application being ported is AIPA, a system that leverages Large Language Models (LLMs) and sophisticated data analytics to enhance the assessment of procurement call bids. The main considerations in the porting process include transparency of open source models and cost of hardware, which are central design choices of the on-premise environment. In addition to presenting the porting process, we evaluate downsides and benefits associated with porting.},
  keywords={Procurement;Cloud computing;Privacy;Costs;Large language models;Legislation;Machine learning;Chatbots;Software;Hardware;Porting;Large Language Models;LLMs},
  doi={10.1109/ICSR66718.2025.00014},
  ISSN={},
  month={April},}@INPROCEEDINGS{10837643,
  author={Mondego, Domingos and Aziz, Omar},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Mapping the Educational Revolution: A Bibliometric Analysis of ChatGPT's Impact on Teaching and Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study provides a succinct overview of the research conducted on the impact of ChatGPT in education. A bibliometric analysis reveals a significant increase in research activity between November 2022 and April 2024. The study identified and analysed the most relevant papers from this period, focusing on 745 relevant studies sourced from the Scopus database. Key findings include the model's contribution to enhancing learner engagement and optimising knowledge acquisition through personalised learning. The study also examines the influence of ChatGPT on curriculum design, assessment strategies, and the emergence of AI-powered educational tools, such as intelligent tutoring systems and chatbots. While highlighting the transformative potential of ChatGPT in education, ethical considerations are acknowledged, including concerns about assessment value reduction, data privacy, and algorithmic bias. Responsible AI integration is emphasised for a balanced and ethical use in learning environments. The bibliometric analysis identifies prominent authors, countries, and subject areas contributing to the field. Kleebayoon, emerges as a prolific contributor, and the United States leads in citations. Co-word and co-citation analyses reveal clusters of keywords and authors, illustrating interconnected themes and relationships in the literature. The study underscores ChatGPT's transformative potential in education, quantifies research trends through bibliometric analysis, and emphasises the importance of responsible AI integration and addressing ethical considerations in the evolving educational landscape.},
  keywords={Training;Ethics;Data privacy;Pandemics;Knowledge acquisition;Education;Bibliometrics;Chatbots;Market research;Artificial intelligence;Education;ChatGPT;Artificial Intelligence;AI-powered Educational tools;Teaching and Learning;Bibliometric Analysis;Scopus},
  doi={10.1109/ITHET61869.2024.10837643},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10892969,
  author={Mason, Sharon and Borasi, Raffaella and Miller, David and Vaughan-Brogan, Patricia and Han, Yu Jung and DeAngelis, Karen},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Avoiding ‘Sinking the Boat’ While not ‘Missing the Boat’: K-12 Leaders' Early-on Perspectives of AI Risks and Benefits and Their Implications for Developers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This full research to practice paper reports on early perspectives from K-12 leaders regarding AI use in schools. With the advent of generative AI applications, K-12 leaders have a key role in providing (or precluding) access to students and teachers' uses of AI tools - as superintendents, principals and other district and school-level administrators will continue to be making (or at the very least informing) decisions about what AI tools will be made available as well as policies governing their use. These decisions will be informed by what K-12 leaders perceive are the potential risks and benefits of AI - as a key charge for K-12 leaders considering any innovation is to evaluate its potential to support student learning while reducing potentially harmful consequences. It is important to understand these current perceptions, especially for anyone designing applications of AI for K-12 education. While previous work has reported on teachers' views of AI, the perspectives of K-12 leaders, who serve as thought-leaders and decision makers, remain largely unexplored. U sing a semi-structured interview protocol, in late 2023, researchers interviewed 36 K-12 leaders across 23 districts in western New York state in order to gather their early perspectives regarding AI and to answer the research question: How do K-12 leaders perceive the risks and opportunities associated with using artificial intelligence in their school environments? Participants included superintendents, principals and various district and school-level administrators as well as some teacher leaders. These K-12 leaders articulated risks that can be categorized by four themes: (a) concerns regarding the ethical use of AI by both students and teachers (including cheating), (b) concerns around privacy and cybersecurity, (c) concerns around the accuracy or legitimacy of the output from AI systems and (d) concerns about replacing people/jobs. At the same time, these K-12 leaders recognized several important opportunities presented by AI, which should also be taken into consideration when making decisions, including (a) preparing students for the future, (b) improving potential for learning and instructional development and (c) supporting K-12 educators. Collectively, these risks and opportunities can be characterized with the idea that K-12 leaders were aware of the need to balance the risks in order to not “sink the boat” while also using care to not delay actions and potentially “miss the boat,” and which represents a more nuanced view of risk, consistent with what has been identified in the entrepreneurship literature. This work has implications for deliberate and informed decision-making regarding policies for and use of AI in the K-12 domain, and the supports needed for their adoption and effective use. The findings also provide valuable insights for developers of domain specific AI systems for K-12 schools. As computer scientists and engineers continue to train models, develop and select algorithms to serve schools, learners and educators, considering the risks and opportunities articulated by K-12 thought leaders and decision makers can support their work in advancing the technologies and potentially improving adoption.},
  keywords={Technological innovation;Privacy;Ethics;Protocols;Generative AI;Boats;Entrepreneurship;Delays;Artificial intelligence;Interviews;artificial intelligence;K-12 leaders;K-12 schools},
  doi={10.1109/FIE61694.2024.10892969},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578655,
  author={Socher, Gudrun and Weisser, Tina},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Shaping the Future: A Cross-Disciplinary Journey in Design and Technology Integration}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In today's world, where digital technologies and artificial intelligence (AI) are everywhere, the education sector is challenged with updating its course formats to stay relevant and future-focused. This paper discusses an innovative educational approach in the Informatics and Design program, combining computer science elements with design education. The program differs from traditional computer science curriculums. It caters to students with heterogeneous levels of tech skills and emphasizes a balanced approach to teach both, design and software development. Central to this program is a unique project co-taught by a computer scientist and a service designer. The project centers on creating a chatbot, incorporating the latest in Natural Language Processing and Large Language Models. This initiative not only keeps pace with the latest tech developments but also stresses the importance of a human-centered design approach in merging design with technology. The outcomes of this educational approach demonstrate that when design and technology are taught in tandem, it leads to a more comprehensive understanding and skill set among students. This approach not only prepares them for the current landscape of digital technology but also instills a mindset of continuous adaptation and learning, which is crucial in the ever-evolving field of informatics and design.},
  keywords={Computer science;Merging;Prototypes;Chatbots;Informatics;Engineering education;Stress;transdisciplinarity;curriculum design;AI education;chatbots;human-centered design},
  doi={10.1109/EDUCON60312.2024.10578655},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10893165,
  author={Torek, Adam and Sorensen, Elijah and Hahle, Natalie and Kennington, Casey},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={A Systematic Evaluation of Code-generating Chatbots for Use in Undergraduate Computer Science Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research paper focuses on evaluating code-generating chatbots. Chatbots like ChatGPT released in the past three years have proven capable of a wide variety of tasks within a conversational interaction, including writing code and answering code-related questions. With these recent advances, chatbots have many potential uses in education, including computer science education. However, before these chatbots are used in CS curricula, their capabilities and limitations must be systematically tested and understood. In this work, we evaluate the capabilities and limitations of four known, open-source, code-based chatbots in programming tasks by performing a standardized study in which different chatbots are tasked with providing answers for a variety of assignments from Boise State University's computer science program. We found that while all of the chatbots can write code and provide explanations, some do better than others, and each of them work differently in conversations. Moreover, all of them suffered similar and important limitations, which has implications for adoption in curriculum. As a second experiment, we used the Llama chatbot to perform a human evaluation by enabling student novice and experienced programmers to use it as a coding assistant to complete specific tasks in a common software development environment. We found that the coding assistant can help novice programmers accomplish simple tasks in comparable time and code efficacy as more experienced programmers. Given these experiments, and given feedback from participants in our studies, we see a clear picture emerge: new programmers should learn important concepts about programming without the help of code assistants so students can (1) demonstrate their understanding of important concepts and (2) have enough experience to assess code assistant output as useful or erroneous. Then, once intermediate skills are mastered (e.g., object oriented programming and data structures), it seems appropriate to introduce students systematically to coding assistants to help with specific assignments throughout the undergraduate computer science curriculum. We conclude by addressing ethical considerations for the use of code-based chatbots in computer science education and future directions of research.},
  keywords={Codes;Systematics;Object oriented modeling;Computational modeling;Writing;Chatbots;Encoding;Computer science education;Programming profession;Software development management;chatbot;large language models;code copilot},
  doi={10.1109/FIE61694.2024.10893165},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10828756,
  author={Durrani, Usman and Akpinar, Mustafa and Togher, Madeleine and Malik, Asif and Dordevic, Milan and Aoudi, Samer},
  booktitle={2024 International Conference on Artificial Intelligence, Metaverse and Cybersecurity (ICAMAC)}, 
  title={Harnessing AI for Personalized Academic Major Recommendations An Application of Large Language Models in Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the domain of educational counseling, the utilization of Large Language Models (LLMs) in conjunction with sophisticated AI technologies, such as embeddings and vector databases, introduces a groundbreaking methodology for advising students on their academic specializations. This study explores the complexities associated with conventional recommendation systems, which include issues like data imbalance and insufficient contextual awareness etc. By adopting a FewShot Learning framework, we harness the flexibility of LLMs to identify critical factors related to students’ interests and competencies. Our approach enables the dynamic extraction of important contextual information, thereby enhancing the predictive efficacy of the models. Through comprehensive experimentation with varied student datasets, we will experiment on if our AI system outperforms traditional recommendation techniques implemented by academic advisors and if it can yield detailed analyses customized to individual student profiles. This pioneering strategy holds considerable potential for advancing academic advising and assisting students in making well-informed choices regarding their educational trajectories.},
  keywords={Employee welfare;Metaverse;Databases;Large language models;Education;Predictive models;Vectors;Trajectory;Data mining;Recommender systems;Artificial Intelligence in Education;Large Language Models Personalized Academic Advising;Educational Recommender Systems;AI-Powered Recommendations},
  doi={10.1109/ICAMAC62387.2024.10828756},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10981346,
  author={Morales-Chan, Miguel and Amado-Salvatierra, Hector R. and Hernandez-Rizzardini, Rocael and Román, Byron Linares},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Workshop: Transforming Student Interaction through Building Educational Chatbots in Engineering and Computing}, 
  year={2025},
  volume={},
  number={},
  pages={1-2},
  abstract={Educational chatbots offer a potential way to enhance student engagement and provide ongoing support throughout a course. This workshop is designed to empower educators with the skills to create educational chatbots tailored to classroom needs using the no-code platform Chatbase, alongside an introduction to OpenAI's API capabilities for non-programmers. Participants will explore the evolving capabilities of AI in creating chatbots that deliver local, course-specific context, such as assignment details, deadlines, and customized responses. The session emphasizes designing chatbot flows that support realistic educational interactions and integrate content specific to their courses. By the end of the workshop, educators will have a working prototype of a chatbot tailored to their specific class requirements, enhancing engagement in personalized learning. This hands-on experience offers an accessible path for educators to embrace AI-driven tools in education.},
  keywords={Generative AI;Conferences;Buildings;Prototypes;Chatbots;Engineering education;artificial intelligence;Chatbot;generative AI tools;LLMs},
  doi={10.1109/EDUNINE62377.2025.10981346},
  ISSN={},
  month={March},}@ARTICLE{10285884,
  author={Wang, Mo and Wang, Minjuan and Xu, Xin and Yang, Lanqing and Cai, Dunbo and Yin, Minghao},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Unleashing ChatGPT's Power: A Case Study on Optimizing Information Retrieval in Flipped Classrooms via Prompt Engineering}, 
  year={2024},
  volume={17},
  number={},
  pages={629-641},
  abstract={This research project investigates the impact of prompt engineering, a key aspect of chat generative pretrained transformer (ChatGPT), on college students' information retrieval in flipped classrooms. In recent years, an increasing number of students have been using AI-based tools, such as ChatGPT rather than traditional research engines to learn and to complete course assignments. Despite this growing trend, previous research has largely overlooked the influence of prompt engineering on students' use of ChatGPT and effective strategies for improving the quality of information retrieval in learning settings. To address this research gap, this study examines the information quality obtained from ChatGPT in a flipped classroom by evaluating its effectiveness in task completion among 26 novice undergraduates from the same major and cohort. The experimental results provide evidence that proficient mastery of prompt engineering improves the quality of information obtained by students using ChatGPT. Consequently, by acquiring proficiency in prompt engineering, students can maximize the positive impact of ChatGPT, obtain high-quality information, and enhance their learning efficiency in flipped classrooms.},
  keywords={Chatbots;Artificial intelligence;Task analysis;Online services;Electronic learning;Transformers;Oral communication;Chat generative pretrained transformer (ChatGPT);flipped classrooms;information retrieval;prompt engineering},
  doi={10.1109/TLT.2023.3324714},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{11021219,
  author={Aspra, Nico O. and Chong, Chien Hwa},
  booktitle={2025 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={Developing an AI-Driven NC Programming Assistant: A Productive Failure Approach in CNC Education}, 
  year={2025},
  volume={},
  number={},
  pages={438-443},
  abstract={The integration of artificial intelligence (AI) into engineering and technology education offers new possibilities for enhancing student learning and feedback delivery. In machining, where accuracy and logic are essential, AI can serve as a powerful support tool. This paper presents the NC Programming Assistant, an application that combines rule-based logic and generative AI to help students write and debug numerical control (NC) programs. The assistant provides real-time, context-specific feedback on errors such as syntax issues and safety violations, enabling students to revise their work and strengthen their programming skills. Grounded in the Productive Failure Model, the assistant is designed not only to correct errors but also to encourage learners to engage in trial, failure, and reflection. The tool was deployed in a machining course, where its impact was evaluated through surveys, usage data, and statistical analysis. Results showed improvements in student confidence, debugging ability, and comprehension. By providing immediate and personalized feedback, the assistant addresses common instructional challenges in technical education and demonstrates how theory-informed AI tools can enhance learning outcomes in skill-based disciplines.},
  keywords={Generative AI;Education;Debugging;Machining;Learning (artificial intelligence);Syntactics;Reflection;Logic;Time factors;Programming profession;Artificial intelligence;Education;CNC Programming;Productive Failure},
  doi={10.1109/SIEDS65500.2025.11021219},
  ISSN={2994-3531},
  month={May},}@ARTICLE{10916617,
  author={Chen, Xin and Zhang, Jin and Zhou, Tong and Zhang, Feng},
  journal={IEEE Access}, 
  title={LLM-CDM: A Large Language Model Enhanced Cognitive Diagnosis for Intelligent Education}, 
  year={2025},
  volume={13},
  number={},
  pages={47165-47180},
  abstract={Cognitive diagnosis is a key component of intelligent education to assess students’ comprehension of specific knowledge concepts. Current methodologies predominantly rely on students’ historical performance records and manually annotated knowledge concepts for analysis. However, the extensive semantic information embedded in exercises, including latent knowledge concepts, has not been fully utilized. This paper presents a novel cognitive diagnosis model based on the LLAMA3-70B framework (referred to as LLM-CDM), which integrates prompt engineering with the rich semantic information inherent in exercise texts to uncover latent knowledge concepts and improve diagnostic accuracy. Specifically, this study first inputs exercise texts into a large language model and develops an innovative prompting method to facilitate deep mining of implicit knowledge concepts within these texts by the model. Following the integration of these newly extracted knowledge concepts into the existing Q matrix, this paper employs a neural network to diagnose students’ understanding of knowledge concepts while applying the monotonicity assumption to ensure the interpretability of model factors. Experimental results from an examination data set for course completion assessments demonstrate that LLM-CDM exhibits superior performance in both accuracy and explainability.},
  keywords={Education;Large language models;Annotations;Accuracy;Semantics;Prompt engineering;Printers;Optimization;Manuals;Long short term memory;Cognitive diagnosis;large language models;exercise texts;higher education and intelligent education},
  doi={10.1109/ACCESS.2025.3549309},
  ISSN={2169-3536},
  month={},}@ARTICLE{10508087,
  author={Liao, Jian and Zhong, Linrong and Zhe, Longting and Xu, Handan and Liu, Ming and Xie, Tao},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Scaffolding Computational Thinking With ChatGPT}, 
  year={2024},
  volume={17},
  number={},
  pages={1628-1642},
  abstract={ChatGPT has received considerable attention in education, particularly in programming education because of its capabilities in automated code generation and program repairing and scoring. However, few empirical studies have investigated the use of ChatGPT to customize a learning system for scaffolding students’ computational thinking. Therefore, this article proposes an intelligent programming scaffolding system using ChatGPT following the theoretical framework of computational thinking and scaffolding. A mixed-method study was conducted to investigate the affordance of the scaffolding system using ChatGPT, and the findings show that most students had positive attitudes about the proposed system, and it was effective in improving their computational thinking generally but not their problem-solving skills. Therefore, more scaffolding strategies are discussed with the aim of improving student computational thinking, especially regarding problem-solving skills. The findings of this study are expected to guide future designs of generative artificial intelligence tools embedded in intelligent learning systems to foster students’ computational thinking and programming learning.},
  keywords={Chatbots;Education;Programming profession;Codes;Task analysis;Problem-solving;Encoding;Artificial-intelligence-generated content (AIGC);ChatGPT;computational thinking (CT);scaffolding},
  doi={10.1109/TLT.2024.3392896},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{11016545,
  author={Mohammed, Crista and Rocke, Sean},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Electrical and Computer Engineering Freshmen and Generative AI: Awareness, Attitudes, and Ethics}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={We are responding to calls for students to be trained in using generative AI (GAI). But training must take account of what students know; their prevailing attitudes; and their ethics with respect to using GAI. And knowing what our students know about GAI gives instructors an opportunity to co-construct meaningful teaching and learning moments. A class of 103 students, enrolled in the course Communication in the Engineering Sciences, in our BSc program in Electrical and Computer Engineering, was probed on their use of generative AI. The study draws on two datasets—student responses to a case study on unethical use of GAI and a questionnaire gathering qualitative data. Questionnaire responses reveal that generally students understand the basics of how GAI works. But this understanding is flawed, for example some students erroneously believe that GAI draws in real time from the Internet. Most respondents have used GAI in their studies, particularly to clarify concepts and summarize. We did not find widespread use of GAI for higher cognitive tasks. But this we suspect is linked to program sequencing: as students advance in their program more sophisticated uses of GAI are likely. This supports the need for longitudinal studies which track use in relation to program advancement. Like peers elsewhere, this class expressed concern about GAI's ability to propagate misinformation and bias; GAI-facilitated plagiarism; data privacy; and overreliance leading to impairment of learning. As it relates to whether GAI qualifies as an author, students demonstrated a fairly nuanced understanding of this complex issue. One student felt that this was a gray area, citing that even outside of GAI generated content, scholars build on each other's work to such an extent that the originality of any work can be questioned. In case study responses, all 103 students agreed that using GAI without permission is dishonest. Respondents noted that students, instructors, and university administration each have a responsibility to ensure that GAI is not misused. And like peers elsewhere, they welcome institutional policy and guidance on using GAI.},
  keywords={Training;Ethics;Sequential analysis;Data privacy;Generative AI;Plagiarism;Real-time systems;Internet;Engineering education;Fake news;academic honesty;engineering education;ethics;freshmen;generative AI},
  doi={10.1109/EDUCON62633.2025.11016545},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016518,
  author={Dewan, Umama and Hingle, Ashish and McDonald, Nora and Johri, Aditya},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Engineering Educators' Perspectives on the Impact of Generative AI in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The introduction of generative artificial intelligence (GenAI) has been met with a mix of reactions by higher education institutions, ranging from consternation and resistance to whole-hearted acceptance. Previous work has looked at the discourse and policies adopted by universities across the U.S. as well as educators, along with the inclusion of GenAI-related content and topics in higher education. Building on previous research, this study reports findings from a survey of engineering educators on their use of and perspectives toward generative AI. Specifically, we surveyed 98 educators from engineering, computer science, and education who participated in a workshop on GenAI in Engineering Education to learn about their perspectives on using these tools for teaching and research. We asked them about their use of and comfort with GenAI, their overall perspectives on GenAI, the challenges and potential harms of using it for teaching, learning, and research, and examined whether their approach to using and integrating GenAI in their classroom influenced their experiences with GenAI and perceptions of it. Consistent with other research in GenAI education, we found that while the majority of participants were somewhat familiar with GenAI, reported use varied considerably. We found that educators harbored mostly hopeful and positive views about the potential of GenAI. We also found that those who engaged more with their students on the topic of GenAI, both as communi-cators (those who spoke directly with their students) and as incorporators (those who included it in their syllabus), tend to be more positive about its contribution to learning, while also being more attuned to its potential abuses. These findings suggest that integrating and engaging with generative AI is essential to foster productive interactions between instructors and students around this technology. Our work ultimately contributes to the evolving discourse on GenAI use, integration, and avoidance within educational settings. Through exploratory quantitative research, we have identified specific areas for further investigation.},
  keywords={Surveys;Resistance;Computer science;Ethics;Generative AI;Shape;Conferences;Distance measurement;Engineering education;Lenses;Generative AI;teaching and research;higher education;engineering education},
  doi={10.1109/EDUCON62633.2025.11016518},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11023952,
  author={Sheng, Junjie and Lin, Yanqiu and Wu, Jiehao and Huang, Yanhong and Shi, Jianqi and Zhang, Min and Wang, Xiangfeng},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={SolSearch: An LLM-Driven Framework for Efficient SAT-Solving Code Generation}, 
  year={2025},
  volume={},
  number={},
  pages={6-10},
  abstract={The Satisfiability (SAT) problem is a core challenge with significant applications in software engineering, including automated testing, configuration management, and program verification. This paper presents SolSearch, a novel framework that harnesses large language models (LLMs) to discover and optimize SAT-solving strategies automatically. Leveraging a curriculum-based, trial-and-error process, SolSearch enables the LLM to iteratively modify and generate SAT solver code, thereby improving solving efficiency and performance. This automated SAT-solving paradigm has the advantage of being plug-and-play, allowing integration with any SAT solver and accelerating the development or design process of new SAT solvers (new methods). Our preliminary experimental results are encouraging by demonstrating that the LLM-powered paradigm improves state-of-the-art SAT solvers on general SAT benchmarks and significantly enhances the performance of the widely used Z3 solver (11% on PAR-2 score). These results highlight the potential for using LLM-driven methods to advance solver adaptability and effectiveness in real-world software engineering challenges. Future research directions are discussed to further refine and validate this approach, offering a promising avenue for integrating AI with traditional software engineering tasks.},
  keywords={Codes;Large language models;Configuration management;Benchmark testing;Software engineering;Large Language Models (LLM);SAT Solver;Code Generation;Heuristic Method},
  doi={10.1109/ICSE-NIER66352.2025.00007},
  ISSN={2832-7632},
  month={April},}@ARTICLE{10843681,
  author={Shoaib, Muhammad and Husnain, Ghassan and Sayed, Nasir and Yasin Ghadi, Yazeed and Alajmi, Masoud and Qahmash, Ayman},
  journal={IEEE Access}, 
  title={Automated Generation of Multiple-Choice Questions for Computer Science Education Using Conditional Generative Adversarial Networks}, 
  year={2025},
  volume={13},
  number={},
  pages={16697-16715},
  abstract={This work presents a novel perspective towards generating automated multiple-choice questions (MCQs)-a task fundamentally different due to the highly dynamic nature of computer science education, which spans several sub-domains. Taking advantage of Conditional Generative Adversarial Networks (cGANs), our model provides a versatile approach to addressing the need for diversity and context in relevant MCQ generation across proficiency levels, topic areas. Resulting MCQs inspire implementations within a variety of educational environments - from classrooms, to online courses, and finally exams - equipping teachers with an instrument that could be easily adapted based on the specific needs o students. The model is trained on a carefully constructed dataset that includes material from more than 20 subareas in computer science, consisting of materials such as textbooks, online encyclopedias and Q&A websites. Through rigorous evaluation using comprehensive performance metrics, including Question Relevance Score (QRS), Diversity Index (DI), and Difficulty Alignment Accuracy (DAA), we demonstrate the efficacy and robustness of our framework in generating high-quality MCQs. Moreover, we address ethical considerations inherent in AI-driven educational assessment, ensuring fairness, transparency, and accountability in the MCQ generation process. The cGAN architecture facilitates the generation of contextually relevant MCQs across various proficiency levels and subject domains, enhancing the educational assessment process. The comprehensive dataset developed for this study encompasses diverse computer science topics curated from authoritative textbooks, online resources, question banks, and instructor-generated content. Additionally, a user-friendly QT application has been developed, enabling seamless integration of the cGAN model into educational environments. Through rigorous evaluation and ethical considerations, this framework demonstrates its efficacy, ensuring fairness, transparency, and accountability in MCQ generation. This interdisciplinary work represents a significant advancement in computer science education, providing educators with a powerful tool to enhance student engagement and learning outcomes.},
  keywords={Education;Computer science;Computer science education;Generative adversarial networks;Computational modeling;Indexes;Ethics;Chatbots;Training;Testing;Automated MCQ generation;conditional generative adversarial networks (cGANs);computer science education;dataset curation;educational assessment},
  doi={10.1109/ACCESS.2025.3530474},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10983252,
  author={Bhatia, Gaurav and Alhajri, Raya},
  booktitle={2025 International Conference for Artificial Intelligence, Applications, Innovation and Ethics (AI2E)}, 
  title={Accelerate Learning with AI Powered Quiz Master Using Llama LLM}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Multiple-choice questions quizzes provide an interactive and engaging way to assess students' understanding and reinforce learning, but their manual creation can be time-consuming and labor-intensive for educators. The emergence of Large Language Models (LLMs) offers a transformative solution by enabling automated MCQ generation, correction, and personalized feedback. LLMs, with their advanced natural language understanding and generation capabilities, facilitate the creation of diverse and adaptive MCQ quizzes that cater to various learning objectives and difficulty levels. This paper introduces Quiz Master, an AI-powered platform for automated MCQ quiz generation, correction, and feedback, developed using open-source tools such as Meta Llama, Ollama, LangChain, and Streamlit. Quiz Master delivers an engaging and personalized learning experience, allowing students to actively participate in quizzes while receiving instant, adaptive feedback. By optimizing quiz creation and reducing educator workload, Quiz Master demonstrates the potential of LLMs to enhance educational practices, making learning more enjoyable, interactive, and effective.},
  keywords={Human computer interaction;Technological innovation;Ethics;Adaptation models;Adaptive systems;Large language models;Education;Manuals;Natural language processing;Data models;LLM;Llama3.2;Ollama;LangChain;Streamlit;AI},
  doi={10.1109/AI2E64943.2025.10983252},
  ISSN={},
  month={Feb},}@BOOK{10769323,
  author={Wen, Jun},
  booktitle={Accelerating IoT Development with ChatGPT: A practical guide to building your first IoT project using AI-assisted coding and cloud integration},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Build cutting-edge projects with ChatGPT, PlatformIO, ESP32, and Arduino-compatible sensors by integrating AWS Cloud and the ThingsBoard dashboardKey FeaturesLeverage ChatGPT to generate code on ESP32 for sending sensor data to AWS CloudCreate your own visualization dashboard on ThingsBoard CloudFollow step-by-step configuration guidance to ingest, process, store, and query data on AWS CloudPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionUnlike other IoT books that focus on theory and generic applications, this guide takes a practical approach, empowering you to leverage ChatGPT to build your very first IoT prototype. With over 20 years of experience in wireless and IoT technologies and a background as an instructor, Jun Wen expertly guides you from project kick-off to a fully functional prototype. The book emphasizes the transformative impact of ChatGPT for IoT, teaching you how to use ChatGPT to generate code for your applications, even with limited coding experience. You’ll be introduced to using PlatformIO IDE within Visual Studio Code and discover the cutting-edge RISC-V architecture, the ESP32 MCU, Arduino-compatible sensors, and integration methods for AWS and the ThingsBoard dashboard. Working through 10 different project examples, including flame detection, smoke detection, and air quality measurement, you’ll become proficient in the functions and specifications of each sensor and the use cases they solve. By the end of this book, you’ll be ready to undertake IoT development projects, bridging the gap between your ideas and functional creations.What you will learnMaster IoT essentials, such as networks, end devices, wireless connectivity, and the cloudExplore the ChatGPT prompting framework and build crucial skills for IoT projectsDiscover best practices for building robust IoT hardware prototypesFind out how to set up Visual Studio Code and PlatformIO IDEConnect ESP32 to AWS through TLS and MQTTExplore popular connectivity technologies widely adopted in IoTIntegrate IoT sensors with ESP32 to capture accurate data using ChatGPT's assistanceWho this book is forIf you’re a beginner interested in applying IoT technology to your projects but face challenges due to limited experience in embedded software coding, specifically in C and C++, this book is for you. Whether you’re a student, hardware hobbyist, DIY enthusiast, IoT developer, or professional from a non-technical background, if you feel that your ability to innovate is often stalled by the complexity of software coding, this easy-to-follow guide to using ChatGPT for generating example code will boost your IoT prototype development.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835467879},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769323},}@ARTICLE{10979380,
  author={Maraza-Quispe, Benjamín and Hugo Rosas-Iman, Victor and Feliciano-Yucra, Giuliana and Cesar Martínez-Lopez, Atilio and Marianela Quispe-Flores, Lita and Reyes-Villalba, Edwin and Pablo Nina-Mita, Pedro},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={Enhancing Research Capabilities in Teaching and Learning: The Transformative Impact of ChatGPT}, 
  year={2025},
  volume={20},
  number={},
  pages={115-124},
  abstract={The research analyzes the impact of ChatGPT on the development of investigative competencies in students of regular basic education, focusing on three main aspects: its role in information retrieval, its contribution to the generation of accurate and relevant content, and its usability in fostering investigative skills. An experimental design was applied to a sample of 100 students, with 50 students using ChatGPT during the development of learning sessions and a control group of 50 students conducting their sessions through traditional methods. The students developed research projects evaluated according to six key criteria: coherence, precision, originality, content depth, problem-solving ability, and source management. Descriptive and comparative statistical analyses indicated that the experimental group outperformed the control group in coherence, precision, and originality. However, the control group showed better performance in source management, suggesting that traditional methodologies remain more effective for handling bibliographic references and searching for reliable sources. Regarding content depth and problem-solving ability, both groups achieved similar results, with a slight advantage observed in the experimental group. In summary, ChatGPT improves students’ coherence, precision, and originality in research tasks. Nonetheless, it is recommended to integrate its use with traditional methods to strengthen source management and ensure the comprehensive development of investigative competencies, promoting the ethical and responsible use of technology.},
  keywords={Chatbots;Education;Artificial intelligence;Ethics;Usability;Training;Learning (artificial intelligence);Data privacy;Collaboration;Coherence;ChatGPT;investigative competencies;information retrieval;research skills development;educational technology},
  doi={10.1109/RITA.2025.3565180},
  ISSN={1932-8540},
  month={},}@INPROCEEDINGS{10980840,
  author={Mangarelli, Eduardo},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Plenary: Enhancing Engineering Education: Integrating Generative AI Tools}, 
  year={2025},
  volume={},
  number={},
  pages={1-2},
  abstract={Generative Artificial Intelligence and Large Language Models are reshaping the way we produce, refine, and engage with information. This plenary focuses on the implications of these technologies, specifically in engineering education, highlighting both the general educational benefits and the unique demands of adapting established engineering practices to leverage Artificial Intelligence (AI) effectively. We discuss practical strategies for classroom and laboratory integration, illustrate how software engineering workflows must accommodate AI-generated code, and underscore the importance of equipping future engineers with the essential technical and ethical competencies. Finally, we address the broad challenge of envisioning how industry and academic disciplines may evolve in response to AI, so that institutions can proactively provide learners with the skills and knowledge needed for the professions of tomorrow.},
  keywords={Industries;Ethics;Codes;Generative AI;Large language models;Engineering education;Software engineering;Generative AI;Engineering Education;AI Engineering Workflows},
  doi={10.1109/EDUNINE62377.2025.10980840},
  ISSN={},
  month={March},}@INPROCEEDINGS{10554692,
  author={Gallagher, Shannon K. and Ratchford, Jasmine and Brooks, Tyler and Brown, Bryan and Heim, Eric and McMillan, Scott and Nichols, William R. and Rallapalli, Swati and Smith, Carol and VanHoudnos, Nathan and Winski, Nick and Mellinger, Andrew O.},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)}, 
  title={Assessing LLMs for High Stakes Applications}, 
  year={2024},
  volume={},
  number={},
  pages={103-105},
  abstract={Large Language Models (LLMs) promise strategic benefit for numerous application domains. The current state-of-the-art in LLMs, however, lacks the trust, security, and reliability which prohibits their use in high stakes applications. To address this, our work investigated the challenges of developing, deploying, and assessing LLMs within a specific high stakes application, intelligence reporting workflows. We identified the following challenges that need to be addressed before LLMs can be used in high stakes applications: (1) challenges with unverified data and data leakage, (2) challenges with fine tuning and inference at scale, and (3) challenges in re-producibility and assessment of LLMs. We argue that researchers should prioritize test and assessment metrics, as better metrics will lead to insight to further improve these LLMs.},
  keywords={Measurement;Security;Reliability;Tuning;Software engineering;Large language models;TEVV;metrics;scaling;HCI;trust},
  doi={10.1145/3639477.3639720},
  ISSN={2832-7659},
  month={April},}@INPROCEEDINGS{10714569,
  author={Tang, Ningzhi},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={Towards Effective Validation and Integration of LLM-Generated Code}, 
  year={2024},
  volume={},
  number={},
  pages={369-370},
  abstract={Recent advances in large language model (LLM)-based code generation tools have shown the potential to lower the barrier to programming and improve developer productivity. However, validating the generated codes and integrating them into projects present significant challenges, especially for developers with limited expertise or domain-specific knowledge. I present a novel approach to help developers understand and modify LLM-generated code to align with their intentions, informed by my empirical study of developer behaviors when working with LLM code generation models. In the future, I propose to extend the work to include support for project-level code validation, dynamic program behavior integration, developer behavioral and cognitive context modeling, and computer science education.},
  keywords={Productivity;Visualization;Codes;Computational modeling;Large language models;Computer science education;Programming profession;Context modeling;large language model;debugging;developer behavior;code generation},
  doi={10.1109/VL/HCC60511.2024.00051},
  ISSN={1943-6106},
  month={Sep.},}@ARTICLE{10706805,
  author={Yin, Xin and Ni, Chao and Wang, Shaohua},
  journal={IEEE Transactions on Software Engineering}, 
  title={Multitask-Based Evaluation of Open-Source LLM on Software Vulnerability}, 
  year={2024},
  volume={50},
  number={11},
  pages={3071-3087},
  abstract={This paper proposes a pipeline for quantitatively evaluating interactive Large Language Models (LLMs) using publicly available datasets. We carry out an extensive technical evaluation of LLMs using Big-Vul covering four different common software vulnerability tasks. This evaluation assesses the multi-tasking capabilities of LLMs based on this dataset. We find that the existing state-of-the-art approaches and pre-trained Language Models (LMs) are generally superior to LLMs in software vulnerability detection. However, in software vulnerability assessment and location, certain LLMs (e.g., CodeLlama and WizardCoder) have demonstrated superior performance compared to pre-trained LMs, and providing more contextual information can enhance the vulnerability assessment capabilities of LLMs. Moreover, LLMs exhibit strong vulnerability description capabilities, but their tendency to produce excessive output significantly weakens their performance compared to pre-trained LMs. Overall, though LLMs perform well in some aspects, they still need improvement in understanding the subtle differences in code vulnerabilities and the ability to describe vulnerabilities to fully realize their potential. Our evaluation pipeline provides valuable insights into the capabilities of LLMs in handling software vulnerabilities.},
  keywords={Software;Training;Biological system modeling;Codes;Software quality;Large language models;Source coding;Software systems;Software engineering;Nickel;Software vulnerability analysis;large language model},
  doi={10.1109/TSE.2024.3470333},
  ISSN={1939-3520},
  month={Nov},}@INPROCEEDINGS{10460039,
  author={Ram, Shanker and Qian, Chen},
  booktitle={2023 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={A Study on the Vulnerability of Test Questions against ChatGPT-based Cheating}, 
  year={2023},
  volume={},
  number={},
  pages={1710-1715},
  abstract={ChatGPT is a chatbot that can answer text prompts fairly accurately, even performing very well on postgraduate-level questions. Many educators have found that their take-home or remote tests and exams are vulnerable to ChatGPT-based cheating because students may directly use answers provided by tools like ChatGPT. In this paper, we try to provide an answer to an important question: how well ChatGPT can answer test questions and how we can detect whether the questions of a test can be answered correctly by ChatGPT. We generated ChatGPT's responses to the MedMCQA dataset, which contains over 10,000 medical school entrance exam questions. We analyzed the responses and uncovered certain types of questions ChatGPT answers more inaccurately than others. In addition, we have created a basic natural language processing model to single out the most vulnerable questions to ChatGPT in a collection of questions or a sample exam. Our tool can be used by test-makers to avoid ChatGPT-vulnerable test questions.},
  keywords={Machine learning;Chatbots;machine learning;data analysis;ChatGPT;NLP},
  doi={10.1109/ICMLA58977.2023.00259},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{10624638,
  author={Ning, Jing and Gao, Yi and Luo, Mingxin},
  booktitle={2024 International Conference on Informatics Education and Computer Technology Applications (IECA)}, 
  title={Application Research of Generative Artificial Intelligence Technology in the Design and Art Course Teaching}, 
  year={2024},
  volume={},
  number={},
  pages={165-169},
  abstract={The education mode of art design education in colleges and universities is more flexible, and the practitioners and art design talents in this field have a high acceptance of new technologies and new scenes, providing a wide range of application scenarios and product forms for the integration of technology and art. However, there is little research on the application of AI technology in the field of design and design education, so this paper studies the application of generative AI in the teaching of art and design courses. To provide help for the promotion and characteristic development of artificial intelligence technology in art design education in universities. Study artificial intelligence to understand its intelligent dialogue mechanism. Artificial intelligence can support vector machine sorting learning algorithms, transform sorting questions into classification questions, and answer the questioner’s questions. The operation mode of generative artificial intelligence technology and its application in the analysis of design teaching needs can allocate the application of creative teaching concept of art design, try to build a high-quality design education system supported by digital technology, promote the implementation of digital strategy of design education, and help realize modern design education in colleges and universities.},
  keywords={Support vector machines;Art;Generative AI;Education;Transforms;Learning (artificial intelligence);Classification algorithms;Generative artificial intelligence;Design teaching;Digital education},
  doi={10.1109/IECA62822.2024.00038},
  ISSN={},
  month={Jan},}@ARTICLE{10529287,
  author={Diab Idris, Mohamed and Feng, Xiaohua and Dyo, Vladimir},
  journal={IEEE Access}, 
  title={Revolutionizing Higher Education: Unleashing the Potential of Large Language Models for Strategic Transformation}, 
  year={2024},
  volume={12},
  number={},
  pages={67738-67757},
  abstract={This paper investigates the transformative potential of Large Language Models (LLMs) within higher education, highlighting their capacity to reshape the academic landscape. By examining the complex impact of LLMs across critical areas of Higher Education Institutions (HEIs), including the role of HEIs as gatekeepers of knowledge, providers of credentials, research centres, incubators of innovation, drivers of social change and employers. In addition to academic integrity, the future of higher education, intellectual property, and public perception. The findings of this paper indicate that LLMs can empower transformation in HEIs by revolutionising various aspects of academia. The aim is to unveil the profound implications of integrating these cutting-edge technologies. The comprehensive study in this paper reveals the significant impacts and challenges associated with using LLMs in academic settings, which is achieved through a detailed analysis of current literature. The core findings suggest that LLMs hold the promise to trigger significant advancements in higher education. This paper also discusses the innovative potential of LLMs, and it outlines a path for their effective use in HEIs, emphasising the importance of a thoughtful approach to maximise their educational benefits. HEIs must address these challenges thoughtfully, ensuring that the integration of LLMs aligns with their fundamental objectives of promoting education, critical thinking, and personal growth.},
  keywords={Education;Training;Large language models;Ethics;Task analysis;Planning;Performance evaluation;Challenges of LLMs in higher education;impacts of LLMs in higher education;higher education institutions (HEIs);large language models (LLMs);LLMs in education},
  doi={10.1109/ACCESS.2024.3400164},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10569736,
  author={Šarčević, Antonia and Tomičić, Ivan and Merlin, Andrija and Horvat, Marko},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Enhancing Programming Education with Open-Source Generative AI Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={2051-2056},
  abstract={This paper describes the development of an Open-Source Generative AI Chatbot, utilizing free Large Language Models (LLM) to enrich the student learning experience for a university course in “Introduction to Programming”. The article aims to provide a step-by-step guide for selecting, fine-tuning, and evaluating available models. As a first step in choosing the appropriate LLM, which provides the most accurate responses while not requiring excessive computing power, the article will cover a discussion of the advantages and disadvantages of local vs. cloud-available models. After selecting a few promising models, the next stage includes fine-tuning LLMs to answer domain-specific questions using a dataset containing essential rules, guidelines, and explanatory content regarding the subject. The crucial aspect of selecting a model was evaluating answers, and in this context, both human and automatic evaluation techniques will be presented. Finally, it is possible to enhance the model performance and accuracy by incorporating Retrieval-Augmented Generation (RAG) techniques and exploring the influence of various factors, such as different vector databases, model temperatures, maximum token lengths, prompt templates, embeddings, repetition penalties, and chunking sizes. Our results show that chatbots have significant potential to improve academic support and learning efficiency, as well as personalized education in general.},
  keywords={Electric potential;Accuracy;Temperature;Generative AI;Computational modeling;Education;Chatbots;chatbots;generative models;large language models;natural language processing;education;digital learning},
  doi={10.1109/MIPRO60963.2024.10569736},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{11016490,
  author={Zhang, Yue and Reusch, Pascal},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Trust in and Adoption of Generative AI in University Education: Opportunities, Challenges, and Implications}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Generative AI has emerged as a transformative tool in the realm of higher education, offering a wealth of opportunities for personalized learning, automated feedback, and enhanced collaboration. However, its successful adoption within university environments is significantly dependent on the trust it earns from its users, particularly students. This study investigates the levels of trust and the adoption of Generative AI among students enrolled in both German and international study programs at Hochschule Bielefeld (HSBI) and its transnational partner, Hainan Bielefeld University of Applied Sciences (BiUH). Utilizing a comprehensive questionnaire, the research explores students' perceptions of the trustworthiness of Generative AI, their usage patterns, and their concerns regarding the ethical and academic implications of its use. Preliminary findings suggest that while students widely recognize the potential of Generative AI to improve learning outcomes and efficiency, the degree of trust in its reliability and fairness varies significantly. Key factors influencing this trust include the transparency of AI systems, the perceived accuracy of outputs, and concerns about bias and misuse. Students in international and cross-cultural programs face additional challenges, such as language barriers and cultural differences, which affect how AI is perceived and utilized. Ethical concerns, particularly regarding plagiarism and academic integrity, are prevalent across all groups, underscoring the need for clear institutional guidelines and policies. The findings highlight the importance of fostering AI literacy and providing support structures to build trust and encourage responsible use. Recommendations include the implementation of transparent AI tools, tailored training programs, and the development of ethical guidelines to ensure that Generative AI enhances education while upholding academic standards. This research provides actionable insights for universities aiming to integrate Generative AI into diverse educational contexts, ensuring that it serves as a beneficial tool that complements traditional educational methods while preparing students for a future where AI plays an increasingly central role.},
  keywords={Training;Ethics;Generative AI;Plagiarism;Learning automata;Reliability;Artificial intelligence;Engineering education;Standards;Guidelines;Generative AI;trust;university education;adoption;academic integrity;AI literacy},
  doi={10.1109/EDUCON62633.2025.11016490},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11016313,
  author={Drašković, Dražen},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Integration of Ai Tools into an Ai-Driven Software System to Make Learning Programming Easier}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Today, a person can be considered fully digitally literate if they know how to use and integrate ready-made artificial intelligence (AI) tools. The use of AI tools is becoming increasingly common in students' learning processes. However, learning programming can be challenging and exhausting, especially for younger learners. In this research, a software system was developed to integrate multiple AI tools to facilitate the learning process. The system includes tools for speech and text processing, program code generation, code testing, and result verification. Through a user-friendly software interface, users can define a problem or programming task using speech. The software then converts the speech into text using the Whisper AI API, which is subsequently processed by the GPT-3.5 Turbo and Claude AI APIs to generate program code. Once the program code is generated, it undergoes a series of tests, including parallel testing on the LeetCode platform. Users then compare the obtained results and manually complete a survey evaluating both external tools. One key research requirement was for the software system to accept input data in Serbian, a language with limited resources and complex grammatical rules. This made it difficult to find a suitable AI tool for accurate speech-to-text transformation. The system was tested with speech in both English and Serbian but supports many additional languages thanks to the powerful Whisper AI API. The implemented system is modular and easily extensible with new APIs, making it applicable to other areas of education beyond programming.},
  keywords={Codes;Accuracy;Speech coding;Writing;Software systems;Artificial intelligence;Speech processing;Programming profession;Testing;Text processing;Artificial intelligence;Large language models;Multilingual AI tools;GPT-3.5 Turbo;Claude;Whisper},
  doi={10.1109/EDUCON62633.2025.11016313},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10825124,
  author={Underwood, William and Gage, Joan},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Can GPT-4 Think Computationally about Digital Archival Tasks? – Part 2}, 
  year={2024},
  volume={},
  number={},
  pages={2533-2542},
  abstract={This study examines the computational problem-solving capabilities of GPT-4, focusing on its knowledge of machine learning, email categorization, and computational problem solving, alongside its proficiency in Python programming, computational abstraction, and program debugging. The aim of these investigations is to evaluate whether the capabilities of Large Language Models (LLMs), as demonstrated by GPT-4, can support Master of Library and Information Science (MLIS), graduate students in developing computational thinking skills relevant to digital archival tasks.},
  keywords={Computational modeling;Large language models;Text categorization;Machine learning;Debugging;Chatbots;Electronic mail;Problem-solving;Programming profession;Python;computational thinking;GPT-4;computational problem solving;large language models;MLIS education},
  doi={10.1109/BigData62323.2024.10825124},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10892918,
  author={Hussein, Rania and Zhang, Zhiyun and Amarante, Pedro and Hancock, Nate and Orduna, Pablo and Rodriguez-Gil, Luis},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Personalized AI-Assisted Instruction Into Remote Laboratories: Enhancing Engineering Education with OpenAI's GPT Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={In recent years, remote laboratories have become integral to modern education, offering flexibility and accessibility compared to traditional, in-person labs. Integrating AI-powered assistance into remote labs has the potential to give them an edge by providing personalized learning experiences. This paper explores an innovative approach to promoting independent learning and critical thinking by embedding AI-driven support, using OpenAI's GPT-4 model, into a remote Field Programmable Gate Array (FPGA) laboratory. Through a web-based code editor, students write SystemVerilog programs and receive tailored assistance from the AI, while their designs are deployed on a Terasic DEl-SoC FPGA development board with real-time feedback via a live camera feed. The study, which involved students from an advanced digital design course interacting with the AI assistant, revealed strong engagement and positive feedback. Preliminary results indicate that AI-powered guidance can meaningfully boost student involvement, providing a scalable and effective framework for fostering active learning in engineering education.},
  keywords={Remote laboratories;Navigation;Logic gates;Real-time systems;Encoding;Trajectory;Feeds;Artificial intelligence;Engineering education;Field programmable gate arrays;AI assistance;remote laboratories;engineering education;GPT models;personalized learning},
  doi={10.1109/FIE61694.2024.10892918},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11016449,
  author={Shu, Chao and Yao, Na and Chen, Yue and Wijeratne, Vindya and Ma, Ling and Loo, Jonathan and Chai, Kok Keong and Alam, Atm and Abuelmaatti, Aisha},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Ai-Assisted Multiple-Choice Questions Generation with Multimodal Large Language Models in Engineering Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={This paper presents an AI-assisted approach that leverages Multimodal Large Language Models (MLLMs) to automate the generation of Multiple-Choice Questions (MCQs) for modules in engineering education. The system introduces a LOs extraction to MCQs generation pipeline, which extracts Learning Outcomes (LOs) from provided lecture notes and generates relevant MCQs with solutions and explanations based on the extracted LOs. By harnessing MLLMs' capabilities in vision and text comprehension, coupled with carefully crafted prompts from human educators, the tool efficiently produces context-relevant MCQs that can streamline teaching material development. The effectiveness of this AI-powered MCQ generation pipeline is investigated through experiments across a number of engineering modules with evaluations on the quality of the generated MCQs by human educators. The analysis of the evaluation results shows the AI tool's ability to generate MCQs that are well-aligned with LOs and exhibit strong contextual relevance, demonstrating the potential of AI-assisted approaches to enhance the efficiency of creating high-quality MCQs in engineering education. However, the variability in quality ratings across different aspects underscores the continued need for human expertise and oversight in the assessment design process. The findings provide useful insights into the capabilities and limitations of state-of-the-art multimodal language models in supporting assessment development in engineering education.},
  keywords={Generative AI;Large language models;Pipelines;Learning (artificial intelligence);Question generation;Engineering education;Multiple-choice Question design;Learning Outcome authoring;Generative Artificial Intelligence (GenAI);Multimodal Large Language Models;Contextual generation;Engineering Education},
  doi={10.1109/EDUCON62633.2025.11016449},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10834324,
  author={Chen, Xin and Yin, Chuantao and Chen, Hui and Rong, Wenge and Ouyang, Yuanxin and Chai, Yanmei},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Course Recommendation System Based on Course Knowledge Graph Generated by Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With the advent of the big data era, knowledge graphs, as important tools for organizing, managing, and understanding massive amounts of information, are gradually becoming a research hotspot in the field of artificial intelligence. This article focuses on the research and practice of automated construction and application of knowledge graphs in the field of university courses, aiming to improve the efficiency and accuracy of knowledge graph construction and provide strong support for the application in related fields.This study integrated publicly available datasets, mainstream online education platforms, and course explanation texts. Using rule-based and deep learning information extraction methods, combined with a large language model, the automatic extraction of entities, attributes, and relationships was successfully achieved, and an initial course knowledge graph was constructed based on this. Furthermore, by calculating the similarity between course description texts and combining the extracted course prerequisite and peer relationships from the texts, the study not only enriches the structure and content of the course knowledge graph, but also enhances its accuracy and practicality. In order to provide more personalized course recommendation services, this article combines sequence based recommendation algorithms and graph embedding algorithms, fully utilizing the information of the course itself and the dependency information of the course sequence, designing a unique personalized recommendation algorithm, and verifying its effectiveness and accuracy through experiments. This study not only provides strong knowledge graph support for online education platforms, but also provides strong technical support for personalized learning recommendations.},
  keywords={Deep learning;Accuracy;Large language models;Soft sensors;Education;Knowledge graphs;Big Data;Information retrieval;Data mining;Recommender systems;component;formatting;style;styling;insert},
  doi={10.1109/TALE62452.2024.10834324},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10893017,
  author={Johri, Aditya and Hingle, Ashish and Schleiss, Johannes},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Misconceptions, Pragmatism, and Value Tensions: Evaluating Students' Understanding and Perception of Generative AI for Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={In this research paper we examine undergraduate students' use of and perceptions of generative AI (GenAI). Although the initial hype around ChatGPT has subsided, GenAI applications continue to make inroads across learning activities. Like any other emerging technology, there is a lack of consensus around using GenAI within higher education. Students are early adopters of the technology, utilizing it in atypical ways and forming a range of perceptions and aspirations about it. To understand where and how students are using these tools and how they view them, we present findings from an open-ended survey response study with undergraduate students pursuing information technology degrees. Students were asked to describe 1) their understanding of GenAI; 2) their use of GenAI; 3) their opinions on the benefits, downsides, and ethical issues pertaining to its use in education; and 4) how they envision GenAI could ideally help them with their education. Thirty-seven students provided responses ranging in length from 20 to 300 words for each question. Responses were iteratively coded by researchers to uncover patterns in the data and then categorized thematically. Findings reveal that students' definitions of GenAI differed substantially and included many misconceptions - some highlight it as a technique, an application, or a tool, while others described it as a type of AI. There was a wide variation in the use of GenAI by students, with two common uses being writing and coding. They identified the ability of GenAI to summarize information and its potential to personalize learning as an advantage. Students identified two primary ethical concerns with using GenAI: plagiarism and dependency, which means that students do not learn independently. They also cautioned that responses from GenAI applications are often untrustworthy and need verification. Overall, they appreciated that they could do things quickly with GenAI but were cautious as using the technology was not necessarily in their best long-term as it interfered with the learning process. In terms of aspirations for GenAI, students expressed both practical advantages and idealistic and improbable visions. They said it could serve as a tutor or coach and allow them to understand the material better. We discuss the implications of the findings for student learning and instruction.},
  keywords={Surveys;Ethics;Generative AI;Plagiarism;Education;Writing;Encoding;Distance measurement;Stakeholders;Information technology;generative artificial intelligence (GenAI);survey study;thematic analysis;undergraduate students},
  doi={10.1109/FIE61694.2024.10893017},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10774819,
  author={Vhatkar, Abhijit and Pawar, Vilis and Chavan, Pravin},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Generative AI in Education: A Bibliometric and Thematic Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper uses the bibliometric analysis technique to find out the current stage and future scope of research in the field of Generative Artificial Intelligence (AI) in the education sector. Generative AI which is demonstrated by popular platforms like ChatGPT, has emerged as a transformative force. It has offered a personalized learning environment, adaptive instruction, and opportunities for creative exploration for the students. The analysis done in this research paper is based on the data collected from the Scopus database. It shows the publication trends, geographical distribution, citation patterns, and thematic clusters of published research articles and conference papers in the recent past. The findings of this study reveal that the countries like United States, the United Kingdom, and Australia have significant research contributions with research themes spanning student-centred learning, medical and science education, and computing and information systems education. This research paper has identified the direction for future research which focuses on ethical considerations, teacher training, interdisciplinary collaboration, and inclusiveness. This research provides valuable insights into the growing field of Generative AI in education and guides future endeavours aiming at optimizing the educational outcome with responsible AI integration into the educational sector.},
  keywords={Training;Ethics;Generative AI;Databases;Data security;Bibliometrics;Force;Market research;Monitoring;Information systems;generative AI;generative artificial intelligence;artificial intelligence;quality education;ChatGPT},
  doi={10.1109/ICCUBEA61740.2024.10774819},
  ISSN={2771-1358},
  month={Aug},}@INPROCEEDINGS{10190325,
  author={Treude, Christoph},
  booktitle={2023 IEEE/ACM 5th International Workshop on Bots in Software Engineering (BotSE)}, 
  title={Navigating Complexity in Software Engineering: A Prototype for Comparing GPT-n Solutions}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Navigating the diverse solution spaces of non-trivial software engineering tasks requires a combination of technical knowledge, problem-solving skills, and creativity. With multiple possible solutions available, each with its own set of trade-offs, it is essential for programmers to evaluate the various options and select the one that best suits the specific requirements and constraints of a project. Whether it is choosing from a range of libraries, weighing the pros and cons of different architecture and design solutions, or finding unique ways to fulfill user requirements, the ability to think creatively is crucial for making informed decisions that will result in efficient and effective software. However, the interfaces of current chatbot tools for programmers, such as OpenAI’s ChatGPT or GitHub Copilot, are optimized for presenting a single solution, even for complex queries. While other solutions can be requested, they are not displayed by default and are not intuitive to access. In this paper, we present our work-in-progress prototype “GPTCOMPARE”, which allows programmers to visually compare multiple source code solutions generated by GPT-n models for the same programming-related query by highlighting their similarities and differences.},
  keywords={Navigation;Source coding;Prototypes;Chatbots;Software;Libraries;Problem-solving;Chatbots;diversity;complexity;solution spaces},
  doi={10.1109/BotSE59190.2023.00008},
  ISSN={},
  month={May},}@INPROCEEDINGS{10343467,
  author={Zastudil, Cynthia and Rogalska, Magdalena and Kapp, Christine and Vaughn, Jennifer and MacNeil, Stephen},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Generative AI in Computing Education: Perspectives of Students and Instructors}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative models are now capable of producing natural language text that is, in some cases, comparable in quality to the text produced by people. In the computing education context, these models are being used to generate code, code explanations, and programming exercises. The rapid adoption of these models has prompted multiple position papers and workshops which discuss the implications of these models for computing education, both positive and negative. This paper presents results from a series of semi-structured interviews with 12 students and 6 instructors about their awareness, experiences, and preferences regarding the use of tools powered by generative AI in computing classrooms. The results suggest that Generative AI (GAI) tools will play an increasingly significant role in computing education. However, students and instructors also raised numerous concerns about how these models should be integrated to best support the needs and learning goals of students. We also identified interesting tensions and alignments that emerged between how instructors and students prefer to engage with these models. We discuss these results and provide recommendations related to curriculum development, assessment methods, and pedagogical practice. As GAI tools become increasingly prevalent, it's important to understand educational stakeholders' preferences and values to ensure that these tools can be used for good and that potential harms can be mitigated.},
  keywords={Codes;Systematics;Computational modeling;Education;Natural languages;Curriculum development;Stakeholders;Generative models;large language models;computing education;student perceptions;instructor perceptions},
  doi={10.1109/FIE58773.2023.10343467},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10670435,
  author={Gao, Lin and Lu, Jing and Shao, Zekai and Lin, Ziyue and Yue, Shengbin and Leong, Chiokit and Sun, Yi and Zauner, Rory James and Wei, Zhongyu and Chen, Siming},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Fine-Tuned Large Language Model for Visualization System: A Study on Self-Regulated Learning in Education}, 
  year={2025},
  volume={31},
  number={1},
  pages={514-524},
  abstract={Large Language Models (LLMs) have shown great potential in intelligent visualization systems, especially for domain-specific applications. Integrating LLMs into visualization systems presents challenges, and we categorize these challenges into three alignments: domain problems with LLMs, visualization with LLMs, and interaction with LLMs. To achieve these alignments, we propose a framework and outline a workflow to guide the application of fine-tuned LLMs to enhance visual interactions for domain-specific tasks. These alignment challenges are critical in education because of the need for an intelligent visualization system to support beginners' self-regulated learning. Therefore, we apply the framework to education and introduce Tailor-Mind, an interactive visualization system designed to facilitate self-regulated learning for artificial intelligence beginners. Drawing on insights from a preliminary study, we identify self-regulated learning tasks and fine-tuning objectives to guide visualization design and tuning data construction. Our focus on aligning visualization with fine-tuned LLM makes Tailor-Mind more like a personalized tutor. Tailor-Mind also supports interactive recommendations to help beginners better achieve their learning goals. Model performance evaluations and user studies confirm that Tailor-Mind improves the self-regulated learning experience, effectively validating the proposed framework.},
  keywords={Data visualization;Data models;Education;Adaptation models;Tutorials;Large language models;Knowledge based systems;Fine-tuned large language model;visualization system;self-regulated learning;intelligent tutorial system},
  doi={10.1109/TVCG.2024.3456145},
  ISSN={1941-0506},
  month={Jan},}@BOOK{10970464,
  author={Siino, Marco and Tinnirello, Ilenia and Cascia, Marco},
  booktitle={From Foundations to GPT in Text Classification: A Comprehensive Survey on Current Approaches and Future Trends},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={In several Natural Language Processing (NLP) applications like news categorization, sentiment analysis, and subject labelling, text classification is a crucial and relevant task. The goal is to tag or label textual components like sentences, questions, paragraphs, and documents. In this era of massive information dissemination, manually processing and categorizing huge amounts of text data takes a relevant amount of time and effort. Text classification stands as a cornerstone within the realm of NLP, particularly when viewed through computer science and engineering. The past decade has seen deep learning revolutionize text classification, propelling advancements in text retrieval, categorization, information extraction, and summarization. The efficacy of text classification models relies heavily on their ability to capture intricate textual relationships and non-linear correlations, necessitating a comprehensive examination of the entire text classification pipeline. This work integrates traditional and contemporary text mining methodologies, fostering a holistic understanding of text classification. In the NLP domain, numerous text representation techniques and model architectures have emerged, with Large Language Models (LLMs) and Generative pre-trained Transformers (GPTs) at the forefront. These models are adept at transforming extensive textual data into meaningful vector representations encapsulating semantic information. Text classification is multidisciplinary in nature, encompassing data mining, linguistics, and information retrieval. This monograph provides an in-depth exploration of the text classification pipeline, with a particular emphasis on evaluating the impact of each component on the overall performance of text classification models. The pipeline includes state-of-the-art datasets, text preprocessing techniques, text representation methods, classification models, evaluation metrics, and future trends. Each section examines these stages, presenting technical innovations and recent findings. The work assesses various classification strategies, offering comparative analyses, examples and case studies. These contributions extend beyond a typical survey, providing a detailed and insightful exploration of the field.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638285595},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10970464},}@INPROCEEDINGS{11016470,
  author={Benites, Fernando and Battegay, Caspar},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={AI Literacy: Evaluation of an AI Literacy Course for Engineers}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={In this paper, we discuss the implementation and evaluation of a project-based self-direct learning competency-based module on AI literacy. This module was developed for various Bachelor's degree programs from the school of Engineering at the University of Applied Sciences and Arts Northwestern Switzerland. The aim of this course is not only to show how AI can help with writing and programming (learning), but also to get students firstly to reflect on working with AI and introduce them to important current debates, and secondly to teach the basics of large language models and central methods of data science. Students should be made aware to academic work (including finding and evaluating sources) with and about AI. During the course, they have to combine analytical and technical skills like programming and web scraping when developing a selfchosen project. An important finding of our work is that, despite their daily engagement with computer science and digital tools, without such specific formats, students are unlikely to acquire the necessary knowledge and critical thinking to navigate the rapidly changing landscape of AI autonomously and confidently.},
  keywords={Industries;Ethics;Navigation;Engineering profession;Large language models;Writing;Artificial intelligence;Programming profession;Faces;Guidelines;project-based learning;intrinsic motivation;self-directed learning},
  doi={10.1109/EDUCON62633.2025.11016470},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{11012071,
  author={Othman, Zhala Sarkawt and Karabatak, Sonsül and Karabatak, Murat},
  booktitle={2025 13th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={Bibliometric Analysis in AI Assistant for e-learning to Focus Students by Using Camera, Keyboard and Mouse}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, artificial intelligence has been a widely researched topic, particularly in education. This study evaluates the role of AI assistants in enhancing student motivation and focus in e-Iearning by conducting a bibliometric analysis of academic publications. In our study, we analyzed the use of AI assistants in e-Iearning to help students stay focused through the use of cameras, keyboards, and mice, addressing student distraction in e-Iearning. We propose that AI assistants can support teachers in motivating students and improving their engagement. To conduct our analysis, we examined data from the last ten years (2015–2025) using the Web of Science database and bibliometric analysis tools such as VOSviewer. We focused on publications categorized under Computer Science - Artificial Intelligence, Education - Educational Research, and Computer Science - Software Engineering. A total of 676 academic publications ten years were analyzed. The highest number of publications occurred in 2024, with “Artificial Intelligence,” “ChatGPT,” and “Machine Learning” being the most frequently used keywords. The primary objective of this study was to examine previous research that applied AI in e-education, exploring its impact on students through various approaches. Based on our findings, AI assistants in e-Iearning are expected to playa crucial role not only in the present but also in the coming years. Our results indicate that AI-assisted educational technologies have rapidly evolved and are significantly improving student engagement in e-Iearning environments.},
  keywords={Computer science;Electronic learning;Bibliometrics;Keyboards;Machine learning;Cameras;Mice;Security;Artificial intelligence;Software engineering;artificial intelligence;AI assistant;focus student;motivate student;distance education;distance learning;e-learning;bibliometric analysis},
  doi={10.1109/ISDFS65363.2025.11012071},
  ISSN={2768-1831},
  month={April},}@INPROCEEDINGS{10795004,
  author={Rahman, Tajmilur and Zhu, Yuecai and Maha, Lamyea and Roy, Chanchal and Roy, Banani and Schneider, Kevin},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Take Loads Off Your Developers: Automated User Story Generation using Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={791-801},
  abstract={Software Maintenance and Evolution (SME) is moving fast with the assistance of artificial intelligence (AI), especially Large Language Models (LLM). Researchers have already started automating various activities of the SME workflow. Un-derstanding the requirements for maintenance and development work i.e. Requirements Engineering (RE) is a crucial phase that kicks off the SME workflow through multiple discussions on a proposed scope of work documented in different forms. The RE phase ends with a list of user stories for each unit task and usually created and tracked on a project management tool such as GitHub, Jira, AzurDev, etc. In this research, we collaborated with Bell Mobility to develop a tool “Geneus” (Generate UserSory) using GPT-4-turbo to automatically create user stories from software requirements documents. Requirements documents are usually long and contain complex information. Since LLMs typically suffer from hallucination when the input is too complex, this paper proposes a new prompting strategy, “Refine and Thought” (RaT), to mitigate that issue and improve the performance of the LLM in prompts with large and noisy contexts. Along with manual evaluation using RUST (Readability, Understandability, Specificity, Technical-aspects) survey questionnaire, automatic evaluation with BERTScore, and AlignScore evaluation metrics are used to evaluate the results of the “Geneus” tool. Results show that our method with RaT performs consistently better in most of the cases of interactions compared to the single-shot baseline method. However, the BERTScore and AlignScore test results are not consistent. In the median case, Geneus performs significantly better in all three interactions (requirements specifi-cation, user story details, and test case specifications) according to AlignScorebut it shows slightly low performance in requirements specifications according to BERTScore. Distilling RE documents requires significant time & effort from the senior members of the team through multiple meetings with stakeholders. We believe automating this process will certainly reduce additional loads off the software engineers and increase the ultimate productivity allowing them to utilize their time on other prioritized tasks.},
  keywords={Surveys;Productivity;Software maintenance;Large language models;Project management;Maintenance;Planning;Requirements engineering;Stakeholders;Testing;LLM;Prompt Engineering;Refine and Thought;User Story;Auto Generate;Software Maintenance Tasks},
  doi={10.1109/ICSME58944.2024.00082},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10590605,
  author={Li, Yi and Zhang, Riteng and Qu, Danni and Samary, Maíra Marques},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Leveraging LLMs and MLPs in Designing a Computer Science Placement Test System}, 
  year={2023},
  volume={},
  number={},
  pages={1670-1676},
  abstract={Introductory Computer Science (CS) programs at higher education institutions include a variety of introductory courses commonly known as CS1 and CS2; some institutions offer additional variations (e.g., CS0, CS1.5). Accurate placement of students in these courses is vital for students' success. This paper introduces a machine learning-based CS placement test system using LLMs and classifiers, incorporating a concept inventory (CI) assessment. Five LLMs were evaluated, and the best one was chosen to generate questions. The questions were stored in a database, allowing customized placement tests through an interactive assessment system. After the test, students' performance data were used to train three simple MLP classifiers, achieving over 83% accuracy in a case study with 46 participants.},
  keywords={Computer science;Accuracy;Scientific computing;Reviews;Navigation;Filtering;Databases;Computer science education;Introductory CS courses;Placement test;Concept inventory;Large language model},
  doi={10.1109/CSCI62032.2023.00276},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10710971,
  author={Bircan, Abdullah and Mandal, Dilek and Kösesoy, İrfan},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={Academic Use of ChatGPT: Examining the Trends According to Disciplines}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With the rapid advancement of large language models, particularly ChatGPT, have had a profound impact both in the academic world and in commercial applications. The innovative solutions offered by this technology in areas such as natural language processing, data analysis, and human-computer interaction have led to the emergence of new research domains across various disciplines. However, there has been no comprehensive examination in the literature of which academic disciplines focus on ChatGPT and which areas have attracted more interest.This study aims to systematically examine academic publications related to ChatGPT and to identify the disciplines in which this technology is more widely adopted, as well as the areas where intensive research is conducted. To this end, a specially developed tool was utilized to scan all academic publications pertaining to ChatGPT, allowing for a comprehensive interdisciplinary analysis. The results of the analysis reveal the academic fields in which ChatGPT is most intensively utilized, highlighting the differences among these fields. Notably, there is a concentration in categories such as “Medical Sciences,” “Computer Sciences,” and “Education Sciences,” which also stand out among the most cited publications. Our findings indicate that ChatGPT has gained broad acceptance within the academic community, with certain disciplines leading the way in this regard. Furthermore, the interactions among categories sharing common keywords demonstrate how ChatGPT facilitates interdisciplinary knowledge flow.},
  keywords={Data analysis;Large language models;Chatbots;Market research;Data models;ChatGPT;Human-Computer Interaction (HCI);Natural Language Processing (NLP);Large Language Models (LLMs);Transformers},
  doi={10.1109/IDAP64064.2024.10710971},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11016312,
  author={Chans, Guillermo M. and Merino-Soto, César and Chávez, Santiago Santillán and García Castro, Jaime A. and Zavala, Genaro and Rodriguez, Elvia Sánchez},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Integrating Generative AI Into Design Thinking: Assessing Impact on Creativity and Innovation in STEM Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Design thinking (DT), widely recognized as a structured method for fostering creativity and innovation, has gained significant traction in research and practice across various disciplines. However, with the rise of disruptive technologies like artificial intelligence (AI), DT practices are gradually evolving, reshaping the innovation process. This study investigates the effectiveness of integrating generative AI into a product design thinking activity, employing a single-group pretest-posttest design (i.e., without a control group). The time interval between pretest and posttest measurements was four hours, coinciding with the duration of the DT activity. Conducted in a chemical engineering course at a private university in central Mexico, the research tasked nine students of average academic performance with designing a new beverage. Over a four-hour session, students used AI tools-ChatGPT, Perplexity, and Gemini-at various stages of the design process, including empathy mapping, need statements, idea classification, hills writing, and storyboarding. Several multidimensional constructs were measured using self-report questionnaires to assess the key attributes that DT stimulates: perceptions of creative self-efficacy, design thinking mindset, and empathy. Additionally, the study explored students' views on the usefulness of generative AI and their intention to use such tools. It was hypothesized that post-test scores for each construct would increase. The analysis involved two phases: first, psychometric indicators (alpha reliability) were obtained; second, a statistical approach for assessing individual change was applied, precisely the standardized individual difference (SID). The SID was set at a nominal level of 0.80 (right tail of the normal distribution). Scores with unacceptable measurement error (alpha <. 60) were excluded from the primary analysis. The results revealed a significant increase in students' perceived usefulness of AI between pre- and post-experiment measurements, with a moderate improvement in affective empathy. Other constructs also showed consistent, though modest, post-test score increases. However, only a few participants exceeded the SID threshold, indicating individual variations in response to the intervention. These preliminary findings highlight AI's potential to enhance student creativity through idea generation and expand their consideration of the end user in product design. The results provide valuable insights and recommendations for integrating AI into innovation-driven projects using the design thinking approach and implementing a single-group pretest-posttest design with short time intervals.},
  keywords={Technological innovation;Generative AI;Chemical engineering;Writing;Product design;Time measurement;Reliability;Problem-solving;Creativity;STEM;Design thinking;artificial intelligence;higher education;educational innovation;STEM;creative self-efficacy;empathy},
  doi={10.1109/EDUCON62633.2025.11016312},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10174472,
  author={Sudirman, Ivan Diryana and Rahmatillah, Intan},
  booktitle={2023 IEEE World AI IoT Congress (AIIoT)}, 
  title={Artificial Intelligence-Assisted Discovery Learning: An Educational Experience for Entrepreneurship Students Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={0786-0791},
  abstract={Artificial intelligence-assisted discovery learning is a powerful tool that can help students engage in discovery-based learning. This paper aims to investigate how ChatGPT might enrich the educational experience of students enrolled in Technopreneurship course. This research will be conducted on students from the Entrepreneurship Program in a university in Bandung. A total of 213 students participated in this study and filled out forms that were distributed via Google form. The results show that students who participated in the discussion session using ChatGPT found it both informative and enjoyable. The vast majority of students who attended the chatgpt session found the conversation informative and entertaining. The research question and the findings suggest that the use of AI-powered tools such as chatGPT can improve students’ learning experiences and aid them in developing workable ideas for mobile apps. This study can pave the way for further research into how AI can be applied to the classroom and what kind of impact it can have on students’ educational outcomes.},
  keywords={Heuristic algorithms;Education;Entrepreneurship;Learning (artificial intelligence);Oral communication;Chatbots;Market research;Artificial intelligence;discovery learning;ChatGPT;educational experience;Technopreneurship;entrepreneurship},
  doi={10.1109/AIIoT58121.2023.10174472},
  ISSN={},
  month={June},}@INPROCEEDINGS{10589972,
  author={Chen, Xi and Liao, Yuebin and Yu, Wei},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Generative AI in Higher Art Education}, 
  year={2024},
  volume={},
  number={},
  pages={135-140},
  abstract={This research delves into the perspectives of Chinese university art teachers on the integration of Artificial Intelligence in Generative Content. Collaboratively initiated by art teachers from Chinese universities through the AI Art Education Alliance in Wuhan, the study aims to comprehend their attitudes, concerns, and preparations regarding the infusion of generative AI tools into art and design curricula. The research employs a comprehensive approach, incorporating group interviews during the inaugural session of the AI Art Education Alliance. Additionally, questionnaire research is utilized as supplementary evidence. Participants include middle-level administrators and teachers from diverse colleges, offering a nuanced understanding of viewpoints across various educational institutions. Key findings reveal nuanced perspectives on AI in higher art education. Notably, there exists a spectrum of AI anxiety, with comprehensive universities showing readiness, while caution prevails in art colleges. The study underscores the potential benefits of AI in art education but highlights concerns about its impact on traditional pedagogy. The research emphasizes the urgency of addressing equity issues related to resource disparities, academic integrity, and cultural resistance within the education community. Recommendations include standardized AI tool usage, adaptations in professional structures, and fostering collaborative alliances to harness AI's potential effectively.},
  keywords={Training;Art;Generative AI;Surface resistance;Education;Anxiety disorders;Collaboration;generative AI tools;higher education;teachers' perspectives;AI in art education;AI anxiety},
  doi={10.1109/CSTE62025.2024.00032},
  ISSN={},
  month={April},}@INPROCEEDINGS{10556182,
  author={Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
  booktitle={2024 IEEE/ACM 3rd International Conference on AI Engineering – Software Engineering for AI (CAIN)}, 
  title={Seven Failure Points When Engineering a Retrieval Augmented Generation System}, 
  year={2024},
  volume={},
  number={},
  pages={194-199},
  abstract={Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.CCS CONCEPTS• Software and its engineering → Empirical software validation.},
  keywords={Semantic search;Education;Information retrieval;Chatbots;Software;Robustness;Task analysis;Retrieval Augmented Generation;RAG;SE4AI;Case Study},
  doi={},
  ISSN={},
  month={April},}@INPROCEEDINGS{10554965,
  author={Ibrahimzada, Ali Reza},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={Program Decomposition and Translation with Static Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={453-455},
  abstract={The rising popularity of Large Language Models (LLMs) has motivated exploring their use in code-related tasks. Code LLMs with more than millions of parameters are trained on a massive amount of code in different Programming Languages (PLs). Such models are used for automating various Software Engineering (SE) tasks using prompt engineering. However, given the very large size of industry-scale project files, a major issue of these LLMs is their limited context window size, motivating the question of “Can these LLMs process very large files and can we effectively perform prompt engineering?”. Code translation aims to convert source code from one PL to another. In this work, we assess the effect of method-level program decomposition on context window of LLMs and investigate how this approach can enable translation of very large files which originally could not be done due to out-of-context issue. Our observations from 20 well-known java projects and approximately 60K methods suggest that method-level program decomposition significantly improves the limited context window problem of LLMs by 99.5%. Furthermore, our empirical analysis indicate that with method-level decomposition, each input fragment on average only consumes 5% of the context window, leaving more context space for prompt engineering and the output. Finally, we investigate the effectiveness of a Call Graph (CG) approach for translating very large files when doing method-level program decomposition.},
  keywords={Java;Computer languages;Codes;Source coding;Static analysis;Task analysis;Software engineering},
  doi={10.1145/3639478.3641226},
  ISSN={2574-1934},
  month={April},}@ARTICLE{10908666,
  author={Chen, Jintao and Wang, Fan and Pang, Shengye and Chen, Mingshuai and Xi, Meng and Zhao, Tiancheng and Yin, Jianwei},
  journal={Tsinghua Science and Technology}, 
  title={A Privacy Policy Text Compliance Reasoning Framework with Large Language Models for Healthcare Services}, 
  year={2025},
  volume={30},
  number={4},
  pages={1831-1845},
  abstract={The advancement of artificial intelligence-generated content drives the diversification of healthcare services, resulting in increased private information collection by healthcare service providers. Therefore, compliance with privacy regulations has increasingly become a paramount concern for both regulatory authorities and consumers. Privacy policies are crucial for consumers to understand how their personal information is collected, stored, and processed. In this work, we propose a privacy policy text compliance reasoning framework called FACTOR, which harnesses the power of large language models (LLMs). Since the General Data Protection Regulation (GDPR) has broad applicability, this work selects Article 13 of the GDPR as regulation requirements. FACTOR segments the privacy policy text using a sliding window strategy and employs LLM-based text entailment to assess compliance for each segment. The framework then applies a rule-based ensemble approach to aggregate the entailment results for all regulation requirements from the GDPR. Our experiments on a synthetic corpus of 388 privacy policies demonstrate the effectiveness of FACTOR. Additionally, we analyze 100 randomly selected websites offering healthcare services, revealing that nine of them lack a privacy policy altogether, while 29 have privacy policy texts that fail to meet the regulation requirements.},
  keywords={Privacy;Pediatrics;Technological innovation;Sensitivity;Large language models;Medical services;Regulation;Cognition;General Data Protection Regulation;Protection;service regulation;privacy policy;compliance reasoning;healthcare services},
  doi={10.26599/TST.2024.9010089},
  ISSN={1007-0214},
  month={August},}@INPROCEEDINGS{10435040,
  author={Bau, Rahmat Taufik R.L and Hermila, A and Farman, Indra and Muhammad Hidayat, L and Salim, Sardi},
  booktitle={2023 9th International Conference on Education and Technology (ICET)}, 
  title={AI Perspectives in Education: A BERT-based Exploration of Informatics Students’ Attitudes to ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={36-41},
  abstract={This study examined informatics students’ perspectives on ChatGPT through sentiment analysis, utilizing advanced BERT neural networks within Python to understand their sentiments comprehensively. By harnessing BERT’s intricate contextual embeddings and attention mechanisms, we effectively evaluated the subtleties of students’ attitudes. Our methodology encompassed categorizing student ChatGPT reviews using a 5-star rating scale, capturing diverse sentiments and enabling scrutiny of their distribution and trends. Positive sentiments were predominant, as students lauded ChatGPT’s potential as a valuable academic tool. Its capacity to assist in research, assignments, and information retrieval garnered significant praise. However, neutral and negative sentiments pinpointed areas for improvement. Neutral sentiments indicated potential optimization, while negative sentiments flagged inaccuracies and response time concerns. Ultimately, this amalgamation of sentiment analysis and BERT insights provided a lucid view of informatics students’ interactions with ChatGPT. In conclusion, the fusion of sentiment analysis and BERT insights has spotlighted ChatGPT’s immense potential as an academic companion. This study underscores its value as an effective support tool, emphasizing the commitment to continuous enhancement. By diligently refining ChatGPT, we can enhance its performance, tailor it more precisely to students’ diverse needs, and seamlessly empower them to integrate AI-driven language models into their educational journeys.},
  keywords={Sentiment analysis;Education;Chatbots;User experience;Time factors;Informatics;Task analysis;sentiment analysis;students;ChatGPT;BERT},
  doi={10.1109/ICET59790.2023.10435040},
  ISSN={2770-4807},
  month={Oct},}@INPROCEEDINGS{10541593,
  author={McDaniel, Steven and Zibran, Minhaz F.},
  booktitle={2024 7th International Conference on Information and Computer Technologies (ICICT)}, 
  title={Improving Source Code with Assistance from AI — A Pilot Case Study with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={332-337},
  abstract={ChatGPT queries were used to provide feedback on five C++ programs selected from various programming assignments for two graduate-level computer science courses – a scientific programming course and an algorithms course. The evaluated software was written by the first author for those courses within the last two years. ChatGPT was asked to evaluate and provide feedback for each program. Specifically, ChatGPT was asked to evaluate the code for strengths and weaknesses and make recommendations for improving (1) execution speed as well as (2) readability and maintainability. A subjective agreement rating was generated by the authors for each strength, weakness, and recommended change provided by ChatGPT. While the overall agreement with the ChatGPT provided feedback was over 90 percent, at times, ChatGPT’s recommendations were found misleading.},
  keywords={Codes;Generative AI;Source coding;Software algorithms;C++ languages;Software quality;Programming;ChatGPT;Code;Readability;Program;Analysis;Execution Speed;Maintainability},
  doi={10.1109/ICICT62343.2024.00060},
  ISSN={2769-4542},
  month={March},}@ARTICLE{10856105,
  author={Setyawan Soekamto, Yosua and Christopher Limanjaya, Leonard and Kaleb Purwanto, Yoshua and Kang, Dae-Ki},
  journal={IEEE Access}, 
  title={From Queries to Courses: SKYRAG’s Revolution in Learning Path Generation via Keyword-Based Document Retrieval}, 
  year={2025},
  volume={13},
  number={},
  pages={21434-21455},
  abstract={Large Language Models (LLMs) hold immense potential for transforming education by automating the generation of personalized learning paths. However, traditional LLMs often suffer from hallucinations and content irrelevance. To address these challenges, we propose SKYRAG, a Separated Keyword Retrieval Augmentation Generation system that enhances the learning path generation process by integrating advanced retrieval mechanisms with LLMs. SKYRAG retrieves relevant course materials from Massive Open Online Course (MOOC) platforms, aligning them with individual learner profiles to provide personalized and coherent learning paths. Compared with Naïve RAG, SKYRAG demonstrates superior performance in terms of accuracy, relevance, and user satisfaction, as confirmed by human evaluations across four domains. By improving retrieval precision and addressing the limitations of traditional methods, SKYRAG represents a significant advancement in educational technology. This study contributes to the growing body of research on AI-driven learning systems and highlights SKYRAG’s potential for widespread adoption in dynamic educational environments.},
  keywords={Retrieval augmented generation;Accuracy;Semantics;Mathematical models;Large language models;Data models;Context modeling;Computational modeling;Transformers;Training data;Retrieval augmented generation;personalized learning path;large language models;educational technology;human-centric design},
  doi={10.1109/ACCESS.2025.3535618},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10342985,
  author={Hingle, Ashish and Katz, Andrew and Johri, Aditya},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Exploring NLP-Based Methods for Generating Engineering Ethics Assessment Qualitative Codebooks}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={This Full Research paper presents a comparison of two codebook generation methods using natural language processing (NLP): a human and NLP collaboration method and a fully automated NLP method (referred to as Human-NLP and Auto-NLP, respectively). Codebook generation serves as a preliminary step in most qualitative projects, and using NLP as a tool can help support the analysis and efficiency of the researcher. By utilizing NLP in the early stages of codebook generation, there are opportunities for detailed and productive gains when working with large corpora of textual data. Using NLP at this stage also allows the researcher to make sense of any outputs generated through automated means rather than simply accepting the output as it is. The outcome of both methods tested in this work will be used to evaluate and apply the codes across a large dataset. The Human-NLP method involves generating the initial themes using a large-language model (LLM), and the researcher revises the codebook further. The Auto-NLP method involves generating three rounds of codes, summarizing the codes in each until a saturation level has been reached through the overarching themes. The dataset used for this study comes from an analysis of students' perception and recognition of ethical concepts after participating in a semester-long course focused on ethics, society, and technology. The course introduced students to traditional ethics topics, such as those around engineering disasters, but also explored developing topics, such as facial recognition, dataset bias, and the impact of technology on the global food supply. We collected data between fall 2020 and 2022 from six (6) iterations of a semester-long course. A total of 210 student responses to the question - what did this course teach you about ethics - were analyzed. The results from both Human-NLP and Auto-NLP methods were promising in the level of detail summarized and the similarity of themes across the data. Eight (8) themes were finalized through the Human-NLP method, and twelve (12) were generated through the Auto-NLP method. We present a discussion exploring these themes and the limitations of using these methods.},
  keywords={Ethics;Codes;Face recognition;Collaboration;Natural language processing;Artificial intelligence;engineering ethics;natural language processing;codebook generation;generative AI},
  doi={10.1109/FIE58773.2023.10342985},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{11007284,
  author={Liu, Sunan and Jiang, Jiantao and Wei, Kailin and Wu, Runtian and Xu, Yaxiong},
  booktitle={2024 International Conference on Digital Technology and Intelligent Education (ICDTIE)}, 
  title={Enhancing University Students' ESG Competencies Through “Artificial Intelligence + Education”-A Case Study of ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={27-30},
  abstract={Under the background of “artificial intelligence + education”, artificial intelligence is promoting the high-quality development of education, especially showing the potential in cultivating of environmental, social and governance (ESG) capabilities. This study takes ChatGPT as an example to explore how intelligent education can empower university students in enhancing their ESG capabilities. A comprehensive, multidimensional educational strategy is proposed, which includes the curriculum system centered around the integration of artificial intelligence and ESG, the reinforcement of practice-oriented teaching methods, the promotion of interdisciplinary and cross-sector research projects, and the establishment of internship mechanisms based on collaboration between academia and industry. These strategies aim to facilitate students' deep understanding of ESG principles and enhance their ability to apply these concepts in real-world scenarios.},
  keywords={Industries;Education;Knowledge based systems;Collaboration;Chatbots;Multilingual;Sustainable development;Augmented reality;Immersive learning;ESG ability of college students;Educational empowerment;Interdisciplinary education;Chat-GPT},
  doi={10.1109/ICDTIE65977.2024.00012},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10342976,
  author={Hickman, Henry and McKeown, Paul and Bell, Tim},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Beyond Question Shuffling: Randomization Techniques in Programming Assessment}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  abstract={Randomization is a technique that can be used with programming assessments to discourage academic misconduct by making it unlikely for two colluding students to get the exact same questions. Previous research about randomization has shown it to be an effective tool for addressing academic misconduct, but this work often focuses on randomization broadly, with few considering specific techniques. In contrast, we consider different randomization techniques and the contexts that they are best suited to. In addition, we investigate the effectiveness of randomization techniques against emerging AI technologies. This is done by exploring randomization in the context of an online quiz system that evaluates student responses to pro-gramming challenges, specifically the CodeRunner system for the Moodle learning management system. We provide a classification of techniques, and discuss the benefits of each. This classification starts with simpler techniques, such as shuffling question order, shuffling multi-choice question options, and question pooling. We then move on to more advanced techniques, including simple substitution, altering expected output, switching logic, and steganography. We also investigate two approaches to generating randomized questions, considering the benefits and drawbacks of each. These approaches are generating the questions beforehand (pre-generation) and generating the questions when the quiz is started (on-the-fly generation). We then identify four categories of assessment based on assessment that is formative/summative, and proctored/non-proctored, then identify which randomization techniques are suited for each category. Finally, we test randomized questions against OpenAI's Codex, to see if these techniques could prevent this new opportunity for academic dishonesty. We found that there are some types of questions that Codex currently performs poorly on, such as program reasoning, and creating complex classes, but overall randomization was not effective in defeating it, with Codex scoring 79.7% on questions that were created after it was trained, and 85.3 % on questions that could have been available to it when it was trained.},
  keywords={Steganography;Learning management systems;Taxonomy;Education;Switches;Cognition;Servers;academic integrity;randomization;automatic assessment tools;AI generated code},
  doi={10.1109/FIE58773.2023.10342976},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{9766649,
  author={Ramnarain-Seetohul, Vidasha and Bassoo, Vandana and Rosunally, Yasmine},
  booktitle={2022 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Work-in-Progress: Computing Sentence Similarity for Short Texts using Transformer models}, 
  year={2022},
  volume={},
  number={},
  pages={1765-1768},
  abstract={The field of natural language processing is being revolutionized with transformers. The latter is based on a novel type of neural network framework that is already pre-trained. Hence, large datasets to train models are no longer required. This framework is suitable for automated assessment systems (AAS), where a large number of labeled data is needed. The larger the dataset, the higher the accuracy of the AAS. In this work-in-progress paper, a prototype for an AAS has been built where two transformer models, namely the Sentence-Transformers from hugging face and the OpenAI GPT-3 models have been used. The transformer models generate the similarity index between students’ answers and reference answers from the Texas dataset. Then the similarity index is used to compute marks for students. The performance of the prototype is evaluated using the quadratic weighted kappa metric.},
  keywords={Measurement;Computational modeling;Conferences;Neural networks;Prototypes;Transformers;Natural language processing;Sentence Similarity;Automated Assessment System;Transformers},
  doi={10.1109/EDUCON52537.2022.9766649},
  ISSN={2165-9567},
  month={March},}@INPROCEEDINGS{10857758,
  author={Keerthichandra, Malshan and Vihidun, Tharoosha and Lakshan, Shanuka and Perera, Indika},
  booktitle={2024 9th International Conference on Information Technology Research (ICITR)}, 
  title={Large Language Model-Based Student Intent Classification for Intelligent Tutoring Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Intent classification is a foundational element in natural language processing, enabling conversational systems to accurately interpret user intent. In educational contexts, effective intent classification within Intelligent Tutoring Systems (ITS) can significantly enhance personalized student interactions. This paper presents the intent classification module for the Learner-Aware AI (LAAI) tutor, a dialogue-based ITS designed to recognize and respond to diverse student behaviors, such as valid answers, questions, expressions of boredom, and requests for clarification. We introduce LAAIIntentD, a custom data set specifically designed for this task, containing 1,244 labeled training records and 278 evaluation records. Leveraging this dataset, we fine-tuned a large language model (LLM) LAAI-intent-classifier using Low-Rank Adaptation (LoRA) techniques to create a lightweight yet powerful intent classifier. Our fine-tuned model achieves better overall Recall (0.86), Precision (0.85), and F1-Score (0.83) compared to GPT-based methods. GPT models with CoT and Few-Shot prompting improve Recall but sacrifice F1 scores. This highlights our model's efficiency in balancing accuracy and scalability for ITS applications.},
  keywords={Training;Adaptation models;Intent recognition;Scalability;Large language models;Focusing;Robustness;Natural language processing;Information technology;Context modeling;Intent classification;Intelligent Tutoring System (ITS);Large Language Model (LLM);LAAI tutor;Few-shot prompting},
  doi={10.1109/ICITR64794.2024.10857758},
  ISSN={2831-3399},
  month={Dec},}@INPROCEEDINGS{11015302,
  author={Miladinovic, Igor and Schefer-Wenzl, Sigrid},
  booktitle={2024 15th International Conference on Distance Learning and Education (ICDLE)}, 
  title={From Learners to Contributors: Redefining Bachelor's and Master's Theses in the Context of Generative AI Tools}, 
  year={2024},
  volume={},
  number={},
  pages={15-19},
  abstract={The integration of Generative AI (GenAI) tools, such as ChatGPT, into academic environments has raised significant questions about the traditional format and integrity of final theses, particularly in engineering studies. This paper investigates the goal of final theses and the appropriate actions to achieve them in the context of modern technological advancements. Utilizing Dettmer's methodology, we identify and analyze the underlying causes of challenges introduced by GenAI tools. Our findings highlight the need for curriculum adaptations to address these challenges effectively. These include shifting the emphasis from thesis components easily generated by AI to students' contributions from a research project. These adaptations aim to enhance the quality and originality of final theses, foster deeper student engagement in research projects, and introduce innovative, multimedia formats for thesis presentation. The proposed solutions not only uphold academic integrity but also leverage the potential of GenAI tools to enrich the educational experience.},
  keywords={Computer aided instruction;Generative AI;Education;Chatbots;Generative AI;higher education;theses},
  doi={10.1109/ICDLE63439.2024.00010},
  ISSN={2169-1444},
  month={Sep.},}@INPROCEEDINGS{10814636,
  author={Beining, Yang and Alassane, Samba and Guillaume, Fraysse and Sihem, Cherrared},
  booktitle={2024 20th International Conference on Network and Service Management (CNSM)}, 
  title={Generating Commit Messages for Configuration Files in 5G Network Deployment Using LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Network automation is crucial for improving network performance. Commit messages describes the different actions of the modification of network configuration files and deployments. This paper presents experiments and studies on automated commit message generation in the deployment of 5G networks. We extracted data from repositories of various projects engineered in Orange’s 5G network. We then developed five prompts for experiments to identify the most suitable methods for this task. To select large language models, we used an in-house GPT-4 interface provided by Orange, and locally deployed popular large models such as Llama3, Mistral. We used both automated and human evaluation methods, selecting BLEU, ROUGE, and METEOR as our metrics for automated assessment. Our experiments shows that commit messages for configuration files generated by Large Language Models (LLMs) have better scores when using one-shot and Retrieval-Augmented Generation (RAG) technologies, for messages generated both by humans and bots.},
  keywords={Measurement;Automation;5G mobile communication;Large language models;Retrieval augmented generation;Meteors;Data mining;Commit Message Generation;Large Language Model;network automation},
  doi={10.23919/CNSM62983.2024.10814636},
  ISSN={2165-963X},
  month={Oct},}@INPROCEEDINGS{10372877,
  author={Cobos, Miguel and Cherres, Henry},
  booktitle={2023 IEEE 3rd International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={School evaluation and artificial intelligence}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Assessment in education has evolved over time and has established new ways of obtaining information about students’ academic progress. However, the advent of artificial intelligence, such as ChatGPT, has posed challenges in the assessment process, as students can use these technologies to solve questions and tasks without studying. This research focused on recommending alternative educational resources for assessment, considering the pros and cons of ChatGPT and other AI. A systematic literature review was conducted and resources such as written tests, Kahoot!, Quizlet, Mentimeter and Nearpod were identified and evaluated in the tool designed in Microsoft Excel to evaluate their effectiveness. The results showed that the written test and the Plickers tool were the most effective, followed by ClassTools, Flip, Kahoot!, Quizlet, Mentimeter and Nearpod, in addition a list of activities that can be used to assess knowledge through the rubric is shown, among the most important are: oral lessons, exhibitions, open houses, speeches, case studies, debates and observation of participation, because these types of work encourage the speaker to prepare and master the subject. Traditional assessment in the educational field has faced challenges with the advent of artificial intelligence because AI’s ability to generate tasks and answers without students having to read, write or study poses a challenge to ensure the actual acquisition of knowledge and skills. This research recommends educational resources to assess through digital tools or educational activities that allow for authentic assessment of learning and limit reliance on AI.},
  keywords={Systematics;Bibliographies;Education;Learning (artificial intelligence);Chatbots;Spreadsheet programs;Task analysis;evaluation;educational resources;artificial intelligence;ChatGPT},
  doi={10.1109/ICALTER61411.2023.10372877},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10569759,
  author={Drushlyak, M. and Lukashova, T. and Sabadosh, Yuliia and Melnikov, Ivan and Semenikhina, O.},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Using ChatGPT for the Development of Critical Thinking in Youth: Example of Inequality Proof}, 
  year={2024},
  volume={},
  number={},
  pages={334-339},
  abstract={The article explores the problem of using artificial intelligence in education. Practices of using ChatGPT in professional training are analyzed, highlighting both the positive aspects and risks of AI implementation in the educational process. The possibility of using AI to develop pre-service teachers’ critical thinking is justified. ChatGPT is used as a generator of possible pupils’ responses. The application of artificial intelligence, specifically ChatGPT, in proving inequalities is demonstrated. The generated responses are analyzed. Results of a pedagogical experiment on using ChatGPT for the development of pre-service mathematics teachers’ critical thinking are described. The evaluation criteria for individual tasks are based on key characteristics of critical thinking: 1) the ability to analyze information critically; 2) the ability to identify logical inconsistencies in statements; 3) the ability to eliminate logical inconsistencies; 4) a tendency to seek the most rational solution to a problem. The sign test is employed for statistical analysis of the results. The hypothesis regarding the positive impact of analyzing proofs of inequalities proposed by ChatGPT on the development of students’ critical thinking is confirmed. Problems in using ChatGPT in the Ukrainian language are identified.},
  keywords={Training;Statistical analysis;Chatbots;Market research;Mathematics;Generators;Information and communication technology;critical thinking;artificial intelligence;proof of inequalities;mathematics education;pre-service mathematics teachers;professional training},
  doi={10.1109/MIPRO60963.2024.10569759},
  ISSN={2623-8764},
  month={May},}@ARTICLE{10697478,
  author={Zhang, Yuzhe and Liu, Huan and Xiao, Yang and Amoon, Mohammed and Zhang, Dalin and Wang, Di and Yang, Shusen and Quek, Chai},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={LLM-Enhanced Multi-Teacher Knowledge Distillation for Modality-Incomplete Emotion Recognition in Daily Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The critical importance of monitoring and recognizing human emotional states in healthcare has led to a surge in proposals for EEG-based multimodal emotion recognition in recent years. However, practical challenges arise in acquiring EEG signals in daily healthcare settings due to stringent data acquisition conditions, resulting in the issue of incomplete modalities. Existing studies have turned to knowledge distillation as a means to mitigate this problem by transferring knowledge from multimodal networks to unimodal ones. However, these methods are constrained by the use of a single teacher model to transfer integrated feature extraction knowledge, particularly concerning spatial and temporal features in EEG data. To address this limitation, we propose a multi-teacher knowledge distillation framework enhanced with a Large Language Model (LLM), aimed at facilitating effective feature learning in the student network by transferring knowledge of extracting integrated features. Specifically, we employ an LLM as the teacher for extracting temporal features and a graph convolutional neural network for extracting spatial features. To further enhance knowledge distillation, we introduce causal masking and a confidence indicator into the LLM to facilitate the transfer of the most discriminative features. Extensive testing on the DEAP and MAHNOB-HCI datasets demonstrates that our model outperforms existing methods in the modality-incomplete scenario. This study underscores the potential application of large models in this field. The code is publicly available at https://github.com/yuzhezhangEEG/LM-KD.},
  keywords={Brain modeling;Electroencephalography;Emotion recognition;Physiology;Knowledge engineering;Feature extraction;Medical services;Bioinformatics;Biological system modeling;Training;Healthcare;Emotion Recognition;Large Language Model;Multi-teacher Knowledge Distillation},
  doi={10.1109/JBHI.2024.3470338},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10441780,
  author={Kumar, Tajinder and Kait, Ramesh and Ankita and Rani, Sunita},
  booktitle={2023 International Conference on Advanced Computing & Communication Technologies (ICACCTech)}, 
  title={Possibilities and Pitfalls of Generative Pre-Trained Transformers in Healthcare}, 
  year={2023},
  volume={},
  number={},
  pages={37-44},
  abstract={For its potential use in healthcare, Generative Pre-trained Transformers (GPT) and comparable models have attracted a lot of attention. These models present opportunities for therapeutic decision assistance, effective recordkeeping, natural language interactions, and patient education. Their application in healthcare, however, also has some drawbacks and difficulties that need to be properly handled.. The applications of GPT models in healthcare are incredibly broad. Through natural language interactions, they can produce patient education materials, offer decision help to healthcare professionals, and enhance user experience. GPT models offer the potential to improve tele-medicine projects, healthcare process optimization, and patient engagement. They can also help in literature reviews, information retrieval, and medical research, which enable researchers and healthcare practitioners to stay current with evidence-based practices. When applying GPT models in healthcare, a number of issues must be taken into account. These include the limitations of medical knowledge, ethical issues, potential biases and informational errors, legal and regulatory compliance, and the difficulty of having limited contextual awareness. GPT models should be used to support human decision-making rather than to replace medical experts. Critical issues that must be taken into account include patient confidentiality, data security, and the ethical usage of GPT models. To establish credibility and validate the GPT models' outputs in healthcare contexts, improvements to their interpretability and explain ability are required. To guarantee the application and efficacy of GPT models in healthcare, domain-specific adaption and clinical validation are crucial research fields. To properly handle the opportunities and drawbacks of GPT models, collaboration between researchers, healthcare professionals, and policymakers is crucial. The potential for revolutionizing healthcare delivery is enormous with pre-trained Transformers. But the difficulties and potential traps they pose must be carefully considered. GPT models can be ethically implemented and help to improve healthcare outcomes by resolving ethical issues, guaranteeing data privacy and security, and proving their efficacy in clinical situations. For GPT models to be used in healthcare to their fullest potential and to reduce the hazards involved, further research and collaboration are required.},
  keywords={Ethics;Adaptation models;Education;Decision making;Collaboration;Medical services;Transformers;Generative Pre-trained Transformers (GPT);Medical Chatbot;GPT-3 Health Bots;GPT-3 Clinical Documentation;GPT-3 Health Assistant},
  doi={10.1109/ICACCTech61146.2023.00016},
  ISSN={},
  month={Dec},}@ARTICLE{10494570,
  author={Barambones, Jose and Moral, Cristian and de Antonio, Angélica and Imbert, Ricardo and Martínez-Normand, Loïc and Villalba-Mora, Elena},
  journal={IEEE Transactions on Learning Technologies}, 
  title={ChatGPT for Learning HCI Techniques: A Case Study on Interviews for Personas}, 
  year={2024},
  volume={17},
  number={},
  pages={1460-1475},
  abstract={Before interacting with real users, developers must be proficient in human–computer interaction (HCI) so as not to exhaust user patience and availability. For that, substantial training and practice are required, but it is costly to create a variety of high-quality HCI training materials. In this context, chat generative pretrained transformer (ChatGPT) and other chatbots based on large language models (LLMs) offer an opportunity to generate training materials of acceptable quality without foregoing specific human characteristics present in real-world scenarios. Personas is a user-centered design method that encompasses fictitious but believable user archetypes to help designers understand and empathize with their target audience during product design. We conducted an exploratory study on the Personas technique, addressing the validity and believability of interviews designed by HCI trainers and answered by ChatGPT-simulated users, which can be used as training material for persona creation. Specifically, we employed ChatGPT to respond to interviews designed by user experience (UX) experts. Two groups, HCI professors and professionals, then evaluated the validity of the generated materials considering quality, usefulness, UX, and ethics. The results show that both groups rated the interviews as believable and helpful for Personas training. However, some concerns about response repetition and low response variability suggested the need for further research on improved prompt design in order to generate more diverse and well-developed responses. The findings of this study provide insight into how HCI trainers can use ChatGPT to help their students master persona creation skills before working with real users in real-world scenarios for the first time.},
  keywords={Interviews;Training;Chatbots;Surveys;Ethics;Task analysis;Recruitment;Chatbots;computer science education;human–computer interaction (HCI);large language model (LLM);training;user-centered design},
  doi={10.1109/TLT.2024.3386095},
  ISSN={1939-1382},
  month={},}@INPROCEEDINGS{10852445,
  author={Sadiq, Muhammad and Tariq, Ramsha and Ullah, Anayat and Panezai, Jeneen},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={From Pixels to Paragraphs: Extraction of Text from Medical Reports using LLMs, Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={216-228},
  abstract={Large language models are emerging very rapidly in applications covering nearly all fields including healthcare. In healthcare, these are commonly used for image to text, information extraction and generation and finding results from the medical notes and images. In spite of their extraordinary applications in healthcare, a standard and comprehensive systematic literature review (SLR) in this domain is lacking. However, there are quite a few systematic literature reviews in the field of large language models (LLMs) approaching the medical field. For that reason, this paper evaluates the literature to gather the relevant studies regarding LLMs in the medical field. The SLR process including a detail search was utilized to evaluate the research papers published between 2018 to date i.e. 2024, and a total of 82 studies, after rigorous screening, were included in this SLR. To wisely categorize these studies, consequently, we employed specific quality assessment criteria. Out of these 82 significant studies, only 4% were recognized to have utilized standard SLR guidelines. The results were presented in the form of charts and tables covering all the important aspects of meta data related to these selected studies. The quality assessment in screening these studies is also carried out in a very meticulous manner. Finally, an extensive discussion is carried out on formulated research questions in the methodology section and the suitable answers are discussed there. This paper therefore fulfills the gap for the scholars working on LLMs in the medical domain.},
  keywords={Large language models;Medical services;Metadata;Information retrieval;Quality assessment;Standards;Systematic literature review;Biomedical imaging;Guidelines;large language models;LLMs;text extraction;vision language models (VLMs);medical images into text and LLMs in medicine},
  doi={10.1109/FLLM63129.2024.10852445},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10487540,
  author={Jo, Jinyoung and Choi, Sean},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Analysis of Plagiarism via ChatGPT on Domain-Specific Exams}, 
  year={2023},
  volume={},
  number={},
  pages={1026-1033},
  abstract={This work presents a case study, linguistic analysis and potential prevention methods on the use of large language models (LLM) for generating solutions for exams on cloud computing course that require domain-specific knowledge. The study involves analyzing the responses of three groups of students: a group who used ChatGPT to plagiarize solutions, another group who referred to external non-LLM resources (e.g., web search) to plagiarize solutions, a control group who generated solutions without any external assistance. Results show that solutions from groups that participated in plagiarism tend to be lengthy, use uncommon words, and are similar to each other compared to human-generated solutions. This study not only shows that it is possible to generate legitimate solutions for exams that require extensive domain-specific knowledge using ChatGPT, but also shows some potential signals one can use to detect plagiarism, thus providing potential of promoting academic integrity by curbing unethical use of AI in academic settings.},
  keywords={Cloud computing;Plagiarism;Computational modeling;Linguistics;Chatbots;Computer science education;Web search;Large Language Model;Academic Integrity;Computer Science Education;Plagiarism Detection},
  doi={10.1109/CSCE60160.2023.00171},
  ISSN={},
  month={July},}@INPROCEEDINGS{11016642,
  author={Pua, Li Xue and Ramesh, Rushil and Natarajan, Prabhu and Iyer, Ganesh Neelakanta},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={CustomAIzEd: Bridging Interdisciplinary Gaps in AI Education with Customized Content Using LLMs}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The relationship between Artificial Intelligence (AI) and Education has witnessed substantial development in recent years, driven by a rising demand for learning AI concepts and the integration of AI technologies to enhance educational experiences. The inherent complexity of AI concepts necessitates the development of personalized pedagogical approaches to convey these concepts to students. However, few existing solutions enable the creation of customized content tailored to the unique learning needs of students. To bridge this gap, we have developed CustomAIzEd, an adaptive learning platform that harnesses large language models (LLMs) to thoughtfully create and recommend personalized quizzes and programming assignments focused on AI concepts. To evaluate the efficacy of this feature, a user study was conducted on students and instructors of IT1244, an introductory AI course offered by the National University of Singapore (NUS), based on the Unified Theory of Acceptance and Use of Technology (UTAUT) framework. The study revealed strong user intent from both students and instructors, highlighting the application's potential to enhance the experiences both of learners and educators in the field of AI.},
  keywords={Productivity;Learning management systems;Large language models;Learning (artificial intelligence);Solids;Prompt engineering;Artificial intelligence;Engineering education;Programming profession;Software engineering;Artificial Intelligence;Educational Technology;Software Engineering;Personalized Learning},
  doi={10.1109/EDUCON62633.2025.11016642},
  ISSN={2165-9567},
  month={April},}@ARTICLE{11002710,
  author={McIntosh, Timothy R and Susnjak, Teo and Arachchilage, Nalin and Liu, Tong and Xu, Dan and Watters, Paul and Halgamuge, Malka N},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs’ complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems’ integration into society.},
  keywords={Benchmark testing;Cultural differences;Generative AI;Computer science;Large language models;Ethics;Cognition;Hardware;Adaptation models;Training;Artificial Intelligence (AI);AI Evaluation;Benchmark;Evaluation Frameworks;Large Language Model (LLM)},
  doi={10.1109/TAI.2025.3569516},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10184267,
  author={Allam, Hesham and Dempere, Juan and Akre, Vishwesh and Parakash, Divya and Mazher, Noman and Ahamed, Jinesh},
  booktitle={2023 9th International Conference on Information Technology Trends (ITT)}, 
  title={Artificial Intelligence in Education: An Argument of Chat-GPT Use in Education}, 
  year={2023},
  volume={},
  number={},
  pages={151-156},
  abstract={Artificial intelligence (AI) is a popular concept for modernizing and automating traditional, time-consuming tasks with smart technology. AI can be applied to a wide range of areas, such as healthcare, finance, law, and education. AI has the potential to revolutionize the way we learn by making education more interactive and engaging. One possible step The way forward in this field is through the use of generative artificial intelligence.technologies like the ChatGPT conversational agent. Although enthusiastic techno-utopian cheerleaders are praising the tool.for answering questions, writing essays, summarizing documents,and generating sophisticated codes, it has some pitfalls that were acknowledged by the creators of OpenAI themselves. In this article, we discuss the application of artificial intelligence in education and put the trendy ChatGPT to the test in an educator-Learner context to see how it performs. We also discuss some of the benefits and drawbacks of ChatGPT and demonstrate how it might be utilized in the classroom. It is essential for educators to understand the implications of this technology and to investigate Strategies to modify the educational environment},
  keywords={Law;Education;Virtual reality;Medical services;Writing;Licenses;Chatbots;Artificial Intelligence;ChatGPT;AIED;intelligent agents;assessment;intelligent tutoring systems;personalized learning},
  doi={10.1109/ITT59889.2023.10184267},
  ISSN={},
  month={May},}@INPROCEEDINGS{10834346,
  author={Hayashi, Victor Takashi and Mohallem Paiva, Henrique},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={ChatGPT Calls for Self Reflection: Student Perceptions of Evaluation Activities in Video}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={ChatGPT has shown significant adoption for students when answering evaluation activities in undergraduate courses such as Information Systems, Computer Engineering, Software Engineering and Computer Science. When facing this challenge, one possibility for educators is to enable the students to learn while using the tool instead of restricting its usage. In this paper, we describe a case study of evaluation activities in video format as a way to motivate self-reflection in students. This alternative method prevents students from simply copying and pasting textual answers without any reflection. Furthermore, it encourages active participation and improves communication skills and the ability to articulate arguments, which may be lacking when students rely solely on written responses. We present 53 student perceptions regarding these video-based evaluation activities collected during two years, the benefits and drawbacks of the proposed approach, and suggestions for future implementations. According to students perceptions, most of them prefer text and coding evaluation approaches, however these are the ones more prone for ChtGPT ’copy and paste’. The qualitative responses indicate that the main positive aspects are the time flexibility and the additional reflection. The main negative aspects are related to lack of flexibility in communication form, extra work in video editing and additional student anxiety.},
  keywords={Technological innovation;Reviews;Generative AI;Scalability;Anxiety disorders;Chatbots;Reflection;Encoding;Software engineering;Information systems;evaluation;chatgpt;reflection;assessment;artificial intelligence;education},
  doi={10.1109/TALE62452.2024.10834346},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10578712,
  author={Ciolacu, Monica Ionita and Marghescu, Cristina and Mihailescu, Bogdan and Svasta, Paul},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Does Industry 5.0 Need an Engineering Education 5.0? Exploring Potentials and Challenges in the Age of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasing disruption from Industry 4.0/5.0, climate change, digital transformation, wars and high levels of volatility, uncertainty, complexity and ambiguity (VUCA) are leading to major changes in the labor market. In addition, improvements in chatbots and Generative AI are opening new opportunities for students and the future workforce. They seem to have become ‘creative’ in their field of study and are turning to AI applications for their learning, assignments or theses. However, there are concerns about academic integrity and cybersecurity. Students and researchers have already started using AI chatbots to learn, program, write academic essays or conduct research faster and more effectively. This paper explores whether AI can serve as a bicycle for human creativity and innovation. What are the first words that come to mind when you think of Engineering Education 5.0? Have you used Artificial Intelligence tools in your teaching, learning or research? This paper presents the results of a survey conducted at the Faculty of Electronics, Technology and Information Technology on the challenges and opportunities of using Generative AI(GenAI) in Engineering Education. This paper also outlines the Generative AI ecosystem for teaching, learning and research. Engineering Education 5.0 needs a future ready Curricula including AI Literacy, new teaching and learning methods, analytical and critical thinking, reflection, collaboration and complex problem-solving, and communities of practice with the industry to foster innovation and creativity.},
  keywords={Industries;Learning systems;Technological innovation;Generative AI;Education;Artificial intelligence;Engineering education;engineering education 5.0;technology-enhanced learning;innovation;creativity;generative AI},
  doi={10.1109/EDUCON60312.2024.10578712},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10967446,
  author={Mahmoudi, Mohsen and Taghiyareh, Fattaneh and Hessami, Farshad},
  booktitle={2025 29th International Computer Conference, Computer Society of Iran (CSICC)}, 
  title={Enhancing Learning Performance through LLM-Driven Adaptive Contents Based on Facial Engagement Detection}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Recent advancements in AI have opened new avenues for personalized education, enabling learning environments to adapt to individual needs. This study explores the intersection of AI and Image Processing, mainly using facial emotion detection to monitor cognitive engagement and distraction during learning tasks. Previous research highlights the efficacy of emotion detection in identifying cognitive states and improving educational outcomes through personalized learning environments. Our primary goal is to evaluate how AI can adapt educational content in real time to enhance learning effectiveness based on emotional feedback. We utilized an LLM to develop educational content and identified moments of distraction or disengagement by monitoring learners' facial emotions while interacting with the system. Upon detecting distraction, the LLM dynamically restructures the content, subtly reintegrating it into subsequent materials without the learners' awareness. This method reinforces learning by presenting material in varied contexts, thereby improving learners' understanding. Our preliminary results indicate that this approach enhances comprehension levels in distracted learners. Furthermore, integrating emotion-based monitoring with LLMs may provide a responsive educational framework that adapts to learners' immediate needs, promoting deep cognitive engagement and a pleasant personalized learning experience. These findings suggest broader applications beyond academic learning, including professional training. It is the ambition of any learning system to be able to detect any attention fall and to have smart reactions without learners' awareness, which is the vision of our approach.},
  keywords={Training;Learning systems;Emotion recognition;Adaptive systems;Large language models;Predictive models;Chatbots;Generators;Real-time systems;Monitoring;Adaptive Learning;Emotional Feedback;Large Language Models (LLM);Personalized Education;User Modeling},
  doi={10.1109/CSICC65765.2025.10967446},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10893194,
  author={Romero-Vera, Alex and Guarochico-Moreira, Victor and Velasco-Galarza, Victor and Espinoza-Andaluz, Mayken and Guaman-Quintanilla, Sharon and Chiluiza, Katherine},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing Pre-Class Content Learning in a Flipped Classroom: An Experimental Study of the Benefits of Note-Taking}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper describes an experimental study investigating the benefits of note-taking to enhance pre-class content learning in a flipped classroom (FC) environment applied to an Engineering Physics course. In an FC, fundamental content learning occurs before the class (targeting low cognitive levels on Bloom's taxonomy), allowing in-class time to reinforce and apply concepts (addressing high cognitive levels on Bloom's taxonomy). However, there is a lack of empirical and controlled research studies investigating optimal strategies for obtaining high-value pre-class content learning. This study aims to contribute to this matter. Four groups are considered, each comprising an average of 40 students, following the FC instructional methodology. Pre-class activities precede the class, including reading prepared documents and watching prepared videos. In-class assessments consist of a brief multiple-choice test (maximum of 5 questions) related to the pre-class activities, aiming to evaluate low cognitive levels on Bloom's taxonomy. To enhance note-taking practices, students are encouraged to take notes, and at the beginning of the course, a video showcasing five note-taking strategies is provided. The experiment carried out along one of the chapters revised in the Engineering Physics course includes one control group and one experimental group. In the control group, students are encouraged to take notes without additional guidance, whereas in the experimental group, students receive a fill-in-the-blank style note- taking guide. The results indicate that students who engage in note-taking, irrespective of the strategy used, outperform those who do not take notes. It is well-documented that note-taking produces an improvement in the in-class learning process. Here, we show how this benefit can be translated to activities before class, enhancing self-regulation learning and reducing the cognitive load during in-class note-taking. Regarding the note-taking guide, there is no significant evidence to support the improvement of student performance. This lack of progress may be attributed to the nature of the guide, using a linear note-taking strategy that ends with non-generative notes. This study shows the benefits of note-taking in enhancing pre-class content learning in an FC environment applied to an Engineering Physics course and invites us to rethink how the note-taking guide structure could encourage the production of generative notes.},
  keywords={Electronic learning;Statistical analysis;Taxonomy;Education;Production;Cognitive load;Online services;Physics;Videos;note- taking;flipped classroom;linear note- taking strategy;Bloom's taxonomy},
  doi={10.1109/FIE61694.2024.10893194},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10795042,
  author={Tayeb, Ahmad and Alahmadi, Mohammad and Tajik, Elham and Haiduc, Sonia},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Investigating Developers' Preferences for Learning and Issue Resolution Resources in the ChatGPT Era}, 
  year={2024},
  volume={},
  number={},
  pages={413-425},
  abstract={The landscape of software developer learning re-sources has continuously evolved, with recent trends favoring engaging formats like video tutorials. The emergence of Large Language Models (LLMs) like ChatG PT presents a new learning paradigm. While existing research explores the potential of LLMs in software development and education, their impact on developers' learning and solution-seeking behavior remains unexplored. To address this gap, we conducted a survey targeting software developers and computer science students, gathering 341 responses, of which 268 were completed and analyzed. This study investigates how AI chatbots like ChatGPT have influenced developers' learning preferences when acquiring new skills, ex-ploring technologies, and resolving programming issues. Through quantitative and qualitative analysis, we explore whether AI tools supplement or replace traditional learning resources such as video tutorials, written tutorials, and Q&A forums. Our findings reveal a nuanced view: while video tutorials continue to be highly preferred for their comprehensive coverage, a significant number of respondents view AI chatbots as potential replacements for written tutorials, underscoring a shift towards more interactive and personalized learning experiences. Additionally, AI chatbots are increasingly considered valuable supplements to video tutorials, indicating their growing role in the developers' learning resources. These insights offer valuable directions for educators and the software development community by shedding light on the evolving preferences toward learning resources in the era of ChatGPT.},
  keywords={Surveys;Software maintenance;Large language models;Education;Tutorials;Chatbots;Market research;Programming profession;Software development management;AI-driven learning tools;ChatGPT;programming learning preferences;programming issue resolution;video tutorials;written tutorials;Q&A forums;developer learning resources},
  doi={10.1109/ICSME58944.2024.00045},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{10504111,
  author={Zhang, Yanjun and Sun, Xiaoyu and Yu, Jiangde},
  journal={Journal of Web Engineering}, 
  title={Transformative Technologies in the Evaluation of a Vocational Education System}, 
  year={2024},
  volume={23},
  number={2},
  pages={275-298},
  abstract={The increasing demand for vocational education has necessitated the presence of highly skilled teachers. This study presents a novel framework for the effective management of vocational college instructors' professional development through the utilization of advanced technologies. The system utilizes deep learning technology to analyze many data points, including academic achievements, teaching experience, student comments, and professional activities, in order to assess the performance and potential of teachers. The system evaluates both the positive and negative aspects, offers customized training programs, and enhances the delivery of instruction through the utilization of a generative language model. The effectiveness of the system is supported by a case study, which demonstrates enhancements in talent management, professional development, teaching quality, and student happiness. This proposed solution aims to improve vocational education by empowering educators and transforming the processes of evaluation, support, and guidance throughout their professional trajectories.},
  keywords={Training;Deep learning;Trajectory;Intelligent management framework;vocational college teachers;deep learning;generative language model},
  doi={10.13052/jwe1540-9589.2324},
  ISSN={1544-5976},
  month={March},}@INPROCEEDINGS{10983088,
  author={Srivastava, Snehi and Nagpal, Namrata and Srivastava, Meenakshi},
  booktitle={2024 IEEE 11th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON)}, 
  title={Analyzing Student Engagement With ChatGPT: A Data-Analysis Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The study examines the use of ChatGPT in education, highlighting its potential to enhance productivity and learning. It emphasizes the importance of pedagogical strategies, human oversight, and data security. Performance Expectancy is linked to ChatGPT's effectiveness, while Effort Expectancy is related to its ease of use. The study reveals a predominantly optimistic student reception (approximately 73% of the total respondents) to ChatGPT in education, it's ease of use and versatile functionalities while also highlighting the need for ethical guidelines, data transparency, and academic integrity in its deployment. It was found that in the semi-structured interview of 2000 students, out of 1314 students who deemed ChatGPT advantageous, 87.9% also think they can pose potential risk if not used responsibly.},
  keywords={Productivity;Ethics;Vocabulary;Accuracy;Limiting;Education;Chatbots;Particle measurements;Interviews;Guidelines;ChatGPT;Data Analysis;Student engagement;Education Technology;Ethical Consideration;AI chatbot},
  doi={10.1109/UPCON62832.2024.10983088},
  ISSN={2687-7767},
  month={Nov},}@INPROCEEDINGS{10969684,
  author={Ahmed, Naveed and Iqbal, Zahid and Khan, Rabia and Al-Aswadi, Fatima N. and AlDharhani, Ghassan Saleh and Chan, Huah Yong},
  booktitle={International Conference on Energy, Power, Environment, Control and Computing (ICEPECC 2025)}, 
  title={Automated question generation from job descriptions using large language models: an evaluation of role-fit and fairness}, 
  year={2025},
  volume={2025},
  number={},
  pages={628-635},
  abstract={This paper introduces an automated framework for generating high-quality, role-specific interview questions directly from complex job descriptions using an ensemble of Large Language Models (LLMs). We leverage seven advanced LLMs (gemma2-9b-it,gemma-7b-it,llama-3.3-70b-versatile,llama-3.1-8b-instant,llama3-70b-8192,mixtral-8x7b-32768, andOpenAI-3.5) to produce a diverse pool of questions. Our approach integrates prompt engineering and debiasing strategies to ensure that the generated questions are contextually relevant, role-aligned, and free from harmful biases. We compare the LLMs’ outputs against a strong baseline (ChatGPT o1 Pro) and human domain experts’ assessments, employing a multi-faceted evaluation framework including relevance, clarity, specificity, and fairness metrics. Our results, validated on a curated set of job descriptions across multiple industries, demonstrate that a multi-model generation strategy, combined with bias mitigation and expert-informed prompt design, yields superior interview question sets. This research offers insights into enhancing recruitment practices, improving efficiency, and fostering equitable candidate assessment.},
  keywords={},
  doi={10.1049/icp.2025.1174},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11016655,
  author={Soll, Marcus and Kobras, Louis},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Do Large Language Models Require Prior Knowledge for Learning? A Preliminary Study}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={LLMs find increasing use as an educational tool, both from the instructors' perspective as well as from the students'. This paper presents a preliminary study investigating the effects of prior knowledge concerning a given topic on the effectiveness of using an LLM (Microsoft Copilot) to study the topic. Choosing Büchi automata as an example, twelve computer science students were tasked with first giving a self-report on prior knowledge, then studying Büchi automata for 15 minutes using only an LLM as a study tool, and afterwards filling out a short topical questionnaire. Two trends could be observed: Prior knowledge of LLMs seems to increase the learning effect while prior knowledge of a topic that is related to the studied topic seems to diminish the learning effect.},
  keywords={Visualization;Learning automata;Large language models;Fitting;Automata;Formal languages;Rendering (computer graphics);Market research;Filling;STEM;Computer Science Education;Large Language Models;Pedagogy;STEM education},
  doi={10.1109/EDUCON62633.2025.11016655},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10981323,
  author={Soto, Wilson},
  booktitle={2025 IEEE Engineering Education World Conference (EDUNINE)}, 
  title={Tool-Based Retrieval-Augmented Generative as an Automated Assistant in Object-Oriented Programming Course}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The integration of artificial intelligence into educational tools is transforming learning environments. In computer science, students frequently encounter challenges with complex concepts and practical applications. While LLMs offer valuable support, their responses can sometimes lack precision or rely on outdated information. Addressing these limitations is essential to enhance the effectiveness of AI-based tools in educational support. The main objective of this paper is to propose a tool-based RAG as automated assistant in an OOP Course. The tool was tested using common student queries and its responses were compared with those generated by ChatGPT. Initial observations suggest that RAG consistently generated contextually relevant responses due to its ability to access pertinent information from a structured knowledge base, resulting in more precise and applicable answers for students. The introduction of a RAG-based tool in classrooms has the potential to enhance student learning by providing instant, tailored responses to specific queries.},
  keywords={Computer science;Large language models;Knowledge based systems;Learning (artificial intelligence);Chatbots;Object oriented programming;Engineering education;Artificial Intelligence;Automated Assistant;Large Language Models (LLMs);OOP (Object-Oriented Programming);RAG (Retrieval-Augmented Generative)},
  doi={10.1109/EDUNINE62377.2025.10981323},
  ISSN={},
  month={March},}@INPROCEEDINGS{10814858,
  author={Sun, Jiaqin and Kwong, Chiew-Foong and Buticchi, Giampaolo},
  booktitle={2024 IEEE 11th International Conference on E-Learning in Industrial Electronics (ICELIE)}, 
  title={The Potential of AI in Electrical and Electronic Engineering Education: A Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The rapid advancement of Artificial Intelligence (AI) technologies is transforming education, particularly in Electrical and Electronic Engineering (EEE). This paper explores the potential applications, benefits, and challenges of Generative AI (GenAI) and Large Language Models (LLMs) in EEE education. Key areas include personalized learning, intelligent tutoring systems, automated grading, and predictive analytics. While these technologies offer significant enhancements in teaching and learning, they also present challenges such as data privacy, bias, and the need for human interaction. By examining current implementations and providing recommendations, this paper aims to guide educators and researchers in effectively integrating AI to improve EEE education.},
  keywords={Industrial electronics;Electric potential;Data privacy;Electronic learning;Reviews;Generative AI;Large language models;Education;Predictive analytics;Electronics engineering education},
  doi={10.1109/ICELIE62250.2024.10814858},
  ISSN={2997-7282},
  month={Nov},}@INPROCEEDINGS{10633447,
  author={Takerngsaksiri, Wannita and Warusavitarne, Cleshan and Yaacoub, Christian and Keng Hou, Matthew Hee and Tantithamthavorn, Chakkrit},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Students' Perspectives on AI Code Completion: Benefits and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={1606-1611},
  abstract={AI Code Completion (e.g., GitHub's Copilot) has revolutionized how computer science students interact with programming languages. However, AI code completion has been studied from the developers' perspectives, not the students' perspectives who represent the future generation of our digital world. In this paper, we investigated the benefits, challenges, and expectations of AI code completion from students' perspectives. To facilitate the study, we first developed an open-source Visual Studio Code Extension tool AutoAurora, powered by a state-of-the-art large language model StarCoder, as an AI code completion research instrument. Next, we conduct an interview study with ten student participants and apply grounded theory to help analyze insightful findings regarding the benefits, challenges, and expectations of students on AI code completion. Our findings show that AI code completion enhanced students' productivity and efficiency by providing correct syntax suggestions, offering alternative solutions, and functioning as a coding tutor. However, the over-reliance on AI code completion may lead to a surface-level understanding of programming concepts, diminishing problem-solving skills and restricting creativity. In the future, AI code completion should be explainable and provide best coding practices to enhance the education process.},
  keywords={Productivity;Visualization;Computer languages;Codes;Syntactics;Encoding;Artificial intelligence;AI Code Completion;Software Engineering;Programming Education},
  doi={10.1109/COMPSAC61105.2024.00252},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10956533,
  author={Maulana, Fairuz Iqbal and Adi, Puput Dani Prasetyo and Widartha, Vandha Pradwiyasma},
  booktitle={2024 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)}, 
  title={A Comprehensive Review and Research Trends of Large Language Models (LLMs) in Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={346-351},
  abstract={The emergence of Artificial Intelligence (AI) has significantly impacted the development of computational models for social systems, providing new opportunities for feedback-rich simulations. To achieve human-level language understanding, the incorporation of language models into comprehensive understanding systems is a crucial advancement. The use of Large Language Models (LLMs) in various fields, such as geomorphology and physics, highlights the necessity for robust policies and frameworks to regulate their use. Data selection from the Scopus database yielded a total of 2149 documents from 1173 sources. The most cited article from 2023 is 799 citations. Average citations per doc is 6.221. USA, China, and United Kingdom appear to dominate in terms of the number of published. By conducting a scientometric review and bibliometric analysis using R studio and VOSviewer software, this study aims to identify key focus areas, challenges, and opportunities in the implementation of IoT technologies in urban environments. As AI technologies, including LLMs, progress, their influence on diverse sectors like education, engineering, and healthcare is increasingly evident, emphasizing the importance of thorough assessments of their capabilities and constraints. By synthesizing insights from existing literature and exploring emerging trends, this study contributes to the advancement of Large Language Models (LLMs) in Artificial Intelligence and the development of a more connected and intelligent urban future.},
  keywords={Reviews;Databases;Large language models;Computational modeling;Bibliometrics;Urban areas;Transformer cores;Market research;Transformers;Surges;Large language model;LLMs;Artificial Intelligence;Bibliometric;Review},
  doi={10.1109/ICIMCIS63449.2024.10956533},
  ISSN={2837-5203},
  month={Nov},}@INPROCEEDINGS{10837597,
  author={Gusman, Elvina and Gide, Ergun and El Khodr, Mahmoud and Chaudhry, Ghulam},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The Benefits and Challenges of Using Artificial Intelligence in Teaching English as a Foreign Language in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the implementation of artificial intelligence (AI) in education, particularly in teaching English as a foreign language (TEFL) in higher education. AI has been applied in TEFL since the 1950s and developed significantly over the decades. However, it has received global attention in the last two years after introducing ChatGPT and other similar Generative AI (GenAl) applications. Implementing AI provides benefits and challenges to educators and students in English learning and teaching (ELT). This study examines systematic literature reviews regarding the benefits and challenges of employing AI toward ELT in higher education. This study synthesizes previous research to enhance insights into TEFL by applying AI effectively. Applying AI to teach English as a foreign language has several benefits and challenges. These can be summarized in the dimensions of using machine learning, chatbots, intelligent virtual environments, translation tools, multidimensional ethics, and social media. Each dimension provides valuable benefits and considers the challenges for educators in delivering English as a foreign language at the university level. The benefits of utilizing AI in TEFL are evolutionary and revolutionary changes in teaching methods, personalized learning environments, better management, and more accessible education. Despite these benefits, the challenges of utilizing AI can be identified as computational issues, limited language exposure, and lack of human interaction. Furthermore, this study can enhance the understanding and insight of implementing AI in teaching English as a foreign language by minimizing the challenges and optimizing the benefits of AI.},
  keywords={Training;Ethics;Translation;Social networking (online);Education;Virtual environments;Machine learning;Chatbots;Artificial intelligence;Systematic literature review;artificial intelligence;GenAl;benefits;challenges;teaching English;higher education},
  doi={10.1109/ITHET61869.2024.10837597},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10593283,
  author={Singh, Anuradha and Sharma, Himanshu and Jindal, Kanika and Chaudhary, Ankur},
  booktitle={2024 International Conference on Communication, Computer Sciences and Engineering (IC3SE)}, 
  title={Synergizing Futures: Precision Career Mapping with Llama 2 and AI Fine-Tuning for Personalized Path Prediction and Guided Navigation}, 
  year={2024},
  volume={},
  number={},
  pages={336-341},
  abstract={These days, a lot of students struggle in how to choose the career. As they progress through their studies, students must recognize their abilities and assess their areas of interest to determine the most appropriate job for them. With the aid of this approach, today's youngsters will be able to determine which career route will yield the best outcomes in the long run if they choose the suggested vocation. This will assist in raising the student's performance and spark their interest to keep them concentrated on their desired job. This system is based on an exam that students must complete; based on their responses, it will produce a summary of the test results. The primary goal of this system is to give a summary of the artificial intelligence methods that we employed to forecast the student's performance. This structure likewise be emphasizing how we are identifying characteristics in student data by employing prediction systems. For educators, educational institutions, and students alike, using this system has proven to be advantageous. In this paper we have used various technologies like Flutter, Llama-2 generative A.I. model, Firebase and UI/UX design tools. Our experimental results of proposed system reduce the career searching effort by 80% when tested for Lyman people.},
  keywords={Employee welfare;Engineering profession;Navigation;Scalability;Large language models;Design tools;Sparks;Student career guidance;Artificial Intelligence;Llama-2;Fine-Tuning;P3GS},
  doi={10.1109/IC3SE62002.2024.10593283},
  ISSN={},
  month={May},}@ARTICLE{11029015,
  author={Chibuike, Onuoha and Dang, Vu Hai and Nam, Nguyen Duc and Huong, Truong Thu and Nam, Pham Ngoc and Thang, Truong Cong},
  journal={IEEE Access}, 
  title={Subjective and Objective Quality Assessments of AI-generated Images for Language E-Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={AI-generated images (AIGIs) are becoming popular and can be employed in many applications, thanks to Generative AI (GAI). Researchers have developed models that can be used to generate images in different scenarios. Also, researchers have proposed datasets of natural scene images for language learning and different AIGI-quality datasets for general applications. For e-learning, particularly in the context of language learning, no AIGI dataset is currently available. To fill this gap, we first proposed an AIGI quality dataset for language learning. Both subjective and objective assessments have been conducted on the proposed dataset. The findings from subjective assessment show that higher perceptual quality also corresponds to a more substantial alignment. It also shows that the average MOS scores of images generated from Stability AI models are similar and lower than images generated by the Dall.E3 model. Results from the objective assessment indicate that the performance of off-the-shelf quality models is generally low. In addition, results from finetuning learning-based quality models show that significant gains and improvements can be achieved using the dataset. Results from the alignment evaluation show that the HPS model is the best, and realistic images in the dataset produced the best alignment correlation compared with the other styles in the dataset. The findings also show that multimodal large language models, such as vision-enabled GPT-4 (GPT-4V) still struggle to produce alignment scores that correlate with humans.},
  keywords={Electronic learning;Visualization;Text to image;Quality of experience;Quality assessment;Diffusion models;Training data;Training;Generators;Generative AI;AI-generated image;subjective study;AIGI;objective evaluation;QoE;e-learning;language learning},
  doi={10.1109/ACCESS.2025.3578047},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10718488,
  author={Nivithan, S. and Abhishek, A. and Thanapal, P. and Prakash Balaji, M. Sundar and Joseph Michael Jerard, V. and Ganesan, P. and Elamaran, V.},
  booktitle={2024 Third International Conference on Electrical, Electronics, Information and Communication Technologies (ICEEICT)}, 
  title={Exploring State-of-the-Art Methods in Mastering Digital Signal Processing through Blended Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This study highlights the necessity of employing extremely potent software tools for both teaching and mastering mathematically complex theory subjects. In the field of Electrical Engineering, there are courses like Engineering Electromagnetics, Signals & Systems, Control Systems, Digital Signal Processing, Digital Image Processing, Antennas & Wave Propagation, etc., where students learn very little because teachers must spend a lot of time in the classroom explaining mathematical principles. Since lecturing alone doesn't aid in the appropriate interpretation of the material, learners perceive it as being extremely difficult and unconnected. A robust graphical data flow programming environment with an extensive library of functions and tool sets in both simulation and real-time mode is one of the many such software tools that are currently accessible. With the use of these technologies, students from non-electronics streams can complete courses with a strong mathematical foundation more quickly and easily. This paper uses Orange Data Mining software tools, ChatGPT, Google Classroom, Matlab, and the Whatsapp platform to teach digital signal processing more effectively. Educators may focus more on practice because of this kind of research, which encourages students to learn for themselves.},
  keywords={Propagation;Process control;Digital signal processing;Speech recognition;Real-time systems;Libraries;Software tools;MATLAB;Streams;Programming environments;Digital signal processing;classroom learning;lecturing;machine learning;Orange software;speech processing},
  doi={10.1109/ICEEICT61591.2024.10718488},
  ISSN={},
  month={July},}@INPROCEEDINGS{10336315,
  author={Sami, Mansour and Sami, Ashkan and Barclay, Pete},
  booktitle={2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={A case study of fairness in generated images of Large Language Models for Software Engineering tasks}, 
  year={2023},
  volume={},
  number={},
  pages={391-396},
  abstract={Bias in Large Language Models (LLMs) has significant implications. Since they have revolutionized content creation on the web, they can lead to more unfair outcomes, lack of inclusivity, reinforcement of stereotypes and ethical and legal concerns. Notably, OpenAI has recently made claims they have introduced a new technique to ensure that DALL-E-2 generates images of people accurately reflect the diversity of the world’s population. In order to investigate bias within the field of Software Engineering, the study utilized DALL-E-2 image generation to assess 56 tasks related to software engineering. Another objective was to determine the impact of OpenAI’s new measures on the generated images for these specific tasks. Two sets of experiments were conducted. In one set, the tasks were prefixed with the clause "As a Software Engineer," while in the other set, only the tasks themselves were used. The tasks were presented in a gender-neutral manner, and the AI was instructed to generate images for each task 20 times. For a female-dominant task of doing administrative tasks, 40 more images were generated. The study revealed a large gender bias in the 2,280 images generated. For instance, in the subset of experiments with prompts explicitly incorporating the phrase "As a software engineer," only 2% of the generated images portrayed female protagonists. In all the images in this setting, male protagonists were dominant and in 45 tasks 100% of the protagonists were male. Notably, images generated without the prefixed clause only had more female protagonists in ‘provide comments on project milestones’ and ‘provide enhancements’, while other tasks did not exhibit a similar pattern. The findings emphasize unsuitability of implemented guardrails and the importance of further research on LLMs assessments. Further research is needed in LLMs to find out where their guardrails fail so companies can address them properly.},
  keywords={Software maintenance;Ethics;Law;Image synthesis;Sociology;Companies;Task analysis;Large Language Models;bias;gender diversity;Generative images;DALL-E-2},
  doi={10.1109/ICSME58846.2023.00051},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10815706,
  author={Tarek, Ahmed and Mahmoud, Marwa and Afifi, Basma and Mashaly, Maggie and Abu-Elkheir, Mervat},
  booktitle={2024 International Conference on Microelectronics (ICM)}, 
  title={Query-Based Topic Modeling and Trend Analysis in Scientific Literature}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The number of scientific publications grows every year. This growth has contributed to the continuous emergence of new trends across various scientific domains where researchers and investors are eager to predict these trends in advance. Using Natural Language Processing (NLP) techniques, this study aimed to develop a topic modeling approach to identify possible emerging trendy topics in a predetermined scientific field based on a given query and a set of thousands of abstracts. The proposed approach involves abstracts preprocessing, abstracts, and query encoding with the “allenai-specter” Sentence-BERT (SBERT) model, retrieving abstracts similar to the user query, and clustering them using the Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) algorithm. Subsequently, Latent Dirichlet Allocation (LDA) is applied to each cluster for topic modeling, and the resulting topics are labeled and analyzed over time to discover their trending status. Finally, abstracts discussing these emerging topics are summarized using the OpenAI “gpt-3.5-turbo-0125” model. Our approach, combining these technologies, achieved its objectives. Tested on data from 2016 to 2023 and focused on NLP as the domain of examination, our approach accurately identified five clusters, each representing specific NLP subfields, and highlighted approximately six trending topics spanning areas such as Performance Optimization in Pretrained Language Models, Multimodal Language Processing, Sentiment Analysis, and Text Generation methods in LLMs.},
  keywords={Analytical models;Sentiment analysis;Noise;Predictive models;Market research;Encoding;Data models;Microelectronics;Resource management;Optimization;NLP;LDA;trend prediction;HDBSCAN clustering;UMAP;SBERT;ML},
  doi={10.1109/ICM63406.2024.10815706},
  ISSN={2159-1679},
  month={Dec},}@INPROCEEDINGS{10662997,
  author={Böttcher, Axel and Thurner, Veronika},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Assessing Software Development Competences Constructively Aligned in an Open-Web Format}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={To assess in a constructively aligned way those programming competences that are relevant for the professional practice of future software developers, an assessment format would be suitable where students actively program, within the integrated development environment (IDE) that they are individually used to, and with unrestricted access for researching in the web. A format that accommodates these needs well is “Bring Your Own Device, Open Book, Open Web”, where students work on their own devices against given git repositories, with full access on knowledge bases and the internet. In this work, we share experiences and suggest well established practices for executing this exam type. As well, we discuss how the ready availability of large language models impacts this assessment type.},
  keywords={Large language models;Knowledge based systems;Software;Bring your own device;Programming profession;Software development management;assessment;electronic exams;computer science education;teaching methods},
  doi={10.1109/CSEET62301.2024.10662997},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10590517,
  author={Wang, Kevin and Lawrence, Ramon},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Using Assignment Incentives to Reduce Student Procrastination and Encourage Code Review Interactions}, 
  year={2023},
  volume={},
  number={},
  pages={1628-1633},
  abstract={Procrastination causes student stress, reduced learning and performance, and results in very busy help sessions immediately before deadlines. A key challenge is encouraging students to complete assignments earlier rather than waiting until right before the deadline, so the focus becomes on the learning objectives rather than just meeting deadlines. This work presents an incentive system encouraging students to complete assignments many days before deadlines. Completed assignments are code reviewed by staff for correctness and providing feedback, which results in more student-instructor interactions and may help reduce student use of generative AI. The incentives result in a change in student behavior with 45% of assignments completed early and 30% up to 4 days before the deadline. Students receive real-time feedback with no increase in marking time.},
  keywords={Codes;Scientific computing;Reviews;Generative AI;Real-time systems;Stress;Computational intelligence;incentives;procrastination;code review;generative AI;time management},
  doi={10.1109/CSCI62032.2023.00270},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10868886,
  author={Remegio, Florlyn Mae C. and Asahid-Cheng, Remelyn},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={Decoding Acceptance through Technology Acceptance Model: A Descriptive Study of ChatGPT Usage Across Academic Disciplines}, 
  year={2024},
  volume={},
  number={},
  pages={398-402},
  abstract={This study applies the Technology Acceptance Model (TAM) to explore students’ perceptions of ChatGPT’s usability across different academic disciplines. Using a stratified sample of university students, this research investigates variations in acceptance and identifies factors influencing usability perceptions. The findings reveal significant disciplinary differences, with students in computer-related fields showing the highest acceptance of ChatGPT. These insights underscore the importance of considering disciplinary contexts when integrating AI into educational frameworks. This paper demonstrates the utility of TAM in understanding AI adoption in higher education and provides actionable recommendations for leveraging AI tools like ChatGPT to enhance learning outcomes.},
  keywords={Technology acceptance model;Target tracking;Employment;Educational technology;Chatbots;Decoding;Artificial intelligence;Usability;Analysis of variance;Context modeling;Artificial Intelligence in Education;ChatGPT Usability;Technology Acceptance Model},
  doi={10.1109/ICET62460.2024.10868886},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10578718,
  author={de Kereki, Inés Friss and Garrido, Ismael},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Solving Computer Science 2 Tasks: Students’ Reflections on the Use of ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Computer Science II is a subject in the 2nd semester of the Bachelor's and Systems Engineering, Electrical, Electronics, and Telecommunications courses. As part of the evaluation, four tasks are included in the course to be performed individually by each student. From the beginning of the course, the use of Artificial Intelligence tools was introduced in different class activities, particularly ChatGPT. In this work, the activities are described and the solutions to the tasks presented by the students are evaluated. The surveys conducted with the students regarding their experience with these tools are examined.},
  keywords={Surveys;Chatbots;Reflection;Telecommunications;Problem-solving;Task analysis;Artificial intelligence;Computer Science 2;Programming;Artificial Intelligence;ChatGPT},
  doi={10.1109/EDUCON60312.2024.10578718},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{11023945,
  author={Doan, Long and Nguyen, ThanhVu},
  booktitle={2025 IEEE/ACM 47th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={AI-Assisted Autoformalization of Combinatorics Problems in Proof Assistants}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Proof assistants such as Coq and LEAN have been increasingly used by renowned mathematicians to formalize and prove mathematical theorems. Despite their growing use, writing formal proofs is challenging, and even the first step of stating the problem formally is difficult as it requires a deep understanding of these systems’ languages. Recent advancements in AI, especially large language models (LLMs), have shown promise in automating this formalization task. However, domains such as combinatorics pose significant challenges for AI-assisted proof assistant systems due to their cryptic nature and the lack of existing data to train AI models. We introduce AutoForm4Lean, a system designed to leverage LLMs to aid in formalizing combinatorics problems for LEAN. By combining LLMs with techniques from software engineering and formal methods such as validation and synthesis, AutoForm4Lean generates formalizations of combinatorics problems more effectively than the current state-of-the-art LLMs. Moreover, this project seeks to provide a comprehensive collection of formalized combinatorics problems, theorems, and lemmas, which would enrich the LEAN library and provide valuable training data for LLMs. Preliminary results demonstrate the effectiveness of AutoForm4Lean in formalizing combinatorics problems in LEAN, making a step forward in AI-based theorem proving.},
  keywords={Large language models;Training data;Writing;Libraries;Data models;Software engineering;Proof assistants;Autoformalization;Combina-torics;AI;LLM;Lean},
  doi={10.1109/ICSE-NIER66352.2025.00006},
  ISSN={2832-7632},
  month={April},}@INPROCEEDINGS{10665172,
  author={Kaleemunnisa, FNU and Scharff, Christelle and Bathula, Krishna and Zhumakova, Begimai},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={ChatGPT in the Classroom: Experimentation in a Python Class for Non-Computing Majors}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={AI-based chatbots such as ChatGPT present themselves as technologies to assist students in their learning. This study explores the use of ChatGPT in solving Python programming assignments in an introduction to computing class taken by students who are new to programming and non-computing majors. It uses a mixed research approach and involves experimental and control groups. The experimental group used ChatGPT, while the control group did not. The learning satisfaction and overall attitude of students toward ChatGPT, as well as gained Python skills, were analyzed and evaluated through surveys, Google Colab notebook assignments, and ChatGPT transcripts, as data collection instruments. While the study is limited in scope, it shows promising results as students considered the tool as an enabler to solve different programming problems. The study could not conclude that ChatGPT motivates students in learning Python. The evaluation of transcripts show that students need to be trained on how to use ChatGPT, from using critical thinking to writing prompts. In parallel, instructors have to change the way they create, reuse and present assignments to challenge students.},
  keywords={Surveys;Instruments;Writing;Data collection;Chatbots;Internet;Programming profession;ChatGPT;Introduction to Computing;Non-computing Majors;Python},
  doi={10.1109/ISEC61299.2024.10665172},
  ISSN={2473-7623},
  month={March},}@ARTICLE{10646468,
  author={Yu, Le and Wang, Lina and Cai, Jijing and Yang, Zijia and Wen, Long and Bashir, Ali Kashif and Wang, Wei},
  journal={IEEE Consumer Electronics Magazine}, 
  title={Consumer Electronics and GenAI Providing User Experiences in Mental Health}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={As consumer electronics become more ubiquitous and Generative Artificial Intelligence (GenAI) technologies advance rapidly, processing and analyzing semantic information collected from users to enhance their experiences becomes especially important. Traditionally, monitoring students' educational and psychological health has relied primarily on teachers, a method that is both inefficient and inadequate for comprehensively grasping students' needs. Therefore, the application of artificial intelligence is particularly critical. GenAI has the capability to gather semantic information from consumer electronics commonly used by students, such as smartphones, wearable devices, and tablets, and perform in-depth analysis. By analyzing curriculum schedules, GenAI can personalize learning paths and predict students' psychological states through examining individual mental health and media usage data. This paper explores how GenAI processes this information to intervene in students' education and psychological health, and discusses the analysis of adolescent mental health test data collected in recent years as well. Evidence suggests that students enrolled in high schools suffer from the highest rates of depression and major depressive disorder compared to other stages, at 40% and 12.5% respectively, underscoring the importance of using GenAI for educational and psychological health monitoring. The article summarizes the relevant technologies and models, highlighting the potential of GenAI in enhancing student well-being and academic performance.},
  keywords={Consumer electronics;Mental health;Education;Semantics;Psychology;Monitoring;Smart phones},
  doi={10.1109/MCE.2024.3449558},
  ISSN={2162-2256},
  month={},}@ARTICLE{10912437,
  author={Yang, Meiqi and Diao, Mingguang and Luo, Jiahuan and Shen, Weiqi and Zhang, Chuyan},
  journal={IEEE Access}, 
  title={GLM-4 Based Method for Automatic Construction of Content Graph}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Content graphs are essential for representing domain knowledge and play a significant role in digital education. To overcome the challenges associated with manual knowledge extraction and content structuring, including low efficiency, high costs, and a high risk of errors, and to improve teaching and learning quality, this paper presents an automated approach for constructing course content graphs for digital teaching platforms by utilizing a large language model. Specifically, the pre-trained GLM-4 model is utilized for semantic parsing and entity extraction, while a group query attention mechanism is applied to infer relationships between knowledge points, automatically transforming raw course content into structured tabular datasets. The process involves two steps: entity extraction and relationship recognition, which convert the original dataset into discrete knowledge points and output them in a structured format. The structured data is then visualized using the Neo4j graph database, enabling automated content graph construction. Experimental results show that this method significantly enhances the accuracy and efficiency of content graph construction, achieving an F1 score above 0.85 for entity extraction and relationship recognition accuracies of 0.82 and 0.80 before and after processing, respectively. Leveraging the model’s strong performance, a content graph with 393,600 triples—consisting of 9 entity types and 2 relationship types—has been constructed, covering the domain of software engineering courses. These results offer an effective and scalable solution to advance the intelligent development of digital teaching platforms.},
  keywords={Semantics;Education;Accuracy;Feature extraction;Computational modeling;Analytical models;Vectors;Software;Tokenization;Context modeling;Course content graph;Large language models;Tabular datasets;Grouped query attention;Entity extraction;Digital teaching platforms},
  doi={10.1109/ACCESS.2025.3548590},
  ISSN={2169-3536},
  month={},}
@INPROCEEDINGS{10554730,
  author={Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={320-330},
  abstract={Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs. However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.},
  keywords={Measurement;Training;Codes;Runtime;Organizations;Chatbots;Task analysis;Programming Assignment;Code Performance;Tool Support},
  doi={10.1145/3639474.3640065},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10819129,
  author={Čikić, Đorđe and Đorđević, Nikola and Janković, Dragan},
  booktitle={2024 32nd Telecommunications Forum (TELFOR)}, 
  title={Comparison of Ensemble Methods for Sentiment Analysis in Serbian Language}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Sentiment analysis plays a significant role in natural language processing (NLP). This paper compares different ensemble methods for Sentiment analysis in Serbian language, as a low-resource language. No previous studies have experimented with ensemble methods in Serbian language and therefore this is a novel study. Dataset used in our experiment consists of movie reviews in Serbian language. Our experiment shows that ensemble of Large Language Models (LLMs) like BERT, RoBERTa, GPT-2, DistilBERT, that represent Transformers-based architecture and traditional models can boost the accuracy of the system in comparison with the base learners mentioned.},
  keywords={Training;Sentiment analysis;Analytical models;Accuracy;Reviews;Large language models;Transformers;Probability distribution;Telecommunications;Ensemble learning;sentiment analysis;ensemble methods;natural language processing;large language models},
  doi={10.1109/TELFOR63250.2024.10819129},
  ISSN={2994-5828},
  month={Nov},}@INPROCEEDINGS{10402376,
  author={Zagirniak, Denys and Shalimova, Nataliia and Akmaldinova, Oleksandra and Stezhko, Yuri and Perevozniuk, Viktoriia},
  booktitle={2023 IEEE 5th International Conference on Modern Electrical and Energy System (MEES)}, 
  title={Transformation of Education in the Context of Modern Informational and Cultural Realities of Artificial Intelligence ChatGPT Application}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The article is intended to provide an idea of the role of artificial intelligence in education in the postmodern situation. The emergence of ChatGPT with artificial intelligence has caused concern in society about possible threats and negative consequences, in particular, for education. Publications abound with warnings that artificial intelligence is capable of surpassing human intelligence. Therefore, the article substantiates the inability of ChatGPT to generate innovative ideas of the level of social intelligence. The generation of ideas by artificial intelligence burdened by formal logic does not accommodate innovation. The provision on the priority of authentic intelligence over its artificial prototype is substantiated. The role of integrity, responsibility and other personal qualities of the acquirer of knowledge in the application of the capabilities of artificial intelligence is revealed. The result of penetration of artificial intelligence into the area of postmodern cultural transformations is the humanitarianization of education in general and engineering in particular, overcoming its alienation from the value demands of society. The representation of reality in professional creativity is the parity of rational and irrational forms of knowledge. Professional competence involves systematic knowledge based on the integration of natural, mathematical, technical and social sciences, rethinking the very philosophy of education. The conducted experiment proved that in modern projecting as a mutual condition of divergent and convergent thinking, the advantage in the selection of ideas for innovation belongs to artificial intelligence. It is noted that with proper organization, the involvement of ChatGPT will lead to the intensification of the educational process, will become a personalized assistant for the student, a means of his release from routine work. It is mentioned that the expressed moderate optimism regarding the prospects of education in the realities of artificial intelligence conditions is based on the philosophical understanding of the priority of social creativity over its machine organization.},
  keywords={Training;Technological innovation;Education;Process control;Organizations;Chatbots;Artificial intelligence;education;artificial intelligence;creativity;innovativeness;postmodern culture;humanitarianization of education},
  doi={10.1109/MEES61502.2023.10402376},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10469498,
  author={Lee, Kuan-Yin and Hong, Cai-Lian},
  booktitle={2023 IEEE 3rd International Conference on Social Sciences and Intelligence Management (SSIM)}, 
  title={Usage Intentions of AIGC: From Social Media Conversation Volume and Consumer Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={328-333},
  abstract={In November 2022, OpenAI launched the ChatGPT chatbot, and within just two months, it had garnered one hundred million registrations. The introduction of ChatGPT has generated significant attention and discussions online. Its applications are incredibly diverse, impacting the development of numerous industries. It has improved work efficiency in the business sector, enhanced customer service, expanded market analysis, assisted in daily tasks, and provided personalized recommendations. In education, it has aided students in personalized learning, answering questions, and providing explanations. With the advancement of technology, Internet usage and social media have been used widely the current generation, particularly the Z generation. Social media has become a habitual practice, changing people's social habits. Social media provides a platform for communication, sharing images and videos, as well as interacting, commenting, and sharing other people's content. Utilizing the CHOOSE public option analysis platform developed by Blue Planet, we explores articles discussing ChatGPT on social media and analyzes the sources of conversation volume using the public option analysis to understand the level of interest and favorability of social media users regarding ChatGPT.},
  keywords={Social networking (online);Planets;Education;Social sciences;Oral communication;Media;Chatbots;AI technology;social media conversation volume;favorability},
  doi={10.1109/SSIM59263.2023.10469498},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10773596,
  author={Gerede, Çağdaş Evren},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Are We Asking the Right Questions to ChatGPT for Learning Software Design Patterns?}, 
  year={2024},
  volume={},
  number={},
  pages={1092-1097},
  abstract={The emergence of AI-powered chatbots like ChatGPT has generated excitement in many fields, including education. Some see this technology as a tool with a transformative impact similar to that of the printing press or the Internet. In this paper, we evaluate how effectively undergraduate computer engineering students can use this technology and the challenges they encounter in their interactions with ChatGPT. To this end, we examined whether students could ask effective questions to ChatGPT while learning software design patterns with its assistance. Based on our findings, we provide curriculum recommendations to improve the integration of ChatGPT into undergraduate computer engineering education.},
  keywords={Computer science;Software design;Education;Chatbots;Internet;Computer science education;Engineering students;Printing machinery;ChatGPT;AI in higher education;computer engineering education;software design patterns;self-learning;effective questioning},
  doi={10.1109/UBMK63289.2024.10773596},
  ISSN={2521-1641},
  month={Oct},}@INPROCEEDINGS{10270477,
  author={Abdelfattah, Aly Maher and Ali, Nabila Ahmed and Elaziz, Mohamed Abd and Ammar, Hany H},
  booktitle={2023 International Conference on Artificial Intelligence Science and Applications in Industry and Society (CAISAIS)}, 
  title={Roadmap for Software Engineering Education using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a novel method for teaching software engineering using the AI tool, ChatGPT, to create an engaging and immersive learning platform. The technique emphasizes understanding requirements engineering principles via interactive exercises and hands-on examples. The approach involves ChatGPT assisting in collecting user stories, creating a use case and class diagrams, and formulating sequence diagrams. This method employs an agile strategy focusing on select user stories and encourages student interaction with ChatGPT for a deeper understanding of the subject. The goal is to demonstrate the potential of AI tools to transform software engineering education by providing practical applications and real-life scenarios. The research outlines a comprehensive plan for integrating ChatGPT into a software engineering syllabus, focusing on requirements engineering. The findings could significantly influence the teaching and understanding of software engineering principles, benefiting educators and students.},
  keywords={Learning systems;Industries;Education;Focusing;Virtual reality;Transforms;Learning (artificial intelligence);Software engineering education;Interactive learning environment;ChatGPT;Requirements engineering;Agile process;AI in education},
  doi={10.1109/CAISAIS59399.2023.10270477},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10420194,
  author={Padilla, Jay Rhald C. and Montefalcon, Myron Darrel L. and Hernandez, Alexander A.},
  booktitle={2023 IEEE 11th Conference on Systems, Process & Control (ICSPC)}, 
  title={Language AI in Programming: A Case Study of ChatGPT in Higher Eduation Using Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={276-281},
  abstract={ChatGPT is an emerging technology used in education. It provides promising support to enhance teaching and learning activities. However, there is lacking understanding of its use to programming courses in computing programs. This study investigates the benefits, issues, and challenges of using ChatGPT, a language AI model, in programming tasks. Data was collected through surveys administered to undergraduate students in computing programs across various National Capital Region (NCR) universities. The collected data was analyzed using Natural Language Processing (NLP) and Latent Dirichlet Allocation (LDA) techniques to gain insights from the students responses. A word intrusion test assessed theme coherence, and evaluators demonstrated moderate agreement (Fleiss Kappa score: 0.62). The study reveals the benefits of employing ChatGPT for programming, including efficient coding, understanding complex codes, and its capability to be used as a problem-solving tool. However, it highlights critical issues and challenges, such as data privacy and ethical concerns, plagiarism tendencies, and contextual understanding limitations. The findings contribute valuable insights for developers, educators, and researchers interested in leveraging language AI models like ChatGPT to enhance programming workflows while effectively addressing associated challenges.},
  keywords={Education;Chatbots;Resource management;Problem-solving;Artificial intelligence;Task analysis;Programming profession;chatGPT;natural language processing;latent dirichlet allocation;artificial intelligence;programming;artificial intelligence in education},
  doi={10.1109/ICSPC59664.2023.10420194},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10297824,
  author={Butgereit, Laurie and Martinus, Herman and Abugosseisa, Muna Mahmoud},
  booktitle={2023 IEEE 27th International Conference on Intelligent Engineering Systems (INES)}, 
  title={Prof Pi: Tutoring Mathematics in Arabic Language using GPT-4 and Whatsapp}, 
  year={2023},
  volume={},
  number={},
  pages={000161-000164},
  abstract={Prof Pi is a mathematics tutoring system which is available using the Whatsapp chat facility, the Telegram chat facility, and the web. It is driven by GPT-4 (the underlying API behind chatGPT). Prof Pi allows participants to ask questions about specific mathematics problems. Prof Pi is specifically designed to NOT simply answer the mathematics questions but to, rather, guide the participants into solving their problems on their own. Although originally conceived to be an English language mathematics tutor, this paper describes a project of using the Prof Pi service in Khartoum, Sudan, to help university students with their mathematics problems using the Arabic language.},
  keywords={Freeware;Chatbots;Mathematics;Internet telephony;Prof Pi;math tutoring;GPT-4;Whatsapp},
  doi={10.1109/INES59282.2023.10297824},
  ISSN={1543-9259},
  month={July},}@INPROCEEDINGS{10795104,
  author={Kruse, Hans-Alexander and Puhlfürϐ, Tim and Maalej, Walid},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Can Developers Prompt? A Controlled Experiment for Code Documentation Generation}, 
  year={2024},
  volume={},
  number={},
  pages={574-586},
  abstract={Large language models (LLMs) bear great potential for automating tedious development tasks such as creating and maintaining code documentation. However, it is unclear to what extent developers can effectively prompt LLMs to create concise and useful documentation. We report on a controlled experiment with 20 professionals and 30 computer science students tasked with code documentation generation for two Python functions. The experimental group freely entered ad-hoc prompts in a Chat- GPT-like extension of Visual Studio Code, while the control group executed a predefined few-shot prompt. Our results reveal that professionals and students were unaware of or unable to apply prompt engineering techniques. Especially students perceived the documentation produced from ad-hoc prompts as significantly less readable, less concise, and less helpful than documentation from prepared prompts. Some professionals produced higher quality documentation by just including the keyword Docstring in their ad-hoc prompts. While students desired more support in formulating prompts, professionals appreciated the flexibility of ad-hoc prompting. Participants in both groups rarely assessed the output as perfect. Instead, they understood the tools as support to iteratively refine the documentation. Further research is needed to understand which prompting skills and preferences developers have and which support they need for certain tasks.},
  keywords={Computer science;Visualization;Software maintenance;Codes;Large language models;Documentation;Prompt engineering;Iterative methods;Python;Software Documentation;Large Language Model;Program Comprehension;Developer Study;AI4SE},
  doi={10.1109/ICSME58944.2024.00058},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{11016480,
  author={Strachan, Rebecca and Anderson, Emma and Oguna, Cynthia and Oruche, Ugochukwu},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={An Exploratory Study of Senior Computing UK Academic Faculty Perspectives on Academic Integrity and Student Cheating}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The expansion of essay mills and the recent emerging opportunities presented by generative Artificial Intelligence tools have led to fresh concerns about the authenticity of students' assessed work. These changes mean it is timely to revisit academic integrity within the UK Higher Education computing community. The aim of this research is to explore the current perspectives of senior computing academics on academic integrity and student cheating, particularly given the rapid development of generative AI tools and resources and the growth in essay mills. An exploratory research approach was adopted using a mixed methods approach. A critical literature review was undertaken and this together with the researcher team's expertise was used to underpin the design of the practical research activities. A survey was conducted of UK higher education senior academics (response rate, $\mathrm{n}=16$). The results from this informed a set of in-depth individual semistructured interviews with senior UK computing academics $(\mathrm{n}=5)$. Descriptive statistics were used to analyse the quantitative survey data and exploratory thematic analysis undertaken with the qualitative data from the survey and interviews. Methodological triangulation was used across these data sets to inform the key findings and their interpretation and discussion. The findings demonstrate that senior computing academics are concerned about the levels and types of student cheating on their assessed work. The reasons for this are complex and multifaceted, with no simple solution. Academic misconduct is perceived to adversely affect academic standards. Challenges with the detection and investigation of student cheating and the need to ensure consistency of approach by all staff are highlighted. Action is needed urgently and respondents emphasize that this should focus on prevention rather than detection of academic misconduct. These findings have informed a set of recommendations to promote good academic practice and integrity across the UK Higher Education computing community. The findings also highlight that in order to implement these recommendations, staff, students and their departments/institutions need to come together and draw on each others' expertise and experiences to enable a high-quality ethical learning experience.},
  keywords={Surveys;Ethics;Generative AI;Prevention and mitigation;Interviews;Engineering education;Standards;Systematic literature review;academic integrity;academic misconduct;student cheating;essay mills;generative AI;authenticity},
  doi={10.1109/EDUCON62633.2025.11016480},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10314331,
  author={Yu, Dan and Ai, Jun and Su, Haorao and Zhang, Hong},
  booktitle={2023 10th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Assessing ChatGPT’s Comprehension of Perturbed Text through Text Linguistic Features}, 
  year={2023},
  volume={},
  number={},
  pages={839-850},
  abstract={This paper presents an evaluation method for assessing ChatGPT’s ability to understand perturbed text, offering a novel approach to evaluating the robustness of large language models from a text understanding perspective. The proposed method analyzes ChatGPT’s comprehension of perturbed text across three dimensions: static sensitivity, dynamic sensitivity, and comprehensive ability. This is achieved through the utilization of traditional metrics and a difference norm based on textual linguistic features. The integration of linguistic features into the assessment of text perturbation degree provides a fast, efficient, and accurate evaluation method that can be easily applied to other large language models. Analysing of results identifies perturbations with high static and dynamic sensitivity for ChatGPT, and assesses its comprehensive comprehension both qualitatively and quantitatively.},
  keywords={Deep learning;Sensitivity;Perturbation methods;Refining;Linguistics;Chatbots;Robustness;ChatGPT;Perturbation;Robustness;Linguistic feature;Large Language Model},
  doi={10.1109/DSA59317.2023.00119},
  ISSN={2767-6684},
  month={Aug},}@ARTICLE{10379820,
  author={Li, Bai and Xu, Tian'ao and Li, Xinyuan and Cui, Yaodong and Bian, Xuepeng and Teng, Siyu and Ma, Siji and Fan, Lili and Tian, Yonglin and Wang, Fei-Yue},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Integrating Large Language Models and Metaverse in Autonomous Racing: An Education-Oriented Perspective}, 
  year={2024},
  volume={9},
  number={1},
  pages={59-64},
  abstract={This letter is the third report from a series of IEEE TIV's decentralized and hybrid workshops (DHWs) on intelligent vehicles for education (IV4E). Autonomous racing serves as a vital platform for nurturing engineering talents among university students, contributing to the development of skills essential for the intelligent vehicle industry. This letter investigates how recent emerging techniques, such as large language models (LLMs) and the Metaverse, can contribute to organizing IV4E-oriented autonomous racing events. Among these DHWs, scholars from diverse fields have collectively explored the integration of LLMs and the Metaverse into autonomous racing for educational purposes. The discussions emphasize the role of Metaverse in creating dynamic and immersive training virtual reality platforms and the role of LLMs in enhancing race commentary and the spectator experience. Within this context, the Metaverse introduces complex scenarios to the racetrack, maintaining suspense about the winning team until a race's final moment. This dynamic feature excites the race and motivates the participating teams to intensify their competition efforts. LLMs facilitate personalized commentary, inspiring spectators to become future participants in these races. Our DHWs highlighted a future in which technology, autonomy, and education intersect, fostering inclusive, educational, and engaging autonomous racing events.},
  keywords={},
  doi={10.1109/TIV.2024.3349466},
  ISSN={2379-8904},
  month={Jan},}@INPROCEEDINGS{11016517,
  author={Park, Seong Min and Ho, Marco and Lin, Michael Pin-Chuan and Ryoo, Jeeho},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Evaluating the Impact of Assistive AI Tools on Learning Outcomes and Ethical Considerations in Programming Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This study critically evaluates the efficacy of GitHub Copilot in low-level programming education, specifically within C programming tasks involving complex concepts like memory management and pointer manipulation. While AI tools have shown promise in supporting high-level programming, its impact on skill-intensive, low-level contexts remains underexplored. We conducted a within-subject experimental study with 34 graduate computer science students, assessing performance on AI -assisted and independent tasks. Statistical analyses revealed that Copilot, one of the AI programming tools, enhances productivity in routine coding activities; however, it is insufficient for tasks requiring deep problem-solving skills. Notably, a significant performance decline in AI-free tasks suggests a dependency on Copilot that may hinder the development of essential independent problem-solving abilities. Survey feedback underscores ethical concerns, with 40.6 % of students expressing uncertainty about responsible AI usage and potential over-reliance. These findings highlight the ne-cessity for structured instructional practices, including AI-free assessments and clear ethical guidelines, to promote balanced technology integration in programming education. This study contributes to educational theory by illuminating the limitations of generative AI within constructivist and self-regulated learning frameworks. Future research should explore the long-term effects of AI dependency on technical skill development and investigate AI advancements tailored for low-level programming to better support foundational skills.},
  keywords={Productivity;Ethics;Memory management;Debugging;Encoding;Problem-solving;Artificial intelligence;Programming profession;Software development management;Guidelines;GitHub Copilot;C Programming;Dependency in Learning;Constructivist Learning;Self-Regulated Learning;Educational Technology Ethics;AI-Assisted Learning;Program-ming Education;Academic Integrity in AI},
  doi={10.1109/EDUCON62633.2025.11016517},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10819409,
  author={Liu, Qiming and Yang, Ruirong and Gao, Qin and Liang, Tengxiao and Wang, Xiuyuan and Li, Shiju and Lei, Bingyin and Gao, Kaiye},
  journal={IEEE Access}, 
  title={A Review of Applying Large Language Models in Healthcare}, 
  year={2025},
  volume={13},
  number={},
  pages={6878-6892},
  abstract={In response to the growing demand for healthcare and the increasing importance people place on medical services, efficiently meeting these needs within the constraints of limited healthcare resources is of great social and economic benefit. Therefore, research into applying Large Language Models (LLMs) in the healthcare sector holds significant importance. This paper provides a review of the research progress on the application of LLMs in the healthcare field. First, the basic framework of LLMs is summarized, and the training process of LLMs in healthcare is systematically reviewed. Next, six specific application areas of LLMs in healthcare are reviewed: disease diagnosis and decision support, dissemination of medical knowledge, medical assistance, medical image analysis, biomedicine, and medical education. Then, several representative healthcare-specific LLMs are discussed, along with their performance analysis. Following this, the challenges faced by LLMs in healthcare are summarized, and relevant suggestions are provided. The future development trends of LLMs in healthcare are also explored. Finally, a bibliometric analysis is performed. Through the literature review, we found: 1) After pretraining, LLMs are widely adaptable to downstream tasks, significantly enhancing processing performance and efficiency; 2) LLMs in healthcare possess multiple capabilities and can handle multimodal data; 3) Bibliometric analysis shows that researchers are paying increasing attention to the application of LLMs in healthcare; 4) Further research is needed in optimizing, improving reliability, and expanding practical applications of large healthcare models.},
  keywords={Medical services;Large language models;Training;Transformers;Medical diagnostic imaging;Biological system modeling;Bibliometrics;Analytical models;Mathematical models;Market research;Healthcare;large language models;literature bibliometric;medical},
  doi={10.1109/ACCESS.2024.3524588},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10172763,
  author={Kang, Sungmin and Yoon, Juyeon and Yoo, Shin},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)}, 
  title={Large Language Models are Few-shot Testers: Exploring LLM-based General Bug Reproduction}, 
  year={2023},
  volume={},
  number={},
  pages={2312-2323},
  abstract={Many automated test generation techniques have been developed to aid developers with writing tests. To facilitate full automation, most existing techniques aim to either increase coverage, or generate exploratory inputs. However, existing test generation techniques largely fall short of achieving more semantic objectives, such as generating tests to reproduce a given bug report. Reproducing bugs is nonetheless important, as our empirical study shows that the number of tests added in open source repositories due to issues was about 28% of the corresponding project test suite size. Meanwhile, due to the difficulties of transforming the expected program semantics in bug reports into test oracles, existing failure reproduction techniques tend to deal exclusively with program crashes, a small subset of all bug reports. To automate test generation from general bug reports, we propose Libro, a framework that uses Large Language Models (LLMs), which have been shown to be capable of performing code-related tasks. Since LLMs themselves cannot execute the target buggy code, we focus on post-processing steps that help us discern when LLMs are effective, and rank the produced tests according to their validity. Our evaluation of Libro shows that, on the widely studied Defects4J benchmark, Libro can generate failure reproducing test cases for 33% of all studied cases (251 out of 750), while suggesting a bug reproducing test in first place for 149 bugs. To mitigate data contamination (i.e., the possibility of the LLM simply remembering the test code either partially or in whole), we also evaluate Libro against 31 bug reports submitted after the collection of the LLM training data terminated: Libro produces bug reproducing tests for 32% of the studied bug reports. Overall, our results show Libro has the potential to significantly enhance developer efficiency by automatically generating tests from bug reports.},
  keywords={Codes;Computer bugs;Semantics;Training data;Benchmark testing;Writing;Test pattern generators;test generation;natural language processing;software engineering},
  doi={10.1109/ICSE48619.2023.00194},
  ISSN={1558-1225},
  month={May},}@INPROCEEDINGS{10857545,
  author={Yadagiri, Annepaka and Pakray, Partha},
  booktitle={2025 19th International Conference on Ubiquitous Information Management and Communication (IMCOM)}, 
  title={Deep Learning Strategies for Identifying Machine-Generated Text}, 
  year={2025},
  volume={},
  number={},
  pages={1-8},
  abstract={Generative AIs like LLMs are now accessible to the general public. For example, students can utilize these tools to create essays or complete theses. However, how is a teacher supposed to determine if a text was composed by the student or an AI? Using deep learning techniques, we investigate novel and classic approaches for detecting text created by artificial intelligence. We also study the more complex instance when the AI is asked to write the text in a way that a human would not recognize as AI-generated, as we discovered that categorization is more challenging in this scenario. For our studies, we used llm-detect-ai-generated text from the Kaggle competition dataset, which included texts written by students and texts produced using different LLMs. Our top systems achieve an accuracy of 0.98% and F1 scores of more than 0.98% in classifying simple and complex texts produced by humans and AI-Genereted. The systems combine features such as TF-IDF vectorization, word2Vec, and word embedding properties. Our findings demonstrate that these additional characteristics significantly enhance the performance of several classifiers. Compared to deep learning models, our best-performing model for detecting AI-generated text outperforms even the fine-tuned ROBERTA-Open-AI classifier, achieving an accuracy of 0.98%. This underscores the efficacy of our proposed approach in distinguishing between human and AI-generated content.},
  keywords={Deep learning;Training;Adaptation models;Accuracy;Text recognition;Text categorization;Text detection;Detectors;Transformers;Information management;Large Language Models;Natural Language Processing;Neural Networks;Generative AI},
  doi={10.1109/IMCOM64595.2025.10857545},
  ISSN={},
  month={Jan},}@ARTICLE{10183726,
  author={Amaro, Ilaria and Barra, Paola and Greca, Attilio Della and Francese, Rita and Tucci, Cesare},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Believe in Artificial Intelligence? A User Study on the ChatGPT’s Fake Information Impact}, 
  year={2024},
  volume={11},
  number={4},
  pages={5168-5177},
  abstract={Technological evolution has enabled the development of new artificial intelligence (AI) models with generative capabilities. Among them, one of the most discussed is the virtual agent ChatGPT. This chatbot may occasionally produce fake information, as also declared by the producer OpenAI. Such a model may provide very useful support in several tasks, ranging from text summarization to programming. The research community has marginally investigated the impact that fake information created by AI models has on the users’ perceptions and on their belief in AI. We analyzed the impact of the fake information produced by AI on user perceptions, specifically trust and satisfaction, by performing a user study on ChatGPT. An additional issue is assessing whether the early or late knowledge of the possibility of the tool generating fake information has a different impact on the users’ perceptions. We conducted an experiment, involving 62 university students, a category of users who may employ tools such as ChatGPT extensively. The experiment consisted of a guided interaction with ChatGPT. Some of the participants experienced the failure of the chatbot, while a control group only received correct and reliable answers. We collected participants’ perceptions of trust, satisfaction, and usability, together with the net promoter score (NPS). The results demonstrated a statistically significant difference in trust and satisfaction between the users who early experienced fake information production compared to those who discovered ChatGPT’s faulty behaviors later during the interaction. Also, there is no statistically significant difference among the users who received the late fake information and the control group (no fake information). Usability and the NPS also resulted higher when the fake news was detected in the late interaction. When users are aware of the fake information generated by ChatGPT their trust and satisfaction decrease, especially when they impact on this at the early stage of use of the chatbot. Nevertheless, the perception of trust and satisfaction still remains high, as some of the users are still enthusiastic; others consider a more conscious use of the tool in terms of support to be verified. A useful strategy could be to favor a critical use of ChatGPT, letting young people to verify the provided information. This should be a new way to perform learning activities.},
  keywords={Chatbots;Artificial intelligence;Reliability;Usability;Ethics;Trajectory;Fake news;Trust management;Believe artificial intelligence (AI);ChatGPT;controlled experiment;fake information;trust in AI},
  doi={10.1109/TCSS.2023.3291539},
  ISSN={2329-924X},
  month={Aug},}@INPROCEEDINGS{10554713,
  author={Fwa, Hua Leong},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Experience Report: Identifying Common Misconceptions and Errors of Novice Programmers with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={233-241},
  abstract={Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.},
  keywords={Training;Adaptation models;Codes;Manuals;Knowledge representation;Syntactics;Chatbots;LLM;ChatGPT;misconception;programming;errors;cluster;prompts},
  doi={10.1145/3639474.3640059},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10893083,
  author={Azemi, Asad},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Navigating the Dual Edges of AI in Engineering Education: Opportunities, Challenges, and Societal Readiness}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This research full paper describes how integrating Artificial Intelligence (AI) in engineering education represents a transformative shift with profound implications. In this work, we outline the multifaceted impact of AI, emphasizing its benefits and potential misuse within the classroom, and extend to consider its broader societal implications. AI's introduction in engineering education signals a new era of personalized learning environments. Its capacity for analyzing vast data sets enables tailored educational experiences, addressing individual student needs with unprecedented precision. AI-driven tools can identify learning gaps and provide customized resources, optimizing the learning process. These advancements are not without pitfalls. A notable concern is the misuse of AI by students, such as leveraging AI to complete assignments unethically, which undermines learning objectives and academic integrity. Beyond the classroom, AI's influence on society, particularly in the labor market, is a double-edged sword. AI poses a threat to traditional job markets. Automation risks displacing a significant portion of the workforce, particularly in sectors reliant on routine tasks. We have emphasized the importance of a balanced approach, advocating for the responsible integration of AI in educational settings with human oversight to prevent unethical use, potential job displacement, and other societal impacts. We have also advocated for studying and designing new pedagogical approaches and courses that would integrate AI-based applications such as ChatGPT to enhance problem-solving and critical thinking among students.},
  keywords={Automation;Navigation;Chatbots;Problem-solving;Artificial intelligence;Engineering education;Artificial Intelligence;Large Language Model;ChatGPT;Learning Methodologies},
  doi={10.1109/FIE61694.2024.10893083},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{10510580,
  author={Maita, Idria and Saide, Saide and Putri, Afifah Mesha and Muwardi, Didi},
  journal={IEEE Engineering Management Review}, 
  title={Pros and Cons of Artificial Intelligence–ChatGPT Adoption in Education Settings: A Literature Review and Future Research Agendas}, 
  year={2024},
  volume={52},
  number={3},
  pages={27-42},
  abstract={The integration of artificial intelligence, particularly ChatGPT, in education presents both promising opportunities and notable challenges. Through a systematic review employing the PRISMA method, this article analyzed 45 references published of ChatGPTs impact on educational environments. While ChatGPT offers teachers a versatile learning tool, aiding in tasks, such as lesson planning and content generation, concerns regarding academic integrity and over-reliance on technology have emerged. Ethical considerations, including the potential for cheating in assignments and exams, highlight the need for clear guidelines and ethical frameworks to govern its use. Institutions or related organizations must address issues, such as plagiarism and data privacy, to ensure responsible integration of ChatGPT. Nurturing a growth mindset among educators and learners is crucial to effectively navigate ChatGPT integration. By aligning strategies to leverage ChatGPTs’ capabilities while mitigating risks, educators, institutions, and policymakers can enhance the quality of education in an evolving technological landscape. This article contributes to a deeper understanding of ChatGPTs’ implications in education, providing insights into its advantages and challenges. Informed decision making and proactive measures are essential to harness ChatGPTs potential for transformative impact while safeguarding educational integrity and ethics.},
  keywords={Chatbots;Artificial intelligence;Education;Information systems;Robots;Knowledge transfer;Ethics;Artificial intelligence (AI);chatGPT;digital pedagogy;educational technology;educators;information systems;knowledge management (KM);pros–cons circumstance;students},
  doi={10.1109/EMR.2024.3394540},
  ISSN={1937-4178},
  month={June},}@INPROCEEDINGS{10850835,
  author={Krupáš, Maroš and Antonets, Liudmyla and Vaščák, Ján and Zolotová, Iveta},
  booktitle={2024 International Conference on Emerging eLearning Technologies and Applications (ICETA)}, 
  title={AI-Based Assistant: LLMs for Effective Robotics Education and Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Large language models (LLMs) offer new educational and research opportunities by enabling personalized learning, providing tutoring and assistance and enhancing accessibility. This paper examines the current application solutions of LLMs in education and their usability, benefits, and challenges. Through our use case and experimental data on Turtlebot3 education robots, we discuss the potential of different transformer-based LLMs and their limitations to improve educational and research outcomes for students working with robotic systems in laboratory conditions. We also evaluated selected models based on quantitative and qualitative metrics to choose one which was best suited for our AI-based education and research assistant use case.},
  keywords={Measurement;Technological innovation;Systematics;Education;Transformers;Data models;Usability;Robots;Tuning;Testing;AI-based education and research assistant;Large Language Models (LLM);generative pre-trained transformers;robotics education;Turtlebot3},
  doi={10.1109/ICETA63795.2024.10850835},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10825748,
  author={Wu, Jinlin and Liang, Xusheng and Bai, Xuexue and Chen, Zhen},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={SurgBox: Agent-Driven Operating Room Sandbox with Surgery Copilot}, 
  year={2024},
  volume={},
  number={},
  pages={2041-2048},
  abstract={Surgical interventions, particularly in neurology, represent complex and high-stakes scenarios that impose substantial cognitive burdens on surgical teams. Although deliberate education and practice can enhance cognitive capabilities, surgical training opportunities remain limited due to patient safety concerns. To address these cognitive challenges in surgical training and operation, we propose SurgBox, an agent-driven sandbox framework to systematically enhance the cognitive capabilities of surgeons in immersive surgical simulations. Specifically, our SurgBox leverages large language models (LLMs) with tailored Retrieval-Augmented Generation (RAG) to authentically replicate various surgical roles, enabling realistic training environments for deliberate practice. In particular, we devise Surgery Copilot, an AI-driven assistant to actively coordinate the surgical information stream and support clinical decision-making, thereby diminishing the cognitive workload of surgical teams during surgery. By incorporating a novel Long-Short Memory mechanism, our Surgery Copilot can effectively balance immediate procedural assistance with comprehensive surgical knowledge. Extensive experiments using real neurosurgical procedure records validate our SurgBox framework in both enhancing surgical cognitive capabilities and supporting clinical decision-making. By providing an integrated solution for training and operational support to address cognitive challenges, our SurgBox framework advances surgical education and practice, potentially transforming surgical outcomes and healthcare quality. The code is available at https://github.com/franciszchen/SurgBox.},
  keywords={Training;Neurology;Decision making;Retrieval augmented generation;Surgery;Virtual environments;Medical services;Safety;Neurosurgery;Load modeling;Surgery Simulation;Surgery Copilot;Neurosurgery;Large Language Models},
  doi={10.1109/BigData62323.2024.10825748},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{11016497,
  author={i Vilar, Guiu Puigcercos and Rashid, Parvez and Tonekaboni, Navid Hashemi},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Accessible and Reliable AI Coding Tutors: Augmenting Large Language Models with Retrieval-Augmented Generation for Java Programming}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper addresses the challenge of improving the reliability and accuracy of Large Language Models (LLMs) for assisting students in learning Java programming, a critical component of object-oriented computer science courses. While LLMs have shown promise in generating code, they often produce incorrect or unreliable outputs, which can hinder the learning process. To mitigate these issues, we propose a novel augmentation framework that integrates Retrieval-Augmented Generation (RAG), enabling LLMs to retrieve best-practice Java code examples from external sources to enhance the accuracy of generated solutions. We evaluate this framework using 250 Java coding tasks, covering a range of difficulties. Our findings show that the RAG-augmented model, when applied to a lightweight LLM (Google DeepMind's Gemma), outperformed baseline model by 19 % for mid and high-difficulty problems. In particular, Augmented Gemma generated accepted code for 11 problems where no other model could provide a valid solution. This suggests that retrieving external best-practice examples is critical in addressing complex coding challenges. These results highlight the potential of lightweight, accessible models enhanced with RAG to provide reliable AI coding assistance in educational settings, facilitating both accurate problem-solving and reinforcement of best coding practices.},
  keywords={Java;Codes;Accuracy;Object oriented modeling;Large language models;Retrieval augmented generation;Reliability engineering;Encoding;Problem-solving;Programming profession;Large Language Models (LLMs);Retrieval Augmented Generation (RAG);Coding Assistant;Open-source models;Java programming language;Artificial Intelligence},
  doi={10.1109/EDUCON62633.2025.11016497},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10935983,
  author={Ruf, Boris and Detyniecki, Marcin},
  booktitle={2024 International Symposium on Multimedia (ISM)}, 
  title={The ≪Huh?≫ Button: Improving Understanding in Educational Videos with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={285-289},
  abstract={We propose a simple way to use large language models (LLMs) in education. Specifically, our method aims to improve individual comprehension by adding a novel feature to online videos. We combine the low threshold for interactivity in digital experiences with the benefits of rephrased and elaborated explanations typical of face-to-face interactions, thereby supporting to close knowledge gaps at scale. To demonstrate the technical feasibility of our approach, we conducted a proof-of-concept experiment and implemented a prototype which is available for testing online. Through the use case, we also show how caching can be applied in LLM-powered applications to reduce their carbon footprint.},
  keywords={Human computer interaction;Generative AI;Large language models;Prototypes;Educational technology;Streaming media;Carbon footprint;Videos;Testing;Educational Technology;Human Computer Interaction;Generative AI;Large Language Models},
  doi={10.1109/ISM63611.2024.00064},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{11015021,
  author={Pandini, Gabriele and Martini, Antonio and Videsjorden, Adela Nedisan and Fontana, Francesca Arcelli},
  booktitle={2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C)}, 
  title={An Exploratory Study on Architectural Smell Refactoring Using Large Languages Models}, 
  year={2025},
  volume={},
  number={},
  pages={462-471},
  abstract={Architectural smells are abundant in codebases and regularly hinder the development of stable and maintainable code. Understanding and removing these elements can consume a huge amount of developers' time, who often need to prioritize implementing new features. This causes a substantial increase in Technical Debt, compromising the scalability and maintainability of the codebases, at time bringing the development to a standstill. Meanwhile, the use of Large Language Models for small error correction is constantly growing, bringing the attention of an ever-wider audience to these technologies. This study explores a first approach to use Large Language Models to suggest refactoring for architectural smells, with a focus on Cyclic Dependencies smells. We study the use of detailed prompt and Retrieval-Augmented Generation (RAG) to enhance LLMs, and we study local vs cloud LLMs. The results are promising, also validated with a series of interviews with students and developers, and highlight how additional and precise context is key to enhance the use of LLMs to propose refactoring suggestions. A multi-agent approach seems to be more suited when increasing the complexity of the smells.},
  keywords={Codes;Software architecture;Large language models;Scalability;Retrieval augmented generation;Error correction;Complexity theory;Interviews;Architectural Smell;Refactoring;LLM;RAG},
  doi={10.1109/ICSA-C65153.2025.00070},
  ISSN={2768-4288},
  month={March},}@ARTICLE{10849533,
  author={Cubillos, Claudio and Mellado, Rafael and Cabrera-Paniagua, Daniel and Urra, Enrique},
  journal={IEEE Access}, 
  title={Generative Artificial Intelligence in Computer Programming: Does It Enhance Learning, Motivation, and the Learning Environment?}, 
  year={2025},
  volume={13},
  number={},
  pages={40438-40455},
  abstract={Generative artificial intelligence (GenAI) is emerging as a transformative technology in higher education, particularly in programming instruction. However, its impact on learning, motivation, and the educational environment must still be fully understood. This study aims to determine the capacity of GenAI to generate effective computer programming learning in STEM university students, comparing it with active learning methods based on video. An experiment was conducted with 40 computer engineering students divided into two groups: one using GenAI (Google Gemini 1.5) and another employing educational videos. Pre- and post-tests of knowledge and the Intrinsic Motivation Inventory (IMI) were applied to evaluate learning, intrinsic motivation, and the learning environment. No significant differences in learning were found between the groups. However, GenAI significantly increased perceived autonomy and reduced perceived effort and pressure, while video-based learning significantly improved perceived competence. These findings suggest that both methods seem to motivate in diverse ways and that they could complement each other in an integrated teaching approach, offering new perspectives for designing programming learning environments in higher education.},
  keywords={Programming profession;Education;Learning (artificial intelligence);Generative AI;Codes;Artificial intelligence;Focusing;Active learning;Ethics;Chatbots;Generative artificial intelligence;programming education;intrinsic motivation;active learning;engineering programming},
  doi={10.1109/ACCESS.2025.3532883},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10590353,
  author={Painter, Jeffery L. and Mahaux, Olivia and Vanini, Marco and Kara, Vijay and Roshan, Christie and Karwowski, Marcin and Chalamalasetti, Venkateswara Rao and Bate, Andrew},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Enhancing Drug Safety Documentation Search Capabilities with Large Language Models: A User-Centric Approach}, 
  year={2023},
  volume={},
  number={},
  pages={49-56},
  abstract={Integrating Large Language Models (LLMs) to enhance complex business document retrieval represents an emerging field known as retrieval-augmented generation (RAG). In highly regulated domains like drug safety (pharmacovigilance), its application has remained largely unexplored. This technology brings numerous advantages, including expedited staff on-boarding, enhanced comprehension of contextual queries, and swift information retrieval through natural language inquiries, surpassing conventional keyword searches. This study delves into various operational tasks, such as locating regulatory process guidance, navigating intricate scenarios for advice, and ensuring the LLM's competence in recognizing uncertainties to prevent misinformation. LLMs empower users to engage with documentation using natural language, markedly improving search efficiency. The case study underscores LLM's effectiveness in delivering prompt guidance within pharmacovigilance and adverse event processing and reporting, offering a user-centric solution that streamlines the search for intricate business documentation.},
  keywords={Drugs;Data privacy;Uncertainty;Large language models;Documentation;Information retrieval;User experience;large language models;LLM;retrieval-augmented generation;drug safety;pharmacovigilance},
  doi={10.1109/CSCI62032.2023.00015},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10486526,
  author={Chopade, Abhay and Shingde, Vaibhav and Chavare, Aman and Bhagwat, Tejas},
  booktitle={2024 2nd International Conference on Computer, Communication and Control (IC4)}, 
  title={Code Insight - Flowchart Generator}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The goal of the project is to automate the conversion of pseudocode into visually appealing flowcharts, facilitating the transition from human-readable algorithm descriptions to machine-executable code in software. This study presents a new approach that uses the OpenAI GPT-3.5 Turbo model for automatic flowchart generation. Addressing the lack of tools that understand pseudocode, the method interprets pseudocode, generates executable code fragments, and creates aesthetically pleasing flowcharts. This article reviews the literature and highlights a gap in automated flow charts. The selected methodology uses state-of-theart language models, with a special focus on natural language processing (NLP). The study aims to improve the understanding of algorithms by visually representing complex algorithms through automatic flowchart generation.Examples 1. Sorting rhythm: Consider a scenario where a complex sorting algorithm is described in pseudocode. The flowchart generator interprets the pseudocode, generates the corresponding executable code, and converts it into a complete flowchart. This visual representation helps developers understand algorithm logic, encourages discussion, and improves collaboration.2. Recursive algorithms and tree structures: The project extends the application to handle recursive algorithms and tree structures. For example, when a flowchart generator is provided with recursive pseudocode to traverse a binary tree, it smoothly transforms the abstract description into a detailed flowchart. This feature increases the versatility of the toolbox and offers a wide range of algorithmic models.3. Optimization Algorithm Performance: The flowchart generator not only helps to understand but also to improve algorithms by identifying potential bottlenecks and optimizing the generated code. Critical decision points and loops in the flowchart visually highlight key areas and provide developers with valuable information to make informed optimization decisions.},
  keywords={Flowcharts;Visualization;Codes;Software algorithms;Transforms;Generators;Natural language processing;serialization;flowchart;algorithm design;tree structures;algorithm efficiency;pseudocode interpretation;natural language processing;GPT-3.5 turbo;collaborative development},
  doi={10.1109/IC457434.2024.10486526},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10554841,
  author={Sapozhnikov, Arkadii and Olsthoorn, Mitchell and Panichella, Annibale and Kovalenko, Vladimir and Derakhshanfar, Pouria},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={TestSpark: IntelliJ IDEA's Ultimate Test Generation Companion}, 
  year={2024},
  volume={},
  number={},
  pages={30-34},
  abstract={Writing software tests is laborious and time-consuming. To address this, prior studies introduced various automated test-generation techniques. A well-explored research direction in this field is unit test generation, wherein artificial intelligence (AI) techniques create tests for a method/class under test. While many of these techniques have primarily found applications in a research context, existing tools (e.g., EvoSuite, Randoop, and AthenaTest) are not user-friendly and are tailored to a single technique. This paper introduces Test-Spark, a plugin for IntelliJ IDEA that enables users to generate unit tests with only a few clicks directly within their Integrated Development Environment (IDE). Furthermore, TestSpark also allows users to easily modify and run each generated test and integrate them into the project workflow. TestSpark leverages the advances of search-based test generation tools, and it introduces a technique to generate unit tests using Large Language Models (LLMs) by creating a feedback cycle between the IDE and the LLM. Since TestSpark is an open-source (https://github.com/JetBrains-Research/TestSpark), extendable, and well-documented tool, it is possible to add new test generation methods into the plugin with the minimum effort. This paper also explains our future studies related to TestSpark and our preliminary results. Demo video: https://youtu.be/0F4PrxWfiXo},
  keywords={Writing;Software;Test pattern generators;Software engineering;Unit Test Generation;IntelliJ IDEA Plugin;Large Language Models},
  doi={10.1145/3639478.3640024},
  ISSN={2574-1934},
  month={April},}@INPROCEEDINGS{10874112,
  author={Tian, John and Shao, Yourui},
  booktitle={2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS)}, 
  title={Predicting College Admission Results with Machine Learning on Unstructured Online Data}, 
  year={2024},
  volume={},
  number={},
  pages={289-300},
  abstract={College admissions in the U nited States is a complex and often opaque process, leading to uncertainty and potential unfair biases. This paper presents a novel approach to predicting college admission results using machine learning on unstructured online data. Specifically, we utilize GPT-4o to extract and structure student application details and admission outcomes from more than 4,000 posts on the r/collegeresults subreddit, demonstrating the capabilities of advanced language models in preprocessing unstructured data for machine learning tasks. We employ two distinct methods for predicting admissions results: the first combines descriptive scalars extracted by GPT-4o from unstructured text data with XGBoost and a neural network to predict the probability of acceptance into an institution selectivity tier. The second predicts admission outcomes for specific institutions and compares the effectiveness of tokenization versus descriptive scalars extracted by GPT-4o in representing text features. The models achieve promising results, with Method 1 attaining an accuracy of 91.66% and an AUC-ROC of 0.9298. The results from Method 2 also demonstrate the greater effectiveness of using tokenization (85.1±.2% accuracy) over the explicitly defined features we specified (84.3±.2% accuracy).},
  keywords={Accuracy;Uncertainty;Neural networks;Machine learning;Data science;Feature extraction;Tokenization;Data models;Data mining;college admissions;machine learning;natural language processing;GPT-4o;feature extraction},
  doi={10.1109/FMLDS63805.2024.00060},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10767612,
  author={Miranda, Diego and Palma, Dayana and Fernández, Adrian and Noel, René and Cechinel, Cristian and Munoz, Roberto},
  booktitle={2024 43rd International Conference of the Chilean Computer Science Society (SCCC)}, 
  title={Enhancing Agile Project Management Education with AI: ChatGPT-4's Role in Evaluating Student Contributions}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={The planning poker estimation technique encour-ages all team members to participate equally, which is essential in the training of future software engineers. By proposing a coordination scheme based on the experience and knowledge of the team members, it enforces the common ownership of effort estimation. Thus, it is crucial that all members contribute to the process [10]. However, given the personal factors that could affect team interaction dynamics, the contributions of team members could not be equally distributed, hindering the goal of the technique. Ensuring the equal participation of team members sets a challenge not only in the professional context but also for training future software developers and team managers [18] that must facilitate team collaboration. Hence, it is vital to detect team members' contributions in order to value collaboration in a development team. In this article, we present the analyses of the interventions of 13 groups of students from the Computer Engineering course at the University of Valparaiso during a user story estimation activity using planning poker. The experimental setup involved computer science undergraduate students, performing a learning activity regarding the Planning Poker estimation technique. The students' interventions were classified according to a human expert following a collaboration framework. Subsequently, they were classified using ChatGPT 4 using the Zero Shot technique in order to compare the automatically generated labels with those provided by human experts. The type of classification used was binary to determine whether or not the intervention analysed was a contribution. The analysis focused on evaluating the accuracy and consistency of ChatGPT in the contribution classification task, considering the model's ability to correctly identify the different types of interventions. The results of this comparison demonstrate the effectiveness of ChatGPT and its potential to assist in real-time evaluation and analysis tasks. This study enhances the understanding of how artificial intelligence tools can complement the work of human experts, improving efficiency and accuracy in educational and agile project management activities.},
  keywords={Training;Computer science;Accuracy;Collaboration;Estimation;Agile project management;Chatbots;Software;Planning;Artificial intelligence;planning poker;contributions;zero shot;collab-oration},
  doi={10.1109/SCCC63879.2024.10767612},
  ISSN={2691-0632},
  month={Oct},}@INPROCEEDINGS{10852461,
  author={Slama, Faten and Lemire, Daniel},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Comparative Analysis of Loop-Free Function Evaluation Using ChatGPT and Copilot with C Bounded Model Checking}, 
  year={2024},
  volume={},
  number={},
  pages={58-65},
  abstract={Advanced machine learning models and automated coding helpers have significantly transformed software development and verification techniques in recent years. This paper performs a comparative investigation of two prominent AI-driven code generation tools, ChatGPT and Copilot, with a specific emphasis on their ability to evaluate loop-free functions. By employing C Bounded Model Checking (CBMC) as the verification framework, we use model checking (MC) to systematically compare the accuracy and effectiveness of code produced by both tools. Our approach entails creating function implementations that are free of loops by utilizing established requirements with the assistance of ChatGPT and Copilot. These implementations are then subjected to thorough examination using CBMC to evaluate aspects such as functional correctness, safety, and potential vulnerabilities. Performance measurements encompass coding accuracy, verification time, and error identification. Results reveal notable differences in the performance of ChatGPT and Copilot. While both tools show promise in code generation, distinct strengths and weaknesses emerge in handling complex specifications and ensuring code correctness. This work provides useful insights into coding assistants powered by artificial intelligence and emphasizes the significance of incorporating formal verification methods, such as CBMC, to ensure dependable software development. This comparative analysis adds to the expanding research on AI-assisted programming, offering practical guidance for developers and researchers seeking efficient and dependable code generation tools.},
  keywords={Codes;Accuracy;Model checking;Programming;Chatbots;Encoding;Software reliability;Software development management;Formal verification;Testing;AI-driven code generation tools;ChatGPT;Copilot;CBMC},
  doi={10.1109/FLLM63129.2024.10852461},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10554754,
  author={Pan, Wei Hung and Chok, Ming Jie and Wong, Jonathan Leong Shan and Shin, Yung Xin and Poon, Yeong Shian and Yang, Zhou and Chong, Chun Yong and Lo, David and Lim, Mei Kuan},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Assessing AI Detectors in Identifying AI-Generated Code: Implications for Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Educators are increasingly concerned about the usage of Large Language Models (LLMs) such as ChatGPT in programming education, particularly regarding the potential exploitation of imperfections in Artificial Intelligence Generated Content (AIGC) Detectors for academic misconduct. In this paper, we present an empirical study where the LLM is examined for its attempts to bypass detection by AIGC Detectors. This is achieved by generating code in response to a given question using different variants. We collected a dataset comprising 5,069 samples, with each sample consisting of a textual description of a coding problem and its corresponding human-written Python solution codes. These samples were obtained from various sources, including 80 from Quescol, 3,264 from Kaggle, and 1,725 from Leet-Code. From the dataset, we created 13 sets of code problem variant prompts, which were used to instruct ChatGPT to generate the outputs. Subsequently, we assessed the performance of five AIGC detectors. Our results demonstrate that existing AIGC Detectors perform poorly in distinguishing between human-written code and AI-generated code.},
  keywords={Training;Codes;Detectors;Chatbots;Encoding;Programming profession;Software engineering;Software Engineering Education;AI-Generated Code;AI-Generated Code Detection},
  doi={10.1145/3639474.3640068},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{10663027,
  author={Speth, Sandro and Meißner, Niklas and Becker, Steffen},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={ChatGPT's Aptitude in Utilizing UML Diagrams for Software Engineering Exercise Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The integration of Artificial Intelligence (AI) tech-nologies into educational settings has paved the way for inno-vative teaching and learning approaches. In Software Engineering (SE) education, using Unified Modeling Language (UML) diagrams is a fundamental teaching element for understanding complex software systems. This research addresses ChatGPT's ability to utilize UML class and sequence diagrams to create SE modeling exercises. We use ChatGPT to generate exercises based on the information from uploaded UML diagrams by analyzing textual UML representations such as Mermaid and graphical diagrams. The research explores ChatGPT's ability to synthesize UML-specific information from class and sequence diagrams, enabling the generation of various exercises tailored to strengthen conceptual understanding and practical application. Furthermore, we investigate generating graphical UML class and sequence diagrams based on natural language as input. By bridging the gap between AI -driven natural language understanding and the comprehension of UML diagrams, this study highlights the potential of ChatGPT to improve SE education. Our concise findings address educators, practitioners, and other researchers engaged in the field of SE education with a special focus on UML.},
  keywords={Reviews;Unified modeling language;Education;Manuals;Learning (artificial intelligence);Chatbots;Software systems;Data mining;Engineering education;Software engineering;AI-Generated Exercises;UML Modeling;Model Comprehension;ChatGPT;Software Engineering Education},
  doi={10.1109/CSEET62301.2024.10663027},
  ISSN={2377-570X},
  month={July},}@ARTICLE{11015274,
  author={Zhu, Lanyun and Chen, Tianrun and Ji, Deyi and Xu, Peng and Ye, Jieping and Liu, Jun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={LLaFS++: Few-Shot Image Segmentation With Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-18},
  abstract={Despite the rapid advancements in few-shot segmentation (FSS), most of existing methods in this domain are hampered by their reliance on the limited and biased information from only a small number of labeled samples. This limitation inherently restricts their capability to achieve sufficiently high levels of performance. To address this issue, this paper proposes a pioneering framework named LLaFS++, which, for the first time, applies large language models (LLMs) into FSS and achieves notable success. LLaFS++ leverages the extensive prior knowledge embedded by LLMs to guide the segmentation process, effectively compensating for the limited information contained in the few-shot labeled samples and thereby achieving superior results. To enhance the effectiveness of the text-based LLMs in FSS scenarios, we present several innovative and task-specific designs within the LLaFS++ framework. Specifically, we introduce an input instruction that allows the LLM to directly produce segmentation results represented as polygons, and propose a region-attribute corresponding table to simulate the human visual system and provide multi-modal guidance. We also synthesize pseudo samples and use curriculum learning for pretraining to augment data and achieve better optimization, and propose a novel inference method to mitigate potential oversegmentation hallucinations caused by the regional guidance information. Incorporating these designs, LLaFS++ constitutes an effective framework that achieves state-of-the-art results on multiple datasets including PASCAL-$5^{i}$, COCO-$20^{i}$, and FSS-1000. Our superior performance showcases the remarkable potential of applying LLMs to process few-shot vision tasks.},
  keywords={Image segmentation;Feature extraction;Large language models;Data mining;Training;Prototypes;Few shot learning;Transformers;Semantics;Optimization;Few-shot segmentation;large language models},
  doi={10.1109/TPAMI.2025.3573609},
  ISSN={1939-3539},
  month={},}@INPROCEEDINGS{10765939,
  author={Castillo, Karina Culebro and Zárate Hernández, Ximena M. and Gazca Herrera, Luis A. and Garizurieta Bernabe, Jessica},
  booktitle={2024 IEEE International Conference on Engineering Veracruz (ICEV)}, 
  title={Study of perception on the use of generative artificial intelligence in higher-level students}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Generative Artificial Intelligence (GAI) tools are advanced systems capable of generating content in formats such as text, images, or videos, which has been transforming fields such as education. However, excessive use of these tools may result in students not fully utilizing their own skills, thereby diminishing their critical thinking, analytical abilities, and information search skills. This research aims to study the perceptions of higher education students regarding GAI tools to assess their experiences with the usefulness of these instruments and their impact on learning. To achieve this, a non-experimental, comparative, descriptive research approach with a quantitative focus was employed, involving theoretical and conceptual processing. An instrument was designed to measure dimensions such as ethics, experience, usefulness, and quality. Finally, the results revealed that students use and understand basic concepts of GAI tools, recognize their limitations, and are thus familiar with them. The study also identified certain risks related to students' perception of these tools as substitutes for their teachers rather than as supportive aids and noted that they are perceived as potentially diminishing students' learning capacity.},
  keywords={Ethics;Generative AI;Instruments;Education;Organizations;Information retrieval;Problem-solving;Videos;Higher education;learning process;generative artificial intelligence},
  doi={10.1109/ICEV63254.2024.10765939},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10569274,
  author={Milinković, Anja and Vuleta, Daniela and Babić, i Tihana},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Student Perception of Using Generative AI Tools in Relation to Academic Integrity and Their Advantages and Disadvantages}, 
  year={2024},
  volume={},
  number={},
  pages={601-606},
  abstract={The increasing use of generative artificial intelligence (AI) tools in learning contexts calls for a reassessment of the complex dynamics surrounding academic integrity. It is a “hot” topic in the academic community, given that these more generative AI tools have become available to students to complete student assignments, and universities have had to urgently adopt rules on their use for academic purposes. While some universities have completely banned the use of such programs for the purpose of writing assignments and essays because they believe that this violates academic integrity, some other universities believe that they have the potential to influence the way we learn and approach education and that generative AI tools they must use for the benefit of students and faculty staff. The aim of the study conducted at the universities of Vern and Algebra in Zagreb, in the winter semester academic year 2023/2024 was to investigate whether students use generative AI tools for writing assignments and academic papers, how they perceive academic integrity in relation to the use of generative AI tools, and the advantages and disadvantages of generative artificial intelligence tools.},
  keywords={Costs;Accuracy;Generative AI;Algebra;Education;Learning (artificial intelligence);Writing;artificial intelligence;academic integrity;generative AI tools;ChatGPT;students perception},
  doi={10.1109/MIPRO60963.2024.10569274},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{10797032,
  author={Bruscia, Mattia and Manduzio, Graziano A. and Galatolo, Federico A. and Cimino, Mario G.C.A. and Greco, Alberto and Cominelli, Lorenzo and Scilingo, Enzo Pasquale},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={An Overview On Large Language Models Across Key Domains: A Systematic Review}, 
  year={2024},
  volume={},
  number={},
  pages={125-130},
  abstract={This systematic review explores the applications of Large Language Models (LLMs) across a variety of academic disciplines and professional fields. The analysis is structured through a methodical examination of data derived from the Scopus database over the period from 2017 to 2024. We created both annual and comprehensive datasets of articles and related information based on a generic query, which allowed us to track the development and integration of LLMs into different application fields. To this end, we conceived a dedicated approach that includes an analysis of the trends of subject areas and a Pertinence Analysis (PA) to filter out articles that are not genuinely related to LLMs. Additionally, we performed an annual and overall Terminological Relevance Analysis (TRA) using Machine Learning (ML) techniques, and we examined the yearly trends in research areas containing LLM-related articles by observing the relevance indicators of emerging terms. This extensive investigation highlights how LLMs are increasingly being utilized to improve efficiency, accuracy and productivity, particularly in health and healthcare care, guiding the responsible advancement and application of these technologies in sensitive domains.},
  keywords={Productivity;Large language models;Neural engineering;Medical services;Machine learning;Learning (artificial intelligence);Metrology;Market research;Systematic literature review;Periodic structures;large language models;systematic review;Scopus database;trend analysis;metadata analysis;pertinence analysis;terminological relevance;health and healthcare;annual trend;professional fields;machine learning},
  doi={10.1109/MetroXRAINE62247.2024.10797032},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{11008316,
  author={Lazrek, Ghita and Chetioui, Kaouthar and Balboul, Younes},
  booktitle={2025 5th International Conference on Innovative Research in Applied Science, Engineering and Technology (IRASET)}, 
  title={Unveiling Health’s Tomorrow: A Comprehensive Review of Anomaly Detection for IoMT Using Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This systematic literature review provides a thorough examination of the utilization of Large Language Models (LLMs) in predictive analysis and anomaly detection for IoMT networks, focusing on the latest developments in research landscape, and potential future prospects. LLMs have exhibited considerable promise in interpreting and analyzing vast datasets to recognize patterns, anticipate future occurrences, and identify abnormal behavior across diverse domains. Moreover, this review presents a detailed overview of LLM and outlines pivotal trends anticipated to influence the advancement of LLMs in these areas, encompassing the shift towards real-time processing, the significance of adopting sustainable modeling methodologies, and the benefits derived from collaboration across disciplines. In conclusion, this review emphasizes the revolutionary impact of LLMs in IoMT predictive and anomaly identification, highlighting the imperative for ongoing innovation, and practical solutions to fully harness their capabilities.},
  keywords={Technological innovation;Accuracy;Large language models;Market research;Real-time systems;Security;Reliability;Anomaly detection;Standards;Systematic literature review;Internet of Medical Things (IoMT);Security;Large Language Model (LLM);anomaly detection},
  doi={10.1109/IRASET64571.2025.11008316},
  ISSN={},
  month={May},}@INBOOK{10790761,
  author={Choi, Sean and Jo, Jinyoung},
  booktitle={Artificial Intelligence: Machine Learning, Convolutional Neural Networks and Large Language Models}, 
  title={Leveraging linguistic features to improve machine learning models for detecting ChatGPT usage on exams}, 
  year={2024},
  volume={},
  number={},
  pages={281-308},
  abstract={This work presents a case study, linguistic analyses, and the results of experiments on using linguistic features to improve the detection mechanism of the use of large language models (LLM) to generate solutions for exams that require domainspecific knowledge. The study involves analyzing the responses of three groups of students: a group who verbatim copied outputs of ChatGPT to plagiarize solutions, another group who referred to external non-LLM resources (e.g., web search) to plagiarize solutions, a control group who did not plagiarize. Linguistic analyses show that solutions from groups that participated in plagiarism tend to be longer, use uncommon words, and are similar to each other compared to solutions that were not plagiarized. In addition, utilizing these characteristics as features improves F1 score of machine learning models that detect plagiarism as much as 5.5%. This study shows that certain linguistic features can be utilized in machine learning models to detect use of LLMs, ultimately improving academic integrity by deterring the unethical use of AI in academic settings.},
  keywords={Chatbots;Feature extraction;Machine learning algorithms;Linguistics;Plagiarism;Machine learning;Text categorization;Computational modeling;Data models;Classification algorithms},
  doi={},
  ISSN={},
  publisher={De Gruyter},
  isbn={9783111344171},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10790761},}@INPROCEEDINGS{10578705,
  author={Tripaldelli, Alessia and Pozek, George and Butka, Brian},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Leveraging Prompt Engineering on ChatGPT for Enhanced Learning in CEC330: Digital System Design in Aerospace}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research examines the transformative role of prompt engineering in optimizing ChatGPT's utility in a digital-system-design class at Embry-Riddle Aeronautical University. By exploring various prompt engineering strategies, the authors investigate how to tailor prompts to significantly enhance ChatGPT's ability to assist students in complex coding and debugging tasks. The study highlights the pivotal role of prompt engineering in elevating ChatGPT from a basic informational tool to an integral component of the educational process. The chosen course centers on using FPGAs to generate and apply state machines. One course activity involves generating musical tones and sequentially playing them to produce the specified songs. Another activity challenges students to construct the foundational elements of a simple reduced instruction set processor, which includes defining a custom instruction set and conforming to a 16-bit design specification. This process entails developing an arithmetic logic unit, creating a general register array, and formulating the processor's specific instruction set. Therefore, this research is a pilot study with a small sample of students using ChatGPT to examine what prompts work best when used in a technical programming class.},
  keywords={Adaptation models;Codes;Instruction sets;Refining;Chatbots;Encoding;Iterative methods;Artificial Intelligence;ChatGPT;Prompt Engineering},
  doi={10.1109/EDUCON60312.2024.10578705},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10766746,
  author={Mellado, Rafael and Cubillos, Claudio and Ahumada, Giovanni},
  booktitle={2024 IEEE International Conference on Automation/XXVI Congress of the Chilean Association of Automatic Control (ICA-ACCA)}, 
  title={Effectiveness of Generative Artificial Intelligence in learning programming to higher education students}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Learning programming in higher education faces significant challenges, including high dropout rates and difficulties in understanding abstract concepts. Previous studies have explored various teaching methods, but the effectiveness of Generative Artificial Intelligence (GenAI) in this context has not yet been widely investigated. This study compares the efficacy of GenAI with video-based active learning methods for teaching programming to university students. Through an experimental design with 40 computer engineering students, academic performance, perception of usefulness and ease of use, and satisfaction and motivation were evaluated. The results showed no statistically significant differences between the groups in academic performance, perception of usefulness and ease of use, or satisfaction and motivation. Both methods proved equally effective in improving learning and maintaining student motivation. These findings suggest that GenAI can be a viable alternative to traditional methods, offering opportunities to diversify pedagogical strategies in programming education. Educators are encouraged to consider integrating GenAI to complement existing methods, ensuring implementation that maintains high levels of perceived control, immersion, and curiosity among students.},
  keywords={Training;Technology acceptance model;Generative AI;Education;Learning (artificial intelligence);Educational technology;Engineering students;Programming profession;Faces;Videos;generative artificial intelligence;computer programming;active learning},
  doi={10.1109/ICA-ACCA62622.2024.10766746},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10549466,
  author={Imran, Mia Mohammad and Chatterjee, Preetha and Damevski, Kostadin},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={Uncovering the Causes of Emotions in Software Developer Communication Using Zero-shot LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={2244-2256},
  abstract={Understanding and identifying the causes behind developers' emotions (e.g., Frustration caused by ‘delays in merging pull requests’) can be crucial towards finding solutions to problems and fostering collaboration in open-source communities. Effectively identifying such information in the high volume of communications across the different project channels, such as chats, emails, and issue com-ments, requires automated recognition of emotions and their causes. To enable this automation, large-scale software engineering-specific datasets that can be used to train accurate machine learning models are required. However, such datasets are expensive to create with the variety and informal nature of software projects' communication channels. In this paper, we explore zero-shot LLMs that are pretrained on massive datasets but without being fine-tuned specifically for the task of detecting emotion causes in software engineering: ChatGPT, GPT-4, and flan-alpaca. Our evaluation indicates that these recently available models can identify emotion categories when given detailed emotions, although they perform worse than the top-rated models. For emotion cause identification, our results indicate that zero-shot LLMs are effective at recognizing the correct emotion cause with a BLEU-2 score of 0.598. To highlight the potential use of these techniques, we conduct a case study of the causes of Frus-tration in the last year of development of a popular open-source project, revealing several interesting insights.},
  keywords={Emotion recognition;Automation;Merging;Collaboration;Machine learning;Chatbots;Software;Emotion Cause Extraction;Emotion Classification;Zero-Shot Prompting;Large Language Model;GPT-4;ChatGPT},
  doi={10.1145/3597503.3639223},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10893375,
  author={Qu, Yanzhen and Letort, Daniel and Evans, Howard and Abbas, Noura and Cai, Richard and Haj-Hussein, Mazen and Biggs, Anastasia and Durgin, Janet},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Unlocking Learning Potential: Generative AI Chatbots as Study Partners in Online BS in Computer Science Degree Program}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper presents our innovative approach to integrating Generative Artificial Intelligence (GAI) chatbots into selected BSCS courses. These courses operate within an Online Learning Environment (OLE) based on asynchronous communication. We have detailed two distinct approaches to implement Retrieval-Augmented Generation (RAG) model-based GAI chatbots. The first approach utilizes Microsoft Copilot Studio, allowing us to create customized chatbots without the need for coding. The second approach involves Python coding to develop more advanced GAI chatbots. Both methods are straightforward and cost-effective, leveraging the latest advancements to enhance communication between students and faculty. By incorporating frequently asked questions and answers from various BSCS courses into these chatbots, we can enrich the learning experience and aid both students and faculty in achieving their goals. Our preliminary results suggest that with careful planning, design, and implementation, these chatbots can circumvent common issues such as misinformation, inaccuracy, ethical and safety concerns, and lack of contextual understanding, thereby enhancing the effectiveness of student learning in an asynchronous communication-based OLE.},
  keywords={Computer science;Ethics;Generative AI;Retrieval augmented generation;Chatbots;Encoding;Safety;Planning;Fake news;Python;GAI chatbot;RAG model;Online Learning Environment;Study Partner},
  doi={10.1109/FIE61694.2024.10893375},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10763263,
  author={Wijaya, Owen Christian and Purwarianti, Ayu},
  booktitle={2024 11th International Conference on Advanced Informatics: Concept, Theory and Application (ICAICTA)}, 
  title={An Interactive Question-Answering System Using Large Language Model and Retrieval-Augmented Generation in an Intelligent Tutoring System on the Programming Domain}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The insufficient communication between mentors and students has been one of the main disadvantages of modern programming learning platforms. In this paper, we propose the development of a web-based intelligent tutoring system with a question-answering (QA) system to provide live interaction between students and a mentor figure. We propose the implementation of an alternative QA system using a large language model (LLM) and a retrieval-augmented generation (RAG) mechanism. We utilized the LangChain library and integrated the RAG mechanism with the history-aware retriever and direct integration into the web application. We performed internal and external evaluations in the form of qualitative evaluation via subjective scoring towards answers from various quantized LLMs in both single-turn and multi-turn conversation scenarios. We conclude that the Llama 3 model displays consistent and promising results compared to other models and that documents with a higher character count may act as better knowledge bases for the RAG process.},
  keywords={Large language models;Knowledge based systems;Oral communication;Programming;Libraries;History;Informatics;Testing;LLM;question-answering;retrieval;chatbot},
  doi={10.1109/ICAICTA63815.2024.10763263},
  ISSN={2996-2552},
  month={Sep.},}@INPROCEEDINGS{10893904,
  author={Jothi, T. and Dominic, J. and Jaganbabu, J.},
  booktitle={2025 International Conference on Multi-Agent Systems for Collaborative Intelligence (ICMSCI)}, 
  title={Enhancing Medical Libraries: AI-Driven Tools and Techniques for Digital Transformation and Sustainable Innovation}, 
  year={2025},
  volume={},
  number={},
  pages={1182-1186},
  abstract={Artificial intelligence (AI) is transforming numerous fields, particularly in research and education, and its integration into medical library operations has become essential to maintaining relevance and competitiveness in today's global landscape. This exploration examines how AI-driven tools and methods are reshaping various aspects of medical library services, offering a comprehensive look at the potential and practical applications of AI in the library setting. The core objective of AI is to develop systems capable of performing cognitive tasks that mimic human thought. By incorporating AI, medical libraries can transcend physical limitations, becoming more intelligent, accessible, and responsive. This article explores how advancements such as Natural Language Processing (NLP), Large Language Models (LLM), Expert Systems (ES), AI-powered indexing tools, and Chabot's can enhance medical library infrastructure and services. These AI applications hold promise for improving outcomes across user groups-benefiting students, faculty, healthcare researchers, and clinical practitioners a like. In providing an in-depth analysis of AI's advantages, limitations, and innovative uses, this article fosters a deeper understanding of AI's role in library science. Through a balanced perspective on AI's transformative potential, libraries are equipped to make informed decisions, leveraging technology to support an evolving and dynamic medical information environment.},
  keywords={Technological innovation;Large language models;Digital transformation;Education;Medical services;Libraries;Natural language processing;Artificial intelligence;Expert systems;Indexing;Artificial Intelligence (AI);Natural Language Processing (NLP);Large Language Model;Expert Systems;AI-driven Tools;Medical Institute library},
  doi={10.1109/ICMSCI62561.2025.10893904},
  ISSN={},
  month={Jan},}@ARTICLE{10649569,
  author={Dwivedi, Rahul and Elluri, Lavanya},
  journal={IEEE Access}, 
  title={Exploring Generative Artificial Intelligence Research: A Bibliometric Analysis Approach}, 
  year={2024},
  volume={12},
  number={},
  pages={119884-119902},
  abstract={Artificial Intelligence (AI) and its many applications are changing our lives in ways we could not have imagined a decade ago. Generative artificial intelligence is an artificial intelligence system capable of generating texts, images, and other media based on the input training data. Although still in their early stages, numerous examples of such systems in different domains have gained widespread attention from the public, media, policymakers, and researchers. This study aims to explore the generative AI academic research in the past decade using bibliometrics, text analysis, and social network analysis. Specifically, research themes and their relationships, the evolution of research themes over time, and prominent authors, articles, journals, institutions, and countries publishing in generative AI are identified. The data was further found to partially support the classical bibliometrics laws of Zipf, and Bradford’s. The two overarching research themes identified using knowledge synthesis from most cited articles and journals are technical advancements and developments in generative AI systems; and their applications to image processing, pattern recognition, and computer vision. ChatGPT, large language models, and the application of generative AI to healthcare and education are emerging research topics. Additionally, generative AI’s usefulness to geoscience, remote sensing, Internet of Things (IoT), and cybersecurity are discussed.},
  keywords={Bibliometrics;Generative AI;Artificial intelligence;Databases;Market research;Indexes;Internet;Generative artificial intelligence;bibliometric analysis},
  doi={10.1109/ACCESS.2024.3450629},
  ISSN={2169-3536},
  month={},}@ARTICLE{10507163,
  author={Liu, Zhijie and Tang, Yutian and Luo, Xiapu and Zhou, Yuming and Zhang, Liang Feng},
  journal={IEEE Transactions on Software Engineering}, 
  title={No Need to Lift a Finger Anymore? Assessing the Quality of Code Generation by ChatGPT}, 
  year={2024},
  volume={50},
  number={6},
  pages={1548-1584},
  abstract={Large language models (LLMs) have demonstrated impressive capabilities across various natural language processing (NLP) tasks, such as machine translation, question answering, summarization, and so on. Additionally, LLMs are also highly valuable in supporting software engineering tasks, particularly in the field of code generation. Automatic code generation is a process of automatically generating source code or executable code based on given specifications or requirements, improving developer productivity. In this study, we perform a systematic empirical assessment to the quality of code generation using ChatGPT, a recent state-of-the-art product LLM. We leverage 728 algorithm problems in five languages (i.e., C, C++, Java, Python, and JavaScript) and 18 CWEs with 54 code scenarios for the code generation task. Our evaluation encompasses a comprehensive analysis of code snippets generated by ChatGPT, focusing on three critical aspects: correctness, complexity, and security. We also specifically investigate ChatGPT's ability to engage in multi-round fixing process (i.e., ChatGPT's dialog ability, chatting between users and ChatGPT for fixing generated buggy code) of facilitating code generation. By delving into the generated code and examining the experimental results, this work provides valuable insights into the performance of ChatGPT in tackling code generation tasks over the three critical aspects. The experimental results demonstrate that (1) ChatGPT is better at generating functionally correct code for problems before 2021 in different languages than problems after 2021 with $48.14\%$48.14% advantage in Accepted rate on judgment platform, but ChatGPT's ability to directly fix erroneous code with multi-round fixing process to achieve correct functionality is relatively weak; (2) the distribution of cyclomatic and cognitive complexity levels for code snippets in different languages varies. Furthermore, the multi-round fixing process with ChatGPT  generally preserves or increases the complexity levels of code snippets; (3) in algorithm scenarios with languages of C, C++, and Java, and CWE scenarios with languages of C and Python3, the code generated by ChatGPT  has relevant vulnerabilities. However, the multi-round fixing process for vulnerable code snippets demonstrates promising results, with more than $89\%$89% of vulnerabilities successfully addressed; and (4) code generation may be affected by ChatGPT's non-determinism factor, resulting in variations of code snippets in functional correctness, complexity, and security. Overall, our findings uncover potential issues and limitations that arise in the ChatGPT-based code generation and lay the groundwork for improving AI and LLM-based code generation techniques.},
  keywords={Codes;Chatbots;Task analysis;Complexity theory;Security;Transformers;Electronic mail;Large language model;ChatGPT;code generation},
  doi={10.1109/TSE.2024.3392499},
  ISSN={1939-3520},
  month={June},}@ARTICLE{10720422,
  author={Wu, Dongyuan and Nie, Liming and Mumtaz, Rao Asad and Agarwal, Kadambri},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A LLM-Based Hybrid-Transformer Diagnosis System in Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={The application of computer vision-powered large language models (LLMs) for medical image diagnosis has significantly advanced healthcare systems. Recent progress in developing symmetrical architectures has greatly impacted various medical imaging tasks. While CNNs or RNNs have demonstrated excellent performance, these architectures often face notable limitations of substantial losses in detailed information, such as requiring to capture global semantic information effectively and relying heavily on deep encoders and aggressive downsampling. This paper introduces a novel LLM-based Hybrid-Transformer Network (HybridTransNet) designed to encode tokenized Big Data patches with the transformer mechanism, which elegantly embeds multimodal data of varying sizes as token sequence inputs of LLMS. Subsequently, the network performs both inter-scale and intra-scale self-attention, processing data features through a transformer-based symmetric architecture with a refining module, which facilitates accurately recovering both local and global context information. Additionally, the output is refined using a novel fuzzy selector. Compared to other existing methods on two distinct datasets, the experimental findings and formal assessment demonstrate that our LLM-based HybridTransNet provides superior performance for brain tumor diagnosis in healthcare informatics.},
  keywords={Transformers;Image segmentation;Medical diagnostic imaging;Computer architecture;Medical services;Computational modeling;Accuracy;Training;Convolution;Context modeling;Diagnosis;Medical imaging;Transformer;Fuzzy selector;LLM},
  doi={10.1109/JBHI.2024.3481412},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10774681,
  author={Rachh, Rashmi and Kavatagi, Sanjana},
  booktitle={2024 3rd International Conference for Advancement in Technology (ICONAT)}, 
  title={Study on Students' Perceptions of Generative AI in Learning Programming Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={The proliferation of generative AI has taken the world by storm, and the education sector is no exception. It is imperative to leverage this emerging technology to bring about positive transformation in teaching and learning. However, the adoption of generative AI in education must be approached with caution, necessitating several pedagogical interventions. This paper discusses the various challenges and issues involved in adopting generative AI for teaching programming language courses and proposes plausible solutions.},
  keywords={Computer languages;Generative AI;Storms;Education;Programming profession;Generative AI;Education;Pedagogy;Programming},
  doi={10.1109/ICONAT61936.2024.10774681},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10986583,
  author={Deshpande, Deepali and Deshpande, Renuka and Gadekar, Akash and Gaikwad, Rutvik and Gejage, Vipul and Ghavate, Sarthak},
  booktitle={2025 3rd International Conference on Disruptive Technologies (ICDT)}, 
  title={Skilldev: Genai-Powered Skill Upgrading Platform}, 
  year={2025},
  volume={},
  number={},
  pages={520-525},
  abstract={The rapid evolution of technology has transformed the landscape of education, making it essential for students to stay up-to-date with industry-relevant skills. The project presents a web-based platform to enhance campus placement preparation for pre-final and final-year engineering students of various computer-related faculties. The platform uses Generative AI to assess student skill levels in various core and important subjects under the computer domain. By categorizing students into Beginner, Intermediate, or Advanced levels, the platform delivers personalized learning resources and tutorial recommendations as per the user's needs while tracking the overall progress. The system provides visual insights through graphical analysis of student performance to improve employability and better equip students for competitive placement processes. Additionally, it also delivers responsive feedback for the overall achievement and progress of the user. Through various self-designed recommendation and evaluation algorithms, the system adapts to student's learning needs, ensuring an optimized and dynamic learning experience.},
  keywords={Visualization;Generative AI;Engineering profession;Heuristic algorithms;Education;Focusing;Tutorials;Logic;Engineering students;Monitoring;Generative AI;Recommendation Model;Progressive Flow Logic;Personalization;Flask;SQL;Placement Preparation},
  doi={10.1109/ICDT63985.2025.10986583},
  ISSN={},
  month={March},}@ARTICLE{10874155,
  author={Tracy, Kaitlyn and Spantidi, Ourania},
  journal={IEEE Transactions on Learning Technologies}, 
  title={Impact of GPT-Driven Teaching Assistants in VR Learning Environments}, 
  year={2025},
  volume={18},
  number={},
  pages={192-205},
  abstract={Virtual reality (VR) has emerged as a transformative educational tool, enabling immersive learning environments that promote student engagement and understanding of complex concepts. However, despite the growing adoption of VR in education, there remains a significant gap in research exploring how generative artificial intelligence (AI), such as generative pretrained transformer can further enhance these experiences by reducing cognitive load and improving learning outcomes. This study examines the impact of an AI-driven instructor assistant in VR classrooms on student engagement, cognitive load, knowledge retention, and performance. A total of 52 participants were divided into two groups experiencing a VR lesson on the bubble sort algorithm, one with only a prescripted virtual instructor (control group), and the other with the addition of an AI instructor assistant (experimental group). Statistical analysis of postlesson quizzes and cognitive load assessments was conducted using independent t-tests and analysis of variance (ANOVA), with the cognitive load being measured through a postexperiment questionnaire. The study results indicate that the experimental group reported significantly higher engagement compared to the control group. While the AI assistant did not significantly improve postlesson assessment scores, it enhanced conceptual knowledge transfer. The experimental group also demonstrated lower intrinsic cognitive load, suggesting the assistant reduced the perceived complexity of the material. Higher germane and general cognitive loads indicated that students were more invested in meaningful learning without feeling overwhelmed.},
  keywords={Artificial intelligence;Cognitive load;Training;Chatbots;Load modeling;Immersive learning;Generative Pre-trainer transformer;Generative AI;Cultural differences;Computer science;Generative artificial intelligence (GenAI);human–computer interaction;interactive learning environments;learning efficacy;learning outcomes;virtual reality (VR)},
  doi={10.1109/TLT.2025.3539179},
  ISSN={1939-1382},
  month={},}@ARTICLE{10546929,
  author={Liang, Hao and Zhang, Jiaxin and Li, Yunqin and Wang, Bowen and Huang, Jingyong},
  journal={IEEE Access}, 
  title={Automatic Estimation for Visual Quality Changes of Street Space via Street-View Images and Multimodal Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={87713-87727},
  abstract={Estimating Visual Quality of Street Space (VQoSS) is pivotal for urban design, environmental sustainability, civic engagement, etc. Recent advancements, notably in deep learning, have enabled large-scale analysis. However, traditional deep learning approaches are hampered by extensive data annotation requirements and limited adaptability across diverse VQoSS tasks. Multimodal Large Language Models (MLLMs) have recently demonstrated proficiency in various computer vision tasks, positioning them as promising tools for automated VQoSS assessment. In this paper, we pioneer the application of MLLMs to VQoSS change estimation, with our empirical findings affirming their effectiveness. In addition, we introduce Street Quality Generative Pre-trained Transformer (SQ-GPT), a model that distills knowledge from the current most powerful but inaccessible (not free) GPT-4V, requiring no human efforts. SQ-GPT approaches GPT-4V’s performance and is viable for large-scale VQoSS change estimation. In a case study of Nanjing, we showcase the practicality of SQ-GPT and knowledge distillation pipeline. Our work promises to be a valuable asset for future urban studies research.},
  keywords={Visualization;Task analysis;Estimation;Deep learning;Image color analysis;Data models;Context modeling;Smart cities;Large language models;Smart city;visual quality;deep learning;multimodal large language models},
  doi={10.1109/ACCESS.2024.3408843},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10589969,
  author={Huang, Guimin and Liang, Xinxian},
  booktitle={2024 6th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Generative AI Research of Education from 2013 to 2023}, 
  year={2024},
  volume={},
  number={},
  pages={125-130},
  abstract={Generative AI offers a new possibility for teaching and learning, where the role of the teacher will be affected and the way students learn will potentially be disrupted. This study analyzed the Wos database of relevant literature over the past 10 years (January 2013-November 2023) using the visual analysis software CiteS pace, with the aim of providing an overview of generative-time AI research in the field of education, revealing the main research patterns and trends characterizing it. The results of the study reveal the authors, regions, journals, and references that have made significant contributions. In addition, keyword co-occurrence, burst words, and timeline maps were generated to identify key hotspots in this research area.},
  keywords={Computer science;Visualization;Generative AI;Education;Market research;Software;Visual databases;generative AI;education;LLM;AIGC;ChatGPT;research trends},
  doi={10.1109/CSTE62025.2024.00030},
  ISSN={},
  month={April},}@INPROCEEDINGS{10665264,
  author={Charney, Max},
  booktitle={2024 IEEE Integrated STEM Education Conference (ISEC)}, 
  title={Fostering Diversity and Knowledge in Artificial Intelligence: An Inclusive Platform of Career Insights and Resources from Conversations with Leaders in the Field}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={Computer science has recently experienced a surge in popularity with the release of generative artificial intelligence models. Yet, while the popular imagination has been captured, evidence indicates that pre-college students, especially those from underrepresented populations, lack adequate education about careers in the field. Effective methods for gaining understanding include shadowing professionals or acquiring internships, yet these means are often not attainable or realistic for many students. Overall, this insufficient education can lead to future disadvantages, including future workforce disparities. To address these problems, Computer Science Next (CSNext) is an organization that was founded in early 2024 to convey insights from the current to the next generation of computer scientists. CSNext's first project will be a series of video interviews with leaders in artificial intelligence intended for a high school student audience. Video interviews will be released for free, and responses will be synthesized to share meaningful and insightful commonalities and responses. In addition, a list of the resources discussed in the interview will be cataloged alongside the videos and indexed for the site in its entirety. Particular attention will be focused on inclusivity, including underrepresented minorities, when selecting interview candidates.},
  keywords={Computer science;Engineering profession;Education;Organizations;Oral communication;Interviews;Artificial intelligence;Artificial intelligence education;Career exploration;Expert discourse;Inclusivity},
  doi={10.1109/ISEC61299.2024.10665264},
  ISSN={2473-7623},
  month={March},}@INPROCEEDINGS{10343985,
  author={Tsoeu, Mohohlo and Maladzi, Rendani and Mthombeni, Nomcebo and Moloi, Katleho and Mashifana, Tebogo and Nemavhola, Fulufhelo},
  booktitle={2023 World Engineering Education Forum - Global Engineering Deans Council (WEEF-GEDC)}, 
  title={Engineering, the Profession in Trouble: Lack of Programme Development Standards That Support the AI Chatbot? A System View}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={As the world embraces the transformative potential of artificial intelligence (AI), large language models (LLM), and conversational agents also known as chatbots, the engineering profession stands at a crucial juncture. This paper critically examines the current state of engineering education and its readiness to incorporate AI chatbots effectively. Focusing on the lack of standardized programme development that supports AI chatbots, this paper sheds light on the implications of this gap for engineering education. Standardization is defined as the degree to which educational programmes meet common national and international quality standards. By synthesizing existing literature, this study investigates the challenges, opportunities, and strategies required to bridge this divide and ensure that engineering programmes are adequately equipped to produce graduates who can harness the power of AI chatbots. We found that strong and continuing trends are emerging in the use of AI and chatbots in engineering education and industry. We further noted that current standards from accreditation bodies need to respond to enable AI and chatbot incorporation from curriculum to pedagogical levels of engineering education. Industry-academia partnerships are vital in managing the integration of AI into engineering education.},
  keywords={Knowledge engineering;Industries;Navigation;Focusing;Chatbots;Market research;Accreditation;AI;chatbots;artificial intelligence;education;standards;programmes;development;curricula;accreditation},
  doi={10.1109/WEEF-GEDC59520.2023.10343985},
  ISSN={2837-5025},
  month={Oct},}@INPROCEEDINGS{10764947,
  author={Wu, Di and Mu, Fangwen and Shi, Lin and Guo, Zhaoqiang and Liu, Kui and Zhuang, Weiguang and Zhong, Yuqi and Zhang, Li},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={iSMELL: Assembling LLMs with Expert Toolsets for Code Smell Detection and Refactoring}, 
  year={2024},
  volume={},
  number={},
  pages={1345-1357},
  abstract={Detecting and refactoring code smells is challenging, laborious, and sustaining. Although large language models have demonstrated potential in identifying various types of code smells, they also have limitations such as input-output token restrictions, difficulty in accessing repository-level knowledge, and performing dynamic source code analysis. Existing learning-based methods or commercial expert toolsets have advantages in handling complex smells. They can analyze project structures and contextual information in-depth, access global code repositories, and utilize advanced code analysis techniques. However, these toolsets are often designed for specific types and patterns of code smells and can only address fixed smells, lacking flexibility and scalability. To resolve that problem, we propose iSMELL, an ensemble approach that employs various code smell detection toolsets via Mixture of Experts (MoE) architecture for comprehensive code smell detection, and enhances the LLMs with the detection results from expert toolsets for refactoring those identified code smells. First, we train a MoE model that, based on input code vectors, outputs the most suitable expert tool for identifying each type of smell. Then, we select the recommended toolsets for code smell detection and obtain their results. Finally, we equip the prompts with the detection results from the expert toolsets, thereby enhancing the refactoring capability of LLMs for code with existing smells, enabling them to provide different solutions based on the type of smell. We evaluate our approach on detecting and refactoring three classical and complex code smells, i.e., Refused Bequest, God Class, and Feature Envy. The results show that, by adopting seven expert code smell toolsets, iSMELL achieved an average F1 score of 75.17% on code smell detection, outperforming LLMs baselines by an increase of 35.05% in F1 score. We further evaluate the code refactored by the enhanced LLM. The quantitative and human evaluation results show that iSMELL could improve code quality metrics and conduct satisfactory refactoring toward the identified code smells. We believe that our proposed solution could provide new insights into better leveraging LLMs and existing approaches to resolving complex software tasks.},
  keywords={Measurement;Learning systems;Codes;Source coding;Scalability;Large language models;Feature extraction;Vectors;Software;Software engineering},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10795109,
  author={Cooper, Nathan and Tufano, Rosalia and Bavota, Gabriele and Poshyvanyk, Denys},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={On the Generalizability of Transformer Models to Code Completions of Different Lengths}, 
  year={2024},
  volume={},
  number={},
  pages={375-387},
  abstract={The programming landscape is nowadays being reshaped by the advent of Large Language Models (LLMs) able to automate code-related tasks related to code implementation (e.g., code completion) and comprehension (e.g., code summarization). Such a paradigm shift comes with a number of implications related to how software will be written, maintained, and evolved. Also, these LLMs are extremely expensive to train, posing questions on their sustainability over time. Given their training cost, their ability to generalize, namely their ability to work on task instances different from those on which they have been trained, is an aspect worth being investigated. Previous work already showed that transformer models can successfully support code completion in a cross-project setting. However, it is unclear whether LLM are able to generalize to inputs having lengths not seen during training. For example, it is known that training a model on short instances allows to substantially reduce the training cost. However, the extent to which such a model would provide good performance on sequences having lengths not seen during training is not known. Many recent works in Natural Language Processing (NLP) tackled this problem in the context of decoder-only LLMs, i.e., xPOS and ALiBi. To assess if these solutions extend to encoder-decoder LLMs usually adopted in the code-related tasks, we present a large empirical study evaluating this generalization property of these and other encoding schemes proposed in the literature, namely Sinusoidal, xPOS, ALiBi, and T5. We found that none of these solutions successfully generalize to unseen lengths and that the only safe solution is to ensure the representativeness in the training set of all lengths likely to be encountered at inference time.},
  keywords={Training;Software maintenance;Codes;Costs;Transformers;Encoding;Natural language processing;Sustainable development;Context modeling;Software engineering;DL4SE;Code Completion},
  doi={10.1109/ICSME58944.2024.00042},
  ISSN={2576-3148},
  month={Oct},}@ARTICLE{10410841,
  author={Mubin, Omar and Alnajjar, Fady and Trabelsi, Zouheir and Ali, Luqman and Parambil, Medha Mohan Ambali and Zou, Zhao},
  journal={IEEE Access}, 
  title={Tracking ChatGPT Research: Insights From the Literature and the Web}, 
  year={2024},
  volume={12},
  number={},
  pages={30518-30532},
  abstract={This article presents a scientometric and literature analysis of current research on ChatGPT, a conversational AI technology developed by OpenAI. Using various databases, 103 relevant articles were retrieved and analyzed through scientometric, quantitative, and application-based approaches. A Google trend analysis and comparison with other generative AI and chatbot technologies were also carried out. The study provides insights into the distribution of ChatGPT publications across different countries and regions, the network of co-occurring keywords, authorship analysis, article typology, and publishing entities. The findings offer a comprehensive overview of the current state of ChatGPT research, highlighting key directions for future research. The study finds that ChatGPT has gained significant attention and interest in online platforms, particularly in technology, education, and healthcare, and highlights potential ethical and legal concerns related to its use. Its applications extend to several literary and text generation areas. We do note that the sample of extracted publications is lower than anticipated due to the niche area of investigation. The article is relevant to researchers, practitioners, and policymakers interested in the field of AI-powered language models, especially ChatGPT.},
  keywords={Chatbots;Bibliometrics;Education;Artificial intelligence;Task analysis;Market research;Search engines;Natural language processing;Open Access;ChatGPT;artificial intelligence;natural language processing;NLM},
  doi={10.1109/ACCESS.2024.3356584},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10565716,
  author={Sobral, Sónia Roll},
  booktitle={2023 XIII International Conference on Virtual Campus (JICV)}, 
  title={Why ChatGPT Isn't Introductory Programming Freshmen's Best Friend}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The emergence of ChatGPT brought a lot of controversy in society and academia due to the ease with which students can effortlessly perform work. This paper investigates whether a freshman student in an introductory programming unit using Python benefits from using ChatGPT, even as an aid. The methodology used was the application of three written tests of one semester - using Python programming language -, answered by ChatGPT (free version), analysed, and compared with a “good” solution of each one. Strangely, or maybe not, errors and problems were found in the solutions provided by ChatGPT that are the same ones that self-taught student (those who learn on YouTube and websites around the Internet world) make.},
  keywords={Video on demand;Programming;Chatbots;Internet;Web sites;Python;ChatGPT;Python;introductory programming},
  doi={10.1109/JICV59748.2023.10565716},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10734614,
  author={Li, Zhiming and Cao, Yushi and Xu, Xiufeng and Jiang, Junzhe and Liu, Xu and Teo, Yon Shin and Lin, Shang-Wei and Liu, Yang},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={LLMs for Relational Reasoning: How Far are We?}, 
  year={2024},
  volume={},
  number={},
  pages={119-126},
  abstract={Large language models (LLMs) have revolutionized many areas (e.g. natural language processing, software engineering, etc.) by achieving state-of-the-art performance on extensive downstream tasks. Aiming to achieve robust and general artificial intelligence, there has been a surge of interest in investigating the reasoning ability of the LLMs. Whereas the textual and numerical reasoning benchmarks adopted by previous works are rather shallow and simple, it is hard to conclude that the LLMs possess strong reasoning ability by merely achieving positive results on these benchmarks. Recent efforts have demonstrated that the LLMs are poor at solving sequential decision-making problems that require common-sense planning by evaluating their performance on the reinforcement learning benchmarks. In this work, we conduct an in-depth assessment of several state-of-the-art LLMs’ reasoning ability based on the inductive logic programming (ILP) benchmark, which is broadly recognized as a representative and challenging measurement for evaluating logic program induction/synthesis systems as it requires inducing strict cause-effect logic to achieve robust deduction on independent and identically distributed (IID) and out-of-distribution (OOD) test samples. Our evaluations illustrate that compared with the neural program induction systems which are much smaller in model size, the state-of-the-art LLMs are much poorer in terms of reasoning ability by achieving much lower performance and generalization using either natural language prompting or truth-value matrix prompting.1},
  keywords={Large language models;Pipelines;Reinforcement learning;Benchmark testing;Cognition;Planning;Logic;Surges;Standards;Software engineering;Large Language Models;Relational Reasoning;Program Induction},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10677538,
  author={Bernardino, Maicon and Cargnelutti, Rodrigo and de Souza Garcia, Renato and Silva, Williamson},
  journal={IEEE Revista Iberoamericana de Tecnologias del Aprendizaje}, 
  title={The Use of ChatGPT in Improving and Reviewing Scientific Paper Writing: An Exploratory Study}, 
  year={2024},
  volume={19},
  number={},
  pages={120-128},
  abstract={Software Engineering students enrolled in the Problem Solving I (PSI) course experience a Requirements Engineering (RE) approach to education. As part of one of the PSI assessments, students must develop a manuscript on RE. Following submission and presentation, we conducted an exploratory study to assess students’ perception of using ChatGPT to support improving and reviewing their scientific paper writing. Based on the results obtained from the participants (n = 40), we highlight the different ways to use ChatGPT to support the learning process. We conclude that ChatGPT and other AI tools can and should be explored by students and professors in the academic setting. However, evaluating the generated responses with caution and discernment is essential. Moreover, to enhance the overall experience, it is crucial to pose precise questions that yield accurate responses; this, in essence, constitutes the primary challenge.},
  keywords={Chatbots;Artificial intelligence;Software engineering;Problem-solving;Codes;Computer science education;Educational courses;ChatGPT;scientific paper writing;exploratory study;software engineering education},
  doi={10.1109/RITA.2024.3458848},
  ISSN={1932-8540},
  month={},}@INPROCEEDINGS{10929431,
  author={Dian Martha, Ati Suci and Widowati, Sri and Rahayu, Desy Puspa and Nursyawal, Muhammad Ilham and Hariz, Rayhan Rizqial},
  booktitle={2024 International Conference on Information Technology Systems and Innovation (ICITSI)}, 
  title={Examining Usability and Student Experience of ChatGPT as a Learning Tool on Moodle in Higher Education}, 
  year={2024},
  volume={},
  number={},
  pages={8-13},
  abstract={The integration of ChatGPT into Moodle has revolutionized teaching and learning practices. However, assessing the usability of this integration is essential for understanding its effectiveness and the challenges of using ChatGPT in Moodle, as well as its contribution to enhancing students' learning experiences. This study evaluates the usability of ChatGPT and students' experiences with it on the Moodle platform. Utilizing a mixed-methods approach, the research combines quantitative data from a survey-based questionnaire with qualitative insights from semi-structured interviews. A One-Group Posttest-Only design was employed in this research. Quantitative data were collected using the CUQ and UEQ+ questionnaires adapted for an Indonesian context. The CUQ score of 66.4 indicates that the usability of ChatGPT in Moodle is in the "fairly good" category. Nonetheless, specific areas require enhancement, including personality traits, error handling, and onboarding procedures. The results from the UEQ+ revealed positive outcomes across seven measured criteria, indicating favorable user experiences in aspects such as ease of use, efficiency, dependability, stimulation, intuitive use, content quality, and overall usability. Overall, students reported feeling notably supported by the presence of ChatGPT in Moodle; however, further improvements are needed to enhance the learning experience even more. The article's final section addresses the study's limitations and offers recommendations for future research.},
  keywords={Technological innovation;Education;Chatbots;User experience;Usability;Interviews;Information technology;Testing;ChatGPT;Moodle;usability;student experience;CUQ;UEQ+},
  doi={10.1109/ICITSI65188.2024.10929431},
  ISSN={2996-1084},
  month={Dec},}@INPROCEEDINGS{10690334,
  author={Bekkar, Hibat-Allah and Chtouki, Yousra},
  booktitle={2024 10th International Conference on Smart Computing and Communication (ICSCC)}, 
  title={Chatbots in Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={637-644},
  abstract={Artificial intelligence (AI) has rapidly transitioned from theoretical concepts to practical applications across various sectors, including education. This paper presents a systematic literature review focusing on the use of chatbots, particularly those based on large language models (LLMs), in educational settings. The review examines existing literature, surveys, and studies on the topic, exploring the capabilities of LLM-based chatbots in personalizing tutoring, automating assessments, and providing immediate feedback. Additionally, the paper discusses the challenges of integrating these technologies. Key findings highlight the significant potential of chatbots to enhance educational experiences by offering personalized learning, accessible tools, and interactive tutoring systems. We also gathered and visualized existing studies related to user acceptance and satisfaction using chatbots. The paper concludes with recommendations for future research to address existing challenges and optimize the use of LLM-based chatbots in education.},
  keywords={Surveys;Measurement;Large language models;Education;Data preprocessing;Focusing;Chatbots;Transformers;Real-time systems;Prompt engineering;Chatbots;e-Tutor;AI in Education;LLMs;Education;eLearning;Transformer Model},
  doi={10.1109/ICSCC62041.2024.10690334},
  ISSN={},
  month={July},}@INPROCEEDINGS{10894980,
  author={Raghi, K R and Sudha, K and M, Sreeram A and Joshua S, Steve},
  booktitle={2024 International Conference on Emerging Research in Computational Science (ICERCS)}, 
  title={Software Development Automation Using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The Software Development Lifecycle (SDLC) is a structured process that guides the development of software projects, encompassing phases from planning to deployment. Traditionally, the SDLC has relied on manual input, making it prone to delays, errors, and inefficiencies. With the recent advancements in Generative AI (GenAI) and Large Language Models (LLMs) such as GPT, it is now feasible to automate substantial portions of the SDLC. This paper presents a novel approach to automating the SDLC using LLMs and the Langchain framework, aiming to streamline the entire software development process. By au-tomating key phases, including project planning, requirements gathering, code generation, testing, and deployment, this research explores how AI can minimize human intervention and accelerate software development timelines. The paper also discusses the potential advantages of AI-driven SDLC automation, such as improved efficiency, consistency, and scalability, while addressing challenges related to its integration. The proposed approach offers a glimpse into the future of software engineering, where AI plays a central role in transforming how software is developed and delivered.},
  keywords={Automation;Generative AI;Scientific computing;Scalability;Manuals;Software;Planning;Software development management;Testing;Software engineering;Software Development Lifecycle (SDLC);Generative AI (GenAI);Large Language Models (LLMs);GPT;Langchain;SDLC automation;AI-driven software development;code generation},
  doi={10.1109/ICERCS63125.2024.10894980},
  ISSN={},
  month={Dec},}@ARTICLE{10980222,
  author={Zhang, Zherui and Xu, Rongtao and Wang, Changwei and Xu, Wenhao and Chen, Shunpeng and Xu, Shibiao and Xu, Guangyuan and Guo, Li},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={DFMC:Feature-Driven Data-Free Knowledge Distillation}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Data-Free Knowledge Distillation (DFKD) enables knowledge transfer from teacher networks without access to the real dataset. However, generator-based DFKD methods often suffer from insufficient diversity or low-confidence in synthetic images, negatively impacting student network performance. This paper introduces DFMC, a generative feature-driven framework to mitigate the inherent limitations of DFKD. We propose exploiting semantic description between generative feature domains to guide augmentation strategies, avoiding random abstract inputs caused by inconsistent semantic quality. Then, by applying noise to the generative features, we produce contrastive learning pairs indirectly, limiting the sampling range of the feature domain to encourage the student network to learn domain-invariant features. Finally, we guide the student network to deeply mimic the teacher’s layer-wise implicit classification behavior for the augmented synthetic images. Extensive experiments across various datasets and downstream tasks demonstrate the effectiveness of DFMC, achieving significant improvements while preventing student networks from overfitting to semantic ambiguous images.},
  keywords={Semantics;Knowledge engineering;Generators;Contrastive learning;Training;Synthetic data;Noise;Knowledge transfer;Circuits and systems;Diversity methods;Data-Free Knowledge Distillation;Feature Augmentation;Contrastive Learning},
  doi={10.1109/TCSVT.2025.3565616},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10222927,
  author={Jin, Ying and Chen, Yinpeng and Wang, Jianfeng and Wang, Lijuan and Hwang, Jenq-Neng and Liu, Zicheng},
  booktitle={2023 IEEE International Conference on Image Processing (ICIP)}, 
  title={Zero-Shot Human-Object Interaction (HOI) Classification by Bridging Generative and Contrastive Image-Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={1970-1974},
  abstract={Existing studies in Human-Object Interaction (HOI) classification rely on costly human-annotated labels. The goal of this paper is to study a new zero-shot setup to remove the dependency on ground-truth labels. We propose a novel Heterogenous Teacher-Student (HTS) framework and a new loss function. HTS employs a generative pretrained image captioner as the teacher and a contrastive pre-trained classifier as the student. HTS combines the discriminability from generative pre-training and efficiency from contrastive pre-training. To facilitate learning of HOI in this setup, we introduce pseudo-label filtering which aggregates HOI probabilities from multiple regional captions to supervise the student. To enhance the multi-label learning of the student on few-shot classes, we design LogSumExp (LSE)-Sign loss which features a dynamic gradient re-weighting mechanism. Eventually, the student achieves 49.6 mAP on the HICO dataset without using ground truth, becoming a new state-of-the-art method that outperforms supervised approaches. Code is available.},
  keywords={Training;High-temperature superconductors;Image recognition;Codes;Filtering;Aggregates;HOI Classification;Scene Understanding;Image Captioning;Contrastive Pre-training},
  doi={10.1109/ICIP49359.2023.10222927},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10819214,
  author={Paredes-Vargas, Alfredo and Salinas-Llorca, Piero and Santisteban, José},
  booktitle={2024 IEEE 4th International Conference on Advanced Learning Technologies on Education & Research (ICALTER)}, 
  title={Natural Language Processing Algorithms for Academic Content Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={This study has conducted several activities to analyze and compare the performance of five Natural Language Processing (NLP) models: GPT-3, T5, ERNIE, BERT, and XLNet for generating academic content in universities located in Lima, Peru. Some NLP models, including GPT and BERT, were assessed based on accuracy, quality, speed, and customization capabilities. The research examined the use of various algorithms for academic tasks like essay and summary creation. The findings show that all models perform adequately; however, some excel in generating coherent content tailored to different academic styles, thereby optimizing the time of both students and teachers. In conclusion, the ERNIE model emerges as one of the best, as it enables the generation of diverse and high-quality content efficiently.},
  keywords={Measurement;Hands;Analytical models;Solid modeling;Accuracy;Education;Linguistics;Natural language processing;Reliability;Context modeling;algorithm;SCORM;NLP;academic content;higher education},
  doi={10.1109/ICALTER65499.2024.10819214},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10578742,
  author={Hammer, Sabine and Ottinger, Sarah and Zönnchen, Benedikt and Hohendanner, Michel and Hobelsberger, Martin and Thurner, Veronika},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={ChatGPT in Higher Education: Perceptions of Computer Science-Related Students}, 
  year={2024},
  volume={},
  number={},
  pages={01-08},
  abstract={In the field of education ChatGPT has sparked both admiration and controversy. This study explores students' perspectives, specifically focusing on those in computer science-related fields. We investigated their motivations, trust, perceptions of utility, and reliability of ChatGPT by conducting two surveys-one at the beginning and another at the end of the semester. During the semester, students were encouraged to engage with ChatGPT. Our findings highlight the tool's multifaceted use in an academic settings, establishing it as a valuable resource for a variety of learning tasks. Most students have incorporated ChatGPT into their regular academic activities and view it as a beneficial aid. They perceive it as a multi-task solver and anticipate significant advancements in its writing assistance features in the near future. Many, not only attribute high accuracy to it but think that it adheres to appropriate content and structural norms. Our results suggest that active confrontation with ChatGPT enhances understanding of its capabilities, limitations and autoregressive nature. Consequently, we recommend an approach of informed engagement that includes the distinction between language processing and genuine language understanding and a carefully crafted terminology.},
  keywords={Accuracy;Terminology;Computational modeling;Focusing;Writing;Chatbots;Multitasking;ChatGPT;large language models;higher education;educational technology},
  doi={10.1109/EDUCON60312.2024.10578742},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10778529,
  author={Andonov, Venko},
  booktitle={2024 12th International Scientific Conference on Computer Science (COMSCI)}, 
  title={Enhancing University Students’ Activities with Interactive Immediate Feedback Using Customized LLMs}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={One of the significant issues for the students is getting timely feedback on their work so that they can understand their mistakes and improve their knowledge iteratively. There have been significant results in this area through automated evaluation, but they require a strongly defined structure of the expected results, which has its limitations. We propose using customized large language models as the core of an assignment evaluation software architecture that is used for automated evaluation and feedback generation on a variety of tasks in an introductory Java programming course. The model is implemented and tested, achieving significantly better results than using general-purpose models.},
  keywords={Java;Software architecture;Computational modeling;Large language models;Software;Programming profession;Context modeling;education;learning systems;large language models},
  doi={10.1109/COMSCI63166.2024.10778529},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10761147,
  author={Arin, Ikrar and Farkhan, Arsyil and Muhamad, Fahmi and Anjani, Fairuz Thahirah},
  booktitle={2024 2nd International Conference on Technology Innovation and Its Applications (ICTIIA)}, 
  title={Analysis of the Impact of ChatGPT Utilization on the Levels of Laziness and Productivity}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study aims to analyze the effect of using ChatGPT on student laziness and productivity levels. The research focuses on how students utilize ChatGPT for various academic tasks such as research, writing, and problem-solving. Laziness is measured through self-reported procrastination and task avoidance behaviors. Using the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model, we examined factors influencing ChatGPT adoption and its impact on academic behaviors. The research method used is quantitative, with data collected through distributed questionnaires to students who actively use ChatGPT. The results show that Habit and Price Value have a significant positive effect on Behavioral Intention, and Behavioral Intention has a significant positive effect on Student Productivity. However, Effort Expectancy, Facilitating Conditions, Hedonic Motivation, Performance Expectancy, and Social Influence have an insignificant negative effect on Behavioral Intention. Additionally, behavioral intention has an insignificant negative effect on the level of laziness, contrary to the hypothesis's direction.},
  keywords={Productivity;Technological innovation;Costs;Education;Distributed databases;Writing;Chatbots;Problem-solving;Artificial intelligence;ChatGPT;Student;Productivity;Academic Laziness;Technology Acceptance;Higher Education},
  doi={10.1109/ICTIIA61827.2024.10761147},
  ISSN={},
  month={Sep.},}@ARTICLE{11024027,
  author={Kumar, Akshi and Sharma, Aditi and Sangwan, Saurabh Raj},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={DynaMentA: Dynamic Prompt Engineering and Weighted Transformer Architecture for Mental Health Classification Using Social Media Data}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Mental health classification is inherently challenging, requiring models to capture complex emotional and linguistic patterns. Although large language models (LLMs) such as ChatGPT, Mental-Alpaca, and MentaLLaMA show promise, they are not trained on clinically grounded data and often overlook subtle psychological cues. Their predictions tend to overemphasize emotional intensity, while failing to capture contextually relevant indicators that are critical for accurate mental health assessment. This article introduces dynamic prompt engineering and weighted transformer architecture dynamic prompt engineering and weighted transformer architecture for mental health classification (DynaMentA), a novel dual-layer transformer framework that integrates the strengths of BioGPT and decoding-enhanced BERT with disentangled attention (DeBERTa) to address these challenges. BioGPT captures fine-grained biomedical indicators, while DeBERTa provides context-aware disambiguation. The ensemble mechanism dynamically weights their outputs, guided by a simulated feedback loop that refines the predictions during training. Unlike previous studies that treat classification statically, DynaMentA incorporates dynamic prompt engineering to better align with evolving linguistic and emotional signals. Evaluated on three benchmark datasets, DepSeverity, suicide versus depression classification natural language (SDCNL), and Dreaddit, DynaMentA achieves precision of 92.6%, 91.9% F1-score, and 0.94 AUC-ROC, consistently outperforming the existing benchmark, including general-purpose LLMs and domain-specific mental health models. This scalable and interpretable framework establishes a state-of-the-art methodology for computational mental health analysis in high-stakes applications, such as suicide risk assessment and crisis intervention and early detection of severe depressive episodes.},
  keywords={Mental health;Transformers;Biological system modeling;Linguistics;Prompt engineering;Computer architecture;Adaptation models;Depression;Computational modeling;Social networking (online);Artificial intelligence (AI) in mental health;deep learning for social systems;mental health classification;social media data analysis;weighted transformer models},
  doi={10.1109/TCSS.2025.3569400},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{10825945,
  author={Wang, Bingjiao and Zhang, Yong and Zeng, Qinglei},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Resources Construction and LLM Fine-tuning for Education of Computer Science}, 
  year={2024},
  volume={},
  number={},
  pages={1655-1663},
  abstract={The limited inference capabilities of large language models in the field of computer science significantly hinder their application in computer education question-answering tasks. To address this issue, this paper focuses on three key areas: constructing domain-specific datasets, enhancing these datasets, and fine-tuning large language models to improve their performance in computer education question answering. The foundational dataset is sourced from university and online question banks, consisting of over 1600 entries, including 678 multiple-choice questions, 502 true/false questions, and 509 fill-in-the-blank questions. These questions span 11 disciplines, such as artificial intelligence, software engineering, and digital logic. Additionally, this study uses a large model for data augmentation, expanding the scope and scale of the base dataset. The augmented content is sourced from Baidu Baike and GPT-generated text, ultimately increasing the dataset to over 10000 entries. Based on this expanded dataset, the study employs LoRA technology to fine-tune the LLaMA2-7B model. Experimental results demonstrate that the performance of the fine-tuned model significantly outperforms other baselines across various task types.},
  keywords={Computational modeling;Large language models;Education;Web and internet services;Data augmentation;Data models;Question answering (information retrieval);Logic;Programming profession;Software engineering;data augmentation with large language models;fine-tuning;dataset construction;computer science Q&A},
  doi={10.1109/BigData62323.2024.10825945},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10987407,
  author={Seetaworn, Supitsara and Phenhiran, Phuree and Ngokpol, Perapard and Innoy, Montira and Ingboon, Sorayuth and Utasri, Tharathon and Takhom, Akkharawoot},
  booktitle={2025 IEEE International Conference on Cybernetics and Innovations (ICCI)}, 
  title={Leveraging Knowledge Graphs for Personalized Internship Recommendations: A Case Study on Software Engineering Courses}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Internships play a vital role in bridging academic learning with industry requirements. This paper presents a knowledge graph-based framework for generating personalized internship recommendations by integrating course syllabi, student competencies, and job descriptions. The approach leverages structured knowledge representation and graph traversal to dynamically match students' academic progress with relevant opportunities. Additionally, Large Language Models (LLMs) are employed for entity extraction to enhance recommendation accuracy. A case study involving Software Engineering subjects within a Programme of Innovative Engineering demonstrates the framework's ability to provide tailored internship suggestions and identify skill gaps. The results indicate that knowledge graphs offer a scalable and adaptable solution for aligning academic curricula with evolving industry needs.},
  keywords={Industries;Technological innovation;Accuracy;Large language models;Knowledge graphs;Cybernetics;Software engineering;Internship Recommendation;Skill Mapping;Knowledge Graph;Large Language Models;Graph Traversal},
  doi={10.1109/ICCI64209.2025.10987407},
  ISSN={},
  month={April},}@ARTICLE{10681241,
  author={Zhou, Yijie and Cheng, Xianhui and Zhang, Qiming and Wang, Lei and Ding, Wenchao and Xue, Xiangyang and Luo, Chunbo and Pu, Jian},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={ALGPT: Multi-Agent Cooperative Framework for Open-Vocabulary Multi-Modal Auto-Annotating in Autonomous Driving}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Large Language Models (LLMs) have achieved impressive progress in decision-making and task automation for intelligent agents. However, multiple agents must cooperate to complete tasks in complex real-world applications, such as auto-annotating in autonomous driving. The primary challenges lie in how multiple agents effectively communicate and collaborate in a multi-modal environment and how to automatically refine annotating results to reduce human intervention. These challenges also hinder LLMs from fully evolving into embodied intelligent agents. Driven by these motivations, we propose ALGPT, a multi-agent cooperative framework for open-vocabulary multi-modal auto-annotation in autonomous driving. ALGPT dynamically assembles agent teams with different roles, and agents cooperate to complete annotation tasks according to requirements. By leveraging Chain of Thought (CoT) and In-Context Learning (ICL) techniques, ALGPT's reasoning capabilities are enhanced, allowing it to develop suitable plans autonomously without human intervention. Furthermore, drawing from project management standards, we introduce project management documents and Standard Operating Procedures (SOPs), which further align ALGPT's behavior with human expectations and mitigate the impact of GPT illusions caused by the cascading effects of multiple GPTs. The source code will be released at https://github.com/Fudan-ProjectTitan/OpenAnnotate.},
  keywords={Annotations;Intelligent agents;Autonomous vehicles;Manuals;Cognition;Three-dimensional displays;Standards;Automatic annotation;autonomous driving;multi-agents;multi-modal data annotation},
  doi={10.1109/TIV.2024.3461651},
  ISSN={2379-8904},
  month={},}@INPROCEEDINGS{10605652,
  author={Dudysheva, Elena V. and Veryaev, Anatoly A.},
  booktitle={2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE)}, 
  title={Enhancing Interactive Information Support in Student Interdisciplinary Project Training: A Socio-Ecological Perspective of the Digital Environment}, 
  year={2024},
  volume={},
  number={},
  pages={246-251},
  abstract={Interactive information support tools play a pivotal role in project-based training, particularly when students engage in independent practical tasks outside the classroom over extended periods. This study investigates the socio-ecological conditions within the digital environment and explores the characteristics of interactive electronic tools that can enhance the effectiveness of independent work of students. The digital environment offers significant prospects for interactive educational content, educational communication, and information support. Socio-ecological aspects manifest through explicit and implicit interactions among actors within the educational process. These aspects can be effectively studied using hierarchical models within the learning ecology framework. Intelligent information support tools hold promises for enhancing teaching efficiency, especially when experts together lecturers engage in remote monitoring and asynchronous communication with students. Leveraging generative neural models for information support services further augments this potential. Additionally, integrating digital gamification methods based on mobile and immersive technologies complements intelligent learning tools. Experimental work with future teachers has revealed that socio-environmental factors significantly impact students' independent work and foster novel forms of communication within open digital environments. Ecological models of educational communication can serve as the foundation for socio-ecological education, facilitating personal adaptation to cultural and historical experiences.},
  keywords={Training;Asynchronous communication;Adaptation models;Biological system modeling;Ecology;Global communication;Cultural differences;interdisciplinary project training;interactive learning tools;intellectual tools of information support;effects of social ecology;learning ecology systems;digital gamification;semiotics of educational communications},
  doi={10.1109/TELE62556.2024.10605652},
  ISSN={},
  month={June},}@INPROCEEDINGS{10633294,
  author={Ahmed, Fatma Refaat and Al-Yateem, Nabeel and Rushdan, Esraa and Saifan, Ahmad Rajeh and Rahman, Syed and Mottershead, Richard and Hijazi, Heba and Subu, Muhammad Arsyad and Bani-Issa, Wegdan and Dias, Jacqueline Maria and Aburuz, Mohannad Eid},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Health Sciences students and educators experience with using ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1926-1928},
  abstract={This study investigates the experiences, challenges, and opportunities presented by ChatGPT AI in health sciences education, focusing on self-directed learning among students and educators at the University of Sharjah, UAE. Utilizing a descriptive qualitative research design, the study engaged participants through semi-structured interviews to explore diverse perspectives on ChatGPT's application in health sciences education. Results indicate mixed reactions: while users appreciate ChatGPT for its efficiency in academic tasks, concerns were raised about its offline functionality, linguistic inclusivity, ethical considerations, and potential impact on learning integrity and skill acquisition. Non-users expressed apprehension towards dependency on AI, diminished learning engagement, and academic dishonesty. The study concludes that while ChatGPT offers significant benefits in terms of resourcefulness and efficiency, its integration into educational settings necessitates careful consideration of accessibility, ethical standards, and the maintenance of academic integrity. These findings underline the need for a balanced approach to adopting AI technologies in education, highlighting the importance of addressing both the opportunities and challenges they present to foster an enriching learning environment.},
  keywords={Ethics;Education;Learning (artificial intelligence);Linguistics;Chatbots;Software;Maintenance;Artificial Intelligence;ChatGPT;Health Sciences Education;Technology Acceptance},
  doi={10.1109/COMPSAC61105.2024.00305},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10542754,
  author={Baksa, Tanja and Konecki, Mario and Konecki, Mladen},
  booktitle={2024 12th International Conference on Information and Education Technology (ICIET)}, 
  title={High School Students' Perception of AI and Its Future Impact on Education}, 
  year={2024},
  volume={},
  number={},
  pages={215-219},
  abstract={Different artificial intelligence (AI) based technologies and systems are gaining in a variety of uses, including personal assistants, chatbots, different suggestion engines, smart appliances etc. Usage of this technology is accompanied by various positive views, but also by a fair share of skepticism. Since ChatGPT has been introduced, there have been rising debates regarding AI and its effects on education, employment, ethics, security, and other areas. One of the important questions is how young people view this new technology and all its implications. The purpose of this study was to learn more about how high school students view and feel about AI. Research regarding AI was conducted among 124 high school students in classes I through IV (aged 15 to 19). Although new technologies are something they embrace, students also find that no AI technology can completely replace human beings in education. Despite having different viewpoints on the matter, they are optimistic about new technologies and think that AI tools would be beneficial for future teaching and learning.},
  keywords={Chaos;Ethics;Education;Employment;Aging;Chatbots;Security;artificial intelligence;high school students;perception of AI;AI in education},
  doi={10.1109/ICIET60671.2024.10542754},
  ISSN={},
  month={March},}@ARTICLE{10659742,
  author={Zhou, Xin and Xu, Bowen and Kim, Kisub and Han, DongGyun and Nguyen, Hung Huu and Le-Cong, Thanh and He, Junda and Le, Bach and Lo, David},
  journal={IEEE Transactions on Software Engineering}, 
  title={Leveraging Large Language Model for Automatic Patch Correctness Assessment}, 
  year={2024},
  volume={50},
  number={11},
  pages={2865-2883},
  abstract={Automated Program Repair (APR) techniques have shown more and more promising results in fixing real-world bugs. Despite the effectiveness, APR techniques still face an overfitting problem: a generated patch can be incorrect although it passes all tests. It is time-consuming to manually evaluate the correctness of generated patches that can pass all available test cases. To address this problem, many approaches have been proposed to automatically assess the correctness of patches generated by APR techniques. These approaches are mainly evaluated within the cross-validation setting. However, for patches generated by a new or unseen APR tool, users are implicitly required to manually label a significant portion of these patches (e.g., 90% in 10-fold cross-validation) in the cross-validation setting before inferring the remaining patches (e.g., 10% in 10-fold cross-validation). To mitigate the issue, in this study, we propose LLM4PatchCorrect, the patch correctness assessment by adopting a large language model for code. Specifically, for patches generated by a new or unseen APR tool, LLM4PatchCorrect does not need labeled patches of this new or unseen APR tool for training but directly queries the large language model for code to get predictions on the correctness labels without training. In this way, LLM4PatchCorrect can reduce the manual labeling effort when building a model to automatically assess the correctness of generated patches of new APR tools. To provide knowledge regarding the automatic patch correctness assessment (APCA) task to the large language model for code, LLM4PatchCorrect leverages bug descriptions, execution traces, failing test cases, test coverage, and labeled patches generated by existing APR tools, before deciding the correctness of the unlabeled patches of a new or unseen APR tool. Additionally, LLM4PatchCorrect prioritizes labeled patches from existing APR tools that exhibit semantic similarity to those generated by new APR tools, enhancing the accuracy achieved by LLM4PatchCorrect for patches from new APR tools. Our experimental results showed that LLM4PatchCorrect can achieve an accuracy of 84.4% and an F1-score of 86.5% on average although no labeled patch of the new or unseen APR tool is available. In addition, our proposed technique significantly outperformed the prior state-of-the-art.},
  keywords={Computer bugs;Codes;Task analysis;Large language models;Feature extraction;Training;Manuals;Automatic patch correctness assessment;large language models of code;in-context learning},
  doi={10.1109/TSE.2024.3452252},
  ISSN={1939-3520},
  month={Nov},}@INPROCEEDINGS{10485053,
  author={Yin, Junqi and Dash, Sajal and Wang, Feiyi and Shankar, Mallikarjun Arjun},
  booktitle={SC23: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={FORGE: Pre-Training Open Foundation Models for Science}, 
  year={2023},
  volume={},
  number={},
  pages={1-13},
  abstract={Large language models (LLMs) are poised to revolutionize the way we conduct scientific research. However, both model complexity and pre-training cost are impeding effective adoption for the wider science community. Identifying suitable scientific use cases, finding the optimal balance between model and data sizes, and scaling up model training are among the most pressing issues that need to be addressed. In this study, we provide practical solutions for building and using LLM-based foundation models targeting scientific research use cases. We present an end-to-end examination of the effectiveness of LLMs in scientific research, including their scaling behavior and computational requirements on Frontier, the first Exascale supercomputer. We have also developed for release to the scientific community a suite of open foundation models called FORGE with up to 26B parameters using 257B tokens from over 200M scientific articles, with performance either on par or superior to other state-of-the-art comparable models. We have demonstrated the use and effectiveness of FORGE on scientific downstream tasks. Our research establishes best practices that can be applied across various fields to take advantage of LLMs for scientific discovery.},
  keywords={Training;Costs;Computational modeling;High performance computing;Buildings;Pressing;Data models},
  doi={10.1145/3581784.3613215},
  ISSN={2167-4337},
  month={Nov},}@INPROCEEDINGS{11018890,
  author={Venkatraman, S and Bamrah, Sumneet Kaur and Rani, D Pushgara},
  booktitle={2025 International Conference on Computing and Communication Technologies (ICCCT)}, 
  title={Automated Multilingual Translation of Exam Question Papers Using Generative AI}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={The research article undertakes an experimental analysis of utilizing conversational/generative AI tools for translating question papers from English to other Indian languages, as frequently seen in the question papers of many Indian universities/colleges and competitive recruitment examinations. This automation of question paper translation shall offload a portion of the workload of academic teachers who are into preparing question papers for various types of examinations. A desktop application of GUI type is developed leveraging artificial intelligence backed ChatGPT and Claude AI as a ready to use zero cost application.},
  keywords={Translation;Costs;Automation;Accuracy;Generative AI;Chatbots;Communications technology;Multilingual;Recruitment;Graphical user interfaces;AI;Artificial Intelligence;ChatGPT;Claude AI;conversational;generative;teachers},
  doi={10.1109/ICCCT63501.2025.11018890},
  ISSN={2995-3197},
  month={April},}@ARTICLE{10856008,
  author={Abdullahi, Shamsu and Usman Danyaro, Kamaluddeen and Zakari, Abubakar and Abdul Aziz, Izzatdin and Amila Wan Abdullah Zawawi, Noor and Adamu, Shamsuddeen},
  journal={IEEE Access}, 
  title={Time-Series Large Language Models: A Systematic Review of State-of-the-Art}, 
  year={2025},
  volume={13},
  number={},
  pages={30235-30261},
  abstract={Large Language Models (LLMs) have transformed Natural Language Processing (NLP) and Software Engineering by fostering innovation, streamlining processes, and enabling data-driven decision-making. Recently, the adoption of LLMs in time-series analysis has catalyzed the emergence of time-series LLMs, a rapidly evolving research area. Existing reviews provide foundational insights into time-series LLMs but lack a comprehensive examination of recent advancements and do not adequately address critical challenges in this domain. This Systematic Literature Review (SLR) bridges these gaps by analysing state-of-the-art contributions in time-series LLMs, focusing on architectural innovations, tokenisation strategies, tasks, datasets, evaluation metrics, and unresolved challenges. Using a rigorous methodology based on PRISMA guidelines, over 700 studies from 2020 to 2024 were reviewed, with 59 relevant studies selected from journals, conferences, and workshops. Key findings reveal advancements in architectures and novel tokenization strategies tailored for temporal data. Forecasting dominates the identified tasks with 79.66% of the selected studies, while classification and anomaly detection remain underexplored. Furthermore, the analysis reveals a strong reliance on datasets from the energy and transportation domains, highlighting the need for more diverse datasets. Despite these advancements, significant challenges persist, including tokenization inefficiencies, prediction hallucinations, and difficulties in modelling long-term dependencies. These issues hinder the robustness, scalability, and adaptability of time-series LLMs across diverse applications. To address these challenges, this SLR outlines a research roadmap emphasizing the improvement of tokenization methods, the development of mechanisms for capturing long-term dependencies, the mitigation of hallucination effects, and the design of scalable, interpretable models for diverse time-series tasks.},
  keywords={Time series analysis;Forecasting;Measurement;Tokenization;Systematic literature review;Systematics;Databases;Transformers;Search problems;Anomaly detection;Time-series;large language models;forecasting;tokenization;time-series LLMs},
  doi={10.1109/ACCESS.2025.3535782},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10736116,
  author={Jovanovic, Jelena},
  booktitle={2024 19th Conference on Computer Science and Intelligence Systems (FedCSIS)}, 
  title={The Interplay of Learning Analytics and Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={35-44},
  abstract={The widespread use of digital systems and tools in education has opened up opportunities for collecting, measuring, and analysing data about user (learner, teacher) interactions with a variety of learning resources and activities, with the ultimate objective of better understanding learning and advancing both learning outcomes and the overall learning experience. This promise motivated the development of Learning Analytics (LA) as a research and practical field and the use of insights derived from learning trace data for evidence-based decision making in a variety of educational settings. While LA has made a significant contribution to better understanding of learning and the environments in which it takes place, many open questions and challenges remain. Furthermore, new opportunities and challenges continue to emerge with the ever-changing modalities of teaching and learning, the latest of which are associated with the rapid development and accessibility of Artificial Intelligence (AI). Taking the cyclical model of LA as its exploration framework, this paper examines how key components of the LA model – namely data, methods, and actions – relate to and may benefit from the latest developments in AI, and especially Generative AI. Aiming for evidence-based analysis and discussion of the interplay between LA and AI, the paper relies on the latest empirical research in LA and the related research fields of AI in Education and Educational Data Mining.},
  keywords={Analytical models;Data privacy;Generative AI;Digital systems;Education;Decision making;Learning (artificial intelligence);Data models;Stakeholders;Public policy;Learning Analytics;Artificial Intelligence in Education;Generative AI},
  doi={10.15439/2024F5859},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10314211,
  author={Li, Yihao and Xu, Jialong and Zhu, Yinghua and Liu, Huashuo and Liu, Pan},
  booktitle={2023 10th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={The Impact of ChatGPT on Software Engineering Education: A Quick Peek}, 
  year={2023},
  volume={},
  number={},
  pages={595-596},
  abstract={Since its public launch at the end of 2022, ChatGPT has garnered global attention, showcasing the diverse capabilities of AI in tackling human tasks. Its rapid growth and widespread adoption have permeated every corner of our daily routine. This paper provides a quick peek at the impact of ChatGPT from the perspective of software engineering education. Specifically, to make our case study creative and interesting, we compare the impact answered by ChatGPT with the real feedback from existing literature. In this way, we explore the potential of ChatGPT as a teaching and learning tool in software engineering.},
  keywords={Education;Chatbots;Task analysis;Artificial intelligence;Software engineering;ChatGPT;software engineering;education;teaching and learning},
  doi={10.1109/DSA59317.2023.00087},
  ISSN={2767-6684},
  month={Aug},}@INPROCEEDINGS{10959761,
  author={Cheng, Yiduo and Wang, Tongbang},
  booktitle={2024 International Conference on Intelligent Education and Intelligent Research (IEIR)}, 
  title={The Impact of AIGC on Modern Education: Transforming Learning and Teaching Methods}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper examines the transformative influence of artificial intelligence generated content (AIGC) on modern education, focusing on its applications for both learners and educators. By leveraging cutting-edge algorithms such as GAN, Diffusion and Transformer, AIGC technologies like ChatGPT and DALL-E enable automated content creation, interactive learning, and multimedia generation. The paper explores the diverse roles AIGC plays in improving educational processes, proposing a methodology of using AIGC to assist learning and teaching. It also discusses the challenges, including the risk of misinformation, academic integrity concerns, the changing dynamics of teacher-student relationships and uncertain results. This study emphasizes the need for ethical integration and critical thinking to maximize the positive effects of AIGC in education.},
  keywords={Ethics;Education;Focusing;Transforms;Learning (artificial intelligence);Chatbots;Transformers;Market research;Planning;Fake news;artificial intelligence generated content (AIGC);chatGPT;personalized learning;adaptive teaching strategies;teacher-student dynamics},
  doi={10.1109/IEIR62538.2024.10959761},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10441978,
  author={Liao, Fei},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer (EIECT)}, 
  title={Public Perception and Sentiment of ChatGPT: Machine Learning Analysis on Weibo Posts}, 
  year={2023},
  volume={},
  number={},
  pages={579-583},
  abstract={ChatGPT, a large, pre-trained language model, which is developed by OpenAI, has exerted a great influence on society in all aspects since its launch. Knowing the adopters’ perspectives, preferences and sentiment is of critical significance for a technological company to promote and improve its products. Such social media as YouTube and Weibo, offer a convenient and time-saving channel for opinion mining. In this paper, 67,985 Weibo posts ranging from December 1, 2022 to September 30, 2023 were analyzed to explore the main topics and sentiment of users by employing machine learning techniques, including latent Dirichlet allocation (LDA) topic modeling algorithm and sentiment analysis. The results suggest that more than half of the adopters expressed a positive attitude towards all topics. However, a small portion of users have expressed worry and concern about the impact of ChatGPT on education and career compared to the other two topics, the development of the AI industry and the introduction of ChatGPT. This paper, while further proving the applicability of social media to explore the public’s opinion toward a new technology, offers insights into and contributes to the development and popularity of ChatGPT by figuring out Chinese users’ perspectives and sentiment.},
  keywords={Industries;Sentiment analysis;Social networking (online);Education;Blogs;Machine learning;Chatbots;topic modeling;sentiment analysis;ChatGPT;Weibo posts;machine learning},
  doi={10.1109/EIECT60552.2023.10441978},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10709091,
  author={Sihan, Sun and Shiming, Ma},
  booktitle={2024 IEEE 2nd International Conference on Image Processing and Computer Applications (ICIPCA)}, 
  title={Optimizing Logistic Regression for Predicting Teacher Job Satisfaction: An AI-Driven Approach to Faculty Development}, 
  year={2024},
  volume={},
  number={},
  pages={206-210},
  abstract={This study focuses on the development and optimization of a logistic regression model to predict teacher job satisfaction, emphasizing the role of artificial intelligence technology in enhancing the accuracy of educational data analysis. By applying Generative Adversarial Networks (GAN) and Random Forest algorithms to enhance and optimize data from 453 teacher surveys, this research demonstrates the effective use of computer models in addressing complex educational issues. The optimized model not only excels in predicting teacher satisfaction but also provides insights for educational management, aiding in the improvement of teachers' working environments and professional development. This work not only proves the potential of deep learning technologies in the field of education but also offers a new perspective and tools for future educational research and practices using artificial intelligence.},
  keywords={Surveys;Logistic regression;Analytical models;Data analysis;Computational modeling;Predictive models;Prediction algorithms;Generative adversarial networks;Data models;Artificial intelligence;Logistic regression model;teacher job satisfaction;Generative Adversarial Networks;Random Forest algorithm;artificial intelligence;educational data analysis},
  doi={10.1109/ICIPCA61593.2024.10709091},
  ISSN={},
  month={June},}@INPROCEEDINGS{10633327,
  author={Li, Yishu and Keung, Jacky and Ma, Xiaoxue and Chong, Chun Yong and Zhang, Jingyu and Liao, Yihan},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={LLM-Based Class Diagram Derivation from User Stories with Chain-of-Thought Promptings}, 
  year={2024},
  volume={},
  number={},
  pages={45-50},
  abstract={In agile requirements engineering, user stories are the primary means of capturing project requirements. However, deriving conceptual models, such as class diagrams, from user stories requires significant manual effort. This paper explores the potential of leveraging Large Language Models (LLMs) and a tailored Chain-of- Thought (CoT) prompting technique to automate this task. We conducted a comprehensive preliminary study to investigate different prompting techniques applied to the task. The study involved comparing LLM-based approaches with guided and unguided human extraction to evaluate the effectiveness of the proposed LLM-based techniques. Our findings demonstrate that LLM-based approaches, particularly when combined with well-crafted few-shot prompts, outperform guided human extraction in identifying classes. However, we also identified areas of suboptimal performance through qualitative analysis. The proposed CoT prompting technique offers a promising pathway to automate the derivation of class diagrams in agile projects, reducing the reliance on manual effort. Our study contributes valuable insights and directions for future research in this field.},
  keywords={Accuracy;Large language models;Computational modeling;Manuals;Software;Requirements engineering;Task analysis;Requirements engineering;user story;large language models;chain of thought prompting},
  doi={10.1109/COMPSAC61105.2024.00017},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10892909,
  author={Ghimire, Sujan and Chowdhury, Muhtasim Alam and Tsang, Ryan and Yarnell, Richard and Heckert, Emma and Carpenter, Jaeden and Lin, Yu-Zheng and Mamun, Muntasir and DeMara, Ronald F. and Rafatirad, Setareh and Satam, Pratik and Salehi, Soheil},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Interactive Framework for Cybersecurity Education and Future Workforce Development}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This research-to-practice paper presents a novel pedagogical tool for hardware cybersecurity education and workforce development. The growing importance of hardware security has made it essential for individuals and organizations to understand hardware security principles and best practices. However, the current educational curriculum falls short of fulfilling these emerging demands due to the rapidly changing hardware security landscape and limited opportunities for hands-on training. To address these challenges, we propose and have developed the Interactive Hardware and Cybersecurity (I-HaC) Educational Framework, a pedagogical educational framework that supplements existing courses by leveraging generative AI for individualized instruction related to hardware and cybersecurity, data mining, and applied Machine Learning (ML), as well as data visualization to enhance cybersecurity education and workforce development. The framework is designed to be utilized by graduate and undergraduate Electrical and Computer Engineering (ECE) and Computer Science (CS) students for a comprehensive introduction to cybersecurity exploits and countermeasures in an interactive manner with hands-on components. Using I-HaC, we have developed tailored lab components for a diverse range of students and intend to release I-HaC as open-source for the benefit of the ECE and CS education community.},
  keywords={Training;Generative AI;Databases;Hardware security;Data visualization;Organizations;Machine learning;Ontologies;Computer security;Protection;National Vulnerability Database (NVD);Com-mon Vulnerability and Exposure (CVE);Common Weakness Enumeration (CWE);Hardware Security;Cybersecurity Education;Future Workforce Development},
  doi={10.1109/FIE61694.2024.10892909},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10708253,
  author={Rezgui, Kalthoum},
  booktitle={2024 10th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Large Language Models for Healthcare: Applications, Models, Datasets, and Challenges}, 
  year={2024},
  volume={},
  number={},
  pages={2366-2371},
  abstract={Large Language Models (LLMs) are being increasingly explored and used in healthcare for their potential applications. These models show the capacity to impact clinical care, research, and medical education significantly. In this research, we shed light on the transformative potential of LLMs in reshaping the healthcare landscape, emphasizing their role in enhancing patient care, improving decision-making processes, and advancing medical research. While the application of LLMs in healthcare presents immense opportunities, this research, also, addresses critical challenges and limitations. Concerns regarding the accuracy, reliability, and ethical implications of LLMs in medical contexts are highlighted, emphasizing the need for continuous monitoring and evaluation to ensure patient safety and data privacy. By exploring the opportunities and challenges associated with LLMs in healthcare, this study contributes to a deeper understanding of the implications and future directions of this technology in the healthcare sector.},
  keywords={Ethics;Privacy;Technological innovation;Regulators;Large language models;Decision making;Medical services;Safety;Reliability;Medical diagnostic imaging;Healthcare;Large Language Models;Applications;Challenges},
  doi={10.1109/CoDIT62066.2024.10708253},
  ISSN={2576-3555},
  month={July},}@INPROCEEDINGS{10852443,
  author={Pasupuleti, Rajesh and Vadapalli, Ravi and Mader, Christopher and Timothy, Norris},
  booktitle={2024 2nd International Conference on Foundation and Large Language Models (FLLM)}, 
  title={Popular LLM-Large Language Models in Enterprise Applications}, 
  year={2024},
  volume={},
  number={},
  pages={125-131},
  abstract={For the public, understanding Large Language Models (LLMs) can be likened to recognizing how a well-trained assistant works—one that has read an extensive library of information on virtually every topic imaginable. Imagine an assistant that not only reads and remembers all this information but also learns the nuances of how words and ideas are connected across different contexts. This assistant can then use this knowledge to write articles, answer questions, compose emails, or even generate creative stories, all in a manner that feels surprisingly human. This capability comes from what's known as "transformer architecture," a type of design that helps the model pay attention to different parts of the text as it reads, making it adept at understanding and generating language. LLMs are a breakthrough in technology because they can understand and produce language with a level of subtlety and complexity that was previously unachievable, making them valuable tools across various industries. The paper aims to provide a comprehensive analysis of the transformative impact of LLMs across various enterprise sectors. It intends to contribute to the understanding of how LLMs can enhance efficiency, innovation, and decision-making processes in industries such as healthcare, finance, education, and in the software engineering sector. It also provides a comprehensive overview of current popular LLMs in Enterprise applications, in various domains, and discusses the Ethical, Technical, and Regulatory challenges, future trends, and developments in this dynamic field.},
  keywords={Industries;Technological innovation;Image recognition;Large language models;Finance;Medical services;Transformers;Market research;Libraries;Software engineering;Large Language Models (LLMs);Natural Language Processing (NLP);Popular LLMs;Transformer Architecture;Artificial Intelligence;Deep Learning;Machine Learning;Enterprise LLM applications},
  doi={10.1109/FLLM63129.2024.10852443},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10556432,
  author={Sergeyuk, Agnia and Lvova, Olga and Titov, Sergey and Serova, Anastasiia and Bagirov, Farid and Kirillova, Evgeniia and Bryksin, Timofey},
  booktitle={2024 IEEE/ACM 32nd International Conference on Program Comprehension (ICPC)}, 
  title={Reassessing Java Code Readability Models with a Human-Centered Approach}, 
  year={2024},
  volume={},
  number={},
  pages={225-235},
  abstract={To ensure that Large Language Models (LLMs) effectively support user productivity, they need to be adjusted. Existing Code Readability (CR) models can guide this alignment. However, there are concerns about their relevance in modern software engineering since they often miss the developers’ notion of readability and rely on outdated code. This research assesses existing Java CR models for LLM adjustments, measuring the correlation between their and developers’ evaluations of AI-generated Java code. Using the Repertory Grid Technique with 15 developers, we identified 12 key code aspects influencing CR that were consequently assessed by 390 programmers when labeling 120 AI-generated snippets. Our findings indicate that when AI generates concise and executable code, it’s often considered readable by CR models and developers. However, a limited correlation between these evaluations underscores the importance of future research on learning objectives for adjusting LLMs and on the aspects influencing CR evaluations included in predictive models.},
  keywords={Productivity;Surveys;Java;Codes;Correlation;Predictive models;Data models;Code Readability;Code Readability Models;Repertory Grid Technique;AI-Generated Code;Human-Computer Interaction},
  doi={},
  ISSN={2643-7171},
  month={April},}@INPROCEEDINGS{10589832,
  author={Barclay, Peter J and Sami, Ashkan},
  booktitle={2024 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Investigating Markers and Drivers of Gender Bias in Machine Translations}, 
  year={2024},
  volume={},
  number={},
  pages={455-464},
  abstract={Implicit gender bias in Large Language Models (LLMs) is a well-documented problem that needs to be better understood in order to be addressed effectively. Implications of gender introduced into automatic translations can perpetuate real-world biases in Software Engineering and other domains. However, some LLMs use heuristics or post-processing to mask such bias, which makes investigation more difficult. Here, we examine bias in language models via back-translation, using the DeepL online translation service to investigate the bias evinced when repeatedly translating a set of 56 Software Engineering tasks used in a previous study. Each statement starts with ‘she’, and is translated first into a ‘genderless’ intermediate language then back into English; we then examine pronoun-choice in the back-translated texts. We believe this approach provides a useful alternative to large-scale surveys in mapping biases. We expand prior research in the following ways: (1) by comparing results across five intermediate languages, namely Finnish, Indonesian, Estonian, Turkish and Hungarian; (2) by proposing a novel metric for assessing the variation in gender implied in repeated translations of the same phrase, avoiding the over-interpretation of individual pronouns, apparent in earlier work; (3) by investigating sentence features that drive bias; (4) and by comparing results from three time-lapsed datasets to establish the reproducibility of the approach. We found that some languages display similar patterns of pronoun use, falling into three loose groups, but that patterns vary between groups; this underlines the need to work with multiple languages. We also identify the main verb appearing in a sentence as a likely significant driver of implied gender in the translations. Moreover, we see a good level of replicability in the results, and establish that our variation metric proves robust despite an obvious change in the behaviour of the DeepL translation API during the course of the study. These results show that the back-translation method can provide further insights into bias in language models.},
  keywords={Surveys;Analytical models;Sensitivity;Software;Reproducibility of results;Machine translation;Task analysis;back-translation;machine translation;large language model;gender bias},
  doi={10.1109/SANER60148.2024.00054},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10765115,
  author={Siddiq, Mohammed Latif and Da Silva Santos, Joanna Cecilia and Devareddy, Sajith and Muller, Anna},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW)}, 
  title={Sallm: Security Assessment of Generated Code}, 
  year={2024},
  volume={},
  number={},
  pages={54-65},
  abstract={With the growing popularity of Large Language Models (LLMs) in software engineers’ daily practices, it is important to ensure that the code generated by these tools is not only functionally correct but also free of vulnerabilities. Although LLMs can help developers to be more productive, prior empirical studies have shown that LLMs can generate insecure code. There are two contributing factors to the insecure code generation. First, existing datasets used to evaluate LLMs do not adequately represent genuine software engineering tasks sensitive to security. Instead, they are often based on competitive programming challenges or classroom-type coding tasks. In real-world applications, the code produced is integrated into larger codebases, introducing potential security risks. Second, existing evaluation metrics primarily focus on the functional correctness of the generated code while ignoring security considerations. Therefore, in this paper, we described Sallm, a framework to benchmark LLMs’ abilities to generate secure code systematically. This framework has three major components: a novel dataset of security-centric Python prompts, configurable assessment techniques to evaluate the generated code, and novel metrics to evaluate the models’ performance from the perspective of secure code generation.CCS Concepts• Security and privacy → Software security engineering; • Software and its engineering → Software verification and validation; • Computing methodologies → Natural language processing.},
  keywords={Measurement;Codes;Large language models;Programming;Transformers;Software;Natural language processing;Security;Software engineering;Python;security evaluation;large language models;pre-trained transformer model;metrics},
  doi={},
  ISSN={2151-0849},
  month={Oct},}@INPROCEEDINGS{10298494,
  author={Dipongkor, Atish Kumar and Moran, Kevin},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={A Comparative Study of Transformer-Based Neural Text Representation Techniques on Bug Triaging}, 
  year={2023},
  volume={},
  number={},
  pages={1012-1023},
  abstract={Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.},
  keywords={Training;Software maintenance;Computer bugs;Text categorization;Manuals;Machine learning;Transformers;Bug Triaging;Transformer;LLMs;Text-Embedding;DL4SE},
  doi={10.1109/ASE56229.2023.00217},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{10554146,
  author={Ivanov, Rosen and Velkova, Victoria},
  booktitle={2024 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)}, 
  title={Microservice-Based Interface to ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In today’s digitally connected world, the emergence of conversational artificial intelligence powered by generative language models has ushered in a new era of human-computer interaction. Chatbots using these technologies are increasingly being used in a variety of scientific as well as social domains. These intelligent conversational agents, powered by advances in generative language models, offer a wide range of applications from customer support and healthcare to software development and education. This paper discusses the development of a microservice that works as an interface to ChatGPT through the GPT API. The goal is to facilitate the integration of next generation chatbots to distributed architecture services. Access to the microservice is implemented using an Advanced Message Queuing Protocol (AMQP) message broker. To conduct the experiments, a microservice was developed that provides a REST interface to the proposed microservice for clients that do not support the AMQP protocol.},
  keywords={Protocols;Microservice architectures;Chatbots;Museums;Reliability;Robots;Programming profession;Chatbots;Microservices;MSA;AMQP;GPT API},
  doi={10.1109/AQTR61889.2024.10554146},
  ISSN={1844-7872},
  month={May},}@INPROCEEDINGS{10678704,
  author={Mitra, Modhurita and de Vos, Martine G. and Cortinovis, Nicola and Ometto, Dawa},
  booktitle={2024 IEEE 20th International Conference on e-Science (e-Science)}, 
  title={Generative AI for Research Data Processing: Lessons Learnt From Three Use Cases}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={There has been enormous interest in generative AI since ChatGPT was launched in 2022. However, there are concerns about the accuracy and consistency of the outputs of generative AI. We have carried out an exploratory study on the application of this new technology in research data processing. We identified tasks for which rule-based or traditional machine learning approaches were difficult to apply, and then performed these tasks using generative AI.We demonstrate the feasibility of using the generative AI model Claude 3 Opus in three research projects involving complex data processing tasks:1)Information extraction: We extract plant species names from historical seedlists (catalogues of seeds) published by botanical gardens.2)Natural language understanding: We extract certain data points (name of drug, name of health indication, relative effectiveness, cost-effectiveness, etc.) from documents published by Health Technology Assessment organisations in the EU.3)Text classification: We assign industry codes to projects on the crowdfunding website Kickstarter.We share the lessons we learnt from these use cases: How to determine if generative AI is an appropriate tool for a given data processing task, and if so, how to maximise the accuracy and consistency of the results obtained.},
  keywords={Industries;Drugs;Accuracy;Crowdfunding;Codes;Generative AI;Machine learning;Generative AI;Large Language Models;artificial intelligence;data processing;accuracy of results;consistency of results;reliability of research method},
  doi={10.1109/e-Science62913.2024.10678704},
  ISSN={2325-3703},
  month={Sep.},}@INPROCEEDINGS{10555675,
  author={Colavito, Giuseppe and Lanubile, Filippo and Novielli, Nicole and Quaranta, Luigi},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Leveraging GPT-like LLMs to Automate Issue Labeling}, 
  year={2024},
  volume={},
  number={},
  pages={469-480},
  abstract={Issue labeling is a crucial task for the effective management of software projects. To date, several approaches have been put forth for the automatic assignment of labels to issue reports. In particular, supervised approaches based on the fine-tuning of BERT-like language models have been proposed, achieving state-of-the-art performance. More recently, decoder-only models such as GPT have become prominent in SE research due to their surprising capabilities to achieve state-of-the-art performance even for tasks they have not been trained for. To the best of our knowledge, GPT-like models have not been applied yet to the problem of issue classification, despite the promising results achieved for many other software engineering tasks. In this paper, we investigate to what extent we can leverage GPT-like LLMs to automate the issue labeling task. Our results demonstrate the ability of GPT-like models to correctly classify issue reports in the absence of labeled data that would be required to fine-tune BERT-like LLMs.CCS CONCEPTS• Software and its engineering → Documentation; Software evolution; Maintaining software; • Information systems → Clustering and classification;},
  keywords={Annotations;Computational modeling;Scalability;Supervised learning;Manuals;Software;Data models;LLM;Issue Labeling;GPT;Software Maintenance and Evolution;Labeling Unstructured Data},
  doi={},
  ISSN={2574-3864},
  month={April},}@ARTICLE{10381724,
  author={Vives, Luis and Cabezas, Ivan and Vives, Juan Carlos and Reyes, Nilton German and Aquino, Janet and Cóndor, Jose Bautista and Altamirano, S. Francisco Segura},
  journal={IEEE Access}, 
  title={Prediction of Students’ Academic Performance in the Programming Fundamentals Course Using Long Short-Term Memory Neural Networks}, 
  year={2024},
  volume={12},
  number={},
  pages={5882-5898},
  abstract={In recent years, there has been evidence of a growing interest on the part of universities to know in advance the academic performance of their students and allow them to establish timely strategies to avoid desertion and failure. One of the biggest challenges to predicting student performance is presented in the course “Programming Fundamentals” of Computer Science, Software Engineering, and Information Systems Engineering careers in Peruvian universities for high student dropout rates. The objective of this research was to explore the efficiency of Long-Short Term Memory Networks (LSTM) in the field of Educational Data Mining (EDM) to predict the academic performance of students during the seventh, eighth, twelfth, and sixteenth weeks of the academic semester, which allowed us to identify students at risk of failing the course. This research compares several predictive models, such as Deep Neural Network (DNN), Decision Tree (DT), Random Forest (RF), Logistic Regression (LR), Support Vector Classifier (SVM), and K-Nearest Neighbor (KNN). A major challenge machine learning algorithms face is a class imbalance in a dataset, resulting in over-fitting to the available data and, consequently, low accuracy. We use Generative Adversarial Networks (GAN) and Synthetic Minority Over-sampling Technique (SMOTE) to balance the data needed in our proposal. From the experimental results based on accuracy, precision, recall, and F1-Score, the superiority of our model is verified concerning a better classification, with 98.3% accuracy in week 8 using LSTM-GAN, followed by DNN-GAN with 98.1% accuracy.},
  keywords={Predictive models;Radio frequency;Prediction algorithms;Machine learning algorithms;Static VAr compensators;Classification algorithms;Data mining;Educational data mining;generative adversarial networks;long-short term memory;synthetic minority over-sampling technique},
  doi={10.1109/ACCESS.2024.3350169},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10837600,
  author={Mormul, Yevhenii and Przybyszewski, Jan and Siriburanon, Teerachot and Healy, John and Cuffe, Paul},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Gauging the Capability of Artificial Intelligence Chatbot Tools to Answer Textbook Coursework Exercises in Circuit Design Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Powerful chatbots, based on intensively-trained large language models, have recently become available for consumer use. The ability of such chatbots to provide credible textual responses to sophisticated engineering problems has been demonstrated in various subfields. This paper seeks to gauge the extent to which such a chatbot can be prompted to complete a set of homework and project exercises for university-level courses in analog, digital, mixed -signal, and signal processing classes. The purpose of this paper is to delineate and clearly articulate the present capabilities of artificial intelligence tools to complete coursework taks across the field of circuit theory. Building on these research findings, this paper suggests practical ways to mitigate artifical intelligence chatbot tools' disription to academic integrity and genuine learning in universities.},
  keywords={Training;Large language models;Buildings;Signal processing;Chatbots;Circuit synthesis;Information technology;Standards;Circuit theory},
  doi={10.1109/ITHET61869.2024.10837600},
  ISSN={2473-2060},
  month={Nov},}
@INPROCEEDINGS{10401818,
  author={Yousri, Ramez and Safwat, Soha},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={How Big Can It Get? A comparative analysis of LLMs in architecture and scaling}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Large Language models (LLMs) are increasingly becoming an integral part of our society. They play important roles in education, marketing and healthcare. These models exhibit emergent behavior when scaled, however such scaling might have its disadvantages as well. As a way to combat such disadvantages, new architectures and types of models have been designed. In this paper, we show the different architectural decisions when it comes to building LLMs as well as discuss how big a model needs to be in order to be specialized in a certain area or sector. We show that most specialized models are small in size yet outperform larger models in specific domain tasks.},
  keywords={Analytical models;Computational modeling;Computer architecture;Medical services;Transformers;Data models;Task analysis;Large language models;Transformers;NLP;Specialized models;LLM size},
  doi={10.1109/ICCA59364.2023.10401818},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{11016366,
  author={Mohammed, Crista and Sarjusingh, Wayne and Rocke, Sean},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Uses of Generative AI in Engineering, Technology, and Computing Classrooms: Findings From the IEEE FIE Conference Proceedings}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={Generative AI (GAI) can be leveraged to good effect in engineering, technology, and computing (ETC) classrooms but with pre-conditions; among these include teacher preparedness. One dimension of teacher preparedness is knowing how GAI is used in classrooms like their own. This paper responds to that need. The paper surveys the literature to answer three questions: in formal instructional interventions, what were the tasks for which GAI was used; what methods did scholars use to evaluate the GAI instructional set; and what were some of the identified challenges and opportunities regarding the use of GAI in ETC classrooms? Taking account of quality and recency of scholarship, and the need to focus on ETC practices, a rapid review of IEEE FIE conference proceedings for 2023 and 2024 was undertaken. Of the 1,181 papers published in both conference proceedings, and after a two-stage screening process, 20 papers were selected for synthesis. Of the 20 papers examined in this review, we found seven patterns of research design. The most common was the learning and teaching intervention followed by gathering student feedback. While we expect that a bigger corpus will yield additional research designs, these seven provide a start for defining a typology of research design investigating student use of GAI. The review revealed eight distinct categories of use ranging from software development, the most common, with over 26 distinct tasks, to data classification and data analysis, each with two distinct tasks. GAI was found to be used for many low-cognitive tasks like generating bibliographies to cognitivelydemanding uses like design and modeling. The studies reported recurring concerns about using GAI, like perpetuating bias, and hallucinations. One striking empirical finding is that previous ways of accomplishing ETC tasks, like using MATLAB and hand analysis, may be quicker and easier than using GAI. The scholarship advocates for broad and deep GAI literacy programs, addressing GAI abilities, limitations, ethics of use, and prompt design. Moreover, instructors are encouraged to be GAI literate themselves. This know-how is central to designing meaningful GAI-based tasks which seek to prepare students for an increasingly AI-infused world and workplace.},
  keywords={Surveys;Hands;Ethics;Reviews;Generative AI;Scholarships;Employment;Engineering education;MATLAB;Software development management;engineering education;engineering;technology and computing education;generative AI},
  doi={10.1109/EDUCON62633.2025.11016366},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10661085,
  author={Williams, Randi and Ali, Safinah and Alcantara, Raúl and Burghleh, Tasneem and Alghowinem, Sharifa and Breazeal, Cynthia},
  booktitle={2024 19th ACM/IEEE International Conference on Human-Robot Interaction (HRI)}, 
  title={Doodlebot: An Educational Robot for Creativity and AI Literacy}, 
  year={2024},
  volume={},
  number={},
  pages={772-780},
  abstract={Today, Artificial Intelligence (AI) is prevalent in everyday life, with emerging technologies like AI companions, autonomous vehicles, and AI art tools poised to significantly transform the future. The development of AI curricula that shows people how AI works and what they can do with it is a powerful way to prepare everyone, and especially young learners, for an increasingly AI-driven world. Educators often employ robotic toolkits in the classroom to boost engagement and learning. However, these platforms are generally unsuitable for young learners and learners without programming expertise. Moreover, these platforms often serve as either programmable artifacts or pedagogical agents, rarely capitalizing on the opportunity to support students in both capacities. We designed Doodlebot, a mobile social robot for hands-on AI education to address these gaps. Doodlebot is an effective tool for exploring AI with grade school (K-12) students, promoting their understanding of AI concepts such as perception, representation, reasoning and generation. We begin by elaborating Doodlebot’s design, highlighting its reliability, user-friendliness, and versatility. Then, we demonstrate Doodlebot’s versatility through example curricula about AI character design, autonomous robotics, and generative AI accessible to young learners. Finally, we share the results of a preliminary user study with elementary school youth where we found that the physical Doodlebot platform was as effective and user-friendly as the virtual version. This work offers insights into designing interactive educational robots that can inform future AI curricula and tools.CCS CONCEPTS• Human-centered computing → Collaborative and social computing devices.},
  keywords={Social computing;Educational robots;Statistical analysis;Social robots;Prototypes;Transforms;Reliability engineering;Social robots;education;creativity;collaboration},
  doi={},
  ISSN={2167-2121},
  month={March},}@ARTICLE{10991962,
  author={Xue, Mingfu and Chen, Kewei and Zhang, Leo Yu and Zhang, Yushu and Liu, Weiqiang},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={An Active Authorization Control Method for Deep Reinforcement Learning Model Based on GANs and Adaptive Trigger}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In recent years, deep reinforcement learning (DRL) has found widespread applications across diverse scenarios. Since the DRL training process requires substantial time and financial costs, well-trained DRL policies should be considered as intellectual property (IP) which deserves proper protection. However, to date, there are only a few studies on IP protection on DRL and the existing methods are limited to passive copyright verification. In this paper, we propose the first active authorization control method for DRL which can proactively protect deep reinforcement learning policy. The DRL policy trained with this method can be used by authorized users normally, but cannot be used by unauthorized users (i.e., the protected policy’s performance for unauthorized users is paralyzed). Specifically, we train a trigger injection network and a discriminator network based on generative adversarial networks (GANs). During the DRL policy training phase, we use trigger injection network to insert sample-specific triggers to all observations and use triggered observations to train the protected policy. Our approach is applicable across various deep reinforcement learning algorithms. We conduct effectiveness experiments on different DRL policies trained using different DRL algorithms, and the experimental results revealed that the performance of authorized users is on par with the performance of clean DRL policy trained normally (baseline), whereas the performance of unauthorized users significantly deviates from that of the baseline. Specifically, the authorized performance of protected Breakout-DQN, Breakout-A2C, MsPacman-DQN and MsPacman-A2C policies are 416.4 (baseline 397.8), 403.0 (baseline 415.0), 2552.0 (baseline 2472.0), and 1964.0 (baseline 1828.0). Comparatively, the unauthorized performance of protected Breakout-DQN, Breakout-A2C, MsPacman-DQN and MsPacman-A2C policies are only 4.4 (baseline 397.8), 2.0 (baseline 415.0), 74.0 (baseline 2472.0), and 514.0 (baseline 1828.0). Furthermore, the experiments demonstrate that the proposed method exhibits robustness against pruning, fine-tuning, and adaptive attacks.},
  keywords={Watermarking;Authorization;Deep reinforcement learning;Training;Protection;Intellectual property;Approximation algorithms;Data mining;Autoencoders;Robustness;Trustworthy Artificial Intelligence;deep reinforcement learning;intellectual property protection;active authorization control;backdoor attack},
  doi={10.1109/TIFS.2025.3567915},
  ISSN={1556-6021},
  month={},}@INPROCEEDINGS{11016386,
  author={Johri, Aditya and Schleiss, Johannes and Ranade, Nupoor},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Lessons for GenAI Literacy from a Field Study of Human-GenAI Augmentation in the Workplace}, 
  year={2025},
  volume={},
  number={},
  pages={1-9},
  abstract={Generative artificial intelligence (GenAI) is increasingly becoming a part of work practices across the technology industry and being used across a range of industries. This has necessitated the need to better understand how GenAI is being used by professionals in the field so that we can better prepare students for the workforce. An improved understanding of the use of GenAI in practice can help provide guidance on the design of GenAI literacy efforts including how to integrate it within courses and curriculum, what aspects of GenAI to teach, and even how to teach it. This paper presents a field study that compares the use of GenAI across three different functions - product development, software engineering, and digital content creation - to identify how GenAI is currently being used in the industry. This study takes a human augmentation approach with a focus on human cognition and addresses three research questions: how is GenAI augmenting work practices; what knowledge is important and how are workers learning; and what are the implications for training the future workforce. Findings show a wide variance in the use of GenAI and in the level of computing knowledge of users. In some industries GenAI is being used in a highly technical manner with deployment of fine-tuned models across domains. Whereas in others, only off-the-shelf applications are being used for generating content. This means that the need for what to know about GenAI varies, and so does the background knowledge needed to utilize it. For the purposes of teaching and learning, our findings indicated that different levels of GenAI understanding needs to be integrated into courses. From a faculty perspective, the work has implications for training faculty so that they are aware of the advances and how students are possibly, as early adopters, already using GenAI to augment their learning practices.},
  keywords={Industries;Training;Generative AI;Employment;Learning (artificial intelligence);Intellectual property;Human augmentation;Product development;Engineering education;Software engineering;generative artificial intelligence;engineering education;computing education;AI literacy;workplace studies},
  doi={10.1109/EDUCON62633.2025.11016386},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10406630,
  author={Chu, R. and Lim, S. C. Johnson},
  booktitle={2023 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)}, 
  title={Education and Training for Future Engineering Teachers in the Age of Artificial Intelligence: A Bibliometric Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={416-420},
  abstract={Engineering teachers play an important role in engineering education to develop the next generation of engineering human resources. In this sense, the education and training of engineering teachers are important. The recent development of artificial intelligence (AI), especially generative AI, has impacted many industries, including education. Thus, this paper aimed to explore existing research focuses and trends in the field of education and training of future engineering teachers in the age of artificial intelligence (AI). Based on scholarly publications obtained between the years 2018 and 2023, a bibliometric analysis has been performed, which includes analysis such as keyword co-occurrence analysis and thematic-based content analysis. The analysis in this paper is performed using bibliometric software named VOSViewer. The results from the analysis have identified five research hotspots in this field based on keyword clustering, with each hotspot discussed. Finally, this paper concludes with some elaborations on limitations and future work.},
  keywords={Training;Bibliometrics;Market research;Software;Artificial intelligence;Engineering education;Next generation networking;Artificial intelligence;education;training;engineering teachers;bibliometric analysis},
  doi={10.1109/IEEM58616.2023.10406630},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605444,
  author={Gao, Bo and Wei, Qingsong and Liu, Yong and Goh, Rick Siow Mong},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Unveiling the Potential of ChatGPT in Detecting Machine Unauditable Bugs in Smart Contracts: A Preliminary Evaluation and Categorization}, 
  year={2024},
  volume={},
  number={},
  pages={1481-1486},
  abstract={Smart contracts are becoming an integral part of decentralized applications, yet exploitable bugs in these contracts pose significant threats, often leading to considerable monetary losses. Traditional tools often struggle to identify these bugs, with a recent study indicating that 80% of them are classified as Machine Unauditable Bugs (MUBs), rendering conventional approaches ineffective in addressing such cases. In practice, identifying MUBs requires seasoned expertise and is time-intensive, often stalling project progress. In this work, we present a preliminary evaluation of the performance of ChatGPT, a state-of-the-art large language model, especially in detecting MUBs. Our study first investigates the effectiveness and limitations of ChatGPT in detecting various categories of MUBs with two kinds of prompts, general prompts and guidance prompts, on 246 real-world MUBs collected from Code4rena between 2021 and 2022. Subsequently, we compared the leading tool, SPCON, with ChatGPT on 17 CVE contracts with access control issues (a category of MUBs), and found that ChatGPT exhibited comparable performance but better usability over SPCON. We summarize the implications of our findings for the broader community, shedding light on the model’s capabilities, limitations and potentials in detecting smart contract bugs. Our evaluation dataset and results are released at Github1.},
  keywords={Access control;Large language models;Computer bugs;Smart contracts;Chatbots;Rendering (computer graphics);Decentralized applications;ChatGPT;Exploitable bugs;Effortless usage},
  doi={10.1109/CAI59869.2024.00266},
  ISSN={},
  month={June},}@INPROCEEDINGS{10429948,
  author={Kumar, Yulia and Gordon, Zachary and Morreale, Patricia and Li, J. Jenny and Hannon, Brendan},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)}, 
  title={Love the Way You Lie: Unmasking the Deceptions of LLMs}, 
  year={2023},
  volume={},
  number={},
  pages={875-876},
  abstract={Within the dynamic realm of Artificial Intelligence (AI), models like ChatGPT, Bard, and Bing are renowned for replicating human language. However, their emergence sparks debate over biases and trustworthiness. This research delves into the predominant inaccuracies in chatbots that tend to mislead novices and explores the possibility of establishing an AI Reliability (AIR) framework to fortify trust in these entities. Errors are categorized as factual inaccuracies, misinformation, fabricated data, and deviations from topics, among others. The in-progress AIR Framework offers a meticulous approach to assess chatbot accuracy, leveraging the experiences of nearly 100 CS/IT students with mainly ChatGPT. Recognizing the limitations and hallucinations of these models is essential as they become integral to our lives, underscoring the imperative for responsible and reliable AI.},
  keywords={Atmospheric modeling;Software quality;Chatbots;Software reliability;Sparks;Security;Artificial intelligence;Large Language Models (LLMs);AI Reliability (AIR) Framework;AI bias;AI Misinformation;Ethics of AI},
  doi={10.1109/QRS-C60940.2023.00049},
  ISSN={2693-9371},
  month={Oct},}@INPROCEEDINGS{10725418,
  author={De Silva, D. I. and Athukorala, K. S. N.},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Sinhala-Centric Java Assistance Tool for Entry-Level Programmers}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Programming plays a significant role in computer science and information technology. For example, novice programmers often find it challenging to use the Java programming language due to language barriers. Creating a learning environment that considers the linguistic needs of students can be highly beneficial. By adapting our teaching practices to accommodate different types of learners, we can improve performance. Therefore, this study suggests methods for learning programming using Sinhala as the medium of instruction. Azure Translator is integrated to translate Sinhala questions into English and provide Sinhala explanations, enabling users to receive Java code customized to their specific needs. The system uses ChatGPT 4 integration to generate code. Additionally, the system can transform English code explanations into Sinhala, giving learners access to instructional material whenever they need it. The created tool explains programming principles, logic, and syntax in both Sinhala and English for Java code segments in a simple, concise, and thorough manner. Furthermore, the Java-based Sinhala assistance tool offers explanations of essential Java programming concepts in Sinhala, ensuring comprehensive coverage of both basic and more complex topics. After entering a question in Sinhala, the system displays the relevant Java code along with explanations in Sinhala.},
  keywords={Java;Codes;Transforms;Programming;Syntactics;Linguistics;Chatbots;Logic;Information technology;Faces;Sinhala;Java;assistance tool;entry-level;programmers},
  doi={10.1109/ICCCNT61001.2024.10725418},
  ISSN={2473-7674},
  month={June},}@INPROCEEDINGS{10350777,
  author={Morales, Sergio and Planas, Elena and Clarisó, Robert and Gogolla, Martin},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Generative AI in Model-Driven Software Engineering Education: Friend or Foe?}, 
  year={2023},
  volume={},
  number={},
  pages={110-113},
  abstract={The availability and effectiveness of generative AI tools challenge the currently established methods for learning, teaching and assessment. In this paper, we discuss their potential impact for model-driven software engineering education, both from the point of view of educators and students. The discussion highlights several opportunities and risks, which support the need of a critical perspective in the application of these tools.},
  keywords={Learning systems;Adaptation models;Plagiarism;Education;Data models;Software;Reproducibility of results;Generative AI;education;software engineering;model-driven software engineering;modeling},
  doi={10.1109/MODELS-C59198.2023.00034},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10893133,
  author={Axelsson, Andreas and Wallgren, Daniel Tomas and Verma, Udit and Cajander, Åsa and Daniels, Mats and Eckerdal, Anna and McDermott, Roger},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={From Assistance to Misconduct: Unpacking the Complex Role of Generative AI in Student Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This research-to-practice full paper discusses students' views on the role of generative artificial intelligence (GenAI) in their learning. The rapid integration of GenAI in educational settings has prompted significant interest in its implications for learning and academic integrity. This study investigates the adoption and impact of GenAI tools among computing students at a university, focusing on how they are utilized for educational purposes and their ethical implications. Semi-structured interviews with nine computing students were used to examine GenAI's specific use and timing. Additionally, it explores students' perceptions of the trustworthiness of GenAI outputs and identifies the students' ethical boundaries concerning its use in academic work. The findings reveal that while GenAI tools might enhance learning efficiency and provide substantial educational support, they raise significant ethical concerns, particularly regarding academic misconduct. The study highlights the need for educational strategies to navigate the challenges posed by GenAI technologies. Finally, three recommendations for computing education are outlined. This research contributes to the ongoing discourse on GenAI in education by describing the student's reflections on GenAI.},
  keywords={Ethics;Generative AI;Navigation;Education;Focusing;Learning (artificial intelligence);Debugging;Reflection;Timing;Interviews;Generative AI;Student learning;Cheating;Motivation;Misconduct},
  doi={10.1109/FIE61694.2024.10893133},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10578858,
  author={Lehmann, Alexander and Landes, Dieter},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Extracting Metadata from Learning Videos for Ontology-Based Recommender Systems Using Whisper & GPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In modern education, individualized learning environments play a vital role by allowing learners to tailor their learning paths based on personal needs, interests, and abilities. Achieving effective individualization relies on dynamic adaptation of the learning path, typically facilitated by recommender systems. These systems offer personalized suggestions, commonly employing content-based or collaborative filtering approaches. However, traditional recommender systems often lack consideration of the semantics of learning elements. To address this limitation, ontology-based recommender systems integrate semantic modeling, establishing additional connections within a domain to enhance precision and context in recommendations. Notably, these systems mitigate the cold start problem and are particularly advantageous in learning environments with limited data. While videos are prevalent in learning platforms, their unstructured nature poses challenges for processing. This paper introduces an innovative approach, leveraging Large Language Models, specifically GPT, to extract metadata from learning videos. The proposed method intelligently augments videos and links them to a domain ontology, enabling the integration of videos into ontology-based recommender systems. The application of this approach is demonstrated through a case study in software engineering education, showcasing its potential to enhance individualized learning experiences in specific domains. The presented method offers an automated alternative to manual video processing, aligning with the evolving landscape of education technology.},
  keywords={Large language models;Semantics;Manuals;Metadata;Ontologies;Engineering education;Recommender systems;learning analytics;adaptive learning environments;generative AI;large language models;ontology-based recommender systems;learning videos},
  doi={10.1109/EDUCON60312.2024.10578858},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10837616,
  author={Sterbini, Andrea and Temperini, Marco},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Open-Source or Proprietary Language Models? An Initial Comparison on the Assessment of an Educational Task}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Open-source Small and medium Language Models (SLMs) are becoming more and more available, and allow researchers to fine tune and explore their application with more freedom than the proprietary ones. We compare the performances of many recent SLMs with two proprietary models from OpenAI, on two didactic tasks regarding the automatic assessment of algorithm descriptions submitted for an under-graduate course, involving training on Computer Programming. In particular, as the submission is part of a formative peer-assessment workflow, where peers grade three descriptions each, and suggest improvements, we are interested in two tasks: a) discriminating non-algorithms descriptions from algorithm descriptions, and b) grading the clearness of the submitted descriptions (which is related to an effective usefulness during peer-assessment). We see that the tasks are solved with varied performances by the tested Models, and that a proprietary Model can be leader on a task, whereas some SLMs are better at the other task. Then we also show some strategies, to improve the grading/classifying performances. The development of Language Models that are Open Source, Open trained, and overall smaller than the available proprietary ones, is currently at an early stage: nonetheless a conclusion can be that these systems may already have their say, when compared with large, proprietary Language Models.},
  keywords={Training;Computational modeling;Programming;Information technology;Technology Enhanced Learning;Peer Assessment;Automated Assessment;Algorithm Description Quality;Natural language processing;Transformer-based Large and Small Language Models;Open-Source Language Models},
  doi={10.1109/ITHET61869.2024.10837616},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{11016326,
  author={Lenke, Michael and Schulte, Carsten},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Enhancing AI Interaction through Co-Construction: A Multi-Faceted Workshop Framework}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={The boom of research topics such as AI literacy and explainable AI (XAI) intensified political discussions about the right for meaningful explanations of the logic involved leave no doubt about the necessity of AI education. However, technologies that we find in our every lives often hide architectural aspects to make their benefits accessible for everyone. Additionally, performance seems to trade-off for explainability, leading to a black-box system not understandable for users and sometimes even experts. To address this issue this paper introduces a workshop framework designed to enhance interactions with large language models (LLMs) - in particular ChatGPT. With emphasis on observation, analysis and hands-on interaction, the workshop framework pursues three different goals: (1) as an event for scientific research, (2) as a learning event and (3) as science communication work to integrate the public more closely into research. Pre-post-test data suggests a shift in participants' interaction patterns when using ChatGPT. Participants not only questioned the AI's responses but also reflected on their own understanding, asking follow-up questions or offering suggestions on how to better explain concepts to the AI.},
  keywords={Explainable AI;Conferences;Large language models;Closed box;Games;Chatbots;Logic;Engineering education;Monitoring;Testing},
  doi={10.1109/EDUCON62633.2025.11016326},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10187129,
  author={Revanesh, M. and Rudra, Bhawana and Guddeti, Ram Mohana Reddy},
  journal={IEEE Access}, 
  title={An Optimized Question Classification Framework Using Dual-Channel Capsule Generative Adversarial Network and Atomic Orbital Search Algorithm}, 
  year={2023},
  volume={11},
  number={},
  pages={75736-75747},
  abstract={The advancement in education has emphasized the need to evaluate the quality of the examination questions and the cognitive levels of students. Many educational institutions now acknowledge Bloom’s taxonomy-based students’ cognitive levels evaluating subject-related learning. Therefore, in this paper, a novel optimized Examination Question Classification framework, referred to as QC-DcCapsGAN-AOSA, is proposed by combining the Dual-channel Capsule generative Adversarial Network (DcCapsGAN) with Atomic Orbital Search Algorithm (AOSA) for preprocessing a real-time online dataset of university examination questions, thus identify the key features from the raw data using Term Frequency Inverse Document Frequency (TF-IDF) and finally classifying the examination questions. Atomic Orbital Search Algorithm is used to fine-tune the parameters’ weights of the DcCapsGAN, and then uses these weights to categorize questions as Knowledge Level, Comprehension Level, Application Level, Analysis Level, Synthesis Level, and Evaluation Level. Experimental results demonstrate the superiority of the proposed method (QC-DcCapsGAN-AOSA) when compared to the state-of-the-art methods such as QC-LSTM-CNN and QC-BiGRU-CNN with an accuracy improvement of 23.65% and 29.04%, respectively.},
  keywords={Feature extraction;Generative adversarial networks;Taxonomy;Artificial intelligence;Classification algorithms;Visualization;Electronic learning;Testing;Atomic orbital search algorithm (AOSA);dual-channel capsule generative adversarial network (DcCapsGAN);online examination question classification;term frequency-inverse document frequency (TF-IDF)},
  doi={10.1109/ACCESS.2023.3296911},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10975838,
  author={Guoan, Zhao and Mengting, Pan and Shaobo, Wang},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Exploring Educators' Multidimensional Perspectives on Generative AI's Impact in Education: A Study Using Q Methodology}, 
  year={2025},
  volume={},
  number={},
  pages={350-355},
  abstract={The rapid development of generative AI has attracted significant attention in education. This study uses Q methodology to explore educators' views on AI's impact across five key dimensions: educational theory, learning outcomes, educational technology, educational ethics, and pedagogy. The analysis identifies three educator groups: (1) Education Stalwarts Emphasizing Humanistic Care (F1), who prioritize values like critical thinking, self-motivation, and social responsibility; (2) Education Reformers Advocating Technological Integration (F2), who support AI-driven innovations; and (3) Education Explorers Focused on Learning Experiences (F3), who emphasize personalized, technology-enhanced learning. Although perspectives on AI integration vary, there is agreement that education should promote human progress and personal growth. This study contributes to the ongoing discourse by advocating for a balanced approach that integrates tradition with innovation to enhance educational outcomes.},
  keywords={Technological innovation;Ethics;Generative AI;Collaboration;Educational technology;Information technology;Q methodology;generative AI;educators' perspectives;educational impact},
  doi={10.1109/ICEIT64364.2025.10975838},
  ISSN={},
  month={March},}@INPROCEEDINGS{10864428,
  author={Khennouche, Feriel and Elmir, Youssef and Djebari, Nabil and Boubchir, Larbi and Laouid, Abdelkader and Bounceur, Ahcene},
  booktitle={2024 International Conference on Computational Intelligence and Network Systems (CINS)}, 
  title={Comparative Analysis and Application of Large Language Models on FAQ Chatbots}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents a comprehensive evaluation of advanced large language models (LLMs) including GPT, BART, BERT, and T5, fine-tuned using a specialized FAQ dataset from ESTIN, a higher education institution. The study aims to assess the performance of these LLM models in generating accurate and contextually relevant responses to common queries. These models were evaluated using key metrics such as evaluation loss (eval loss) and ROUGE scores (ROUGE-1 and ROUGE-2), which measure the alignment between the generated responses and the reference answers. The experiment results show that BERT outperforms the other models, achieving a lowest eval loss and highest ROUGE-1 and ROUGE-2 scores, making it the most effective model in this context. The findings underscore the potential of BERT in educational AI applications. Finally, some future research directions are discussed, including the integration of additional models and the enhancement of the FAQ dataset to further improve performance.},
  keywords={Analytical models;Accuracy;Reviews;Large language models;Education;Loss measurement;Question answering (information retrieval);Computational intelligence;Context modeling;Network systems;LLM;fine-tunning;FAQ Chatbot;GPT;BART;T5;BERT},
  doi={10.1109/CINS63881.2024.10864428},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10610554,
  author={Macaluso, Annabella and Cote, Nicholas and Chitta, Sachin},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)}, 
  title={Toward Automated Programming for Robotic Assembly Using ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={17687-17693},
  abstract={Despite significant technological advancements, the process of programming robots for adaptive assembly remains labor-intensive, demanding expertise in multiple domains and often resulting in task-specific, inflexible code. This work explores the potential of Large Language Models (LLMs), like ChatGPT, to automate this process, leveraging their ability to understand natural language instructions, generalize examples to new tasks, and write code. In this paper, we suggest how these abilities can be harnessed and applied to real-world challenges in the manufacturing industry. We present a novel system that uses ChatGPT to automate the process of programming robots for adaptive assembly by decomposing complex tasks into simpler subtasks, generating robot control code, executing the code in a simulated workcell, and debugging syntax and control errors, such as collisions. We outline the architecture of this system and strategies for task decomposition and code generation. Finally, we demonstrate how our system can autonomously program robots for various assembly tasks in a real-world project.},
  keywords={Robotic assembly;Codes;Debugging;Chatbots;Encoding;Cognition;Task analysis},
  doi={10.1109/ICRA57147.2024.10610554},
  ISSN={},
  month={May},}@INPROCEEDINGS{10438742,
  author={Wei, Shuohuan and Luo, Yong and Chen, Shuoqi and Huang, Tingting and Xiang, Yixue},
  booktitle={2023 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC)}, 
  title={Deep research and analysis of ChatGPT based on multiple testing experiments}, 
  year={2023},
  volume={},
  number={},
  pages={123-131},
  abstract={The intelligent chat robots, represented by ChatGPT, are rapidly entering the daily learning and life of college students and gradually playing an extremely important role. In this situation, how to explore the role of intelligent chat robots for college students, while exploring the advantages and disadvantages of ChatGPT, guiding college students to actively and effectively use this tool, and leveraging the application value of chat robots in talent cultivation has become a very urgent task at present. On this basis, through case studies, experimental analysis, testing experiments, and other methods, the role and value of ChatGPT are studied and explored, providing reference suggestions for talent cultivation models of college students, and promoting the healthy and rapid development of smart education in universities.},
  keywords={Educational technology;Chatbots;Knowledge discovery;Task analysis;Distributed computing;Robots;Testing;ChatGPT;intelligent chat robot;test experiment;wisdom education},
  doi={10.1109/CyberC58899.2023.00030},
  ISSN={2833-8898},
  month={Nov},}@INPROCEEDINGS{10555858,
  author={Das, Joy Krishan and Mondal, Saikat and Roy, Chanchal K.},
  booktitle={2024 IEEE/ACM 21st International Conference on Mining Software Repositories (MSR)}, 
  title={Investigating the Utility of ChatGPT in the Issue Tracking System: An Exploratory Study}, 
  year={2024},
  volume={},
  number={},
  pages={217-221},
  abstract={Issue tracking systems serve as the primary tool for incorporating external users and customizing a software project to meet the users’ requirements. However, the limited number of contributors and the challenge of identifying the best approach for each issue often impede effective resolution. Recently, an increasing number of developers are turning to AI tools like ChatGPT to enhance problem-solving efficiency. While previous studies have demonstrated the potential of ChatGPT in areas such as automatic program repair, debugging, and code generation, there is a lack of study on how developers explicitly utilize ChatGPT to resolve issues in their tracking system. Hence, this study aims to examine the interaction between ChatGPT and developers to analyze their prevalent activities and provide a resolution. In addition, we assess the code reliability by confirming if the code produced by ChatGPT was integrated into the project’s codebase using the clone detection tool NiCad. Our investigation reveals that developers mainly use ChatGPT for brainstorming solutions but often opt to write their code instead of using ChatGPT-generated code, possibly due to concerns over the generation of "hallucinated" code, as highlighted in the literature.},
  keywords={Codes;Cloning;Debugging;Maintenance engineering;Chatbots;Turning;Software;ChatGPT;Issue Tracking;NiCad;Code Clone},
  doi={},
  ISSN={2574-3864},
  month={April},}@INPROCEEDINGS{10554763,
  author={Saǧlam, Timur and Hahner, Sebastian and Schmid, Larissa and Burger, Erik},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: Software Engineering Education and Training (ICSE-SEET)}, 
  title={Automated Detection of AI-Obfuscated Plagiarism in Modeling Assignments}, 
  year={2024},
  volume={},
  number={},
  pages={297-308},
  abstract={Plagiarism is a widespread problem in computer science education, exacerbated by the impracticability of manual inspection in large courses. Even worse, tools based on large language models like ChatGPT have made it easier than ever to obfuscate plagiarized so-lutions. Additionally, most plagiarism detectors only apply to code, and only a few approaches exist for modeling assignments, which lack broad resilience to obfuscation attacks. This paper presents a novel approach for automated plagiarism detection in modeling assignments that combines automated analysis with human inspection. We evaluate our approach with real-world assignments and plagiarism obfuscated by ChatGPT. Our results show that we achieve a significantly higher detection rate for AI-generated attacks and a broader resilience than the state-of-the-art.},
  keywords={Training;Plagiarism;Computational modeling;Inspection;Chatbots;Tokenization;Computer science education;Plagiarism Detection;Obfuscation;ChatGPT;Artificial Intelligence},
  doi={10.1145/3639474.3640084},
  ISSN={2832-7578},
  month={April},}@INPROCEEDINGS{11015358,
  author={Bui, Nguyen Tuan Anh and Nguyen, Linh and Nguyen, Ngoc Dang Khoa and Hoang, Cuong Chi},
  booktitle={2024 International Conference on Logistics and Industrial Engineering (ICLIE)}, 
  title={Generative AI-driven Digital Transformation in Education: Systematic Review and Future Research Directions}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Generative artificial intelligence (AI) has emerged as a transformative force in multiple disciplines, particularly in education amidst the post-COVID-19 era. The systematic review synthesizes findings from 59 peer-reviewed articles published from 2014 to 2024. Through a rigorous analysis, we delve into several benefits and challenges associated with Generative AI-driven digital transformation in education. Notably, Generative AI offers numerous benefits for educational institutions such as tailored learning experiences, improved student engagement, cost-effective learning solutions and so forth. Nevertheless, reaping such benefits often necessitates grappling with challenges, including technological intricacies, ethical consideration and pedagogical implications. These findings gleaned from this review serve as an invaluable resource for researchers and practitioners seeking to harness Generative AI’s potential to optimize teaching and learning performance. Such a review also lays a robust foundation for future research endeavors, paving the way for continued advancements in this domain.},
  keywords={Ethics;Generative AI;Digital transformation;Education;Force;Industrial engineering;Systematic literature review;Logistics;Generative AI;education sector;digital transformation;systematic literature review},
  doi={10.1109/ICLIE61478.2024.11015358},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10959667,
  author={Muhamad, Gilang Aulia and Alsulami, Bassma Saleh and Thabit, Khalid Omar},
  booktitle={2025 2nd International Conference on Advanced Innovations in Smart Cities (ICAISC)}, 
  title={Innovating NCAAA Accreditation: A Smart Education Management System Powered by Generative Pre-trained Transformer}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces a smart education management system designed to enhance the accreditation processes mandated by the National Commission for Academic Accreditation & Assessment (NCAAA) for postgraduate programs. By leveraging Generative Pre-trained Transformer (GPT) models, the system efficiently generates comprehensive course reports and dynamic assessment questions, aligning them with the cognitive levels defined in Bloom's Taxonomy. Automating these critical but labor-intensive tasks significantly improves the efficiency of accreditation processes in academic settings. Initial testing within the Computer Science Department at King Abdulaziz University (KAU) demonstrated the system's robustness and scalability, indicating its potential for broader application across universities. The integration of Artificial Intelligence (AI) not only streamlines administrative processes but also improves the quality of educational assessments through alignment with Bloom's Taxonomy. This study emphasizes the transformative potential of AI in educational accreditation, setting a new benchmark for future research and development in integrating AI technologies for smart education management systems.},
  keywords={Technological innovation;Smart cities;Scalability;Taxonomy;Educational technology;Benchmark testing;Transformers;Accreditation;Artificial intelligence;Standards;smart education;accreditation;generative pre-trained transformer},
  doi={10.1109/ICAISC64594.2025.10959667},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{11005250,
  author={Alaswad, Sara and Kalganova, Tatiana and Awad, Wasan},
  booktitle={2024 International Conference on IT Innovation and Knowledge Discovery (ITIKD)}, 
  title={Developing a Framework for Using Large Language Models for Viva Assessments in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents a comprehensive framework for evaluating Large Language Models (LLMs) based on educational performance areas and established evaluation metrics. The study bridges the gap between traditional academic assessment criteria and modern AI evaluation techniques, aligning metrics such as coherence, relevance, completeness, and creativity with performance areas like problem definition, methodology, and product outcomes. Drawing insights from experimental results, the framework highlights the top 10 evaluation metrics frequently observed and emphasizes their significance in assessing AI -generated responses. A critical analysis identifies limitations in the initial framework proposed by ChatGPT, leading to refined strategies for more comprehensive evaluation. The refined framework addresses limitations of subjectivity, overlapping criteria, and weighting mechanisms, offering a dynamic evaluation model for both technical and educational contexts. The findings contribute to advancing interdisciplinary evaluation methodologies and offer valuable insights for educators, researchers, and developers in optimizing LLM applications for educational purposes.},
  keywords={Measurement;Technological innovation;Feedback loop;Large language models;Education;Evaluation models;Chatbots;Knowledge discovery;Real-time systems;Creativity;LLM;higher education;VIVA;academic assessment;evaluation metrics;ChatGPT},
  doi={10.1109/ITIKD63574.2025.11005250},
  ISSN={},
  month={April},}@INPROCEEDINGS{11016452,
  author={Brändle, Marcus and Bahr, Tobias and Arnold, Jonas Benedikt and Zinn, Bernd},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Comparative Study of Epistemological Beliefs and AI Chatbot Usage Among Early Adopters and Later Users in Higher Education}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={With the increasing integration of artificial intelligence in education, the relationship between students' learning strategies and their engagement with AI chatbots are of interest. This exploratory study examines the relationships between learning strategies, epistemological beliefs, and motivational orientations concerning AI chatbot usage, as well as the actual usage patterns among students, which has been identified as a research gap. Some studies show that especially India has a high usage of ChatGPT and other countries e. g. Germany how low usage rates. Thus, we operationalized Indian student as so-called early adopters and German students as later users to compare the two subgroups. The study consists of $\mathbf{N = 1 3 5}$ students from various disciplines across multiple German universities ($\mathrm{n}=91$; later users) and an Indian university ($\mathrm{n}=44$; early adopters). The findings indicate that students in subgroup 2 (Indian students) can be considered early adopters, utilizing AI chatbots more frequently and exhibiting less elaborated epistemological beliefs compared to later users. Early adopters perceive AI chatbots as a comprehensive source of knowledge. In contrast, later users reported less frequent use of AI chatbots. While no significant correlation was found between epistemological beliefs and learning strategies in relation to students' usage frequency, the differences in epistemological beliefs between the two subgroups suggest that frequent use of AI chatbots could potentially decrease students' epistemological sophistication and thus impact their learning strategies.},
  keywords={Correlation;Learning (artificial intelligence);Educational technology;Chatbots;Artificial intelligence;Engineering education;Education;Educational technology;Chatbot;Artificial intelligence;Epistemological Beliefs},
  doi={10.1109/EDUCON62633.2025.11016452},
  ISSN={2165-9567},
  month={April},}@INPROCEEDINGS{10343391,
  author={Wolfschwenger, Patrick and Sabitzer, Barbara and Lavicza, Zsolt},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={Integrating Cloud-Based AI in Software Engineers' Professional Training and Development}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial Intelligence (AI) has recently gained immense popularity. With impressive capabilities and versatility, large language models have quickly become a valuable tool for a wide range of applications, from chatbots and language translation to content creation and research. Generative AI can aid in the creation of computer code and provide information on a wide range of technical topics. This work-in-progress brings AI to vocational training by incorporating Cloud Computing (CC) services into a professional training and development program for software engineers, concentrating on practical skills development, hands-on experience and job-specific competencies. The approach is evaluated in the context of action research, with an emphasis on the potential benefits and challenges of code generation.},
  keywords={Cloud computing;Codes;Computational modeling;Learning (artificial intelligence);Vocational training;Chatbots;Software;Artificial Intelligence;Cloud Computing;Professional Training and Development;Lifelong Learning},
  doi={10.1109/FIE58773.2023.10343391},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10896159,
  author={Garzarella, Silvia and Vallasciani, Giacomo and Cascarano, Pasquale and Hajahmadi, Shirin and Cervellati, Elena and Marfia, Gustavo},
  booktitle={2025 IEEE International Conference on Artificial Intelligence and eXtended and Virtual Reality (AIxVR)}, 
  title={An Extended Reality Platform Powered by Large Language Models: A Case Study on Teaching Dance Costumes}, 
  year={2025},
  volume={},
  number={},
  pages={369-375},
  abstract={In this paper, we present an Extended Reality (XR) platform powered by Large Language Models (LLMs), designed to support education in dance history and cultural heritage. The platform here applied to a case study on a dance costume, allows users to interact with 3D models, annotate them, and explore their historical and cultural contexts collaboratively. Using features like image-to-LLM queries, users can gain insights into costume details and performance history, and the annotation tools enable uploading multimedia resources, thereby simulating an archival research environment. By integrating LLMs, the platform provides tailored information and context on demand, enriching the user experience with detailed explanations about objects, such as costume construction, usage, and cultural significance.},
  keywords={Solid modeling;Three-dimensional displays;Extended reality;Annotations;Large language models;User experience;Cultural differences;History;Context modeling;Extended Reality;Artificial Intelligence;LLM;Dance;Cultural Heritage},
  doi={10.1109/AIxVR63409.2025.00069},
  ISSN={2771-7453},
  month={Jan},}@ARTICLE{10558738,
  author={Radke, Richard J.},
  journal={IEEE Signal Processing Magazine}, 
  title={A Signal Processor Teaches Generative Artificial Intelligence [SP Education]}, 
  year={2024},
  volume={41},
  number={2},
  pages={6-10},
  abstract={How did an “old dog” signal processing professor approach learning and teaching the “new tricks” of generative artificial intelligence (AI)? This article overviews my recent experience in preparing and delivering a new course called “Computational Creativity,” reflecting on the methods I adopted compared to a traditional equations-on-a-whiteboard course. The technical material is qualitatively different from traditional signal processing, and the types of students who took the class and their approach to learning were different too. I learned a lot from the experience but also came away with bigger questions about the role of educators in the age of generative AI.},
  keywords={Generative AI;Education;Learning (artificial intelligence);Signal processing;Creativity;Educational courses;Creativity;Computational modeling},
  doi={10.1109/MSP.2024.3388166},
  ISSN={1558-0792},
  month={March},}@INPROCEEDINGS{10671366,
  author={Rai, Laxmisha and Khatiwada, Smriti and Deng, Chunrao and Liu, Fasheng},
  booktitle={2024 IEEE 7th International Conference on Electronic Information and Communication Technology (ICEICT)}, 
  title={Cross-Language Code Development with Generative AI: A Source-to-Source Translation Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={562-565},
  abstract={Since the release of ChatGPT in November 2022, there is growing interest around the world on exploring the capabilities of generative AI tools. In addition to text, image, audio, and video generation, these tools are also able to generate program codes. In this paper, strategies for students, programmers and enthusiasts to understand the prompting methods to generate codes in multiple languages by translating source code written in one language to another target language using generative AI is explored. The prompts are created to test the ability of generative AI to create codes in C, Java, C++, and Python. Some of the methods of generating the complete program using limited original source code statements is presented. In summary, while generating source code in a target language, generative AI tools downplay the significance of accuracy of statements written in original language, syntax, semantics, as well as missing statements in a program. Irrespective of these, generative AI tools are still able to generate complete code in a target language by correcting errors.},
  keywords={Java;Codes;Generative AI;Source coding;Semantics;Syntactics;Chatbots;Generative AI;translation;source code;programming;cross-language code},
  doi={10.1109/ICEICT61637.2024.10671366},
  ISSN={2836-7782},
  month={July},}@INPROCEEDINGS{10864116,
  author={Da Silva, Fabiano Tavares and De Araújo, Felipe Rocha and Bezerra, Erick Costa},
  booktitle={2024 5th International Conference on Artificial Intelligence and Computer Engineering (ICAICE)}, 
  title={A Comparative Study of Bug Triage Representation and Classification Approaches from Canonical to Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={86-93},
  abstract={Bug triage is the task of assigning newly reported bugs to the proper developers or team for resolution. This is a critical point in software maintenance as it directly influences the time and correct allocation that impact the efficiency and effectiveness of the software process. In a global aspect, the number of teams/developers is extensive, which brings a challenge for bug triage. Traditional approaches to assign bugs struggle with the complexity of the problem. This paper proposes a comparative assessment for different text representation combined with text classification approaches for automated bug report triage by incorporating Large Language Models (LLMs) into the classification pipeline to surpass the limitations of canonical methods. Traditional classification methods were compared with LLM-enhanced models across accuracy metric. The results demonstrate an improvement in triage accuracy when utilizing the fine-tuned LLM, highlighting their potential to provide developer-appropriate bug assignments.},
  keywords={Training;Software maintenance;Accuracy;Large language models;Computer bugs;Text categorization;Pipelines;Market research;Resource management;Software development management;bug report triage;LLM;S-BERT},
  doi={10.1109/ICAICE63571.2024.10864116},
  ISSN={},
  month={Nov},}@ARTICLE{11020711,
  author={Feng, Yingchaojie and Chen, Zhizhang and Kang, Zhining and Wang, Sijia and Tian, Haoyu and Zhang, Wei and Zhu, Minfeng and Chen, Wei},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The proliferation of large language models (LLMs) has underscored concerns regarding their security vulnerabilities, notably against jailbreak attacks, where adversaries design jailbreak prompts to circumvent safety mechanisms for potential misuse. Addressing these concerns necessitates a comprehensive analysis of jailbreak prompts to evaluate LLMs' defensive capabilities and identify potential weaknesses. However, the complexity of evaluating jailbreak performance and understanding prompt characteristics makes this analysis laborious. We collaborate with domain experts to characterize problems and propose an LLM-assisted framework to streamline the analysis process. It provides automatic jailbreak assessment to facilitate performance evaluation and support analysis of components and keywords in prompts. Based on the framework, we design JailbreakLens, a visual analysis system that enables users to explore the jailbreak performance against the target model, conduct multi-level analysis of prompt characteristics, and refine prompt instances to verify findings. Through a case study, technical evaluations, and expert interviews, we demonstrate our system's effectiveness in helping users evaluate model security and identify model weaknesses.},
  keywords={Analytical models;Security;Safety;Visualization;Taxonomy;Training;Semantics;Ethics;Large language models;Interviews;Jailbreak attacks;visual analytics;large language models},
  doi={10.1109/TVCG.2025.3575694},
  ISSN={1941-0506},
  month={},}@INPROCEEDINGS{10607367,
  author={Gabriella, Amanda and Gui, Anderes and Chanda, Razib Chandra},
  booktitle={2024 IEEE Symposium on Industrial Electronics & Applications (ISIEA)}, 
  title={The Use of Chatbot and its Impact on Academic Achievement}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years, the adoption of chatbot technology has garnered significant interest for its potential to revolutionize various domains, including education. This study aims to analyse the use of chatbots, specifically ChatGPT, and their impact on students' academic achievement in learning programming languages. The research investigates the influence of AI chatbots on learning motivation, self-efficacy, and academic achievement. Data collection was conducted using purposive sampling techniques, with a questionnaire prepared via Google Forms. Invitations to participate in the survey were distributed through social media platforms such as email, WhatsApp, Facebook, and Instagram. The study targeted students in the JABODETABEK area pursuing bachelor's or associate degrees, with a total of 400 respondents participating. To analyse the data, SmartPLS Version 4.0 was utilized. The results indicate that the use of ChatGPT positively impacts students' learning motivation. Increased learning motivation, in turn, positively influences students' academic achievement. Additionally, self-efficacy has a significant positive effect on academic achievement. The findings of this study provide valuable insights for stakeholders aiming to make chatbots more user-friendly for students to enhance their academic performance. Furthermore, these results enrich the existing literature on chatbot use with valuable information that can serve as a reference for future studies.},
  keywords={Surveys;Computer languages;Freeware;Social networking (online);Chatbots;Web sites;Stakeholders;ChatGPT;Learning Motivation;Self-efficacy;Academic Achievement;Programming Languages},
  doi={10.1109/ISIEA61920.2024.10607367},
  ISSN={2472-7660},
  month={July},}@INPROCEEDINGS{10870993,
  author={Zrelli, Rim and Misson, Henrique Amaral and Ben Attia, Maroua and de Magalhaes, Felipe Gohring and Shabah, Abdo and Nicolescu, Gabriela},
  booktitle={2024 International Workshop on Rapid System Prototyping (RSP)}, 
  title={Advancing Formal Verification: Fine-Tuning LLMs for Translating Natural Language Requirements to CTL Specifications}, 
  year={2024},
  volume={},
  number={},
  pages={21-27},
  abstract={In the domain of formal verification, translating natural language (NL) requirements into Computation Tree Logic (CTL) specifications presents a notable challenge due to the disparity between human-readable documents and formal specifications. This paper introduces a novel approach that leverages Large Language Models (LLMs) to automate this translation process, thereby enhancing the accuracy and efficiency of formal verification practices. We fine-tune three state-of-the-art LLMs—LLAMA3, Mistral, and Qwen2—with a particular focus on optimizing the Mistral model due to its superior performance. Our methodology is supported by the Natural2CTL dataset, consisting of 2,095 NL requirements and their corresponding CTL specifications. We employ evaluation metrics such as validation loss, accuracy, semantic similarity, and Structural Operator Jaccard Similarity (SOJS) for a comprehensive assessment of model performance. Additionally, a comparative analysis with human translators, trained in CTL logic, underscores the LLMs’ potential to match or even surpass human accuracy in translating NL requirements into formal specifications. Our findings reveal that the fine-tuned Mistral model significantly outperforms the other LLMs and human participants, demonstrating superior accuracy in generating CTL specifications. This study advances the field of formal verification by proposing a scalable solution to the NL-to-CTL translation challenge, setting a new benchmark for the integration of AI tools in complex specification tasks.},
  keywords={Measurement;Translation;Accuracy;Large language models;Conferences;Semantics;Benchmark testing;Logic;Formal specifications;Formal verification;Formal Verification;CTL;Automated Translation;LLMs;Model Fine-Tuning;AI Integration},
  doi={10.1109/RSP64122.2024.10870993},
  ISSN={2150-5519},
  month={Oct},}@INPROCEEDINGS{10803425,
  author={Ünlü, Hüseyin and Tenekeci, Samet and Çiftçi, Can and Oral, İbrahim Baran and Atalay, Tunahan and Hacaloğlu, Tuna and Musaoğlu, Burcu and DemirǶrs, Onur},
  booktitle={2024 50th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={Predicting Software Functional Size Using Natural Language Processing: An Exploratory Case Study}, 
  year={2024},
  volume={},
  number={},
  pages={188-193},
  abstract={Software Size Measurement (SSM) plays an essential role in software project management as it enables the acquisition of software size, which is the primary input for development effort and schedule estimation. However, many small and medium-sized companies cannot perform objective SSM and Software Effort Estimation (SEE) due to the lack of resources and an expert workforce. This results in inadequate estimates and projects exceeding the planned time and budget. Therefore, organizations need to perform objective SSM and SEE using minimal resources without an expert workforce. In this research, we conducted an exploratory case study to predict the functional size of software project requirements using state-of-the-art large language models (LLMs). For this aim, we fine-tuned BERT and BERT_SE with a set of user stories and their respective functional size in COSMIC Function Points (CFP). We gathered the user stories included in different project requirement documents. In total size prediction, we achieved 72.8% accuracy with BERT and 74.4% accuracy with BERT_SE. In data movement-based size prediction, we achieved 87.5% average accuracy with BERT and 88.1% average accuracy with BERT_SE. Although we use relatively small datasets in model training, these results are promising and hold significant value as they demonstrate the practical utility of language models in SSM.},
  keywords={Training;Schedules;Accuracy;Estimation;Project management;Companies;Predictive models;Size measurement;Software;Natural language processing;software size measurement;natural language processing;COSMIC;BERT;functional size;software engineering;NLP},
  doi={10.1109/SEAA64295.2024.00036},
  ISSN={2376-9521},
  month={Aug},}@INPROCEEDINGS{10646888,
  author={Oh, Sanghak and Lee, Kiho and Park, Seonhye and Kim, Doowon and Kim, Hyoungshick},
  booktitle={2024 IEEE Symposium on Security and Privacy (SP)}, 
  title={Poisoned ChatGPT Finds Work for Idle Hands: Exploring Developers’ Coding Practices with Insecure Suggestions from Poisoned AI Models}, 
  year={2024},
  volume={},
  number={},
  pages={1141-1159},
  abstract={AI-powered coding assistant tools (e.g., ChatGPT, Copilot, and IntelliCode) have revolutionized the software engineering ecosystem. However, prior work has demonstrated that these tools are vulnerable to poisoning attacks. In a poisoning attack, an attacker intentionally injects maliciously crafted insecure code snippets into training datasets to manipulate these tools. The poisoned tools can suggest insecure code to developers, resulting in vulnerabilities in their products that attackers can exploit. However, it is still little understood whether such poisoning attacks against the tools would be practical in real-world settings and how developers address the poisoning attacks during software development. To understand the real-world impact of poisoning attacks on developers who rely on AI-powered coding assistants, we conducted two user studies: an online survey and an in-lab study. The online survey involved 238 participants, including software developers and computer science students. The survey results revealed widespread adoption of these tools among participants, primarily to enhance coding speed, eliminate repetition, and gain boilerplate code. However, the survey also found that developers may misplace trust in these tools because they overlooked the risk of poisoning attacks. The in-lab study was conducted with 30 professional developers. The developers were asked to complete three programming tasks with a representative type of AI-powered coding assistant tool (e.g., ChatGPT or IntelliCode), running on Visual Studio Code. The in-lab study results showed that developers using a poisoned ChatGPT-like tool were more prone to including insecure code than those using an IntelliCode-like tool or no tool. This demonstrates the strong influence of these tools on the security of generated code. Our study results highlight the need for education and improved coding practices to address new security issues introduced by AI-powered coding assistant tools.},
  keywords={Surveys;Codes;Chatbots;Encoding;Software;Security;Task analysis;Large language model;AI-powered coding assistant tools;poisoning attacks;software development;usable security;code generation},
  doi={10.1109/SP54263.2024.00046},
  ISSN={2375-1207},
  month={May},}@INPROCEEDINGS{10975875,
  author={Zhu, Haoran and Cooper-Stachowsky, Michael and Kamal, Zille Huma},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Enhancing Contextual Understanding in AI-Powered Tutoring: Evaluating the Oliver System for Effective Learning Support}, 
  year={2025},
  volume={},
  number={},
  pages={530-535},
  abstract={In recent years, advancements in conversational AI have led to the development of intelligent tutoring systems to enhance learning experiences through interactive conversation. This paper presents Oliver, an innovative virtual teaching assistant and course management system that leverages contextual memory and response strategies designed to promote active learning and critical thinking. Unlike traditional models that frequently offer direct answers, Oliver encourages exploration and comprehension. We also evaluated Oliver against ChatGPT-4o mini in a controlled environment with over 100 real class interactions by using Bloom's Taxonomy as a framework. Results indicate that Oliver retains lecture-related context and promotes learning more effectively, with 90% of responses fostering higher-order thinking and critical engagement, compared to 60% from ChatGPT-4o mini. These findings underscore Oliver's potential to serve as a powerful tool in education, supporting learners in developing deeper cognitive skills rather than relying on rote memorization.},
  keywords={Learning management systems;Adaptive systems;Conversational artificial intelligence;Taxonomy;Memory management;Active learning;Learning (artificial intelligence);Oral communication;Educational technology;Information technology;Artificial Intelligence in Education;Blend Learning;Educational Technology;Learning Management Systems (LMS);Technology-Enhanced Learning},
  doi={10.1109/ICEIT64364.2025.10975875},
  ISSN={},
  month={March},}@INPROCEEDINGS{10780832,
  author={Gozali, Muhammad Rizqy Al and Revel, Devin and Christian},
  booktitle={2024 International Conference on Information Management and Technology (ICIMTech)}, 
  title={Beyond Chatting an Analysis of the Full Potential Use of Chat Generative AI for University Students in the Greater Jakarta Area}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the realm of education the rising popularity of Chat Generative Artificial Intelligence (AI) has sparked interest in its potential to enhance learning experiences. This technology, known for generating text that resembles speech offers an opportunity for students to hone their questioning skills and leverage it for their academic pursuits. A study conducted in Greater Jakarta encompassing DKI Jakarta, West Java and Banten delves into how students utilize Chat Generative AI to support their journeys. Specifically, the research aims to explore how this tool influences students ability to formulate questions and engage with content. By conducting a survey, the study sheds light on the frequency, context and nature of using Generative AI in a setting. The findings aim to inform educators researchers and developers, about the advantages of incorporating this technology into education practices to enhance the learning experience. Through an analysis of survey data this paper underscores the usage trends and advantages of employing AI chat platforms to create personalized learning environments.},
  keywords={Surveys;Privacy;Generative AI;Education;Learning (artificial intelligence);Security;Problem-solving;Pupils;Particle swarm optimization;Standards;Chat Generative Artificial Intelligence (AI);Insights;Competence},
  doi={10.1109/ICIMTech63123.2024.10780832},
  ISSN={2837-2778},
  month={Aug},}@ARTICLE{10783450,
  author={Hwang, Hyo-Seok and Kim, Yoojoong and Seok, Junhee},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Generative Adversarial Soft Actor–Critic}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={In deep reinforcement learning (RL), learning stochastic and multimodal policies are crucial for various tasks, but most continuous control algorithms model the policy using a deterministic or unimodal Gaussian distribution. Despite being designed to inherently learn a stochastic policy under the maximum entropy RL framework, soft actor–critic (SAC) also uses a factorized Gaussian policy for tractable optimization, which not only restricts the expressiveness of the policy but also ignores correlations among the components of the action vector. In this article, we revisit the approach of employing normalizing flow for SAC policy, justified by the change of variable theorem, and then propose a state-dependent nonvolume preserving (SD-NVP) architecture suitable for SAC learning. In addition, we introduce a generative adversarial SAC (GASAC) that implicitly defines and optimizes various divergences without calculating the normalization constant through a generative adversarial loss. Experimental results on multigoal environment and MuJoCo continuous control tasks suite demonstrate that GASAC model multimodal policy and learn policy more stably in terms of cumulative return.},
  keywords={Entropy;Mathematical models;Generative adversarial networks;Training;Stochastic processes;Vectors;Optimization;Measurement;Computational modeling;Predictive models;Continuous control;deep learning;deep reinforcement learning (RL);generative model},
  doi={10.1109/TNNLS.2024.3493113},
  ISSN={2162-2388},
  month={},}@ARTICLE{10886944,
  author={Hao, Pengfei and Wang, Hongqiu and Yang, Guang and Zhu, Lei},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Enhancing Visual Reasoning with LLM-Powered Knowledge Graphs for Visual Question Localized-Answering in Robotic Surgery}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Expert surgeons often have heavy workloads and cannot promptly respond to queries from medical students and junior doctors about surgical procedures. Thus, research on Visual Question Localized-Answering in Surgery (Surgical-VQLA) is essential to assist medical students and junior doctors in understanding surgical scenarios. Surgical-VQLA aims to generate accurate answers and locate relevant areas in the surgical scene, requiring models to identify and understand surgical instruments, operative organs, and procedures. A key issue is the model's ability to accurately distinguish surgical instruments. Current Surgical-VQLA models rely primarily on sparse textual information, limiting their visual reasoning capabilities. To address this issue, we propose a framework called Enhancing Visual Reasoning with LLM-Powered Knowledge Graphs (EnVR-LPKG) for the Surgical-VQLA task. This framework enhances the model's understanding of the surgical scenario by utilizing knowledge graphs of surgical instruments constructed by the Large Language Model (LLM). Specifically, we design a Fine-grained Knowledge Extractor (FKE) to extract the most relevant information from knowledge graphs and perform contrastive learning with the extracted knowledge graphs and local image. Furthermore, we design a Multi-attention-based Surgical Instrument Enhancer (MSIE) module, which employs knowledge graphs to obtain an enhanced representation of the corresponding surgical instrument in the global scene. Through the MSIE module, the model can learn how to fuse visual features with knowledge graph text features, thereby strengthening the understanding of surgical instruments and further improving visual reasoning capabilities. Extensive experimental results on the EndoVis-17-VQLA and EndoVis-18-VQLA datasets demonstrate that our proposed method outperforms other state-of-the-art methods. We will release our code for future research.},
  keywords={Surgery;Instruments;Visualization;Knowledge graphs;Feature extraction;Computational modeling;Medical diagnostic imaging;Data mining;Training;Bioinformatics;Large Language Model;contrastive learning;surgical visual question localized-answering;knowledge graph},
  doi={10.1109/JBHI.2025.3538324},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10527664,
  author={Varalakshmi, P. and Bugatha, N. Meena Kumari},
  booktitle={2024 Third International Conference on Intelligent Techniques in Control, Optimization and Signal Processing (INCOS)}, 
  title={AI-Powered Resume Based QA Tailoring for Success in Interviews}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In today's competitive job market, individuals encounter the challenge of aligning their skills with suitable job opportunities that match their interests. To tackle this, the system utilizes Natural Language Processing (NLP), leveraging Large Language Models (LLM) such as BERT, T5, ROBERTA, and XLNET. Through the analysis of resumes and job descriptions, it extracts keywords and generates Q&A, significantly increasing the likelihood of finding a role that aligns with their skills and aspirations. Achieving semantic accuracy, it delivers meaningful question and answer generation with an impressive 97% accuracy compared to previous works. This support empowers students and job seekers to confidently showcase their strengths, facilitating a more impactful journey towards securing meaningful employment. Additionally, the system provides a comprehensive analysis of the performance of each model.},
  keywords={Analytical models;Resumes;Semantics;Employment;Signal processing;Natural language processing;Interviews;Contextually linked;Text Summarization;NER;GPT-2;Web Scarping;BERT;T5;XLNET;ROBERTA;Semantic Accuracy},
  doi={10.1109/INCOS59338.2024.10527664},
  ISSN={},
  month={March},}@INPROCEEDINGS{10564292,
  author={Ghimire, Aashish and Edwards, John},
  booktitle={2024 Intermountain Engineering, Technology and Computing (IETC)}, 
  title={Generative AI Adoption in the Classroom: A Contextual Exploration Using the Technology Acceptance Model (TAM) and the Innovation Diffusion Theory (IDT)}, 
  year={2024},
  volume={},
  number={},
  pages={129-134},
  abstract={The burgeoning development of generative artificial intelligence (GenAI) and the widespread adoption of large language models (LLMs) in educational settings have sparked considerable debate regarding their efficacy and acceptability. Despite the potential benefits, the assimilation of these cutting-edge technologies among educators exhibits a broad spectrum of attitudes, from enthusiastic advocacy to profound skepticism. This study aims to dissect the underlying factors influencing educators' perceptions and acceptance of GenAI and LLMs. We conducted a survey among educators and analyzed the data through the frameworks of the Technology Acceptance Model (TAM) and Innovation Diffusion Theory (IDT). Our investigation reveals a strong positive correlation between the perceived usefulness of GenAI tools and their acceptance, underscoring the importance of demonstrating tangible benefits to educators. Additionally, the perceived ease of use emerged as a significant factor, though to a lesser extent, influencing acceptance. Our findings also show that the knowledge and acceptance of these tools is not uniform, suggesting that targeted strategies are required to address the specific needs and concerns of each adopter category to facilitate broader integration of AI tools in education.},
  keywords={Surveys;Technological innovation;Technology acceptance model;Correlation;Generative AI;Computational modeling;Education;Generative Artificial Intelligence (GenAI);Large Language Models (LLMs);Technology Acceptance Model (TAM);Innovation Diffusion Theory (IDT)},
  doi={10.1109/IETC61393.2024.10564292},
  ISSN={},
  month={May},}@INPROCEEDINGS{10816908,
  author={Joshi, Raghav and Bubna, Yash and Sahana, M. and Shruthiba, A.},
  booktitle={2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS)}, 
  title={An Approach to Intelligent Information Extraction and Utilization from Diverse Documents}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In this study, an innovative tool called DOCUFYme is introduced, designed to transform how interactions with and insights from various documents are handled. Leveraging advanced NLP methodologies and the Retrieval-Augmented Generation (RAG) framework, DOCUFYme facilitates efficient and precise information extraction across different fields such as engineering, science, medicine, and agriculture. Unlike conventional NLP systems that depend on predefined rules, this system employs existing metrics (like BLEU) and Large Language Models (LLMs) to achieve a deeper semantic understanding. Additionally, the architecture supports seamless integration of new features and domain-specific modules, enhancing the adaptability and relevance across different document types. The effectiveness of DOCUFYme is validated through multiple case studies and assessments based on real-world applications, including research, corporate knowledge management, healthcare, and education. This positions DOCUFYme as a pivotal tool for intelligent information extraction, bridging knowledge gaps and facilitating access to global knowledge.},
  keywords={Measurement;Retrieval augmented generation;Semantics;Transforms;Medical services;Information retrieval;Natural language processing;Data mining;Standards;Software engineering;Natural Language Processing (NLP);Retrieval-Augmented Generation (RAG);LLMs;Information Extraction;Document Processing;Artificial Intelligence (AI);Vector Embeddings;Text Chunking;Query Processing;Embeddings & Vectorization;Code Summarization},
  doi={10.1109/CSITSS64042.2024.10816908},
  ISSN={2767-1097},
  month={Nov},}@ARTICLE{11008449,
  author={Ge, Qihang and Sun, Wei and Zhang, Yu and Li, Yunhao and Ji, Zhongpeng and Sun, Fengyu and Jui, Shangling and Min, Xiongkuo and Zhai, Guangtao},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={LMM-VQA: Advancing Video Quality Assessment with Large Multimodal Models}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={The explosive growth of videos on streaming media platforms has underscored the urgent need for effective video quality assessment (VQA) algorithms to monitor and perceptually optimize the quality of streaming videos. However, VQA remains an extremely challenging task due to the diverse video content and the complex spatial and temporal distortions, thus necessitating more advanced methods to address these issues. Nowadays, large multimodal models (LMMs), such as GPT-4V, have exhibited strong capabilities for various visual understanding tasks, motivating us to leverage the powerful multimodal representation ability of LMMs to solve the VQA task. Therefore, we propose an Large Multi-Modal based Video Quality Assessment (LMM-VQA) model, which introduces a novel spatiotemporal visual modeling strategy for quality-aware feature extraction. Specifically, we reformulate the quality regression problem into a question and answering (Q&A) task and construct Q&A prompts for VQA instruction tuning. Then, we design a spatiotemporal vision encoder to extract spatial and temporal features to represent the quality characteristics of videos, which are subsequently mapped into the language space by the spatiotemporal projector for modality alignment. Finally, the aligned visual tokens and the quality-inquired text tokens are aggregated as inputs for the large language model (LLM) to generate the quality score as well as the quality level. Extensive experiments demonstrate that LMM-VQA achieves state-of-the-art performance across five VQA benchmarks, exhibiting an average improvement of 5% in generalization ability over existing methods. Furthermore, due to the advanced design of the spatiotemporal encoder and projector, LMM-VQA also performs exceptionally well on general video understanding tasks, further validating its effectiveness. Our code will be released at https://github.com/Sueqk/LMM-VQA.},
  keywords={Feature extraction;Visualization;Quality assessment;Video recording;Spatiotemporal phenomena;Distortion;Training;Sun;Tuning;Three-dimensional displays},
  doi={10.1109/TCSVT.2025.3571788},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10496969,
  author={Yu, Hao and Guo, Yunyun},
  booktitle={2023 5th International Workshop on Artificial Intelligence and Education (WAIE)}, 
  title={Harnessing the Potential of Chat GPT in Education: Unveiling its Value, Navigating Challenges, and Crafting Mitigation Pathways}, 
  year={2023},
  volume={},
  number={},
  pages={48-52},
  abstract={In the evolving landscape of educational technology, Chat GPT emerges as a transformative force, leveraging natural language processing to revolutionize various facets of education. This paper delves into the multifaceted contributions of Chat GPT, highlighting its capacity to foster multi-scenario applications, bolster comprehensive educational support systems, and enhance educational teaching management. It also elucidates the realistic challenges posed by Chat GPT to the contemporary education ecosystem, offering nuanced mitigation strategies. This exploration furnishes valuable insights, paving the way for informed advancements in educational paradigms and serving as a pivotal reference for subsequent research.},
  keywords={Training;Navigation;Biological system modeling;Education;Force;Ecosystems;Educational technology;Chat GPT;Artificial Intelligence;Educational Innovation;Value Realization;Challenge Navigation;Strategic Mitigation},
  doi={10.1109/WAIE60568.2023.00016},
  ISSN={},
  month={Sep.},}@ARTICLE{10816507,
  author={Yang, Liner and Yuan, Jiaxin and Kong, Cunliang and Yu, Jingsi and Chong, Ruining and Liu, Zhenghao and Yang, Erhong},
  journal={IEEE Transactions on Big Data}, 
  title={Tailored Definitions With Easy Reach: Complexity-Controllable Definition Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={The task of complexity-controllable definition generation refers to providing definitions with different readability for words in specific contexts. This task can be utilized to help language learners eliminate reading barriers and facilitate language acquisition. However, the available training data for this task remains scarce due to the difficulty of obtaining reliable definition data and the high cost of data standardization. To tackle those challenges, we introduce a general solution from both the data-driven and method-driven perspectives. We construct a large-scale standard Chinese dataset, COMPILING, which contains both difficult and simple definitions and can serve as a benchmark for future research. Besides, we propose a multitasking framework SimpDefiner for unsupervised controllable definition generation. By designing a parameter-sharing scheme between two decoders, the framework can extract the complexity information from the non-parallel corpus. Moreover, we propose the SimpDefiner guided prompting (SGP) method, where simple definitions generated by SimpDefiner are utilized to construct prompts for GPT-4, hence obtaining more realistic and contextually appropriate definitions. The results demonstrate SimpDefiner's outstanding ability to achieve controllable generation and better results could be achieved when GPT-4 is incorporated.},
  keywords={Dictionaries;Complexity theory;Annotations;Chatbots;Big Data;Training data;Decoding;Costs;Standards;Semantics;Controllable text generation;definition generation;unsupervised style transfer},
  doi={10.1109/TBDATA.2024.3522805},
  ISSN={2332-7790},
  month={},}@ARTICLE{10806880,
  author={Onuoha, Chibuike and Luo, Shihao and Thang, Truong Cong and Dang, Vu Hai and Nam, Nguyen Duc and Huong, Truong Thu},
  journal={IEEE Consumer Electronics Magazine}, 
  title={QoE Assessment for Prompt-based Videos: Acceptability and Quality Factors}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={The development of video technology and consumer devices has resulted in a boom of user-generated clips on various social networking services. The recent OpenAI Sora model can revolutionize the production of consumer videos, simply using prompts. However, videos generated using prompts usually contain new artifacts induced by generative AI. In addition, while various researchers have conducted extensive quality assessments on AI-generated videos, studies specifically focused on the Quality of Experience (QoE) of such videos remain limited. Given the increasing role of generative AI in media production, it is crucial to evaluate how users perceive and interact with these videos. In this paper, we present the first study on the acceptability assessment (also known as Customer Satisfaction Score) of prompt-based videos, which are generated by OpenAI Sora. In the assessment, subjects were asked to rate the video's alignment, perceptual quality, aesthetic quality, and whether the video is acceptable or not. The results show that, though the videos are visually impressive, not many videos are actually acceptable to users. Also, the relationship between acceptability and the other quality aspects is complex and non-linear. Especially, it is found that perceptual quality contributes the most to acceptability, while alignment is the least significant contributor. In addition, we identify over ten quality factors that cause low acceptability of prompt-based videos. Lastly, results from objective evaluation show that the performances of current quality metrics are insufficient to automatically monitor the quality and alignment of prompt-based videos.},
  keywords={Streaming media;Quality of experience;Quality assessment;Consumer electronics;Generative AI;Video recording;Standards;Semantics;Reliability;Production},
  doi={10.1109/MCE.2024.3519777},
  ISSN={2162-2256},
  month={},}@INPROCEEDINGS{10975835,
  author={Oraño, Jannie Fleur V. and Nogra, James Arnold and Mangmang, Geraldine B.},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Analyzing the Landscape of Generative and Open AI in Education: A Text Analytics Exploration of Scopus Publications}, 
  year={2025},
  volume={},
  number={},
  pages={84-90},
  abstract={Generative artificial intelligence (GAI) fundamentally reshaped the educational landscape by introducing innovative tools that enhanced learning outcomes and experiences. In this paper, a thorough examination of key terms surrounding GAI in education was undertaken from Scopus literature through sophisticated text analytics techniques such as word cloud generation and semantic analysis. The most used terms in the findings were “learning,” “ChatGPT,” and “language models,” representing the growing prominence of AI-driven educational solutions. Sentiment analysis revealed that authors had positive opinions about GAI and its potential benefits in developing individual learning paths and automating routines. However, concerns regarding ethics and job displacement were also highlighted. The study outlined important academic centers for GAI research, with significant contributions from Stanford University and publications in outlets such as “Lecture Notes in Computer Science.” Geographically, countries like China and India emerged as relevant in GAI research. Further thematic exploration demonstrated a predominantly positive attitude toward GAI's capability to transform pedagogical methodologies. Therefore, this research underscored the importance of text analytics in understanding GAI's role in education and called for strategic partnerships to advance innovation and equity in the global educational landscape.},
  keywords={Text mining;Sentiment analysis;Ethics;Technological innovation;Generative AI;Semantics;Transforms;Tag clouds;Stakeholders;Next generation networking;text analytics;generative ai;sentiment analysis;academia},
  doi={10.1109/ICEIT64364.2025.10975835},
  ISSN={},
  month={March},}@INPROCEEDINGS{10565703,
  author={Cotino Arbelo, Andrea E. and González-González, Carina S. and Molina Gil, Jezabel M.},
  booktitle={2023 XIII International Conference on Virtual Campus (JICV)}, 
  title={Embracing the Future: Unveiling the Revolution of Human-AI Interaction in the Digital Education Era}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={The recent and emerging introduction of generative AI in all areas of society poses new challenges to be overcome, particularly in the educational setting. The intimate and affective relationship that may develop between students and generative AI devices raises critical questions about the psychological and emotional impact of such interactions. This issue becomes particularly significant when the interactions with AI-based systems begin at an early age, and these systems assume roles as digital tutors, digital secretaries, motivator agents, and/or mentors. The aim of this work in progress was to address a recent challenge within the digital educational context: the psychological and emotional impact that the introduction of AI-based systems in digital education may have on students. However, we have faced limitations in terms of data availability and resources, particularly when addressing the issue from early ages, where there is a notable lack of studies. Although the results may not have been significant, the research has provided a general overview and a solid theoretical foundation for future studies in this field. Therefore, we suggest conducting more rigorous studies with representative samples and complete data, alongside developing reliable and validated methodologies and assessment tools to address the issues involved.},
  keywords={Generative AI;Education;Knowledge based systems;Psychology;Medical services;Reliability theory;Solids;Human-AI Interaction;Artificial Intelligence;Human-Computer Interaction;Affective Computing;Digital Education},
  doi={10.1109/JICV59748.2023.10565703},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10795074,
  author={Sridhara, Giriprasad and Roychowdhury, Sujoy and Soman, Sumit and G., Ranjani H. and Britto, Ricardo},
  booktitle={2024 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Icing on the Cake: Automatic Code Summarization at Ericsson}, 
  year={2024},
  volume={},
  number={},
  pages={689-700},
  abstract={This paper presents our findings on the automatic summarization of Java methods within Ericsson, a global telecommunications company. We evaluate the performance of an approach called Automatic Semantic Augmentation of Prompts (ASAP), which uses a Large Language Model (LLM) to generate leading summary comments (Javadocs) for Java methods. ASAP enhances the LLM's prompt context by integrating static program analysis and information retrieval techniques to identify similar exemplar methods along with their developer-written Javadocs, and serves as the baseline in our study. In contrast, we explore and compare the performance of four simpler approaches that do not require static program analysis, information retrieval, or the presence of exemplars as in the ASAP method. Our methods rely solely on the Java method body as input, making them lightweight and more suitable for rapid deployment in commercial software development environments. We conducted experiments on an Ericsson software project and replicated the study using two widely-used open-source Java projects, Guava and Elasticsearch, to ensure the reliability of our results. Performance was measured across eight metrics that capture various aspects of similarity. Notably, one of our simpler approaches performed as well as or better than the ASAP method on both the Ericsson project and the open-source projects. Additionally, we performed an ablation study to examine the impact of method names on Javadoc summary generation across our four proposed approaches and the ASAP method. By masking the method names and observing the generated summaries, we found that our approaches were statistically significantly less influenced by the absence of method names compared to the baseline. This suggests that our methods are more robust to variations in method names and may derive summaries more comprehensively from the method body than the ASAP approach.},
  keywords={Measurement;Java;Software maintenance;Codes;Semantics;Text summarization;Information retrieval;Telecommunications;Software reliability;Software development management;Automated Code Summarization;Large Language Models;Generative AI;Program Comprehension;Software Maintenance;Industry Study},
  doi={10.1109/ICSME58944.2024.00073},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10585387,
  author={Omirgaliyev, Ruslan and Kenzhe, Damir and Mirambekov, Suienish},
  booktitle={2024 IEEE AITU: Digital Generation}, 
  title={Simulating Life: The Application of Generative Agents in Virtual Environments}, 
  year={2024},
  volume={},
  number={},
  pages={181-187},
  abstract={This research explores the innovative integration of Large Language Models (LLMs) in game development, focusing on the autonomous creation, development, and governance of a virtual village by AI agents within a 2D game environment. The core of this study lies in observing and analyzing the interactions and societal development among AI agents, utilizing advanced algorithms for generative behavior modeling and dynamic skill tree learning. These AI agents are endowed with human-like decision-making capabilities, enabled by LLMs, allowing them to engage in complex social interactions and contribute to emergent societal structures within the game. The uniqueness of this project stems from its approach to simulating lifelike social dynamics in a virtual setting, thus addressing a gap in existing research and marking a significant contribution to the interdisciplinary fields of artificial intelligence and game development. By comparing AI-generated societal behaviors with human social interactions, the study delves into the potential of AI to mirror or enhance human social structures, offering a fresh perspective on the capabilities of AI in game development. This research not only aims to push the boundaries of AI applications in game development but also seeks to provide valuable insights into the potential for AI-driven simulations in studying complex social and behavioral dynamics.},
  keywords={Analytical models;Large language models;Heuristic algorithms;Decision making;Virtual environments;Focusing;Games;Large Language Models;Game Development;Artificial Intelligence Agents;Virtual Societies;Autonomous Agents;Social Dynamics Simulation},
  doi={10.1109/IEEECONF61558.2024.10585387},
  ISSN={},
  month={April},}@INPROCEEDINGS{10527283,
  author={de la Torre, Alejandra and Baldeon-Calisto, Maria},
  booktitle={2024 12th International Symposium on Digital Forensics and Security (ISDFS)}, 
  title={Generative Artificial Intelligence in Latin American Higher Education: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The utilization of Artificial Intelligence (AI) and Generative AI (GenAI) in higher education has increased importantly in the last years. Studies show that AI holds promise in enhancing the learning experiences for both students and educators, offering personalized learning and assessment opportunities. This study conducts a systematic review on the application of AI within Latin American higher education. To this end, we synthesized 25 papers published between 2021 and 2023, encompassing AI's utilization in Mexico, Colombia, Ecuador, Brazil, Peru, Chile, Argentina, and Bolivia. The analysis addresses three key inquiries: the prevalent applications of AI in Latin American education, the perceptions of AI and GenAI models among educators and students, and the particular challenges encountered by Latin American institutions in AI implementation. This systematic review offers an updated understanding of AI's role in Latin American higher education, with a particular emphasis on the latest AI technologies.},
  keywords={Training;Technological innovation;Systematics;Reviews;Generative AI;Navigation;Bibliographies;Artificial intelligence;Generative models;Chat-GPT;Latin America;Higher education;Systematic literature review},
  doi={10.1109/ISDFS60797.2024.10527283},
  ISSN={2768-1831},
  month={April},}@INPROCEEDINGS{10629560,
  author={Guo, Muhan},
  booktitle={2024 5th International Conference on Mechatronics Technology and Intelligent Manufacturing (ICMTIM)}, 
  title={Java Web Programming with ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={834-838},
  abstract={With the rapid development of artificial intelligence (AI), ChatGPT is an important technical breakthrough in the field of natural language processing (NLP). ChatGPT, as a large-scale language model, focuses on the task of conversation generation and has attracted wide attention in academia and industry. Meanwhile, it brings opportunities and challenges to Java Web programming. Compared with previous studies that investigated the ability of ChatGPT to solve small-scale Java programming problems that emphasized basic concepts, this paper explores how well ChatGPT can produce sequential Java code to construct the complete Web project. A series of experiments based on the user-login study case are conducted to evaluate the performance of ChatGPT-generated code. Through thorough experimental analysis, the generated code is characterized by high readability, good quality, and complete functionality. However, ChatGPT's performance degrades when instructions contain limited text information. In conclusion, ChatGPT has the potential to be an important assistant for developers, greatly improving efficiency and productivity in the software development process.},
  keywords={Productivity;Java;Codes;Mechatronics;Oral communication;Programming;Chatbots;Artificial intelligence;ChatGPT;Java Web programming;Natural language processing},
  doi={10.1109/ICMTIM62047.2024.10629560},
  ISSN={},
  month={April},}@INPROCEEDINGS{10752300,
  author={Manish, Vazzula and Manchala, Yugandhar and Vijayalata, Y. and Chopra, Sudeep Banerjee and Reddy, Kothi Yashwanth},
  booktitle={2024 IEEE Region 10 Symposium (TENSYMP)}, 
  title={Optimizing Resume Parsing Processes by Leveraging Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the present era of internet revolution, organizations have to go through numerous resumes in order to identify the most suitable candidates for their Job Description (JD), while ensuring that no acquisition of talent is overlooked through human mistakes. Thus, tools like Applicant Tracking Systems (ATS) have taken over the human process of resume screening, enabling assessment of thousands of resumes in a matter of seconds. Although these technologies are incredibly effective, they are not flawless. Consequently, highly qualified individuals may miss out on said opportunities if their resumes are not formatted correctly. Therefore, individuals must ensure that their resume is appropriately structured prior to submitting it to any organization. The study centers on the present literature and suggests an enhanced approach for parsing resumes by leveraging Large Language Models (LLMs).},
  keywords={Large language models;Resumes;Organizations;Cleaning;Data mining;IEEE Regions;Large Language Model(LLM);Natural Lan-guage Processing (NLP);Deep Learning (DL);Automated Re-sume Parsing;Applicant Tracking Systems (ATS);Software as a Service (SaaS);Human Resources (HR)},
  doi={10.1109/TENSYMP61132.2024.10752300},
  ISSN={2642-6102},
  month={Sep.},}@INPROCEEDINGS{10932399,
  author={Kailash Varma, Nadimpalli Madana and Aryan, Adla and Dhanush, Pagilla and Manikanta, Rangisetti and Chandhu, Nalla and Arora, Gagan Deep},
  booktitle={2025 2nd International Conference on Computational Intelligence, Communication Technology and Networking (CICTN)}, 
  title={Developing an AI-Based Library Assistant: Enhancing Book Retrieval with Natural Language Processing and Machine Learning}, 
  year={2025},
  volume={},
  number={},
  pages={136-140},
  abstract={The current college library system is hindered by inefficiencies in book searching, availability updates, identity verification, and checkout processes, resulting in delays and errors that negatively impact student experiences. This research paper presents an AI-based librarian system designed to address these challenges through automation and digital transformation. Leveraging a Large Language Model (LLM), the proposed system facilitates personalized interactions between students and library resources. Upon student verification, the AI librarian provides real-time information on book availability, location, and tailored recommendations, significantly reducing the time spent on manual searches. The streamlined checkout process allows for automated book issuance and instant confirmation notifications, minimizing human error and enhancing record- keeping. This innovative solution not only improves operational efficiency but also enriches the user experience by offering a user-friendly interface and timely assistance. Future enhancements, such as voice integration and mobile application support, are suggested to further modernize library services. This research underscores the potential of AI technologies to revolutionize library management and improve service delivery in academic settings.},
  keywords={Knowledge engineering;Automation;Large language models;Manuals;Libraries;Natural language processing;User experience;Real-time systems;Mobile applications;Usability;AI-based librarian;library automation;Large Language Model (LLM);personalized recommendations;student identification;library management system;natural language processing},
  doi={10.1109/CICTN64563.2025.10932399},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10597810,
  author={Cavalleri, Emanuele and Mesiti, Marco},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={Construction and Enhancement of an RNA-Based Knowledge Graph for Discovering New RNA Drugs}, 
  year={2024},
  volume={},
  number={},
  pages={5639-5643},
  abstract={Cutting-edge technologies in RNA biology are pushing the study of fundamental biological processes and human diseases and accelerate the development of new drugs tailored to the patient's biomolecular characteristics. Even if many structured and unstructured data sources report the interaction among different RNA molecules and some other biomedical entities (e.g., drugs, diseases, genes), we still lack a comprehensive and well-described RNA-centered Knowledge Graph (KG) that contains such information and sophisticated services that support the user in its creation, maintenance, and enhancement. This PhD project aims to create a biomedical KG (named RNA-KG) to represent, and eventually infer, biological, experimentally validated interactions between different RNA molecules. We also wish to enhance the KG content and develop sophisticated services designed ad-hoc to support the user in predicting uncovered relationships and identifying new RNA-based drugs. Services will rely on deep learning methods that consider the heterogeneity of the graph and the presence of an ontology that describes the possible relationships existing among the involved entities. Moreover, we will consider Large Language Models (LLMs) in combination with RNA-KG for interacting with the user with the ground truth information contained in our KG for extracting relationships from unstructured data sources.},
  keywords={Drugs;Knowledge engineering;Deep learning;RNA;Soft sensors;Large language models;Knowledge graphs;Biomedical knowledge graphs;Graph representation learning;LLMs;RNA therapeutics},
  doi={10.1109/ICDE60146.2024.00453},
  ISSN={2375-026X},
  month={May},}@ARTICLE{11015551,
  author={Skalka, Ján and Przybyła-Kasperek, Małgorzata and Smyrnova-Trybulska, Eugenia and Klimeš, Cyril and Farana, Radim and Dagienė, Valentina and Dolgopolovas, Vladimiras},
  journal={IEEE Access}, 
  title={Artificial Intelligence Literacy Structure and the Factors Influencing Student Attitudes and Readiness in Central Europe Universities}, 
  year={2025},
  volume={13},
  number={},
  pages={93235-93258},
  abstract={This study examines the structure of artificial intelligence (AI) literacy and factors influencing students’ attitudes, readiness, and perceived relevance of AI in higher education at Central European universities. The research, based on data from 1,195 students enrolled in various study programs between 2022 and 2024, examines how variables such as gender, academic discipline, and year of study influence perceptions related to AI. A validated questionnaire targeting constructs including satisfaction, readiness, and relevance of AI was used. Non-parametric statistical methods were used to identify significant differences between groups, including Kruskal-Wallis and Mann-Whitney tests with Dunn-Bonferroni post hoc analysis. The findings reveal consistent differences across genders and disciplines, with males and IT students demonstrating significantly higher readiness and satisfaction with AI. Furthermore, satisfaction levels fluctuated over time, peaking in 2023 – likely influenced by the widespread adoption of tools like ChatGPT. Correlation analysis further highlighted the subtle interrelationships between constructs across different subgroups. The study underscores the importance of tailored AI education strategies and calls for targeted interventions to ensure equitable engagement with AI across diverse student populations.},
  keywords={Artificial intelligence;Ethics;Education;Engineering profession;Problem-solving;Chatbots;Europe;Collaboration;Social sciences;Learning (artificial intelligence);Artificial intelligence;AI literacy;AI relevance;technology adoption;higher education},
  doi={10.1109/ACCESS.2025.3573575},
  ISSN={2169-3536},
  month={},}@ARTICLE{11005735,
  author={Deng, Zehang and Ma, Wanlun and Han, Qing-Long and Zhou, Wei and Zhu, Xiaogang and Wen, Sheng and Xiang, Yang},
  journal={IEEE/CAA Journal of Automatica Sinica}, 
  title={Exploring DeepSeek: A Survey on Advances, Applications, Challenges and Future Directions}, 
  year={2025},
  volume={12},
  number={5},
  pages={872-893},
  abstract={The rapid advancement of large models has led to the development of increasingly sophisticated models capable of generating diverse, personalized, and high-quality content. Among these, DeepSeek has emerged as a pivotal open-source initiative, demonstrating high performance at significantly lower computation costs compared to closed-source counterparts. This survey provides a comprehensive overview of the DeepSeek family of models, including DeepSeek-V3 and DeepSeek-R1, covering their core innovations in architecture, system pipeline, algorithm, and infrastructure. We explore their practical applications across various domains, such as healthcare, finance, and education, highlighting their impact on both industry and society. Further-more, we examine potential security, privacy, and ethical concerns arising from the widespread deployment of these models, emphasizing the need for responsible AI development. Finally, we outline future research directions to enhance the performance, safety, and scalability of DeepSeek models, aiming to foster further advancements in the open-source large model community.},
  keywords={Surveys;Technological innovation;Ethics;Computational modeling;Pipelines;Finance;Medical services;Computer architecture;Safety;Security;DeepSeek;large language model;large multimodal model},
  doi={10.1109/JAS.2025.125498},
  ISSN={2329-9274},
  month={May},}@INPROCEEDINGS{10650776,
  author={Wang, Yu and Liu, Xin and Lu, Xuesong and Zhou, Aoying},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={iiPCS: Intent-Based In-Context Learning for Project-Specific Code Summarization}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Recent years have witnessed growing research interest in automatic source code summarization due to its beneficial potential in software development and maintenance tasks. In the past few years, various deep learning models have been developed to leverage structural and textual features in the code for generating meaningful and succinct summaries. However, the summaries generated by traditional deep learning models often have syntax errors or are meaningless. The emergence of large language models provides an opportunity to overcome the problem. However, the quality of the summaries largely depends on the in-context learning examples of code-summary pairs. In this work, we develop iiPCS, an LLM-based method for code summarization. We retrieve relevant code-summary pairs as in-context learning examples from the same project of the target code, which ensures to generate more project-specific summaries, and use the predicted intent of the target code to pick few-shot examples, which ensures to generate summaries with the correct intent. Experimental results show that iiPCS can generate code summaries with higher quality compared to traditional methods using deep learning and recent methods using LLMs.},
  keywords={Deep learning;Codes;Source coding;Large language models;Semantics;Neural networks;Syntactics;Code Summarization;Large Language Models;Project-specific Summaries;In-context Learning;Developer Intent},
  doi={10.1109/IJCNN60899.2024.10650776},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10765003,
  author={Wu, Yueming and Liu, Chengwei and Xu, Zhengzi and Zhang, Lyuye and Zhang, Yiran and Zhu, Zhiling and Liu, Yang},
  booktitle={2024 39th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={The Software Genome Project: Unraveling Software Through Genetic Principles}, 
  year={2024},
  volume={},
  number={},
  pages={2319-2323},
  abstract={Open-source software is crucial to modern development, but its complexity creates challenges in quality, security, and management. Current governance approaches excel at collaboration but struggle with decentralized management and security. With the rise of large language models (LLM)-based software engineering, the need for a finer-grained understanding of software composition is more urgent than ever. To address these challenges, inspired by the Human Genome Project, we treat the software source code as software DNA and propose the Software Genome Project (SGP), which is geared towards the secure monitoring and exploitation of open-source software. By identifying and labeling integrated and classified code features at a fine-grained level, and effectively identifying safeguards for functional implementations and non-functional requirements at different levels of granularity, the SGP could build a comprehensive set of software genome maps to help developers and managers gain a deeper understanding of software complexity and diversity. By dissecting and summarizing functional and undesirable genes, SGP could help facilitate targeted software optimization, provide valuable insight and understanding of the entire software ecosystem, and support critical development tasks such as open source governance. SGP could also serve as a comprehensive dataset with abundant semantic labeling to enhance the training of LLMs for code. Based on these, we expect SGP to drive the evolution of software development towards more efficient, reliable, and sustainable software solutions.CCS Concepts• Software and its engineering → Software design engineering.},
  keywords={Codes;Ecosystems;Genomics;Software;Complexity theory;Security;Labeling;Bioinformatics;Open source software;Software engineering;Software Genes;Software Composition;OSS Governance},
  doi={},
  ISSN={2643-1572},
  month={Oct},}@INPROCEEDINGS{10740416,
  author={Yabaku, Mounika and Pombo, Nuno and Ouhbi, Sofia},
  booktitle={2024 IEEE 18th International Conference on Application of Information and Communication Technologies (AICT)}, 
  title={Exploring the Potential Use of Generative AI in Software Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The integration of Generative AI into software engineering education marks a transformative shift in teaching methodologies. This paper explores its potential, highlighting the benefits of enhancing student engagement, creativity, and efficiency while preparing them for industry challenges. Through a comprehensive analysis of 13 popular generative AI tools, we examine their roles in various software engineering tasks such as requirements analysis, design, coding, debugging, and testing. This paper contributes to the broader discourse on the future of software engineering education by offering evidence-based recommendations for leveraging generative AI to create adaptive and forward-thinking instructional strategies.},
  keywords={Generative AI;Education;Debugging;Software;Requirements engineering;Software measurement;Usability;Software engineering;Testing;Software development management;Generative AI;Large Language Models (LLMs);Software Engineering Education;Pedagogical Innovation;AIDriven Educational Tools},
  doi={10.1109/AICT61888.2024.10740416},
  ISSN={2472-8586},
  month={Sep.},}@INPROCEEDINGS{10893388,
  author={Mackay, Sean and Eiselt, Kurt and Decker, Adrienne},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Two Sides of the Same Coin: Differing Approaches to Generative AI in Two Computer Science Classrooms}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This innovative practice paper explores two differing approaches to the use of artificial intelligence tools in computer science classrooms. Artificial Intelligence (AI), while not a new technology, has seen a rise in popularity over the past two years, with companies such as OpenAI, Google, and Microsoft making readily available generative AI tools for anyone to use. This surge in AI popularity has led to a rise in its use in educational settings, in some cases allowed and in others discouraged or disallowed. A debate has risen among academics, particularly in higher education, about what AI's place in education is, with some educators actively encouraging its use while others view the use of AI as a form of academic dishonesty. Given AI is only advancing and is becoming more prevalent, it will only continue to become a more dominant force throughout education and the world at large. This paper presents two educators' distinct viewpoints and experiences on how AI should be handled in computer science courses (absolutely forbidden vs. decriminalized). The goal of this paper is to present different perspectives as well as concrete experiences we have had with AI in our own classrooms to encourage others to consider their own positions on its use and its implications for their own learning environments. While the debate on the place of AI in education is a long way from being settled, educators need to think about making choices, clearly articulating policies, and evaluating the positives and negatives of positions about AI in their classrooms.},
  keywords={Codes;Generative AI;Affordances;Education;Force;Companies;Internet;Computer science education;Surges;Programming profession;academic integrity;LLM's;course policies;AI in education},
  doi={10.1109/FIE61694.2024.10893388},
  ISSN={2377-634X},
  month={Oct},}@INBOOK{10952004,
  author={Pandey, Shubham and Patel, Archana and Pokhariyal, Purvi},
  booktitle={Artificial Intelligence for Risk Mitigation in the Financial Industry}, 
  title={Exploring the Role of ChatGPT in the Law Enforcement and Banking Sectors}, 
  year={2024},
  volume={},
  number={},
  pages={327-347},
  abstract={Summary <p>This chapter explores the role of ChatGPT, a powerful artificial intelligence (AI) tool, in the law enforcement and banking sectors. ChatGPT has the potential to revolutionize these industries by offering a wide range of applications and benefits. In law enforcement, ChatGPT can assist in investigative analysis, risk assessment, virtual training, and crime prevention. In the banking sector, it can provide customer support, aid in fraud detection, assist with risk assessment and compliance, and offer personalized financial advice. However, the implementation of ChatGPT also raises concerns related to privacy, security, and the need for human oversight. Therefore, it is crucial to address these concerns and establish regulatory frameworks to govern the use of advanced technologies effectively. This chapter aims to provide legal and technical recommendations to regulate ChatGPT's usage and mitigate associated risks.</p>},
  keywords={Chatbots;Banking;Law enforcement;Artificial intelligence;Translation;Risk management;Fraud;Transformers;Risk mitigation;Oral communication},
  doi={10.1002/9781394175574.ch13},
  ISSN={},
  publisher={Wiley},
  isbn={9781394175567},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10952004},}@INPROCEEDINGS{10967276,
  author={Liao, Zhifang and Liu, Pei and Lan, Peng and Sun, Ke},
  booktitle={2024 31st Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={DupLLM:Duplicate Pull Requests Detection Based on Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={121-130},
  abstract={As the scale of projects expands, the concurrent development model adopted by the open source community leads to an increasingly prominent problem of repetitive pull requests (PRs). The large number of rejections caused by duplicate pull requests increases the review workload of project maintainers and reduces the efficiency of pull request review. Therefore, it is very necessary to conduct automated duplicate PR detection. In this study, we propose DupLLM, a framework designed to detect duplicate PRs. The framework generates refined sum-maries by feeding the content of individual PRs into a large language model (LLM). Subsequently, the resulting summary is vectorized, converting the textual content into a numerical representation. The similarity between PRs is evaluated by calculating the similarity score between PR summary vectors. Ultimately, the model showed better performance than the best existing model, achieving an effect of 0.929 on P@l. This confirms that LLM can also achieve equivalent results in the field of duplicate PR detection as deep learning is used to train on this task, providing a new direction for the application of LLM in the field of software engineering.},
  keywords={Training;Deep learning;Codes;Reviews;Large language models;Merging;Vectors;Numerical models;Software engineering;Software development management;LLM;Pull Request;GitHub;duplicate Pull Request detection},
  doi={10.1109/APSEC65559.2024.00023},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{10574587,
  author={Shan, J and Eliyas, Sherin},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Exploring AI Facial Recognition for Real-time Emotion Detection: Assessing Student Engagement in Online Learning Environments}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={AI facial recognition for real-time emotion detection in online learning environments intends to analyze students’ sentiments throughout online classes, recognizing emotions such as focused, neutral, distracted, enraged, thrilled, or dissatisfied states. The proposed approach uses a generative model trained by conditional Generative Adversarial Networks (cGAN) to accomplish De-expression Residue Learning (DeRL), a facial expression recognition technique. DeRL prioritizes gathering residue for delicate emotion recognition by filtering expressive material and storing it in intermediary layers. This technology gives educators and researchers real-time insights into students’ emotional states, allowing for a more thorough understanding of collective student involvement through the lens of socially shared control of learning. Experiments on seven facial expression databases, including two pre-training datasets, indicate that DeRL outperforms other methods in accurately recognizing and classifying students’ emotions. The findings emphasize its ability to capture subtle feelings during online learning. The discussion dives into theoretical and practical implications, highlighting AI’s potential to enhance the evaluation of student participation in online learning environments. The study concludes by providing relevant information for building tailored learning experiences, indicating a possible avenue for incorporating AI in the classroom.},
  keywords={Emotion recognition;Filtering;Databases;Face recognition;Buildings;Learning (artificial intelligence);Generative adversarial networks;Facial Expression Identification;Psychological Control;Socially Integrated Supervision;Pre-training;De-expression Residue Learning;Synchronous online education;Computer-supported interactive education;conditional Generative Adversarial;Network;Student Self-regulation},
  doi={10.1109/AIIoT58432.2024.10574587},
  ISSN={},
  month={May},}@BOOK{10522580,
  author={Ping, David},
  booktitle={The Machine Learning Solutions Architect Handbook: Practical strategies and best practices on the ML lifecycle, system design, MLOps, and generative AI},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Design, build, and secure scalable machine learning (ML) systems to solve real-world business problems with Python and AWS Purchase of the print or Kindle book includes a free PDF eBookKey FeaturesGo in-depth into the ML lifecycle, from ideation and data management to deployment and scalingApply risk management techniques in the ML lifecycle and design architectural patterns for various ML platforms and solutionsUnderstand the generative AI lifecycle, its core technologies, and implementation risksBook DescriptionDavid Ping, Head of GenAI and ML Solution Architecture for global industries at AWS, provides expert insights and practical examples to help you become a proficient ML solutions architect, linking technical architecture to business-related skills. You'll learn about ML algorithms, cloud infrastructure, system design, MLOps , and how to apply ML to solve real-world business problems. David explains the generative AI project lifecycle and examines Retrieval Augmented Generation (RAG), an effective architecture pattern for generative AI applications. You’ll also learn about open-source technologies, such as Kubernetes/Kubeflow, for building a data science environment and ML pipelines before building an enterprise ML architecture using AWS. As well as ML risk management and the different stages of AI/ML adoption, the biggest new addition to the handbook is the deep exploration of generative AI. By the end of this book , you’ll have gained a comprehensive understanding of AI/ML across all key aspects, including business use cases, data science, real-world solution architecture, risk management, and governance. You’ll possess the skills to design and construct ML solutions that effectively cater to common use cases and follow established ML architecture patterns, enabling you to excel as a true professional in the field.What you will learnApply ML methodologies to solve business problems across industriesDesign a practical enterprise ML platform architectureGain an understanding of AI risk management frameworks and techniquesBuild an end-to-end data management architecture using AWSTrain large-scale ML models and optimize model inference latencyCreate a business application using artificial intelligence services and custom modelsDive into generative AI with use cases, architecture patterns, and RAGWho this book is forThis book is for solutions architects working on ML projects, ML engineers transitioning to ML solution architect roles, and MLOps engineers. Additionally, data scientists and analysts who want to enhance their practical knowledge of ML systems engineering, as well as AI/ML product managers and risk officers who want to gain an understanding of ML solutions and AI risk management, will also find this book useful. A basic knowledge of Python, AWS, linear algebra, probability, and cloud infrastructure is required before you get started with this handbook.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805124825},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10522580},}@INPROCEEDINGS{10550837,
  author={Samarakoon, Pramodya and Asanka, Dinesh and Jayalal, Shantha and Jayalath, Nirasha},
  booktitle={2024 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Analyzing the Learning Effectiveness of Generative AI for Software Development for Undergraduates in Sri Lanka}, 
  year={2024},
  volume={7},
  number={},
  pages={1-7},
  abstract={As the demand for skilled software developers continues to rise, the integration of Generative Artificial Intelligence (Generative AI) in educational settings has garnered attention. This research investigates the effectiveness of Generative AI in enhancing coding proficiency in a diverse cohort of participants. The study employs pre-, mid-, and post-tests to measure coding skills, employing a nuanced analysis across various demographic variables. The findings reveal a substantial increase in average scores, indicating positive impacts of Generative AI on coding abilities. The N-Gain value of 0.33 signifies a medium learning gain, establishing Generative AI as a valuable tool in coding education. A detailed exploration of demographic variables, including gender, age, academic level, A/L stream, A/L district, and preferred programming language, provides insights into the intersectionality of these factors with learning outcomes. This research contributes to the discourse on the impact of Generative AI on coding skills, offering practical insights for educators, policymakers, and practitioners. The study recommends tailored interventions to address specific demographic variables, fostering a more inclusive and effective learning environment.},
  keywords={Computer languages;Generative AI;Atmospheric measurements;Education;Systems engineering and theory;Particle measurements;Encoding;Generative AI;Learning Effectiveness;Software Development Education;Undergraduate Students},
  doi={10.1109/SCSE61872.2024.10550837},
  ISSN={2613-8662},
  month={April},}@INPROCEEDINGS{10762540,
  author={Hartato, Frandi and Yahya, Jovan and Enrico Christiano Hartono, Liem and Sudiana},
  booktitle={2024 International Seminar on Application for Technology of Information and Communication (iSemantic)}, 
  title={Art in the Era of Algorithms: Is Generative AI a Friend or Foe for 2D Artists?}, 
  year={2024},
  volume={},
  number={},
  pages={190-195},
  abstract={This research investigates the transformative impact of AI technologies such as DALL-E, ChatGPT, and other generative AI tools on the arts, particularly focusing on their implications for 2D artwork. These advancements have democratized the creation of 2D art, making it more accessible, but they have also raised concerns about the value of original talent and the potential impact on careers in the arts. The study employs the Technology Acceptance Model (TAM) to evaluate the acceptance and impact of generative AI among individuals in creative fields, including students, lecturers, and professionals. Data collected from 127 respondents through structured surveys indicate high levels of engagement with generative AI, reflecting significant curiosity and usage rates. Analysis using SmartPLS 4.0 Tools validated the initial research model, demonstrating that generative AI significantly influences perceived usefulness, perceived ease of use, and behavioral intention in 2D art creation. These findings underscore the critical need to consider AI's evolving role in the arts, its impact on perceptions of creativity and talent, and its broader implications for the creative industry. The study tested seven hypotheses, with six accepted and one rejected. This indicates that while factors like user computer self-efficacy and quality information significantly influence the perceived usefulness and ease of use of generative AI, ease of use alone does not necessarily lead to a positive attitude towards its use. However, perceived usefulness significantly contributes to a positive attitude towards using generative AI. Additionally, a positive attitude towards generative AI influences the behavioral intention to use it, thereby enhancing skills and providing inspiration for creating artwork.},
  keywords={Surveys;Seminars;Productivity;Industries;Java;Art;Technology acceptance model;Generative AI;Focusing;Chatbots;Artificial Intelligence;Generative AI;2D Artist;TAM Model;SEM-PLS},
  doi={10.1109/iSemantic63362.2024.10762540},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10971486,
  author={Marefat, Alireza and Nishar, Abbaas Alif Mohamed and Ashok, Ashwin},
  booktitle={SoutheastCon 2025}, 
  title={Text2Net: Transforming Plain-text to a Dynamic Interactive Network Simulation Environment}, 
  year={2025},
  volume={},
  number={},
  pages={625-630},
  abstract={This paper introduces Text2Net, an innovative text-based network simulation engine that leverages natural language processing (NLP) and large language models (LLMs) to transform plain-text descriptions of network topologies into dynamic, interactive simulations. Text2Net simplifies the process of configuring network simulations, eliminating the need for users to master vendor-specific syntaxes or navigate complex graphical interfaces. Through qualitative and quantitative evaluations, we demonstrate Text2Net's ability to significantly reduce the time and effort required to deploy network scenarios compared to traditional simulators like EVE-NG. By automating repetitive tasks and enabling intuitive interaction, Text2Net enhances accessibility for students, educators, and professionals. The system facilitates hands-on learning experiences for students that bridge the gap between theoretical knowledge and practical application. The results showcase its scalability across various network complexities, marking a significant step toward revolutionizing network education and professional use cases, such as proof-of-concept testing.},
  keywords={Protocols;Navigation;Scalability;Transforms;Routing;Rapid prototyping;Natural language processing;Virtual private networks;Pattern matching;Testing;Network Simulation and Emulation;Educational Technology;AI in Education;Interactive Learning Environments;Network Configuration Automation;AI-driven Network},
  doi={10.1109/SoutheastCon56624.2025.10971486},
  ISSN={1558-058X},
  month={March},}@INPROCEEDINGS{11009556,
  author={Liu, Kai},
  booktitle={2025 7th International Conference on Software Engineering and Computer Science (CSECS)}, 
  title={A Stylistic Comparative Study for Evaluating Neural Machine Translation Technologies}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={Neural network-based online machine translation technologies have brought great convenience to foreign language teaching and research. However, performance evaluation of these translation technology models from the perspective of stylistic comparisons are currently scarce. In this study, Wenxin 4.0, DeepSeek-V3, and ChatGPT are used to translate a selection from an ancient Chinese story, and a stylistic comparison is conducted among the three versions of translation. By analyzing the transitivity processes of the original text, along with the three translated versions, it is found that the translations processed by the three technological models are closely similar to the original text in terms of the number and type distribution of transitivity processes. Nevertheless, there were certain differences in the use of mental and behavioral processes compared to the original text. Comparing the semantic configuration, as well as the stylistic feature distributions of the translated versions and the original text, is conducive to examining the differences in existing online translation technology models, both at home and abroad, when handling document-level translation units. This provides a basis for performance evaluation to support technological updates.},
  keywords={Performance evaluation;Fans;Translation;Computational modeling;Semantics;Education;Neural machine translation;Linguistics;Machine translation;Software engineering;Online Machine Translation;Technological Model;Semantic Configuration;Interlingual Translation;Stylistic Comparison;Performance Evaluation},
  doi={10.1109/CSECS64665.2025.11009556},
  ISSN={},
  month={March},}@INPROCEEDINGS{10731435,
  author={Mannava, Vivek and Mitrevski, Alex and Plöger, Paul G.},
  booktitle={2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)}, 
  title={Exploring the Suitability of Conversational AI for Child-Robot Interaction}, 
  year={2024},
  volume={},
  number={},
  pages={1821-1827},
  abstract={Current approaches in education, while aiming to be universally effective, often struggle to fully adapt to the unique needs and communication styles of individual children; this disparity can limit the children’s engagement and hinder their learning progress. Similarly, parents or guardians, despite their good intentions, may also be unable to provide consistent and personalized support to each child. In this work, we investigate the use of conversational systems for socially assistive robots (SARs) as a potential solution to this problem, as such systems have the potential to allow children to interact and learn at their own pace, in a way that aligns with their communication preferences. To ensure that the robot’s language is suitable for children, we present a system that leverages a combination of natural language processing (NLP) techniques, including dialog management, child-friendly language generation, and context-aware response adaptation; to achieve this, our system combines Rasa for dialog management, GPT-3.5 for language generation, and textstat for language complexity evaluation. We evaluate the suitability of the generated language for a young audience through two user studies with adult participants, one in which the conversational system was embodied in a robot and involved direct interaction between a human and a robot, and another where participants evaluated conversational transcripts from the first study. Our results suggest that the system has the potential to maintain engaging and safe conversations, and adapt its language to individual needs.},
  keywords={Education;Oral communication;Assistive robots;Natural language processing;Complexity theory;Robots},
  doi={10.1109/RO-MAN60168.2024.10731435},
  ISSN={1944-9437},
  month={Aug},}@INPROCEEDINGS{10260821,
  author={Birkmeier, Dominik Q. and Beck, Martina},
  booktitle={2023 IEEE 31st International Requirements Engineering Conference (RE)}, 
  title={Digital Design - Shaping a Sustainable Digital Future Requires a New Holistic Design Approach}, 
  year={2023},
  volume={},
  number={},
  pages={255-263},
  abstract={In today's digital age, businesses of all sizes face the challenge of adapting to the rapid pace of technological advancements, including new possibilities like ChatGPT, AI in general, Voice User Interfaces, and the Metaverse. In our experience, many companies still lack awareness of the need for digital transformation or are simply not ready for it. The integration of physical and digital products has led to an increase in complexity for both users and companies, necessitating a holistic design approach to encapsulate this complexity and shape a sustainable digital future. While traditional requirements engineering with solution-neutral requirements has been the norm, it is not sufficient for these new core issues. Digital design, with its emphasis on user centered design, technological possibilities, and a comprehensive understanding of the digital ecosystem, fills this gap in requirements engineering. By incorporating digital design competence in every project, companies can design sustainable digital solutions that integrate seamlessly with the user's needs and the company's goals. In this paper, we propose a new field of competence: Digital Design. Within this field we suggest a new model for Shaping, Exploring, and Implementing innovative digital products. As we discuss the steps that science and practice must take to ensure that every project incorporates digital design competence, our paper provides insights for both academia and industry.},
  keywords={Industries;Shape;Metaverse;User centered design;Companies;User interfaces;Information age;digital design;digital innovation;awareness;readiness;sustainability;shaping;exploring;implementing},
  doi={10.1109/RE57278.2023.00033},
  ISSN={2332-6441},
  month={Sep.},}@INPROCEEDINGS{10408241,
  author={Tolk, Andreas and Barry, Philip and Loper, Margaret L. and Rabadi, Ghaith and Scherer, William T. and Yilmaz, Levent},
  booktitle={2023 Winter Simulation Conference (WSC)}, 
  title={Chances and Challenges of ChatGPT and Similar Models for Education in M&S}, 
  year={2023},
  volume={},
  number={},
  pages={3332-3346},
  abstract={This position paper summarizes the inputs of a group of experts from academia and industry presenting their view on chances and challenges of using ChatGPT within Modeling and Simulation education. The experts also address the need to evaluate continuous education as well as education of faculty members to address scholastic challenges and opportunities while meeting the expectation of industry. Generally, the use of ChatGPT is encouraged, but it needs to be embedded into an updated curriculum with more emphasis on validity constraints, systems thinking, and ethics.},
  keywords={Industries;Ethics;Education;Chatbots;Systems thinking;Artificial intelligence},
  doi={10.1109/WSC60868.2023.10408241},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10628480,
  author={Arora, Chetan and Herda, Tomas and Homm, Verena},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Generating Test Scenarios from NL Requirements Using Retrieval-Augmented LLMs: An Industrial Study}, 
  year={2024},
  volume={},
  number={},
  pages={240-251},
  abstract={Test scenarios are specific instances of test cases that describe a sequence of actions to validate a particular software functionality. By outlining the conditions under which the software operates and the expected outcomes, test scenarios ensure that the software functionality is tested in an integrated manner. Test scenarios are crucial for systematically testing an application under various conditions, including edge cases, to identify potential issues and guarantee overall performance and reliability. Manually specifying test scenarios is tedious and requires a deep understanding of software functionality and the underlying domain. It further demands substantial effort and investment from already time- and budget-constrained requirements engineers and testing teams. This paper presents an automated approach (RAGTAG) for test scenario generation using Retrieval-Augmented Generation (RAG) with Large Language Models (LLMs). RAG allows the integration of specific domain knowledge with LLMs' generation capabilities. We evaluate RAGTAG on two industrial projects from Austrian Post with bilingual requirements in German and English. Our results from an interview survey conducted with four experts on five dimensions – relevance, coverage, correctness, coherence and feasibility, affirm the potential of RAGTAG in automating test scenario generation. Specifically, our results indicate that, despite the difficult task of analyzing bilingual requirements, RAGTAG is able to produce scenarios that are well-aligned with the underlying requirements and provide coverage of different aspects of the intended functionality. The generated scenarios are easily understandable to experts and feasible for testing in the project environment. The overall correctness is deemed satisfactory; however, gaps in capturing exact action sequences and domain nuances remain, underscoring the need for domain expertise when applying LLMs.},
  keywords={Surveys;Large language models;Coherence;Software systems;Software reliability;Scenario generation;Requirements engineering;Requirements Engineering;Requirements-driven Testing;Test Scenarios;Large Language Models (LLMs);Industry Study},
  doi={10.1109/RE59067.2024.00031},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10336257,
  author={Kumar, Abhishek and Das, Partha Pratim and Pratim Chakrabarti, Partha},
  booktitle={2023 IEEE International Conference on Software Maintenance and Evolution (ICSME)}, 
  title={Summarize Me: The Future of Issue Thread Interpretation}, 
  year={2023},
  volume={},
  number={},
  pages={341-345},
  abstract={Understanding issue threads is an essential aspect of software maintenance and development, aiding developers in effectively addressing and managing software-related issues. These threads typically contain an issue description, comments discussing possible solutions, and often culminate in a pull request where the proposed changes are elaborated. Even though they are crucial, understanding issue threads can be a lot of work because they are often long and complex, particularly in big projects. This paper, therefore, aims to automate the process of issue thread summarization using advanced AI models, specifically the GPT-3.5-Turbo, reducing the time spent and improving the efficiency of the interpretation process. Our approach taps into the potential of the zero-shot learning methodology, enabling the model to produce context-specific summaries without reliance on prior examples. Additionally, we have developed an algorithm that determines the most effective length for these summaries, which enhances their clarity and relevance. The performance of the model is assessed using automated metrics, including ROUGE and BART scores, for extractive and abstractive summary evaluation respectively. Further, we may like to add that summaries of around 30% to 40% of the total size of the issue thread appears to be sufficient, though it varies slightly from case to case. The model’s successful generation of brief, clear, and pertinent summaries not only boosts team communication and project management but also lays the groundwork for its future integration into a comprehensive tool for simplified exploration and comprehension of complex software repositories.},
  keywords={Measurement;Software maintenance;Zero-shot learning;Project management;Artificial intelligence;Context modeling;Issue Thread Summarization;Machine Learning;Software maintenance;Zero-shot learning;ROUGE and BART scores},
  doi={10.1109/ICSME58846.2023.00042},
  ISSN={2576-3148},
  month={Oct},}@INPROCEEDINGS{10534929,
  author={Zhou, Ethan Phoenix},
  booktitle={2023 IEEE MIT Undergraduate Research Technology Conference (URTC)}, 
  title={The Fallibility of AI Content Detectors}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={With the release of ChatGPT, faculty started adopting AI content detectors to identify AI-generated content. However, faulty detector results led to wrongful accusations against some students. This study evaluates AI content detectors' performance in distinguishing human-written from AI-generated content. Three detectors, Writer, ZeroGPT, and OpenAI Text Classifier, were tested on three types of writing samples: human-written, human written and edited by ChatGPT, and fully AI-generated. Data was categorized into AI-generated, maybe AI, and human-written outputs for each detector. Statistical analysis, including chi-square tests, assessed detector outputs and text sample sources' relationship. Results revealed that only ZeroGPT's outputs depended on the sources but only correctly classified 47.2% of human-written texts.},
  keywords={Statistical analysis;Social networking (online);Fault detection;Text categorization;Detectors;Writing;Chatbots;AI Content Detectors;Statistical Analysis;Inappropriate AI Use},
  doi={10.1109/URTC60662.2023.10534929},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10435711,
  author={Song, Wei and Gan, Lu and Bao, Tie},
  booktitle={2023 3rd International Conference on Communication Technology and Information Technology (ICCTIT)}, 
  title={Software Defect Prediction via Code Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={97-102},
  abstract={Software defect prediction has been effective practice to improve software quality and avoid attacks. Traditional defect prediction models with static or other features cannot understand syntactic and semantic structures well. Recently, large language models like GPT-series show impressive energy on considerable number of tasks. In the realm of software engineering, it has been shown that code language models largely benefit a broad set of code-related downstream tasks. In this paper, we employ code language models with distinct architectures for defect prediction. we propose a unified bi-modal input representation to enhance the comprehension of semantic information. Furthermore, a new bi-modal dataset is proposed based on the PROMISE repository and the engineering files. A large number of experiments are conducted on both within and cross project for evaluation and comparison. The results demonstrate the effectiveness of our proposed method for software defect prediction, which outperforms the state-of-the-art baselines. Among the three architectures, encoder-only achieve the most effective and efficient.},
  keywords={Codes;Semantics;Computer architecture;Predictive models;Syntactics;Software;Task analysis;software defect prediction;code language models;bi-modal representation;semantic information},
  doi={10.1109/ICCTIT60726.2023.10435711},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10956758,
  author={Mawardi, Viny Christanti and Kevin Jonathan, J M and Syahwalina, Jane and Monika, Sesilia and Widoatmodjo, Sawidji and Wijaya, Erik},
  booktitle={2024 Ninth International Conference on Informatics and Computing (ICIC)}, 
  title={Dataset Alignment for Fine-Tuning Large Language Models for PJOK Educational Chatbot}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={BERT is one of the methods in LLMs that can be used to build chatbots. The resulting chatbot is like a question-and-answer system. There are three main stages in adapting BERT for a specific domain: dataset collection, creation, and fine-tuning. BERT is one of the models that has been pre-trained on a very large corpus of text. For Indonesian, there is already IndoBert which has been pre-trained with 220 million words. If it can be adapted to a specific domain, then BERT needs to be fine-tuned with a new dataset that must be prepared in advance. In this research, a chatbot was created using the BERT method and collecting a dataset of PJOK subjects. In this research, a dataset was collected to meet the needs of an educational chatbot in the field of sports and health for elementary school students. The dataset collection involved students, teachers, and student assistants to align it with elementary school textbooks. The result of this research is an alignment dataset containing 300 elementary school physical education (PJOK) questions, complete with context sourced from textbooks. This research successfully produced an alignment dataset with an accuracy of 84 percent.},
  keywords={Training;Accuracy;Large language models;User interfaces;Data collection;Chatbots;Data models;Tokenization;Informatics;Sports;chatbot;BERT;dataset alignment;elementary;PJOK},
  doi={10.1109/ICIC64337.2024.10956758},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10541497,
  author={Tateiwa, Yuichiro},
  booktitle={2024 7th International Conference on Information and Computer Technologies (ICICT)}, 
  title={Development of Dialogue Feature between Participants and ChatGPT in Network Security Exercise System}, 
  year={2024},
  volume={},
  number={},
  pages={479-484},
  abstract={The author confirmed that ChatGPT can provide advice including specific implementation examples on computer network management by dialogue with ChatGPT. According to this confirmation, it is expected that in network security exercises, ChatGPT will be able to resolve participants' network troubles in place of instructors or teaching assistants. In the network security exercises provided by the author, participants perform various communication experiments in a virtual network consisting of virtual machines as nodes. This paper describes a method for collecting network configuration information and conveying it to ChatGPT based on a custom YANG model, as well as a user interface for facilitating dialogue between participants and ChatGPT.},
  keywords={Performance evaluation;Computational modeling;Unified modeling language;Prototypes;Network security;User interfaces;Chatbots;ChatGPT;Network;Security;e-learning;Exercise;YANG model;Large Language Models;Virtual Machine;Dialogue},
  doi={10.1109/ICICT62343.2024.00084},
  ISSN={2769-4542},
  month={March},}@ARTICLE{11020639,
  author={Cervantes, Pablo and Sekikawa, Yusuke and Sato, Ikuro and Shinoda, Koichi},
  journal={IEEE Access}, 
  title={Integrating Generative and Contrastive Approaches for Human Action Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This study introduces a novel approach to unsupervised skeleton-based human action recognition by integrating generative and contrastive learning methods. We propose a decomposition of representations, allowing for the preservation of detailed motion information for the generative learning objective while also extracting action features for the contrastive learning objective. By swapping contrastive representations between positive pairs (coining the name SwapCLR), we ensure that the generative and contrastive representations are complementary and both objectives contribute to learning a strong representation for downstream tasks like action recognition. Additionally, we address the challenge of noisy data in skeleton-based action recognition with a new saturating reconstruction loss, significantly reducing the impact of noise common to key-point detections. Our method demonstrates state-of-the-art performance in unsupervised action recognition on the NTU and PKU-MMD datasets, while also enabling generative downstream tasks such as motion in-painting and motion generation. Overall, these experimental results confirm the method’s effectiveness and suggest its applicability to a variety of action analysis tasks.},
  keywords={Reactive power;Noise;Training;Noise measurement;Skeleton;Contrastive learning;Data models;Training data;Three-dimensional displays;Human activity recognition;Generative and Contrastive;Representation Learning;Unsupervised 3D Action Recognition},
  doi={10.1109/ACCESS.2025.3575707},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10836262,
  author={Al-Ahmad, Ahmad and Kahtan, Hasan and Tahat, Luay and Tahat, Tarek},
  booktitle={2024 International Conference on Decision Aid Sciences and Applications (DASA)}, 
  title={Enhancing Software Engineering with AI: Key Insights from ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Artificial intelligence (AI) is currently a prominent topic in the field of software engineering. AI has greatly transformed software engineering by providing advanced tools that may boost the effectiveness and efficiency of various stages of the system development life cycle. In this paper, we examine the role of AI by focusing primarily on ChatGPT, an OpenAI language model. The research explores how ChatGPT can assist in software engineering tasks such as code generation, bug fixing, and documentation development. Through an analysis of real-world scenarios, the case study highlights the benefits and challenges of using AI tools in these three areas. The findings show that although AI can accelerate the output and simplify processes, its application must be carefully considered because it has issues in terms of lack of context awareness regarding performance considerations, project-specific requirements, its inability to access real-time logs or inspect environments, and its tendency to produce documentation that doesn't capture the necessary details for complex systems.},
  keywords={Productivity;Codes;Computer bugs;Documentation;Software quality;Chatbots;Real-time systems;Artificial intelligence;Software engineering;Software development management;Artificial Intelligence;Software Engineering;ChatGPT;Code Generation;Documentation Generation},
  doi={10.1109/DASA63652.2024.10836262},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10309699,
  author={Lee, Chang-Shing and Wang, Mei-Hui and Chen, Chih-Yu and Reformat, Marek and Nojima, Yusuke and Kubota, Naoyuki},
  booktitle={2023 IEEE International Conference on Fuzzy Systems (FUZZ)}, 
  title={Knowledge Graph-Based Genetic Fuzzy Agent for Human Intelligence and Machine Co-Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a novel approach for evaluating the co-learning performance of human intelligence (HI) and machine intelligence (MI) using a Knowledge Graph-based genetic fuzzy agent. The agent utilizes a Knowledge Graph structure to represent a specific knowledge domain related to human learning and employs a genetic fuzzy learning mechanism to construct a personalized learning model. Human learners can engage in co-learning with machines using state-of-the-art AI tools such as the Meta AI S2ST Taiwanese-English language model and the OpenAI ChatGPT text model. The proposed approach was evaluated using human learning data from an undergraduate computer science course and a series of Taiwanese and English language translation experience activities. The experimental results indicate that the proposed approach can effectively enhance the co-learning process for both human and machine learners.},
  keywords={Computer science;Learning systems;Human intelligence;Computational modeling;Speech recognition;Genetics;Chatbots;Knowledge Graph;Genetic Algorithm;Fuzzy Agent;MetaAI S2ST;Human Intelligence;OpenAI ChatGPT},
  doi={10.1109/FUZZ52849.2023.10309699},
  ISSN={1558-4739},
  month={Aug},}@ARTICLE{10718294,
  author={Feng, Wenyan and Li, Yuhang and Ma, Chunhao},
  journal={IEEE Access}, 
  title={Examining Non-English Foreign Language Education Through Social Media: Discourse and Psychological Analysis Based on Text Mining}, 
  year={2024},
  volume={12},
  number={},
  pages={152568-152578},
  abstract={Based on data from Weibo, the largest social media platform in China, this study employs a composite text mining approach to analyze public discussions about learning non-English foreign languages in recent years, with a focus on the emergence of ChatGPT as a pivotal influence. Through topic modeling and psychological characteristics analysis using the Linguistic Inquiry and Word Count (LIWC) dictionary, this research uncovers key topics and psychological traits associated with discussions on Weibo about non-English foreign language education. Identified topics include Employment, Regrets, Cultural Exchange, and Going Abroad, among others. Analysis of language use reveals significant shifts in psychological characteristics following the rise of ChatGPT, with complex interrelations between these traits and variations across different discussion phases. This study offers valuable insights into Chinese public interest in non-English foreign language education, contributing to the development and refinement of foreign language education in China. It also validates a composite methodology that can be applied to research on language education. The findings provide guidance for optimizing foreign language education in the context of rapidly evolving technology.},
  keywords={Psychology;Employment;Education;Blogs;Dictionaries;Text analysis;Classification algorithms;Chatbots;Virtual assistants;Videos;Natural languages;Linguistics;Non-English;foreign language education;psychological characteristics;topics;linguistic inquiry and word count (LIWC)},
  doi={10.1109/ACCESS.2024.3481049},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10645920,
  author={Dinu, Ion George and Mihăescu, Cristian and Rebedea, Traian},
  booktitle={2024 IEEE International Conference on Advanced Learning Technologies (ICALT)}, 
  title={Matching Problem Statements to Editorials in Competitive Programming}, 
  year={2024},
  volume={},
  number={},
  pages={171-175},
  abstract={Competitive programming presents challenges for students seeking to enhance programming and algorithmic skills. This research introduces a system that efficiently matches problem statements to editorials that describe the solution, helping students find relevant learning resources. The main component of this system is our learning-to-rank model, which achieves a P@1 score of 0.93, indicating its proficiency in identifying the most relevant editorial for a specific problem statement. While our model is smaller in scale compared to general models like GPT-4, it distinguishes itself with comparable results and notable computational efficiency. Additionally, we have developed a new dataset of 1550 competitive programming problem statements and their editorials. Integrated into a competitive programming platform, it has the potential to evolve into an adaptive learning system, customizing paths based on individual user performance. Our code and data are public at https://github.com/DinuGeorge0019/MatchingProblemStatementsToEditorialsInCP.},
  keywords={Analytical models;Adaptive learning;Adaptation models;Codes;Computational modeling;Source coding;Computational efficiency;learning system;competitive programming;learning-to-rank;text analysis;large language models;natural language processing;neural networks},
  doi={10.1109/ICALT61570.2024.00056},
  ISSN={2161-377X},
  month={July},}@INPROCEEDINGS{10685830,
  author={Lee, Lap-Kei and Chan, Eric Ho and Tong, Kyler Kin-Lik and Wong, Nardo Kwun-Hei and Wu, Ben Shing-Yan and Fung, Yin-Chun and Fong, Edmond King Sing and Leong Hou, U and Wu, Nga-In},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Utilizing Virtual Reality and Generative AI Chatbot for Job Interview Simulations}, 
  year={2024},
  volume={},
  number={},
  pages={209-212},
  abstract={Stress and anxiety experienced by interviewees, particularly fresh graduates, would significantly impact their performance in job interviews. Due to the increased affordability and user-friendliness of virtual reality (VR), VR has seen a surge in its application within the educational sector. This paper presents the design and implementation of a job interview simulation system, leveraging VR and a generative AI chatbot to provide an immersive environment for computer science graduates in Hong Kong. The system aims to help graduates practice and familiarize themselves with various real-world scenarios of a job interview in English, Mandarin, and Cantonese, tailored to the unique language requirements of Hong Kong’s professional environment. The system comprises three core modules: a mock question and answer reading module, an AI speech analysis module, and a virtual interview module facilitated by the generative AI chatbot, ChatGPT. We anticipate that the proposed simulator will provide valuable insights to education practitioners on utilizing VR and generative AI for job interview training, extending beyond computer science graduates.},
  keywords={Computer science;Training;Speech analysis;Generative AI;Anxiety disorders;Virtual reality;Educational technology;job interview simulation;virtual reality;generative AI;chatbot;human computer interaction},
  doi={10.1109/ISET61814.2024.00048},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10837603,
  author={Ward, Anthony and Manoharan, Sathiamoorthy and Ye, Xinfeng},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Exploring Academic Integrity in the Age of Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Traditionally, statistics suggest that around 30% of students resort to cheating when presented with the opportunity. This alarming trend often goes unnoticed by instructors, as many do not actively monitor for such misconduct. However, the onset of the pandemic saw a surge in cheating incidents, mainly due to the shift to online learning environments where supervision was more challenging. Despite this, instances of cheating remained detectable, albeit with some effort. As we transition out of the pandemic era, a new challenge has emerged in the form of generative AI technology, which has dramatically altered the landscape of academic dishonesty. With the advent of sophisticated generative AI models, it has become virtually impossible to discern between authentic student work and AI-generated content in unsupervised settings. Consequently, there has been a noticeable decline in detected cheating cases compared to pre-pandemic levels, largely attributed to the widespread use of generative AI tools. Traditional plagiarism detection software such as Turnitin and MOSS, once considered reliable safeguards against academic dishonesty, have become obsolete in the face of these advanced AI systems. The unique solutions produced by generative AI render such detection methods ineffective, posing a significant challenge to maintaining academic integrity in the modern educational landscape. This paper explores the nature of academic misconduct incidents in the context of two universities across the globe: one in the United Kingdom and the other in New Zealand.},
  keywords={Training;Generative AI;Pandemics;Plagiarism;Market research;Software;Software reliability;Surges;Information technology;Monitoring;academic integrity;generative AI;cheating incidents;student assessment;plagiarism detection},
  doi={10.1109/ITHET61869.2024.10837603},
  ISSN={2473-2060},
  month={Nov},}@ARTICLE{10530465,
  author={Muniyandi, Amutha Prabakar and Balusamy, Balamurugan and Dhanaraj, Rajesh Kumar and Ellappan, Vijayan and Murali, S. and Sathyamoorthy, Malathy and Nkenyereye, Lewis},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={Privacy Preserved Reinforcement Learning Model Using Generative AI for Personalized E-Learning}, 
  year={2024},
  volume={70},
  number={3},
  pages={6157-6165},
  abstract={Artificial intelligence algorithms are taking important roleplays in online recommendation models for achieving a high probability of success and these systems are slowly occupying modern learning systems. Modernized learning environments are designed based on personalized E-Learning system, due to the availability of enriched content and flexibility in the learning system. This paper proposed a personalized enriched course recommendation method for an e-learning environment using reinforcement techniques. The proposed method uses an Improved Artificial Bee Colony Optimisation (IABCO) algorithm-based generative AI model for preparing the course recommendations and this recommendation part will act as an Agent in the proposed personalized learning method. The proposed method uses IABCO algorithm for generating enriched course list based on personalized recommendation gather from customers and reinforcement learning model is used to evaluate the suggested course list. The proposed method is experimented with a dataset of online course offering website, which contains 3523 course details and 200 students are taken from various levels of learning maturity. The performance evaluation for the proposed system is measured based on success and accuracy rate of selection from the recommended course list. The average success rate and accuracy for the proposed method is 86.5% and 95.6% compared to the existing AI-based recommendation methods.},
  keywords={Electronic learning;Education;Artificial intelligence;Reinforcement learning;Recommender systems;Consumer electronics;Generative AI;Reinforcement learning;generative AI;artificial bee colony optimisation;privacy preserved learning system;course enriched learning system},
  doi={10.1109/TCE.2024.3398824},
  ISSN={1558-4127},
  month={Aug},}@ARTICLE{11006373,
  author={Ranjan, Sakshi and Mishra, Dheeraj and Singh, Sanjay Kumar},
  journal={IEEE Transactions on Computational Biology and Bioinformatics}, 
  title={Mitigating Catastrophic Forgetting in Molecular Property Prediction via Refresh Learning and Pareto Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={Continual Learning (CL) enables Large Language Models (LLMs) to adapt to new episodes and data streams without forgetting previously acquired knowledge, a critical requirement for dynamic fields like Molecular property Prediction (MP). LLMs, however, often face Catastrophic Forgetting (CF), where learning new information erodes prior knowledge, particularly when data distributions shift significantly between episodes, as seen in chemical, genomic, and proteomic datasets. To address CF, the existing replay-based techniques use memory buffers to store past episode data but often overlook the relationships between episodes, resulting in sub-optimal performance when revisiting earlier episodes. To this, the paper proposes a Multi-task Learning (MTL) framework that reconciles existing CL techniques into a unified hierarchical gradient aggregation framework. It builds a novel framework using the ChemBERTa model, namely MTL-PORL (Multi-task Learner-Pareto Optimized Refresh Learning), i.e., Refresh Learning (RL), inspired by neuroscience, where the brain discards outdated information to enhance retention and facilitate new learning with Pareto Optimization (PO) for MP. The hyper-gradient approach in the MTL-PORL leverages unlearning current data before relearning it, acting as a flexible plug-in that enhances existing CL methods. The MTL-PORL exhibits Anytime Average Accuracy (91.63%, 94.89%, and 92.67%), Test Accuracy (92.48%, 96.48%, and 96.86%), and Forgetting Measure (-0.0048, -0.0045, and -0.0063) on the BBBP, bitter, and sweet datasets, respectively. The comprehensive empirical analysis highlighted significant improvements in sequential learning compared to existing methods, addressing the stability-plasticity trade-off and effectiveness of RL.},
  keywords={Adaptation models;Drugs;Computational modeling;Data models;Predictive models;Drug discovery;Diffusion tensor imaging;Multitasking;Bioinformatics;Pareto optimization;Drug Discovery;Refresh Learning;Catastrophic Forgetting;Multi-task Learner;Simplified Input Line Entry System (SMILES)},
  doi={10.1109/TCBBIO.2025.3571046},
  ISSN={2998-4165},
  month={},}@INPROCEEDINGS{10975892,
  author={Zhong, Chaocheng and Ye, Feihong and Wang, Zihan and Jigeer, Aerman and Zhan, Zehui},
  booktitle={2025 14th International Conference on Educational and Information Technology (ICEIT)}, 
  title={Interdisciplinary-QG: An LLM-Based Framework for Generating High-Quality Interdisciplinary Test Questions with Knowledge Graphs and Chain-of-Thought Reasoning}, 
  year={2025},
  volume={},
  number={},
  pages={68-78},
  abstract={As interdisciplinary education gains prominence in global educational reforms, the design of high-quality interdisciplinary test items remains a challenge due to the complexity of knowledge integration, question difficulty control, and the inefficiency of manual generation. To address these issues, this study introduces Interdisciplinary-QG, an automated interdisciplinary question generation framework based on GPT-4. The framework integrates knowledge graph-enhanced retrieval-based generation with chain-of-thought reasoning and employs a structured BRTE (Background-Role-Task-Example) prompt template, enhancing both accuracy and interdisciplinary coherence. A case study in chemistry demonstrates that Interdisciplinary-QG effectively constructs interdisciplinary knowledge structures and generates high-quality test items with both depth and breadth. Experimental results show that it outperforms the general-purpose LLM ChatGLM in validity, efficiency, and interdisciplinary integration. This study provides new insights into leveraging AI for interdisciplinary education.},
  keywords={Chemistry;Large language models;Education;Knowledge graphs;Manuals;Coherence;Question generation;Cognition;Complexity theory;Information technology;Interdisciplinary Education;Automated Question Generation;Large Language Models;Knowledge Graphs},
  doi={10.1109/ICEIT64364.2025.10975892},
  ISSN={},
  month={March},}@INPROCEEDINGS{10401848,
  author={Elshiny, Reyam Magdy and Hamdy, Abeer},
  booktitle={2023 International Conference on Computer and Applications (ICCA)}, 
  title={Automatic Question Generation Using Natural Language Processing and Transformers}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Online education’s rapid growth and the rise of E-learning tools have raised the demand for creating assessments and challenging questions for learners which require significant effort to create suitable content for testing. Consequently, automatic question generation aims to automate the creation of different types of questions in the shortest period of time possible by applying minimal human effort all using natural language processing and transformers. This paper proposes different methodologies to generate questions like true or false, fill in the blanks, matching, multiple-choice, and “Wh-” questions specified from a given context. Transformer models including GPT, T5, and BERT are used to achieve the methodologies needed to generate such questions. The system, tested through surveys, generated an 80% satisfaction rate among teacher participants and showed potential to generate questions similar to ChatGPT’s.},
  keywords={Surveys;Electronic learning;Transformers;Libraries;Tuning;Context modeling;Testing;transformers;question generation;natural language processing;GPT;BERT;T5},
  doi={10.1109/ICCA59364.2023.10401848},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10837671,
  author={Nafil, Khalid and Lefdaoui, Youssef},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={Innovative Approach to Agile Education: Generative AI-Supported Planning Poker Simulation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study investigates the integration of generative AI into the Scrum planning poker process within an educational environment. Through the Character.ai platform, Students interacted with AI agents, including a Scrum Master and three Developers, using their mobile devices to conduct Planning Poker sessions. Quantitative criteria were developed to assess Agent interactions, Student participation, Collaboration, Communication, and Decision-making Patterns. Initial findings reveal encouraging levels of Student engagement and effective utilization of AI-supported techniques during the sessions. These results highlight the potential of generative AI to enhance educational experiences, particularly within the context of Agile project management methodologies.},
  keywords={Training;Generative AI;Decision making;Collaboration;Agile project management;Mobile handsets;Planning;Information technology;Planning Poker;Scrum;Character.ai;Generative AI;Education},
  doi={10.1109/ITHET61869.2024.10837671},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10892813,
  author={Baradari, Dünya and Han, Harry and Xia, Julia and Strelecki, Carey Ann},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Beyond Imagination: Leveraging Generative AI to Enhance Learning Through Story World Analogies}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This innovative practice full paper describes ConceptualTales, a conversational AI that explains STEM and social science concepts using analogies from popular story worlds and Socratic reasoning. The disconnect between conventional teaching strategies and student engagement is a persistent challenge in educational systems, particularly STEM fields. Traditional methods often fail to resonate with students, rendering the learning process monotonous and detached from their personal interests. Concurrently, students are enthusiastic about and dedicated to fictional worlds such as Marvel, Harry Potter, and Disney. This observation forms the basis for our innovative practice: integrating these beloved narratives into educational content through generative AI. ConceptualTales was tried with middle and high school students in the USA and China and received overwhelmingly positive feedback. Our system combines fiction-inspired learning, analogical reasoning, and Socratic questions, to make educational content personal and interesting to students.},
  keywords={Conversational artificial intelligence;Generative AI;Social sciences;Education;Rendering (computer graphics);Cognition;STEM;analogies;concepts;generative AI;story worlds;narratives;artificial intelligence in education (AIinEd)},
  doi={10.1109/FIE61694.2024.10892813},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10387629,
  author={Vaid, Abhishek and Andreopoulos, William B.},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Real-Time Attention-Based Conversational Agent}, 
  year={2023},
  volume={},
  number={},
  pages={114-117},
  abstract={Neural Machine Translation (NMT) is a prominent natural language processing technique that is being used to develop conversational AI technology. Traditional industrial chatbots often rely on scripted responses and lack the ability to provide real-time data-driven interactions. Developing advanced AI chatbots like Google Bard or ChatGPT are out of reach for smaller or medium-sized organizations due to their scale and associated costs. Chatbots are majorly restricted by the data on which they were trained on and have no knowledge of current events. This research project intends to research and develop an approach that enables chatbots to provide live and up-to-date information in their responses and can be developed in minimalistic costs so that even smaller or medium-level organizations can afford to provide interactive AI chatbots. We experiment with various techniques in terms of the type of data being used to harness live capabilities. We focus on optimizing the hyperparameters required for building a conversational AI agent and leverage open-source technologies to minimize costs. To ensure flexibility and affordability, we adopt a microservice architecture that combines Attention based NMT models and Transformer Models with live API services features, leveraging the RASA actions API. This approach allows us to develop a prototype of an advanced chatbot that goes beyond the traditional scripted responses by providing real-time information to users and being affordable to develop.},
  keywords={Costs;Microservice architectures;Prototypes;Organizations;Chatbots;Transformers;Real-time systems;Neural Machine Translation;Conversational AI},
  doi={10.1109/TransAI60598.2023.00028},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11022196,
  author={Du, Haizhou and Li, Wenhao and Ding, Xiaoyu and Huo, Huan},
  booktitle={2024 8th Asian Conference on Artificial Intelligence Technology (ACAIT)}, 
  title={Can LLMs Understand Parallel and Distributed Machine Learning Algorithms in AIoT?}, 
  year={2024},
  volume={},
  number={},
  pages={501-510},
  abstract={The Internet of Things technology has evolved from standalone tools to open systems supporting parallel and distributed computing. In particular, federated learning (FL) has become a key solution as a distributed team of parallel training methods in the artificial intelligence of things (AIoT). Academia and industry formed a significant consensus on efficient reproducing and rapidly deploying federated learning in the AIoT. The current best practice typically resorts to three approaches: 1) looking for publicly open-source algorithmic prototypes, 2) contacting the authors to get a private prototype, and 3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes, and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor-consuming and error-prone. In this paper, we propose reproducing FL research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with an experiment in which three students with essential parallel and distributed machine learning knowledge reproduce different FL algorithms published in prominent conferences and journals by prompt engineering ChatGPT-4. Finally, our experimental results focus on the efficiency and quality of reproducing code. We report the experiment’s observations and discuss future open research questions of this paper. Additionally, we verify the better robustness of reproduced codes with different data poisoning attacks via extensive experiments. This work also raises no ethical issue.},
  keywords={Training;Machine learning algorithms;Codes;Federated learning;Large language models;Prototypes;Transforms;Robustness;Internet of Things;Artificial intelligence;large language models;federated learning;algorithm reproducibility;distributed machine learning},
  doi={10.1109/ACAIT63902.2024.11022196},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10662985,
  author={Liao, Yiwen and Jiang, Yuchao and Chen, Zhangpeng and Suleiman, Basem},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={FeedbackPulse: GPT-Enabled Feedback Assistant for Software Engineering Educators}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={In response to the growing enrolment in software engineering programs, there is a pressing need for scalable methods to provide effective feedback for students. We designed a GPT-driven interactive assistant, FeedbackPulse, to aid educators in delivering high-quality feedback and alleviating their workload. FeedbackPulse provides real-time, personalised feedback suggestions to educators for improving their feedback to students. Preliminary evaluations of FeedbackPulse in a software engineering course have demonstrated its promising capabilities.},
  keywords={Pressing;Real-time systems;Software engineering},
  doi={10.1109/CSEET62301.2024.10662985},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10963119,
  author={Upeksha, Sanduni and Samarasinghe, Dumindu T. and Sanochana, Mithun and Samarathunga, Sapni S. and Rajamanthri, Lochana and Samarakkody, Takshila and Aluthwala, Chathuni},
  booktitle={2025 5th International Conference on Advanced Research in Computing (ICARC)}, 
  title={The Influence of Generative AI on work-life balance among female software professionals in Sri Lanka}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores the role of generative artificial intelligence on work-life balance among female software professionals in Sri Lanka's software industry. This qualitative study explores the influence of Generative Artificial Intelligence (GenAI) tools on workload, productivity, and overall well-being to show how these technologies uniquely shape professional and personal lives within this demographic group. Data were gathered through semi-structured interviews with 15 female software professionals from various job roles, including software engineers, quality assurance engineers, system engineers, Development and Operations (DevOps) engineers, and project managers. Using thematic analysis, findings disclose that generative AI is mostly utilized for automation, communication and collaboration, creativity and innovation, and decision support, with ChatGPT being the most widely used tool. These tools will enable professionals to streamline the workload, increase efficiency, reduce overtime, and maintain healthy working conditions. The insights of this study yield important implications for employers and government organizations such as the Department of Labor, explicitly pointing out how generative AI can be instrumented to create a favorable work environment. Thus, by applying generative AI solutions, the key stakeholders of the Sri Lankan software industry can create work conditions crucial for the work-life balance of women to enhance organizational performance as well as the work-related well-being of female software professionals.},
  keywords={Industries;Productivity;Employee welfare;Training;Technological innovation;Generative AI;Software;Teamwork;Stakeholders;Creativity;Female Software Professionals;Generative AI;Software Industry;Work-Life Balance},
  doi={10.1109/ICARC64760.2025.10963119},
  ISSN={},
  month={Feb},}@INBOOK{10952278,
  author={Orange, Erica},
  booktitle={AI + The New Human Frontier: Reimagining the Future of Time, Trust + Truth}, 
  title={Shifting from Education to Learning}, 
  year={2024},
  volume={},
  number={},
  pages={170-176},
  abstract={Summary <p>At the older ages, schools and educational institutions in the United States and elsewhere are announcing bans on ChatGPT out of fear that students could use the technology to complete their assignments. Learning for Justice's digital literacy framework sheds light on crucial focus areas that educators and students must address when integrating AI into education. The changing world of work brings the importance of vocational education and training to the forefront. A 2023 Intelligent.com survey finds 1 in 6 Gen Zers may switch from white&#x2010;collar to blue&#x2010;collar jobs due to fears about AI. The way Gen Alphas interact with robots and voice&#x2010;activated devices is beginning to represent a more complex relationship&#x2014;often an emotional one. As more toys teach coding and programming, non&#x2010;digital toys that incorporate kinesthetic learning are a good way to enhance creativity, design thinking, personal expression, and conceptualization.</p>},
  keywords={Artificial intelligence;Education;Chatbots;Engineering profession;Encoding;Brain modeling;Vocational training;Technological innovation;Surveys;Software},
  doi={},
  ISSN={},
  publisher={Wiley},
  isbn={9781394276998},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10952278},}@INPROCEEDINGS{10882269,
  author={Waikar, Rahul and Tamhane, Shraddhesh and Tale, Tanmai and Talekar, Rujul and Tangde, Ayush and Singla, Tanish and Kalokhe, Tanishka},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Student Career Guidance Using Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This conceptualisation involves developing an online application software that incorporates generative AI in providing counselling information on career based on the users' interests, skills and expectations. Face to face counselling on the other hand has its constraints in terms of scale and accessibility but this form of career counseling by use of the present artificial intelligence also aspires to break barriers and provide a leveling ground for all students. This information includes the grade level, expected career, academic interests, skills, and hobbies users offer. The AI provides and explains several occupations, good as well as specific ones, which enables students to consider more jobs. It also provides the best colleges available, required degrees, expected income and future scope. When career awareness has been limited to competitive fields, the application enables students to think pragmatically about the options available to them. The HTML, CSS, and JavaScript-based user interface enables the input of several attributes by students and reception of associated AI career suggestions. The inputs are then passed through a generative AI API running on a Node server to improve the usability of the response. This innovative method teaches students using artificial intelligence and using behavioral counseling principles and provides students with clear, evidence-based information regarding their future occupations.},
  keywords={Employee welfare;Hands;Quantum computing;Engineering profession;Generative AI;User interfaces;Servers;Application software;Usability;Faces;API;Career guidance;Generative AI;Node.js;Web-based application},
  doi={10.1109/ICAIQSA64000.2024.10882269},
  ISSN={},
  month={Dec},}@BOOK{10769388,
  author={Dell, Dr. Scott and Akpan, Dr. Mfon},
  booktitle={ChatGPT and AI for Accountants: A practitioner's guide to harnessing the power of GenAI to revolutionize your accounting practice},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Elevate your accounting skills by applying ChatGPT across audit, tax, consulting, and beyondKey FeaturesLeverage the impact of AI on modern accounting, from audits to corporate governanceUse ChatGPT to streamline your accounting tasks with practical hands-on techniquesUnderstand the impact of AI in accounting through in-depth chapters covering various domains, including ethical considerations and data analyticsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionIn the fast-paced AI world, accounting professionals are increasingly challenged by the complexities of AI. Many struggle to integrate these advanced tools into their workflows, leading to a sense of overwhelm. ChatGPT for Accounting bridges this gap by not only simplifying AI concepts but also offering practical insights for its application in various accounting domains. This book takes you from the foundational principles of Generative Artificial Intelligence (GAI) to its practical applications in audits, tax planning, practice management, fraud examination, financial analysis, and beyond. Each chapter equips you with essential skills, showing you how AI can revolutionize internal control systems, enhance recruitment processes, streamline marketing plans, optimize tax strategies, and boost efficiency in audits. You’ll then advance to exploring the role of AI in forensic accounting, financial analysis, managerial accounting, and corporate governance, while also addressing ethical and security implications. Concluding with a reflective outlook on the promises and challenges of AI, you’ll gain a holistic view of the future of accounting. By the end of this book, you’ll be equipped with the knowledge to harness the power of AI effectively and ethically, transforming your accounting practice and staying ahead in the ever-evolving landscape.What you will learnUnderstand the fundamentals of AI and its impact on the accounting sectorGrasp how AI streamlines and enhances the auditing process for high accuracyUncover the potential of AI in simplifying tax processes and ensuring complianceGet to grips with using AI to identify discrepancies and prevent financial fraudMaster the art of AI-powered data analytics for informed decision-makingGain insights into seamlessly integrating AI tools within existing accounting systemsStay ahead in the evolving landscape of AI-led accounting tools and practicesWho this book is forWhether you're a seasoned accounting professional, a C-suite executive, a business owner, an accounting educator, a student of accounting, or a technology enthusiast, this book provides the knowledge and insights you need to navigate the changing landscape in applying GAI technology to make a difference in all you do. An appreciation and understanding of the accounting process and concepts will be beneficial.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781835462256},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769388},}@INPROCEEDINGS{10172807,
  author={Ronanki, Krishna},
  booktitle={2023 IEEE/ACM 45th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)}, 
  title={Towards an AI-centric Requirements Engineering Framework for Trustworthy AI}, 
  year={2023},
  volume={},
  number={},
  pages={278-280},
  abstract={Ethical guidelines are an asset for artificial intel-ligence(AI) development and conforming to them will soon be a procedural requirement once the EU AI Act gets ratified in the European parliament. However, developers often lack explicit knowledge on how to apply these guidelines during the system development process. A literature review of different ethical guidelines from various countries and organizations has revealed inconsistencies in the principles presented and the terminology used to describe such principles. This research begins by identifying the limitations of existing ethical AI development frameworks in performing requirements engineering(RE) processes during the development of trustworthy AI. Recommendations to address those limitations will be proposed to make the frameworks more applicable in the RE process to foster the development of trustworthy AI. This could lead to wider adoption, greater productivity of the AI systems, and reduced workload on humans for non-cognitive tasks. Considering the impact of some of the newer foundation models like GitHub Copilot and ChatGPT, the vision for this research project is to work towards the development of holistic operationalisable RE guidelines for the development and implementation of trustworthy AI not only on a product level but also on process level.},
  keywords={Productivity;Ethics;Terminology;Organizations;Requirements engineering;Artificial intelligence;Task analysis;Trustworthy AI;EU AI Act;Requirements Engineering;Frameworks;AI co-worker;Ethical AI;Guidelines},
  doi={10.1109/ICSE-Companion58688.2023.00075},
  ISSN={2574-1934},
  month={May},}@INPROCEEDINGS{10773545,
  author={P, Vedanta S and Rao, Madhav},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={PsychSynth: Advancing Mental Health AI Through Synthetic Data Generation and Curriculum Training}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The number of Mental-health help seekers are on rise over recent years, but the medical practitioners are limited due to which the healthcare system is heavily loaded and thereby the outcome is not promising. Advanced AI Technology is expected to ease this problem, however completely relying on the tools is reported to not work with the help seekers. Hence technology to assist help seekers and allow the healthcare system to screen the needy ones from the large pool of distress candidates should make the system efficient a nd effective.H owever for establishing the AI supportive system, two challenges exists: one is the large pool of dataset with diversity, and other is the AI model to respond to a context-aware situations. Expecting large dataset for training model from medical community needs further infrastructure support to make it digitally available with embedded annotations. Relying patiently for the dataset will miss the opportunity to serve the distress patients. Hence synthetic dataset generation and its validation from medical experts is an alternative for training robust and reliable model. Besides, context-aware curriculum inspired AI based summarizer model is found appropriate to adopt for this use-case where relevant features meant for diagnosing the problem is extracted from the improvised input text. The proposed curriculum trained AI model helps in transforming the improvised text inputs fed from the distress individuals to a summarized version representing domain expert form, embedded with symptoms related features for further classification. The synthetic data-set g eneration through OpenAI's GPT-40 models and Nemotron models are further evaluated with BERT based classifier m odels a nd curriculum based AI model. The training of the classifier m odels are also evaluated for synthetic and real-world dataset, which was scrapped from Reddit forum. Around 800 stream of real-world posts were evaluated from the medical experts and their findings related to sympotoms and annotations were employed to fine-tune the classifier and summarizer m odel. It was found t hat the fine-tuned models and training of BERT models from the merged dataset composed of synthetic ones with the medical practitioners annotated dataset were found to perform better than others. The summarizer model fetching shorter version of domain expert output enhanced the classification accuracy by 5 % for the real-world data. The effort is a step towards developing AI assistant to screen large posts of submissions from distress individuals and arrange for the necessary connects for the needy ones with the medical experts. The models and pruned datasets are made freely available for further usage to the researchers community.},
  keywords={Training;Adaptation models;Accuracy;Social networking (online);Computational modeling;Feature extraction;Data models;Artificial intelligence;Medical diagnostic imaging;Synthetic data;Generative AI;GPT;Synthetic Data;Domain Expert;Curriculum based;Summarizer model;BERT;Context-A ware;Mental Health;Distress},
  doi={10.1109/UBMK63289.2024.10773545},
  ISSN={2521-1641},
  month={Oct},}
@INPROCEEDINGS{10578921,
  author={},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={CodeWizardry}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={Gamification stands as a promising remedy to the challenges posed by traditional e-learning systems, as it advocates for the infusion of game elements and mechanisms to elevate motivation, engagement, and the overall learning experience for students. The concept of gamification in e-learning represents a paradigm shift, proposing a transition from traditional methods towards to more interactive approach. By seamlessly integrating game elements, educators aim to not only enhance motivation but also foster a deeper understanding of the subject matter by making the learning process more playful. Meanwhile, the introduction of ChatGPT into academic environments has sparked intense discussions on its transformative potential. Its versatile capabilities across various writing styles raise questions about the implications for creativity, originality, and the role of human intellect in the face of advancing AI technologies. The rapid ascent of ChatGPT, marked by its overwhelming success within a short span, underscores the urgent need for a comprehensive examination of the impact and ethical considerations associated with. For all the above, we propose “CodeWizardy” as an innovative platform for learning programming by mixing in games and AI.},
  keywords={Chatbots;Education;Codes;Games;Artificial intelligence;Problem-solving;Encoding;Gamification;Artificial Intelligence;ChatGPT;E-learning;Gamified Teaching Method},
  doi={10.1109/EDUCON60312.2024.10578921},
  ISSN={2165-9567},
  month={May},}@BOOK{10695822,
  author={Sidahmed, Elandaloussi and Pascale, Zaraté},
  booktitle={Strategic Support Systems for Crisis Management: A Literature Review},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Strategic Support Systems for Crisis Management presents a literature review of Strategic Decision Support Systems (SDSS). The chosen SDSS case study is COVID-19 crisis management and its impact on sectors such as health, education, and the economy. This monograph addresses the following questions: What are the different architectures of defined Strategic DSS and which SDSS is better to deal with each crisis? The monograph begins by discussing a comprehensive methodology for the literature review and providing an overview of the study background. Section 4 is devoted to discussing the most important studies in SDSS technologies. SDSS models are presented in Section 5. Section 6 explores the application of generative AI, and specifically ChatGPT, in the context of COVID-19 pandemic decision support systems. Section 7 provides a brief discussion of the conducted surveys. Finally, Section 8 summarizes the monograph and provides some concluding remarks.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638283935},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10695822},}@ARTICLE{10985773,
  author={Adornetto, Carlo and Mora, Adrian and Hu, Kai and Garcia, Leticia Izquierdo and Atchade-Adelomou, Parfait and Greco, Gianluigi and Pastor, Luis Alberto Alonso and Larson, Kent},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Generative Agents in Agent-Based Modeling: Overview, Validation, and Emerging Challenges}, 
  year={2025},
  volume={},
  number={},
  pages={1-20},
  abstract={The advent of Generative Agents (GAs) based on Large Language Models (LLMs) has significantly influenced the evolution of Agent-Based Modeling (ABM), offering new perspectives across various domains, including engineering and social sciences. This paper provides an extensive overview of the integration of GAs into ABMs, emphasizing the advancements and emerging challenges in their validation. Traditional ABMs, characterized by their simplistic yet powerful approach to modeling complex systems, have been redefined with the introduction of GAs. This new generation of agents is often equipped with conversational capabilities. These agents, capable of simulating believable human behaviors and interactions, present unique opportunities and hurdles, especially in urban simulations and social dynamics. We explore the nuanced differences between traditional ABMs and ABMs populated by GAs—called GABMs. We delve into the state-of-the-art implementations of GAs, and review various validation methods. Through this comprehensive examination, we aim to shed light on the potential and limitations of GAs, advocating for the design of hybrid ABM-GABM approaches and systematic validation.},
  keywords={Biological system modeling;Behavioral sciences;Reviews;Urban areas;Large language models;Terminology;Predictive models;Media;Mathematical models;Decision making;Agent-Based Models;Generative Agents;Generative AI;Large Language Models},
  doi={10.1109/TAI.2025.3566362},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{10386894,
  author={Kumar, Akit and Lakshmi Devi, M.S. and Saltz, Jeffrey S.},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Bridging the Gap in AI-Driven Workflows: The Case for Domain-Specific Generative Bots}, 
  year={2023},
  volume={},
  number={},
  pages={2421-2430},
  abstract={The widespread adoption of generative AI tools, such as ChatGPT, has resulted in its extensive use in a broad range of situations. However, language models often generate inaccurate or misleading responses, negatively impacting its use. Developing domain-specific bots for specific work situations could enhance accuracy and robustness, enabling more effective use of Generative AI in a work context. To help explore this possibility, we developed a data science process-expert generative AI assistant (bot) and evaluated its efficacy. We observed that the bot significantly improved efficiency, guided the exploration of new concepts within data science project management, and fostered creativity. Moreover, the constant availability of the bot allowed access to expertise whenever needed. Furthermore, responses indicated people viewed the bot as a collaborative tool that enabled communication and comprehension of complex questions. In addition, a Likert-scale analysis showed that the bot has the potential to impact the data science field positively. In summary, this research underscores the value of domain-specific bots and the potential impact on data science project management, as well as in other domains.},
  keywords={Generative AI;Collaborative tools;Project management;Data science;Big Data;Chatbots;Robustness;Data Science;Generative AI;CRISP-DM;Chat Bots},
  doi={10.1109/BigData59044.2023.10386894},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10292037,
  author={Rukmono, Satrio Adi and Ochoa, Lina and Chaudron, Michel R.V.},
  booktitle={2023 IEEE International Conference on Data and Software Engineering (ICoDSE)}, 
  title={Achieving High-Level Software Component Summarization via Hierarchical Chain-of-Thought Prompting and Static Code Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={7-12},
  abstract={Comprehension of software systems is key to their successful maintenance and evolution. This comprehension comes at different levels of abstraction: At the low level, one must focus on comprehending functions; while at the high level, one must abstract and comprehend the system's requirements. Diverse Automated Source Code Summarization (ASCS) techniques have been proposed to comprehend systems at the lower level. However, techniques for abstracting higher-level explanations fall short. Research on related fields, such as software architecture recovery, has tried to address system comprehension at the higher level by attempting to detect abstractions of design decisions from source code. Nevertheless, this is an on-going effort and many steps in the process are still unsolved. In this paper, we lever-age the emergent abilities of Large Language Models (LLMs) together with the achievements in the ASCS and static code analysis fields to design an approach that produces component-level summaries of software systems. Particularly, we address the unreliability of LLMs in performing reasoning by applying a chain-of-thought prompting strategy, which allows us to emulate inductive reasoning. We follow a bottom-up approach, where we start by comprehending lower-level software abstractions (e.g., functions), and then we compose these findings-in a cascading style-to comprehend higher-level ones (e.g., classes, components). We demonstrate the feasibility of our approach by applying it to the open-source Java project JHotDraw version 5.1. We believe our approach offers a stepping stone in developing robust automated software summarization approaches that can be applied generally across domains and types of software system.},
  keywords={Analytical models;Java;Codes;Software architecture;Source coding;Maintenance engineering;Software systems;comprehension of software systems;automated source code summarization;static analysis;large language models;chain-of-thought prompting},
  doi={10.1109/ICoDSE59534.2023.10292037},
  ISSN={2640-0227},
  month={Sep.},}@INPROCEEDINGS{10430054,
  author={Liu, Jinrun and Tang, Xinyu and Li, Linlin and Chen, Panpan and Liu, Yepang},
  booktitle={2023 IEEE 23rd International Conference on Software Quality, Reliability, and Security Companion (QRS-C)}, 
  title={ChatGPT vs. Stack Overflow: An Exploratory Comparison of Programming Assistance Tools}, 
  year={2023},
  volume={},
  number={},
  pages={364-373},
  abstract={Programmers often seek help from Q&A websites to resolve issues they encounter during programming. Stack Overflow has been a widely used platform for this purpose for over a decade. Recently, revolutionary AI-powered platforms like ChatGPT have quickly gained popularity among programmers for their efficient and personalized programming assistance via natural language interactions. Both platforms can offer valuable assistance to programmers, but it's unclear which is more effective at enhancing programmer productivity. In our paper, we conducted an exploratory user study to compare the performance of Stack Overflow and ChatGPT in enhancing programmer productivity. Two groups of students with similar programming abilities were instructed to use the two platforms to solve three different types of programming tasks: algorithmic challenges, library usage, and debugging. During the experiments, we measured and compared the quality of code produced and the time taken to complete tasks for the two groups. The results show that, concerning code quality, ChatGPT outperforms Stack Overflow significantly in helping complete algorithmic and library-related tasks, while Stack Overflow is better for debugging tasks. Regarding task completion speed, the ChatGPT group is obviously faster than the Stack Overflow group in the algorithmic challenge, but the two groups have a similar performance in the other two tasks. Additionally, we conducted a post-experiment survey with the participants to understand how the platforms have helped them complete the programming tasks. We analyzed the questionnaires to summarize ChatGPT and Stack Overflow's strengths and weaknesses pointed out by the participants. By comparing these, we identified the reasons behind the two platforms' divergent performances in programming assistance.},
  keywords={Productivity;Codes;Debugging;Programming;Chatbots;Libraries;Task analysis;ChatGPT;Stack Overflow;programming;user study},
  doi={10.1109/QRS-C60940.2023.00105},
  ISSN={2693-9371},
  month={Oct},}@ARTICLE{10945362,
  author={Aloudat, Mohammad Z. and Aboumadi, Abdulla and Soliman, Abdelrahman and Al-Mohammed, Hasan Abbas and Al-Ali, Muhammed and Mahgoub, Asma and Barhamgi, Mahmoud and Yaacoub, Elias},
  journal={IEEE Access}, 
  title={Metaverse Unbound: A Survey on Synergistic Integration Between Semantic Communication, 6G, and Edge Learning}, 
  year={2025},
  volume={13},
  number={},
  pages={58302-58350},
  abstract={With a focus on edge learning, blockchain, sixth generation (6G) wireless systems, semantic communication, and large language models (LLMs), this survey paper examines the revolutionary integration of cutting-edge technologies within the metaverse. This thorough examination highlights the critical role these technologies play in improving realism and user engagement on three main levels: technical, virtual, and physical. While the virtual layer focuses on building immersive experiences, the physical layer highlights improvements to the user interface through augmented reality (AR) goggles and virtual reality (VR) headsets. Blockchain-powered technical layer enables safe, decentralized communication. The survey highlights how the metaverse has the potential to drastically change how people interact in society by exploring applications in a variety of fields, such as immersive education, remote work, and entertainment. Concerns about privacy, scalability, and interoperability are raised, highlighting the necessity of continued study to realize the full potential of the metaverse. For scholars looking to broaden the reach and significance of the metaverse in the digital age, this paper is a useful tool.},
  keywords={Metaverse;Surveys;Semantic communication;6G mobile communication;Blockchains;Digital twins;Large language models;Wireless communication;Systematic literature review;Internet;Metaverse;semantic communication;6G wireless systems;edge learning;blockchain technology;large language models (LLMs);extended reality (XR);digital twin technology},
  doi={10.1109/ACCESS.2025.3555753},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10892994,
  author={Neupane, Subash and Hossain, Elias and Keith, Jason and Tripathi, Himanshu and Ghiasi, Farbod and Golilarz, Noorbakhsh Amiri and Amirlatifi, Amin and Mittal, Sudip and Rahimi, Shahram},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={From Questions to Insightful Answers: Building an Informed Chatbot for University Resources}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This research-to-practice full paper presents Bark-plug v.2, a Large Language Model (LLM)-based chatbot system built using Retrieval Augmented Generation (RAG) pipelines to enhance the user experience and access to information within academic settings. The objective of Barkplug v.2 is to provide information to users about various campus resources, including academic departments, programs, campus facilities, and student resources at a university setting in an interactive fashion. Our system leverages university data as an external data corpus and ingests it into our RAG pipelines for domain-specific question-answering tasks. We evaluate the effectiveness of our system in generating accurate and pertinent responses for Mississippi State University, as a case study, using quantitative measures, employing frameworks such as Retrieval Augmented Generation Assessment (RAGAS). Furthermore, we evaluate the usability of this system via subjective satisfaction surveys using the System Usability Scale (SUS). Our system demonstrates impressive quantitative performance, with a mean RAGAS score of 0.96, and satisfactory user experience, as validated by usability assessments.},
  keywords={Surveys;Measurement;Accuracy;Large language models;Retrieval augmented generation;Pipelines;Chatbots;User experience;Reliability;Usability;Chatbot;LLM;RAG;University resources;information access},
  doi={10.1109/FIE61694.2024.10892994},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10549015,
  author={Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering}, 
  year={2024},
  volume={},
  number={},
  pages={2270-2282},
  abstract={Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
  keywords={Productivity;Uncertainty;Generative AI;Navigation;Chatbots;Task analysis;Standards;Empirical Study;Software Engineering;Generative AI;ChatGPT},
  doi={10.1145/3597503.3639201},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10115963,
  author={Oh, Jane M. C. and Trettel, Ian A. and Fifield, Michael G. and Scandore, Steve F.},
  booktitle={2023 IEEE Aerospace Conference}, 
  title={Mars Project Software Systems Engineering Improvements}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={Increasingly challenging missions are characterized by an expansion of the mission-critical role of software. In the Mars projects, Entry, Descent, and Landing (EDL) are software controlled. EDL relies on software timing and functionality, leading to such things as second chance flight software operating as a copilot on the backup flight computer. Therefore, much of the project risk lies in robustness of software. Within the laboratory, the Project Software Systems Engineering (PSSE) has the responsibility of planning, systems engineering, and overseeing all project software while development organizations deliver domain specific software, such as Command & Data Handling (C&DH) software, Sample Recovery Helicopter (SRH), Guidance, Navigation, & Control (GN&C) software, Vision Compute Element (VCE) software, Ground Data System (GDS) software, Simulation Support Equipment (SSE) software, etc. The software lifecycle chosen for Mars project software development is the incremental lifecycle, wherein the content and scope of each software release will be built upon the delivered capabilities of previous releases to achieve incremental functionality. In this context, the challenge stems from the surge in detail and complexity where current software systems engineering practices will be hard-pressed to keep up. This paper describes an assessment of software systems engineering processes, specifically in the NASA Mars Science Laboratory Curiosity Rover, Mars 2020 Perseverance Rover, and the planned Mars Sample Retrieval Lander, and identifies potential efficiencies and improvements. It also describes the innovations in Mars project software systems engineering and makes recommendations as to how these evolved and what new methods and techniques should be infused into flight projects at the laboratory.},
  keywords={Space vehicles;Mars;Technological innovation;Organizations;Software systems;Aircraft navigation;Robustness},
  doi={10.1109/AERO55745.2023.10115963},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10621527,
  author={Eberhardt, Gergely and Milánkovich, Ákos},
  booktitle={2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, 
  title={VulnGPT: Enhancing Source Code Vulnerability Detection Using AutoGPT and Adaptive Supervision Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={450-454},
  abstract={In this paper, we present a novel approach to vulnerability detection in source code using a collaborative setup built on top of AutoGPT, with a controller and an evaluator AI working together. The controller oversees the evaluation process and adds a layer of self-critique to the GPT- 4 model, while the evaluator AI conducts the security assessment. By following a step-by-step interaction process, the controller prompts the evaluator AI to verify identified vulnerabilities, enabling the AI to self-correct and improve its accuracy. We discuss the results of our approach, which demonstrates the potential for effective vulnerability detection and highlights areas for improvement. Our research aims to advance the development of AI-driven security evaluation techniques to enhance the overall quality of vulnerability detection, which can be used in various areas such as IoT.},
  keywords={Adaptive systems;Accuracy;Source coding;Process control;Collaboration;Security;Internet of Things;vulnerability detection;source code;automation;GPT},
  doi={10.1109/DCOSS-IoT61029.2024.00072},
  ISSN={2325-2944},
  month={April},}@INPROCEEDINGS{10933434,
  author={Turan, Ahmet Serdar and Köksoy, Bedirhan and Paşaoğlu, Ali},
  booktitle={2025 4th International Conference on Sentiment Analysis and Deep Learning (ICSADL)}, 
  title={An Artificial Intelligence Approach for Analyzing Students' Academic Performance Using Machine Learning Algorithms}, 
  year={2025},
  volume={},
  number={},
  pages={927-932},
  abstract={This paper investigates the effect of midterm and short quizzes on the success scores at the end of the course through machine learning methods. Data from 3,427 students in the Faculty of Engineering and Natural Sciences of Istanbul Rumeli University, recorded from the year 2019 to 2024, were analyzed, and of that, 1,547 records were qualified for machine learning after applying specific filtering criteria. Due to insufficient data, 6,300 synthetic records were generated using the Generative Adversarial Networks (GAN) method. To ensure high-quality data generation and stable training, a Wasserstein GAN with Gradient Penalty (WGAN-GP) was implemented, enhancing the synthetic dataset's diversity and reliability. In this paper, the algorithms of Random Forest (RF), AdaBoost, Linear Regression (LR), K-Nearest Neighbors (KNN), and Support Vector Machines (SVM) were used for the classification and prediction of course success. Among these, the most accurate performance, quantified for example by R2 score, Mean Absolute Error and Mean Squared Error, was given by RF, with a probability of being correct at 83.81%. The results indicate that midterm exams have a significantly stronger influence on predicting course success, while short quizzes play an important role in maintaining consistent student engagement and reinforcing foundational concepts. Future studies will aim for data diverseness by adding more features and comparing new methods, such as Artificial Neural Networks with hyperparameter optimization.},
  keywords={Support vector machines;Radio frequency;Machine learning;Artificial neural networks;Nearest neighbor methods;Generative adversarial networks;Prediction algorithms;Classification algorithms;Random forests;Synthetic data;Random Forest;Machine Learning;Generative Adversarial Networks;Artificial Neural Networks},
  doi={10.1109/ICSADL65848.2025.10933434},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10727139,
  author={Mishra, Shyamal and Chatterjee, Preetha},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)}, 
  title={Exploring ChatGPT for Toxicity Detection in GitHub}, 
  year={2024},
  volume={},
  number={},
  pages={6-10},
  abstract={Fostering a collaborative and inclusive environment is crucial for the sustained progress of open source development. However, the prevalence of negative discourse, often manifested as toxic comments, poses significant challenges to developer well-being and productivity. To identify such negativity in project communications, especially within large projects, automated toxicity detection models are necessary. To train these models effectively, we need large software engineering-specific toxicity datasets. However, such datasets are limited in availability and often exhibit imbalance (e.g., only 6 in 1000 GitHub issues are toxic) [1], posing challenges for training effective toxicity detection models. To address this problem, we explore a zero-shot LLM (ChatGPT) that is pretrained on massive datasets but without being fine-tuned specifically for the task of detecting toxicity in software-related text. Our preliminary evaluation indicates that ChatGPT shows promise in detecting toxicity in GitHub, and warrants further investigation. We experimented with various prompts, including those designed for justifying model outputs, thereby enhancing model interpretability and paving the way for potential integration of ChatGPT-enabled toxicity detection into developer communication channels.},
  keywords={Training;Productivity;Toxicology;Collaboration;Communication channels;Chatbots;Software;Software development management;Software engineering;LLM;software engineering;chatgpt;incivility},
  doi={10.1145/3639476.3639777},
  ISSN={2832-7632},
  month={April},}@ARTICLE{9732669,
  author={Fu, Michael and Tantithamthavorn, Chakkrit},
  journal={IEEE Transactions on Software Engineering}, 
  title={GPT2SP: A Transformer-Based Agile Story Point Estimation Approach}, 
  year={2023},
  volume={49},
  number={2},
  pages={611-625},
  abstract={Story point estimation is a task to estimate the overall effort required to fully implement a product backlog item. Various estimation approaches (e.g., Planning Poker, Analogy, and expert judgment) are widely-used, yet they are still inaccurate and may be subjective, leading to ineffective sprint planning. Recent work proposed Deep-SE, a deep learning-based Agile story point estimation approach, yet it is still inaccurate, not transferable to other projects, and not interpretable. In this paper, we propose GPT2SP, a Transformer-based Agile Story Point Estimation approach. Our GPT2SP employs a GPT-2 pre-trained language model with a GPT-2 Transformer-based architecture, allowing our GPT2SP models to better capture the relationship among words while considering the context surrounding a given word and its position in the sequence and be transferable to other projects, while being interpretable. Through an extensive evaluation on 23,313 issues that span across 16 open-source software projects with 10 existing baseline approaches for within- and cross-project scenarios, our results show that our GPT2SP approach achieves a median MAE of 1.16, which is (1) 34%-57% more accurate than existing baseline approaches for within-project estimations; (2) 39%-49% more accurate than existing baseline approaches for cross-project estimations. The ablation study also shows that the GPT-2 architecture used in our approach substantially improves Deep-SE by 6%-47%, highlighting the significant advancement of the AI for Agile story point estimation. Finally, we develop a proof-of-concept tool to help practitioners better understand the most important words that contributed to the story point estimation of the given issue with the best supporting examples from past estimates. Our survey study with 16 Agile practitioners shows that the story point estimation task is perceived as an extremely challenging task. In addition, our AI-based story point estimation with explanations is perceived as more useful and trustworthy than without explanations, highlighting the practical need of our Explainable AI-based story point estimation approach.},
  keywords={Estimation;Transformers;Computer architecture;Planning;Task analysis;Training;Artificial intelligence;Agile story point estimation;AI for SE;explainable AI},
  doi={10.1109/TSE.2022.3158252},
  ISSN={1939-3520},
  month={Feb},}@INPROCEEDINGS{10316094,
  author={Jankovic, Antonio and Mincic, Dunja and Petrovic, Nenad and Tosic, Milorad},
  booktitle={2023 16th International Conference on Advanced Technologies, Systems and Services in Telecommunications (TELSIKS)}, 
  title={ChatGPT Assisted Development of Laravel Applications}, 
  year={2023},
  volume={},
  number={},
  pages={340-343},
  abstract={Rapid progress in machine learning has given rise to a multitude of approaches for various application domains. However, comparing the functionality and effectiveness of these approaches is crucial to obtain accurate and reliable results. In this study, we aim to explore the potential of ChatGPT, a cutting-edge conversational AI model, for coding applications. Our primary goal is to evaluate the effectiveness of ChatGPT in handling coding-related tasks. By conducting a systematic evaluation of the ten functions encompassed in our original dataset, we aim to gauge the effectiveness of ChatGPT in handling various coding tasks in case of Laravel Controller functions. This will enable us to critically examine the capabilities of ChatGPT in the context of our specific coding applications. Additionally, we conduct a survey among university students with a goal to assess adoption level of AI-based code assistance tools.},
  keywords={Surveys;Codes;Systematics;Debugging;Writing;Chatbots;Encoding;ChatGPT;code completion;Large Language Model (LLM);Laravel},
  doi={10.1109/TELSIKS57806.2023.10316094},
  ISSN={},
  month={Oct},}@BOOK{10251209,
  author={Webber, Emily and Olgiati, Andrea},
  booktitle={Pretrain Vision and Large Language Models in Python: End-to-end techniques for building and deploying foundation models on AWS},
  year={2023},
  volume={},
  number={},
  pages={},
  abstract={Master the art of training vision and large language models with conceptual fundaments and industry-expert guidance. Learn about AWS services and design patterns, with relevant coding examplesKey FeaturesLearn to develop, train, tune, and apply foundation models with optimized end-to-end pipelinesExplore large-scale distributed training for models and datasets with AWS and SageMaker examplesEvaluate, deploy, and operationalize your custom models with bias detection and pipeline monitoringBook DescriptionFoundation models have forever changed machine learning. From BERT to ChatGPT, CLIP to Stable Diffusion, when billions of parameters are combined with large datasets and hundreds to thousands of GPUs, the result is nothing short of record-breaking. The recommendations, advice, and code samples in this book will help you pretrain and fine-tune your own foundation models from scratch on AWS and Amazon SageMaker, while applying them to hundreds of use cases across your organization. With advice from seasoned AWS and machine learning expert Emily Webber, this book helps you learn everything you need to go from project ideation to dataset preparation, training, evaluation, and deployment for large language, vision, and multimodal models. With step-by-step explanations of essential concepts and practical examples, you’ll go from mastering the concept of pretraining to preparing your dataset and model, configuring your environment, training, fine-tuning, evaluating, deploying, and optimizing your foundation models. You will learn how to apply the scaling laws to distributing your model and dataset over multiple GPUs, remove bias, achieve high throughput, and build deployment pipelines. By the end of this book, you’ll be well equipped to embark on your own project to pretrain and fine-tune the foundation models of the future.What you will learnFind the right use cases and datasets for pretraining and fine-tuningPrepare for large-scale training with custom accelerators and GPUsConfigure environments on AWS and SageMaker to maximize performanceSelect hyperparameters based on your model and constraintsDistribute your model and dataset using many types of parallelismAvoid pitfalls with job restarts, intermittent health checks, and moreEvaluate your model with quantitative and qualitative insightsDeploy your models with runtime improvements and monitoring pipelinesWho this book is forIf you’re a machine learning researcher or enthusiast who wants to start a foundation modelling project, this book is for you. Applied scientists, data scientists, machine learning engineers, solution architects, product managers, and students will all benefit from this book. Intermediate Python is a must, along with introductory concepts of cloud computing. A strong understanding of deep learning fundamentals is needed, while advanced topics will be explained. The content covers advanced machine learning and cloud techniques, explaining them in an actionable, easy-to-understand way.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781804612545},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10251209},}@BOOK{10824697,
  author={Chan, Stanley H.},
  booktitle={Tutorial on Diffusion Models for Imaging and Vision},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={The astonishing growth of generative tools in recent years has empowered many exciting applications in text-to-image generation and text-to-video generation. The underlying principle behind these generative tools is the concept of diffusion, a particular sampling mechanism that has overcome some shortcomings that were deemed difficult in the previous approaches. The goal of this monograph is to discuss the essential ideas underlying the diffusion models. The target audience includes undergraduate and graduate students who are interested in doing research on diffusion models or applying these models to solve other problems.},
  keywords={},
  doi={},
  ISSN={},
  publisher={now},
  isbn={9781638284338},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10824697},}@INPROCEEDINGS{10823414,
  author={De Silva, D. I. and Athukorala, K. S. N.},
  booktitle={2024 8th International Conference on Business and Information Management (ICBIM)}, 
  title={Transformer-Based Sinhala Java Programming Learning Tool}, 
  year={2024},
  volume={},
  number={},
  pages={105-110},
  abstract={Programming is a fundamental aspect of computer science, yet it presents significant language challenges for non-native English-speaking students. This study focuses on developing a Java programming assistance tool tailored for Sri Lankan novice programmers who are native Sinhala speakers. The primary challenge addressed is the difficulty these students face when using English-based programming resources. To overcome this, the study introduces an innovative assistance tool that integrates a custom transformer-based Sinhala- English translation model with advanced AI technology, specifically ChatGPT, for real-time code generation and explanations in Sinhala. The tool is designed to accept queries in Sinhala and provide relevant Java snippets or explanations of Java code in Sinhala. The system architecture includes a user-friendly front-end built on Flask, a robust back-end API, and an accurate translation model with an 83 % accuracy rate. Usability tests with ten beginner Sinhala-speaking programmers demonstrated significant improvements in their understanding and retention of programming concepts, with an average increase in test scores by 25%. This tool enhances programming education accessibility for Sinhala speakers, promoting a more inclusive global coding community.},
  keywords={Java;Translation;Codes;Accuracy;Education;Chatbots;Transformers;Real-time systems;Artificial intelligence;Programming profession;Programming;Java Code;Sinhala-English translator;language barrier;APIs;Transformers;ChatGPT},
  doi={10.1109/ICBIM63313.2024.10823414},
  ISSN={},
  month={Aug},}@ARTICLE{10050506,
  author={Lijo, Ruben and Quevedo, Eduardo and Castro, Jose Juan and Horta, Ricard},
  journal={IEEE Access}, 
  title={Impact of Electrical Engineering Didactic Videos During Emergency Remote Learning}, 
  year={2023},
  volume={11},
  number={},
  pages={19622-19634},
  abstract={This article demonstrates that didactic videos have the potential to enhance quality perception, performance and interest in engineering education. Emergency Remote Learning (ERL) imposed challenging conditions on education, and its impact was especially noticeable in the Science, Technology, Engineering and Mathematics (STEM) disciplines. This is mainly due to intrinsic cognitive load associated with the high presence of abstract concepts and to difficulties to establish connections among subjects to foster generative processing. Suitable integration of multimedia resources might be beneficial in both regards. The use of didactic videos as pedagogical aid is expected to yield positive results in electrical engineering education, mitigating the impact caused by ERL situations. Using concept maps to identify key concepts in the Electrical Engineering BSc, this article proposes the creation and integration of nine videos to enhance conceptual learning and the creation of links among subjects. This study encompassed three academic years (from 2019 to 2022), covering pre-ERL, ERL and post-ERL scenarios, and considering a total sample of 157 students. By using a Mixed Methods research design, this study has demonstrated how the integration of didactic videos mitigated the negative effects of the unprecedented ERL conditions, with positive impact on students’ perception on videos’ implications in enhancing their interest and understanding of the subject’s concepts.},
  keywords={Videos;STEM;Deep learning;Streaming media;Electrical engineering education;Electric potential;Design methodology;Cognitive load;Distance learning;Electronic learning;Conceptual learning;distance learning;educational technology;electrical engineering education;emergency remote learning;STEM;videos;YouTube},
  doi={10.1109/ACCESS.2023.3248299},
  ISSN={2169-3536},
  month={},}@ARTICLE{10804767,
  author={Faruqui, Nuruzzaman and Thatoi, Priyabrata and Choudhary, Rohit and Roncevic, Ivana and Alqahtani, Hamed and Sarker, Iqbal H. and Khanam, Shapla},
  journal={IEEE Access}, 
  title={AI-Analyst: An AI-Assisted SDLC Analysis Framework for Business Cost Optimization}, 
  year={2024},
  volume={12},
  number={},
  pages={195188-195203},
  abstract={Managing the System Development Lifecycle (SDLC) is a complex task because of its involvement in coordinating diverse activities, stakeholders, and resources while ensuring project goals are met efficiently. The complex nature of the SDLC process leaves plenty of scope for human error, which impacts the overall business cost. This paper introduces AI-Analyst, an AI-assisted framework developed using the transformer-based model with more than 150 million parameters to assist with SDLC management. It minimizes manual effort errors, optimizes resource allocation, and improves decision-making processes, resulting in substantial cost savings. The statistical analysis shows that it saves around 53.33% of costs in an experimental project. The transformer model has been trained with a uniquely prepared dataset tailored for SDLC through transfer learning. It achieved impressive results, with an accuracy of 91.5%, precision of 91.9%, recall of 91.3%, and an F1-score of 91.5%, demonstrating its high reliability and performance. The perplexity score of 15 further indicates the model’s strong language understanding capabilities to retrieve relations from complex characteristics of Natural Language Processing (NLP). The AI-Analyst framework represents a significant advancement in integrating Large Language Models (LLMs) into SDLC, offering a scalable and cost-effective solution for optimizing business processes.},
  keywords={Mathematical models;Transformers;Costs;Vectors;Business;Unified modeling language;Training;Optimization;Testing;Systematic literature review;Transformer model;large language model;system development lifecycle;transfer learning;artificial intelligence;business cost optimization;project management automation;system analyst;LLM;SDLC;AI;PMP},
  doi={10.1109/ACCESS.2024.3519423},
  ISSN={2169-3536},
  month={},}@INBOOK{10744999,
  author={Arellano, Karen Chappell},
  booktitle={Collaborative Intelligence: How Humans and AI Are Transforming Our World}, 
  title={12 AI in Warfighting}, 
  year={2024},
  volume={},
  number={},
  pages={287-314},
  abstract={Increasing numbers of artificial intelligence-related academic articles<superscript>1</superscript> and the recent news covering AI developments, including OpenAI&#x0027;s GPT-3, DALLE 2, and DARPA&#x0027;s AI dogfight (Heaven 2020; Knight 2020; Marcus, Davis, and Aaronson 2022) might give one a growing sense of an AI race or even an AI revolution (Makridakis 2017). Both private and public sectors accelerate development of AI, where the promise of AI grows in fields as diverse as health care, education, transportation, human resources, or even the battlefield, raising questions over widespread acceptance of and partnering for this emerging technology. From concerns over machine learning (ML) bias, to fears over loss of privacy or increased security threats, to the anxiety that human decision making and jobs will be replaced by AI, worry persists that development and deployment of AI systems are speeding ahead, sparking a new technological revolution without serious ethical consideration.},
  keywords={},
  doi={},
  ISSN={},
  publisher={MIT Press},
  isbn={9780262381178},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10744999},}@INPROCEEDINGS{10882426,
  author={Gupta, Abha and Bhardwaj, Ekta and Sirawag, Neeraj and Pandey, Suvrat and Mehta, Riya},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Jarvis: AI-Enhanced Desktop Virtual Assistant}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the development and evaluation of “Jarvis: AI-Enhanced Desktop Virtual Assistant,” a multi- functional system designed to automate daily tasks through voice commands and natural language processing (NLP). Leveraging advanced technologies such as OpenAI's GPT-4, machine learning models, Optical Character Recognition (OCR), and web automation tools, Jarvis integrates voice, text, and graphical interface interactions to deliver an intuitive user experience. With a 95% accuracy in voice command recognition and a 98% task completion rate, Jarvis efficiently handles diverse operations, including code generation, web scraping, and GUI automation. Key functionalities are supported by PyTorch-based neural networks for intent recognition, ListenJs for voice input, and Selenium for web automation, while EasyOCR enhances its ability to interact with graphical elements. The system's ability to engage in natural conversations, execute Python code dynam- ically, and correct errors iteratively demonstrates its robustness and versatility. Future improvements in GUI automation, NLP contextual understanding, and deep learning integration will further enhance its capabilities, positioning Jarvis as a valuable tool in various sectors such as public safety, education, and productivity.},
  keywords={Automation;Codes;Accuracy;Virtual assistants;Optical character recognition;Speech recognition;Oral communication;Natural language processing;User experience;Graphical user interfaces;OpenAI Integration;Speech to Text;Voice Assistant;Voice Recognition},
  doi={10.1109/ICAIQSA64000.2024.10882426},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10551980,
  author={Glebova, Anna},
  booktitle={2024 7th International Conference on Information Technologies in Engineering Education (Inforino)}, 
  title={Current Trends in the Global Information Technology Market in Engineering Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The author considers the prerequisites and directions for the development of the global market for information technologies in higher education, analyze the impact of the changed geopolitical situation in Europe on the provision of Russian higher engineering education with modern information technologies. The purpose of the study is to determine current trends in the development of the Russian information technology market in engineering education. The object of the study is the direction of development of the global market of information technologies in engineering education, the subject of the study is the possibility of developing the Russian segment of the market of information technologies in engineering education in accordance with global trends. As the results of the study, the article presents the identified directions for the development of the Russian segment of the information technology market in engineering education: 1) the use of artificial intelligence technology (for example, ChatGPT), 2) the introduction of virtual reality technologies in engineering education, 3) gamification of the learning process, 4) using mobile devices for learning.},
  keywords={Solid modeling;Globalization;Learning (artificial intelligence);Virtual reality;Market research;Software;Object recognition;EdTech;global information technology market;Russian information technology market;higher engineering education;recommended software},
  doi={10.1109/Inforino60363.2024.10551980},
  ISSN={},
  month={April},}@ARTICLE{10820190,
  author={Amin, Md Faizul Ibne and Watanobe, Yutaka and Rahman, Md Mostafizer and Shirafuji, Atsushi},
  journal={IEEE Access}, 
  title={Source Code Error Understanding Using BERT for Multi-Label Classification}, 
  year={2025},
  volume={13},
  number={},
  pages={3802-3822},
  abstract={Programming is an essential skill in computer science and across a wide range of engineering disciplines. However, errors, often referred to as ‘bugs’ in code, can be challenging to identify and rectify for both students learning to program and experienced professionals. Understanding, identifying, and effectively addressing these errors are critical aspects of programming education and software development. To aid in understanding and classifying these errors, we propose a multi-label error classification approach for source code using fine-tuned BERT models (BERT_Uncased and BERT_Cased). The models achieved average classification accuracies of 90.58% and 90.80%, exact match accuracies of 48.28% and 49.13%, and weighted F1 scores of 0.796 and 0.799, respectively. Precision, Recall, Hamming Loss, and ROC-AUC metrics further evaluate the effectiveness of our models. Additionally, we employed several combinations of large language models (CodeT5, CodeBERT) with machine learning classifiers (Decision Tree, Random Forest, Ensemble Learning, ML-KNN), demonstrating the superiority of our proposed approach. These findings highlight the potential of multi-label error classification to advance programming education, software engineering, and related research fields.},
  keywords={Programming;Programming profession;Codes;Multi label classification;Accuracy;Education;Transformers;Measurement;Computer bugs;Data models;Multi-label classification;BERT;CodeT5;CodeBERT;decision tree;random forest;ML-KNN;ensemble learning;data analysis;educational big data;error classification;learning analytics;programming learning;software engineering},
  doi={10.1109/ACCESS.2024.3525061},
  ISSN={2169-3536},
  month={},}@ARTICLE{9808269,
  author={Lv, Yancheng and Lin, Lin and Liu, Jie and Guo, Hao and Tong, Changsheng},
  journal={Neural Computation}, 
  title={Research on Imbalanced Data Classification Based on Classroom-Like Generative Adversarial Networks}, 
  year={2022},
  volume={34},
  number={4},
  pages={1045-1073},
  abstract={Most of the research on machine learning classification methods is based on balanced data; the research on imbalanced data classification needs improvement. Generative adversarial networks (GANs) are able to learn high-dimensional complex data distribution without relying on a prior hypothesis, which has become a hot technology in artificial intelligence. In this letter, we propose a new structure, classroom-like generative adversarial networks (CLGANs), to construct a model with multiple generators. Taking inspiration from the fact that teachers arrange teaching activities according to students' learning situation, we propose a weight allocation function to adaptively adjust the influence weight of generator loss function on discriminator loss function. All the generators work together to improve the degree of discriminator and training sample space, so that a discriminator with excellent performance is trained and applied to the tasks of imbalanced data classification. Experimental results on the Case Western Reserve University data set and 2.4 GHz Indoor Channel Measurements data set show that the data classification ability of the discriminator trained by CLGANs with multiple generators is superior to that of other imbalanced data classification models, and the optimal discriminator can be obtained by selecting the right matching scheme of the generator models.},
  keywords={},
  doi={10.1162/neco_a_01470},
  ISSN={0899-7667},
  month={March},}@ARTICLE{10744050,
  author={de León Languré, Alejandro and Zareei, Mahdi},
  journal={IEEE Access}, 
  title={Improving Text Emotion Detection Through Comprehensive Dataset Quality Analysis}, 
  year={2024},
  volume={12},
  number={},
  pages={166512-166536},
  abstract={As Artificial Intelligence assistants like OpenAI’s Chat-GPT or Google’s Gemini become increasingly integrated into our daily lives, their ability to understand and respond to human emotions expressed in natural language becomes essential. Affective computing, including text emotion detection (TED), has become crucial for human-computer interaction. However, the quality of datasets used for training supervised machine learning algorithms in TED often receives insufficient attention, potentially impacting model performance and comparability. This study addresses this gap by proposing a comprehensive framework for assessing dataset quality in TED. We introduce 14 quantitative metrics across four dimensions: representativity, readability, structure, and part-of-speech tag distribution, and investigate their impact on model performance. We conduct experiments on datasets with varying quality characteristics Using Bidirectional Long Short-Term Memory (BiLSTM) and Bidirectional Encoder Representations from Transformers (BERT) models. Our findings demonstrate that changes in these quality metrics can lead to statistically significant variations in model performance, with most metrics showing over 5% impact on prediction accuracy. Notably, pre-trained models like BERT exhibit more robustness to dataset quality variations than models trained from scratch. These results underscore the importance of considering and reporting dataset quality metrics in TED research, as they significantly influence model performance and generalizability. Our study lays the groundwork for more rigorous dataset quality assessment in affective computing, potentially leading to more reliable and comparable TED models in the future.},
  keywords={Measurement;Emotion recognition;Accuracy;Indexes;Encoding;Computational modeling;Bidirectional control;Training;Recurrent neural networks;Predictive models;Natural language processing;Text detection;Affective computing;natural language processing;sentiment analysis;text emotion detection;text emotion recognition},
  doi={10.1109/ACCESS.2024.3491856},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10786604,
  author={Borasi, Raffaella},
  booktitle={2024 IEEE Western New York Image and Signal Processing Workshop (WNYISPW)}, 
  title={AI Implications for Education and Educators}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={The main goal of this paper is to propose a framework to better understand and capitalize on the many implications of Artificial Intelligence (AI) for education, especially but not limited to the most recent developments of Generative Artificial Intelligence (GenAI). Four complementary categories are identified, each presenting diverse opportunities and challenges:1)Leveraging AI to improve instruction: This involves using AI to create new and more powerful learning opportunities for learners – at all levels of schools and across subject areas as well as instructional contexts.2)Promoting AI Literacy: This involves helping everyone develop sufficient understanding of AI to function in a society where AI is increasingly used.3)Rethinking workforce preparation: This involves responding to the need to change how we prepare future workers, once uses of AI take over functions previously performed by humans in specific occupations.4)Leveraging AI to support educators’ own work: While the focus of the previous three categories is on student learning, here the focus shifts on educators’ using AI in their work to increase their productivity and well-being.In what follows, I will examine each of these areas using conceptual analysis, building on findings from relevant research studies I have been involved in, as well as recent conversations within an interdisciplinary group of faculty, staff and students as part of an internal planning grant for the University of Rochester. For each area, after a brief introduction I will identify and discuss a few key elements; selected illustrations, in most cases reporting findings from relevant research projects, will also be provided in separate “boxes” so they can be read independently.For further information about this paper please contact the author.},
  keywords={Productivity;Generative AI;Conferences;Education;Buildings;Oral communication;Signal processing;Planning;Artificial intelligence},
  doi={10.1109/WNYISPW63690.2024.10786604},
  ISSN={2471-9242},
  month={Nov},}@INPROCEEDINGS{10397917,
  author={Fegade, Atul and Raut, Rajesh and Deshpande, Amruta and Mittal, Amit and Kaul, Natashaa and Khanna, Vandana},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Unleashing the Power of Generative Artificial Intelligence: Exploring its Boundless Potential and Overcoming Challenges in Academic Environments}, 
  year={2023},
  volume={6},
  number={},
  pages={1243-1249},
  abstract={Integrating generative artificial intelligence tools can allow one to manage and develop novel business methods efficiently. With the introduction of self-learning generative artificial intelligence (GAI) tools, the corporate world is trying to figure out the applications and their business implications. Major technology companies like Microsoft, Google, Facebook, etc., have shown enormous interest in investing in ventures developing generative AI tools/models. These tools/models can be experimented with, and their business use is being explored. The study aims to explore the potential uses of generative AI (GAI) in academics through its current capabilities and applications. The study also highlights the potential challenges and concerns arising from using generative AI in academics. The study has used descriptive and quantitative methods to answer the research questions. The study has used a questionnaire based on the Likert scale to measure the significance of indirect variables, viz. perceived ease of use (PEOU) and perceived trust (PT) on direct variable adoption of generative artificial intelligence (AGAI) in academics. The sample size consists of 100 students and 100 university professors. The study Mentions that perceived ease of use (PEOU) positively influences GAI (AGAI) adoption. Also, perceived trust (PT) has a predictive ability of AGIA when controlling for PEOU. The use of generative AI in a few years will become imperative in most human lives, which makes it mandatory to explore the possible ways of its adoption in the mainstream rather than avoiding or restricting its usage in academics.},
  keywords={Ethics;Generative AI;Social networking (online);Education;Transforms;Internet;Business;Generative Artificial Intelligence;ChatGPT;BARD;Generative Adversarial Networks;Education;Plagiarism;Academic Integrity},
  doi={10.1109/IC3I59117.2023.10397917},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10825415,
  author={D’Amico, Simone and De Santo, Alessia and Mercorio, Fabio and Mezzanzanica, Mario},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Enriching Skill Taxonomies through Vector Space Models}, 
  year={2024},
  volume={},
  number={},
  pages={2297-2302},
  abstract={Hierarchical taxonomies serve as fundamental structures for reasoning with hierarchical concepts across various domains such as healthcare, finance, and economy. However, maintaining their relevance and accuracy is a labor-intensive and error-prone task, demanding experts to identify and revise novel concepts constantly. In this context, distributional semantics techniques offer a promising avenue by suggesting terms likely to be associated with existing concepts. In our study, we propose a method to enhance taxonomies by adding related terms using contextual word embedding as encoders. We introduce VESPATE (VEctor SPAce model for Taxonomy Enrichment), a system designed to automatically expand any given hierarchical taxonomy with new terms using three generative models. Additionally, we integrate VESPATE with human validation to identify and select the most suitable terms for inclusion in the taxonomy. VESPATE was deployed within an EU project to enrich the official European Skill taxonomy, ESCO, with 40K+ digital terms gathered from the Web, aligning ESCO skills with current labor market needs. A total of 924 terms were selected through VESPATE, with 757 new terms subsequently validated by domain experts as correctly matched. Our framework, employing a pool of LLMs as encoders, helped us mitigate the limitations of the generative model, reducing the potential for errors and ensuring precise results in taxonomy enrichment. Additionally, the implementation of VESPATE consistently decreased the human effort required for the project. We evaluated the robustness of our system against a baseline constructed using ESCO’s hierarchy, achieving a 81% Positive Predictive Value (PPV) when combining all three models.},
  keywords={Accuracy;Large language models;Jobs listings;Taxonomy;Semantics;Finance;Medical services;Predictive models;Vectors;Robustness;Automated Taxonomy Enrichment;Labor Market Intelligence;Large Language Models;NLP},
  doi={10.1109/BigData62323.2024.10825415},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{10620649,
  author={Couto, Gustavo Claudio Karl and Antonelo, Eric Aislan},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Hierarchical Generative Adversarial Imitation Learning With Mid-Level Input Generation for Autonomous Driving on Urban Environments}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Deriving robust control policies for realistic urban navigation scenarios is not a trivial task. In an end-to-end approach, these policies must map high-dimensional images from the vehicle's cameras to low-level actions such as steering and throttle. While pure Reinforcement Learning (RL) approaches are based exclusively on engineered rewards, Generative Adversarial Imitation Learning (GAIL) agents learn from expert demonstrations while interacting with the environment, which favors GAIL on tasks for which a reward signal is difficult to derive, such as autonomous driving. However, training deep networks directly from raw images on RL tasks is known to be unstable and troublesome. To deal with that, this work proposes a hierarchical GAIL-based architecture (hGAIL) which decouples representation learning from the driving task to solve the autonomous navigation of a vehicle. The proposed architecture consists of two modules: a GAN (Generative Adversarial Net) which generates an abstract mid-level input representation, which is the Bird's-Eye View (BEV) from the surroundings of the vehicle; and the GAIL which learns to control the vehicle based on the BEV predictions from the GAN as input. hGAIL is able to learn both the policy and the mid-level representation simultaneously as the agent interacts with the environment. Our experiments made in the CARLA simulation environment have shown that GAIL exclusively from cameras (without BEV) fails to even learn the task, while hGAIL, after training exclusively on one city, was able to autonomously navigate successfully in 98% of the intersections of a new city not used in training phase. Videos and code available at: https://sites.google.com/view/hgail},
  keywords={Trajectory;Cameras;Training;Task analysis;Urban areas;Generative adversarial networks;Cloning;Autonomous Driving;Generative Adversarial Imitation Learning;CARLA Simulator;Bird's-Eye View},
  doi={10.1109/TIV.2024.3436587},
  ISSN={2379-8904},
  month={},}@INPROCEEDINGS{10894718,
  author={Otsuka, Ami and Sasaki, Akira and Ito, Atsushi},
  booktitle={2024 IEEE 15th International Conference on Cognitive Infocommunications (CogInfoCom)}, 
  title={“Interactive AI for Software Development Learning: Shifting Focus to Requirement Specification”}, 
  year={2024},
  volume={},
  number={},
  pages={000121-000126},
  abstract={We propose a new approach to programming learning. Specifically, it is a learning method centered on creating requirement specifications using OpenAI’s interactive AI, ChatGPT, which enables learners to gain a deeper understanding of the overall program design and structure and aims at learning through the experience of creating and publishing their software. To this end, we clarify the current programming learning status and problems, propose new learning methods, and evaluate their effectiveness. Furthermore, we will develop a vision for the future based on them. We then provide insights into how programming education should evolve and how advanced technologies such as interactive AI should be used.},
  keywords={Learning systems;Publishing;Learning (artificial intelligence);Chatbots;Software;Programming profession;Software development management;software development model;specification description;software engineering;study material for studying programming;conversational Artificial Intelligence},
  doi={10.1109/CogInfoCom63007.2024.10894718},
  ISSN={2473-5671},
  month={Sep.},}@ARTICLE{10494340,
  author={Cámara, Javier and Troya, Javier and Montes-Torres, Julio and Jaime, Francisco J.},
  journal={IEEE Software}, 
  title={Generative AI in the Software Modeling Classroom: An Experience Report With ChatGPT and Unified Modeling Language}, 
  year={2024},
  volume={41},
  number={6},
  pages={73-81},
  abstract={The use of generative AI chatbots in formative assessment can effectively gauge learning progress, increase the academic performance of students compared to a traditional methodology, and raise student awareness about the tradeoffs of employing generative AI in their work.},
  keywords={Unified modeling language;Chatbots;Software development management;Generative AI;Object oriented modeling;Educational courses;Curriculum development;Computer science education;Unified modeling language;Modeling},
  doi={10.1109/MS.2024.3385309},
  ISSN={1937-4194},
  month={Nov},}@INPROCEEDINGS{10685655,
  author={Huang, Jingxiu and Wei, Yufeng and Zhang, Lixin and Chen, Weirui},
  booktitle={2024 International Symposium on Educational Technology (ISET)}, 
  title={Evaluating generative artificial intelligence in answering course-related open questions: A pilot study}, 
  year={2024},
  volume={},
  number={},
  pages={64-69},
  abstract={ChatGPT, which has been discussed in public in recent years, was launched in November 2022, with a continuously expanding market size. Generative Artificial Intelligence (GAI) has been developing rapidly in China. However, we have little knowledge of how well the GAIs are performing at answering course-related open questions, especially in Chinese. Therefore, this study aims to analyze the performances of GAIs in answering course-related open questions from both machine and manual evaluation perspectives. The results from this study showed that GAIs got unsatisfactory scores in this situation. Two different aspects of comparison of GAIs’ scores are discussed. More study on evaluating the performance of GAI is needed to investigate the capabilities of answering course-related open questions in the future.},
  keywords={Generative AI;Manuals;Educational technology;Chatbots;GAI;automatic evaluation;manual evaluation;course-related open questions},
  doi={10.1109/ISET61814.2024.00022},
  ISSN={2766-2144},
  month={July},}@INPROCEEDINGS{10345880,
  author={Virvou, Maria and Tsihrintzis, George A.},
  booktitle={2023 14th International Conference on Information, Intelligence, Systems & Applications (IISA)}, 
  title={Pre-made Empowering Artificial Intelligence and ChatGPT: The Growing Importance of Human AI-Experts}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper investigates the augmented responsibility of human Artificial Intelligence experts in the era of empowered pre-made Artificial Intelligence (AI). The responsible and ethical use of pre-made AI is of paramount importance in this evolving technology. AI systems have the potential to impact numerous aspects of society, ranging from healthcare and finance to education and IoT. The decisions made by AI algorithms can have significant consequences for individuals, communities, and even entire industries. Using a comparison to the way widely available medicines require a prescription from medical doctors, human AI experts assume the role of evaluating, recommending, and overseeing the implementation of AI systems, even when pre-built AI solutions may seem user-friendly on the surface. The paper has explored the expanded responsibilities of human AI experts within two contemporary scenarios involving pre-made AI, encompassing LLMs and ChatGPT. These AI technologies are applied in two principal manners: initially, as standalone AI products readily accessible to a wide audience, and secondly, as elements undergoing exploration for integration into other AI-driven software and Intelligent Information Systems (IIS), with the goal of enhancing natural language processing (NLP) features within user interfaces. In all cases, the expertise of human AI professionals is indispensable, and their role is augmented. These professionals bear an increased responsibility for ensuring the responsible and ethical deployment of AI technologies, with a focus on human-centered design, bias mitigation, validation and accuracy estimation of the results, transparency promotion, and the necessary balance between automation and human oversight. This paper performs a review on pre-made AI and ChatGPT together with custom-based AI and shows that recent advance require an augmented role of human AI experts},
  keywords={Industries;Ethics;Medical services;User interfaces;Chatbots;Software;Requirements engineering;Responsible Artificial Intelligence;Human-centered AI;AI-Empowered Software Engineering;ChatGPT;Large Language Models (LLMs);Generative AI;e-learning Requirements Engineering in AI;Artificial Intelligence;Intelligent Information Systems},
  doi={10.1109/IISA59645.2023.10345880},
  ISSN={},
  month={July},}@INPROCEEDINGS{10734642,
  author={Georgopoulou, Maria Sofia and Krouska, Akrivi and Troussas, Christos and Sgouropoulou, Cleo},
  booktitle={2024 9th South-East Europe Design Automation, Computer Engineering, Computer Networks and Social Media Conference (SEEDA-CECNSM)}, 
  title={Redefining the Concept of Literacy: a DigCompEdu extension for Critical Engagement with AI tools}, 
  year={2024},
  volume={},
  number={},
  pages={98-102},
  abstract={Artificial Intelligence (AI) is rapidly transforming our world, and education is no exception. The growing popularity and use of AI systems calls for a new understanding of what it means to be literate in the modern world. Thus, it is crucial for individuals to develop AI-driven critical thinking skills to effectively interact with these technologies. However, existing research focuses mainly on the "how" of AI integration, with limited exploration of the "why" and "how" of fostering critical engagement with AI tools. In this article, we propose an extension to DigCompEdu that aligns with the UNESCO pillars of education. This extension highlights five key elements that challenge critical thinking capabilities in relation to AI: "know-what," "know-who," "know-where," "know-how," and "know-why". By combining critical thinking skills with AI functionalities, educators can empower students to become responsible and informed digital citizens in the era of generative AI.},
  keywords={Design automation;Social networking (online);Generative AI;Education;Europe;Computer networks;Artificial intelligence;literacy;Artificial Intelligence;DigCompEdu;four pillars of education;critical engagement;digital citizens},
  doi={10.1109/SEEDA-CECNSM63478.2024.00026},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{11007383,
  author={Kashyap, Ria Kamala and Phalachandra, Prithvi and Kulkarni, Prerana Prashant and Narayan, Rohan and Prasad, V R Badri},
  booktitle={2024 Intelligent Systems and Machine Learning Conference (ISML)}, 
  title={Silent Conversations: A Deep Dive into using CNN and ChatGPT for deriving meaning from Language Gestures}, 
  year={2024},
  volume={},
  number={},
  pages={651-656},
  abstract={For the community who are deaf or hard of hearing, sign language serves as a major means of communication. However, their inability to properly communicate is frequently hampered by a lack of resources and qualified translators. Computer vision and image processing methods, such as Convolutional Neural Networks, a more recent advancement in the field of computer vision, can be utilized to address this problem. The aim of translating sign language is to enable communication between those who are deaf and those who are hearing by precisely identifying, categorizing, and analyzing the hand motions used in sign language. To close the communication gap, this project attempts to develop a technology that can automatically convert Indian sign language into Textual Context. Using techniques like CNN for image classification and generative AI (ChatGPT) for sentence formation, which are techniques and tools known for their high degree of accuracy, we can develop an effective solution.},
  keywords={Sign language;Computer vision;Translation;Accuracy;Generative AI;Auditory system;Oral communication;Linguistics;Chatbots;Convolutional neural networks;Classification;Convolutional Neural Network;Generative AI;ChatGPT},
  doi={10.1109/ISML60050.2024.11007383},
  ISSN={},
  month={May},}@INPROCEEDINGS{10350098,
  author={Heidrich, David and Schreiber, Andreas},
  booktitle={2023 IEEE Working Conference on Software Visualization (VISSOFT)}, 
  title={Visualizing Source Code as Comics Using Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={40-44},
  abstract={The architecture and inner structure of software is often only implicitly available in the form of its source code and thus not tangible and intuitively easy to understand for non-programmers and laymen. Our goal is to create visualizations as automatically as possible, with which such people can neverthe-less understand the software or parts of the software and get a feel for the structure of the software and how its methods work. Especially for newcomers to software projects, for management or even for students and pupils, it can be helpful to get a non-technical insight into the software. We use the concept of visualizing information as comics to present aspects of the software as strikingly as possible, as comics are an effective way to present complex systems and interrelationships for certain target groups. For this purpose, we present a method to generate comics from source code. Our semi-automated process is based on generating a prompt for an LLM from source code, which in turn generates a prompt for a comic image generation using the text-to-image model Stable Diffusion. We show that generative AI methods can be used to rapidly generate human-compatible artistic representations from source code. However, further research is needed to validate the understandability of the results.},
  keywords={Visualization;Image synthesis;Source coding;Computer architecture;Software;Artificial intelligence;Pupils;visualization;software visualization;comics;generative ai;stable diffusion},
  doi={10.1109/VISSOFT60811.2023.00014},
  ISSN={2832-6555},
  month={Oct},}@INPROCEEDINGS{10346594,
  author={Markus, Anna M. and Ovinova, Lada N. and Dmitrusenko, Inna N. and Shraiber, Elena G.},
  booktitle={2023 International Conference on Quality Management, Transport and Information Security, Information Technologies (IT&QM&IS)}, 
  title={Application of Artificial Intelligence Technology in Teaching English Language to Engineering Bachelors}, 
  year={2023},
  volume={},
  number={},
  pages={147-151},
  abstract={Neural networks function and interact in different areas. Artificial Intelligence (AI) technologies are applied in teaching foreign languages in the modern educational system. The purpose of the study was to identify the possibilities of using available artificial intelligence services in teaching the English language in the academic environment. The study used theoretical analysis of pedagogical literature and the questionnaire-diagnostic method. The System Usability Scale (SUS) and Technology Acceptance Model (TAM) were chosen as diagnostic tools for analyzing the characteristics of AI services (Scribble Diffusion, Metavoice, Pictory, ChatGPT). The study involved 96 undergraduate engineering bachelors from South Ural State University. The degree of students' satisfaction with the implementation of AI services was analyzed through the questionnaire. The presented results of the ascertaining experiment confirmed the feasibility and the effectiveness of integrating AI services in teaching the English language to engineering bachelors in the educational process.},
  keywords={Knowledge engineering;Technological innovation;Technology acceptance model;Education;Neural networks;Writing;Chatbots;artificial intelligence;AI technology;foreign languages;engineering bachelors},
  doi={10.1109/ITQMTIS58985.2023.10346594},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10581765,
  author={Yu, Chao and Zhu, Xiao and Xu, Tianyu and Zhu, Wenhao},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Enhancing Sentence Representation with a Transfer Task Enhancement Auxiliary Network}, 
  year={2024},
  volume={},
  number={},
  pages={1764-1767},
  abstract={Contrastive Learning of Sentence Embeddings (CSE) has gained significant traction in the realm of Natural Language Processing (NLP), proving to be particularly effective in applications like sentence similarity assessment and text retrieval, where supervised methods are currently achieving the best performance. We have identified a trend: although supervised sentence representation methods show remarkable effectiveness in semantic similarity assessments, their performance tends to decline in transfer tasks. In order to solve this problem, we propose to use transfer task enhancement auxiliary network, named TEAnet. Our method leverages rationales generated by large language models to guide smaller models, specifically by jointly conducting classification loss training during the contrastive training process. Our experiments demonstrate that the auxiliary network approach enhances performance on the transfer task while maintaining the semantic similarity task of training.},
  keywords={Training;Seminars;Large language models;Semantics;Transfer learning;Contrastive learning;Market research;contrastive learning;sentence embeddings;large language models},
  doi={10.1109/AINIT61980.2024.10581765},
  ISSN={},
  month={March},}@INPROCEEDINGS{10892948,
  author={Aguinalde, Pauline and Shin, Jinnie and Carroll, Bruce F. and Crippen, Kent J.},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Leveraging Large Language Models to Automatically Investigate Core Tasks Within Undergraduate Engineering Work-Integrated Learning Experiences}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This full research paper aims to investigate methods for systematically identifying core tasks within undergraduate engineering work-integrated learning (WIL) opportunities, such as internships and co-ops. It achieves this by automatically analyzing WIL opportunities using transformer models. A dataset of 4,833 engineering internship postings from the last ten years was obtained through a partnership with the University's Career Connections Center. From this, a subset of 374 aerospace engineering internships, yielding 1,913 unique job tasks, was extracted for human labeling. We applied the Llama 2 architecture, a sophisticated pre-trained LLM, to extract a list of specific responsibilities and tasks from the internship postings. The job tasks were used to train an automated classification system to map each task to the established seven ABET student outcomes. Each job task was human-labeled by three subject matter experts, achieving a high level of inter-rater reliability of 0.998, according to Krippendorff's alpha. RoBERTa resulted in the optimal model indicating a label ranking average precision of 0.892 on the validation set and 0.857 on the testing set. Our findings provide novel insights into understanding the evolving skill expectations of undergraduate interns, offering a basis for tailoring engineering education to address these demands. Furthermore, the automated analysis of internship tasks demonstrates the potential for a scalable way to address the gap in understanding the core responsibilities within WIL experiences.},
  keywords={Industries;Training;Analytical models;Accuracy;Subject matter experts;Text categorization;Standards organizations;Transformer cores;Transformers;Aerospace engineering;work-integrated learning;internships;natural language processing;aerospace engineering;ABET},
  doi={10.1109/FIE61694.2024.10892948},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10714517,
  author={Turchi, Tommaso},
  booktitle={2024 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)}, 
  title={FlowPilot: A Generative AI-Driven Visual Language for Computational Thinking Education}, 
  year={2024},
  volume={},
  number={},
  pages={353-355},
  abstract={This paper introduces FlowPilot, a novel flow-based visual programming language designed to enhance Computational Thinking (CT) education. FlowPilot leverages generative AI to create a dynamic, browser-based environment where users can construct programs using natural language descriptions. By integrating AI-driven block generation with a flow-based visual interface, FlowPilot supports key CT pillars such as abstraction and decomposition. This approach offers a unique platform for learners to explore programming concepts at various levels of complexity, fostering a deeper understanding of computational processes.},
  keywords={Visualization;Computer languages;Generative AI;Natural languages;Education;Complexity theory;Programming profession;Visual Programming;Computational Thinking;Generative AI},
  doi={10.1109/VL/HCC60511.2024.00046},
  ISSN={1943-6106},
  month={Sep.},}@INPROCEEDINGS{10957038,
  author={He, Long and Kang, Lai and Geng, Mingyang},
  booktitle={2025 International Conference on Electrical Automation and Artificial Intelligence (ICEAAI)}, 
  title={An Empirical Study on Large Language Models for Aerospace Question Answering}, 
  year={2025},
  volume={},
  number={},
  pages={1295-1300},
  abstract={The application of knowledge-based question answering (QA) systems in the aerospace sector is crucial, providing essential support in training, fault analysis, and operational manual development. These systems enhance efficiency and safety by enabling rapid, precise answers to complex technical questions, aiding in maintaining system reliability. However, limited empirical research has focused on assessing the performance of QA systems specifically tailored for aerospace, leaving an important knowledge gap in understanding their domain-specific effectiveness. This oversight may stem from the sector's unique demands for accuracy and the technical specialization required. Addressing the challenges of building an aerospace QA system requires a model with in-depth technical comprehension, able to deliver precise and contextually relevant answers across a wide range of specialized questions. Moreover, constructing a comprehensive dataset for such complex, evolving knowledge domains presents additional hurdles. This study provides an empirical assessment of three large language models—Gemma2, LLaMA, and Phi3—on a carefully curated dataset of 300 aerospace questions. Using expert human evaluation to validate model performance, we identify each model's strengths, limitations, and practical applicability in aerospace QA. Our findings highlight that while these models show promise in answering aerospace-specific questions, their accuracy, logical structure, and depth of procedural understanding vary. These insights contribute valuable guidance for future improvements in knowledge transfer, operational support, and technical training tools within the aerospace industry.},
  keywords={Training;Analytical models;Adaptation models;Accuracy;Large language models;Question answering (information retrieval);Safety;Reliability;Aerospace industry;Knowledge transfer;Aerospace Question Answering;Large Language Models;Empirical Analysis},
  doi={10.1109/ICEAAI64185.2025.10957038},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10677925,
  author={Peng, Fei and Fu, Huiyuan and Ming, Anlong and Wang, Chuanming and Ma, Huadong and He, Shuai and Dou, Zifei and Chen, Shu},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={AIGC Image Quality Assessment via Image-Prompt Correspondence}, 
  year={2024},
  volume={},
  number={},
  pages={6432-6441},
  abstract={In the rapidly evolving landscape of deep learning, generative models such as Generative Adversarial Networks (GANs) and diffusion models have significantly advanced the capabilities of Artificial Intelligence Generated Content (AIGC). These technologies have streamlined the creative process, enabling AI to autonomously produce a diverse range of content with minimal human input. Despite the remarkable progress in AI-generated images (AIGIs), evaluating the quality of AIGIs remains a complex challenge. Traditional image quality assessment (IQA), focusing on aspects like distortion and blurriness, are insufficient for capturing the correspondence between AIGIs and their prompts. To address this, we propose a novel AIGC image quality assessment (AIGCIQA) framework that emphasizes the correspondence between images and prompts. Utilizing the CLIP model’s pre-trained image and text encoders, our method effectively measures the correspondence between visual and textual inputs. By transforming the assessment into classification probabilities and subsequently into a precise regression task, our method enhances the CLIP model’s performance in AIGCIQA. Our method’s effectiveness is confirmed by its first place in the image track of the NTIRE 2024 Quality Assessment for AI-Generated Content challenge and its state-of-the-art (SOTA) performance on benchmark datasets AGIQA-1K, AGIQA-3K, and AIG-CIQA2023. This research represents a significant advancement in the field, offering an efficient and versatile tool for the evaluation of AIGIs and contributing to the ongoing development of AIGC technologies. Our codes are available at https://github.com/pf0607/IPCE.},
  keywords={Image quality;Visualization;Refining;Focusing;Benchmark testing;Streaming media;Generative adversarial networks},
  doi={10.1109/CVPRW63382.2024.00644},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10465950,
  author={Katrojwar, Himanshu R. and Atkar, Siddhesh D. and Raut, Shreepad R. and Bhoge, Harsh N. and Agrawal, Rahul and Dhule, Chetan},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Comprehensive Study on ChatGPT Sentiment Analysis and Visualization}, 
  year={2023},
  volume={},
  number={},
  pages={1244-1248},
  abstract={The rapid growth of artificial intelligence (AI) is poised to reshape industries and societal aspects, driven by its ability to simulate human intelligence and perform tasks requiring humanlike thinking and learning. ChatGpt has been leading this growth since its inception, enhancing user experience and garnering over 100 million users by February 2023. Social Networking sites have been a source for sharing the sentiments. This research explores tweets on ChatGpt in the field of sentiment analysis and its integration with data visualization techniques to enhance the comprehension of textual data. The research proposed a holistic approach by exploring the methodologies such as data collection, data preprocessing, tokenization, sentiment analysis using Natural Language Processing, accuracy assessment and visualization. For training and testing a dataset has been gathered from Kaggle which daily gets updated. The proposed study gives comprehensive results about sentiments on ChatGPT and explores different visualization techniques.},
  keywords={Training;Sentiment analysis;Social networking (online);Data visualization;Learning (artificial intelligence);Chatbots;User experience;Artificial Intelligence;ChatGpt;GPT;Sentiment;Visualization;Natural Language Processing;Twitter;Analysis},
  doi={10.1109/ICAICCIT60255.2023.10465950},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10487259,
  author={Kim, Dae-Kyoo and Chen, Jingshu and Ming, Hua and Lu, Lunjin},
  booktitle={2023 Congress in Computer Science, Computer Engineering, & Applied Computing (CSCE)}, 
  title={Assessment of ChatGPT's Proficiency in Software Development}, 
  year={2023},
  volume={},
  number={},
  pages={2637-2644},
  abstract={This paper presents an assessment of ChatGPT's proficiency in software development, using an online tour reservation system (TORS) as a case study. The findings indicate that ChatGPT has significant potential in software development, demonstrating its capabilities in assisting various activities throughout the development process, including requirements analysis, domain modeling, design modeling, and implementation. Notably, the model performed well in implementation, generating more than 90% of the code and fixing a majority of errors. It also demonstrated its capability in making design decisions in the design phase. However, the study also identified non-trivial limitations, such as a lack of traceability and inconsistencies among produced artifacts, which required human involvement. Overall, the results suggest that when combined with human developers, ChatGPT can serve as a valuable tool in software development. It has the potential to enhance productivity and efficiency in various aspects of the development process, while acknowledging the need for human expertise to mitigate the limitations.},
  keywords={Productivity;Analytical models;Codes;Chatbots;Software;assessment;ChatGPT;generative artificial intelligence;software development},
  doi={10.1109/CSCE60160.2023.00421},
  ISSN={},
  month={July},}@INPROCEEDINGS{10628503,
  author={Hassani, Shabnam and Sabetzadeh, Mehrdad and Amyot, Daniel and Liao, Jain},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={Rethinking Legal Compliance Automation: Opportunities with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={432-440},
  abstract={As software-intensive systems face growing pressure to comply with laws and regulations, providing automated support for compliance analysis has become paramount. Despite advances in the Requirements Engineering (RE) community on legal compliance analysis, important obstacles remain in developing accurate and generalizable compliance automation solutions. This paper highlights some observed limitations of current approaches and examines how adopting new automation strategies that leverage Large Language Models (LLMs) can help address these shortcomings and open up fresh opportunities. Specifically, we argue that the examination of (textual) legal artifacts should, first, employ a broader context than sentences, which have widely been used as the units of analysis in past research. Second, the mode of analysis with legal artifacts needs to shift from classification and information extraction to more end-to-end strategies that are not only accurate but also capable of providing explanation and justification. We present a compliance analysis approach designed to address these limitations. We further outline our evaluation plan for the approach and provide preliminary evaluation results based on data processing agreements (DPAs) that must comply with the General Data Protection Regulation (GDPR). Our initial findings suggest that our approach yields substantial accuracy improvements and, at the same time, provides justification for compliance decisions.},
  keywords={Automation;Accuracy;Law;Large language models;Information retrieval;Data processing;Regulation;Legal Compliance;Legal Requirements;Large Language Models;GPT-4;GDPR},
  doi={10.1109/RE59067.2024.00051},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10842863,
  author={Jaiswal, Priyanka and Dhomne, Anushree and Rawarkar, Sakshi and Bulkunde, Sanket and Lanjewar, Sarvesh and Mundel, Vedant},
  booktitle={2024 2nd DMIHER International Conference on Artificial Intelligence in Healthcare, Education and Industry (IDICAIEI)}, 
  title={Interactive Coding Platform with Code Summarizer}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study presents a Code Summarizer cum Explanation Tool which helps as the student specially those who are beginner in the world of coding to understand other’s solution for a given problem statement. Our approach involves the utilization of this state-of- the-art language model, widely acknowledged for its prowess in handling various text- related tasks such as code generation and summarization. In this study we have use an open-sourced state-of-the art large language model which is used for many downstream text related task such as code generation, code summarisation, etc. and consist of 7 Billion parameters (weights & biases) developed by Technology Innovation Institute (TIIUAE). We fine-tuned the said model on our custom dataset for code explanation task. We have fine-tuned the model for 1 epoch which took approximate 3 hours on 590 steps. As a result we have obtained a brief summary, when given code as a prompt input. By bridging the gap between theoretical understanding and practical application, our Code Summarizer/Explanation Tool can become an useful tool for beginners on their coding journey.},
  keywords={Industries;Technological innovation;Codes;Art;Atmospheric modeling;Large language models;Education;Medical services;User interfaces;Encoding;Code summarization;Falcon 7B;CodeBERT;Natural Language;Transfer Learning;Large Language Model},
  doi={10.1109/IDICAIEI61867.2024.10842863},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10795351,
  author={Khelifi, Jasem and Chouchen, Moataz and Ouni, Ali and Wang, Dong and Kula, Raula Gaikovina and Hamza, Salma and Mkaouer, Mohamed Wiem},
  booktitle={2024 IEEE International Conference on Source Code Analysis and Manipulation (SCAM)}, 
  title={GitRev: An LLM-Based Gamification Framework for Modern Code Review Activities}, 
  year={2024},
  volume={},
  number={},
  pages={235-241},
  abstract={Modern code review (MCR) is recognized as an effective software quality assurance practice that is broadly adopted by open-source and commercial software projects. MCR is most effective when developers follow best practices, as it improves code quality, enhances knowledge transfer, increases team awareness and shares code ownership. However, prior work highlights that poor code review practices are common and often manifest in the form of low review participation and engagement, shallow review, and toxic communications. To address these issues, we introduce GitRev, a novel approach that applies gamification mechanisms to boost developer motivation and engagement. GitRev is built on top of a Large Language Model (LLM), used as a points-based reward system that leverages the code change context, and code review activities. We implement GitRev as a GitHub app with a web browser extension that consists of a client-side web browser extension that gamifies the GitHub user interface, and a server-side composed of a Node.js server for authentication and data management. To evaluate GitRev, we conduct a controlled experiment with 86 graduate and undergraduate students. Results indicate the promising potential of our approach for improving the code review process and developers' engagement. GitRev is publicly available at https://anonymous.40pen.science/r/GitRev-OB74},
  keywords={Codes;Reviews;Source coding;Large language models;Software quality;User interfaces;Browsers;Servers;Knowledge transfer;Software development management;Modern Code Review;GitHub;Gamification},
  doi={10.1109/SCAM63643.2024.00031},
  ISSN={2470-6892},
  month={Oct},}@INPROCEEDINGS{10810102,
  author={Henry, Matthew Martianus and Heryanto, Nur Adhianti and Isnan, Mahmud and Nugroho, Kuncahyo Setyo and Pardamean, Bens},
  booktitle={2024 9th International Conference on Information Technology and Digital Applications (ICITDA)}, 
  title={Automatic Multiple Choice Question Generation: A Systematic Literature Review}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Despite their drawbacks, multiple-choice questions (MCQ) have been widely used to assess the students' understanding of lectures through examinations. The development of automatic MCQ generation is beneficial, especially for educators. As a starting point for further development, a Systematic Literature Review (SLR) is conducted to uncover current trends, future challenges, and opportunities in automatic MCQ generation. Previously, an SLR was conducted, but it lacks coverage of the utilization of transformer-based models. This SLR covers the development of automatic MCQ generation using either traditional or advanced approaches such as Transformers. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework was used to gather the data from Scopus, IEEE Xplore, SpringerLink, arXiv, and Semantic Scholar. The included articles must be open-access computer science conference papers or journal articles and written in English less than five years ago. Four independent reviewers analyzed the research workflow, evaluation metric, and dataset used in each study. There are 18 included studies, where 17% (n = 3) studies are from 2024, 33% (n = 6) studies are from 2023, 22% (n = 4) studies are from 2022, 11% (n = 2) studies are from 2021, and 17% (n = 3) studies are from 2020. There are 33% (n = 6) of the studies used the traditional feature-based engineering approach, 39% (n = 7) of the studies used the Transformer-based model fine-tuning approach, and the remaining used novel approaches. The study found that BERT variants are the most utilized Transformer-based model in automatic MCQ. The research notes some challenges, but also open various opportunities for further research, including Large Language Model (LLM) utilization for automatic MCQ generation, the utilization BERT-based models for standardized machine-learned evaluation metrics, and the initiative for the creation of an MCQ dataset benchmark.},
  keywords={Measurement;Semantics;Reinforcement learning;Benchmark testing;Ontologies;Transformers;Question generation;Prompt engineering;Standards;Systematic literature review;Multiple choice question;question generation;systematic literature review;Transformer model},
  doi={10.1109/ICITDA64560.2024.10810102},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10808018,
  author={Chen, Qunqiang and Qian, Mei and Zheng, Hao and Huang, Rujuan},
  booktitle={2024 5th International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI)}, 
  title={Research on WeChat Question and Answer Applet Based on “Big Language Model”}, 
  year={2024},
  volume={},
  number={},
  pages={371-376},
  abstract={Accompanied by the rapid development of the artificial intelligence industry, the world's major Internet companies have begun to release their own big language models, the rapid development of artificial intelligence is driving a technological revolution, and it will eventually evolve into a social change. People can use these big language models to facilitate work and learning. In the future, human teachers can teach with the help of AI robots to realize the collaboration between the virtual world and the real world, and synchronize the classroom teaching tasks. Software development engineers can improve the quality of their code with the help of AI. Artificial intelligence applied to smart bionics to provide patients with bionic organs will bring about a number of medical changes. Everyone can enjoy the dividends of the rapid development of the artificial intelligence industry, but it is inevitable that many problems will arise while it continues to develop. Finally, this paper develops a certain introduction to the development of AI Q&A software with the help of a large language model.},
  keywords={Industries;Computational modeling;Biological system modeling;Large language models;Force;Software;Data models;Artificial intelligence;Robots;Software development management;Large language model;The development of AI Q&A software},
  doi={10.1109/ICHCI63580.2024.10808018},
  ISSN={},
  month={Sep.},}@ARTICLE{10880482,
  author={Li, Na and Zhou, Chunyi and Gao, Yansong and Chen, Hui and Zhang, Zhi and Kuang, Boyu and Fu, Anmin},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Machine Unlearning: Taxonomy, Metrics, Applications, Challenges, and Prospects}, 
  year={2025},
  volume={},
  number={},
  pages={1-21},
  abstract={Personal digital data is a critical asset, and governments worldwide have enforced laws and regulations to protect data privacy. Data users have been endowed with the “right to be forgotten” (RTBF) of their data. In the course of machine learning (ML), the forgotten right requires a model provider to delete user data and its subsequent impact on ML models upon user requests. Machine unlearning (MU) emerges to address this, which has garnered ever-increasing attention from both industry and academia. Specifically, MU allows model providers to eliminate the influence of unlearned data without retraining the model from scratch, ensuring the model behaves as if it never encountered this data. While the area has developed rapidly, there is a lack of comprehensive surveys to capture the latest advancements. Recognizing this shortage, we conduct an extensive exploration to map the landscape of MU including the (fine-grained) taxonomy of unlearning algorithms under centralized and distributed settings, debate on approximate unlearning, verification and evaluation metrics, and challenges and solutions across various applications. We also focus on the motivations, challenges, and specific methods for deploying unlearning in large language models (LLMs), as well as the potential attacks targeting unlearning processes. The survey concludes by outlining potential directions for future research, hoping to serve as a beacon for interested scholars.},
  keywords={Data models;Surveys;Measurement;Training;Electronic mail;Data privacy;Taxonomy;General Data Protection Regulation;Computational modeling;Approximation algorithms;Data privacy;federated learning (FL);large language model (LLM);machine learning (ML);machine unlearning (MU)},
  doi={10.1109/TNNLS.2025.3530988},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10590542,
  author={Bessas, Nikos and Tzanaki, Eleni and Vavougios, Dionisios and Plagianakos, Vassilis P.},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Implementing AI in Physics Lessons in the High School}, 
  year={2023},
  volume={},
  number={},
  pages={1775-1779},
  abstract={ChatGPT is a relatively recent application, free to the general public, released at the end of November 2022 and rooted in artificial intelligence. The educational community is still debating how such an application could be used in the teaching and learning area, with the facilities it offers and the risks it entails. The purpose of this paper is to present how such an application responds to physics topics at the high school level, and to suggest ways to use it properly. In order to cover the issue comprehensively, it is approached from both the teacher's and the student's point of view.},
  keywords={Ethics;Data privacy;Scientific computing;Education;Learning (artificial intelligence);Chatbots;Task analysis;Artificial Intelligence;ChatGPT;Physics;Education;Teaching;Learning},
  doi={10.1109/CSCI62032.2023.00293},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{10992488,
  author={Milliken, Louis and Kang, Sungmin and Yoo, Shin},
  booktitle={2025 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)}, 
  title={Beyond pip Install: Evaluating LLM Agents for the Automated Installation of Python Projects}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Many works have recently proposed the use of Large Language Model (LLM) based agents for performing ‘repository level’ tasks, loosely defined as a set of tasks whose scopes are greater than a single file. This has led to speculation that the orchestration of these repository-level tasks could lead to software engineering agents capable of performing almost independently of human intervention. However, of the suite of tasks that would need to be performed by this autonomous software engineering agent, we argue that one important task is missing, which is to fulfil project level dependency by installing other repositories. To investigate the feasibility of this repository level installation task, we introduce a benchmark of of repository installation tasks curated from 40 open source Python projects, which includes a ground truth installation process for each target repository. Further, we propose Installamatic, an agent which aims to perform and verify the installation of a given repository by searching for relevant instructions from documentation in the repository. Empirical experiments reveal that that 55% of the studied repositories can be automatically installed by our agent at least one out of ten times. Through further analysis, we identify the common causes for our agent's inability to install a repository, discuss the challenges faced in the design and implementation of such an agent and consider the implications that such an agent could have for developers.},
  keywords={Correlation;Large language models;Documentation;Benchmark testing;Software;Python;Software engineering;LLMs;installation;documentation},
  doi={10.1109/SANER64311.2025.00009},
  ISSN={2640-7574},
  month={March},}@INPROCEEDINGS{10859640,
  author={Bao, Ailisi and Wei, Tianyi},
  booktitle={2024 IEEE 4th International Conference on Data Science and Computer Application (ICDSCA)}, 
  title={3D X-ray Image Reconstruction Based on Collaborative Neural Radiance Field and Ensemble Learning}, 
  year={2024},
  volume={},
  number={},
  pages={677-683},
  abstract={This research examines the utilization of an integrated learner model that combines Generative Adversarial Network (GAN) and Neural Radiation Field (NeRF) for image reconstruction. The advancement of deep learning technology has led to significant progress in image reconstruction, particularly in addressing conventional issues such as image blurring, noise interference, and high computational demands. This work presents a model that integrates GRAF (Generated Radiation Field) with a unified learner designed to deduce anatomical 3D structures from a limited number or a single observation of X-rays. The model is trained using three distinct configurations of GAN models to enhance its stability and performance. In a generative adversarial network, the generator (G) strives to make counterfeit data that is indistinguishable from authentic data, whereas the discriminator (D) endeavors to differentiate between the genuine data and the counterfeit data generated by G. Through this adversarial training technique, the two entities iteratively co-evolve during the game to enhance model performance. The experimental results indicate that the model attains a peak signal-to-noise ratio (PSNR) of 35.01 and a structural similarity index (SSIM) of 0.928, demonstrating superior image quality and enhanced structural similarity. This research examines the model's potential and limitations in addressing the characteristics and issues of imaging data.},
  keywords={Image quality;Solid modeling;Adaptation models;Three-dimensional displays;PSNR;Computational modeling;Noise;Generative adversarial networks;Data models;Image reconstruction;3D image reconstruction;NeRF;ensemble learning;GAN},
  doi={10.1109/ICDSCA63855.2024.10859640},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10810553,
  author={Wangwiwattana, Chatchai and Jantarick, Worawut},
  booktitle={2024 8th International Conference on Information Technology (InCIT)}, 
  title={Building Intelligent Academic Service Agents: FAQ Extraction and Chatbots With Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={370-375},
  abstract={This study proposes an academic chatbot system utilizing large language models (LLMs) to assist students with university-related tasks. The system is designed to simplify the maintenance of school information by extracting FAQs directly from instant messaging platforms. To ensure safety and reliability, the system incorporates a two-step filtering process. In this study, 300 real-world conversations were analyzed, resulting in the extraction of 95 registrar-related Q&A pairs that were subsequently trained into the system. The system’s performance was evaluated based on three key metrics: context relevance, answer relevance, and groundedness. The results demonstrated high satisfaction levels, with scores of 0.94, 0.93, and 0.92, respectively.},
  keywords={Measurement;Large language models;Customer services;Education;Oral communication;Instant messaging;Chatbots;Safety;Maintenance;Information technology;Large Language Models (LLMs);education;chatbot},
  doi={10.1109/InCIT63192.2024.10810553},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10989036,
  author={Ji, Suhwan and Lee, Sanghwa and Lee, Changsup and Han, Yo-Sub and Im, Hyeonseung},
  booktitle={2025 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Impact of Large Language Models of Code on Fault Localization}, 
  year={2025},
  volume={},
  number={},
  pages={302-313},
  abstract={Identifying the point of error is imperative in software debugging. Traditional fault localization (FL) techniques rely on executing the program and using the code coverage matrix in tandem with test case results to calculate a suspiciousness score for each method or line. Recently, learning-based FL techniques have harnessed machine learning models to extract meaningful features from the code coverage matrix and improve FL performance. These techniques, however, require compilable source code, existing test cases, and specialized tools for generating the code coverage matrix for each programming language of interest. In this paper, we propose, for the first time, a simple but effective sequence generation approach for fine-tuning large language models of code (LLMCs) for FL tasks. LLMCs have recently received much attention for various software engineering problems. In line with these, we leverage the innate understanding of code that LLMCs have acquired through pre-training on large code corpora. Specifically, we fine-tune 13 representative encoder, encoder-decoder, and decoder-based LLMCs (across 7 different architectures) for FL tasks. Unlike previous approaches, LLM Cs can analyze code sequences that do not compile. Still, they have a limitation on the length of the input data. Therefore, for a fair comparison with existing FL techniques, we extract methods with errors from the project-level benchmark, Defects4J, and analyze them at the line level. Experimental results show that LLMCs fine-tuned with our approach successfully pinpoint error positions in 50.6%, 64.2%, and 72.3% of 1,291 methods in Defects4J for Top-1/3/5 prediction, outperforming the best learning-based state-of-the-art technique by up to 1.35, 1.12, and 1.08 times, respectively. We also conduct an in-depth investigation of key factors that may affect the FL performance of LLMCs. Our findings suggest promising research directions for FL and automated program repair tasks using LLMCs.},
  keywords={Location awareness;Software testing;Codes;Large language models;Source coding;Computer architecture;Benchmark testing;Feature extraction;Software debugging;Software engineering;Fault Localization;Vulnerability Detection;Large Language Model of Code;Fine-Tuning;Deep Learning},
  doi={10.1109/ICST62969.2025.10989036},
  ISSN={2159-4848},
  month={March},}@ARTICLE{10918845,
  author={Li, Haoyang and Wang, Zan and Liang, Wei and Wang, Yizhuo},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={X's Day: Personality-Driven Virtual Human Behavior Generation}, 
  year={2025},
  volume={31},
  number={5},
  pages={3514-3524},
  abstract={Developing convincing and realistic virtual human behavior is essential for enhancing user experiences in virtual reality (VR) and augmented reality (AR) settings. This paper introduces a novel task focused on generating long-term behaviors for virtual agents, guided by specific personality traits and contextual elements within 3D environments. We present a comprehensive framework capable of autonomously producing daily activities autoregressively. By modeling the intricate connections between personality characteristics and observable activities, we establish a hierarchical structure of Needs, Task, and Activity levels. Integrating a Behavior Planner and a World State module allows for the dynamic sampling of behaviors using large language models (LLMs), ensuring that generated activities remain relevant and responsive to environmental changes. Extensive experiments validate the effectiveness and adaptability of our approach across diverse scenarios. This research makes a significant contribution to the field by establishing a new paradigm for personalized and context-aware interactions with virtual humans, ultimately enhancing user engagement in immersive applications. Our project website is at: https://behavior.agent-x.cn/.},
  keywords={Behavioral sciences;Three-dimensional displays;Solid modeling;Psychology;Training;Generators;Real-time systems;Multi-agent systems;Decision making;Complexity theory;Personality-driven Behavior;Behavior Generation;Contextual Scene},
  doi={10.1109/TVCG.2025.3549574},
  ISSN={1941-0506},
  month={May},}@INPROCEEDINGS{10703784,
  author={Gudaparthi, Hemanth and Niu, Nan and Zhang, Jianzhang and Savolainen, Juha},
  booktitle={2024 IEEE International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={Applying Cluster Hypothesis to the Next Release Problem}, 
  year={2024},
  volume={},
  number={},
  pages={258-263},
  abstract={The aim of the next release problem (NRP) is to decide the most suitable subset of candidate requirements to include in the software system’s upcoming version. To advance the automation degree of contemporary NRP solutions, we investigate in this paper the cluster hypothesis where we balance the to-be-released candidates with the already implemented features. Clustering the balanced set gives rise to a fully automatic NRP solution, using only the features’ natural language descriptions and a project’s release history. Our experiments on a total of $\mathbf{1, 2 9 6}$ requirements from four real-world systems’ 78 NRP instances show that å k-means best fulfills the cluster hypothesis, and also outperforms the zero-shot learning capability of large language models (LLMs) in solving the NRP.},
  keywords={Automation;Large language models;Zero shot learning;Natural languages;Data science;Software;Data models;Rough surfaces;History;strategic release planning;requirements prioritization;machine learning;large language models},
  doi={10.1109/IRI62200.2024.00060},
  ISSN={2835-5776},
  month={Aug},}@ARTICLE{10902362,
  author={Fidelangeli, Alessia and Galli, Federico and Loreggia, Andrea and Pisano, Giuseppe and Rovatti, Riccardo and Santin, Piera and Sartor, Giovanni},
  journal={IEEE Access}, 
  title={The Summarization of Italian Tax-Law Decisions: The Case of the PRODIGIT Project}, 
  year={2025},
  volume={13},
  number={},
  pages={38833-38855},
  abstract={This paper presents an innovative approach to the automated summarization of tax-law decisions developed within the PRODIGIT project. The work addresses the growing challenge of managing large volumes of judicial rulings, which often hinder access to relevant legal precedents. We introduce a hybrid methodology that combines extractive and abstractive summarization techniques, with a particular emphasis on the application of large language models (LLMs) for abstractive summarization. Our approach includes designing and evaluating various prompt-based configurations, leading to the development of a “combined summarization” method, where distinct summary components are generated and integrated into a cohesive text. Experimental results, validated by tax law experts, demonstrate that this method yields the most comprehensive and accurate summaries. Additionally, we explore the integration of these summaries into semantic search functions, enabling users to retrieve and comprehend relevant case law efficiently. Our findings highlight the potential of AI-driven summarization tools to enhance legal transparency, promote judicial consistency, and support the work of judges, lawyers, and legal scholars.},
  keywords={Law;Finance;Large language models;Hands;Databases;Europe;Text summarization;Prototypes;Natural language processing;Informatics;Tax law;artificial intelligence;abstractive summarization;extractive summarization;large language models},
  doi={10.1109/ACCESS.2025.3545419},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{11014940,
  author={Duarte, Carlos Eduardo},
  booktitle={2025 IEEE 22nd International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Automated Microservice Pattern Instance Detection Using Infrastructure-as-Code Artifacts and Large Language Models}, 
  year={2025},
  volume={},
  number={},
  pages={161-166},
  abstract={Documenting software architecture is essential to preserve architecture knowledge, even though it is frequently costly. Architecture pattern instances, including microservice pattern instances, provide important structural software information. Practitioners should document this information to prevent knowledge vaporization. However, architecture patterns may not be detectable by analyzing source code artifacts, requiring the analysis of other types of artifacts. Moreover, many existing pattern detection instance approaches are complex to extend. This article presents our ongoing PhD research, early experiments, and a prototype for a tool we call MicroPAD for automating the detection of microservice pattern instances. The prototype uses Large Language Models (LLMs) to analyze Infrastructure-as-Code (IaC) artifacts to aid detection, aiming to keep costs low and maximize the scope of detectable patterns. Early experiments ran the prototype thrice in 22 GitHub projects. We verified that 83% of the patterns that the prototype identified were in the project. The costs of detecting the pattern instances were minimal. These results indicate that the approach is likely viable and, by lowering the entry barrier to automating pattern instance detection, could help democratize developer access to this category of architecture knowledge. Finally, we present our overall research methodology, planned future work, and an overview of MicroPAD's potential industrial impact.},
  keywords={Costs;Software architecture;Large language models;Source coding;Microservice architectures;Prototypes;Computer architecture;Software;Knowledge management;Software development management;software architecture;architecture patterns;architecture documentation;pattern identification;knowledge retrieval;microservices;microservice patterns},
  doi={10.1109/ICSA-C65153.2025.00030},
  ISSN={2768-4288},
  month={March},}@INPROCEEDINGS{10956736,
  author={Arista, Artika and Shuib, Liyana and Ismail, Maizatul Akmar},
  booktitle={2024 International Conference on Informatics, Multimedia, Cyber and Information System (ICIMCIS)}, 
  title={Systematic Literature Review and Bibliometric Analysis on Ethical Policies for Generative Artificial Intelligence (GAI) in Higher Education Institutions (HEIs)}, 
  year={2024},
  volume={},
  number={},
  pages={454-459},
  abstract={Generative Artificial Intelligence (GAI) has revolutionized higher education with features like instant feedback, resource and material creation, adaptive learning, interactivity, and more. However, GAI also brings with it a number of serious challenges that raise ethical and moral concerns regarding academic integrity. To carry out this transition process, it will be necessary to develop clear guidelines that adhere to integrity standards and ethical codes of higher education institutions. In addition to offering responses to a number of research questions, the purpose of this study is to further the current discourse surrounding the moral guidelines for GAI in higher education. Using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) technique and Bibliometric Analysis using VOSviewer, 37 related research studies were reviewed and evaluated. The results demonstrate that the number of articles published has been increasing over time, with the largest number of scientific publications occurring in 2024. This can be explained by the fact that, despite the fact that GAI offers benefits and drawbacks for the educational sector, particularly for higher education, it also makes clear how important it is for professionals and organizations to use GAI tools in order to handle ethical issues by continuously developing policies. By creating norms and policies, future ethical problems with GAI in education may be more accurately predicted. The engagement and dedication of academic experts and other relevant stakeholders are essential to achieving this goal of increasing public awareness and effectively utilizing GAI technology.},
  keywords={Ethics;Generative AI;Education;Bibliometrics;Standards organizations;Organizations;Multimedia databases;Stakeholders;Systematic literature review;Guidelines;Systematic Literature Review;Bibliometric Analysis;Ethical Policies;Generative Artificial Intelligence (GAI);Higher Education Institutions (HEIs)},
  doi={10.1109/ICIMCIS63449.2024.10956736},
  ISSN={2837-5203},
  month={Nov},}@INPROCEEDINGS{10607286,
  author={Chen, Chiung-Hui},
  booktitle={2024 9th International Conference on Big Data Analytics (ICBDA)}, 
  title={Web3.0 Generative Art- A Co-Creation System in Environmental Sustainability Concept Form}, 
  year={2024},
  volume={},
  number={},
  pages={264-269},
  abstract={In 2021, the first year of Metaverse, Web3.0 ecosystems emerged as a result of the Internet's de-centralized evolution. In the Web3.0 space, there has been a very active advancement of the generative art non-fungible token, which is a special asset stored on a blockchain that allows creators to buy and sell assets and verify ownership. In other words, as it reconstructs the interpersonal relationship, the generative art non-fungible token must carry cultural values to be meaningful, and waiting to observe artificial intelligence generative art in the future requires a new mindset and posture. Design thinking is a design-based approach to solve today's complex problems. This study thus addresses the new Web3.0 ecosystem and introduces environmental sustain ability issues and computational thinking in the form of generative art to discuss the possibilities of future design thinking. By linking with social information, this study also creates an intersection with heterogeneous knowledge and stimulates a new thinking pattern that is different from previous ones. This project of design and research in the Metaverse virtual environment is still a novel topic. Reviewing past literature indicates that relevant papers are very scarce, and more resources are urgently needed for research in this field.},
  keywords={Art;Metaverse;Ecosystems;Green products;Big Data;Internet;Nonfungible tokens;blockchain;Web3.0;generative art;collaboration;sustainability},
  doi={10.1109/ICBDA61153.2024.10607286},
  ISSN={},
  month={March},}@INPROCEEDINGS{10500608,
  author={Montezuma, Julio Ricardo Martinez and Chong, Mario},
  booktitle={2024 IEEE World Engineering Education Conference (EDUNINE)}, 
  title={Generative Artificial Intelligence Impact on Education and Industry: An Ethical Dimension}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This research stresses the importance of ethics in addressing ethical challenges and serving as a crucial guide in industry and education. It is recommended that organizations integrate ethical principles into their guiding documents and encourage ethical reflection among students. Ethics plays a crucial role in the generative artificial intelligence (GAI) responsible application for the benefit of society. The ethics use is essential in weighing up GAI's strengths and weaknesses.},
  keywords={Industries;Training;Ethics;Technological innovation;Generative AI;Education;Collaboration;Generative Artificial Intelligence;Ethics in Technology;Educational Innovation;Industrial Automation;Ethical Challenges},
  doi={10.1109/EDUNINE60625.2024.10500608},
  ISSN={},
  month={March},}@INPROCEEDINGS{10359304,
  author={Viet, Tung Do and Markov, Konstantin},
  booktitle={2023 12th International Conference on Awareness Science and Technology (iCAST)}, 
  title={Using Large Language Models for Bug Localization and Fixing}, 
  year={2023},
  volume={},
  number={},
  pages={192-197},
  abstract={As part of their learning journey, students frequently encounter challenges and make errors, especially with algorithmic programming questions. Regrettably, providing tailored solutions for these mistakes can impose a significant burden on instructors in terms of time and effort. To address this, automated program repair (APR) techniques have been explored to generate such fixes automatically. Previous research has investigated the use of symbolic and neural approaches for APR in the educational domain. However, both types of approaches necessitate substantial engineering endeavors or extensive data and training. In this study, we propose the utilization of a large language model trained on code to construct an APR system specifically designed for student programs. Our system has the capability to rectify semantic errors by employing a few-shot example generation pipeline solely based on the input code. We assess the performance of our system on one dataset of algorithm implementations, namely QuixBugs. The results demonstrate that the novel example generation pipeline not only enhances the overall system’s performance but also ensures its stability.},
  keywords={Location awareness;Training;Codes;Computer bugs;Semantics;Pipelines;Maintenance engineering;bug localization;bug fixing;program repair;large language model;few-shot prompting;in-context learning},
  doi={10.1109/iCAST57874.2023.10359304},
  ISSN={2325-5994},
  month={Nov},}@INPROCEEDINGS{10652301,
  author={U, Dharaneswaran S and T, Jaswanth Reddy and S, Julius Fusic and M, Balamurali and H, Hemraj N},
  booktitle={2024 IEEE Students Conference on Engineering and Systems (SCES)}, 
  title={Optimizing Drone Construction: Topology Optimization and Generative Design}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study investigates and compares the efficacy of two cutting-edge design methodologies, namely topology optimization and generative design, in the context of optimizing drone construction. Drones play a pivotal role in numerous industries, and enhancing their design efficiency is crucial for improved performance and functionality. The research focuses on evaluating the advantages, limitations, and implications of these methodologies with respect to design complexity, manufacturability, and overall performance. The findings provide valuable insights for engineers seeking optimal solutions in the construction of drones. The proposed work provides a comparative assessment of topology optimization and generative design methodologies in the field of drone designing. By thoroughly exploring the comparative assessment of topology optimization and generative design, this study aims to provide engineers with a roadmap for making informed decisions in the design and construction of efficient and high-performance drones.},
  keywords={Industries;Design methodology;Topology;Complexity theory;Optimization;Drones;boundary conditions;topology optimization;generative design;base design;structural analysis},
  doi={10.1109/SCES61914.2024.10652301},
  ISSN={},
  month={June},}@ARTICLE{10403908,
  author={Ozkan-Okay, Merve and Akin, Erdal and Aslan, ÖMER and Kosunalp, Selahattin and Iliev, Teodor and Stoyanov, Ivaylo and Beloev, Ivan},
  journal={IEEE Access}, 
  title={A Comprehensive Survey: Evaluating the Efficiency of Artificial Intelligence and Machine Learning Techniques on Cyber Security Solutions}, 
  year={2024},
  volume={12},
  number={},
  pages={12229-12256},
  abstract={Given the continually rising frequency of cyberattacks, the adoption of artificial intelligence methods, particularly Machine Learning (ML), Deep Learning (DL), and Reinforcement Learning (RL), has become essential in the realm of cybersecurity. These techniques have proven to be effective in detecting and mitigating cyberattacks, which can cause significant harm to individuals, organizations, and even countries. Machine learning algorithms use statistical methods to identify patterns and anomalies in large datasets, enabling security analysts to detect previously unknown threats. Deep learning, a subfield of ML, has shown great potential in improving the accuracy and efficiency of cybersecurity systems, particularly in image and speech recognition. On the other hand, RL is again a subfield of machine learning that trains algorithms to learn through trial and error, making it particularly effective in dynamic environments. We also evaluated the usage of ChatGPT-like AI tools in cyber-related problem domains on both sides, positive and negative. This article provides an overview of how ML, DL, and RL are applied in cybersecurity, including their usage in malware detection, intrusion detection, vulnerability assessment, and other areas. The paper also specifies several research questions to provide a more comprehensive framework to investigate the efficiency of AI and ML models in the cybersecurity domain. The state-of-the-art studies using ML, DL, and RL models are evaluated in each Section based on the main idea, techniques, and important findings. It also discusses these techniques’ challenges and limitations, including data quality, interpretability, and adversarial attacks. Overall, the use of ML, DL, and RL in cybersecurity holds great promise for improving the effectiveness of security systems and enhancing our ability to protect against cyberattacks. Therefore, it is essential to continue developing and refining these techniques to address the ever-evolving nature of cyber threats. Besides, some promising solutions that rely on machine learning, deep learning, and reinforcement learning are susceptible to adversarial attacks, underscoring the importance of factoring in this vulnerability when devising countermeasures against sophisticated cyber threats. We also concluded that ChatGPT can be a valuable tool for cybersecurity, but it should be noted that ChatGPT-like tools can also be manipulated to threaten the integrity, confidentiality, and availability of data.},
  keywords={Computer security;Deep learning;Security;Fraud;Prediction algorithms;Telecommunication traffic;Reinforcement learning;Machine learning;Artificial intelligence;Cyberattacks and solutions;deep learning;machine learning;reinforcement learning;AI tools},
  doi={10.1109/ACCESS.2024.3355547},
  ISSN={2169-3536},
  month={},}@ARTICLE{10310078,
  author={Ren, Xiongfei and Tong, Lili and Zeng, Jia and Zhang, Chen},
  journal={China Communications}, 
  title={AIGC scenario analysis and research on technology roadmap of Internet industry application}, 
  year={2023},
  volume={20},
  number={10},
  pages={292-304},
  abstract={The explosion of ChatGPT is considered to be a milestone in the normalization of artificial intelligence education applications. On the technical line, the cross-modal AI generation application based on human feedback system is accelerated. In the business model, the scenes to realize interactive functions are constantly enriched. This paper reviews the evolution process of AIGC, closely follows the current situation of the coexistence of business acceleration and technical worries in the application of artificial intelligence education, analyzes the application of AIGC education in 7 subdivided fields, and analyzes the optimization direction of application cases from the perspective of perception-cognition-creation technology maturity matrix. The 3 recommendations and 2 follow-up research directions will promote the scientific application of artificial intelligence education in the AIGC period.},
  keywords={Education;Artificial intelligence;Biological system modeling;Chatbots;Computational modeling;Production;Data models;AIGC;artificial intelligence education application;large model},
  doi={10.23919/JCC.fa.2023-0359.202310},
  ISSN={1673-5447},
  month={Oct},}@INPROCEEDINGS{10345786,
  author={Vazquez, Hernan C. and Diaz-Pace, J. Andres and Tommasel, Antonela},
  booktitle={2023 XLIX Latin American Computer Conference (CLEI)}, 
  title={The JavaScript Package Selection Task: A Comparative Experiment Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1-10},
  abstract={When developing Java Script (JS) applications, the assessment and selection of JS packages have become challenging for developers due to the growing number of technology options available. Given a technology need, a common developers' strat-egy is to query Web repositories via search engines (e.g., NPM, Google) and shortlist candidate JS packages. However, these engines might return a long list of results. Furthermore, these results should be ranked according to the developer's criteria. To address these problems, we developed a recommender system called AIDT that assists developers in the package selection task. AIDT relies on meta-search and machine learning techniques to infer the relevant packages for a query. An initial evaluation of AIDT showed good search effectiveness. Recently, the emergence of ChatGPT has opened new opportunities for this kind of assistants, as reported by some experiments. Anyway, human developers should judge whether the recommendations (e.g., JS packages) of these tools are fit to purpose. In this paper, we report on a user study in which we used both AIDT and ChatGPT on a sample of JS-related queries, compared their results, and also validated them against developers' criteria and expectations for the task. Our initial findings show that ChatGPT is not yet on par with AIDT or even human efforts for the task at hand, but the model is flexible to be improved and furthermore, it can provide good arguments for its package choices.},
  keywords={Computational modeling;Machine learning;Search engines;Predictive models;Chatbots;Internet;Metasearch;Package Selection;JavaScript;Recommender System;GPT Model;User Study},
  doi={10.1109/CLEI60451.2023.10345786},
  ISSN={2771-5752},
  month={Oct},}@INPROCEEDINGS{10734659,
  author={Pister, Kaiser and Paul, Dhruba Jyoti and Brophy, Patrick and Joshi, Ishan},
  booktitle={2024 IEEE/ACM International Workshop on Large Language Models for Code (LLM4Code)}, 
  title={PromptSet: A Programmer’s Prompting Dataset}, 
  year={2024},
  volume={},
  number={},
  pages={62-69},
  abstract={The rise of capabilities expressed by large language models has been quickly followed by the integration of the same complex systems into application level logic. Algorithms, programs, systems, and companies are built around structured prompting to black box models where the majority of the design and implementation lies in capturing and quantifying the ‘agent mode’. The standard way to shape a closed language model is to prime it for a specific task with a tailored prompt, often initially handwritten by a human. The textual prompts co-evolve with the codebase, taking shape over the course of project life as artifacts which must be reviewed and maintained, just as the traditional code files might be. Unlike traditional code, we find that prompts do not receive effective static testing and linting to prevent runtime issues. In this work, we present a novel dataset called PromptSet, with more than 61,000 unique developer prompts used in open source Python programs. We perform analysis on this dataset and introduce the notion of a static linter for prompts. Released with this publication is a HuggingFace dataset and a Github repository to recreate collection and processing efforts, both under the name pisterlabs/promptset.CCS CONCEPTS• Computing methodologies → Natural language generation.},
  keywords={Codes;Runtime;Shape;Large language models;Natural language generation;Logic;Standards;Testing;Software development management;Python;Prompt Management;Large Language Models;Dataset;Information systems;Ethnography;Taxonomy},
  doi={},
  ISSN={},
  month={April},}@ARTICLE{10981607,
  author={Zhu, Hancheng and Shi, Ju and Shao, Zhiwen and Yao, Rui and Sun, Kunyang and Li, Leida},
  journal={IEEE Transactions on Fuzzy Systems}, 
  title={Progressively Generated Text-Assisted Image Aesthetic Quality Assessment}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Image Aesthetic Quality Assessment (IAQA) aims to simulate user perceptions to judge the aesthetic quality of images. Due to the high subjectivity of users and the complexity of image aesthetics, modeling IAQA solely at the image level is a compromise. Consequently, existing methods mainly focus on multimodal-based models and achieve effective performance. These methods explore aesthetic comments on images to characterize users and serve as auxiliary text information for multimodal modeling. Unfortunately, this may suffer from two limitations. One limitation is that aesthetic comments are often unavailable for an unknown image in the test phase, and another limitation is that the semantic information of these comments may be uncertain and fuzzy. Therefore, this paper proposes a progressively generated text-assisted image aesthetic quality assessment method, aiming to address the lack of aesthetic comments and the fuzziness of aesthetic judgments in these comments. Specifically, we first adopt a Multimodal Large Language Model (MLLM) to generate aesthetic comments on images by simulating user perceptions and utilize the generated comments to characterize their aesthetic perception to assist in the pre-training of our multimodal-based IAQA model. Then, we design an attribute prediction module to determine the attribute levels of aesthetic judgments and utilize text template construction to further generate explicit descriptions of image aesthetics. Finally, we leverage the generated attribute descriptions to further assist in training our IAQA model. By progressively generating textual auxiliary descriptions of aesthetics for images, the proposed model can gradually determine the aesthetic quality of the images. Massive experimental results indicate that the proposed method outperforms existing mainstream methods on multiple IAQA datasets.},
  keywords={Training;Quality assessment;Image color analysis;Feature extraction;Semantics;Social networking (online);Lighting;Visualization;Deep learning;Adaptation models;Aesthetic quality assessment;attribute prediction;fuzzy description;multimodal modeling;progressively generated text},
  doi={10.1109/TFUZZ.2025.3566145},
  ISSN={1941-0034},
  month={},}@ARTICLE{11027910,
  author={Ye, Fei and Bors, Adrian G.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Training a Dynamic Growing Mixture Model for Lifelong Learning}, 
  year={2025},
  volume={},
  number={},
  pages={1-15},
  abstract={Lifelong learning (LLL) defines a training paradigm that aims to continuously acquire and capture new concepts from a sequence of tasks without forgetting. Recently, dynamic expansion models (DEMs) have been proposed to address catastrophic forgetting under the LLL paradigm. However, the efficiency of DEMs lacks a thorough explanation based on theoretical analysis. In this article, we develop a new theoretical framework that interprets the forgetting process of the DEM as increasing the statistical discrepancy distance between the distribution of the probabilistic representation of the new data and the previously learned knowledge. The theoretical analysis shows that adding new components to a mixture model represents a trade-off between model complexity and its performance. Inspired by the theoretical analysis, we introduce a new DEM, called the growing mixture model (GMM), where generative data components are added according to the novelty of the incoming task information compared to what is already known. A new component selection mechanism considering the model’s already acquired knowledge is employed for updating new DEM’s components, promoting efficient future task learning. We also train a compact student model with samples drawn through the generative mechanisms of the GMM, aiming to accumulate cross-domain representations over time. By employing the student model, we can significantly reduce the number of parameters and make quick inferences during the testing phase.},
  keywords={Data models;Continuing education;Training;Mixture models;Generative adversarial networks;Analytical models;Adaptation models;Linear programming;Computational modeling;Testing;Continual learning;dynamic expansion model (DEM);lifelong generative modeling;lifelong learning (LLL)},
  doi={10.1109/TNNLS.2025.3569156},
  ISSN={2162-2388},
  month={},}@INPROCEEDINGS{10689798,
  author={Singh, Gulbir and Srivastava, Vivek and Kumar, Suneet and Bhatnagar, Vivek and Dhondiyal, Shiv Ashish},
  booktitle={2024 5th International Conference on Electronics and Sustainable Communication Systems (ICESC)}, 
  title={Understanding the Ethical Implications of Generative AI: A Multi-Disciplinary Perspective}, 
  year={2024},
  volume={},
  number={},
  pages={1714-1719},
  abstract={The capacity of generative Artificial Intelligence (AI) to develop material such as writing, graphics, and music is one of its defining characteristics. Generative AI has applications in a broad variety of fields, including but not limited to the following: art, literature, software development, education, product design, healthcare, finance, gaming, entertainment, and many more. From the viewpoint of many disciplines, this research study presents the implications of generative AI, considering the technical, educational, legal, and social aspects of the area. By combining concepts from various domains, this article aims to present a comprehensive understanding of the ethical concerns posed by generative AI. Additionally, the research will provide viable frameworks for resolving these issues.},
  keywords={Ethics;Art;Generative AI;Law;Reviews;Education;Oral communication;Product design;Creativity;Software development management;Generative AI;Artificial Intelligence;Ethics;Machine Learning},
  doi={10.1109/ICESC60852.2024.10689798},
  ISSN={2996-5357},
  month={Aug},}@ARTICLE{11017583,
  author={Rahimi, Fatema and Sadeghi-Niaraki, Abolghasem and Choi, Soo-Mi},
  journal={IEEE Access}, 
  title={Generative AI Meets Virtual Reality: A Comprehensive Survey on Applications, Challenges, and Future Direction}, 
  year={2025},
  volume={13},
  number={},
  pages={94893-94909},
  abstract={The integration of generative artificial intelligence (AI) with virtual reality (VR) is reshaping how immersive environments are designed, personalized, and experienced. Unlike traditional VR systems that rely on static and pre-scripted content, Generative VR leverages AI-driven content generation, multimodal interaction, and contextual adaptation to create dynamic virtual spaces. This paper presents a comprehensive survey of the core components, applications, and challenges associated with Generative VR. It explores its transformative impact across education, healthcare, industrial training, entertainment, and emerging fields such as environmental conservation and virtual tourism. While Generative VR enhances user engagement and realism, it also introduces critical challenges, including computational scalability, ethical concerns, AI explainability, and real-time performance constraints. The paper further identifies key research gaps and future directions, such as AI-driven multi-user collaboration, cognitive load management, and cross-domain interoperability. By addressing these challenges and advancing the integration of AI with VR, Generative VR has the potential to reshape human-computer interaction, unlocking new possibilities for creativity, accessibility, and intelligent virtual ecosystems.},
  keywords={Generative AI;Artificial intelligence;Virtual reality;Three-dimensional displays;Real-time systems;Scalability;Ethics;Bibliometrics;Technological innovation;Surveys;Generative AI;virtual reality;generative VR},
  doi={10.1109/ACCESS.2025.3574779},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10581306,
  author={Aamana and Ain, Qurat Ul and Nisa, Sardar Un},
  booktitle={2024 International Conference on Engineering & Computing Technologies (ICECT)}, 
  title={Beyond Agile: NLP-Driven Quality Attributes Retrieval Using ChatGPT in Software Development Strategies}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study explores Agile Software Development (ASD) methodologies' effectiveness in achieving quality software products. It investigates the underexplored application of ChatGPT as a Quality Attribute Extractor in ASD. Utilizing hard prompt techniques, ChatGPT extracts quality attributes from user stories without fine-tuning, enhancing understanding through few-shot and zero-shot Prompt Engineering. This innovative approach bridges NLP advancements with agile methodologies, facilitating efficient quality assessment in software development processes.},
  keywords={Natural languages;Decision making;Agile software development;Software quality;Chatbots;Software systems;Quality assessment;Quality Attributes;User Stories;Natural Language Processing (NLP);ChatGPT;Software Development Strategies;Prompt-based Techniques;Agile Software Development},
  doi={10.1109/ICECT61618.2024.10581306},
  ISSN={},
  month={May},}@ARTICLE{11027082,
  author={Zhang, Ye and Gao, Qing and Hu, Rong and Ding, Qingtang and Li, Boyang and Guo, Yulan},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Differentiable Prior-Driven Data Augmentation for Sensor-Based Human Activity Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Sensor-based human activity recognition (HAR) usually suffers from the problem of insufficient annotated data, due to the difficulty in labeling the intuitive signals of wearable sensors. To this end, recent advances have adopted handcrafted operations or generative models for data augmentation. The handcrafted operations are driven by some physical priors of human activities, e.g., action distortion and strength fluctuations. However, these approaches may face challenges in maintaining semantic data properties. Although the generative models have better data adaptability, it is difficult for them to incorporate important action priors into data generation. This article proposes a differentiable prior-driven data augmentation framework for HAR. First, we embed the handcrafted augmentation operations into a differentiable module, which adaptively selects and optimizes the operations to be combined together. Then, we construct a generative module to add controllable perturbations to the data derived by the handcrafted operations and further improve the diversity of data augmentation. By integrating the handcrafted operation module and the generative module into one learnable framework, the generalization performance of the recognition models is enhanced effectively. Extensive experimental results with three different classifiers on five public datasets demonstrate the effectiveness of the proposed framework. Project page: https://github.com/crocodilegogogo/DriveData-Under-Review.},
  keywords={Human activity recognition;Data augmentation;Data models;Adaptation models;Data collection;Noise;Training;Generative adversarial networks;Semantics;Solid modeling;Differentiable framework;generative models;handcrafted operations;prior-driven data augmentation;sensor-based human activity recognition (HAR)},
  doi={10.1109/TCSS.2025.3565414},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{11013092,
  author={Abdel-Rahem, Rami A. and Hadi, Wael and Al-Remawi, Mayyas and Aburub, Faisal and Jamal, Naser},
  booktitle={2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA)}, 
  title={A Survey on Some Artificial Intelligence Learning Tools at the University of Petra}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  abstract={This research explores the perspectives of 105 instructors from the University of Petra (UOP), specifically from the Faculties of Arts and Science (FAS) and Information Technology (FIT), regarding personalized learning (PL) and generative artificial intelligence (GAI) tools. The study examines instructors' views on the theoretical foundations of these technologies, their perceived need for training in the use of such tools, and their opinions on the benefits of PL in education. The primary objective is to gain insights into faculty members' attitudes toward integrating AI tools into the educational process at UOP. The findings from this survey are expected to inform strategies for enhancing AI adoption in education at UOP and other institutions. This investigation will aid the university in preparing for the emerging era of AI-driven education.},
  keywords={Training;Surveys;Technological innovation;Generative AI;Learning (artificial intelligence);Artificial intelligence;Information technology;Stress;Computational intelligence;Best practices;Artificial Intelligence;Personalized Learning;Generative AI;University of Petra;Instructors Training},
  doi={10.1109/ICCIAA65327.2025.11013092},
  ISSN={},
  month={April},}@INPROCEEDINGS{10435553,
  author={Wang, Hongchang and Ma, Qingxin},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={Domain Knowledge Enhanced BERT for Chinese Named Entity Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={406-409},
  abstract={Digitalization of educational resources and revolutionizing knowledge frameworks are essential in achieving smart education. Knowledge graphs play a pivotal role in addressing knowledge representation, correlation, and sharing within digital education. Named Entity Recognition (NER) is a fundamental task in constructing knowledge graphs. This study introduces a Domain Knowledge-Enhanced BERT Chinese NER model, DK-BERT-CRF (Domain Knowledge BERT CRF), to address the deficiency of lexical information features within the Chinese NER task using the BERT pre-trained model. To construct an automated labeling dataset, we perform an automated labeling dataset construction based on ChatGPT, focusing on the example of computer science's data structures. We conduct experiments and evaluations using this dataset and the general CLUENER2020 dataset. Comparative experiments with BERT+CRF and BiLSTM+CRF are also conducted. The experimental results demonstrate that the DK-BERT-CRF model, enriched with domain knowledge, exhibits an improved F1 score compared to the other two models. Particularly, the DK-BERT-CRF model showcases enhanced F1 scores on the computer science data structure dataset after the incorporation of domain knowledge.},
  keywords={Computer science;Annotations;Computational modeling;Knowledge graphs;Data structures;Labeling;Task analysis;Smart Education;Knowledge Graph;Named Entity Recognition;BERT;ChatGPT},
  doi={10.1109/EIECS59936.2023.10435553},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10837679,
  author={Ranasinghe, Harshani and Gide, Ergun and ElKhodr, Mahmoud},
  booktitle={2024 21st International Conference on Information Technology Based Higher Education and Training (ITHET)}, 
  title={The Significance of GenAI Empowered ERP Systems Course Teaching in Quality Education}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper aims to analyse the significance of Generative Artificial Intelligence (GenAI) Empowered Enterprise Resource Planning (ERP) systems as a course in higher education. With the advancement of GenAI technology, ERP systems are capable of automating and streamlining business operations across various industries. The usage of ERP systems has become prevalent in small to medium-sized organizations worldwide, akin to the utilization of office packages for day-to-day operations. Therefore, Fundamental knowledge and understanding of GenAI Empowered ERP system concepts is an advantageous skill for undergraduate and graduate students as potential job seekers in various industries.},
  keywords={Training;Industries;Generative AI;Decision making;Customer satisfaction;Curriculum development;Organizations;Enterprise resource planning;Information technology;ERP systems;GenAI;Higher Education;Systematic review;Job market;Quality},
  doi={10.1109/ITHET61869.2024.10837679},
  ISSN={2473-2060},
  month={Nov},}@INPROCEEDINGS{10928044,
  author={Hesham, Alaa and Hamdy, Abeer},
  booktitle={2024 International Conference on Computer and Applications (ICCA)}, 
  title={Fine-Tuning GPT-4o-Mini for Programming Questions Generation}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Creating programming questions that are both meaningful and educationally relevant is a critical task in computer science education. This paper introduces a fine-tuned GPT4o-mini model (C2Q). It is designed to generate meaningful questions by leveraging semantic feature extraction and well- crafted prompts. The approach addresses the limitations of traditional generative models, offering a deeper understanding of programming code and producing questions that are precise, diverse, and relevant to a given code snippets. The proposed framework incorporates essential code elements, such as control structures and method attributes, to generate questions that align with programming concepts. Evaluation metrics used were BLEU, ROUGE-1, and ROUGE-L to evaluate the model's performance. The findings reveal that the model achieves better structural coherence and conceptual relevance while focusing on contextual understanding over exact term matching. This work highlights the potential of the proposed approach to advance teaching and assessment methods in computer science.},
  keywords={Measurement;Codes;Computational modeling;Semantics;Natural language generation;Focusing;Feature extraction;Question generation;Prompt engineering;Programming profession;Generative models;Natural Language Processing;Natural Language Generation;Question generation;Prompt Engineering},
  doi={10.1109/ICCA62237.2024.10928044},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10397753,
  author={Tyagi, Deepanshu and Tanwar, Sarvesh and Mittal, Neetu and Badotra, Sumit},
  booktitle={2023 6th International Conference on Contemporary Computing and Informatics (IC3I)}, 
  title={Analyse and Evaluate Quixbugs with Open AI Codex and Powering Next Generation Application}, 
  year={2023},
  volume={6},
  number={},
  pages={165-170},
  abstract={The paper investigates the ordinary language age limits of massive language models, with applications to the development of two types of learning tools commonly found in programming courses. We construct programming workouts and code explanations, reviewing these abstractly and statistically, using the Open AI Codex as the massive language model. Our findings indicate that the majority of the content so given is both unique and sensible, and that it is occasionally ready to use without any guarantees. While rehearsing, we discovered that it is astonishingly simple to affect both the programming ideas and the practical subjects they include simply by offering expressions of commitment to the model. Findings indicate massively generative computer intelligence models have fundamental value.},
  keywords={Training;Codes;Smoothing methods;Computational modeling;Programming;Artificial intelligence;Robots;GPT-3;Open AI;Codex;Java;Security;Intelligence;Application},
  doi={10.1109/IC3I59117.2023.10397753},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10949557,
  author={Mo, Jiayun and Ann, Ong Chin},
  booktitle={2024 4th International Conference on Robotics, Automation and Artificial Intelligence (RAAI)}, 
  title={Towards Responsible and Ethical AI Chatbot in Education: A Guideline for Developers}, 
  year={2024},
  volume={},
  number={},
  pages={52-58},
  abstract={With the expansion of generative Artificial Intelligence (AI) and the penetration of AI chatbots into every aspect of people's daily lives, discussions and issues related to AI ethics and responsibility began to arise simultaneously. A large portion of AI users remain ignorant of such ethical discussions, while a significant percentage of developers lack precautionary measures to prevent irresponsible AI behaviors. An increasing number of companies and organizations are taking action to address the problems. Despite the efforts, prominent issues still prevail. Most existing solutions are too general and theoretical; few are narrowed down to examine the specific application scenario of AI chatbots in education. In response, this study aims to address the arising concerns and the lack of a satisfying solution. After conducting an extensive literature review and performing a detailed analysis of survey data, this study develops a comprehensive guideline about AI ethics and responsible AI, which specifically targets undergraduate developers and guides them during their development of AI chatbots used in education. This guideline successfully bridges the knowledge gap, raises awareness about AI ethics, and acts as the first guideline for undergraduate students, influencing future development practices.},
  keywords={Surveys;Ethics;Systematics;Generative AI;Educational robots;Education;Chatbots;Artificial intelligence;Guidelines;Systematic literature review;Chatbot Development;Ethical AI Framework;Responsible AI;Digital Trust;Secure Development},
  doi={10.1109/RAAI64504.2024.10949557},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10604584,
  author={Rosales, Shomira and Reátegui, Ruth and Toledo, Charlie Cárdenas},
  booktitle={2023 Fourth International Conference on Information Systems and Software Technologies (ICI2ST)}, 
  title={A Topic Modeling Approach to Analyze Teaching Innovation Projects}, 
  year={2023},
  volume={},
  number={},
  pages={46-53},
  abstract={Topic modeling is a data mining strategy that permit to automatically extract the topics discussed in a given corpus. The objective of this study is to discover the topics that are common in a set of educational innovation projects proposed by university teachers. The LDA algorithm, which is a generative probabilistic model, was used. To identify the correct number of topics the coherence and perplexity metrics were applied. Ten topics were obtained, which, among other aspects, reflect the careers and subjects that work the most in educational innovation projects, as well as the methodologies, strategies and resources that teachers use in their projects.},
  keywords={Measurement;Technological innovation;Vocabulary;Engineering profession;Education;Ontologies;Probabilistic logic;Text mining;topic modeling;LDA;higher-educational institutions},
  doi={10.1109/ICI2ST62251.2023.00014},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10999036,
  author={Sharma, Madhav and Bansal, Payal and Dutta, Ritam and Saini, Hukum Chand and Chaudhary, Shalini and Das, Debmitra},
  booktitle={2nd International Conference on Pervasive Computing Advances and Applications (PerCAA 2024)}, 
  title={Advancements in deep learning: from theory to application using natural language processing}, 
  year={2024},
  volume={2024},
  number={},
  pages={123-128},
  abstract={Deep analyzing has witnessed excellent enhancements in modern-day-day years, mainly in its software program to natural language processing (NLP). This paper offers an entire assessment of the evolution of deep learning strategies, tracing their journey from theoretical foundations to sensible packages in NLP. The theoretical underpinnings of deep getting to know, which incorporates neural network architectures together with convolution neural networks and recurrent neural networks are mentioned, highlighting their capability to capture complicated styles in data. We delve into the stressful conditions faced via manner of conventional NLP techniques and the way deep reading has addressed the ones demanding conditions with the useful resource of allowing greater nuanced records of language via techniques which encompass phrase embeddings and interest mechanisms. Moreover, the paper explores contemporary upgrades in deep studying models tailored specially for NLP obligations, together with transformers and pre-informed language fashions like BERT, GPT, and XLNet. These models have revolutionized the arena through achieving extraordinarily-modern-day regular overall performance throughout severa NLP benchmarks, starting from sentiment assessment and named entity recognition to gadget translation and question answering.},
  keywords={},
  doi={10.1049/icp.2025.0781},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10825682,
  author={Nweke, Francis and Azmee, Abm Adnan and Al Hafiz Khan, Md Abdullah and Pei, Yong and Thomas, Dominic and Nandan, Monica},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Explainable Multi-Label Classification Framework for Behavioral Health Based on Domain Concepts}, 
  year={2024},
  volume={},
  number={},
  pages={6528-6537},
  abstract={Behavioral health, which covers mental health, lifestyle choices, addictions, and crises, poses serious issues in the community. Thus, appropriately analyzing and classifying behavioral health data is crucial for making informed health-care decisions. Traditional deep learning and natural language processing approaches struggle to effectively identify behavioral health issues because the data is unstructured, complex, and lacks sufficient context. Furthermore, subject matter experts must be consulted to ensure effective identification. In this work, we proposed a deep learning-based framework consisting of several modules: A) domain concept encoder converts the keywords and their evidence types to vectors, which were predefined by a subject matter expert; B) the semantic representation encoder (SRE) is trained on the vectors to learn the relationship between them; C) transformed-based feature learner is an advanced learner that extracts feature embeddings from documents and generates attention weights since it has more context given the incorporated relationship weights; D) The behavioral health multilabel classifier utilizes feature embeddings to classify a document into one or more behavioral health classes; and E) The LLM-enabled explainer provides explanations based on attention weights and classifications. Our proposed framework outperformed state-of-the-art models in multilabel behavioral health case classification while also providing explanations for each classification. Which is crucial in behavioral health analysis.},
  keywords={Deep learning;Subject matter experts;Semantics;Multi label classification;Mental health;Medical services;Feature extraction;Vectors;Natural language processing;Data models;explainable model;deep learning;behavioral health},
  doi={10.1109/BigData62323.2024.10825682},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10775064,
  author={Joshi, Atharva and Pede, Shailaja and Kolekar, Prathmesh and Metkar, Aditya},
  booktitle={2024 8th International Conference on Computing, Communication, Control and Automation (ICCUBEA)}, 
  title={Resume Parsing and Skill Extraction using Custom Pattern Matching algorithm and Gemini API}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the realm of contemporary recruitment, efficient resume parsing is essential for talent acquisition. This paper investigates resume parsing using advanced OCR technology and NLP methods. We begin with preprocessing, enhancing scanned resumes for legibility. Leveraging the Tesseract OCR engine, we convert images to machine-readable text. Through NLP techniques with spaCy, we extract key information like personal details, education, experience, and skills.Our approach integrates the Gemini Pro Vision API for semantic analysis and question-answering. This enriches our framework, enabling deeper insights and implicit attribute inference. Empirical validation across diverse datasets demonstrates the robustness of our methodology. This work sheds light on performance metrics and challenges in automated resume parsing, paving the way for future enhancements.},
  keywords={Visualization;Technological innovation;Machine learning algorithms;Resumes;Optical character recognition;Semantics;Robustness;Data mining;Pattern matching;Recruitment;Optical Character Recognition (OCR);Text Detection;Gemini Pro API;Natural Language Processing (NLP);Semantic analysis;spaCy;Tesseract OCR engine;Talent acquisition},
  doi={10.1109/ICCUBEA61740.2024.10775064},
  ISSN={2771-1358},
  month={Aug},}@BOOK{10559429,
  author={Jha, Ashish Ranjan},
  booktitle={Mastering PyTorch: Create and deploy deep learning models from CNNs to multimodal models, LLMs, and beyond},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Master advanced techniques and algorithms for machine learning with PyTorch using real-world examples Updated for PyTorch 2.x, including integration with Hugging Face, mobile deployment, diffusion models, and graph neural networks Purchase of the print or Kindle book includes a free eBook in PDF formatKey FeaturesUnderstand how to use PyTorch to build advanced neural network modelsGet the best from PyTorch by working with Hugging Face, fastai, PyTorch Lightning, PyTorch Geometric, Flask, and DockerUnlock faster training with multiple GPUs and optimize model deployment using efficient inference frameworksBook DescriptionPyTorch is making it easier than ever before for anyone to build deep learning applications. This PyTorch deep learning book will help you uncover expert techniques to get the most out of your data and build complex neural network models. You’ll build convolutional neural networks for image classification and recurrent neural networks and transformers for sentiment analysis. As you advance, you'll apply deep learning across different domains, such as music, text, and image generation, using generative models, including diffusion models. You'll not only build and train your own deep reinforcement learning models in PyTorch but also learn to optimize model training using multiple CPUs, GPUs, and mixed-precision training. You’ll deploy PyTorch models to production, including mobile devices. Finally, you’ll discover the PyTorch ecosystem and its rich set of libraries. These libraries will add another set of tools to your deep learning toolbelt, teaching you how to use fastai to prototype models and PyTorch Lightning to train models. You’ll discover libraries for AutoML and explainable AI (XAI), create recommendation systems, and build language and vision transformers with Hugging Face. By the end of this book, you'll be able to perform complex deep learning tasks using PyTorch to build smart artificial intelligence models.What you will learnImplement text, vision, and music generation models using PyTorchBuild a deep Q-network (DQN) model in PyTorchDeploy PyTorch models on mobile devices (Android and iOS)Become well versed in rapid prototyping using PyTorch with fastaiPerform neural architecture search effectively using AutoMLEasily interpret machine learning models using CaptumDesign ResNets, LSTMs, and graph neural networks (GNNs)Create language and vision transformer models using Hugging FaceWho this book is forThis deep learning with PyTorch book is for data scientists, machine learning engineers, machine learning researchers, and deep learning practitioners looking to implement advanced deep learning models using PyTorch. This book is ideal for those looking to switch from TensorFlow to PyTorch. Working knowledge of deep learning with Python is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781801079969},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10559429},}@INPROCEEDINGS{10912174,
  author={Pandey, Tanya and Yadav, Armaan and Sharma, Janvi and Singhal, Shefali},
  booktitle={2024 2nd International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={Design based Retrieval Augmented Generation Oriented Education Chatbot: Edubot}, 
  year={2024},
  volume={1},
  number={},
  pages={1278-1283},
  abstract={Chatbot, a system which focuses on utilizing advanced natural language processing (NLP) techniques. This research aims to provide a comprehensive understanding of Chatbot, including its background, evolution and future application, with the focus mainly on its impact on education. The landscape of scientific research has been transformed by artificial intelligence (AI) and machine learning. This research explores OpenAI’s chatbot, which leverages advanced techniques in Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to understand and generate text that closely resembles human-written content. As per state-of-art, an interface has been developed along with dataset creation. A small level BOT that would use a self-made database on Pinecone which has been integrated into it. The interface will take the queries from the user and provide a suitable and accurate answer by using the RAG & LLM algorithm.},
  keywords={Technological innovation;Retrieval augmented generation;Education;Supervised learning;Reinforcement learning;Chatbots;User experience;Information and communication technology;Reliability;Testing;Retrieval Augmented Generation (RAG);Hugging face;Pinecone DB;Mistral X86;Natural Language Processing;LLM},
  doi={10.1109/ICAICCIT64383.2024.10912174},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10663002,
  author={Braun, Peter},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={A Method and Software to Create SCORM Units for Computer Science Courses}, 
  year={2024},
  volume={},
  number={},
  pages={1-2},
  abstract={Producing learning videos for flipped classrooms is a time-consuming and manual task. This paper presents a method and software to create SCORM units for computer science courses. The method consists of a common structure for learning videos, a Python script to create SCORM units, and ChatGPT for quiz creation. The software is based on the open-source software FFmpeg for video production. The results after 40 learning units show that producing a learning video can be automated to a great extent.},
  keywords={Computer science;Electronic learning;Education;Production;Manuals;Recording;Online services;flipped classroom;learning units;video production},
  doi={10.1109/CSEET62301.2024.10663002},
  ISSN={2377-570X},
  month={July},}@BOOK{10769232,
  author={Gonzalez, Leondra R. and Baltes, Angela and Stubberfield, Aaren},
  booktitle={Cracking the Data Science Interview: Unlock insider tips from industry experts to master the data science field},
  year={2024},
  volume={},
  number={},
  pages={},
  abstract={Rise above the competition and excel in your next interview with this one-stop guide to Python, SQL, version control, statistics, machine learning, and much moreKey FeaturesAcquire highly sought-after skills of the trade, including Python, SQL, statistics, and machine learningGain the confidence to explain complex statistical, machine learning, and deep learning theoryExtend your expertise beyond model development with version control, shell scripting, and model deployment fundamentalsPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionThe data science job market is saturated with professionals of all backgrounds, including academics, researchers, bootcampers, and Massive Open Online Course (MOOC) graduates. This poses a challenge for companies seeking the best person to fill their roles. At the heart of this selection process is the data science interview, a crucial juncture that determines the best fit for both the candidate and the company. Cracking the Data Science Interview provides expert guidance on approaching the interview process with full preparation and confidence. Starting with an introduction to the modern data science landscape, you’ll find tips on job hunting, resume writing, and creating a top-notch portfolio. You’ll then advance to topics such as Python, SQL databases, Git, and productivity with shell scripting and Bash. Building on this foundation, you'll delve into the fundamentals of statistics, laying the groundwork for pre-modeling concepts, machine learning, deep learning, and generative AI. The book concludes by offering insights into how best to prepare for the intensive data science interview. By the end of this interview guide, you’ll have gained the confidence, business acumen, and technical skills required to distinguish yourself within this competitive landscape and land your next data science job.What you will learnExplore data science trends, job demands, and potential career pathsSecure interviews with industry-standard resume and portfolio tipsPractice data manipulation with Python and SQLLearn about supervised and unsupervised machine learning modelsMaster deep learning components such as backpropagation and activation functionsEnhance your productivity by implementing code versioning through GitStreamline workflows using shell scripting for increased efficiencyWho this book is forWhether you're a seasoned professional who needs to brush up on technical skills or a beginner looking to enter the dynamic data science industry, this book is for you. To get the most out of this book, basic knowledge of Python, SQL, and statistics is necessary. However, anyone familiar with other analytical languages, such as R, will also find value in this resource as it helps you revisit critical data science concepts like SQL, Git, statistics, and deep learning, guiding you to crack through data science interviews.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781805120193},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10769232},}@INPROCEEDINGS{10356369,
  author={Jones, Alyse M. and Johnson, Amos and Headley, William C.},
  booktitle={MILCOM 2023 - 2023 IEEE Military Communications Conference (MILCOM)}, 
  title={Demoing the RFRL Gym: A Reinforcement Learning Testbed for Wireless Communications}, 
  year={2023},
  volume={},
  number={},
  pages={235-236},
  abstract={Radio Frequency Reinforcement Learning (RFRL) is anticipated to be a widely leveraged technology in the next generation of wireless communication systems, particularly 6G systems and next-gen military communications. To support education, research, and innovation in RFRL technologies, an open source simulation and analysis tool specifically for simulating wireless communications applications (both commercial and military) is under development that leverages the well-known OpenAI Gymnasium framework. In this demonstration, the current feature-complete functionalities of the RFRL Gym are showcased, particularly the ability to train and evaluate open-source Gymnasium-compatible RL algorithms against a series of representative user-defined wireless scenarios. In particular, scenarios representing dynamic spectrum access scenarios, as well as jamming/anti-jamming scenarios, will be demoed. Additionally, two simulation modes of the RFRL Gym will be demonstrated, namely a high-level abstracted gamified mode for researchers with minimal background in wireless communications and a low-level expert mode simulating real wireless signals, channels, and sensing for researchers with expertise in wireless communications concepts. The goal of this demonstration is two-fold. First, to showcase and solicit feedback on how RFRL Gym can be helpful to experts in the field to test and evaluate candidate RL algorithms for next-generation wireless systems. Second, to showcase and solicit feedback on how RFRL Gym can be helpful to develop a better understanding of RF and RL concepts for researchers with minimal expertise in the area.},
  keywords={Wireless communication;Military communication;Radio frequency;Wireless sensor networks;Technological innovation;Heuristic algorithms;Reinforcement learning},
  doi={10.1109/MILCOM58377.2023.10356369},
  ISSN={2155-7586},
  month={Oct},}@INBOOK{10952453,
  author={Khan, Rehan and Khan, Shadab Pasha and Ali, Syed Adnan},
  booktitle={Conversational Artificial Intelligence}, 
  title={Conversational AI}, 
  year={2024},
  volume={},
  number={},
  pages={249-268},
  abstract={Summary <p>Artificial intelligence (AI) has been used to develop conversational AI chatbots, which can understand and respond to natural language input. These chatbots utilize techniques such as natural language processing (NLP), natural language understanding (NLU), and natural language generation (NLG) to understand and respond to user input. The human&#x2013;computer interaction (HCI) aspect of chatbots has also been an essential area of research, as the goal is to create chatbots that can have natural and seamless conversations with users. One such example of a conversational AI chatbot is ChatGPT, which has been trained on a large dataset and can generate human&#x2010;like responses. In this chapter, we have discussed the origin and subsequent developments in the field of conversational AI. Framework breakthroughs like Rasa and GPT&#x2010;3 allow the integration of AI, NLP, NLU, NLG, and HCI in the development of chatbots, providing the potential for more sophisticated and human&#x2010;like conversations. These conversational AI chatbots are being used in a wide range of applications, from customer service and e&#x2010;commerce to healthcare and education. As technology continues to advance, we can expect to see even more natural and intuitive conversational AI chatbots in the future.</p>},
  keywords={Chatbots;Oral communication;Virtual assistants;Artificial intelligence;Natural language generation;Faces;Linguistics;History;Psychiatry;Meteorology},
  doi={10.1002/9781394200801.ch16},
  ISSN={},
  publisher={Wiley},
  isbn={9781394200795},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10952453},}@BOOK{10948547,
  author={Ramaswami, Yoni and Williamson, Dael and Govaere, Jan},
  booktitle={Time Series Analysis with Spark: A practical guide to processing, modeling, and forecasting time series with Apache Spark},
  year={2025},
  volume={},
  number={},
  pages={},
  abstract={Master the fundamentals of time series analysis with Apache Spark and Databricks and uncover actionable insights at scaleKey FeaturesQuickly get started with your first models and explore the potential of Generative AILearn how to use Apache Spark and Databricks for scalable time series solutionsEstablish best practices to ensure success from development to production and beyondPurchase of the print or Kindle book includes a free PDF eBookBook DescriptionWritten by Databricks Senior Solutions Architect Yoni Ramaswami, whose expertise in Data and AI has shaped innovative digital transformations across industries, this comprehensive guide bridges foundational concepts of time series analysis with the Spark framework and Databricks, preparing you to tackle real-world challenges with confidence. From preparing and processing large-scale time series datasets to building reliable models, this book offers practical techniques that scale effortlessly for big data environments. You’ll explore advanced topics such as scaling your analyses, deploying time series models into production, Generative AI, and leveraging Spark's latest features for cutting-edge applications across industries. Packed with hands-on examples and industry-relevant use cases, this guide is perfect for data engineers, ML engineers, data scientists, and analysts looking to enhance their expertise in handling large-scale time series data. By the end of this book, you’ll have mastered the skills to design and deploy robust, scalable time series models tailored to your unique project needs—qualifying you to excel in the rapidly evolving world of big data analytics.What you will learnUnderstand the core concepts and architectures of Apache SparkClean and organize time series dataChoose the most suitable modeling approach for your use caseGain expertise in building and training a variety of time series modelsExplore ways to leverage Apache Spark and Databricks to scale your modelsDeploy time series models in productionIntegrate your time series solutions with big data tools for enhanced analyticsLeverage GenAI to enhance predictions and uncover patternsWho this book is forIf you are a data engineer, ML engineer, data scientist, or analyst looking to enhance your skills in time series analysis with Apache Spark and Databricks, this book is for you. Whether you’re new to time series or an experienced practitioner, this guide provides valuable insights and techniques to improve your data processing capabilities. A basic understanding of Apache Spark is helpful, but no prior experience with time series analysis is required.},
  keywords={},
  doi={},
  ISSN={},
  publisher={Packt Publishing},
  isbn={9781803247175},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10948547},}@INPROCEEDINGS{10303509,
  author={Monteiro, Walbert Cunha and Dos Santos, Diego Hortêncio and De Sousa, Thiago Augusto Soares and Queiroz, Vinicius Favacho and De Araújo, Tiago Davi Oliveira and Meiguins, Bianchi Serique},
  booktitle={2023 27th International Conference Information Visualisation (IV)}, 
  title={Workload Evaluation to Create Data Visualization Using ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={136-141},
  abstract={The value of good data visualization has already been shown in several scenarios. Still, it is not always easy to obtain it, as it depends on factors such as the dataset, the amount of data, task types, the user profile, the type of interaction, etc. To mitigate the challenges addressed, automated or semi-automated systems have been proposed, emphasizing rule-based/heuristic approaches and machine-learning models. However, many of these applications require specialized knowledge and present results (data visualizations) that are not flexible for customization. Papers have highlighted the ease of tools like ChatGPT in creating various tasks, including creating data charts. This facility, in addition to the intelligent computational model involved, is also due to the expressiveness used in the requests to execute the tasks by the users since these tools use Natural Language Interfaces. Despite adopting these tools overgrowing in different scenarios of society, studies on the best way to use them, integrate them into existing processes, or evaluative studies on their effectiveness or efficiency are still incipient. Thus, this paper will evaluate the workload for creating data visualization using ChatGPT 3.5. For assessment, the NASA Task Load Index (Nasa TLX) methodology was applied, and users with experience creating data visualization created two proposed scenarios. The preliminary results showed high temporal and mental demand, mainly due to the vocabulary used and the completeness of the user instructions. The average time to create and perform InfoVis tasks in two proposed evaluation scenarios was 33 and 44 minutes, and 14 queries were applied on average for both scenarios. The direct consequence was that the users have redone the requests and improved the instructions at each new iteration, and all users completed the proposed tasks.},
  keywords={Vocabulary;Computational modeling;NASA;Natural languages;Data visualization;Machine learning;Chatbots;Information Visualization;ChatGPT;Interface Natural Language;Nasa-TLX},
  doi={10.1109/IV60283.2023.00032},
  ISSN={2375-0138},
  month={July},}@ARTICLE{10646341,
  author={Mejía, Jezreel and Terrón-Macias, Victor and Muñoz, Mirna and Terrón-Hernández, Miguel and Canseco-Pérez, Miguel},
  journal={IEEE Access}, 
  title={VSEST 29110 Tool: Using ChatGPT to Evaluate the Implementation of the ISO/IEC 29110 Work Products}, 
  year={2024},
  volume={12},
  number={},
  pages={120935-120948},
  abstract={The global software industry is predominantly composed of micro, small, and medium-sized enterprises (MSMEs), highlighting the need for software quality management to ensure the proper functioning and quality of the software. This research focuses on the evaluation of the implementation of the ISO/IEC 29110 standard work products, which is a standard tailored by the ISO/IEC specifically for MSMEs, which improves the software development process by implementing two processes in its basic profile: Project Management (PM) and Software Implementation (SI). Despite this standard being tailored specifically for this type of enterprise, implementing ISO/IEC 29110 faces several challenges, such as a lack of knowledge and difficulties in adequately implementing the work products regarding the compliance of standard criteria, among others. To address these challenges, we introduce VSEST 29110, a web tool designed to evaluate the ISO/IEC 29110 standard implementation work products by leveraging Artificial Intelligence (AI) technologies, specifically the ChatGPT model, provide detailed feedback on compliance with standard criteria, offer suggestions for improvement based on ChatGPT analysis and streamline the implementation process for MSMEs. To achieve this, our research incorporates a systematic literature review and validation through a case study by document analysis, demonstrating VSEST 29110’s effectiveness in enhancing compliance and providing comprehensive feedback compared to auditor recommendations, which impacts 69.33% on average.},
  keywords={ISO Standards;IEC Standards;Artificial intelligence;Software development management;Chatbots;Text analysis;ISO/IEC 29110 standard;LLMs;ChatGPT;implementation process improvement},
  doi={10.1109/ACCESS.2024.3449252},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10893453,
  author={FalvoJr, Venilton and Da Silva Marcolino, Anderson and Bruno, Diego Renan and Martins Falvo, Catherine Helen and Osório, Fernando Santos and Barbosa, Ellen Francine},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Enhancing Learning Objects Accessibility Through Speech-To-Text Based Architecture: A Comprehensive Triangulation Study}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={This full research paper expands on the results and discussions from a case study conducted within a Brazilian EdTech company. It focuses on the accuracy of AI-based speech recognition models for automatic transcription of video lectures, aiming to improve the accessibility of Learning Objects (LOs), especially the audible ones. Previous work assessed the quality of automatic transcriptions in English, Portuguese, and Spanish from Speech- To- Text (STT) services provided by major market players (Amazon, Google, IBM, Microsoft, and OpenAI), using a quantitative approach based on lexical similarity algorithms. Statistically significant differences were identified between the providers and languages evaluated, indicating that STT service can affect the quality of audible OAs enriched with transcriptions or subtitles. This study introduces a new dimension of analysis by incorporating the perceptions of technology students on the accuracy of automatic transcriptions, gathered through an anonymous survey with 56 participants. The survey captured mainly quantitative data using a Likert scale on the accuracy of transcriptions. To provide a comprehensive analysis, this study employs a data triangulation approach, integrating (1) quantitative data from lexical similarity methods, (2) quantitative data from the survey, and (3) findings from a complementary review of the literature. The qualitative analysis, applying Grounded Theory principles to both the survey data and the bibliographic review, enables the exploration of emerging themes and enriches the understanding of factors influencing the quality of automatic transcriptions. This effort underscores the importance of a user-centered perspective and demonstrates the complexity of evaluating STT technologies, pointing to the necessity for future research that combines quantitative and qualitative methods. Additionally, it highlights the relevance of STT in various educational contexts and the need to align such technologies with principles of accessibility and inclusion. By aiming to create more accessible LOs, this work emphasizes the need to develop solutions that ensure inclusion and equity in educational access, reflecting a concerted effort to meet the diverse needs of learners and promote a more welcoming and inclusive learning environment.},
  keywords={Surveys;Measurement;Accuracy;Data analysis;Reviews;Companies;Internet;Complexity theory;Speech to text;Speech-To-Text (STT);Software Architecture;Learning Objects (LOs);Accessibility;Data Triangulation},
  doi={10.1109/FIE61694.2024.10893453},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{11005596,
  author={Routray, Sudhir K.},
  journal={IEEE Computer Graphics and Applications}, 
  title={Ethical Considerations and Implications of Generative AI in Computer Graphics}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Generative AI has immense potential to create diverse computer graphics for various applications, but it also raises significant ethical issues. This paper examines the ethical landscape of using generative AI in computer graphics, highlighting key concerns such as the authenticity of generated content, intellectual property rights, and cultural appropriation. Additional ethical challenges include algorithmic bias in graphics generation, representation, privacy, inclusivity, and the impact on human-computer interaction and artistic integrity. The displacement of creative professionals, erosion of trust in visual media, and psychological effects of AI-generated content further complicate the ethical debate. Addressing these issues requires a comprehensive approach that integrates technological innovation with regulatory oversight, ethical education, and collaboration among stakeholders. By carefully considering these ethical dimensions, we can fully leverage generative AI's potential in computer graphics while mitigating its risks.},
  keywords={Generative AI;Ethics;Artificial intelligence;Technological innovation;Creativity;Intellectual property;Training;Data models;Cultural differences;Computational modeling},
  doi={10.1109/MCG.2025.3570722},
  ISSN={1558-1756},
  month={},}@INPROCEEDINGS{10158670,
  author={Krutilla, Zsolt and Kovari, Attila},
  booktitle={2023 IEEE 17th International Symposium on Applied Computational Intelligence and Informatics (SACI)}, 
  title={How we can use text classification in the Back-Office environment of a bank as ‘business as usual’ solution}, 
  year={2023},
  volume={},
  number={},
  pages={000209-000214},
  abstract={Natural Language Processing nowadays provides scientists with many research areas and opportunities, but as with most applied sciences, our goal in Natural Language Processing is to refine the underlying science and technology until it can be used reliably for business purposes. Transformer models, such as GPT or BERT, are currently showing outstanding results in the field of natural-language processing, but they require huge computational power and data to teach, but these conditions can only be met by larger research centers and large companies, and their inaccuracy makes them unsuitable for use as a ‘business as usual’ (BAU) solution. In this paper, we present a solution that is able to overcome these problems by focusing on accuracy and usability, and that can also bring a new perspective to the process of teaching deep learning models.},
  keywords={Uncertainty;Text categorization;Manuals;Logic gates;Transformers;Natural language processing;Reliability;natural language processing;transformers;generative pre-trained transformers;text analytics;document classification},
  doi={10.1109/SACI58269.2023.10158670},
  ISSN={2765-818X},
  month={May},}@INPROCEEDINGS{10868958,
  author={Shi, Yuxuan and Huang, Wen and Sang, Yijing},
  booktitle={2024 4th International Conference on Educational Technology (ICET)}, 
  title={A Narrative Review of Utilizing Generative Artificial Intelligence in Classroom Instructions}, 
  year={2024},
  volume={},
  number={},
  pages={419-422},
  abstract={This review examines the utilization of Generative Artificial Intelligence (GAI) in classroom instructions, emphasizing its transformative potential in education. After reviewing 23 relevant articles, we identified three themes: application advantages, possible risks, and future paths. Specifically, GAI has the potential to facilitate personalized learning, promote communication, and promoting education equity. However, concerns over content validity, ethical issues, and the risk of diminished innovation necessitate careful consideration. Additionally, prior literature suggests improving instructional evaluation methods, enhancing AI literacy, and addressing ethical challenges to maximize GAI's benefits and drive continuous educational innovation.},
  keywords={Technological innovation;Ethics;Reviews;Generative AI;Learning (artificial intelligence);Educational technology;generative artificial intelligence;classroom instruction;literature review},
  doi={10.1109/ICET62460.2024.10868958},
  ISSN={},
  month={Sep.},}@ARTICLE{10664616,
  author={Hong, Yifan and Shi, Chuanqi and Chen, Junyang and Wang, Huan and Wang, Di},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Multitask Asynchronous Metalearning for Few-Shot Anomalous Node Detection in Dynamic Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-12},
  abstract={Few-shot anomalous node detection in dynamic networks has been extensively investigated in the field of research. In this few-shot scenario, the detection of these anomalous nodes is particularly challenging due to the continuously evolving network topology and data distribution over time, which is known as concept drift. Concept drift refers to the phenomenon where the underlying concepts or patterns in the data generation process change over time, leading to varying data distributions across different periods. Due to these changes in data distribution, the patterns learned during training may become invalid under the new data distribution. Existing models primarily aim to enhance the representation of evolving node attributes and relationships to mitigate the impact of concept drift in few-shot scenarios. However, the scarcity of anomalous samples further limits the model’s ability to learn new patterns, thereby reducing its effectiveness in addressing concept drift in few-shot scenarios. To address this challenge, we propose the multitask asynchronous metalearning framework (MAMF), which aims to mitigate bias induced by concept drift in few-shot anomalous node detection. Our framework consists of four main components: a feature extractor, an anomaly simulator, an asynchronous learner, and a type detector. The feature extractor captures the relative variations of each node in an evolving graph stream. The anomaly simulator uses generative adversarial models to learn anomaly distributions and generate samples at different time intervals. The asynchronous learner samples from various time distributions to create metatasks for anomalous node detection, allowing it to adapt to changes between these distributions. To aid in few-shot anomalous node detection, the type detector is used for anomaly type recognition. Our framework achieves AUC improvements of 5.12%, 6.87%, and 1.91% over the best existing methods on Wikipedia, Reddit, and Mooc datasets, respectively, demonstrating its effectiveness and robustness in adapting to concept drift and detecting anomalous nodes.},
  keywords={Concept drift;Adaptation models;Metalearning;Data models;Feature extraction;Anomaly detection;Training data;Anomalous node detection;concept drift;graph neural networks;metalearning;multitask learning},
  doi={10.1109/TCSS.2024.3442238},
  ISSN={2329-924X},
  month={},}@INPROCEEDINGS{10882421,
  author={Joshi, Deepali and Tekade, Shreyash and Zanzane, Sayee and Sakharwade, Dhawal and Tripathi, Ankur and Tiwadi, Shivam},
  booktitle={2024 International Conference on Artificial Intelligence and Quantum Computation-Based Sensor Application (ICAIQSA)}, 
  title={Generative AI-Driven Chatbot for Personalized University Information and Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper outlines the development of a generative AI-driven chatbot for university admissions and general inquiries, using a Retrieval-Augmented Generation (RAG) framework. By embedding university-related documents into a vector database and indexing them with FAISS, the system efficiently retrieves information and generates precise, context-aware responses. The chatbot improves user experience by providing accurate answers to prospective students and other users, showcasing the potential of generative AI in educational settings for managing inquiries effectively},
  keywords={Quantum computing;Accuracy;Generative AI;Databases;Retrieval augmented generation;Chatbots;User experience;Vectors;Indexing;Generative AI;Retrieval-Augmented Generation (RAG);University Chatbot;Natural Language Processing (NLP);Information Retrieval},
  doi={10.1109/ICAIQSA64000.2024.10882421},
  ISSN={},
  month={Dec},}
@ARTICLE{10643089,
  author={Srivastava, Akchay and Memon, Atif},
  journal={IEEE Access}, 
  title={Toward Robust Evaluation: A Comprehensive Taxonomy of Datasets and Metrics for Open Domain Question Answering in the Era of Large Language Models}, 
  year={2024},
  volume={12},
  number={},
  pages={117483-117503},
  abstract={Open Domain Question Answering (ODQA) within natural language processing involves building systems that answer factual questions using large-scale knowledge corpora. Recent advances stem from the confluence of several factors, such as large-scale training datasets, deep learning techniques, and the rise of large language models. High-quality datasets are used to train models on realistic scenarios and enable the evaluation of the system on potentially unseen data. Standardized metrics facilitate comparisons between different ODQA systems, allowing researchers to objectively track advancements in the field. Our study presents a thorough examination of the current landscape of ODQA benchmarking by reviewing 52 datasets and 20 evaluation techniques across textual and multimodal modalities. We introduce a novel taxonomy for ODQA datasets that incorporates both the modality and difficulty of the question types. Additionally, we present a structured organization of ODQA evaluation metrics along with a critical analysis of their inherent trade-offs. Our study aims to empower researchers by providing a framework for the robust evaluation of modern question-answering systems. We conclude by identifying the current challenges and outlining promising avenues for future research and development.},
  keywords={Internet;Task analysis;Online services;Encyclopedias;Taxonomy;Artificial intelligence;Large language models;Machine learning;Natural language processing;Question answering (information retrieval);Artificial intelligence;datasets;large language models;machine learning;metrics;multimodal;natural language processing;open domain question answering;review;taxonomy},
  doi={10.1109/ACCESS.2024.3446854},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10793131,
  author={Giordani, Jeremiah and Xu, Ziyang and Colby, Ella and Ning, August and Godala, Bhargav Reddy and Chaturvedi, Ishita and Zhu, Shaowei and Chon, Yebin and Chan, Greg and Tan, Zujun and Collier, Galen and Halverson, Jonathan D. and Deiana, Enrico Armenio and Liang, Jasper and Sossai, Federico and Su, Yian and Patel, Atmn and Pham, Bangyen and Greiner, Nathan and Campanoni, Simone and August, David I.},
  booktitle={SC24: International Conference for High Performance Computing, Networking, Storage and Analysis}, 
  title={Revisiting Computation for Research: Practices and Trends}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={In the field of computational science, effectively supporting researchers necessitates a deep understanding of how they utilize computational resources. Building upon a decade-old survey that explored the practices and challenges of research computation, this study aims to bridge the understanding gap between providers of computational resources and researchers who rely on them. This study revisits key survey questions and gathers feedback on open-ended topics from over a hundred interviews. Quantitative analyses of present and past results illuminate the landscape of research computation. Qualitative analyses, including careful use of large language models, highlight trends and challenges with concrete evidence. Given the rapid evolution of computational science, this paper offers a toolkit with methodologies and insights to simplify future research and ensure ongoing examination of the landscape. This study, with its findings and toolkit, guides enhancements to computational systems, deepens understanding of user needs, and streamlines reassessment of the computational landscape.},
  keywords={Surveys;Data analysis;Scientific computing;Statistical analysis;Large language models;High performance computing;Buildings;Market research;Solids;Interviews},
  doi={10.1109/SC41406.2024.00076},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10210230,
  author={Chen, Zhenyu},
  booktitle={2023 IEEE/ACIS 23rd International Conference on Computer and Information Science (ICIS)}, 
  title={Education Reform of Software Engineering in the Age of A.I: Keynote Address}, 
  year={2023},
  volume={},
  number={},
  pages={2-2},
  abstract={In the age of artificial intelligence (A.I.), software engineering is facing unprecedented changes. Software developers need to have a deep understanding of, especially large model technologies, since the traditional software development model cannot meet the new needs. Moreover, software engineering also needs to pay more attention to the value of data. The data-driven software development models are growing, and data analysis and machine learning technologies have also been widely used. Software development requires higher efficiency, quality, and flexibility. New methods such as agile development and DevOps have emerged. Software testing also needs to be more intelligent, and test automation has become an essential part in software engineering. This speech focuses on sharing the opportunities and challenges brought by GPT and other big models to software development and testing. It also looks forward to the changes brought by A.I. to software engineering education and how we coped. The reform of software engineering is an inevitable trend, and software developers need to constantly learn new technologies and master new methods in the age of A.I.},
  keywords={Software;Software engineering;Education;Software testing;Web and internet services;Optimization;Mobile applications},
  doi={10.1109/ICIS57766.2023.10210230},
  ISSN={},
  month={June},}@ARTICLE{10993463,
  author={Ma, Zeyuan and Guo, Hongshu and Gong, Yue-Jiao and Zhang, Jun and Tan, Kay Chen},
  journal={IEEE Transactions on Evolutionary Computation}, 
  title={Toward Automated Algorithm Design: A Survey and Practical Guide to Meta-Black-Box-Optimization}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In this survey, we introduce Meta-Black-Box-Optimization (MetaBBO) as an emerging avenue within the Evolutionary Computation (EC) community, which incorporates Meta-learning approaches to assist automated algorithm design. Despite the success of MetaBBO, the current literature provides insufficient summaries of its key aspects and lacks practical guidance for implementation. To bridge this gap, we offer a comprehensive review of recent advances in MetaBBO, providing an in-depth examination of its key developments. We begin with a unified definition of the MetaBBO paradigm, followed by a systematic taxonomy of various algorithm design tasks, including algorithm selection, algorithm configuration, solution manipulation, and algorithm generation. Further, we conceptually summarize different learning methodologies behind current MetaBBO works, including reinforcement learning, supervised learning, neuroevolution, and in-context learning with Large Language Models. A comprehensive evaluation of the latest representative MetaBBO methods is then carried out, alongside an experimental analysis of their optimization performance, computational efficiency, and generalization ability. Based on the evaluation results, we meticulously identify a set of core designs that enhance the generalization and learning effectiveness of MetaBBO. Finally, we outline the vision for the field by providing insight into the latest trends and potential future directions. Relevant literature will be continuously collected and updated at https://github.com/MetaEvo/Awesome-MetaBBO.},
  keywords={Optimization;Surveys;Training;Metalearning;Performance gain;Heuristic algorithms;Supervised learning;Reviews;Recurrent neural networks;Glass box;Meta-Black-Box-Optimization;Evolutionary Computation;Black-Box-Optimization;Learning to Optimize},
  doi={10.1109/TEVC.2025.3568053},
  ISSN={1941-0026},
  month={},}@INPROCEEDINGS{10137767,
  author={Alamleh, Hosam and AlQahtani, Ali Abdullah S. and ElSaid, AbdElRahman},
  booktitle={2023 Systems and Information Engineering Design Symposium (SIEDS)}, 
  title={Distinguishing Human-Written and ChatGPT-Generated Text Using Machine Learning}, 
  year={2023},
  volume={},
  number={},
  pages={154-158},
  abstract={The use of sophisticated Artificial Intelligence (AI) language models, including ChatGPT, has led to growing concerns regarding the ability to distinguish between human-written and AI-generated text in academic and scholarly settings. This study seeks to evaluate the effectiveness of machine learning algorithms in differentiating between human-written and AI-generated text. To accomplish this, we collected responses from Computer Science students for both essay and programming assignments. We then trained and evaluated several machine learning models, including Logistic Regression (LR), Decision Trees (DT), Support Vector Machines (SVM), Neural Networks (NN), and Random Forests (RF), based on accuracy, computational efficiency, and confusion matrices. By comparing the performance of these models, we identified the most suitable one for the task at hand. The use of machine learning algorithms for detecting text generated by AI has significant potential for applications in content moderation, plagiarism detection, and quality control for text generation systems, thereby contributing to the preservation of academic integrity in the face of rapidly advancing AI-driven content generation.},
  keywords={Support vector machines;Training;Machine learning algorithms;Computational modeling;Plagiarism;Quality control;Chatbots;TextOriginClassifier;ChatGPT;human-written text;AI-generated text;machine learning;academic integrity;content detection;AI;NLP;TF-IDF},
  doi={10.1109/SIEDS58326.2023.10137767},
  ISSN={},
  month={April},}@INPROCEEDINGS{10369130,
  author={Nihal, K. Sai and Pallavi, L. and Raj, Ritik and Babu, Chunduri Madhu and Mishra, Binod},
  booktitle={2023 International Conference on Research Methodologies in Knowledge Management, Artificial Intelligence and Telecommunication Engineering (RMKMATE)}, 
  title={Enhancing Soft Skill Development with ChatGPT and VR: An Exploratory Study}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This research paper explores the significance of soft skills in predicting and enhancing future success. It emphasizes the use of current technologies, particularly virtual reality (VR) training methods, to address the lack of experience in employees and students. VR simulations have proven effective and efficient, surpassing traditional methods. The paper also discusses the emergence of AI, like ChatGPT, for training, but acknowledges the challenges of accuracy, biases, and ethics. To use VR training, one needs to think about factors like the equipment, the expense, and the ability to expand. Organizations can leverage AI and VR training to create impactful solutions by navigating these drawbacks.},
  keywords={Training;Ethics;Solid modeling;Virtual reality;Organizations;Chatbots;Software;Virtual Reality(VR);Soft-skills;ChatGPT;Students;Employees},
  doi={10.1109/RMKMATE59243.2023.10369130},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10663016,
  author={Olmez, Muhammet Mustafa and Gehringer, Edward},
  booktitle={2024 36th International Conference on Software Engineering Education and Training (CSEE&T)}, 
  title={Automation of Test Skeletons Within Test-Driven Development Projects}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={In addressing the need for test case generation in software projects and the validation and repair processes, various algorithms and AI models are increasingly being applied with novel approaches. On the other hand, despite the established effectiveness of the Test-Driven Development (TDD) approach in testing and development, there is still a lack of research examining the impact of human-machine interaction on software validation and coding. This paper introduces a tool, the test-skeleton generator, which utilizes an OpenAI model to generate test skeletons. These skele-tons include test names, signatures, and scenario descriptions, omitting the actual test bodies. To explore the implications of this tool, an empirical experiment involving student participation was conducted to assess the conversion of test skeletons into functional tests with human-machine interaction. The study reveals significant insights, indicating that human-machine interaction plays a crucial role in shaping both the testing and programming phases, encouraging students to prioritize writing tests before modifying source code. Teams adopting this approach demonstrate a tendency to produce more tests, leading to higher code coverage. Additionally, our research underscores the growing potential of AI language models to generate tests that closely resemble those written by human developers. Notably, human-machine interaction has proven its significant positive impact on the validation and repair process of AI -generated tests.},
  keywords={Human computer interaction;Source coding;Human-machine systems;Software algorithms;Maintenance engineering;Writing;Programming;Test skeletons;Test-driven development;test generation;Human-machine interaction;AI tool},
  doi={10.1109/CSEET62301.2024.10663016},
  ISSN={2377-570X},
  month={July},}@INPROCEEDINGS{10195137,
  author={Ortega, Eduardo and Tran, Michelle and Bandeen, Grace},
  booktitle={2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={AI Digital Tool Product Lifecycle Governance Framework through Ethics and Compliance by Design†}, 
  year={2023},
  volume={},
  number={},
  pages={353-356},
  abstract={The acceleration of Artificial Intelligence (AI) has brought forward new digital tools that have had a wide impact across society. However, AI digital tools (such as ChatGPT, midjourney, DALL-E 2) have brought forward legal and ethical concerns. — Internationally, public, and private leaders are introducing regulatory frameworks to address data governance for such these AI digital tools (i.e., Global Data Protection Regulation, the European AI Act, Blueprint for an AI Bill of Rights, NIST Risk Management Framework, etc.). We recognize that these AI digital tools are a vital aspect of future technological development, but they require input from various sectors in addressing ethics and compliance design. We survey the current landscape of published AI-specific regulatory frameworks and known engineering design process methods. Using a product lifecycle approach, we also introduce a trans-disciplinary framework to address AI ethics and compliance via design. This product lifecycle approach considers several principles: a Human-Centered Design for Risk Assessment, Functional Safety and Risk Management Standardization, and Continuous Governance throughout Product Lifecycle. Establishing risk management throughout AI product lifecycles can ensure accountability for AI product use cases. In addition, by utilizing previous Functional Safety considerations we can create safety mechanisms throughout the product lifecycle of AI digital tools. Finally, establishing in-field testing for continuous governance will enable the flexibility for new compliance standards and transparency. We establish this governance framework to aid in new compliance strategies for these emerging issues with AI digital tools.},
  keywords={Surveys;Ethics;Law;NIST;Regulation;Safety;Risk management;Ethics;Compliance;AI;Risk Management;Human-Centered-Design;Engineering Design Thinking},
  doi={10.1109/CAI54212.2023.00155},
  ISSN={},
  month={June},}@INPROCEEDINGS{10822765,
  author={Yujiao, Li and Jie, Yang and Ming, Xiao},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Research on the Emotional Impact of Restorative Environments Based on Facial Emotion Recognition Systems and Sora Model Virtual Reality Technology}, 
  year={2024},
  volume={},
  number={},
  pages={5638-5645},
  abstract={In recent years, the positive impact of virtual reality restorative environments on mental health has been confirmed by numerous studies. This study employed OpenAI's Sora model to create three types of virtual videos with restorative effects: natural, animal, and human environments. Using a facial emotion recognition system built with Keras, OpenCV, and PyQt5, along with the fer2013 facial expression database, and the psychological indicator detection technology of the PAD emotion scale, we conducted an experiment with 24 college students to assess their emotional responses and intensity to these three types of virtual videos in immersive virtual reality scenarios. We also collected subjective and objective physiological data from participants after they experienced different restorative virtual videos and analyzed the data using statistical methods.The results indicate that the three types of virtual videos generated by the Sora model had a positive impact on the participants' emotions. Most participants experienced a significant increase in positive emotions such as gentleness and surprise after watching the virtual natural environment videos, while negative emotions like anxiety and unease were effectively alleviated. Further analysis showed that the animal and natural environments were more effective in emotional regulation than the human environment.This study innovatively investigates the application of AI technology, particularly the Sora model, in virtual reality restorative environments, paving new directions for the exploration and application of AI technology in the emotional regulation of college students and providing new insights for future research.},
  keywords={Solid modeling;Analytical models;Emotion recognition;Animals;Anxiety disorders;Data models;Regulation;Physiology;Artificial intelligence;Videos;Artificial intelligence;Restorative environment;College students;Emotional regulation;Mental health},
  doi={10.1109/BIBM62325.2024.10822765},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10653003,
  author={Jetter, Antonie J and Agrawal, Ameeta and Hongchai, Dahm Mongkol and Weber, Charles M. and Tao, Yufei},
  booktitle={2024 Portland International Conference on Management of Engineering and Technology (PICMET)}, 
  title={Training Practitioners for Real-time Product Development Using Generative Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={A workshop to train practitioners in real-time new product development (NPD) using generative artificial intelligence (AI) was conducted. Three teams of graduate students in Engineering and Technology Management (many with work experience as managers and engineers) were given minimalist instructions to develop a product concept and a preliminary marketing plan for a product of their choosing within six hours using ChatGPT, search engines, and other Internet-based tools. The product was to be novel, and the plan was to include customer identification, market analysis, generating personas, and a 15-minute presentation at the end of the workshop. The goal was to 'inspire a sales force'. A panel of judges, which included the authors and an external marketing professional, determined the strengths, weaknesses, and viability of the development efforts of the teams. The results of the workshop validated the utility of AI in NPD for multiple industries. The panel rated the output of the effort of the teams as ‘highly creative’ and potentially viable in the real world. The most significant contribution of the workshop was demonstrating the speed at which product development activity could be performed.},
  keywords={Training;Industries;Technology management;Generative AI;Conferences;Force;Search engines},
  doi={10.23919/PICMET64035.2024.10653003},
  ISSN={2159-5100},
  month={Aug},}@ARTICLE{10988654,
  author={Ding, Yuyang and Qiao, Dan and Li, Juntao and Xu, Jiajie and Chao, Pingfu and Zhou, Xiaofang and Zhang, Min},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Towards DS-NER: Unveiling and Addressing Latent Noise in Distant Annotations}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={Distantly supervised named entity recognition (DS-NER) has emerged as a cheap and convenient alternative to traditional human annotation methods, enabling the automatic generation of training data by aligning text with external resources. Despite the many efforts in noise measurement methods, few works focus on the latent noise distribution between different distant annotation methods. In this work, we explore the effectiveness and robustness of DS-NER by two aspects: (1) distant annotation techniques, which encompasses both traditional rule-based methods and the innovative large language model supervision approach, and (2) noise assessment, for which we introduce a novel framework. This framework addresses the challenges by distinctly categorizing them into the unlabeled-entity problem (UEP) and the noisy-entity problem (NEP), subsequently providing specialized solutions for each. Our proposed method achieves significant improvements on eight real-world distant supervision datasets originating from three different data sources and involving four distinct annotation techniques, confirming its superiority over current state-of-the-art methods.},
  keywords={Annotations;Noise measurement;Noise;Training;Chatbots;Large language models;Data mining;Nearest neighbor methods;Named entity recognition;Data models;Distantly supervised learning;Named entity recognition;Noise measurement},
  doi={10.1109/TKDE.2025.3567204},
  ISSN={1558-2191},
  month={},}@INPROCEEDINGS{10893167,
  author={Hooper, Kerrie and Lunn, Stephanie J.},
  booktitle={2024 IEEE Frontiers in Education Conference (FIE)}, 
  title={Values in Education: Exploration of Artificial Intelligence Ethics Syllabi Using Natural Language Processing Analyses}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With new technologies come additional responsibilities. Examining Artificial Intelligence (AI) through an ethical lens has become increasingly important and significant. Advancements in AI have led numerous organizations, such as IEEE, to develop AI ethics guidelines for consideration in academia and industry. Additionally, higher education has an essential role in fostering innovation and developing skilled professionals who will work on topics that span social, philosophical, scientific, and technical spheres. To assess the content being covered in tertiary classrooms, we utilized a Natural Language Processing (NLP) approach for analysis. This study examines $(\mathrm{n}=45)$ AI ethics syllabi that were publicly available online. The course description, topics, department, and year were some important features captured from each syllabus. Using various NLP tools for analysis, a general exploration of AI ethics curricula was conducted. Through supervised clustering, k-means clustering, and latent Dirichlet Allocation (LDA), various patterns in the contents of the AI ethics syllabus were found. Some of these include trends and patterns from syllabi across various academic departments, years, and the pre-post Chat-GPT era. Cluster evaluation was also done on the unsupervised clusters using various metrics to determine the viability of the clusters. The LDA analysis enabled a review of topics that are consistent among the clusters, which helped highlight salient areas of focus in AI ethics syllabi. The findings from this study can serve to inform administrators and educators, acting as a baseline for including language around AI ethics topics and uncovering potential topical gaps in the contents of AI ethics syllabi. They can also provide insight into how different academic departments, like computer science and philosophy, may approach the topic. Such understanding is critical to ensuring the next generation of graduates not only considers how to utilize AI but also promotes doing so responsibly and with regard to its societal implications},
  keywords={Ethics;Technological innovation;Philosophical considerations;Reviews;Education;Organizations;Natural language processing;Resource management;Artificial intelligence;Next generation networking;artificial intelligence;AI;ethics;natural language processing;clustering},
  doi={10.1109/FIE61694.2024.10893167},
  ISSN={2377-634X},
  month={Oct},}@ARTICLE{11028073,
  author={Rajesh, Shaun George and Madangarli, Smriti Vipin and Pisharady, Gauri Santosh and Subrahmanyam, Rolla},
  journal={IEEE Access}, 
  title={Enhancement of Virtual Assistants through MultiModal AI for Emotion Recognition}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Emotion recognition is becoming increasingly critical for enhancing human-computer interactions, as emotions play a vital role in shaping human interactions and overall well-being. Machines that can detect and respond to emotional cues similar to humans are essential in multiple industries. Emotionally responsive agents find applications in education, healthcare, gaming, marketing, customer service, human-robot interaction, and entertainment. This study explores the potential of enhancing virtual assistants through multimodal Artificial Intelligence (AI), utilizing various emotion recognition techniques to create more empathetic and effective systems. The proposed methodology makes use of facial expressions and textual cues to enhance the emotional awareness of the system and achieve user satisfaction through empathetic conversation. The Facial Emotion Recognition (FER) model achieved 71% real-time accuracy, whereas the Textual Emotion Recognition (TER) model achieved 59% validation accuracy, demonstrating effective Multimodal Emotion Recognition (MER). Unlike prior multimodal emotion-aware systems, our lightweight architecture ensures real-time inference and uniquely integrates facial and textual emotion recognition with DialoGPT-based response generation — demonstrating compatibility with large language models for empathetic dialogue.},
  keywords={Emotion recognition;Virtual assistants;Accuracy;Real-time systems;Deep learning;Computational modeling;Artificial intelligence;Visualization;Data models;Chatbots;virtual assistants;large language models;facial emotion recognition;BERT;computer vision;neural networks},
  doi={10.1109/ACCESS.2025.3577664},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10701449,
  author={Osińska, Veslava and Szalach, Adam and Piotrowski, Dominik M.},
  booktitle={2024 Progress in Applied Electrical Engineering (PAEE)}, 
  title={Eye tracking as a tool for analysing human -AI image interactions}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={In recent years, artificial intelligence (AI) has significantly advanced fields like computer vision, image description, and generation, proving particularly relevant in creative areas such as generative art. This research aimed to explore AI’s capabilities in creating and describing images compared to human perception. It included a comparative analysis of visual perception using eyetracking techniques in two settings: a VR art gallery created for the BITSCOPE project and a stationary ET study of individual images. The images, sourced from the BITSCOPE project’s CHIST-ERA IV collection, were initially described by an expert following specific instructions, which were then used by AI to generate corresponding images. The eyetracking study focused on key areas and gaze plot sequences, using a gaze plot similarity metric based on topology and path length, enabled by the size of the research group.},
  keywords={Computer vision;Visualization;Art;Phase measurement;Atmospheric measurements;Gaze tracking;Time measurement;Topology;Artificial intelligence;Visual perception;artificial intelligence;eyetracking;virtual reality;computer vision},
  doi={10.1109/PAEE63906.2024.10701449},
  ISSN={2837-8326},
  month={June},}@INPROCEEDINGS{10612458,
  author={Kumar, Umang and S, Shenbaga Raj and P, Kasirajan and Sivakamasundari, G.},
  booktitle={2024 International Conference on Expert Clouds and Applications (ICOECA)}, 
  title={Smart PDF Inquiry Hub: A Comprehensive Solution for Efficient PDF Document Querying and Information Extraction}, 
  year={2024},
  volume={},
  number={},
  pages={192-198},
  abstract={With the exponential growth of digital documents, navigating through extensive PDF files to extract specific information can be time-consuming and challenging. This project addresses this issue by providing a seamless solution for users to upload PDF documents, input queries, and receive relevant responses swiftly. The ‘Smart PDF Inquiry Hub’ is a user-friendly application designed to streamline the process of querying information within PDF documents. The application utilizes advanced text processing techniques to handle PDF content effectively. It automatically extracts text, divides it into manageable chunks, and stores them in a Vector Store for quick retrieval. Users can input queries related to the document, initiating a similarity search to find relevant sections within the PDF. The “Smart PDF Inquiry Hub” incorporates advanced question-answering models from OpenAI. These models analyze user queries and extract text chunks to produce precise responses. With a user-friendly Streamlit interface, users can effortlessly upload documents, ask questions, and receive insightful answers. It serves as an invaluable tool for researchers, students, professionals, and anyone dealing with large volumes of PDF documents. By harnessing the power of text processing and machine learning, this application empowers users to efficiently navigate and extract knowledge from PDFs, saving time and enhancing productivity.},
  keywords={Visualization;Accuracy;Navigation;Machine learning;User interfaces;Portable document format;Information retrieval;Portable Document Format information retrieval;text processing;machine learning;similarity search;question answering;Streamlit;Open Artificial Intelligence;Vector Store;information retrieval;natural language processing},
  doi={10.1109/ICOECA62351.2024.00045},
  ISSN={},
  month={April},}@INPROCEEDINGS{10913604,
  author={Sampaio, Telmo and Oliveira, Pedro Filipe and Matos, Paulo},
  booktitle={2024 International Conference on Engineering and Emerging Technologies (ICEET)}, 
  title={Development of a Chatbot to Support an University Institutional Website}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Currently, the institutional website of the Polytechnic Institute of Bragança (IPB) lacks an interactive system that allows users to obtain information quickly and efficiently. With the increase in the use of online services and the preference of students for instant interactions, there is a growing need for tools that facilitate communication and access to information. This work proposes the development of a chatbot to support the IPB website, with the aim of improving user experience and providing quick and accurate answers to their queries. The main objective of this project is to create an intelligent chatbot capable of understanding and responding to a wide range of questions related to IPB. To achieve this, modern natural language processing and machine learning technologies such as Streamlit, Langchain, and OpenAI are used. The system includes an automated Web Scraper to keep information up-to-date, an architecture based on efficient document segmentation, and an administrative back office for monitoring and management. This development represents a significant advance in how users interact with the IPB website, offering a more efficient and accessible communication channel. The chatbot has the potential to reduce the workload of administrative staff while improving user satisfaction by providing accurate and instant answers to their questions.},
  keywords={Accuracy;Interactive systems;Machine learning;Communication channels;Chatbots;Solids;User experience;Service-oriented architecture;Monitoring;chatbot;webscraper;machine-learning;stream-lit},
  doi={10.1109/ICEET65156.2024.10913604},
  ISSN={2831-3682},
  month={Dec},}@INPROCEEDINGS{10245872,
  author={Qi, Junwei and Deng, Yuhao and Wang, Qingchun and Yang, Zhen and Li, Yingsong},
  booktitle={2023 IEEE 6th International Conference on Electronic Information and Communication Technology (ICEICT)}, 
  title={No-Reference Image Quality Assessment Based on Active Reasoning Module}, 
  year={2023},
  volume={},
  number={},
  pages={274-278},
  abstract={We present a no-reference image-quality - assessment algorithm based on active reasoning module. This algorithm has three modules: the feature extraction module, the active reasoning module, and the quality assessment module. The active reasoning module incorporates the generator component of the generative adversarial network and enhances its structure with the Res2Net architecture. By integrating this module into the backbone feature extraction network, we improve the receptive field of each convolutional layer, enabling the network to capture information at different scales of the image. To preserve the texture information of the image, we input the gradient map of the distorted image, the distorted image itself, and the image features generated by the generator into the quality assessment module, which has a multi-feature regression networks. This module establishes a mapping model from image-feature to image-quality scores. We conducted experimental analysis of this algorithm on three widely used public datasets, confirming the excellent performance and superiorities of the presented algorithm. The results validate the effectiveness of the designed algorithm and its ability to assess image quality accurately.},
  keywords={Image quality;Training;Feature extraction;Generative adversarial networks;Distortion;Cognition;Generators;no-reference image-quality-assessment (IQA);IGM;transformer;Res2Net},
  doi={10.1109/ICEICT57916.2023.10245872},
  ISSN={2836-7782},
  month={July},}@INPROCEEDINGS{10589162,
  author={Garcia, Manuel B. and Revano, Teodoro F. and Maaliw, Renato R. and Lagrazon, Pitz Gerald G. and Valderama, Arlene Mae C. and Happonen, Ari and Qureshi, Basit and Yilmaz, Ramazan},
  booktitle={2023 IEEE 15th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)}, 
  title={Exploring Student Preference between AI-Powered ChatGPT and Human-Curated Stack Overflow in Resolving Programming Problems and Queries}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Among computer programmers and developers, the user-oriented question-and-answer website of Stack Overflow is a useful platform for sourcing solutions to programming problems, exchanging insights, and accessing a wealth of shared knowledge. However, the timeliness of responses on this platform is frequently a limiting factor that ChatGPT could potentially address. The goal of this study was to explore the preferences of novice programmers between these platforms for finding answers to their programming questions. Anchored in the Technology Acceptance Model (TAM) and the Information Foraging Theory (IFT), the study investigates users' perceptions of usefulness, ease of use, information scent, cognitive effort, as well as overall preferences. Our findings show discernible variations in preferences within the group of students (i.e., application and website developers). In line with these results, we discussed theoretical and practical implications and suggested a dual-pronged approach to leverage both environments as coding assistants in computer programming education.},
  keywords={Knowledge engineering;Technology acceptance model;Limiting;Chatbots;Reservoirs;Reliability;Problem-solving;ChatGPT;Stack Overflow;Computer Programming;Large Language Models;Artificial Intelligence;Problem Solving},
  doi={10.1109/HNICEM60674.2023.10589162},
  ISSN={2770-0682},
  month={Nov},}@INPROCEEDINGS{10840155,
  author={Gunawan, Alifi Lazuardi and Bachtiar, Fitra Abdurrachman and Setiawan, Budi Darma},
  booktitle={2024 12th Electrical Power, Electronics, Communications, Controls and Informatics Seminar (EECCIS)}, 
  title={Comparison of Q&A Classification Using BiLSTM Based on Closed Domain Knowledge}, 
  year={2024},
  volume={},
  number={},
  pages={202-207},
  abstract={The Faculty of Computer Science, Universitas Brawijaya (Filkom UB) is committed to providing quality services for the users especially internal and external stakeholders, one of which is through the HaloFilkom service. HaloFilkom services have limitations in terms of time. HaloFilkom services are not available 24 hours due to limited working hours. Questions asked by users are not answered directly. This weakness in the HaloFilkom system can be overcome by using a chatbot system. Chatbot is an interactive system that works with natural human language and can work 24 hours. Thus, the current study explores the basic chatbot model by classifying the Q&A in the closed domain knowledge. The dataset in this research is in the form of pairs of questions and answers regarding various topics at the Filkom UB. The knowledge is preprocessed using text preprocessing which includes case folding, tokenization, padding, and tensorization. One of the chatbot models is a generative model. Creating a generative chatbot model can be done using the Seq2Seq model mechanism which consists of an encoder and decoder. The model created consists of four different architectures, namely a model with an LSTM encoder without attention and with attention and a BiLSTM model encoder without attention and with attention. Hyperparameter tuning was conducted to obtain the best hyperparameter combination. The experiment results show the best hyperparameter combination obtained is hidden size 448, drop out rate 0.5, learning rate 0.001, batch size 64, and teacher force 0. The model with the best loss is obtained with a BiLSTM encoder architecture without an attention mechanism with a train loss of 0.120. The model with the highest BLEU Score was obtained by a model with a BiLSTM encoder architecture without an attention mechanism with a BLEU Score of 0.8587 on the training data. Testing using prompt testing obtained an average BLEU Score of 0.3745 on the BiLSTM encoder without an attention mechanism model. Finally, the best model architecture obtained in this research is BiLSTM encoder without an attention mechanism.},
  keywords={Attention mechanisms;Force;Bidirectional long short term memory;Training data;Computer architecture;Chatbots;Data models;Space exploration;Tuning;Testing;q&a;text preprocessing;LSTM;BiLSTM;Seq2Seq;closed domain},
  doi={10.1109/EECCIS62037.2024.10840155},
  ISSN={2835-2777},
  month={Oct},}@ARTICLE{10526434,
  author={Trivedi, Chandan and Bhattacharya, Pronaya and Prasad, Vivek Kumar and Patel, Viraj and Singh, Arunendra and Tanwar, Sudeep and Sharma, Ravi and Aluvala, Srinivas and Pau, Giovanni and Sharma, Gulshan},
  journal={IEEE Open Journal of Industry Applications}, 
  title={Explainable AI for Industry 5.0: Vision, Architecture, and Potential Directions}, 
  year={2024},
  volume={5},
  number={},
  pages={177-208},
  abstract={The Industrial Revolution has shifted toward Industry 5.0, reinventing the Industry 4.0 operational process by introducing human elements into critical decision processes. Industry 5.0 would present massive customization via transformative technologies, such as cyber-physical systems (CPSs), artificial intelligence (AI), and big data analytics. In Industry 5.0, the AI models must be transparent, valid, and interpretable. AI models employ machine learning and deep learning mechanisms to make the industrial process autonomous, reduce downtime, and improve operational and maintenance costs. However, the models require explainability in the learning process. Thus, explainable AI (EXAI) adds interpretability and improves the diagnosis of critical industrial processes, which augments the machine-to-human explanations and vice versa. Recent surveys of EXAI in industrial applications are mostly oriented toward EXAI models, the underlying assumptions. Still, fewer studies are conducted toward a holistic integration of EXAI with human-centric processes that drives the Industry 5.0 applicative verticals. Thus, to address the gap, we propose a first-of-its-kind survey that systematically untangles EXAI integration and its potential in Industry 5.0 applications. First, we present the background of EXAI in Industry 5.0 and CPSs and a reference EXAI-based Industry 5.0 architecture with insights into large language models. Then, based on the research questions, a solution taxonomy of EXAI in Industry 5.0 is presented, which is ably supported by applicative use cases (cloud, digital twins, smart grids, augmented reality, and unmanned aerial vehicles). Finally, a case study of EXAI in manufacturing cost assessment is discussed, followed by open issues and future directions. The survey is designed to extend novel prototypes and designs to realize EXAI-based real-time Industry 5.0 applications.},
  keywords={Fifth Industrial Revolution;Artificial intelligence;Surveys;Fourth Industrial Revolution;Data models;Predictive models;Industries;Automation;cobots;cyber-physical systems (CPSs);digital twins (DTs);explainable artificial intelligence (EXAI);Industry 5.0},
  doi={10.1109/OJIA.2024.3399057},
  ISSN={2644-1241},
  month={},}@ARTICLE{10486845,
  author={McDonald, Carol and Carmicino, Bonny and Schildmeyer, Katy and Scott, Emma and Dabolina, Inga},
  journal={Position, Posture, and Pose Definitions for 3D Body Processing}, 
  title={Position, Posture, and Pose Definitions for 3D Body Processing}, 
  year={2024},
  volume={},
  number={},
  pages={1-47},
  abstract={The interchangeable use of the terms position, posture, and pose causes confusion for 3D body processing (3DBP) applications. This paper reviews current definitions and contextual use of these terms to suggest standardized nomenclature for posture and pose. This paper also reviews and discusses possible standard definitions for location, body regions, landmarks, and anatomical relationships. With large language models being central to artificial intelligence (AI), standardized terminology is imperative to all digitization efforts. Replicating, or cloning of, actual posture is a known challenge inhibiting cloned human body models, optimized virtual try-on, and critical fit assessment. 3DBP applications need to be sophisticated enough to accept and utilize unique actual postures, in a given pose, which may vary drastically from a predetermined norm. The discussion builds off of current ISO standards to an open discussion for standards toward posture-improved human body models inclusive of widely varying morphology.},
  keywords={3DBP;3D body processing;body models;definitions;pose;posture;standardized terminology;terminology},
  doi={},
  ISSN={},
  month={March},}@ARTICLE{9878171,
  author={Picinini Méxas, Rodrigo and Rodrigues Leta, Fabiana and Gonzalez Clua, Esteban Walter},
  journal={IEEE Latin America Transactions}, 
  title={Comparison of Reinforcement and Imitation Learning algorithms in autonomous sailboat Digital Twins}, 
  year={2022},
  volume={20},
  number={9},
  pages={2153-2161},
  abstract={This project aims to study the performance of two reinforcement machine learning algorithms, namely the Proximal Policy Optimization and Soft Actor Critic, in the simulation of autonomous sailboats and their response to different wind directions while avoiding obstacles detected by image analysis and following defined target check-points. Also, the effect of the imitation learning algorithms Behavioral Cloning and Generative Adversarial Imitation Learning combined with the first mentioned algorithms is studied. The proposed scenarios consist of areas filled with random static or moving obstacles and with the presence of favorable or crosswinds. The motivation for the project comes from the lack of studies of the mentioned algorithms in autonomous sailboats, issue which the current study tries to address. The Unity platform and ML-Agents machine learning toolkit are used for development and the methodology that guides the project can be similarly applied to other reinforcement learning problems. Through agent training, it is possible to compare the results and observe that the Proximal Policy Optimization obtains better performance within the proposed scenarios, both with and without the support of imitation learning algorithms.},
  keywords={Q-learning;Optimization;Python;Machine learning algorithms;Collision avoidance;Visualization;Tornadoes;reinforcement learning;imitation learning;autonomous sailboat;unmanned surface vehicle},
  doi={10.1109/TLA.2022.9878171},
  ISSN={1548-0992},
  month={Sep.},}@INPROCEEDINGS{10398656,
  author={Vasiliniuc, Mircea-Serban and Groza, Adrian},
  booktitle={2023 IEEE 19th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Case study: using AI-assisted code generation in mobile teams}, 
  year={2023},
  volume={},
  number={},
  pages={339-346},
  abstract={We evaluate the performance of AI-assisted programming in mobile development teams that are focused on native mobile languages like Kotlin and Swift. The case study involves 16 participants and 2 technical reviewers, from a software development department and it is designed to understand the impact of using Large Language Models trained for code generation in particular phases of the team, more specifically, technical onboarding and technical stack switch. The study uses technical problems dedicated to each phase and requests solutions from the participants with and without using AI-Code generators. It measures time, correctness, and ‘technical integration’ using a new proposed metric ReviewerScore, extracted from industry standards, the code reviewer of merge/pull requests.The output is converted and analyzed together with feedback from the participants in an attempt to determine if using AI-assisted programming tools will have an impact on getting developers onboard in a project or helping them with a smooth transition between the two native development environments of mobile development, Android and iOS. The study was performed between May and June 2023 with members of the mobile department of a software development company based in Cluj-Napoca, with Romanian ownership and management.},
  keywords={Codes;Switches;Writing;Programming;Generators;Software;Encoding;BigCode;Machine Learning (ML);Large Language Models (LLM);Mobile Development;Swift;Kotlin;Software Development Industry;Code Generation;Text-to-Code},
  doi={10.1109/ICCP60212.2023.10398656},
  ISSN={2766-8495},
  month={Oct},}@ARTICLE{10443461,
  author={Shao, Yunna and Xiang, Bangmeng},
  journal={IEEE Access}, 
  title={Enhancing Bug Report Summaries Through Knowledge-Specific and Contrastive Learning Pre-Training}, 
  year={2024},
  volume={12},
  number={},
  pages={37653-37662},
  abstract={Bug reports are crucial in software maintenance, with concise summaries significantly enhancing the efficiency of bug triagers and ultimately contributing to the development of high-quality software products. Contemporary methods for automatic bug report summarization primarily utilize neural networks’ robust learning capabilities. However, these approaches often produce suboptimal summaries due to two primary limitations: 1) the difficulty in assimilating the domain-specific knowledge inherent in bug reports, and 2) the limitations of purely supervised learning in comprehending the comprehensive context of bug reports. To address the above two problems, in this paper, we propose a new approach for bug report summarization, namely KSCLP, which leverages large language models and domain-specific pre-training strategies, i.e., Knowledge-Specific and Contrastive Learning Pre-training. Specifically, the Knowledge-Specific strategy allows to pre-train KSCLP on project-specific bug reports corpus, by which the model can fully learn internal knowledge of bug reports, learning bug report-aware representation. As for the Contrastive Learning strategy, it performs a sequence-level pre-training for KSCLP, helping it capture the semantic information of bug reports on a global level. Upon completion of the pre-training phase, KSCLP undergoes further refinement through a Sequence-to-Sequence framework specifically tailored for bug report summarization. The efficacy of KSCLP is rigorously evaluated against five baseline models using a publicly available dataset. The empirical results demonstrate that KSCLP outperforms all baselines, achieving remarkable improvements by up to 23.73, 13.97, and 20.89 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, thereby setting new benchmarks in the field of bug report summarization.},
  keywords={Computer bugs;Task analysis;Codes;Self-supervised learning;Software maintenance;Semantics;Representation learning;Domain specific languages;Computer bugs;Software packages;Bug report summarization;domain-specific pre-training;software maintenance;representation learning},
  doi={10.1109/ACCESS.2024.3368915},
  ISSN={2169-3536},
  month={},}@INBOOK{10880614,
  author={Sharma, Riya and Singh, Balraj and Khamparia, Aditya},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Machine Learning and Generative AI Techniques for Sentiment Analysis with Applications}, 
  year={2025},
  volume={},
  number={},
  pages={183-208},
  abstract={Summary <p>This chapter presents a thorough investigation and examination of machine learning and generative artificial intelligence (AI)&#x2010;based sentiment analysis approaches in the context of social media. As more and more companies use social media platforms for customer involvement and service delivery, it is critical to comprehend the feelings and viewpoints that people are expressing. Although sentiment analysis is a machine learning technique that is skilled in identifying positive and negative sentiment polarities within textual data, due to technological advancements and an increase in the number of data, AI models are becoming popular nowadays. This chapter explores the different approaches used in sentiment analysis, using publications, journals, and scientific research articles. Sentiment analysis can turn an enormous amount of raw data from social media&#x2014;a rich supply of user&#x2010;generated content in a variety of formats, including text, photos, videos, and audio&#x2014;into insightful understandings. To better understand machine learning and generative AI, the study classifies popular research methods and applications from a range of domains.</p>},
  keywords={Sentiment analysis;Social networking (online);Classification algorithms;Unsupervised learning;Lexicon;Training data;Support vector machines;Supervised learning;Probabilistic logic;Principal component analysis},
  doi={10.1002/9781394280735.ch10},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10880614},}@INBOOK{10880623,
  author={Singh, Sudhanshu and Singh, Suruchi and Raghuvanshi, C.S.},
  booktitle={Generative Artificial Intelligence for Biomedical and Smart Health Informatics}, 
  title={Generating Synthetic Medical Data Using GAI}, 
  year={2025},
  volume={},
  number={},
  pages={51-71},
  abstract={Summary <p>The scene of clinical examination is going through a change in outlook, filled by the extraordinary force of Generative Computerized reasoning (GAI). This part dives into the interesting domain of Producing Manufactured Clinical Information utilizing GAI, investigating reforming healthcare enormous potential. We set out on an excursion directed by the four mainstays of imagination, decisive reasoning, cooperation, and correspondence.</p> <p>Creativity ignites our exploration, as we envision a kaleidoscope of possibilities. From crafting realistic patient populations to simulating intricate disease progressions, GAI paints a vibrant canvas of synthetic data, unconstrained by the limitations of real&#x2010;world cohorts.</p> <p>Decisive reasoning fills in as our compass, guaranteeing we explore this early field with reasonability. We dig into the moral contemplations, possible predispositions, and generalizability challenges intrinsic in manufactured information age. By fundamentally assessing these angles, we prepare for mindful and effective applications. Joint effort turns into the extension that associates assorted points of view. We investigate the collaboration between clinical experts, information researchers, and simulated intelligence trained professionals, underscoring the force of interdisciplinary groups in saddling the maximum capacity of GAI for clinical information age. Correspondence shapes the extension between the specialized complexities and the more extensive clinical local area. We endeavor to introduce complex ideas in an open and drawing in way, cultivating an exchange that engages specialists, clinicians, and general society to comprehend and use the extraordinary force of manufactured clinical information. This section isn't only a specialized piece; it is a solicitation to an ensemble of innovativeness, decisive reasoning, joint effort, and correspondence. Together, we can open the tremendous capability of GAI in creating manufactured clinical information, pushing medical care towards a future overflowing with conceivable outcomes. <ul> <li>Crafted with Creativity Imagine a world where AI conjures realistic patient cohorts, mirroring the intricate tapestry of human health and disease. We'll investigate GAI's kaleidoscope of strategies, from Contingent Generative Ill&#x2010;disposed Organizations (cGANs) that paint clear pictures of clinical imaging to Variational Autoencoders (VAEs) that murmur the mysteries concealed inside hereditary information. We should release our creative mind and investigate the unfamiliar regions of engineered information age, where illness displaying and drug revelation waltz connected at the hip.</li> <li>Fueled by Critical Thinking But venturing into the synthetic realm demands a discerning eye. We'll fastidiously take apart the moral contemplations and expected traps of GAI&#x2010;produced information, guaranteeing it fills in as a dependable reflection, not a mutilated mirror, of human wellbeing. We'll consider the fragile dance between information constancy and security, and investigate strategies to relieve inclination and guarantee the mindful utilization of this incredible asset.</li> <li>Rooted in Collaboration This journey is not meant to be traversed alone. We'll praise the soul of coordinated effort, cultivating associations between specialists, clinicians, and simulated intelligence specialists. Envision interdisciplinary groups, where clinical aptitude guides artificial intelligence advancement, and man&#x2010;made intelligence bits of knowledge enlighten clinical practice. We'll investigate open&#x2010;source stages and information sharing drives, building spans that prepare for aggregate advancement.</li> <li>Articulated with Clarity Our narrative unfolds with clear, concise language, accessible to a diverse audience. We'll make an interpretation of perplexing specialized ideas into absorbable exposition, guaranteeing that the groundbreaking capability of GAI resounds with everybody, from prepared scientists to inquisitive understudies.</li> <li>Creative Ideas for the Chapter Patient Avatar Generation: Describe a GAI system that creates personalized patient avatars, complete with medical histories, genetic profiles, and virtual responses to treatment interventions. Disease Progression Simulation: Showcase a GAI model that simulates the real&#x2010;time progression of complex diseases, enabling researchers to test treatment strategies in a virtual environment. Drug Discovery Acceleration: Explore how GAI&#x2010;generated synthetic data can be used to virtually screen millions of potential drug candidates, significantly accelerating the drug discovery process. Personalized Medicine Advancements: Discuss how synthetic data can be used to tailor treatment plans to individual patients, ushering in a new era of personalized medicine. Ethical Considerations and Societal Impact: Dedicate a section to the ethical considerations and potential societal impacts of GAI&#x2010;generated medical data, fostering responsible and inclusive applications.</li> </ul> </p>},
  keywords={Biomedical imaging;Diseases;Data privacy;Autoencoders;Artificial intelligence;Paints;Genetics;Generators;Ethics;Wrist},
  doi={10.1002/9781394280735.ch3},
  ISSN={},
  publisher={IEEE},
  isbn={9781394280728},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10880623},}@ARTICLE{10772566,
  author={Obite, Felix and Krayani, Ali and Alam, Atm S. and Marcenaro, Lucio and Nallanathan, Arumugam and Regazzoni, Carlo},
  journal={IEEE Transactions on Cognitive Communications and Networking}, 
  title={Exploring Active Inference for Efficient Resource Allocation in UAV-Enabled Cognitive NOMA Uplink}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={The integration of unmanned aerial vehicles (UAVs), cognitive radio (CR), and non-orthogonal multiple access (NOMA) presents a promising solution to significantly enhance the performance of future wireless networks. Achieving this integration requires cognitive self-awareness for intelligent resource allocation. In this paper, we address the problem of sum rate maximization in UAV-enabled cognitive NOMA uplink systems through the joint optimization of subchannel assignment and power allocation, while considering the UAV’s mobility. The traditional approach to finding the optimal solution requires an iterative or exhaustive search across all possible combinations of subchannel assignment, power allocation, and UAV position at each time slot, leading to excessive computational complexity. Furthermore, machine learning models, often trained on datasets that do not fully capture the complexity of real-world scenarios, struggle to handle non-stationary events effectively. To solve this nonconvex optimization challenge, we draw inspiration from active inference in cognitive neuroscience and propose a novel data-driven approach called the Active Generalized Dynamic Bayesian Network (Active-GDBN). The main idea is to process the unknown nonlinear input of an exhaustive search optimization algorithm using an Active-GDBN framework. This framework leverages a probabilistic generative model to learn the complex relationships and dependencies among subchannel assignments, power distributions, and the UAV’s mobility. The model is facilitated by continuous neuronal message passing in both discrete and continuous states to predict the optimal configuration. Numerical results show that the proposed approach achieves sum rate performance near the optimal exhaustive search and surpasses other baseline approaches.},
  keywords={NOMA;Autonomous aerial vehicles;Resource management;Wireless networks;Optimization;Throughput;Heuristic algorithms;Computational modeling;Uplink;Inference algorithms;Active inference;generalized dynamic Bayesian network (GDBN);resource allocation;UAV;cognitive-NOMA},
  doi={10.1109/TCCN.2024.3510577},
  ISSN={2332-7731},
  month={},}@INPROCEEDINGS{11016327,
  author={Ordoumpozanis, Kostas and Apostolidis, Hippokratis},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={A Second-Generation Agentic Framework for Generative Ai-Driven Augmented Reality Educational Games}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={This paper presents a multi-agent collaborative framework with human-in-the-loop integration for creating educational augmented reality (AR) serious games. It provides a detailed analysis of the system's internal modules, agents, and tools, highlighting its complexity. This work focuses on the design phase, while implementation of the framework is yet to be developed. The framework consists of four main modules: Data Management,Narrative Crafting, Content Generation, and Game Creation. It uses the Scratch-pad as a shared memory to manage agent communication and long-context data, guiding agents step-by-step in the game-building process. The framework also incorporates short- and long-term memory to improve agent performance over time. Additionally, it integrates Generative AI (Gen-AI) models for asset creation in immersive games. The analysis reveals the system's complexity and the numerous hyper-parameters that need further study at both technical and user experience levels. This study invites other researchers to contribute to this framework, aiming to develop a collaborative educational tool that removes technical barriers and empowers teachers and students to create and engage with immersive interactive learning experiences.},
  keywords={Generative AI;Memory management;Collaboration;Games;Transforms;Human in the loop;User experience;Complexity theory;Serious games;Augmented reality;AI Agents;Augmented Reality;Serious Games;Short-term;long-term;memory},
  doi={10.1109/EDUCON62633.2025.11016327},
  ISSN={2165-9567},
  month={April},}@ARTICLE{10964151,
  author={Yang, Wanting and Xiong, Zehui and Guo, Song and Mao, Shiwen and Kim, Dong In and Debbah, Merouane},
  journal={IEEE Transactions on Mobile Computing}, 
  title={Efficient Multi-user Offloading of Personalized Diffusion Models: A DRL-Convex Hybrid Solution}, 
  year={2025},
  volume={},
  number={},
  pages={1-17},
  abstract={Generative diffusion models like Stable Diffusion are at the forefront of the thriving field of generative models today, celebrated for their robust training methodologies and high-quality photorealistic generation capabilities. These models excel in producing rich content, establishing them as essential tools in the industry. Building on this foundation, the field has seen the rise of personalized content synthesis as a particularly exciting application. However, the large model sizes and iterative nature of inference make it difficult to deploy personalized diffusion models broadly on local devices with heterogeneous computational power. To address this, we propose a novel framework for efficient multi-user offloading of personalized diffusion models. This framework accommodates a variable number of users, each with different computational capabilities, and adapts to the fluctuating computational resources available on edge servers. To enhance computational efficiency and alleviate the storage burden on edge servers, we propose a tailored multi-user hybrid inference approach. This method splits the inference process for each user into two phases, with an optimizable split point. Initially, a cluster-wide model processes low-level semantic information for each user's prompt using batching techniques. Subsequently, users employ their personalized models to refine these details during the later phase of inference. Given the constraints on edge server computational resources and users' preferences for low latency and high accuracy, we model the joint optimization of each user's offloading request handling and split point as an extension of the Generalized Quadratic Assignment Problem (GQAP). Our objective is to maximize a comprehensive metric that balances both latency and accuracy across all users. To solve this NP-hard problem, we transform the GQAP into an adaptive decision sequence, model it as a Markov decision process, and develop a hybrid solution combining deep reinforcement learning with convex optimization techniques. Simulation results validate the effectiveness of our framework, demonstrating superior optimality and low complexity compared to traditional methods. All related code, datasets, and fine-tuned models are available at https://github.com/wty2011jl/E-MOPDM.},
  keywords={Computational modeling;Diffusion models;Noise reduction;Servers;Measurement;Adaptation models;Accuracy;Semantics;Optimization;Inference algorithms;Diffusion model;edge offloading;generalized quadratic assignment problem;DRL;AIGC service;hybrid inference},
  doi={10.1109/TMC.2025.3560582},
  ISSN={1558-0660},
  month={},}@ARTICLE{10536869,
  author={Rekanar, Kaavya and Ahmed, Abbirah and Mohandas, Reenu and Sistu, Ganesh and Eising, Ciarán and Hayes, Martin},
  journal={IEEE Access}, 
  title={Subjective Scoring Framework for VQA Models in Autonomous Driving}, 
  year={2024},
  volume={12},
  number={},
  pages={141306-141323},
  abstract={The development of vision and language transformer models has paved the way for Visual Question Answering (VQA) models and related research. There are metrics to assess the general accuracy of VQA models but subjective assessment of the answers generated by the models is necessary to gain an in-depth understanding and a framework for subjective assessment is required. This work develops a novel scoring system based on the subjectivity of the question and analyses the answers provided by the model using multiple types of natural language processing models (bert-base-uncased, nli-distilBERT-base, all-mpnet-base-v2 and GPT-2) and sentence similarity benchmark metrics (Cosine Similarity). A case study detailing the use of the proposed subjective scoring framework on three prominent VQA models- ViLT, ViLBERT, and LXMERT using an automotive dataset is also presented. The framework proposed aids in analyzing the shortcomings of the discussed VQA models from a driving perspective and the results achieved help determine which model would work best when fine-tuned on a driving-specific VQA dataset.},
  keywords={Autonomous vehicles;Measurement;Visualization;Analytical models;Intelligent vehicles;Data models;Task analysis;Semantics;Question answering (information retrieval);Visualization;Semantic analysis;scoring framework;subjective assessment;VQA models},
  doi={10.1109/ACCESS.2024.3404349},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10143584,
  author={Rao, Jian and Qiu, Chuqi and Xiong, Mengzhen},
  booktitle={2022 3rd International Conference on Information Science and Education (ICISE-IE)}, 
  title={Research on Image Processing and Generative Teaching in the Context of AIGC}, 
  year={2022},
  volume={},
  number={},
  pages={20-25},
  abstract={AIGC, meaning AI-generated content, is discussed in this paper, mainly in the form of painting, without discussing the automation of music composition and text-writing poetry, etc. While generative art has aesthetic characteristics, more content needs to be studied in the context of computer information science, with a particular emphasis on computer vision and computer graphics. The article focuses on a comparative analysis of two models, diffusion algorithms and generative adversarial networks, and their application to tools. The practical part of image processing uses a combination of case studies and questionnaires to demonstrate the lack of methodology, teaching experience, and introductory learning materials for non-computer professionals in the emerging field, and to explain “filter mapping” through Processing, a visual programming software. The author’s reflections on the generated content combine the self-similarity of the “Uncanny Valley effect” and the “Dunning Kruger effect” lineage, comparing the “self-organizing” (machine) simulation personification and the “life form” (human) simulation personification. The process of cognitive assimilation of a “living organism” (human) is used to understand the new human-machine associative relationship.},
  keywords={Information science;Visualization;Art;Image processing;Education;Semantics;Software;AIGC;Disco Diffusion;Processing;Generative art;semantic mapping},
  doi={10.1109/ICISE-IE58127.2022.00011},
  ISSN={},
  month={Nov},}@ARTICLE{10684193,
  author={Kuhail, Mohammad Amin and Berengueres, Jose and Taher, Fatma and Khan, Sana Zeb and Siddiqui, Ansah},
  journal={IEEE Access}, 
  title={Designing a Haptic Boot for Space With Prompt Engineering: Process, Insights, and Implications}, 
  year={2024},
  volume={12},
  number={},
  pages={134235-134255},
  abstract={Recent literature indicates the potential of applying Artificial Intelligence (AI) tools to enhance ideation outcomes and optimize functionality across various engineering disciplines. However, a comprehensive understanding of applying AI in the design process is lacking, particularly regarding projects involving innovative design. Here, we address the integration of AI in a case study project. The project goal is to design a haptic boot to be used on Mars. We apply a popular AI tool, ChatGPT-3.5, to each design step, from the requirement gathering phase to the prototyping and testing phase. To assess the merit of the AI contributions, we asked eight domain experts to give qualitative feedback. The results indicate that current AI tools can provide a valuable starting point in the requirements and design phases. However, we noted instances of hallucinations and poor traceability. Finally, the experts’ evaluation points out that the AI-proposed requirements and design are missing key elements expected as an outcome in an engineering design process. This study offers insight into the practical application of AI through a specific engineering design process.},
  keywords={Artificial intelligence;Prompt engineering;Haptic interfaces;Education;Chatbots;Industries;Software engineering;AI;ChatGPT;design;engineering;space;haptics},
  doi={10.1109/ACCESS.2024.3449396},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10987974,
  author={Patil, Bhavesh and Yadav, Gitanjali B and Buchade, Amar and Borkar, Soham and Bhosale, Shreyash and Honbute, Vikrant},
  booktitle={2025 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Dynamic StarCraft: Multi-Agent Generative AI for Immersive Experiences}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={The present research reveals a unique educational approach through the use of Generative Artificial Intelligence (GenAI) with the focus on storytelling with children. It is shown that by adding GenAI narrative co-creation, voice-over synthesis, and video audition to the system, the learning process becomes interesting. We understand how the audience creates the stories with which they will perform, how the stories are narrated in audio created with advanced text-to-speech systems, and how images for the narratives are generated with text-to-video. Our assessment is however concerned with the level of the languages used in writing the stories, how the stories written were pronounced and the images that were produced, as we point out the ability of the tool to entertain young learners.},
  keywords={Measurement;Generative AI;Refining;Pipelines;Layout;Media;Writing;Software;Text to speech;Text to video;GenAI;LLM;Text-To-Speech(TTS);Text-to-Video(TTV);TTM},
  doi={10.1109/ESCI63694.2025.10987974},
  ISSN={2996-1815},
  month={March},}@INPROCEEDINGS{10489028,
  author={Saeed, Abdullah and Dhanda, Namrata and Rao, Ansh Samuel and Verma, Rajat},
  booktitle={2024 2nd International Conference on Disruptive Technologies (ICDT)}, 
  title={AI-Enabled Semantic Web}, 
  year={2024},
  volume={},
  number={},
  pages={1136-1141},
  abstract={The paper presents a comprehensive study on the development of an AI-enabled Semantic Search application using a Full Stack approach. The project integrates cutting-edge technologies, such as Next.js, Langchain, Pinecone, and ChatGPT, to create a robust and efficient information retrieval system. The methodology begins by setting up the essential imports and utility functions for Langchain and Pinecone. Diverse data types are then loaded seamlessly using specialized loaders. The project's core involves the creation of a Pinecone index and successfully uploading documents, which establishesa powerful and accessible database. The application's user interface can be enriched with advanced UI features. These features enhance the aesthetic appeal and interactivity of the platform, facilitating user navigation and query formulation. The implemented technique discusses the challenges of developing an AI-enabled Semantic Search application, such as the need to deal with large volumes of data and the complexity of natural language processing, and suggests solutions to these challenges, such as using distributed computing and machine learning techniques. The culmination of these efforts is a comprehensive Semantic Search application that leverages the capabilities of AI and modern web technologies to deliver an immersive, efficient, and personalized information retrieval experience. This research contributes to the advancement of full-stack development practices and demonstrates the potential of integrating AI technologies to enhance user interactions with data-rich platforms.},
  keywords={Semantic Web;Systematics;Semantic search;Navigation;Transforms;Search engines;User interfaces;LangChain;LLMs;Semantic Search;Text Embedding;Web},
  doi={10.1109/ICDT61202.2024.10489028},
  ISSN={},
  month={March},}@ARTICLE{10213396,
  author={Bull, Christopher and Kharrufa, Ahmed},
  journal={IEEE Software}, 
  title={Generative Artificial Intelligence Assistants in Software Development Education: A Vision for Integrating Generative Artificial Intelligence Into Educational Practice, Not Instinctively Defending Against It}, 
  year={2024},
  volume={41},
  number={2},
  pages={52-59},
  abstract={The use of Generative AI in software development is gaining traction. But what are the potentials and implications on software development education? We gathered insights on the use of Generative AI from professional software developers and make some pedagogical recommendations.},
  keywords={Codes;Chatbots;Software development management;Programming profession;Artificial intelligence;Generative AI;Computer science education;Social implications of technology;Programming profession;Educational programs;Education;Software engineering;Problem-solving;Training},
  doi={10.1109/MS.2023.3300574},
  ISSN={1937-4194},
  month={March},}@ARTICLE{10598190,
  author={Carvalko, Joseph R.},
  journal={IEEE Transactions on Technology and Society}, 
  title={Generative AI, Ingenuity, and Law}, 
  year={2024},
  volume={5},
  number={2},
  pages={169-182},
  abstract={This paper discusses generative pre-trained transformer technology and its intersection with forms of creativity and law. It highlights the potential of generative AI to change considerable elements of society, including modes of creative endeavors, problem-solving, employment, education, justice, medicine, and governance. The author emphasizes the need for policymakers and experts to join in regulating against the potential risks and implications of this technology. The European Commission has taken steps to address the risks of AI through the European AI Act (EIA), which categorizes AI uses based on their potential harm. The legislation aims to ensure scrutiny and control in extreme cases like autonomous weapons or medical devices. However, the author criticizes the lack of meaningful AI oversight in the United States and argues that time has come for government to step in and offer meaningful regulation given the technology’s (1) rate of diffusion (2) virtually uncountable product permutations, the purposes, extent and depths to which it is anticipated to penetrate institutional and daily life.},
  keywords={Generative AI;Artificial intelligence;Ethics;Internet;Chatbots;Deep learning;Neural networks;Regulation;Problem-solving;Employment;Education;Europe;Creativity;Social implications of technology;Risk management;Artificial intelligence;computation and language;deep learning neural networks;NLP;LLM;OpenAI;ChatGPT;generative AI;generative pretrained transformer;transformer-based AI;European AI Act;EIA;technology ethics},
  doi={10.1109/TTS.2024.3413591},
  ISSN={2637-6415},
  month={June},}@INPROCEEDINGS{10836028,
  author={Ahmed, Waqas and Sentosa, Ilham and Hizam, Sheikh Muhamad and Mat, Che Rosmawati Che and Hernandez, Martin Spraggon},
  booktitle={2023 International Conference on Data, Information and Computing Science (CDICS)}, 
  title={Evaluating the Acceptance of Enhanced Generative AI Services}, 
  year={2023},
  volume={},
  number={},
  pages={73-77},
  abstract={The rapid advancement of artificial intelligence (AI) has introduced a spectrum of generative AI services that promise to enhance various professional and personal tasks. This study aims to explore the factors influencing users’ intentions to transition from basic to premium generative AI services, focusing on Performance Expectancy (PE), Technology Self-Efficacy (TSE), Personal Innovativeness (PI), and Social Influence (SI). A survey of 193 individuals, primarily university students with an IT background, revealed that PE, TSE, and SI significantly affect the Behavioral Intention (BI) to adopt enhanced services, with SI being the most influential. Contrary to expectations, PI did not predict BI, indicating that innovation alone does not drive the adoption of advanced AI capabilities. The findings suggest that the practicality of AI tools, user confidence in their technical skills, and the persuasive power of social networks are pivotal in the decision-making process for upgrading AI services. This research contributes to the understanding of AI adoption patterns and provides insights for developers and marketers to tailor user experiences and educational initiatives that align with user needs and social dynamics. It also underscores the importance of addressing ethical considerations as AI continues to permeate various aspects of society.},
  keywords={Surveys;Technological innovation;Ethics;Generative AI;Social networking (online);Decision making;Focusing;Chatbots;Generative AI;ChatGPT;Technology Acceptance;User Behavior;Social Influence},
  doi={10.1109/CDICS61497.2023.00022},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10972692,
  author={Bosser, Anne-Gwenn and Cascarano, Pasquale and Lacoche, Jérémy and Hajahmadi, Shirin and Stanescu, Ana and Sörös, Gábor},
  booktitle={2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)}, 
  title={Preface to the First Workshop on GenAI-XR: Generative Artificial Intelligence meets Extended Reality}, 
  year={2025},
  volume={},
  number={},
  pages={129-130},
  abstract={The GenAI-XR workshop aims to explore the intersection of Generative Artificial Intelligence (GenAI) and Extended Reality (XR), examining their combined potential to revolutionize various sectors including entertainment, arts, education, factory work, healthcare, architecture, and others. The workshop will provide a platform for researchers, industry professionals, and practitioners to discuss innovative methods of integrating GenAI into XR environments, enhancing immersive experiences, and personalizing interactions in real time. Through presentation and discussion sessions, participants will gain insights into the latest developments, challenges, and future directions at the intersection of GenAI and XR.},
  keywords={Three-dimensional displays;Extended reality;Generative AI;Conferences;Education;Entertainment industry;Medical services;User interfaces;Real-time systems;Production facilities;IndexTerms: Generative Artificial Intelligence;Extended Reality;Artificial Intelligence and Extended Reality Integration;Personalized Interactions;Adaptive Environments;Context-Aware Systems},
  doi={10.1109/VRW66409.2025.00033},
  ISSN={},
  month={March},}@INPROCEEDINGS{10569755,
  author={Vlahović, N. and Košanski, M. and Glavan, Lj. Milanović},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Reinventing Mobile-assisted Language Learning using Natural Language Processing}, 
  year={2024},
  volume={},
  number={},
  pages={398-403},
  abstract={Mobile-assisted Language Learning (MALL) is a trend in language acquisition through informal learning supported by mobile devices. The transition from the previous generation of software solutions, Computer-Assisted Language Learning applications or CALL applications, was characterized usually by direct translation of known functionalities from stationary hardware to mobile hardware without taking into account all of the capabilities of mobile devices while creating and implementing various mechanisms for language acquisitions. Additionally, natural language processing technologies have reached level of maturity even more recently and as such have not been used on a larger scope to enrich the approaches to language acquisition. In this paper we will investigate several possible concepts that utilize natural language processing capabilities with mobile technology in order to provide more variety and enhance engagement in informal language learning process. The main goal of the paper is to present several types of activities that aim to reinvent mobile-assisted language learning using generative AI for text-to-speech and speech-to-text functionalities provided by natural language processing. Additionally, we will also present a study of attitudes of students toward the presented solutions and innovations. Results testify that student population assesses these approaches as useful, refreshing and engaging.},
  keywords={Surveys;Technological innovation;Sociology;Prototypes;Natural language processing;Software;Mobile handsets;Educational software;Foreign Language Learning;Natural language processing (NLP);Generative AI;Informal Learning;Software engineering},
  doi={10.1109/MIPRO60963.2024.10569755},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{9870312,
  author={Tao, Ning and Ventresque, Anthony and Saber, Takfarinas},
  booktitle={2022 IEEE Congress on Evolutionary Computation (CEC)}, 
  title={Multi-objective Grammar-guided Genetic Programming with Code Similarity Measurement for Program Synthesis}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Grammar-Guided Genetic Programming (G3P) is widely recognised as one of the most successful approaches for program synthesis, i.e., the task of automatically discovering an executable piece of code given user intent. G3P has been shown capable of successfully evolving programs in arbitrary languages that solve several program synthesis problems based only on a set of input/output examples. Despite its success, the restriction on the evolutionary system to only leverage input/output error rate during its assessment of the programs it derives limits its scalabil-ity to larger and more complex program synthesis problems. With the growing number and size of open software repositories and generative artificial intelligence approaches, there is a sizeable and growing number of approaches for retrieving/generating source code (potentially several partial snippets) based on textual problem descriptions. Therefore, it is now, more than ever, time to introduce G3P to other means of user intent (particularly textual problem descriptions). In this paper, we would like to assess the potential for G3P to evolve programs based on their similarity to particular target codes of interest (obtained using some code retrieval/generative approach). Through our experimental evaluation on a well-known program synthesis benchmark, we have shown that G3P successfully manages to evolve some of the desired programs with all four considered similarity measures. However, in its default configuration, G3P is not as successful with similarity measures as it is with the classical input/output error rate when solving program synthesis problems. Therefore, we propose a novel multi-objective G3P approach that combines the similarity to the target program and the traditional input/output error rate. Our experiments show that compared to the error-based G3P, the multi-objective G3P approach could improve the success rate of specific problems and has great potential to improve on the traditional G3P system.},
  keywords={Codes;Error analysis;Measurement uncertainty;Genetic programming;Evolutionary computation;Benchmark testing;Software;Program Synthesis;Grammar-Guided Genetic Programming;Code Similarity;Multi-Objective Optimization},
  doi={10.1109/CEC55065.2022.9870312},
  ISSN={},
  month={July},}@ARTICLE{10908885,
  author={Zhu, Dandan and Zhang, Kaiwei and Min, Xiongkuo and Zhai, Guangtao and Yang, Xiaokang},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={ScanDTM: A Novel Dual-Temporal Modulation Scanpath Prediction Model for Omnidirectional Images}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={Scanpath prediction for omnidirectional images aims to effectively simulate the human visual perception mechanism to generate dynamic realistic fixation trajectories. However, the majority of scanpath prediction methods for omnidirectional images are still in their infancy as they fail to accurately capture the time-dependency of viewing behavior and suffer from sub-optimal performance along with limited generalization capability. A desirable solution should achieve a better trade-off between prediction performance and generalization ability. To this end, we propose a novel dual-temporal modulation scanpath prediction (ScanDTM) model for omnidirectional images. Such a model is designed to effectively capture long-range time-dependencies between various fixation regions across both internal and external time dimensions, thereby generating more realistic scanpaths. In particular, we design a Dual Graph Convolutional Network (Dual-GCN) module comprising a semantic-level GCN and an image-level GCN. This module servers as a robust visual encoder that captures spatial relationships among various object regions within an image and fully utilizes similar images as complementary information to capture similarity relations across relevant images. Notably, the proposed Dual-GCN focuses on modeling temporal correlations from both local and global perspectives within the internal time dimension. Furthermore, drawing inspiration from the promising generalization capabilities of diffusion models across various generative tasks, we introduce a novel diffusion-guided saliency module. This module formulates the prediction issue as a conditional generative process for the saliency map, utilizing extracted semantic-level and image-level visual features as conditions. With the well-designed diffusion-guided saliency module, our proposed ScanDTM model acting as an external temporal modulator, we can progressively refine the generated scanpath from the noisy map. We conduct extensive experiments on several benchmark datasets, and the results demonstrate that our ScanDTM model significantly outperforms other competitors. Meanwhile, when applied to tasks such as saliency prediction and image quality assessment, our ScanDTM model consistently achieves superior generalization performance.},
  keywords={Visualization;Predictive models;Feature extraction;Modulation;Solid modeling;Correlation;Trajectory;Electronic mail;Training;Face recognition;Scanpath prediction;dual graph convolutional network;diffusion model;dual temporal modulator;omnidirectional image},
  doi={10.1109/TCSVT.2025.3545908},
  ISSN={1558-2205},
  month={},}@INPROCEEDINGS{10590319,
  author={Gao, Weizheng and Allagan, Julian D. and Gao, Shanzhen and Su, Jianning and Malomo, Olumide and Eyob, Ephrem and Adekoya, Adeyemi},
  booktitle={2023 International Conference on Computational Science and Computational Intelligence (CSCI)}, 
  title={Problem-Solving Using Logic and Reasoning, Mathematics, Algorithms, Python and Generative AI}, 
  year={2023},
  volume={},
  number={},
  pages={371-377},
  abstract={Problem-solving is essential in various fields, including business, technology, and everyday life. It often involves a combination of experience, knowledge, intuition, and rational analysis. Furthermore, it requires integrating disciplines such as logic and reasoning, mathematics, algorithms, Python, and generative AI in today's complex world. We will provide detailed descriptions of how to solve problems based on integrating previously mentioned disciplines. Later, we will discuss how to guide students through making intelligent investment decisions.},
  keywords={Generative AI;Scientific computing;Programming;Mathematics;Cognition;Problem-solving;Logic;Problem-Solving;intelligent decision-making;generative AI;ChatGPT;Python Programming Language;logic and reasoning;mathematics;algorithms},
  doi={10.1109/CSCI62032.2023.00066},
  ISSN={2769-5654},
  month={Dec},}@INPROCEEDINGS{11004879,
  author={Chaudhary, Jyoti and A V, Vijaya Kumar and K, Manikannan and Sapatnekar, Amol and Barve, Amit and Maranan, Ramya},
  booktitle={2025 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={Enhanced Software Defect Prediction using Quantum Hamiltonian Generative Adversarial Network for Improved Software Performance Reliability}, 
  year={2025},
  volume={},
  number={},
  pages={1047-1052},
  abstract={The development of software systems with high quality and decreased maintenance costs depends on Software Defect Prediction (SDF). The current dataset qualities combined with feature redundancies make confident fault detection difficult through conventional methods. Current defect prediction techniques display multiple deficits through inaccurate results along with many false alarms and dataset bias. A high-performance quantum-inspired method must be researched in working to create an accurate precision model. The project will create the Enhanced Software Defect Prediction using Quantum Hamiltonian Generative Adversarial Network for Improved Software Performance Reliability (DBO-QH-GAN) model. Several software metrics need to be retrieved from the PROMISE datasets before this process can be initiated. The second step includes Fuzzy K- Top Matcher (FK- TM) functionality that removes undesirable noise factors such as redundant features and missing values as well as outliers. The Botox Optimization (BotO) algorithm selects five essential metrics that encompass cyclomatic complexity as well as Halstead measures and coupling and code churn and historical defect density. These preprocessed set of characteristics are fed to a Quantum Hamiltonian Generative Adversarial Network (QH-GAN) which identifies the defects from probabilistic thresholding and thereafter optimized using Duck Bevy Optimization (DBO) to achieve the optimal possible performance. Accuracy of the model was 99.2%, precision was 99.4%, and recall was 99.1 %. The DBO-QH-GAN model sets new standards for defect prediction by providing an improved enhancement of reliability along with decreased maintenance cost.},
  keywords={Quantum computing;Costs;Accuracy;Software performance;Predictive models;Generative adversarial networks;Software reliability;Maintenance;Optimization;Standards;Botox Optimization;Duck Bevy Optimization;Fuzzy K-Top Matcher;Quantum Hamiltonian Generative Adversarial Network;PROMISE;Software Defect Prediction},
  doi={10.1109/ICICT64420.2025.11004879},
  ISSN={2767-7788},
  month={April},}@INPROCEEDINGS{10796462,
  author={Albano, Norberto and Brignone, Sandro},
  booktitle={2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={Exploring Bias in Text-to-Image Models: From Body Representation of Teenage Students to Perspectives for the Aging Society}, 
  year={2024},
  volume={},
  number={},
  pages={1212-1217},
  abstract={Starting from the results of a study on body shaming conducted between Italy and Romania in ay 2020/21, this investigation explores the presence of bias in images produced by generative Text-To-Image (TTI) models. Specifically, it proposes an analysis and evaluation of the representation of adolescent students' bodies in the outputs of two different TTI systems, highlighting social, cultural, and technological factors. The findings reveal significant biases in the representations of students, with notable differences between the platforms examined, and underline the need for targeted educational interventions to counter distorted perceptions of the body. This research provides a reflective contribution on the impact of TTIs on society and on the representation of body image that extends to different social and demographic categories, among these, the elderly, who are often victims or passive users of these technologies.},
  keywords={Training;Biological system modeling;Social sciences;Text to image;Neural engineering;Aging;Metrology;Cultural differences;Older adults;Investment;Artificial Intelligence;TTI Models;Fairness;Bias;Body Representation and Perception;Body Shaming;Education and Awareness},
  doi={10.1109/MetroXRAINE62247.2024.10796462},
  ISSN={},
  month={Oct},}@ARTICLE{10777917,
  author={Staron, Miroslaw and Abraháo, Silvia and Serebrenik, Alexander and Penzenstadler, Birgit and Horkoff, Jennifer and Honnenahalli, Chetan},
  journal={IEEE Software}, 
  title={Laws, Ethics, and Fairness in Software Engineering}, 
  year={2025},
  volume={42},
  number={1},
  pages={110-113},
  abstract={Software engineering in the era of generative AI, large data sets and superfast pace of software development often tends to focus on technology, tools and methods, putting aside us, software engineers. In this column, we focus on softer aspects of software engineering and report from two conferences: 28th International Conference on Evaluation and Assessment in Software Engineering (EASE 2024) and 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM 2024). The selection of papers provides a glimpse on handling privacy, documenting ethical considerations in AI models and trustworthy AI.},
  keywords={Ethics;Privacy;Generative AI;Software measurement;Software engineering;Software development management;Artificial intelligence},
  doi={10.1109/MS.2024.3469488},
  ISSN={1937-4194},
  month={Jan},}@INPROCEEDINGS{9835627,
  author={Chakrabarty, Krishnendu},
  booktitle={2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)}, 
  title={EDAML 2022 Invited Speaker 4: Fault Criticality Assessment in AI Accelerators}, 
  year={2022},
  volume={},
  number={},
  pages={1185-1185},
  abstract={Summary form only. The ubiquitous application of deep neural networks (DNN) has led to a rise in demand for AI accelerators. DNN-specific functional criticality analysis identifies faults that cause measurable and significant deviations from acceptable requirements such as the inferencing accuracy. This talk will examine the problem of classifying structural faults in the processing elements (PEs) of systolic-array accelerators. The speaker will first present a two-tier machine-learning (ML) based method to assess the functional criticality of faults. The problem of minimizing misclassification will be addressed by utilizing generative adversarial networks (GANs). The two- tier ML/GAN-based criticality assessment method leads to less than 1% test escapes during functional criticality evaluation of structural faults. While supervised learning techniques can be used to accurately estimate fault criticality, it requires a considerable amount of ground truth for model training. The speaker will therefore present a neural-twin framework for analyzing fault criticality with a negligible amount of ground-truth data. A recently proposed misclassification-driven training algorithm will be used to sensitize and identify biases that are critical to the functioning of the accelerator for a given application workload. The proposed framework achieves up to 100% accuracy in fault-criticality classification in 16-bit and 32-bit PEs by using the criticality knowledge of only 2% of total faults in a PE.},
  keywords={Circuit faults;AI accelerators;Technological innovation;Distributed processing;Circuits and systems},
  doi={10.1109/IPDPSW55747.2022.00197},
  ISSN={},
  month={May},}@ARTICLE{10669782,
  author={Castelo, Sonia and Rulff, Joao and Solunke, Parikshit and McGowan, Erin and Wu, Guande and Roman, Iran and Lopez, Roque and Steers, Bea and Sun, Qi and Bello, Juan and Feest, Bradley and Middleton, Michael and Mckendrick, Ryan and Silva, Claudio},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={HuBar: A Visual Analytics Tool to Explore Human Behavior Based on fNIRS in AR Guidance Systems}, 
  year={2025},
  volume={31},
  number={1},
  pages={119-129},
  abstract={The concept of an intelligent augmented reality (AR) assistant has significant, wide-ranging applications, with potential uses in medicine, military, and mechanics domains. Such an assistant must be able to perceive the environment and actions, reason about the environment state in relation to a given task, and seamlessly interact with the task performer. These interactions typically involve an AR headset equipped with sensors which capture video, audio, and haptic feedback. Previous works have sought to facilitate the development of intelligent AR assistants by visualizing these sensor data streams in conjunction with the assistant's perception and reasoning model outputs. However, existing visual analytics systems do not focus on user modeling or include biometric data, and are only capable of visualizing a single task session for a single performer at a time. Moreover, they typically assume a task involves linear progression from one step to the next. We propose a visual analytics system that allows users to compare performance during multiple task sessions, focusing on non-linear tasks where different step sequences can lead to success. In particular, we design visualizations for understanding user behavior through functional near-infrared spectroscopy (fNIRS) data as a proxy for perception, attention, and memory as well as corresponding motion data (acceleration, angular velocity, and gaze). We distill these insights into embedding representations that allow users to easily select groups of sessions with similar behaviors. We provide two case studies that demonstrate how to use these visualizations to gain insights about task performance using data collected during helicopter copilot training tasks. Finally, we evaluate our approach through an in-depth examination of a think-aloud experiment with five domain experts.},
  keywords={Data visualization;Behavioral sciences;Functional near-infrared spectroscopy;Sensors;Time series analysis;Data models;Visual analytics;Perception & Cognition;Application Motivated Visualization;Temporal Data;Image and Video Data;AR/VR/Immersive},
  doi={10.1109/TVCG.2024.3456388},
  ISSN={1941-0506},
  month={Jan},}@INPROCEEDINGS{10943733,
  author={Mukherjee, Anjishnu and Zhu, Ziwei and Anastasopoulos, Antonios},
  booktitle={2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)}, 
  title={Crossroads of Continents: Automated Artifact Extraction for Cultural Adaptation with Large Multimodal Models}, 
  year={2025},
  volume={},
  number={},
  pages={1755-1764},
  abstract={We present a comprehensive three-phase study to ex-amine (1) the cultural understanding of Large Multimodal Models (LMMs) by introducing Dalle Street, a large-scale dataset generated by DALL-E 3 and validated by hu-mans, containing 9, 935 images of 67 countries and 10 concept classes, (2) the underlying implicit and potentially stereotypical cultural associations with a cultural artifact extraction task, and (3) an approach to adapt cultural representation in an image based on extracted associations using a modular pipeline, Cultureadapt. We find disparities in cultural understanding at geographic sub-region levels with both open-source (LLaVA) and closed-source (GPT-4V) models on Dalle Street and other existing benchmarks, which we try to understand using over 18, 000 artifacts that we identify in association to different coun-tries. Our findings reveal a nuanced picture of the cultural competence of LMMs, highlighting the need to develop culture-aware systems.11Dataset and code are available: https://github.com/iamshnoo/crossroads},
  keywords={Cultural competence;Adaptation models;Computer vision;Codes;Computational modeling;Pipelines;Benchmark testing;Cultural differences;Continents;Artificial intelligence;cultural localization;cultural bias analysis;llm;multimodal;culture;dataset},
  doi={10.1109/WACV61041.2025.00178},
  ISSN={2642-9381},
  month={Feb},}@INPROCEEDINGS{10932270,
  author={Desai, Arun and Kulkarni, Anagha},
  booktitle={2025 1st International Conference on AIML-Applications for Engineering & Technology (ICAET)}, 
  title={Unleashing the Potential of Ontology in Skill Extraction}, 
  year={2025},
  volume={},
  number={},
  pages={1-6},
  abstract={Research reveals ontology's ability to extract information about skills from online job sites by giving a structured and semantically rich representation of skills. The study talks about more accurate and thorough skill profiling by systematically building ontological models that allow for an indepth knowledge of the complex links between skills, abilities, and domains. In this research, we study papers from different methods like supervised learning, unsupervised learning, and LLMs. The paper begins by providing not only an overview what is new in ontology generation but also its application in the context of skill extraction. It then delves into the challenges and opportunities associated with ontology-based skill extraction, highlighting the ways of processing natural language in bridging the gap between unstructured text and the formal representation of skills and competencies. Furthermore, the paper presents a comprehensive framework for ontology-driven skill extraction, emphasizing the importance of contextual awareness and the identification of implicit skills that may not be explicitly stated in the source text. The potential implications of this approach are manifold, as it could significantly impact various aspects of the talent management ecosystem.},
  keywords={Manifolds;Accuracy;Biological system modeling;Supervised learning;Natural languages;Ecosystems;Machine learning;Ontologies;Data mining;Unsupervised learning;Ontology;skill extraction;skills;Jobs;Machine Learning},
  doi={10.1109/ICAET63349.2025.10932270},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10777249,
  author={De Silva, D. I. and Athukorala, K. S. N.},
  booktitle={2024 International Conference on Information and Communication Technology for Development for Africa (ICT4DA)}, 
  title={Sinhala Java Development Aid with Machine Translation Integration}, 
  year={2024},
  volume={},
  number={},
  pages={194-199},
  abstract={Programming plays a vital role in computer science. However, beginners often face challenges such as limited availability of programming resources and language barriers. A Sinhala programming aid specifically designed for new Java programmers is proposed to address these issues. Ensuring translator accuracy is essential to overcoming the language barrier. To assist with translations, a transformer-based model was trained on a Java-specific dataset, achieving an accuracy of 84%. This model assists in generating the responses based on questions that have been translated and integrated with the ChatGPT. This two-in-one application lets users submit Java code to get explanations in Sinhala, or input queries in Sinhala to get equivalent Java code snippets, effectively removing linguistic barriers from the learning process. The system architecture includes a robust back-end API, an advanced translation model that guarantees accurate and contextually relevant translations, and an easy-to-use front-end developed with Flask. Usability and functionality testing were conducted with ten novice Sinhala-speaking programmers. Their feedback was instrumental in improving the tool's usability and efficacy. This study addresses the integration of several technologies to improve the accessibility of programming instruction for Sinhala-speaking learners. It also elaborates on the development process, from basic concept to execution phases. By providing a localized learning environment, the proposed technology simplifies learning programming and aids in concept retention while promoting a more inclusive global coding community.},
  keywords={Java;Accuracy;Codes;Quality assurance;Systems architecture;Programming;Transformers;Chatbots;Usability;Testing;Java developers;machine translation model;programming aid;Flask;ChatGPT},
  doi={10.1109/ICT4DA62874.2024.10777249},
  ISSN={},
  month={Nov},}@ARTICLE{10812818,
  author={Guo, Qi and Pang, Shanmin and Jia, Xiaojun and Liu, Yang and Guo, Qing},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Efficient Generation of Targeted and Transferable Adversarial Examples for Vision-Language Models via Diffusion Models}, 
  year={2025},
  volume={20},
  number={},
  pages={1333-1348},
  abstract={Adversarial attacks, particularly targeted transfer-based attacks, can be used to assess the adversarial robustness of large visual-language models (VLMs), allowing for a more thorough examination of potential security flaws before deployment. However, previous transfer-based adversarial attacks incur high costs due to high iteration counts and complex method structure. Furthermore, due to the unnaturalness of adversarial semantics, the generated adversarial examples have low transferability. These issues limit the utility of existing methods for assessing robustness. To address these issues, we propose AdvDiffVLM, which uses diffusion models to generate natural, unrestricted and targeted adversarial examples via score matching. Specifically, AdvDiffVLM uses Adaptive Ensemble Gradient Estimation (AEGE) to modify the score during the diffusion model’s reverse generation process, ensuring that the produced adversarial examples have natural adversarial targeted semantics, which improves their transferability. Simultaneously, to improve the quality of adversarial examples, we use the GradCAM-guided Mask Generation (GCMG) to disperse adversarial semantics throughout the image rather than concentrating them in a single area. Finally, AdvDiffVLM embeds more target semantics into adversarial examples after multiple iterations. Experimental results show that our method generates adversarial examples 5x to 10x faster than state-of-the-art (SOTA) transfer-based adversarial attacks while maintaining higher quality adversarial examples. Furthermore, compared to previous transfer-based adversarial attacks, the adversarial examples generated by our method have better transferability. Notably, AdvDiffVLM can successfully attack a variety of commercial VLMs in a black-box environment, including GPT-4V. The code is available at https://github.com/gq-max/AdvDiffVLM},
  keywords={Diffusion models;Semantics;Robustness;Closed box;Noise;Image quality;Adaptation models;Electronic mail;Glass box;Focusing;Adversarial attack;visual language models;diffusion models;score matching},
  doi={10.1109/TIFS.2024.3518072},
  ISSN={1556-6021},
  month={},}@ARTICLE{10849613,
  author={Parikh, Nishant Ashokkumar},
  journal={IEEE Engineering Management Review}, 
  title={Managing AI-First Products: Roles, Skills, Challenges, and Strategies of AI Product Managers}, 
  year={2025},
  volume={},
  number={},
  pages={1-11},
  abstract={Artificial Intelligence (AI) is revolutionizing industries, offering significant opportunities for innovation while introducing unique complexities in product management. Despite its transformative potential, research on the distinct responsibilities, challenges, and skills required of AI Product Managers (AI PMs) remains limited, leaving a critical gap in understanding how to effectively manage AI-driven products. This study addresses this gap using a grounded theory approach to analyze the evolving roles of AI PMs and propose strategies for managing the complexities of AI-first product development. Central to this study is the introduction of the AI PM Archetype Persona Framework, which encompasses expanded responsibilities, specific challenges and mitigation strategies, essential skills and competencies, AI product lifecycle management, personality traits, and the application of generative AI tools in product management. These findings provide actionable insights for practitioners and organizations, enabling them to tackle AI challenges, refine product lifecycle strategies, and foster sustainable innovation in an AI-driven market landscape.},
  keywords={Artificial intelligence;Interviews;Ethics;Product development;Prevention and mitigation;Generative AI;Complexity theory;Technological innovation;Navigation;Encoding;AI product life cycle;AI product manager;AI product manager archetype persona;AI product manager challenges;AI product manager skills},
  doi={10.1109/EMR.2025.3530942},
  ISSN={1937-4178},
  month={},}@INPROCEEDINGS{10859219,
  author={Liem, Cynthia C. S. and Taşcılar, Doğa and Demetriou, Andrew M.},
  booktitle={2024 International Conference on Content-Based Multimedia Indexing (CBMI)}, 
  title={A Quest Through Interconnected Datasets: Lessons From Highly-Cited ICASSP Papers}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={As audio machine learning outcomes are deployed in societally impactful applications, it is important to have a sense of the quality and origins of the data used. Noticing that being explicit about this sense is not trivially rewarded in academic publishing in applied machine learning domains, and neither is included in typical applied machine learning curricula, we present a study into dataset usage connected to the top-5 cited papers at the International Conference on Acoustics, Speech, and Signal Processing (ICASSP). In this, we conduct thorough depthfirst analyses towards origins of used datasets, often leading to searches that had to go beyond what was reported in official papers, and ending into unclear or entangled origins. Especially in the current pull towards larger, and possibly generative AI models, awareness of the need for accountability on data provenance is increasing. With this, we call on the community to not only focus on engineering larger models, but create more room and reward for explicitizing the foundations on which such models should be built.},
  keywords={Publishing;Generative AI;Annotations;Machine learning;Signal processing;Data models;Acoustics;Speech processing;Indexing;Annotation practices;data quality;data provenance;responsible research;applied machine learning},
  doi={10.1109/CBMI62980.2024.10859219},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10475599,
  author={Karkiner, Zeynep and Yaman, Begum and Zengin, Begum and Cavli, Feride Nursena and Sert, Mustafa},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={ParsyBot: Chatbot for Baskent University Related FAQs}, 
  year={2024},
  volume={},
  number={},
  pages={168-175},
  abstract={Reading regulations and instructions may take lots of time and sometimes it results in disappointments. To avoid this issue, people are prone to use sources that provide fast and accurate answers while accessing the information. Chatbots, are one of the most popular trend topics nowadays, and may adapted into various fields e.g., healthcare, finance, and education. This paper proposes the development of ParsyBot which is a Turkish chatbot designed to inform users about the regulations, admissions, departments, scholarships, and social clubs of Baskent University. Furthermore, users may ask via voice in Turkish this feature is not common among the other chatbots. ParsyBot uses a pre-trained BERT model which is specifically trained with regulations and instructions of Baskent University. Parsybot runs on web and mobile platforms to make it available for everyone. Our experiments on the utilized dataset, ParsyBot, reached 0.81 in METEOR, and 0.24 in ROGUE-1, which are promising compared to the ChatGPT 3.5.},
  keywords={Scholarships;Semantics;Education;Finance;Medical services;Chatbots;Market research;Chatbot;BERT;NLP;Mobile Application},
  doi={10.1109/ICSC59802.2024.00033},
  ISSN={2472-9671},
  month={Feb},}@ARTICLE{10541859,
  author={Lyu, Yunbo and Kang, Hong Jin and Widyasari, Ratnadira and Lawall, Julia and Lo, David},
  journal={IEEE Transactions on Software Engineering}, 
  title={Evaluating SZZ Implementations: An Empirical Study on the Linux Kernel}, 
  year={2024},
  volume={50},
  number={9},
  pages={2219-2239},
  abstract={The SZZ algorithm is used to connect bug-fixing commits to the earlier commits that introduced bugs. This algorithm has many applications and many variants have been devised. However, there are some types of commits that cannot be traced by the SZZ algorithm, referred to as “ghost commits”. The evaluation of how these ghost commits impact the SZZ implementations remains limited. Moreover, these implementations have been evaluated on datasets created by software engineering researchers from information in bug trackers and version controlled histories. Since Oct 2013, the Linux kernel developers have started labelling bug-fixing patches with the commit identifiers of the corresponding bug-inducing commit(s) as a standard practice. As of v6.1-rc5, 76,046 pairs of bug-fixing patches and bug-inducing commits are available. This provides a unique opportunity to evaluate the SZZ algorithm on a large dataset that has been created and reviewed by project developers, entirely independently of the biases of software engineering researchers. In this paper, we apply six SZZ implementations to 76,046 pairs of bug-fixing patches and bug-introducing commits from the Linux kernel. Our findings reveal that SZZ algorithms experience a more significant decline in recall on our dataset ($\downarrow 13.8\%$↓13.8%) as compared to prior findings reported by Rosa et al., and the disparities between the individual SZZ algorithms diminish. Moreover, we find that 17.47% of bug-fixing commits are ghost commits. Finally, we propose Tracing-Commit SZZ (TC-SZZ), that traces all commits in the change history of lines modified or deleted in bug-fixing commits. Applying TC-SZZ to all failure cases, excluding ghost commits, we found that TC-SZZ could identify 17.7% of them. Our further analysis based on git log found that 34.6% of bug-inducing commits were in the function history, 27.5% in the file history (but not in the function history), and 37.9% not in the file history. We further evaluated the effectiveness of ChatGPT in boosting the SZZ algorithm's ability to identify bug-inducing commits in the function history, in the file history and not in the file history.},
  keywords={History;Software algorithms;Kernel;Linux;Computer bugs;Codes;Chatbots;SZZ;defect prediction;empirical study;ChatGPT},
  doi={10.1109/TSE.2024.3406718},
  ISSN={1939-3520},
  month={Sep.},}@INPROCEEDINGS{10133863,
  author={Narrain, Jigisha M and Taneja, Vanshika and Atrey, Sanjana B and Sivaram, Jahnavi and Singh, Dinesh},
  booktitle={2023 Winter Summit on Smart Computing and Networks (WiSSCoN)}, 
  title={Extractive Summarization - A Comparison of Pre-Trained Language Models and Proposing a Hybrid Approach}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  abstract={The automatic summarization of technical articles is a field that has garnered a fair amount of interest, and one that enjoys a significant portion of NLP-related research. As a whole, automatic summarization can be split into two broad categories - extractive and abstractive. Extractive summarization implies that important and relevant sentences are picked from the article as is, and inserted in the summary. Abstractive summarization, on the other hand, requires contextual understanding of the document, and rearranging and shortening the sentences, while maintaining the core essence of the article. Multiple algorithms have been proposed for both these classes of automatic summarization. In the recent past, the emergence of pre-trained language models for NLP tasks have been heralded by the creation of attention mechanisms and Transformers. These models implement encoder-decoder structures, and have far wider applications than previously utilised algorithms. Four such pretrained models are - BERT, BART, XLNet and GPT-2. In this project, we use transfer learning to fit these models on our corpus of Medium articles, fine-tuning them for the task of summarization. Further, we generate online summaries of the data, and use ROUGE metrics to evaluate the accuracy of the model-generated summaries alongside those. We also implement the popular Word2Vec model on the same data, and compare its result with the ones obtained from the attention based models, once again using ROUGE metrics. In addition, we explore the effectiveness of a hybrid approach to the summarization task, by using different combinations of the models on the same article to investigate the results of the same.},
  keywords={Measurement;Computational modeling;Transfer learning;Natural languages;Bit error rate;Transformer cores;Transformers;natural language processing;machine learning;automatic summarization;language model;attention mechanism;BERT;BART;XLNet;GPT-2;hybrid model;word2vec},
  doi={10.1109/WiSSCoN56857.2023.10133863},
  ISSN={},
  month={March},}@INPROCEEDINGS{10233997,
  author={Kale, Sumedh S. and Andreopoulos, William B.},
  booktitle={2023 IEEE Ninth International Conference on Big Data Computing Service and Applications (BigDataService)}, 
  title={Job Tailored Resume Content Generation}, 
  year={2023},
  volume={},
  number={},
  pages={40-47},
  abstract={Generally candidates apply to multiple jobs with a single resume and do not tend to customize their resume to match the job description. This hampers their chances of getting a resume shortlisted for the job. The project aims to help such candidates build job tailored resumes that help them create a customized and targeted resume for a specific job. The tool specifically targets candidates’ employment work history for resume content generation. We create a synthetic dataset built from candidates’ employment history and online job descriptions. We use natural language processing (NLP) techniques to extract and organize the dataset, experiment with multiple dataset variations and cite ways to effectively build the dataset for the proposed task. We then use natural language generation by fine tuning GPT-2 for the task of resume content generation. Finally we evaluate the fine tuned model on various metrics and report our findings.},
  keywords={Measurement;Resumes;Employment;Computer architecture;Transformers;Natural language processing;History;content generation;natural language generation;natural language processing;generative AI;transformers},
  doi={10.1109/BigDataService58306.2023.00012},
  ISSN={},
  month={July},}@INPROCEEDINGS{10570106,
  author={Moeini, Mobina and Ahmadian, Rouhollah and Ghatee, Mehdi},
  booktitle={2024 8th International Conference on Smart Cities, Internet of Things and Applications (SCIoT)}, 
  title={Calibrated SVM for Probabilistic Classification of In-Vehicle Voices into Vehicle Commands via Voice-to-Text LLM Transformation}, 
  year={2024},
  volume={},
  number={},
  pages={180-188},
  abstract={With the rapid advancement of artificial intelligence technologies in human life, particularly within the automotive industry, the popularity of smart vehicles has increased. Designing an intelligent car cabin capable of seamless interactions with both the driver and the vehicle emerges as a crucial solution to address human-vehicle interaction challenges. This project aims to implement a digital voice assistant that recognizes vehicle commands. It utilizes three main techniques: speech-to-text conversion, text classification, and calibrating the classifier in order to detect out-of-distribution (OOD) sentences. Using Vosk, an LLM model, voices in the vehicle environment are converted into text format. Then, after pre-processing the text, an SVM classifies them. Using Platt scaling the SVM classifier outputs become calibrated, which makes them probabilistic. The experimental result shows that the proposed model achieves command recognition with 96.43% accuracy, 96.83% precision, 96.43% recall, 96.39% F1-score, and 0.1437 cross-entropy loss. Furthermore, the optimal threshold for OOD sentences is 0.4.},
  keywords={Support vector machines;Industries;Smart cities;Text categorization;Personal voice assistants;Probabilistic logic;Internet of Things;Driver Assistant;Voice Assistant;Command Recognition;Automotive Systems;LLM;Vosk;SVM},
  doi={10.1109/SCIoT62588.2024.10570106},
  ISSN={},
  month={May},}@INPROCEEDINGS{10944943,
  author={Hu, Jiekang and Li, Yakai and Xiang, Zhaoxi and Ma, Luping and Jia, Xiaoqi and Huang, Qingjia},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={LLM4MDG: Leveraging Large Language Model to Construct Microservices Dependency Graph}, 
  year={2024},
  volume={},
  number={},
  pages={859-869},
  abstract={Microservices architecture has gained popularity in modern software development due to its scalability and flexibility. However, understanding the complexity of interactions and dependencies between services presents significant challenges, which complicates the identification and analysis of errors within microservice applications. To gain insights into the architecture and interdependencies of microservices applications, prior studies have developed dependency graphs to illustrate the relationships among services. However, the methods used to construct these dependency graphs are not suitable for common microservices applications and suffer from insufficient data granularity. To address these shortcomings, we introduce LLM4MDG, an in-novative framework for constructing microservices dependency graphs using an LLM-driven multi-agent system. By leveraging optimized prompt engineering and principles of knowledge graphs, LLM4MDG can effectively identify and interpret service interactions across diverse microservice ecosystems, achieving high accuracy and adaptability across various scenarios. We also present a new open-source dataset comprising 47 microservices applications, annotated by domain experts, to validate our frame-work. Evaluation results demonstrate that LLM4MDG achieves an 88.3% accuracy in identifying data dependencies in the Train Ticket project, a benchmark application with over 80 service instances. This study provides a robust solution for constructing dependency graphs and facilitating better system understanding and management.},
  keywords={Accuracy;Large language models;Scalability;Microservice architectures;Computer architecture;Knowledge graphs;Prompt engineering;Security;Software development management;Multi-agent systems;Microservice Architecture;Large Language Model;Prompt Engineering;Data Dependencies;Knowledge Graph},
  doi={10.1109/TrustCom63139.2024.00128},
  ISSN={2324-9013},
  month={Dec},}@ARTICLE{10737883,
  author={Moser, Brian B. and Shanbhag, Arundhati S. and Raue, Federico and Frolov, Stanislav and Palacio, Sebastian and Dengel, Andreas},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Diffusion Models, Image Super-Resolution, and Everything: A Survey}, 
  year={2024},
  volume={},
  number={},
  pages={1-21},
  abstract={Diffusion models (DMs) have disrupted the image super-resolution (SR) field and further closed the gap between image quality and human perceptual preferences. They are easy to train and can produce very high-quality samples that exceed the realism of those produced by previous generative methods. Despite their promising results, they also come with new challenges that need further research: high computational demands, comparability, lack of explainability, color shifts, and more. Unfortunately, entry into this field is overwhelming because of the abundance of publications. To address this, we provide a unified recount of the theoretical foundations underlying DMs applied to image SR and offer a detailed analysis that underscores the unique characteristics and methodologies within this domain, distinct from broader existing reviews in the field. This article articulates a cohesive understanding of DM principles and explores current research avenues, including alternative input domains, conditioning techniques, guidance mechanisms, corruption spaces, and zero-shot learning approaches. By offering a detailed examination of the evolution and current trends in image SR through the lens of DMs, this article sheds light on the existing challenges and charts potential future directions, aiming to inspire further innovation in this rapidly advancing area.},
  keywords={Image quality;Superresolution;Diffusion models;Surveys;Computational modeling;Faces;Degradation;Training;Standards;Reviews;Diffusion models (DMs);super-resolution (SR);survey},
  doi={10.1109/TNNLS.2024.3476671},
  ISSN={2162-2388},
  month={},}@INBOOK{10897226,
  author={Islam, Mohammad Rubyet},
  booktitle={Generative AI, Cybersecurity, and Ethics}, 
  title={Introduction}, 
  year={2025},
  volume={},
  number={},
  pages={1-16},
  abstract={Summary <p>In today's fast&#x2010;paced digital world, the intersection of generative artificial intelligence (GenAI), cybersecurity, and ethics presents both thrilling opportunities and significant challenges. This book embarks on an exciting journey, showcasing how GenAI enhances digital security while addressing the ethical dilemmas that arise. From safeguarding personal data to thwarting complex cyberattacks, understanding the link between AI and cybersecurity is more crucial than ever. As we unlock GenAI's potential, we also encounter new ethical challenges, necessitating responsible harnessing of these advanced technologies. This introductory chapter explores pivotal themes in GenAI, cybersecurity, and ethics, laying the foundation for a comprehensive examination of this captivating subject.</p>},
  keywords={Artificial intelligence;Deep learning;Biological neural networks;Virtual assistants;Technological innovation;Propulsion;Programming;Generative AI;Data visualization;Virtual environments},
  doi={10.1002/9781394279326.ch1},
  ISSN={},
  publisher={Wiley},
  isbn={9781394279319},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10897226},}@INBOOK{10834115,
  author={Dubey, Shival and Sikarwar, Shailendra Singh},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Applications of AI in Cancer Detection &#x2014; A Review of the Specific Ways in which AI Is Being Used to Detect and Diagnose Various Types of Cancer}, 
  year={2025},
  volume={},
  number={},
  pages={147-166},
  abstract={Summary <p>The mixing of superior deep learning strategies has profoundly impacted the sector of sickness identification, promising sizable advancements in diagnostic accuracy and performance. This paper explores the utilization of multi&#x2010;scale convolutional layers, interest mechanisms, switch learning, generative adversarial networks (GANs), and self&#x2010;supervised learning in the healthcare domain. These techniques collectively beautify the capability of convolutional neural networks (CNNs) to discover and diagnose diseases from medical pix with extraordinary precision. Multi&#x2010;scale convolutional layers allow the models to capture features at numerous scales, improving the sensitivity and specificity of disease detection, mainly in situations like most cancers. Attention mechanisms similarly refine this process by allowing models to focus on the most applicable components of an picture, mirroring the meticulous examination by healthcare professionals.</p> <p>Transfer learning, leveraging training fashions, extensively reduces the reliance on tremendous, categorized datasets, thereby expediting the development process and enhancing version accuracy. This approach has shown outstanding success throughout distinctive imaging modalities, from X&#x2010;rays to CT scans, improving the adaptability and robustness of diagnostic models. GANs contribute via producing artificial records to augment schooling datasets, addressing the challenge of limited data availability and enhancing model performance, specifically in uncommon disease scenarios. Self&#x2010;supervised learning, which trains fashions on unlabeled records via proxy duties, has demonstrated comparable performance to absolutely supervised fashions while requiring fewer categorized samples, therefore lowering the need for luxurious and time&#x2010;eating data annotation.</p> <p>Innovations in those areas have not only improved the technical performance of disease identification models but also opened new avenues for his or her application. Future research should explore multimodal learning, which mixes data from various assets, including genomic information and digital health data, imparting a more complete diagnostic perspective. The implementation of federated learning guarantees data privacy while enhancing model training via decentralized records assets. Explainable AI (XAI) techniques enhance model interpretability, fostering extra consider and popularity amongst healthcare professionals. Moreover, the integration of AI with wearable devices for continuous fitness tracking and the improvement of real&#x2010;time adaptive learning fashions hold tremendous promise for revolutionizing patient care and disease control.</p> <p>This comprehensive method to leveraging superior deep learning methodologies in disorder identification underscores the transformative potential of AI in healthcare. With the aid of addressing modern&#x2010;day demanding situations and exploring progressive answers, we can pave the way for greater accuracy, efficiency, and personalized diagnostic systems, in the end enhancing patient results and advancing current care in medical exercise.</p>},
  keywords={Artificial intelligence;Cancer detection;Medical services;Cancer;Technological innovation;Oncology;Accuracy;Medical diagnostic imaging;Collaboration;Bioinformatics},
  doi={10.1002/9781394278695.ch7},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10834115},}@ARTICLE{10893855,
  author={Vyas, Piyush and Vyas, Gitika},
  journal={IT Professional}, 
  title={Generative Artificial Intelligence: Current Trends, Issues, and Challenges}, 
  year={2025},
  volume={27},
  number={1},
  pages={20-26},
  abstract={This article explores the landscape of generative artificial intelligence (GAI), aiming to elucidate the current discourse, trends, and challenges. Given the scarcity of literature, the study undertakes a literature search, conducting a thorough examination to compile relevant information. By shedding light on GAI’s current trends, issues, and challenges, this work underscores the requirement of comprehending the intricacies of GAI for its ethical and appropriate deployment across diverse sectors. This study reveals the urgency for further research, emphasizing the need for in-depth investigations to facilitate the development of the next generation of GAI models. More exploration is needed to ensure the responsible and ethical realization of GAI’s full potential in shaping societal landscapes. Moreover, explainability, security, intellectual property, data privacy, finance, and ethics are crucial issues associated with GAI.},
  keywords={Ethics;Data privacy;Generative AI;Finance;Intellectual property;Market research;Security;Next generation networking;Market research;Intellectual property;Social factors},
  doi={10.1109/MITP.2024.3516058},
  ISSN={1941-045X},
  month={Jan},}@INPROCEEDINGS{10968966,
  author={Kaur, Parneet and Gupta, Deepali and Uppal, Mudita},
  booktitle={2025 10th International Conference on Signal Processing and Communication (ICSC)}, 
  title={Generative AI Meets IoT: A Bibliometric Mapping of Research and Development}, 
  year={2025},
  volume={},
  number={},
  pages={434-439},
  abstract={Computer technology has transformed the way people interact online within society. The integration of (GIoT) combines Artificial Intelligence (AI) and Internet of Things (IoT) technology, offering numerous benefits in many fields for innovation and growth. GIoT helps with real-time applications for data prediction and alerts. Based on the authors' understanding and searches in scholarly databases, less bibliometric analysis has yet been performed on Generative Artificial Intelligence (GAI) for the IoT, even though such analyses are crucial for research development in this field. This study conducted a thorough bibliometric examination of GAI applications in the IoT over the period from 2014 to 2024. The analysis is based on a dataset of 296 documents sourced from the Scopus database. The bibliometric review was conducted using the Biblioshiny application, a tool available within the Bibliometric package in the R programming language. Top literature sources, major fields of study, nations, well-known authors, popular subjects, authorship, citations, author-keywords, and co-keywords were all subjected to bibliometric analysis.},
  keywords={Technological innovation;Computer languages;Generative AI;Databases;Reviews;Bibliometrics;Signal processing;Real-time systems;Internet of Things;Research and development;Generative Artificial Intelligence;Generative Internet of Things;bibliometric analysis},
  doi={10.1109/ICSC64553.2025.10968966},
  ISSN={2643-444X},
  month={Feb},}@INBOOK{10676369,
  author={Daim, Tugrul U. and Zamani, Mehdi and Naeini, Ali B. and Alsoubaie, Fayez and Zhang, Hao and Yal&#xe7;&#x131;n, Haydar},
  booktitle={Future-Oriented Technology Assessment: A Manager's Guide with Case Applications}, 
  title={Technology Intelligence: Geothermal Energy}, 
  year={2025},
  volume={},
  number={},
  pages={151-220},
  abstract={Summary <p>The increasing demand of power energy need for sustainable energy sources has made geothermal energy a viable substitute. However, the creation of novel technologies is necessary for the efficient use of geothermal energy. In this study, therefore, it is essential to determine the current level of technology in this area and to examine the patterns and trends in technological development. The methodology used to go through patent data analysis, The research goal was to provide a comprehensive overview of geothermal energy technology currently available, as well as its future prospects.</p> <p>This study provides a novel method of mapping technology related to geothermal energy through the examination of patent data by implementing a generative probabilistic model of text mining such as Latent Dirichlet Allocation (LDA) and social network analysis to identify significant technology clusters and trace their evolutionary history. Analyzing cutting&#x2010;edge topics that could push further advancements in geothermal energy technologies demonstrated the technology's unique position in the current context.</p> <p>The results also demonstrated how crucial it is to maintain these critical topics in order to support long&#x2010;term technological advancement. Geothermal energy technology decision&#x2010;makers can benefit from the information provided in this report to guide their strategic planning and investments.</p>},
  keywords={Heating systems;Earth;Geothermal energy;Thermodynamics;Springs;Resistance heating;Electricity},
  doi={10.1002/9781119909880.ch7},
  ISSN={},
  publisher={IEEE},
  isbn={9781119909866},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10676369},}@INBOOK{10834092,
  author={Iqbal, Mohammed Ismail and Kaushik, Priyanka},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Deep Learning for Disease Detection &#x2014; A Deep Dive into Deep Learning Techniques Such as Convolutional Neural Networks (CNNs) and Their Use in Disease Detection}, 
  year={2025},
  volume={},
  number={},
  pages={99-122},
  abstract={Summary <p>The mixing of superior deep learning strategies has deeply affected the sector of disease identification, promising sizeable advancements in diagnostic accuracy and performance. This chapter explores the utilization of multiscale convolutional layers, interest mechanisms, switch learning, generative adverse networks (GANs), and self&#x2010;supervised learning in the healthcare domain. These techniques collectively beautify the capability of convolutional neural networks (CNNs) to discover and diagnose diseases from medical pix with extraordinary precision. Multiscale convolutional layers allow the models to capture features at numerous scales, improving the sensitivity and specificity of ailment detection, mainly in situations like most cancers. Attention mechanisms similarly refine this process by allowing models to focus on the most applicable components of an image, mirroring the meticulous examination by human professionals.</p> <p>The chapter discusses deep learning, leveraging pre&#x2010;educated models, which extensively reduces the reliance on tremendous, categorized datasets, thereby expediting the development process and enhancing version accuracy. This approach has shown outstanding success throughout distinctive imaging modalities, from X&#x2010;rays to CT scans, improving the adaptability and robustness of diagnostic models. GANs contribute via producing artificial records to augment schooling datasets, addressing the challenge of limited data availability and enhancing model performance, specifically in uncommon disease scenarios. Self&#x2010;supervised learning, which trains models on unlabeled records via proxy duties, has demonstrated comparable performance to absolutely supervised models while requiring fewer categorized samples, therefore lowering the need for luxurious and time&#x2010;eating data annotation.</p> <p>Innovations in these areas have not only enhanced the technical performance of disease detection models but also expanded their potential applications. Future studies instructions consist of the exploration of multimodal learning, which mixes data from various assets including genomic information and digital health data, imparting a more complete diagnostic perspective. The implementation of federated learning guarantees data privacy while enhancing version training via decentralized records assets. Explainable AI (XAI) techniques enhance version interpretability, fostering more consideration and popularity amongst healthcare professionals. Moreover, the integration of AI with wearable devices for continuous fitness tracking, and the improvement of real&#x2010;time adaptive knowledge of models, hold tremendous promise for revolutionizing patient care and disease control.</p> <p>This comprehensive method to leveraging superior deep learning methodologies in disorder identification underscores the transformative potential of AI in healthcare. With the aid of addressing modern&#x2010;day demanding situations and exploring progressive answers, we can pave the way for greater accurate, efficient, and personalized diagnostic systems, in the end enhancing patient outcomes by using advanced AI and deep learning to enhance diagnostic accuracy, treatment efficiency, and patient outcomes, ultimately setting a new benchmark for best practices in healthcare.</p>},
  keywords={Diseases;Medical diagnostic imaging;Deep learning;Accuracy;Data models;Transfer learning;Training;Magnetic resonance imaging;Explainable AI;Data augmentation},
  doi={10.1002/9781394278695.ch5},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10834092},}@ARTICLE{10838616,
  author={},
  journal={IEEE Transactions on Artificial Intelligence}, 
  title={Consistency-Heterogenity Balanced Fake News Detection via Cross-modal Matching}, 
  year={2025},
  volume={},
  number={},
  pages={1-10},
  abstract={Generating synthetic content through Generative AI (GAI) presents considerable hurdles for current fake news detection methodologies. Many existing detection approaches concentrate on feature-based multi-modal fusion, neglecting semantic relationships such as correlations and diversities. In this study, we introduce an innovative cross-modal matching-driven approach to reconcile semantic relevance (text-image consistency) and semantic gap (text-image heterogeneity) in multimodal fake news detection. Unlike the conventional paradigm of multi-modal fusion followed by detection, our approach integrates textual modality, visual modality (images), and text embedded within images (auxiliary modality) to construct an end-to-end framework. This framework considers the relevance of contents across different modalities while simultaneously addressing the gap in structures, achieving a delicate balance between consistency and heterogeneity. Consistency is fostered by evaluating inter-modality correlation via pairwise-similarity scores, while heterogeneity is addressed by employing cross-attention mechanisms to account for inter-modality diversity. To achieve equilibrium between consistency and heterogeneity, we employ attention-guided enhanced modality interaction and similarity-based dynamic weight assignment to establish robust frameworks. Comparative experiments conducted on the Chinese Weibo dataset and the English Twitter dataset demonstrate the effectiveness of our approach, surpassing the state-of-the-art by 7% to 13%.},
  keywords={Feature extraction;Fake news;Semantics;Visualization;Correlation;Social networking (online);Artificial intelligence;Blogs;Data mining;Accuracy;multimodal fake news detection;cross-modal matching;text-image consistency;text-image heterogentiy},
  doi={10.1109/TAI.2025.3527921},
  ISSN={2691-4581},
  month={},}@INPROCEEDINGS{11016553,
  author={Browning, Jonathan W. and McKeever, Stephen and Ferrario, Maria Angela and O'Neill, Ian and Stewart, Darryl},
  booktitle={2025 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Creating Sustainable Solutions: An Inclusive Hackathon Leveraging GenAI in a Local Context}, 
  year={2025},
  volume={},
  number={},
  pages={1-7},
  abstract={This paper presents the design and implementation of a two-week hackathon at a large prestigious UK university, focused on creating sustainable solutions leveraging generative artificial intelligence (genAI). The hackathon deviated from the traditional one to three-day format, providing an extended period for ideation, development, and public voting. The event aimed to foster innovation, engage the local community in sustainability efforts, and augment participants' problem-solving capabilities through the use of genAI. The hackathon incorporated inclusivity measures based on evidence-based recommendations, ensuring diverse participation and a supportive environment. The participants could choose from four challenges to create a solution around that were based on local sustainability issues: housing regeneration, promoting sustainable and active travel, revitalizing the city center, and increasing re-naturing within the city. Teams were formed using a mix of self-selection and pre-assignment. Participants had access to comprehensive resources, including workshops on jupyter notebooks, genAI, video creation, and support from mentors. The final outputs each team was expected to produce was a 90 second video that detailed the challenge, their proposed solution, how they used open data, how they used genAI either in their solution or in their work process, as well as any files required for their solution to run/compile. The video was also to be used for the public vote, to decide the people's choice award, and hence could be promotional in nature but everyone in the team had to contribute to it in a meaningful way. Thus, they do not have to appear in it but could write a script or edit, etc. Judging criteria focused on the quality of the presentation, creativity, effective use of open data, and engagement with genAI. The event concluded with awards for the most polished solution, most creative idea, best use of open data, best use of genAI, best overall, and a people's choice award decided by a public vote. This paper contributes to the body of knowledge on leveraging genAI for sustainability and offers insights into develoning inclusive and impactful hackathons.},
  keywords={Technological innovation;Generative AI;Urban areas;Particle measurements;Teamwork;Problem-solving;Sustainable development;Hackathon;Open data;Creativity;generative AI;hackathon;innovation;student engagement;sustainability},
  doi={10.1109/EDUCON62633.2025.11016553},
  ISSN={2165-9567},
  month={April},}@INBOOK{10834125,
  author={Verma, Nikhil and Sharma, Tripti and Kaur, Bobbinpreet},
  booktitle={AI in Disease Detection: Advancements and Applications}, 
  title={Explanation of Machine Learning Algorithms Used in Disease Detection, Such as Decision Trees and Neural Networks}, 
  year={2025},
  volume={},
  number={},
  pages={27-52},
  abstract={Summary <p>Machine learning (ML) as a tool in disease diagnosis has come of age. However, in voluminous medical data, outclasses in analysis for digging out hidden patterns helpful for early detection. Current methodologies are effective, notwithstanding their limitations. This chapter thus presents a new approach &#x2013; a &#x201c;symphony of innovation&#x201d; &#x2013; by redefining disease detection to integrate the established methods with truly groundbreaking advancements systematically.</p> <p>This symphony goes beyond established, well&#x2010;rehearsed routines of current ML practices. It introduces AI orchestration as a new conductor that would work in harmony with all other components involved in the disease detection workflow and adapt to the workflow. Picture a network of hospitals, each equipped with patient data as if playing a concert together. Federated learning is a way to train ML models on this &#x201c;decentralized data,&#x201d; unlocking its power for improved disease detection, especially in the case of rare or geographically isolated cases, while protecting patient privacy in the process &#x2013; just like each hospital keeping its sheet music confidential. Another innovation in this symphony is active learning. Traditionally, training ML models require massive amounts of meticulously labeled data. Active learning algorithms act as a discerning conductor that identifies the most informative data points, reducing the need for manual labeling. This reduces not only the workload for medical professionals but also enables more efficient and targeted data collection.</p> <p>Static models can become useless with a changing healthcare environment and patient populations. This symphony is introducing algorithms of continuous learning. These algorithms function much like an adaptable maestro, continuously ingesting new data streams and dynamically refining their predictions to provide perpetual improvement in disease detection accuracy from day one &#x2013; to keep up with the evolving landscape in healthcare.</p> <p>Generative adversarial networks will elevate the level of innovation further. Now, imagine having to compose a host of entirely new musical pieces &#x2013; all those that would enhance the repertoire of an orchestra. GANs are capable of generating synthetic, false, anonymous patient data. In this way, researchers can train ML models on more extensive and more diverse datasets without being faced with questions about privacy, which is very useful in case of rare diseases with minimal real&#x2010;world data.</p> <p>This symphony of innovation, however, does not end with technological progress but is also reflected in the harmonious concurrence of man's brain and machine expertise.</p> <p>XAI techniques focused on the medical domain will turn out to be critical. As a model, such techniques are bound to provide transparent and interpretable explanations for their predictions, engendering trust and acceptance among medical professionals. Picture a program accompanying a complex musical piece that lets an audience &#x2013; here, doctors &#x2013; understand the intricacies of the performance. AI&#x2010;empowered clinical decision support systems are real&#x2010;time companions for a doctor in arriving at a diagnosis and instituting treatment. They study patient data, offer possible diagnoses, and suggest treatment options. Picture an AI assistant that can provide insights in real&#x2010;time and help doctors make more learned decisions about the clinical history of their patients. The ultimate goal of this symphony is personalized medicine. Armed with a patient's case history, genomic data, and data related to lifestyle habits, AI can predict their individual disease risk and hence help in the formulation of targeted interventions. Proactive healthcare &#x2013; prevention before manifestation of the actual disease &#x2013; is within reach.</p> <p>This vision in disease detection goes beyond the conventionally adopted methods in disease detection. With AI orchestration, human&#x2010;machine collaboration, and ethical concerns, we can unleash the promise of healthcare with very early diagnoses and a treatment regime that makes a difference &#x2013; leading to a genuinely healthful future for all. Such a symphony of innovation is taking to the streets and on course to rewrite the score relating to disease detection; every advancement within its repertoire seems to act as a note of hope in this fight for global health.</p>},
  keywords={Diseases;Medical diagnostic imaging;Medical services;Technological innovation;Predictive models;Accuracy;Prediction algorithms;Heuristic algorithms;Feature extraction;Decision trees},
  doi={10.1002/9781394278695.ch2},
  ISSN={},
  publisher={IEEE},
  isbn={9781394278688},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10834125},}@ARTICLE{10130818,
  author={Cortiñas-Lorenzo, Karina and Lacey, Gerard},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={Toward Explainable Affective Computing: A Review}, 
  year={2024},
  volume={35},
  number={10},
  pages={13101-13121},
  abstract={Affective computing has an unprecedented potential to change the way humans interact with technology. While the last decades have witnessed vast progress in the field, multimodal affective computing systems are generally black box by design. As affective systems start to be deployed in real-world scenarios, such as education or healthcare, a shift of focus toward improved transparency and interpretability is needed. In this context, how do we explain the output of affective computing models? and how to do so without limiting predictive performance? In this article, we review affective computing work from an explainable AI (XAI) perspective, collecting and synthesizing relevant papers into three major XAI approaches: premodel (applied before training), in-model (applied during training), and postmodel (applied after training). We present and discuss the most fundamental challenges in the field, namely, how to relate explanations back to multimodal and time-dependent data, how to integrate context and inductive biases into explanations using mechanisms such as attention, generative modeling, or graph-based methods, and how to capture intramodal and cross-modal interactions in post hoc explanations. While explainable affective computing is still nascent, existing methods are promising, contributing not only toward improved transparency but, in many cases, surpassing state-of-the-art results. Based on these findings, we explore directions for future research and discuss the importance of data-driven XAI and explanation goals, and explainee needs definition, as well as causability or the extent to which a given method leads to human understanding.},
  keywords={Affective computing;Training;Data models;Computational modeling;Task analysis;Terminology;Predictive models;Affective computing;explainable AI (XAI);multimodal machine learning;review},
  doi={10.1109/TNNLS.2023.3270027},
  ISSN={2162-2388},
  month={Oct},}@ARTICLE{10839294,
  author={Yang, Bolin and Deng, Jie and Liang, Xiaoxuan and Chen, Zhenghan and Wu, Ruoxue},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={DOGMH: A Diffusion and Optimization Approach for Generative Molecular Health Informatics in Consumer Electronics}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={This is a task of computational chemistry and pharmaceutical development, with rapidly growing relevance for consumer healthcare electronics: deducing three-dimensional molecular structures from two-dimensional diagrams. In this paper, we introduce a new generative model, DOGMH, specifically tailored for applications on consumer electronic devices, which considerably increases the accuracy in this process. DOGMH borrows from the diffusion mechanisms of classical nonequilibrium thermodynamics and treats atoms as individual particles, excelling in the inversion of the diffusion process-turning noise into organized molecular structures. Our approach leverages a specially tailored bilevel optimization technique that ensures roto-translational invariance and allows for efficient processing on resource-constrained consumer devices. We show that DOGMH outperforms existing methods in terms of both conformational synthesis and distance distribution accuracy. DOGMH also provides the ability to create AI-enabled interactive 3D visualizations of molecular structures for consumer health education. Our work paves the way for advanced molecular informatics capabilities in consumer-grade devices and will potentially revolutionize personal healthcare management through AI-enhanced insights. By bridging the gap between complex molecular modeling and consumer electronics, DOGMH will open up a new frontier in intelligent, molecularly aware health devices accessible to the general public.},
  keywords={Computational modeling;Accuracy;Optimization;Proteins;Noise;Consumer electronics;Training;Three-dimensional displays;Medical services;Predictive models;Molecular structure prediction;Consumer healthcare electronics;AI-generated content;Edge computing},
  doi={10.1109/TCE.2025.3528966},
  ISSN={1558-4127},
  month={},}@INPROCEEDINGS{9882932,
  author={Rivera, Miguel Angel Bello and Flores, Perfecto Malaquías Quintero and Loaiza, Rodolfo Eleazar Pérez and Rivera, Leticia Gómez},
  booktitle={2022 IEEE Mexican International Conference on Computer Science (ENC)}, 
  title={Analysis of Audio Signals Using Deep Learning Algorithms Applied to COVID Diagnostic Systems}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={In recent years the application of deep learning algorithms in the subdomain of audio analysis has grown rapidly, however it is a topic that can be complex for students and researchers who have a first approach and want to develop an application in this field. The use of deep learning techniques applied to audio signals has allowed the development of a wide variety of useful tools in our daily lives, from virtual assistants to medical applications. This article presents a literature review of the main techniques that have been used in recent years for analysis, feature extraction and classification from audio spectra or spectrograms, as well as examples of application in the context of the COVID-19 pandemic in which multiple related projects have emerged, such as diagnostic systems. The techniques addressed are recurrent neural networks (RNN), convolutional neural networks (CNN) and generative adversarial networks (GAN). It is intended that the reader will be able to acquire this knowledge from a simple perspective and that this information will be useful in their research or development.},
  keywords={Silicon;Deep learning;Convolutional neural networks;Computer science;COVID-19;Visualization;Recurrent neural networks},
  doi={10.1109/ENC56672.2022.9882932},
  ISSN={2332-5712},
  month={Aug},}@INPROCEEDINGS{10569447,
  author={Haramina, Emilia and Paladin, Mateo and Petričušić, Zdravko and Posarić, Fran and Drobnjak, Antun and Botički, Ivica},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={Learning Algorithms Concepts in a Virtual Reality Escape Room}, 
  year={2024},
  volume={},
  number={},
  pages={2057-2062},
  abstract={Although the standard way to learn algorithms is by coding, learning through games is another way to obtain knowledge while having fun. Virtual reality is a computer-generated three-dimensional environment in which the player is fully immersed by having external stimuli mostly blocked out. In the game presented in this paper, players are enhancing their algorithms skills by playing an escape room game. The goal is to complete the room within the designated time by solving puzzles. The puzzles change for every playthrough with the use of generative artificial intelligence to provide every player with a unique experience. There are multiple types of puzzles such as. time complexity, sorting algorithms, searching algorithms, and code execution. The paper presents the results of a study indicating students’ preference for learning through gaming as a method of acquiring algorithms knowledge.},
  keywords={Codes;Generative AI;Virtual environments;External stimuli;Games;Learning (artificial intelligence);Encoding;learning;education;extended reality;virtual reality;generative artificial intelligence;escape room;puzzles;user testing;user experience;user study},
  doi={10.1109/MIPRO60963.2024.10569447},
  ISSN={2623-8764},
  month={May},}@INBOOK{10529827,
  author={},
  booktitle={Smart Edge Computing: An Operation Research Perspective}, 
  title={Edge Computing with Operations Research Using IoT Devices in Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={65-95},
  abstract={Summary <p>This chapter gives a systematic review of the reputation of edge computing in healthcare. It discusses the systematic review of artificial intelligence (AI) techniques used in the edge healthcare system. Three sections of AI, namely machine learning, deep learning and the generative adversarial network, focus on providing detailed descriptions. The chapter describes the rise of smartphone&#x2010;based healthcare technology and discusses the classification of mobile device applications according to their functionalities. The medical calculator, drug discovery, disease treatment and diagnosis are the most used applications by nursing students, healthcare professionals and medical advisors. IoT collects information from the user through sensors in devices and smartphones. The Cloud helps to store those data quickly and efficiently. Medical practitioners use these technologies to provide a modernized and effective treatment, keeping people updated about their health information for healthy living.</p>},
  keywords={Medical services;Edge computing;Internet of Things;Operations research;Servers;Monitoring;Cloud computing},
  doi={10.1002/9781394277599.ch4},
  ISSN={},
  publisher={Wiley},
  isbn={9781394277575},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10529827},}@ARTICLE{9925159,
  author={Albuquerque Filho, José Edson De and Brandão, Laislla C. P. and Fernandes, Bruno José Torres and Maciel, Alexandre M. A.},
  journal={IEEE Access}, 
  title={A Review of Neural Networks for Anomaly Detection}, 
  year={2022},
  volume={10},
  number={},
  pages={112342-112367},
  abstract={Anomaly detection is a critical issue across several academic fields and real-world applications. Artificial neural networks have been proposed to detect anomalies from different input types, but there is no clear guide to deciding which model to use in a specific case. Therefore, this study examines the most relevant Neural Network Outlier Detection algorithms in the literature, compares their benefits and drawbacks in some application scenarios, and displays their outcomes in benchmark datasets. The initial search revealed 1422 papers on projects completed between 2017 and 2021. These papers were further narrowed based on title, abstract, quality assessment, inclusion, and exclusion criteria, remaining 76 articles. Finally, we reviewed these publications and verified that Autoencoder Neural Network, Convolutional Neural Network, Recurrent Neural Network, and Generative Adversarial Network have promisor outcomes for outlier detection, the advantages of these neural networks for outlier detection, and the significant challenges of outlier detection strategies.},
  keywords={Anomaly detection;Neural networks;Behavioral sciences;Protocols;Systematics;Machine learning;Quality assessment;Anomaly detection;neural networks;outlier detection;systematic review},
  doi={10.1109/ACCESS.2022.3216007},
  ISSN={2169-3536},
  month={},}@ARTICLE{10433498,
  author={Jamil, Azhar and Saif-Ur-Rehman and Mahmood, Khalid and Villar, Monica Gracia and Prola, Thomas and Diez, Isabel De La Torre and Samad, Md Abdus and Ashraf, Imran},
  journal={IEEE Access}, 
  title={Deep Learning Approaches for Image Captioning: Opportunities, Challenges and Future Potential}, 
  year={2024},
  volume={},
  number={},
  pages={1-1},
  abstract={Generative intelligence relies heavily on the integration of vision and language. Much of the research has focused on image captioning, which involves describing images with meaningful sentences. Typically, when generating sentences that describe the visual content, a language model and a vision encoder are commonly employed. Because of the incorporation of object areas, properties, multi-modal connections, attentive techniques, and early fusion approaches like bidirectional encoder representations from transformers (BERT), these components have experienced substantial advancements over the years. This research offers a reference to the body of literature, identifies emerging trends in an area that blends computer vision as well as natural language processing in order to maximize their complementary effects, and identifies the most significant technological improvements in architectures employed for image captioning. It also discusses various problem variants and open challenges. This comparison allows for an objective assessment of different techniques, architectures, and training strategies by identifying the most significant technical innovations, and offers valuable insights into the current landscape of image captioning research.},
  keywords={Visualization;Feature extraction;Convolutional neural networks;Context modeling;Task analysis;Surveys;Computational modeling;Deep learning;Artificial intelligence;Natural language processing;Image processing;Image capture;Image captioning;deep learning;image processing;artificial intelligence},
  doi={10.1109/ACCESS.2024.3365528},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10638598,
  author={Lambertenghi, Stefano Carlo and Stocco, Andrea},
  booktitle={2024 IEEE Conference on Software Testing, Verification and Validation (ICST)}, 
  title={Assessing Quality Metrics for Neural Reality Gap Input Mitigation in Autonomous Driving Testing}, 
  year={2024},
  volume={},
  number={},
  pages={173-184},
  abstract={Simulation-based testing of automated driving systems (ADS) is the industry standard, being a controlled, safe, and cost-effective alternative to real-world testing. Despite these advantages, virtual simulations often fail to accurately replicate real-world conditions like image fidelity, texture representation, and environmental accuracy. This can lead to significant differences in ADS behavior between simulated and real-world domains, a phenomenon known as the sim2real gap. Researchers have used Image-to-Image (I2I) neural translation to mitigate the sim2real gap, enhancing the realism of simulated environments by transforming synthetic data into more authentic representations of real-world conditions. However, while promising, these techniques may potentially introduce artifacts, distortions, or inconsistencies in the generated data that can affect the effectiveness of ADS testing. In our empirical study, we investigated how the quality of image-to-image (I2I) techniques influences the mitigation of the sim2real gap, using a set of established metrics from the literature. We evaluated two popular generative I2I architectures, pix2pix and CycleGAN, across two ADS perception tasks at a model level, namely vehicle detection and end-to-end lane keeping, using paired simulated and real-world datasets. Our findings reveal that the effectiveness of I2I architectures varies across different ADS tasks, and existing evaluation metrics do not consistently align with the ADS behavior. Thus, we conducted task-specific fine-tuning of perception metrics, which yielded a stronger correlation. Our findings indicate that a perception metric that incorporates semantic elements, tailored to each task, can facilitate selecting the most appropriate I2I technique for a reliable assessment of the sim2real gap mitigation.},
  keywords={Measurement;Software testing;Prevention and mitigation;Vehicle detection;Computer architecture;Software reliability;Task analysis;autonomous vehicles testing;generative adversarial networks;sim2real;reality gap},
  doi={10.1109/ICST60714.2024.00024},
  ISSN={2159-4848},
  month={May},}@INPROCEEDINGS{10489462,
  author={Dixit, Krishna Kant and Aswal, Upendra Singh and Saravanan, V. and Sararswat, Manishn and Shalini, N and Srivastava, Amit},
  booktitle={2023 International Conference on Artificial Intelligence for Innovations in Healthcare Industries (ICAIIHI)}, 
  title={Data Augmentation with Generative Adversarial Networks for Deep Learning in Healthcare}, 
  year={2023},
  volume={1},
  number={},
  pages={1-6},
  abstract={In order to overcome the difficulties caused by small datasets, this study investigates the combination of Generative Adversarial Networks (GANs) for healthcare information augmentation. Using a descriptive method with additional data gathering, we apply an approach based on a deductive and an interpretivist framework. The findings include a robustness test, a visual assessment, a comparative efficiency study, and an objective evaluation. Technical nuances and ethical implications are highlighted in our critical study. Suggestions support improving GAN structures, verifying robustness, and fostering responsible implementation. Subsequent research ought to concentrate on customized GANs for particular medical modalities, moral principles, and real-time therapeutic implementations.},
  keywords={Industries;Deep learning;Ethics;Visualization;Technological innovation;Medical services;Generative adversarial networks;deep learning;generative neural networks;healthcare;moral concerns},
  doi={10.1109/ICAIIHI57871.2023.10489462},
  ISSN={},
  month={Dec},}@ARTICLE{10508385,
  author={Ali Raza, Syed and Habib, Usman and Usman, Muhammad and Ashraf Cheema, Adeel and Sajid Khan, Muhammad},
  journal={IEEE Access}, 
  title={MMGANGuard: A Robust Approach for Detecting Fake Images Generated by GANs Using Multi-Model Techniques}, 
  year={2024},
  volume={12},
  number={},
  pages={104153-104164},
  abstract={Recent advances in Generative Adversarial Networks (GANs) have produced synthetic images with high visual fidelity, making them nearly indistinguishable from human-created images. These synthetic images referred to as deepfakes, have become a major source of misinformation due to social media. Technology is advancing rapidly, so reliable methods for distinguishing real from fake images are needed. The current detection mechanisms require image forensics tools such as error level analysis (ELA), and clone detection to detect manipulated images. These approaches are limited because they require forensics expertise to use, are manual in application nature, and are unscalable, creating a need for a framework for a scalable tool that experts and non-experts can use to combat the spread of manipulated images and preserve digital visual information authenticity. We approach this problem with a multi-model ensemble framework using the transfer learning method to effectively detect fake images. The proposed approach named Multi-Model GAN Guard (MMGANGuard)integrates four models into an ensemble framework to identify GAN-generated image characteristics to improve deepfake detection. The Gram-Net architecture, ResNet50V2, and DenseNet201 models are used with co-occurrence matrices using transfer learning for MMGANGuard. Through comprehensive experiments, the proposed model demonstrates promising results in detecting the deepfake with high accuracy on the StyleGAN dataset. For automated detection of deepfake-generated images, the proposed model exceeded 97% accuracy, 98.5% TPR, 98.4% TPR, and 95.6% TPR in these evaluations, eliminating the need for manual assessment which is promising for future research in this domain.},
  keywords={Deepfakes;Predictive models;Social networking (online);Neurons;Image coding;Computer architecture;Data analysis;Deep learning;Generative adversarial networks;Deep fake;data analytics;deep learning;GANs;StyleGAN;detection;multi-model},
  doi={10.1109/ACCESS.2024.3393842},
  ISSN={2169-3536},
  month={},}@ARTICLE{10347559,
  author={Feng, Kai and Cook, Marco M. and Marnerides, Angelos K.},
  journal={IEEE Transactions on Information Forensics and Security}, 
  title={Sizzler: Sequential Fuzzing in Ladder Diagrams for Vulnerability Detection and Discovery in Programmable Logic Controllers}, 
  year={2024},
  volume={19},
  number={},
  pages={1660-1671},
  abstract={Programmable Logic Controllers (PLCs) constitute the basis of Industrial Control Systems (ICSs) underpinning sectors ranging from nuclear, up to energy and manufacturing. Currently, PLC vulnerability assessment practices employed by ICS operators are limited due to their reliance on empirical observations of visible code crashes prompted by PLC compilers. In parallel, the prevalent PLC firmware dependency on proprietary vendor routines restricts the composition of generic vulnerability detection or discovery schemes for zero-day threat vectors. In this work, we propose Sizzler: a novel vendor-independent vulnerability discovery framework specific to PLC applications operating with logic realised through ladder diagrams. Sizzler extends the current state of the art by proposing the optimal synergy of a mutation-based fuzzing strategy using Sequential Generative Adversarial Network (SeqGAN). By virtue of critical vendor restrictions on emulating PLC firmware, we also refine the Quick Emulator (QEMU)’s General Purpose I/O (GPIO) and the Inter-Integrated Circuit (I2C) protocols to evaluate and compare Sizzler across 30 PLC ladder diagram programs compiled from LDmicro and OpenPLC projects over five widely used Micro-Controller Units (MCUs). It is noteworthy that Sizzler has successfully identified vulnerabilities in ladder diagrams within a relatively short time frame based on our proprietary dataset and secured a CVE-ID. Moreover, through a comparison of Sizzler with prevalent fuzzing techniques over the commonly used Magma and LAVA-M datasets we exhibit its wider applicability on embedded systems and identify its limitations.},
  keywords={Fuzzing;Codes;Microprogramming;Emulation;Integrated circuits;Hardware;Protocols;Industrial control systems;programmable logic controllers;fuzzing;vulnerability discovery},
  doi={10.1109/TIFS.2023.3340615},
  ISSN={1556-6021},
  month={},}@ARTICLE{11029979,
  author={Wang, Haiyan and Wang, Bingjie and Huang, Wenbo and Liu, Yibin and Du, Yu and Hung, Guang-Uei and Hu, Zhanli and Mok, Greta S. P.},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Deep-learning-based Partial Volume Correction in 99mTc-TRODAT-1 SPECT for Parkinson's Disease: A Preliminary Study on Clinical Translation}, 
  year={2025},
  volume={},
  number={},
  pages={1-12},
  abstract={99mTc-TRODAT-1 SPECT is effective for the early detection of Parkinson's disease (PD). However, SPECT images suffer from severe partial volume effect, which impairs tissue boundary clarity and subsequent quantification accuracy. This work proposes an anatomical prior- and segmentation-free deep learning (DL)-based partial volume correction (PVC) method using an attentionbased conditional generative adversarial network (Att-cGAN) for 99mTc-TRODAT-1 SPECT. A population of 454 digital brain phantoms modelling anatomical and 99mTc-TRODAT activity variations in different PD categories are used to generate realistic SPECT projections using the SIMIND Monte Carlo code, and then reconstructed using ordered subset expectation maximization algorithm. The dataset is split into 320, 44 and 90 used for training, validation, and testing. Att-cGAN, cGAN and U-Net are implemented based on simulated data, then directly tested on 100 retrospectively collected clinical 99mTc-TRODAT data, with same acquisition and reconstruction parameters as in simulations. Non-DL PVC methods of Van-Cittert and iterative Yang are implemented for comparison. Physical and clinical metrics, as well as a no-gold standard technique (NGST) are applied to evaluate different PVC methods in the absence of clinical ground truth. Att-cGAN yields superior PVC performance in simulations as compared to other methods in physical and clinical evaluations. NGST assessment is generally consistent with the clinical metric evaluation. For the clinical study, Att-cGAN also obtains better NGST result than others striatal compartments can be discriminated on DLbased processed images. DL-PVC method is feasible for clinical PD SPECT using highly realistic simulated data.},
  keywords={Single photon emission computed tomography;Image reconstruction;Data models;Training;Imaging phantoms;Image segmentation;Phantoms;Diseases;Artificial intelligence;Image resolution;Parkinson's disease;SPECT;partial volume correction;deep learning},
  doi={10.1109/JBHI.2025.3578526},
  ISSN={2168-2208},
  month={},}@ARTICLE{10807241,
  author={Zhang, Fan and Wang, Luyao and Zhang, Xinhong},
  journal={Big Data Mining and Analytics}, 
  title={Desensitized Financial Data Generation Based on Generative Adversarial Network and Differential Privacy}, 
  year={2025},
  volume={8},
  number={1},
  pages={103-117},
  abstract={Artificial intelligence has been widely used in the financial field, such as credit risk assessment, fraud detection, and stock prediction. Training deep learning models requires a significant amount of data, but financial data often contains sensitive information, some of which cannot be disclosed. Acquiring large amounts of financial data for training deep learning models is a pressing issue that needs to be addressed. This paper proposes a Noise Visibility Function-Differential Privacy Generative Adversarial Network (NVF-DPGAN) model, which generates privacy preserving data similar to the original data, and can be applied to data augmentation for deep learning. This study conducts experiments using financial data from China Stock Market & Accounting Research (CSMAR) database. It compares the generated data with real data from various perspectives, including mean, probability density distribution, and correlation. The experimental results show that the two datasets exhibit similar characteristics. A time series forecasting model is trained on the generated data and the real data separately, and their prediction results are closely aligned. NVF-DPGAN model is feasible and practical in terms of financial data enhancement and privacy protection. This method can also be generalized to other fields, such as the privacy protection of medical data.},
  keywords={Deep learning;Training;Differential privacy;Noise;Data enhancement;Time series analysis;Generative adversarial networks;Data models;Protection;Stock markets;data desensitization;Generative Adversarial Network (GAN);differential privacy;noise visibility function},
  doi={10.26599/BDMA.2024.9020047},
  ISSN={2097-406X},
  month={February},}@INPROCEEDINGS{10546023,
  author={Mohseni, Milad and Thilagham, K T and K, Aravinda and Kumar, B Santhosh and Nagpal, Amandeep and Geetha, B. T.},
  booktitle={2024 IEEE 13th International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={Deep Learning Applications in Microscopy and Holography for near-field Signal Processing}, 
  year={2024},
  volume={},
  number={},
  pages={612-618},
  abstract={Focusing on near-field signal processing, we provide a novel and comprehensive strategy for improving picture quality, obtaining super-resolution, and performing quantitative analysis in the disciplines of microscopy and holography. Three deep learning algorithms—Enhanced ImageNet (EINet), HoloReconGAN, and QuantSegNet—are combined in this method to maximize their potential. In order to improve images, super-resolve them, and analyze them quantitatively, many algorithms have been developed. In order to better comprehend each method, mathematical equations are provided to describe the main steps involved. With the use of convolutional neural networks, noise is reduced and finer features are brought into focus with the help of the Enhanced ImageNet (EINet) method. To accomplish super-resolution and 3D reconstruction from holographic data, HoloReconGAN combines generative adversarial networks (GANs) with variational autoencoders (VAEs). Label-free segmentation and quantitative analysis of structures in microscopy and holography pictures are the focus of QuantSegNet, a semantic segmentation network. Our suggested technique has been shown to outperform six established methods over a broad variety of assessment criteria. Image quality, noise suppression, feature recognition, computational efficiency, and resilience are just few of the areas where it shines. It's also faster, uses less memory, is more accurate, easier to use, cheaper, and faster. Applications in several scientific fields might be facilitated, and the area of microscopy and holography as a whole could see significant advancements as a result.},
  keywords={Deep learning;Technological innovation;Three-dimensional displays;Statistical analysis;Microscopy;Superresolution;Noise reduction;3D reconstruction;deep learning;holography;image enhancement;image quality;microscopy;near-field signal processing;quantitative analysis;super-resolution;label-free segmentation;robustness;computational efficiency;memory efficiency;accuracy},
  doi={10.1109/CSNT60213.2024.10546023},
  ISSN={2473-5655},
  month={April},}@INBOOK{10494663,
  author={Kaushik, Keshav},
  booktitle={Applying Artificial Intelligence in Cybersecurity Analytics and Cyber Threat Detection}, 
  title={Leveraging Deep Learning Techniques for Securing the Internet of Things in the Age of Big Data}, 
  year={2024},
  volume={},
  number={},
  pages={311-325},
  abstract={There is a growing need for adequate procedures to make sure that smart devices are resistant to different threats and assaults on the <term definitionRef="#c15-tdef-0001" type="abbreviation" xml:id="c15-term-0001">Internet of Things</term> (<termDefinition xml:id="c15-tdef-0001">IoT</termDefinition>) ecosystem as they continue to permeate many facets of our everyday lives. <term definitionRef="#c15-tdef-0002" type="abbreviation" xml:id="c15-term-0002">Deep learning</term> (<termDefinition xml:id="c15-tdef-0002">DL</termDefinition>) is proving to be one of the most effective and practical approaches in this area for addressing various IoT security issues. The massive increase in IoT device numbers makes them the primary source of data. Big data is being generated in enormous quantities via IoT. Big data analytics are used to harness the enormous volume of data and turn it into useful insights to maximize IoT's effectiveness. This elevates the IoT above simple monitoring equipment. IoT and big data combine nicely to provide analysis and insights. Big data analytics pushes the computer architecture to the margins for real&#x2010;time decision making because of the IoT.The chapter discusses the application of DL techniques for addressing the security challenges on the IoT systems. IoT security is a complex and challenging field, where the amount of data is constantly increasing, and traditional security approaches may not be sufficient. DL approaches have emerged as a promising tool for addressing these challenges. The author provides an overview of various DL techniques, such as anomaly detection, intrusion detection, malware detection, botnet detection, attack attribution, vulnerability assessment, and privacy&#x2010;preserving techniques. Convolutional neural networks, recurrent neural networks, autoencoders, and generative adversarial networks are just a few examples of DL architectures that are discussed in the author's discussion on the importance of DL in IoT security. Furthermore, the author discusses the big data challenges in IoT security and how DL can help address those challenges. Finally, the author discusses the future scope of DL in IoT security and the promising areas where DL can make significant contributions to ensuring the security and integrity of IoT systems.},
  keywords={Internet of Things;Security;Big Data;Organizations;Real-time systems;Memory;Recurrent neural networks},
  doi={10.1002/9781394196470.ch15},
  ISSN={},
  publisher={Wiley},
  isbn={9781394196456},
  url={https://ieeexplore-ieee-org.focus.lib.kth.se/document/10494663},}@INPROCEEDINGS{10883930,
  author={Jain, Alok and William, P. and Ayasrah, Firas Tayseer and Lakshmi, G. Prasanna and Diwan, Tarun Dhar},
  booktitle={2024 11th International Conference on Software Defined Systems (SDS)}, 
  title={Analyzing Automatic Code Generation for Learning Models in Generative AI}, 
  year={2024},
  volume={},
  number={},
  pages={50-58},
  abstract={Independent code generation models produced by generative AI provide a new way to software development. These models automatically generate code using machine learning based on input samples. This study examines the fundamentals, applications, problems, and future prospects of AI-related automated code generation technologies. Model-based software, domain-specific code, and testing procedures are examples of these research topics. Performance analysis and assessment are used to assess the efficacy, efficiency, and reliability of several automated code generating methods. The fact that these models have pros and cons and room for development is highlighted.},
  keywords={Analytical models;Codes;Generative AI;Training data;Software;Software reliability;Performance analysis;Research and development;Software development management;Testing;Automatic code generation;Generative AI;machine learning;software development;testing methodologies;model-based development;domain-specific code generation},
  doi={10.1109/SDS64317.2024.10883930},
  ISSN={},
  month={Dec},}@ARTICLE{11015914,
  author={Wang, Yihao and Zhang, Yu and Qiao, Dewen and Guo, Songtao and Liu, Yu and Zhao, Chenhao and Gu, Tao and Ding, Qiaoqiao and Zhang, Xiaoqun and Chen, Xuetao},
  journal={IEEE Internet of Things Journal}, 
  title={EESyn-CTP: Edge-End Collaboration for Patient-Friendly CTP Image Synthesis}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={In the field of medical imaging driven by the Internet of Things (IoT), with the rapid growth of the number of medical devices and the widespread application of edge computing (EC) technology, efficient collaborative computing on resource-constrained end medical devices has become the key to improving diagnostic efficiency, thereby bringing a more patient-friendly diagnosis and treatment experience. Computed tomography perfusion (CTP) images play an irreplaceable role in the assessment of brain tissue ischemia in patients with acute ischemic stroke (AIS), with high diagnostic accuracy in identifying ischemic lesions and distinguishing infarction from penumbra, but it has the disadvantages of high radiation dose and high cost. To this end, we propose a CTP image synthesis framework based on edge-end collaboration (EESyn-CTP), which aims to use non-contrast CT (NCCT), CT angiography (CTA), and delayed CTA (CTA+8s) images to synthesize CTP images with arbitrary time to optimize AIS diagnosis. The framework consists of two stages: the pre-training stage on the edge server and the fine-tuning stage on the end device. Specifically, we first deploy a temporal residual generative network, t-UNet, on the edge server for pre-training. This process utilizes multiple CTP images, which share similar perfusion features with CTA, CTA+8s, and NCCT images, to effectively learn the gap in perfusion information between the inputs and outputs. Subsequently, the pre-trained t-UNet model parameters are frozen and broadcast to the edge medical device. A UNet adapter is introduced before the model, and fine-tuning is performed on the adapter weights using real NCCT, CTA, and CTA+8s images as input. This approach facilitates the synthesis of CTP images at arbitrary time points. Finally, experiments on an internal data set showed that the quality of Syn-CTP images synthesized by the EESyn-CTP framework is comparable to that of real CTP images and significantly reduces computation latency and energy overhead.},
  keywords={Image edge detection;Artificial intelligence;Biomedical imaging;Computed tomography;Collaboration;Accuracy;Optimization;Medical diagnostic imaging;Internet of Things;Image synthesis;Internet of Things;edge computing;computed tomography perfusion;acute ischemic stroke;CT angiography},
  doi={10.1109/JIOT.2025.3573756},
  ISSN={2327-4662},
  month={},}@ARTICLE{10789626,
  author={Rodrigues Perche Mahlow, Felipe and Zanella, André Felipe and Cruz Castañeda, William Alberto and Aparecida Sarzi-Ribeiro, Regilene},
  journal={IEEE Latin America Transactions}, 
  title={Illustrating Classic Brazilian Books using a Text-To-Image Diffusion Model}, 
  year={2024},
  volume={22},
  number={12},
  pages={1000-1008},
  abstract={In recent years, Generative Artificial Intelligence (GenAI) has undergone a profound transformation in addressing intricate tasks involving diverse modalities such as textual, auditory, visual, and pictorial generation. Within this spectrum, text-to-image (TTI) models have emerged as a formidable approach to generating varied and aesthetically appealing compositions, spanning applications from artistic creation to realistic facial synthesis, and demonstrating significant advancements in computer vision, image processing, and multimodal tasks. The advent of Latent Diffusion Models (LDMs) signifies a paradigm shift in the domain of AI capabilities. This article delves into the feasibility of employing the Stable Diffusion LDM to illustrate literary works. For this exploration, seven classic Brazilian books have been selected as case studies. The objective is to ascertain the practicality of this endeavor and to evaluate the potential of Stable Diffusion in producing illustrations that augment and enrich the reader's experience. We will outline the beneficial aspects, such as the capacity to generate distinctive and contextually pertinent images, as well as the drawbacks, including any shortcomings in faithfully capturing the essence of intricate literary depictions. Through this study, we aim to provide a comprehensive assessment of the viability and efficacy of utilizing AI-generated illustrations in literary contexts, elucidating both the prospects and challenges encountered in this pioneering application of technology.},
  keywords={Artificial intelligence;Image synthesis;Diffusion models;Training;Visualization;Text to image;Noise reduction;Computational modeling;Refining;Ethics;image generation;diffusion models;text-to-image;illustration},
  doi={10.1109/TLA.2024.10789626},
  ISSN={1548-0992},
  month={Dec},}@ARTICLE{9965611,
  author={Zhu, Ziye and Tong, Hanghang and Wang, Yu and Li, Yun},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={BL-GAN: Semi-Supervised Bug Localization via Generative Adversarial Network}, 
  year={2023},
  volume={35},
  number={11},
  pages={11112-11125},
  abstract={Various automated bug localization technologies have recently emerged that require adequate bug-fix records available to train a predictive model. However, many projects in practice might not provide these necessities, especially for new projects in the first release, due to the expensive human effort for constructing a large amount of bug-fix records. Aiming to capture the potential relevance distribution between the bug report and code file from a limited number of available bug-fix records, we present the first semi-supervised bug localization model named BL-GAN in this paper. For this purpose, the promising Generative Adversarial Network is introduced in BL-GAN, in which synthetic bug-fix records close to the real ones are constructed by searching the project directory tree to generate file paths instead of traversing the contents of all code files. For processing bug reports, the proposed BL-GAN adopts an attention-based Transformer architecture to capture semantic and sequence information. In order to capture the proprietary structural information in code files, BL-GAN incorporates a novel multilayer Graph Convolutional Network to process the source code in a graphical view. Extensive experiments on large-scale real-world datasets reveal that our model BL-GAN significantly outperforms the state-of-the-art on all evaluation measures.},
  keywords={Computer bugs;Codes;Location awareness;Generative adversarial networks;Generators;Task analysis;Feature extraction;Bug localization;bug report;semi-supervised learning;generative adversarial network},
  doi={10.1109/TKDE.2022.3225329},
  ISSN={1558-2191},
  month={Nov},}@ARTICLE{10290887,
  author={Makris, Nikolaos and Mitrou, Nikolaos},
  journal={IEEE Access}, 
  title={Multisubject Analysis and Classification of Books and Book Collections, Based on a Subject Term Vocabulary and the Latent Dirichlet Allocation}, 
  year={2023},
  volume={11},
  number={},
  pages={120881-120898},
  abstract={In this paper, a new method for automatically analyzing and classifying books and book collections according to the subjects they cover is presented. It is based on a combination of the LDA method for discovering latent topics in the collection, on the one hand, and the description of subjects by means of a subject term vocabulary, on the other. Books, topics and subjects, all are modelled as bag-of-words, with specific distributions over the underlying word vocabulary. The Table of Contents (ToC) was used to describe the books, instead of their entire body, while subject (or standard) documents are produced by a subject term hierarchy of the respective disciplines. Frequency-of-terms in the documents and word-generative probabilistic models (as the ones postulated by LDA) were integrated into a consistent statistical framework. Using Bayesian statistics and simple marginalization equations we were able to transform the expressions of the books from distributions over unlabeled topics (derived by the LDA) to distributions over labeled subjects representing the respective disciplines (Physical sciences, Health sciences, Mathematics, etc). More specifically, the necessary theoretical basis is firstly established, with each subject formally defined by the respective branch of a subject term hierarchy (much like a ToC) or the respective bag of words (single words and biwords) produced by flattening the hierarchy branch; flattening is realized by taking all the terms of the nodes and leaves of the branch with repetitions allowed. Being confined within a closed set of subjects, we are able to invert the frequency-of-terms in each subject [also interpreted as the probability of generating a term ( $w_{n}$ ) when sampling the subject ( $s_{i}$ ) and denoted by Pr{ $w_{n}\vert $   $s_{i}$ })] and express each term as a weighted mixture (or probability distribution) of subjects, denoted by Pr{ $s_{i}\vert $   $w_{n}$ }. This is the key idea of the proposed method. Then, any document (dm) can be expressed as a weighted mixture of subjects (or the respective distribution, denoted by Pr{ $s_{i}\vert \text{d}_{m}$ }) by simply summing up the distributions of the individual terms contained in the document. This is made possible by virtue of some simple formulas that have been formally proven for the union of documents ( $\Pr \left \{{{\mathrm {s}_{i}\vert (\mathbf {d}}_{1}\mathrm {\cup }\mathbf {d}_{2}) }\right \})$  and for the union of subjects  $(\Pr \left \{{{\mathrm {(\mathbf {s}}}_{i}\mathrm {\cup }\mathbf {s}_{j}\mathrm {)\vert \mathbf {d}} }\right \})$ . Since not all vocabulary terms are found in a particular set of books, nor, conversely, all corpus words are included in the subject vocabulary either, two important measures come to the foreground and are calculated with the proposed formulation: the coverage of a book or a corpus by the subject term vocabulary and, conversely, the vocabulary coverage by a set of books. These measures are useful for updating/enriching the subject term vocabulary, whenever it happens that documents with new subjects are included in the corpus under analysis. Following the theoretical formulation, the derived results are combined with the LDA in order to further facilitate our multisubject analysis task: using the subject term vocabulary, LDA is applied on the corpus under study and results in expressing each book (bm), as a probability distribution over hidden topics (denotedby  $\text{Pr}\left\{\mathbf{t}_k \mid \mathbf{b}_m\right\}$ ). In the same framework, each topic  $\left(\mathbf{t}_k\right)$  is expressed as a probability distribution over words  $\left(\text{Pr}\left\{w_n \mid \mathbf{t}_k\right\}\right)$ . Having estimated each word's probability distribution over subjects  $\left(\text{Pr}\left\{\mathbf{s}_i \mid w_n\right\}\right)$ , we can express each discovered topic as a weighted mixture of subjects  $\left[\text{Pr}\left\{\mathbf{s}_i \mid \mathbf{t}_k\right\}=\sum_n \text{Pr}\left\{w_n \mid \mathbf{t}_k\right\} \text{Pr}\left\{\mathbf{s}_i \mid w_n\right\}\right]$  and, by using that, we express each book in the same manner  $\left[\text{Pr}\left\{\mathbf{s}_i \mid \mathbf{b}_m\right\}=\sum_k \text{Pr}\left\{\mathbf{t}_k \mid \mathbf{b}_m\right\} \text{Pr}\left\{\mathbf{s}_i \mid \mathbf{t}_k\right\}\right]$ . This is a very clear and formal way towards obtaining the desired result. The proposed methodology was applied to a Springer's e-book collection with more than 50,000 books, while a subject term hierarchy developed by KALLIPOS, a project creating openaccess e-books, was used for the proof of concept. A number of experiments were conducted to showcase the validity and usefulness of the proposed approach.},
  keywords={Vocabulary;Probability distribution;Task analysis;Resource management;Ensemble learning;Recurrent neural networks;Probabilistic logic;Artificial intelligence;digital libraries;classification algorithms;latent Dirichlet allocation;multi-subject classification;statistical natural language processing;subject headings;university coursebooks;Springer ebooks;Kallipos project},
  doi={10.1109/ACCESS.2023.3326722},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10725605,
  author={Ranjit, Gayathri and Subramoniam, Suresh and Jnaneswar, K},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Evidences of AI powered Use Cases and Challenges in E-tailing from leading Indian E-tailers}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The paper highlights the usage and challenges of artificial intelligence in etailing, citing use cases from leading Indian etailers like Amazon and Flipkart. Both organizations have embraced artificial intelligence in a number of ways to improve its operations and enhance customer experience. AI has emerged as a powerful tool that has significantly impacted etailers throughout the globe and especially in India. The results of the study show that both etailers have harnessed the transformative capabilities of AI to secure a strong market position. While Amazon employs machine learning, chatbot assistants, product recommendations, and generative AI, Flipkart applies AI for customized search, issue detection, Microsoft partnership, project Mira to name a few. This article is a reflection of how these leading Indian e-tailers has devoted resources to developing AI capabilities and also exposes the challenges involved like security risks, perception regarding ethics, technology integration, culture wars and quality of data.},
  keywords={Technological innovation;Companies;Machine learning;Reflection;Product design;Quality assessment;Electronic commerce;Security;Artificial intelligence;Guidelines;artificial intelligence;e-tailing;machine learning;chatbot;generative AI;Mira},
  doi={10.1109/ICCCNT61001.2024.10725605},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10988859,
  author={Liu, Chenyang and Chen, Keyan and Zhao, Rui and Zou, Zhengxia and Shi, Zhenwei},
  journal={IEEE Geoscience and Remote Sensing Magazine}, 
  title={Text2Earth: Unlocking text-driven remote sensing image generation with a global-scale dataset and a foundation model}, 
  year={2025},
  volume={},
  number={},
  pages={2-23},
  abstract={Recently, generative foundation models (GFMs) have significantly advanced large-scale text-driven natural image generation and become a prominent research trend across various vertical domains. However, in the remote sensing field, there is still a lack of research on large-scale text-to-image (text2image) generation technology. Existing remote sensing image‒text datasets are small in scale and confined to specific geographic areas and scene types. Besides, existing text2image methods have struggled to achieve global-scale, multiresolution controllability, and unbounded image generation. To address these challenges, this article presents two key contributions: the Git-10M dataset and the Text2Earth foundation model. Git-10M is a global-scale image‒text dataset consisting of 10.5 million image‒text pairs, five times larger than the previous largest one. The dataset covers a wide range of geographic scenes and contains essential geospatial metadata, significantly surpassing existing datasets in both size and diversity. Building on Git-10M, we propose Text2Earth, a 1.3 billion-parameter GFM based on the diffusion framework to model global-scale remote sensing scenes. Text2Earth integrates a resolution guidance mechanism, enabling users to specify image resolutions. A dynamic condition adaptation (DCA) strategy is proposed for training and inference to improve image generation quality. Text2Earth not only excels in zero-shot text2image generation but also demonstrates robust generalization and flexibility across multiple tasks, including unbounded scene construction, image editing, and cross-modal image generation. This robust capability surpasses previous models restricted to basic fixed sizes and limited scene types. On the previous text2image benchmark dataset, Text2Earth outperforms previous models, with a significantly improved +26.23 Fréchet inception distance (FID) score and +20.95% zero-shot classification overall accuracy (Cls-OA) metric. Our project page is https://chen-yang-liu.github.io/Text2Earth/.},
  keywords={Remote sensing;Image resolution;Image synthesis;Training;Foundation models;Diffusion models;Visualization;Spatial resolution;Noise reduction;Metadata},
  doi={10.1109/MGRS.2025.3560455},
  ISSN={2168-6831},
  month={},}@INPROCEEDINGS{10350585,
  author={Song, Hao and Panjvani, Karim and Liu, Zhigang and Amar, Huzaifa and Kochian, Leon and Ye, Shengjian and Yang, Xuan and Feurtado, J. Allan and Chavda, Krunal and Chimbo Huatatoca, Karina Angela and Eramian, Mark},
  booktitle={2023 IEEE/CVF International Conference on Computer Vision Workshops (ICCVW)}, 
  title={Plant Root Occlusion Inpainting with Generative Adversarial Network}, 
  year={2023},
  volume={},
  number={},
  pages={531-539},
  abstract={Three-dimensional (3D) image analysis represents the state-of-the art for phenotyping in the fields of biology and plant science including studies of root system architecture. A widely used approach for capturing root architecture in 3D involves growth of roots in hydroponic media and capture of optical camera views via a stepper-motor-based rotation system. However, the introduction of structures to support 3D root growth system leads to significant occlusion of the roots during image acquisition, thereby causing the complexity and introducing inaccuracy of subsequent operations such as 3D modeling and root traits calculation. Instead of using a traditional manual sketching methods, this project proposes an automatic root gaps detection and inpainting method based on a Generative Adversarial Networks (GAN). The model was trained and evaluated using two distinct maize datasets, both of which were enriched with manually annotated segmentation and inpainting labels. The quantitative analysis of the inpainting results demonstrated variation in the performance of the GAN model. However, promising outcomes were observed with certain instances achieving Intersection of Union (IoU) and Dice Similarity Coefficient (DSC) values surpassing 0.9 with specific images or patches exhibiting lower accuracy and reproducibly. Despite this variability, the overall model performance maintained an average range of 0.8-0.9. Our GAN model presents a robust, effective and automatic solution for inpainting plant root gaps, leading to improved accuracy within the phenotyping pipeline. Moreover, the model demonstrates a great generality for inpainting other root system of species or cultivars beyond those encountered during training. The performance of the model exhibits superiority when confronted with less intricate root structures, but it produces less accurate results when confronted with complex root systems with large gaps or high root density.},
  keywords={Training;Analytical models;Three-dimensional displays;Statistical analysis;Plants (biology);Pipelines;Systems architecture;Deep Learning;Inpainting;Generative Adversarial Network;Plant Root;Root System Architecture;Plant Root Phenotyping},
  doi={10.1109/ICCVW60793.2023.00060},
  ISSN={2473-9944},
  month={Oct},}@ARTICLE{10980460,
  author={Zhang, Junkang and Fang, Faming and Wang, Tingting and Zhang, Guixu and Song, Haichuan},
  journal={IEEE Transactions on Multimedia}, 
  title={FrDiff: Framelet-based Conditional Diffusion Model for Multispectral and Panchromatic Image Fusion}, 
  year={2025},
  volume={},
  number={},
  pages={1-14},
  abstract={The process of fusing low-resolution multispectral (LRMS) and high-resolution panchromatic (PAN) imagery, commonly referred to as pansharpening, is intended to generate high-resolution multispectral (HRMS) imagery. Typically, most pre-existing pansharpening frameworks mainly emphasize the straightforward learning of the mapping relationship among PAN and LRMS images to HRMS images. However, a key limitation of these frameworks is their potential overemphasis on spatial information, particularly the enhancement of low-frequency components. As a result, such an oversight potentially hinders the model's ability to simultaneously restore both spectral and spatial details. To address this issue, we propose a novel pansharpening model based on the denoising diffusion probabilistic model (DDPM), dubbed FrDiff. Specifically, we build a framelet-based conditional diffusion model that leverages the generative power of diffusion models to produce more refine results. Different from conventional methods directly inferring HRMS images, our strategy is designed to project their framelet coefficients, utilizing the available PAN and LRMS images as resources. This approach enables the separation of high-frequency and low-frequency components through framelet transformation, which are subsequently recombined to create a novel set of conditional embeddings that feed into the diffusion process. At the same time, the powerful predictive power of the diffusion model is exploited to simultaneously recover the high-frequency and low-frequency components of the HRMS. Moreover, we introduce a framelet-oriented cross-attention module dedicated to honing spectral fidelity. This module is crucial for improving the spectral precision of the HRMS images, ensuring a balanced emphasis on both spatial and spectral enhancements. Quantitative and qualitative experiments on multiple benchmark datasets demonstrate that the proposed method achieves more robustness and high-quality results than other state-of-the-art pansharpening methods.},
  keywords={Pansharpening;Diffusion models;Spatial resolution;Remote sensing;Noise reduction;Multiresolution analysis;Training;Image restoration;Image fusion;Deep learning;Convolutional neural network;diffusion model;pansharpening;framelet transform},
  doi={10.1109/TMM.2025.3565985},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10122084,
  author={Stürmer, Matthias},
  booktitle={2023 Ninth International Conference on eDemocracy & eGovernment (ICEDEG)}, 
  title={Keynote - AI for the Public Sector and the Case of Legal NLP}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={Recent innovations such as ChatGPT have increased public interest in artificial intelligence (AI). The keynote explained why AI is not just a short-term hype but has a long history of spanning several eras. A recent revolution has been in the field of Natural Language Processing (NLP). This interdisciplinary field of research is also known as computational linguistics. It is usually implemented by specific NLP tasks, ranging from simple processing steps such as tokenization, stemming, lemmatization to Part of Speech (PoS) tagging and topic modeling. A second, more complex set of NLP tasks includes Namend Entity Recognition (NER), information retrieval, relationship extraction, sentiment analysis, text similarity, and coreference resolution. Finally, the most challenging NLP tasks are considered Question Answering (QA), text summarization, text simplification, text generation, text translation, and chatbots. NLP has especially great potential in the public sector. For example, a new multilingual legal language model for more than 20 languages, developed for the Swiss Federal Court, offers opportunities to increase accessibility of legal documents for citizens while preserving the digital sovereignty of government institutions. These technical results of the National Research Program (NRP) 77 project “Open Justice versus Privacy” are published on Hugging Face, a platform for sharing openly available machine learning models and datasets. Today, it is mostly private companies that build such Large Language Models (LLM), because it requires a large amount of computational resources and highly skilled engineers. For example, to train the new LLaMA model, Meta AI (Facebook) needed more than $30 million worth of graphical processing units (GPU). In addition, 450 MWh of electricity worth about $90,000 was needed to process the data on these GPUs. Negative for innovation and the environment, Meta AI released the LLaMA model only under a non-commercial license. This means that startups and other companies cannot use the model for their own services. This calls for a discussion about how “open” today's machine learning models should be and what “open” actually means in the age of AI. The keynote presentation therefore included a proposal of 5 elements of such machine learning models that need to be openly available and licensed under an official open license in order to speak of an Open AI Model. This term is used by the United Nations definition of Digital Public Goods. These five elements include 1) model architecture (detailed scientific publications), 2) hyperparameters (built configuration), 3) training data (labeled and unlabeled datasets), 4) model weights and intermediate checkpoints (parameters), and 5) source code to build the model (programming scripts etc.). A truly openly available AI model is BLOOM, an LLM from the BigScience initiative. It was built by more than 1000 researchers from over 70 countries, trained on an infrastructure that would have cost EUR 3 million. BLOOM was released on July 12th, 2022 on Hugging Face and is licensed under the Responsible AI License (RAIL), a new type of AI license that incorporates ethical aspects while preserving the openness of the machine learning elements described.},
  keywords={},
  doi={10.1109/ICEDEG58167.2023.10122084},
  ISSN={2573-1998},
  month={April},}@INPROCEEDINGS{10398616,
  author={Muresan, Smaranda},
  booktitle={2023 IEEE 19th International Conference on Intelligent Computer Communication and Processing (ICCP)}, 
  title={Keynote Lecture: Human-centric Natural Language Processing for Social Good and Responsible Computing}, 
  year={2023},
  volume={},
  number={},
  pages={vii-vii},
  abstract={Large language models (LLMs) constitute a paradigm shift in Natural Language Processing and its applications across all domains. To move towards human-centric NLP designed for social good and responsible computing, I argue we need knowledge-aware NLP systems and human-AI collaboration frameworks. NLP systems that interact with humans need to be knowledge aware (e.g., linguistic, commonsense, sociocultural norms) and context aware (e.g., social, perceptual) so that they communicate better and in a safer and more responsible fashion with humans. Moreover, NLP systems should be able to collaborate with humans to create high-quality datasets for training and/or evaluating NLP models, to help humans solve tasks, and ultimately to align better with human values. In this talk, I will give a brief overview of my research agenda in the context of NLP for social good and responsible computing (e.g., misinformation detection, NLP for education and public health, building NLP technologies with language and culture diversity in mind). I will highlight key innovations on theory-guided and knowledge-aware models that allow us to address two important challenges: lack of training data, and the need to model commonsense knowledge. I will also present some of our recent work on human-AI collaboration frameworks for building high-quality datasets for various tasks such as generating visual metaphors or modeling cross-cultural norms similarities and differences.},
  keywords={},
  doi={10.1109/ICCP60212.2023.10398616},
  ISSN={2766-8495},
  month={Oct},}@ARTICLE{10319928,
  author={Sánchez-Gordón, Mary and Tovar, Edmundo and Colomo-Palacios, Ricardo and Piedra, Nelson and Castro, Manuel},
  journal={Computer}, 
  title={Educating Augmented Programmers}, 
  year={2023},
  volume={56},
  number={12},
  pages={100-104},
  abstract={There is an artificial intelligence-based technology that has the potential to augment the work of human programmers. This article discusses some capabilities built around generative artificial intelligence and large language models that impact programming education.},
  keywords={Computer languages;Programming environments;Artificial intelligence;Human factors;Computer science education},
  doi={10.1109/MC.2023.3313325},
  ISSN={1558-0814},
  month={Dec},}@ARTICLE{10547114,
  author={Bego, Campbell R. and Nwokeji, Joshua C. and Trytten, Deborah A.},
  journal={IEEE Transactions on Education}, 
  title={FIE-TOE Guest Editorial Grand Challenges in Engineering and Computing Education: Beyond the Pandemic}, 
  year={2024},
  volume={67},
  number={3},
  pages={333-335},
  abstract={The promise of engineering and computing education is to prepare and fully equip students to solve societal problems that are complex, open-ended, and/or poorly defined [1]. So far, engineering and computing educators have made notable progress toward fulfilling this promise. However, established practices are constantly tested by new challenges like those caused by the coronavirus pandemic and breakthroughs in generative artificial intelligence. For engineering and computing education to achieve its full potential and deliver its promise, these new challenges have to be elicited, analyzed, and addressed.},
  keywords={Special issues and sections;Engineering education;Computer science education;Social factors;Problem-solving;Curriculum development;Generative AI;Pandemics;Social implications of technology},
  doi={10.1109/TE.2024.3382848},
  ISSN={1557-9638},
  month={June},}@ARTICLE{10660597,
  author={Reisman, Sorel},
  journal={Computer}, 
  title={Generative Artificial Intelligence and Problematic Student E-Mails}, 
  year={2024},
  volume={57},
  number={9},
  pages={124-127},
  abstract={Students often challenge their instructors via e-mail. This, in turn, requires instructors to respond with tact. Can generative artificial intelligence be harnessed to compose tactful replies to the toughest student criticism?},
  keywords={Generative AI;Electronic mail;Writing;Professional communication;Artificial intelligence;Education},
  doi={10.1109/MC.2024.3422548},
  ISSN={1558-0814},
  month={Sep.},}@ARTICLE{10639261,
  author={Joshi, Rajiv and Ziegler, Matthew and Han, Jin-Ping and Maghraoui, Kaoutar El},
  journal={IEEE Circuits and Systems Magazine}, 
  title={6th IBM IEEE CAS/EDS AI Compute Symposium (AICS’23) [CASS Conference Highlights]}, 
  year={2024},
  volume={24},
  number={3},
  pages={49-53},
  abstract={The 6th IBM IEEE CAS/EDS AI Compute Symposium was held hybrid at the T. J. Watson Research Center on 28 November 2023. The event was extremely successful and well attended by over 2000 folks from all over the world (in-person and virtual). The symposium featured 8 distinguished speakers (7 from industry and 1 from academia), over 30 student in-person posters, best poster awards, and a panel discussion. The registration list spanned citizens of 53 countries. The theme of the symposium, “From Chips to Chiplets,” turned out to be an opportune and important topic for the current semiconductor industry direction. The symposium served as an educational as well as a brainstorming session for industry/academia/students across the world. The symposium covered a range of topics from emerging device technology, innovative circuits, chip and chiplet architecture, advanced packaging technologies, such as 2D to 3D packaging elements, and how these topics drive the rapid growth of AI and generative AI. Dr. Rajiv Joshi, General Chair and IEEE Life Fellow opened the symposium with welcoming remarks along with the goals and accomplishments of this symposium under the auspices of CAS and IBM.},
  keywords={},
  doi={10.1109/MCAS.2024.3395580},
  ISSN={1558-0830},
  month={thirdquarter},}@ARTICLE{10718671,
  author={Gupta, Varun and Gupta, Chetna},
  journal={Computer}, 
  title={Navigating the Landscape of AI-Generated Text Detection: Issues and Solutions for Upholding Academic Integrity}, 
  year={2024},
  volume={57},
  number={11},
  pages={118-123},
  abstract={Artificial intelligence (AI) generative tools offer students significant opportunities, albeit posing challenges to academic integrity. Given the constant advancements in generative AI, AI detection, and AI humanizer technologies, we provide three proactive strategies toward assuring such integrity.},
  keywords={},
  doi={10.1109/MC.2024.3445068},
  ISSN={1558-0814},
  month={Nov},}
@ARTICLE{10547095,
  author={Reisman, Sorel},
  journal={Computer}, 
  title={Practical Classroom Use of Generative Artificial Intelligence—A Case Study}, 
  year={2024},
  volume={57},
  number={6},
  pages={110-114},
  abstract={This article describes the author’s unsuccessful attempt to use current generative artificial intelligence tools to reduce instructors’ workloads by creating course syllabi that reference no cost resources.},
  keywords={Generative AI;Performance evaluation;Educational technology;Educational courses;Costs;Quality assessment;Software tools},
  doi={10.1109/MC.2024.3382453},
  ISSN={1558-0814},
  month={June},}@ARTICLE{10660605,
  author={Kshetri, Nir and Voas, Jeffrey},
  journal={Computer}, 
  title={Adapting to Generative Artificial Intelligence: Approaches in Higher Education Institutions}, 
  year={2024},
  volume={57},
  number={9},
  pages={128-133},
  abstract={Generative artificial intelligence (GAI) is reshaping higher education institutions (HEIs). HEIs are responding with policies, leveraging GAI to optimize operations, update curricula, and develop multidisciplinary programs, showcasing a proactive approach to transformative educational practices.},
  keywords={Generative AI;Educational programs;Educational institutions;Curriculum development},
  doi={10.1109/MC.2024.3422589},
  ISSN={1558-0814},
  month={Sep.},}@INPROCEEDINGS{10332336,
  author={Vidmar, Matjaz and Fleck, James and Williams, Robin},
  booktitle={2023 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)}, 
  title={AI and Data in Engineering and Innovation: Towards a Sustainable Future?}, 
  year={2023},
  volume={},
  number={},
  pages={1-2},
  abstract={29th International Conference on Engineering, Technology, and Innovation (ICE 2023) touched upon the critical issues in engineering of the generative AI era. By looking at the key challenges in data-driven project management and sustainable development, the overarching theme emerging from the event was one of adaptation to AI and data tools as essential part of the work process and supporting new approaches in engineering, technology development and innovation and entrepreneurship. This points to a promising future ahead, where digital transformation reaches the extended engineering disciplines, which is the theme of the following ICE conference. Having said that, the use of digital tools also presents a number of problems, from data-driven biases to challenges of interdisciplinary, inter-organisational and inter-entity collaborations.},
  keywords={ICE 2023;artificial intelligence;sustainability;data;interdisciplinarity},
  doi={10.1109/ICE/ITMC58018.2023.10332336},
  ISSN={2693-8855},
  month={June},}@ARTICLE{10458714,
  author={Togelius, Julian and Yannakakis, Georgios N.},
  journal={Proceedings of the IEEE}, 
  title={Choose Your Weapon: Survival Strategies for Depressed AI Academics [Point of View]}, 
  year={2024},
  volume={112},
  number={1},
  pages={4-11},
  abstract={As someone who does artificial intelligence (AI) research in a university, you develop a complicated relationship with the corporate AI research powerhouses, such as Google DeepMind, OpenAI, and Meta AI. Whenever you see one of these papers that train some kind of gigantic neural net model to do something you were not even sure a neural network could do, unquestionably pushing the state-of-the-art and reconfiguring your ideas of what is possible, you get conflicting emotions. On the one hand, it is very impressive. Good on you for pushing AI forward. On the other hand, how could we possibly keep up? As an AI academic, leading a laboratory with a few Ph.D. students and (if you are lucky) some postdoctoral fellows, perhaps with a few dozen graphics processing units (GPUs) in your laboratory, this kind of research is simply not possible to do.},
  keywords={Research and development;Artificial intelligence;Deep learning;Ethics;Education;Philosophical considerations;Scientific publishing;Business;Cultural aspects;Social implications of technology;Social factors;Human factors;Industries},
  doi={10.1109/JPROC.2024.3364137},
  ISSN={1558-2256},
  month={Jan},}@ARTICLE{10111517,
  author={Dix, Jürgen and Zhang, Zhongfei},
  journal={IEEE Intelligent Systems}, 
  title={AI’s 10 to Watch, 2022}, 
  year={2023},
  volume={38},
  number={2},
  pages={3-14},
  abstract={IEEE Intelligent Systems is promoting young and aspiring artificial intelligence (AI) scientists and recognizing the rising stars as “AI‘s 10 Watch.” This biennial 2022 edition is slightly different from the previous editions: We solicited submissions from individuals who had obtained their Ph.D. up to 10 years prior (as opposed to 5 years in all of the previous editions). This led to more applications of the highest quality. The selection committee finally had to select 10 outstanding contributors from a pool of 30+ highly competitive and strong nominations, which made the selection decisions rather difficult. After a careful and detailed selection process through many rounds of discussions via e-mails and live meetings, the committee voted unanimously on a short list of 10 top candidates who have all demonstrated outstanding achievements in different areas of AI. The selection was based solely on scientific quality, reputation, impact, and expert endorsements accumulated since their Ph.D. It is our honor and privilege to announce the following 2022 class of “AI’s 10 to Watch.”• Bo Li. She is working on trustworthy machine learning (ML) at the intersection of ML, security and privacy, and game theory. She was able to integrate domain knowledge and logical reasoning abilities into data-driven statistical ML models to improve learning robustness with guarantees, and she has designed scalable privacy-preserving data-publishing frameworks for high-dimensional data. Her work has provided rigorous guarantees for the trustworthiness of learning systems and been deployed in industrial applications. She is an assistant professor with the University of Illinois at Urbana-Champaign.• Tongliang Liu. He is working in the fields of trustworthy ML. His work in theories and algorithms of ML with noisy labels has led to significant contributions and influence in the fields of ML, computer vision, natural language processing (NLP), and data mining, as large-scale datasets in those fields are prone to suffering severe label errors. He is a senior lecturer at the School of Computer Science, University of Sydney, and a visiting associate professor at the Department of Machine Learning, Mohamed bin Zayed University of Artificial Intelligence.• Liqiang Nie. He is the dean of and a professor with the School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen). He works on multimedia content analysis and search, with a particular emphasis on data-driven multimodal learning and knowledge-guided multimodal reasoning. He pioneered the explicit modeling of consistent, complementary, and partial alignment relationships among modalities.• Soujanya Poria. He is an assistant professor at Singapore University of Technology and Design (SUTD). His seminal research on fusing information from textual, audio, and visual modalities for diverse behavioral and affective tasks significantly improved systems reliant on multimodal data, paving the way to various novel research avenues. His latest works are on information extraction, vision–language reasoning, and understanding human conversations in terms of common sense-based, context-grounded causal explanations.• Deqing Sun. He is a staff research scientist at Google. He has made significant contributions to computer vision, in particular in motion estimation. His work on optical flow (“Classic+NL” and “PWC-Net”) has been very influential and has been powering commercial applications such as Super SloMo in NVIDIA’s RTX platform, Face Unblur, and Fusion Zoom on Google’s Pixel phone.• Yizhou Sun. She is a pioneer in heterogeneous information network (HIN) mining, with a recent focus on deep graph learning, neural symbolic reasoning, and providing neural solutions to multiagent dynamical systems. Her work has a wide spectrum of applications, ranging from e-commerce, health care, and material science to hardware design. She is currently an associate professor at the University of California, Los Angeles (UCLA).• Jiliang Tang. He is a University Foundation Professor at Michigan State University. He works on graph ML and trustworthy AI and their applications in education and biology. His contributions to these fields include highly cited algorithms, well-received systems, and popular books.• Zhangyang “Atlas” Wang. He works on efficient and reliable ML. Recently, his core research theme is to leverage, understand, and expand the role of sparsity, from classical optimization to modern neural networks (NNs), whose impacts span the efficient training/inference of large-foundation models, robustness and trustworthiness, generative AI, graph learning, and more.• Hongzhi Yin. He has worked on trustworthy data intelligence to turn data into privacy-preserving, robust, explainable, and fair intelligent services in various industries and scenarios. He is also a leading expert researching and developing next-generation intelligent systems and algorithms for lightweight on-device predictive analytics as well as recommendation and decentralized ML on massive and heterogeneous data. He is an associate professor and ARC Future Fellow at the University of Queensland.• Liang Zheng. He is a senior lecturer at the Australian National University and works on data-centric computer vision, where he seeks to improve the quality of training and validation data, predict test data difficulty without labels, and more. These efforts provide a complementary perspective to model-centric developments. He has also made significant contributions to object re-identification and the broader smart city initiative through the introduction of widely used benchmarks and baseline methods.},
  keywords={Intelligent systems;Artificial intelligence;Companies;Computer applications},
  doi={10.1109/MIS.2023.3252919},
  ISSN={1941-1294},
  month={March},}
@article{springer2025_001,
  title={Construction and analysis of corporate greenwashing index: a deep learning approach},
  year={2025},
  doi={10.1140/epjds/s13688-025-00562-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_002,
  title={AI and the future of creative development: redefining digital media production},
  year={2025},
  doi={10.1007/s43681-025-00765-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_003,
  title={Agent-in-the-loop to distill expert knowledge into artificial intelligence models: a survey},
  year={2025},
  doi={10.1007/s10462-025-11255-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_004,
  title={Exploring Laws of Robotics: A Synthesis of Constitutional AI and Constitutional Economics},
  year={2025},
  doi={10.1007/s44206-025-00204-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_005,
  title={Synergistic integration of metaheuristics and machine learning: latest advances and emerging trends},
  year={2025},
  doi={10.1007/s10462-025-11266-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_006,
  title={Job recommender systems: a systematic literature review, applications, open issues, and challenges},
  year={2025},
  doi={10.1186/s40537-025-01173-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_007,
  title={Capturing research literature attitude towards sustainable development goals: an LLM-based topic modeling approach},
  year={2025},
  doi={10.1186/s40537-025-01189-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_008,
  title={Academic result classification of university students and the impact of dataset dimensionality reduction},
  year={2025},
  doi={10.1007/s41870-025-02584-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_009,
  title={Teaching AI with games: the impact of generative AI drawing on computational thinking skills},
  year={2025},
  doi={10.1007/s10639-025-13624-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_010,
  title={A case study on professional skills and accredited graduate programs of marketing},
  year={2025},
  doi={10.1007/s41109-025-00696-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_011,
  title={A comparative analysis of predictive process monitoring: object-centric versus classical event logs},
  year={2025},
  doi={10.1007/s10115-025-02461-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_012,
  title={Excuses, excuses: moral agency and the professional identity of AI developers},
  year={2025},
  doi={10.1007/s00146-025-02388-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_013,
  title={Examining linguistic shifts in academic writing before and after the launch of ChatGPT: a study on preprint papers},
  year={2025},
  doi={10.1007/s11192-025-05341-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_014,
  title={Systematic exploration of fuzzing in IoT: techniques, vulnerabilities, and open challenges},
  year={2025},
  doi={10.1007/s11227-025-07371-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_015,
  title={Process smells in practice: an evaluative case study},
  year={2025},
  doi={10.1007/s10664-025-10664-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_016,
  title={Indic approach to ethical AI in automated decision making system: implications for social, cultural, and linguistic diversity in native population},
  year={2025},
  doi={10.1007/s00146-025-02381-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_017,
  title={A review of generative models for virtual human motion driving},
  year={2025},
  doi={10.1007/s11432-023-4284-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_018,
  title={Navigating the digital learning landscape: insights into ethical dilemmas and academic misconduct among university students},
  year={2025},
  doi={10.1186/s41239-025-00516-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_019,
  title={Defining quality in peer review reports: a scoping review},
  year={2025},
  doi={10.1007/s10115-025-02435-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_020,
  title={A review of LLMs and their applications in the architecture, engineering and construction industry},
  year={2025},
  doi={10.1007/s10462-025-11241-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_021,
  title={The impact of large language models on computer science student writing},
  year={2025},
  doi={10.1186/s41239-025-00525-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_022,
  title={Face-based machine learning diagnostics: applications, challenges and opportunities},
  year={2025},
  doi={10.1007/s10462-025-11246-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_023,
  title={Towards an AI tutor for undergraduate geotechnical engineering: a comparative study of evaluating the efficiency of large language model application programming interfaces},
  year={2025},
  doi={10.1007/s10791-025-09580-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_024,
  title={AI in education: The mediating role of perceived trust in adoption decisions of school leaders},
  year={2025},
  doi={10.1007/s10639-025-13596-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_025,
  title={Discerning cybers’ threats in an era of digitally connected classrooms: lessons for the Nigerian higher education system and society},
  year={2025},
  doi={10.1007/s10791-025-09564-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_026,
  title={A comparative study on reward models for user interface adaptation with reinforcement learning},
  year={2025},
  doi={10.1007/s10664-025-10659-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_027,
  title={Exploring scientific contributions through citation context and division of labor},
  year={2025},
  doi={10.1007/s11192-025-05318-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_028,
  title={Machine learning innovations in CPR: a comprehensive survey on enhanced resuscitation techniques},
  year={2025},
  doi={10.1007/s10462-025-11214-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_029,
  title={Who will benefit from AIGC: An empirical study on the intentions to use artificial intelligence generated content in higher education},
  year={2025},
  doi={10.1007/s10639-025-13590-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_030,
  title={Ethical approval and informed consent in mental health research: a scoping review},
  year={2025},
  doi={10.1007/s00146-025-02364-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_031,
  title={Building a holistic cybersecurity framework for e-Government based on a systematic analysis of proposals},
  year={2025},
  doi={10.1007/s10207-025-01024-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_032,
  title={Make privacy policies longer and appoint LLM readers},
  year={2025},
  doi={10.1007/s10506-025-09442-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_033,
  title={Weirdnodes: centrality based anomaly detection on temporal networks for the anti-financial crime domain},
  year={2025},
  doi={10.1007/s41109-025-00702-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_034,
  title={Ct-K: a modeling approach for discourse anaphora},
  year={2025},
  doi={10.1007/s41870-025-02487-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_035,
  title={ChatGPT-based posthumous memories of a terminally ill patient: metabioethics and generative AI at the service of palliative medicine},
  year={2025},
  doi={10.1007/s43681-025-00737-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_036,
  title={Sustainable AI meets feminist African ethics},
  year={2025},
  doi={10.1007/s43681-025-00705-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_037,
  title={Domestic violence: a survey on norms and impacts, AI detection approaches, and existing datasets},
  year={2025},
  doi={10.1007/s10115-025-02420-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_038,
  title={Meaningful work in peril? Preserving self-efficacy in the age of artificial intelligence},
  year={2025},
  doi={10.1007/s43681-025-00717-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_039,
  title={Deep Reinforcement Learning in Continuous Action Spaces for Pair Trading: A Comparative Study of A2 C and PPO},
  year={2025},
  doi={10.1007/s42979-025-03854-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_040,
  title={A Survey on Writing Style Change Detection: Current Literature and Future Directions},
  year={2025},
  doi={10.1007/s11633-025-1544-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_041,
  title={Fast machine learning for building management systems},
  year={2025},
  doi={10.1007/s10462-025-11226-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_042,
  title={Navigating fairness: practitioners’ understanding, challenges, and strategies in AI/ML development},
  year={2025},
  doi={10.1007/s10664-025-10650-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_043,
  title={Student perceptions of ChatGPT: benefits, costs, and attitudinal differences between users and non-users toward AI integration in higher education},
  year={2025},
  doi={10.1007/s10639-025-13575-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_044,
  title={Towards a smarter education system: an investigation into ML and DL for information retrieval},
  year={2025},
  doi={10.1007/s11042-025-20656-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_045,
  title={Dimensions of Human-Machine Combination: Prompting the Development of Deployable Intelligent Decision Systems for Situated Clinical Contexts},
  year={2025},
  doi={10.1007/s10606-025-09514-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_046,
  title={An enhanced framework for real-time dense crowd abnormal behavior detection using YOLOv8},
  year={2025},
  doi={10.1007/s10462-025-11206-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_047,
  title={A Probabilistic Approach to Load Balancing in Multi-Cloud Environments via Machine Learning and Optimization Algorithms},
  year={2025},
  doi={10.1007/s10723-025-09805-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_048,
  title={Ethical and practical considerations for AI-driven deep brain stimulation in mild cognitive impairment},
  year={2025},
  doi={10.1007/s43681-025-00724-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_049,
  title={Beyond the code: analyzing OSS developers security awareness and practices},
  year={2025},
  doi={10.1007/s10207-025-01023-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_050,
  title={Software reconfiguration in robotics},
  year={2025},
  doi={10.1007/s10664-024-10596-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_051,
  title={Bridging perspectives on artificial intelligence: a comparative analysis of hopes and concerns in developed and developing countries},
  year={2025},
  doi={10.1007/s00146-025-02331-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_052,
  title={Disruptive tensions and emerging practices: an exploratory inquiry into student perspectives on generative Artificial Intelligence in a problem-based learning environment},
  year={2025},
  doi={10.1007/s10639-025-13533-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_053,
  title={Artificial intelligence in educational leadership: a comprehensive taxonomy and future directions},
  year={2025},
  doi={10.1186/s41239-025-00517-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_054,
  title={RDHNet: addressing rotational and permutational symmetries in continuous multi-agent systems},
  year={2025},
  doi={10.1007/s11704-025-41250-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_055,
  title={Overview of AI and communication for 6G network: fundamentals, challenges, and future research opportunities},
  year={2025},
  doi={10.1007/s11432-024-4337-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_056,
  title={Artificial intelligence facilitators in higher education institutions: A student-centric exploration with comparative analysis in Asian countries},
  year={2025},
  doi={10.1007/s10639-025-13513-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_057,
  title={European reactions to AI in full and flawed democracies: an investigation of key factors},
  year={2025},
  doi={10.1007/s00146-025-02306-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_058,
  title={How far are app secrets from being stolen? a case study on android},
  year={2025},
  doi={10.1007/s10664-024-10607-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_059,
  title={Efficient nearest-neighbor search on moving objects with durability constraints},
  year={2025},
  doi={10.1007/s10707-025-00543-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_060,
  title={Optimization methods in fully cooperative scenarios: a review of multiagent reinforcement learning},
  year={2025},
  doi={10.1631/FITEE.2400259},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_061,
  title={Advanced IDS: a comparative study of datasets and machine learning algorithms for network flow-based intrusion detection systems},
  year={2025},
  doi={10.1007/s10489-025-06422-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_062,
  title={AI Techniques in the Microservices Life-Cycle: a Systematic Mapping Study},
  year={2025},
  doi={10.1007/s00607-025-01432-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_063,
  title={Students' behavioural intention to use content generative AI for learning and research: A UTAUT theoretical perspective},
  year={2025},
  doi={10.1007/s10639-025-13441-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_064,
  title={What does AI consider praiseworthy?},
  year={2025},
  doi={10.1007/s43681-025-00682-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_065,
  title={One model, two skills: active vision and action learning model for robotic manipulation},
  year={2025},
  doi={10.1007/s11432-023-4282-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_066,
  title={Control search rankings, control the world: what is a good search engine?},
  year={2025},
  doi={10.1007/s43681-025-00695-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_067,
  title={A systematic literature review of artificial intelligence (AI) transparency laws in the European Union (EU) and United Kingdom (UK): a socio-legal approach to AI transparency governance},
  year={2025},
  doi={10.1007/s43681-025-00674-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_068,
  title={Reinforcement learning for mutation operator selection in automated program repair},
  year={2025},
  doi={10.1007/s10515-025-00501-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_069,
  title={The paradigm of digital health: AI applications and transformative trends},
  year={2025},
  doi={10.1007/s00521-025-11081-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_070,
  title={Artificial intelligence and communication technologies in academia: faculty perceptions and the adoption of generative AI},
  year={2025},
  doi={10.1186/s41239-025-00511-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_071,
  title={Embodied navigation},
  year={2025},
  doi={10.1007/s11432-024-4303-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_072,
  title={Towards an AI-Literate Future: A Systematic Literature Review Exploring Education, Ethics, and Applications},
  year={2025},
  doi={10.1007/s40593-025-00466-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_073,
  title={AI Ethics’ Institutional Turn},
  year={2025},
  doi={10.1007/s44206-025-00174-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_074,
  title={Evaluating the influence of generative AI on students’ academic performance through the lenses of TPB and TTF using a hybrid SEM-ANN approach},
  year={2025},
  doi={10.1007/s10639-025-13485-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_075,
  title={Assessing Software Practitioners’ Work Engagement and Job Satisfaction in a Large Software Company—What We Have Learned},
  year={2025},
  doi={10.1007/s42979-025-03772-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_076,
  title={Modelling big data platforms as knowledge graphs: the data platform shaper},
  year={2025},
  doi={10.1186/s40537-025-01094-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_077,
  title={Dissecting a social bot powered by generative AI: anatomy, new trends and challenges},
  year={2025},
  doi={10.1007/s13278-025-01410-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_078,
  title={Large language models (LLM) in computational social science: prospects, current state, and challenges},
  year={2025},
  doi={10.1007/s13278-025-01428-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_079,
  title={A survey of SSD simulators and emulators},
  year={2025},
  doi={10.1007/s11227-025-07078-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_080,
  title={Insights into user behavioral-based insider threat detection: systematic review},
  year={2025},
  doi={10.1007/s10207-025-01002-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_081,
  title={Aspect-based sentiment analysis in MOOCs: a systematic literature review introducing the MASC-MEF framework},
  year={2025},
  doi={10.1007/s44443-025-00018-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_082,
  title={Towards semantic versioning of open pre-trained language model releases on hugging face},
  year={2025},
  doi={10.1007/s10664-025-10631-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_083,
  title={Fostering Transversal Skills Through Open Schooling Supported by the CARE-KNOW-DO Pedagogical Model and the UNESCO AI Competencies Framework},
  year={2025},
  doi={10.1007/s40593-025-00458-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_084,
  title={Fog Computing Tasks Management Based on Federated Reinforcement Learning},
  year={2025},
  doi={10.1007/s10723-025-09796-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_085,
  title={FSD-GAN: Generative Adversarial Training for Face Swap Detection via the Latent Noise Fingerprint},
  year={2025},
  doi={10.1007/s11390-024-3337-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_086,
  title={How fair are we? From conceptualization to automated assessment of fairness definitions},
  year={2025},
  doi={10.1007/s10270-025-01277-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_087,
  title={Affordances, constraints, and implications of ChatGPT in education from a social-ecological perspective: A data mining approach},
  year={2025},
  doi={10.1007/s10639-024-13237-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_088,
  title={An empirical study on LLM-based classification of requirements-related provisions in food-safety regulations},
  year={2025},
  doi={10.1007/s10664-025-10619-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_089,
  title={Exploring the impact of generative artificial intelligence on students’ learning outcomes: a meta-analysis},
  year={2025},
  doi={10.1007/s10639-025-13420-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_090,
  title={Balancing risks and benefits: public perceptions of AI through traditional surveys and social media analysis},
  year={2025},
  doi={10.1007/s00146-025-02232-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_091,
  title={An extensive bibliometric analysis of artificial intelligence techniques from 2013 to 2023},
  year={2025},
  doi={10.1007/s11227-025-07021-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_092,
  title={Data augmentation with automated machine learning: approaches and performance comparison with classical data augmentation methods},
  year={2025},
  doi={10.1007/s10115-025-02349-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_093,
  title={Quantum deep learning in neuroinformatics: a systematic review},
  year={2025},
  doi={10.1007/s10462-025-11136-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_094,
  title={The potential of Large Language Models for social robots in special education},
  year={2025},
  doi={10.1007/s13748-025-00363-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_095,
  title={Building trustworthy AI solutions: integrating artificial intelligence literacy into records management and archival systems},
  year={2025},
  doi={10.1007/s00146-025-02194-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_096,
  title={Examining scholarly communication on X (Twitter): insights from participants tweeting COVID-19 and ChatGPT publications},
  year={2025},
  doi={10.1007/s11192-025-05246-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_097,
  title={When LLMs meet cybersecurity: a systematic literature review},
  year={2025},
  doi={10.1186/s42400-025-00361-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_098,
  title={The factors affecting teachers’ adoption of AI technologies: A unified model of external and internal determinants},
  year={2025},
  doi={10.1007/s10639-025-13393-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_099,
  title={Privacy dilemmas and opportunities in large language models: a brief review},
  year={2025},
  doi={10.1007/s11704-024-40583-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_100,
  title={Big data and urban form: a systematic review},
  year={2025},
  doi={10.1186/s40537-025-01084-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_101,
  title={Big data and urban form: a systematic review},
  year={2025},
  doi={10.1186/s40537-025-01084-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_102,
  title={The causal effect of the global crisis on open science research impact: a bibliometric causal analysis},
  year={2025},
  doi={10.1007/s11192-025-05241-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_103,
  title={Prioritization Hindsight Experience Based on Spatial Position Attention for Robots},
  year={2025},
  doi={10.1007/s11633-023-1467-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_104,
  title={General Automatic Solution Generation for Social Problems},
  year={2025},
  doi={10.1007/s11633-024-1496-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_105,
  title={Unveiling the Hidden Interactions Among Features: A Heterogeneous Graph Approach for Personality Prediction},
  year={2025},
  doi={10.1007/s11633-024-1495-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_106,
  title={Technology-driven support: exploring the impact of artificial intelligence on mental health in higher education},
  year={2025},
  doi={10.1007/s10639-025-13352-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_107,
  title={Systematic literature review of smart greenhouse monitoring},
  year={2025},
  doi={10.1007/s42979-024-03640-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_108,
  title={Collaborative online international learning as a third space to improve students’ awareness of cybersecurity},
  year={2025},
  doi={10.1007/s10639-025-13336-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_109,
  title={GaussDB-AISQL: a composable cloud-native SQL system with AI capabilities},
  year={2025},
  doi={10.1007/s11704-024-40624-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_110,
  title={Redefining computational thinking: A holistic framework and its implications for K-12 education},
  year={2025},
  doi={10.1007/s10639-024-13297-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_111,
  title={The rise and potential of large language model based agents: a survey},
  year={2025},
  doi={10.1007/s11432-024-4222-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_112,
  title={A taxonomy of literature reviews and experimental study of deepreinforcement learning in portfolio management},
  year={2025},
  doi={10.1007/s10462-024-11066-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_113,
  title={Ethical Guidelines for the Application of Generative AI in German Journalism},
  year={2025},
  doi={10.1007/s44206-024-00151-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_114,
  title={Intelligence is not deception: from the Turing test to community-based ascriptions},
  year={2025},
  doi={10.1007/s00146-024-02172-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_115,
  title={Enhancing time-series access control using deep recurrent neural networks and generative adversarial networks},
  year={2025},
  doi={10.1007/s10207-024-00977-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_116,
  title={AI in education: Evaluating the impact of moodle AI-powered chatbots and metacognitive teaching approaches on academic performance of higher Institution Business Education students},
  year={2025},
  doi={10.1007/s10639-024-13235-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_117,
  title={The ethical thread: AI’s role in the tapestry of fashion},
  year={2025},
  doi={10.1007/s00146-024-02151-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_118,
  title={AI to renew public employment services? Explanation and trust of domain experts},
  year={2025},
  doi={10.1007/s43681-024-00629-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_119,
  title={A comprehensive survey on impact of applying various technologies on the internet of medical things},
  year={2025},
  doi={10.1007/s10462-024-11063-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_120,
  title={The role of generative AI in academic and scientific authorship: an autopoietic perspective},
  year={2025},
  doi={10.1007/s00146-024-02174-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_121,
  title={Effect of large language models artificial intelligence chatgpt chatbot on achievement of computer education students},
  year={2025},
  doi={10.1007/s10639-024-13293-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_122,
  title={Topic modelling through the bibliometrics lens and its technique},
  year={2025},
  doi={10.1007/s10462-024-11011-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_123,
  title={Fake news detection: comparative evaluation of BERT-like models and large language models with generative AI-annotated data},
  year={2025},
  doi={10.1007/s10115-024-02321-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_124,
  title={A comprehensive bibliometric analysis on social network anonymization: current approaches and future directions},
  year={2025},
  doi={10.1007/s10115-024-02289-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_125,
  title={Socially shared regulation of learning and artificial intelligence: Opportunities to support socially shared regulation},
  year={2025},
  doi={10.1007/s10639-024-13187-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_126,
  title={Research on Disruptive Technology Prediction Methods Based on BERT Model and Graph Theory Analysis},
  year={2025},
  doi={10.1007/978-3-031-75919-2_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_127,
  title={Guidelines for Supporting Software Engineers in Developing Secure Web Applications},
  year={2025},
  doi={10.1007/978-3-031-78386-9_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_128,
  title={Clinical Workflow and Human Factors},
  year={2025},
  doi={10.1007/978-3-031-82971-0_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_129,
  title={Competence of Teachers and Ethical Aspects of Implementing AI Technologies in Education},
  year={2025},
  doi={10.1007/978-3-031-83432-5_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_130,
  title={Pattern Discovery and Validation Using Scientific Research Methods},
  year={2025},
  doi={10.1007/978-3-662-70810-1_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_131,
  title={Introduction to the REoCAS Colloquium in Honor of Rocco De Nicola’s 70th Birthday},
  year={2025},
  doi={10.1007/978-3-031-73709-1_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_132,
  title={Understanding and Fighting Scams: Media, Language, Appeals and Effects},
  year={2025},
  doi={10.1007/978-3-031-76821-7_27},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_133,
  title={Conversational User Interfaces and Agents},
  year={2025},
  doi={10.1007/978-3-031-61375-3_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_134,
  title={Adaptation and Personalization in Human-Centered AI},
  year={2025},
  doi={10.1007/978-3-031-61375-3_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_135,
  title={Green Thoughts and Creative Spaces: An Experimental Study on Influence of Innovation Labs on Productivity and Sustainability of Process Teams},
  year={2025},
  doi={10.1007/978-3-031-72041-3_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_136,
  title={Comparative Analysis of Classic and Reinforcement Learning Approaches for Robot Navigation in Dynamic Environments},
  year={2025},
  doi={10.1007/978-3-031-73058-0_25},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_137,
  title={Transparency},
  year={2025},
  doi={10.1007/978-3-031-69978-8_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_138,
  title={Privacy Requirements Acquisition and Analysis},
  year={2025},
  doi={10.1007/978-3-031-73143-3_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_139,
  title={Legal Requirements Analysis: A Regulatory Compliance Perspective},
  year={2025},
  doi={10.1007/978-3-031-73143-3_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_140,
  title={Sociotechnical Implications of Generative Artificial Intelligence for Information Access},
  year={2025},
  doi={10.1007/978-3-031-73147-1_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_141,
  title={Fully Authentic Visual Question Answering Dataset from Online Communities},
  year={2025},
  doi={10.1007/978-3-031-73195-2_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_142,
  title={Comparative Analysis of Classic and Reinforcement Learning Approaches for Robot Navigation in Dynamic Environments},
  year={2025},
  doi={10.1007/978-3-031-73058-0_25},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_143,
  title={Handbook on Natural Language Processing for Requirements Engineering: Overview},
  year={2025},
  doi={10.1007/978-3-031-73143-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_144,
  title={Legal Requirements Analysis: A Regulatory Compliance Perspective},
  year={2025},
  doi={10.1007/978-3-031-73143-3_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_145,
  title={Privacy Requirements Acquisition and Analysis},
  year={2025},
  doi={10.1007/978-3-031-73143-3_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_146,
  title={Sociotechnical Implications of Generative Artificial Intelligence for Information Access},
  year={2025},
  doi={10.1007/978-3-031-73147-1_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_147,
  title={Thinking Outside the Box?},
  year={2025},
  doi={10.1007/978-3-031-73741-1_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_148,
  title={Data Privacy Vocabulary (DPV) – Version 2.0},
  year={2025},
  doi={10.1007/978-3-031-77847-6_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_149,
  title={WIBA: What Is Being Argued? A Comprehensive Approach to Argument Mining},
  year={2025},
  doi={10.1007/978-3-031-78541-2_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_150,
  title={Resignifying Compliance Between Ontologies and Epistemologies of Law (Invited Paper)},
  year={2025},
  doi={10.1007/978-3-031-75599-6_19},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_151,
  title={Understanding and Fighting Scams: Media, Language, Appeals and Effects},
  year={2025},
  doi={10.1007/978-3-031-76821-7_27},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_152,
  title={Towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings},
  year={2025},
  doi={10.1007/978-3-031-78090-5_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_153,
  title={Strategies for Gen AI Enterprise Adoption},
  year={2025},
  doi={10.1007/978-3-031-80842-5_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_154,
  title={Competence of Teachers and Ethical Aspects of Implementing AI Technologies in Education},
  year={2025},
  doi={10.1007/978-3-031-83432-5_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_155,
  title={A Survey and Insights on Modern Game Development Processes for Software Engineering Education},
  year={2025},
  doi={10.1007/978-3-031-75201-8_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_156,
  title={Safety, Testing, and Maintenance},
  year={2025},
  doi={10.1007/978-3-031-68582-8_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_157,
  title={Feature Learning Taxonomy and Neuroscience Background},
  year={2025},
  doi={10.1007/978-981-99-3393-8_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_158,
  title={Charting Careers in Data Science and Artificial Intelligence: Community Perspectives on Degree Essentiality},
  year={2025},
  doi={10.1007/978-981-96-0692-4_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_159,
  title={Understanding AI Tools Adoption in Academic Work: Case from Chinese Early-Career Researchers},
  year={2025},
  doi={10.1007/978-981-96-0868-3_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_160,
  title={A Hypertension Early Warning Model Combining Generative Adversarial Networks and Long Short-Term Memory Neural Networks},
  year={2025},
  doi={10.1007/978-981-96-1483-7_29},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_161,
  title={Charting Careers in Data Science and Artificial Intelligence: Community Perspectives on Degree Essentiality},
  year={2025},
  doi={10.1007/978-981-96-0692-4_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_162,
  title={Understanding AI Tools Adoption in Academic Work: Case from Chinese Early-Career Researchers},
  year={2025},
  doi={10.1007/978-981-96-0868-3_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_163,
  title={Single Modality to Multi-modality: The Evolutionary Trajectory of Artificial Intelligence in Integrating Diverse Data Streams for Enhanced Cognitive Capabilities},
  year={2025},
  doi={10.1007/978-981-96-2355-6_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_164,
  title={Artificial Intelligence},
  year={2025},
  doi={10.1007/978-981-96-0033-5_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_165,
  title={Feature Learning Taxonomy and Neuroscience Background},
  year={2025},
  doi={10.1007/978-981-99-3393-8_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_166,
  title={On Implementing an Effective Intelligent Tutor and Its Impact on Teaching and Learning Experiences},
  year={2025},
  doi={10.1007/978-981-97-9255-9_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_167,
  title={Artificial Intelligence Evolution: The Rise of Generative AI},
  year={2025},
  doi={10.1007/978-3-031-89063-5_36},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_168,
  title={A Field Study on the Use of Gen AI to Support Computing Education},
  year={2025},
  doi={10.1007/978-3-031-93724-8_17},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_169,
  title={Exploring Trends of Acceptance of Artificial Intelligence in Education: A Systematic Literature Review},
  year={2025},
  doi={10.1007/978-3-031-93412-4_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_170,
  title={Comparative Analysis of STEM and Non-STEM Teachers’ Needs for Integrating AI into Educational Environments},
  year={2025},
  doi={10.1007/978-3-031-93567-1_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_171,
  title={The Mechanism, Patterns, and Directional Considerations of Generative AI Empowering Urban Cultural Renewal},
  year={2025},
  doi={10.1007/978-3-031-93236-6_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_172,
  title={Technological Frontiers in Education: Exploring the Impact of AI and Immersive Learning},
  year={2025},
  doi={10.1007/978-3-031-78357-9_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_173,
  title={Privacy and Urban Living with AI: Opportunities to Improve Technology Design, Policy, Regulation, and Use},
  year={2025},
  doi={10.1007/978-3-031-88765-9_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_174,
  title={Constructing Benchmarks for Open Source Ecosystems: A Stakeholder Needs-Driven Approach},
  year={2025},
  doi={10.1007/978-981-96-6310-1_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_175,
  title={Behavioral Computing for Human Factor Security and Safety in Cyberfinance},
  year={2025},
  doi={10.1007/978-981-96-5194-8_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_176,
  title={Media Bias},
  year={2025},
  doi={10.1007/978-3-658-47798-1_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_177,
  title={Computations and Methods},
  year={2025},
  doi={10.1007/978-981-96-5277-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_178,
  title={Overview of CAMS},
  year={2025},
  doi={10.1007/978-981-96-5277-8_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_179,
  title={The Future of Developer Experience},
  year={2025},
  doi={10.1007/979-8-8688-0242-3_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_180,
  title={Introduction to AI Agents},
  year={2025},
  doi={10.1007/979-8-8688-1134-0_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_181,
  title={Pondering on Capability Brokering with LLM},
  year={2025},
  doi={10.1007/978-3-031-94590-8_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_182,
  title={Generic Architecture of Digital Assistant for Freshman Onboarding Process},
  year={2025},
  doi={10.1007/978-981-97-9255-9_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_183,
  title={Psychological Profiling in Cybersecurity: A Look at LLMs and Psycholinguistic Features},
  year={2025},
  doi={10.1007/978-981-96-1483-7_31},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_184,
  title={Systems Thinking: Basics},
  year={2025},
  doi={10.1007/978-3-031-85012-7_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_185,
  title={Professional Development for Teachers in Artificial Intelligence and Data Literacy},
  year={2025},
  doi={10.1007/978-3-031-88744-4_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_186,
  title={Towards Automated Recovery of Links Between Code Commits and Requirements–Initial Results},
  year={2025},
  doi={10.1007/978-3-031-78386-9_29},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_187,
  title={Data Science and Environmental Sustainability: Mastering the Information and Knowledge},
  year={2025},
  doi={10.1007/978-3-031-84595-6_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_188,
  title={Carbon-Aware Software Services},
  year={2025},
  doi={10.1007/978-3-031-84617-5_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_189,
  title={Efficient Didactic Methods Used in Modern E-Learning and Traditional Environments},
  year={2025},
  doi={10.1007/978-3-031-84263-4_22},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_190,
  title={Dave’s Decision: What Would You Do?},
  year={2025},
  doi={10.1007/978-3-031-85272-5_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_191,
  title={Rigorous Engineering of Collective Adaptive Systems Introduction to the 5 $$^\textrmth$$ Track Edition},
  year={2025},
  doi={10.1007/978-3-031-75107-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_192,
  title={System Security},
  year={2025},
  doi={10.1007/978-3-031-68483-8_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_193,
  title={AI for Sustainable Development: MENA Strategies},
  year={2025},
  doi={10.1007/978-3-031-75589-7_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_194,
  title={Applying Data Science and Machine Learning for Predictive Analytics in Organizational Decision-Making},
  year={2025},
  doi={10.1007/978-3-031-75702-0_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_195,
  title={Introduction},
  year={2025},
  doi={10.1007/978-3-031-76631-2_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_196,
  title={Application of Generative AI in Patient Engagement},
  year={2025},
  doi={10.1007/978-3-031-82963-5_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_197,
  title={The Effect of Generative Artificial Intelligence on Cognitive Thinking Skills in Higher Education Institutions: A Systematic Literature Review},
  year={2025},
  doi={10.1007/978-3-031-78255-8_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_198,
  title={Alloy Repair Hint Generation Based on Historical Data},
  year={2025},
  doi={10.1007/978-3-031-71177-0_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_199,
  title={Software Requirements Analysis and Specification},
  year={2025},
  doi={10.1007/978-3-031-74318-4_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_200,
  title={Prerequisites and Glossary for Natural Language Understanding},
  year={2025},
  doi={10.1007/978-3-031-74364-1_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_201,
  title={Natural Language Understanding & AI},
  year={2025},
  doi={10.1007/978-3-031-73974-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_202,
  title={Dealing with Data for RE: Mitigating Challenges While Using NLP and Generative AI},
  year={2025},
  doi={10.1007/978-3-031-73143-3_17},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_203,
  title={Playing Games},
  year={2025},
  doi={10.1007/978-3-031-83347-2_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_204,
  title={Typical AI Technologies},
  year={2025},
  doi={10.1007/978-981-96-5129-0_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_205,
  title={Significant Developments in AI},
  year={2025},
  doi={10.1007/978-981-96-5129-0_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_206,
  title={6G Cyber Security Resilience: Trends and Challenges},
  year={2025},
  doi={10.1007/978-3-031-85008-0_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_207,
  title={Artificial Intelligence and Deep Neural Networks},
  year={2025},
  doi={10.1007/978-981-99-0353-5_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_208,
  title={Urban Life and Urban AI: From Collaboration to Partnering to Teaming},
  year={2025},
  doi={10.1007/978-3-031-88765-9_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_209,
  title={Leveraging AI for Good with Human Awareness, Creativity, and Insight: The Cross-Fertilization of AI and Human Collective Intelligence in Urban Life},
  year={2025},
  doi={10.1007/978-3-031-88765-9_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_210,
  title={Internet of Things (IoT): Studying the Integration of Everyday Objects with the Internet and the Implications for Human Lives},
  year={2025},
  doi={10.1007/978-3-031-78357-9_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_211,
  title={Reinforcement Learning and Control},
  year={2025},
  doi={10.1007/979-8-8688-0989-7_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_212,
  title={AI Governance and Responsible AI},
  year={2025},
  doi={10.1007/979-8-8688-1154-8_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_213,
  title={Cellular Automata Based Binarized Machine Learning Model},
  year={2025},
  doi={10.1007/978-981-96-1501-8_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_214,
  title={CAML Model for Computational Linguistics},
  year={2025},
  doi={10.1007/978-981-96-1501-8_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_215,
  title={The Application of the MDATA Cognitive Model in Open Source Intelligence Analysis},
  year={2025},
  doi={10.1007/978-981-96-3528-3_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_216,
  title={Trends, Challenges and New Frontiers of Artificial Intelligence},
  year={2025},
  doi={10.1007/978-981-96-1501-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_217,
  title={Adaptive Learning Technologies: Navigating the Road from Hype to Reality},
  year={2025},
  doi={10.1007/978-981-96-2355-6_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_218,
  title={Computational Models and Neural Insights in Music Neuroscience},
  year={2025},
  doi={10.1007/978-981-97-4711-5_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_219,
  title={Introduction},
  year={2025},
  doi={10.1007/978-981-97-5333-8_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_220,
  title={Other Learning Quasi-paradigm},
  year={2025},
  doi={10.1007/978-981-97-5333-8_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_221,
  title={Techniques and Application of Knowledge Mapping},
  year={2025},
  doi={10.1007/978-3-031-54677-8_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_222,
  title={A Comprehensive Review of Artificial General Intelligence Security Development with Its Scope},
  year={2025},
  doi={10.1007/978-981-97-3222-7_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_223,
  title={The Benefits and Risks of Artificial General Intelligence (AGI)},
  year={2025},
  doi={10.1007/978-981-97-3222-7_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_224,
  title={Identification Technologies},
  year={2025},
  doi={10.1007/978-3-031-57342-2_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_225,
  title={Transformer-Driven Models for Language, Vision, and Multimodality},
  year={2025},
  doi={10.1007/978-3-031-57816-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_226,
  title={Human-Computer Interaction, User Experience, and AI Systems},
  year={2025},
  doi={10.1007/978-3-031-61375-3_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_227,
  title={Artificial Intelligence Paradigms and Agent-Based Technologies},
  year={2025},
  doi={10.1007/978-3-031-61375-3_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_228,
  title={AI Ethics},
  year={2025},
  doi={10.1007/978-3-031-61375-3_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_229,
  title={Improving Knowledge Asymmetry in Group Discussions with Smart Assistants},
  year={2025},
  doi={10.1007/978-3-031-76806-4_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_230,
  title={Adapting Generative Information Retrieval Systems to Users, Tasks, and Scenarios},
  year={2025},
  doi={10.1007/978-3-031-73147-1_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_231,
  title={Transforming Clinical Workflows with Artificial Intelligence (AI)-Based Technologies},
  year={2025},
  doi={10.1007/978-3-031-82971-0_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_232,
  title={Influence of ChatGPT on Programming Code Generation: A Case Study of the Technical University of Manabí},
  year={2025},
  doi={10.1007/978-3-031-83210-9_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_233,
  title={Capturing the Viewpoint Dynamics in the News Domain},
  year={2025},
  doi={10.1007/978-3-031-77792-9_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_234,
  title={GoNoGo: An Efficient LLM-Based Multi-agent System for Streamlining Automotive Software Release Decision-Making},
  year={2025},
  doi={10.1007/978-3-031-80889-0_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_235,
  title={Emergence in Multi-agent Systems: A Safety Perspective},
  year={2025},
  doi={10.1007/978-3-031-75107-3_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_236,
  title={Making EULA Great Again: A Novel Nudge Mechanism to Improve Readability, User Attention and Awareness},
  year={2025},
  doi={10.1007/978-3-031-80020-7_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_237,
  title={Are Swedish Passwords Tougher Than the Rest?},
  year={2025},
  doi={10.1007/978-3-031-79007-2_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_238,
  title={Klaim in the Making},
  year={2025},
  doi={10.1007/978-3-031-73709-1_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_239,
  title={Gamification and Immersive Learning with AI},
  year={2025},
  doi={10.1007/978-3-031-81780-9_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_240,
  title={Migration from On-Premises to Cloud: Challenges and Opportunities},
  year={2025},
  doi={10.1007/978-3-031-75144-8_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_241,
  title={Adapting Generative Information Retrieval Systems to Users, Tasks, and Scenarios},
  year={2025},
  doi={10.1007/978-3-031-73147-1_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_242,
  title={General Data Protection Regulation (GDPR)},
  year={2025},
  doi={10.1007/978-3-030-71522-9_1811},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_243,
  title={Design of a Bachelor’s Degree in Cybersecurity and Artificial Intelligence},
  year={2025},
  doi={10.1007/978-981-96-7071-0_22},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_244,
  title={Support + Belief = Decision Trust},
  year={2025},
  doi={10.1007/978-3-031-91736-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_245,
  title={Enhancing IT Education Through Tailored Course Selection: A Case Study from Estonian General Education School},
  year={2025},
  doi={10.1007/978-3-031-93564-0_18},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_246,
  title={Co-designing Lesson Plans for Supporting Human-Centred AI Literacy in K-12 Education},
  year={2025},
  doi={10.1007/978-3-031-93564-0_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_247,
  title={The Hidden Dangers of Publicly Accessible LLMs: A Case Study on Gab AI},
  year={2025},
  doi={10.1007/978-3-031-89363-6_18},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_248,
  title={Comprehensive Framework for Artificial Intelligence and Big Data Integration in Highe Education},
  year={2025},
  doi={10.1007/978-981-96-6400-9_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_249,
  title={Creative Synergies: The Interplay of Art, Science, and Technology in Contemporary Culture},
  year={2025},
  doi={10.1007/978-3-031-78357-9_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_250,
  title={“Do As Your Teacher Tells You!” How Is AI Use Regulated in Nordic Higher Education Institutions?},
  year={2025},
  doi={10.1007/978-3-031-93539-8_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_251,
  title={AI Methods for Games},
  year={2025},
  doi={10.1007/978-3-031-83347-2_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_252,
  title={Artificial Intelligence Application Scenarios Considering Objective and Subjective Influence Factors for Industrial Solutions in Supply Chain Management},
  year={2025},
  doi={10.1007/978-3-031-94263-1_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_253,
  title={LLM-Augmented Curriculum Design: A Framework for Curriculum Innovation in Digital Public Infrastructure Education},
  year={2025},
  doi={10.1007/978-3-031-93724-8_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_254,
  title={Generative AI Tools for Systematic Approaches to Literature Review: Insights from Danish Librarians},
  year={2025},
  doi={10.1007/978-3-031-93567-1_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_255,
  title={Deep Learning and Data Science: Connections and Teaching},
  year={2025},
  doi={10.1007/978-981-96-0742-6_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_256,
  title={Conclusion and Future Work},
  year={2025},
  doi={10.1007/978-3-658-47798-1_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_257,
  title={Behavioral Language Computing},
  year={2025},
  doi={10.1007/978-981-96-5194-8_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_258,
  title={Designing Buy-In: Leveraging HCI to Drive Responsible AI},
  year={2025},
  doi={10.1007/978-3-031-94171-9_25},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_259,
  title={SJ Urban Impact: Generative AI Powered System for Participatory Civic Engagement Among Young Adults},
  year={2025},
  doi={10.1007/978-3-031-94171-9_27},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2025_260,
  title={CAMERA: Context Based Emotion Detection Framework and Its Evaluation},
  year={2025},
  doi={10.1007/978-3-031-85386-9_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_261,
  title={6G autonomous radio access network empowered by artificial intelligence and network digital twin},
  year={2024},
  doi={10.1631/FITEE.2400569},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_262,
  title={Deep learning-based software engineering: progress, challenges, and opportunities},
  year={2024},
  doi={10.1007/s11432-023-4127-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_263,
  title={An empirical study of business process models and model clones on GitHub},
  year={2024},
  doi={10.1007/s10664-024-10584-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_264,
  title={Models of symbol emergence in communication: a conceptual review and a guide for avoiding local minima},
  year={2024},
  doi={10.1007/s10462-024-11048-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_265,
  title={BERTweet.BR: a pre-trained language model for tweets in Portuguese},
  year={2024},
  doi={10.1007/s00521-024-10711-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_266,
  title={Investigating the utilization and impact of large language model-based intelligent teaching assistants in flipped classrooms},
  year={2024},
  doi={10.1007/s10639-024-13264-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_267,
  title={A review on polyadic chatbots: trends, challenges, and future research directions},
  year={2024},
  doi={10.1007/s10115-024-02287-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_268,
  title={Navigating artificial general intelligence (AGI): societal implications, ethical considerations, and governance strategies},
  year={2024},
  doi={10.1007/s43681-024-00642-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_269,
  title={The role of explainability and transparency in fostering trust in AI healthcare systems: a systematic literature review, open issues and potential solutions},
  year={2024},
  doi={10.1007/s00521-024-10868-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_270,
  title={Deep learning-based EEG emotion recognition: a comprehensive review},
  year={2024},
  doi={10.1007/s00521-024-10821-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_271,
  title={AI through the looking glass: an empirical study of structural social and ethical challenges in AI},
  year={2024},
  doi={10.1007/s00146-024-02146-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_272,
  title={FedCare: towards interactive diagnosis of federated learning systems},
  year={2024},
  doi={10.1007/s11704-024-3735-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_273,
  title={Offline model-based reinforcement learning with causal structured world models},
  year={2024},
  doi={10.1007/s11704-024-3946-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_274,
  title={Legal and administrative frameworks as foundations for AI alignment with human volition},
  year={2024},
  doi={10.1007/s43681-024-00640-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_275,
  title={MuxFlow: efficient GPU sharing in production-level clusters with more than 10000 GPUs},
  year={2024},
  doi={10.1007/s11432-024-4227-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_276,
  title={A survey on deep learning-based algorithms for the traveling salesman problem},
  year={2024},
  doi={10.1007/s11704-024-40490-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_277,
  title={Meta-prediction: uncovering patterns and enhancing predictive accuracy through self-learning algorithms},
  year={2024},
  doi={10.1007/s11042-024-20344-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_278,
  title={Harnessing pre-trained generalist agents for software engineering tasks},
  year={2024},
  doi={10.1007/s10664-024-10597-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_279,
  title={Risk management strategy for generative AI in computing education: how to handle the strengths, weaknesses, opportunities, and threats?},
  year={2024},
  doi={10.1186/s41239-024-00494-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_280,
  title={Does ChatGPT-based reading platform impact foreign language paper reading? Evidence from a quasi-experimental study on Chinese undergraduate students},
  year={2024},
  doi={10.1007/s10639-024-13190-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_281,
  title={Deep reinforcement learning for near-field wideband beamforming in STAR-RIS networks},
  year={2024},
  doi={10.1631/FITEE.2400364},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_282,
  title={Inference of access policies through static analysis},
  year={2024},
  doi={10.1007/s10009-024-00777-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_283,
  title={Using DSLs to manage consistency in long-lived enterprise language specifications},
  year={2024},
  doi={10.1007/s10270-024-01243-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_284,
  title={Business process improvement with AB testing and reinforcement learning: grounded theory-based industry perspectives},
  year={2024},
  doi={10.1007/s10270-024-01229-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_285,
  title={Analysis of machine learning-based approaches for securing the Internet of Things in the smart industry: a multivocal state of knowledge review},
  year={2024},
  doi={10.1007/s10207-024-00935-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_286,
  title={Deep reinforcement learning for dynamic strategy interchange in financial markets},
  year={2024},
  doi={10.1007/s10489-024-05965-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_287,
  title={When TPACK meets artificial intelligence: Analyzing TPACK and AI-TPACK components through structural equation modelling},
  year={2024},
  doi={10.1007/s10639-024-13164-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_288,
  title={Exploring the role of generative AI in higher education: Semi-structured interviews with students with disabilities},
  year={2024},
  doi={10.1007/s10639-024-13134-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_289,
  title={Clustered Reinforcement Learning},
  year={2024},
  doi={10.1007/s11704-024-3194-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_290,
  title={The future of cognitive strategy-enhanced persuasive dialogue agents: new perspectives and trends},
  year={2024},
  doi={10.1007/s11704-024-40057-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_291,
  title={Open and real-world human-AI coordination by heterogeneous training with communication},
  year={2024},
  doi={10.1007/s11704-024-3797-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_292,
  title={Unlocking the black box: an in-depth review on interpretability, explainability, and reliability in deep learning},
  year={2024},
  doi={10.1007/s00521-024-10437-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_293,
  title={The data dance: choreographing seamless partnerships between humans, data, and GenAI},
  year={2024},
  doi={10.1007/s41060-024-00684-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_294,
  title={Are the robots taking over? On AI and perceived existential risk},
  year={2024},
  doi={10.1007/s43681-024-00600-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_295,
  title={Robust reinforcement learning with augmented state for leveling control of multi-cylinder hydraulic system},
  year={2024},
  doi={10.1007/s11227-024-06681-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_296,
  title={How is ChatGPT acknowledged in academic publications?},
  year={2024},
  doi={10.1007/s11192-024-05193-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_297,
  title={Developing an AI literacy diagnostic tool for elementary school students},
  year={2024},
  doi={10.1007/s10639-024-13097-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_298,
  title={KD-Crowd: a knowledge distillation framework for learning from crowds},
  year={2024},
  doi={10.1007/s11704-023-3578-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_299,
  title={Towards enhancing the reproducibility of deep learning bugs: an empirical study},
  year={2024},
  doi={10.1007/s10664-024-10579-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_300,
  title={Commonsense for AI: an interventional approach to explainability and personalization},
  year={2024},
  doi={10.1007/s00146-024-02107-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_301,
  title={Enhancing IoT cyber attacks intrusion detection through GAN-based data augmentation and hybrid deep learning models for MQTT network protocol cyber attacks},
  year={2024},
  doi={10.1007/s10586-024-04752-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_302,
  title={Quantum Artificial Intelligence: A Brief Survey},
  year={2024},
  doi={10.1007/s13218-024-00871-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_303,
  title={Document-Level Event Factuality Identification via Reinforced Semantic Learning Network},
  year={2024},
  doi={10.1007/s11390-024-2655-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_304,
  title={Domain adaptation in reinforcement learning: a comprehensive and systematic study},
  year={2024},
  doi={10.1631/FITEE.2300668},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_305,
  title={The potential effects of deepfakes on news media and entertainment},
  year={2024},
  doi={10.1007/s00146-024-02072-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_306,
  title={Ethical use of artificial intelligence based tools in higher education: are future business leaders ready?},
  year={2024},
  doi={10.1007/s10639-024-13099-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_307,
  title={Unveiling the drivers of ChatGPT utilization in higher education sectors: the direct role of perceived knowledge and the mediating role of trust in ChatGPT},
  year={2024},
  doi={10.1007/s10639-024-13095-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_308,
  title={Exploring learners’ experiences and perceptions of ChatGPT as a learning tool in higher education},
  year={2024},
  doi={10.1007/s10639-024-13065-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_309,
  title={Bridging the language gap: an empirical study of bindings for open source machine learning libraries across software package ecosystems},
  year={2024},
  doi={10.1007/s10664-024-10570-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_310,
  title={XIDINTFL-VAE: XGBoost-based intrusion detection of imbalance network traffic via class-wise focal loss variational autoencoder},
  year={2024},
  doi={10.1007/s11227-024-06552-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_311,
  title={The upper bound of information diffusion in code review},
  year={2024},
  doi={10.1007/s10664-024-10442-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_312,
  title={Exploring academics' perspectives on the future implementation of ChatGPT for advancing AI-based precision education: a preliminary study in a developing country},
  year={2024},
  doi={10.1007/s11042-024-20307-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_313,
  title={What Explains Teachers’ Trust in AI in Education Across Six Countries?},
  year={2024},
  doi={10.1007/s40593-024-00433-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_314,
  title={Trustworthy human computation: a survey},
  year={2024},
  doi={10.1007/s10462-024-10974-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_315,
  title={Visualizing the knowledge mapping of artificial intelligence in education: A systematic review},
  year={2024},
  doi={10.1007/s10639-024-13076-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_316,
  title={Influencing factors on NLP technology integration in teaching: A case study in Shanghai},
  year={2024},
  doi={10.1007/s10639-024-13063-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_317,
  title={Bridging the gap between GPDR and software development: the MATERIALIST framework},
  year={2024},
  doi={10.1007/s11042-024-19923-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_318,
  title={A comprehensive review on automatic hate speech detection in the age of the transformer},
  year={2024},
  doi={10.1007/s13278-024-01361-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_319,
  title={A Monadic Second-Order Temporal Logic framework for hypergraphs},
  year={2024},
  doi={10.1007/s00521-024-10365-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_320,
  title={Enhancing DevSecOps practice with Large Language Models and Security Chaos Engineering},
  year={2024},
  doi={10.1007/s10207-024-00909-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_321,
  title={Machine learning approaches to detect, prevent and mitigate malicious insider threats: State-of-the-art review},
  year={2024},
  doi={10.1007/s11042-024-20273-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_322,
  title={Global retractions due to randomly generated content: Characterization and trends},
  year={2024},
  doi={10.1007/s11192-024-05172-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_323,
  title={Twenty-four years of empirical research on trust in AI: a bibliometric review of trends, overlooked issues, and future directions},
  year={2024},
  doi={10.1007/s00146-024-02059-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_324,
  title={Multi-trainer binary feedback interactive reinforcement learning},
  year={2024},
  doi={10.1007/s10472-024-09956-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_325,
  title={Large language models, social demography, and hegemony: comparing authorship in human and synthetic text},
  year={2024},
  doi={10.1186/s40537-024-00986-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_326,
  title={The use of multi-task learning in cybersecurity applications: a systematic literature review},
  year={2024},
  doi={10.1007/s00521-024-10436-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_327,
  title={Evolution of topics and trends in emerging research fields: multiple analyses with entity linking, Mann–Kendall test and burst methods in cloud computing},
  year={2024},
  doi={10.1007/s11192-024-05139-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_328,
  title={Decent deepfakes? Professional deepfake developers’ ethical considerations and their governance potential},
  year={2024},
  doi={10.1007/s43681-024-00542-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_329,
  title={Increasing the presence of BIPOC researchers in computational science},
  year={2024},
  doi={10.1038/s43588-024-00693-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_330,
  title={The lost data: how AI systems censor LGBTQ+ content in the name of safety},
  year={2024},
  doi={10.1038/s43588-024-00695-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_331,
  title={International governance of advancing artificial intelligence},
  year={2024},
  doi={10.1007/s00146-024-02050-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_332,
  title={A survey of deep causal models and their industrial applications},
  year={2024},
  doi={10.1007/s10462-024-10886-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_333,
  title={Data integration from traditional to big data: main features and comparisons of ETL approaches},
  year={2024},
  doi={10.1007/s11227-024-06413-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_334,
  title={Explainable Generative AI (GenXAI): a survey, conceptualization, and research agenda},
  year={2024},
  doi={10.1007/s10462-024-10916-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_335,
  title={Artificial consciousness in AI: a posthuman fallacy},
  year={2024},
  doi={10.1007/s00146-024-02061-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_336,
  title={Comparison of generative AI performance on undergraduate and postgraduate written assessments in the biomedical sciences},
  year={2024},
  doi={10.1186/s41239-024-00485-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_337,
  title={NeurDB: an AI-powered autonomous data system},
  year={2024},
  doi={10.1007/s11432-024-4125-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_338,
  title={Localizing AIED: moving beyond North–South narratives to serve contextual needs},
  year={2024},
  doi={10.1007/s00146-024-02047-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_339,
  title={Artificial intelligence for the study of human ageing: a systematic literature review},
  year={2024},
  doi={10.1007/s10489-024-05817-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_340,
  title={Universal conceptual modeling: principles, benefits, and an agenda for conceptual modeling research},
  year={2024},
  doi={10.1007/s10270-024-01207-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_341,
  title={From United Steel to Waymo: industrializing simulation},
  year={2024},
  doi={10.1007/s00146-024-02051-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_342,
  title={Navigating the metaverse: unraveling the impact of artificial intelligence—a comprehensive review and gap analysis},
  year={2024},
  doi={10.1007/s10462-024-10881-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_343,
  title={Tuning Synaptic Connections Instead of Weights by Genetic Algorithm in Spiking Policy Network},
  year={2024},
  doi={10.1007/s11633-023-1481-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_344,
  title={Artificial intelligence for literature reviews: opportunities and challenges},
  year={2024},
  doi={10.1007/s10462-024-10902-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_345,
  title={Fairness in machine learning: definition, testing, debugging, and application},
  year={2024},
  doi={10.1007/s11432-023-4060-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_346,
  title={Aspect-based sentiment analysis: approaches, applications, challenges and trends},
  year={2024},
  doi={10.1007/s10115-024-02200-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_347,
  title={“Game changer”: the AI advocacy discourse of 2023 in the US},
  year={2024},
  doi={10.1007/s00146-024-02027-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_348,
  title={Unveiling the landscape of generative artificial intelligence in education: a comprehensive taxonomy of applications, challenges, and future prospects},
  year={2024},
  doi={10.1007/s10639-024-12936-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_349,
  title={Meta-learning in Healthcare: A Survey},
  year={2024},
  doi={10.1007/s42979-024-03166-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_350,
  title={Sharing practices of software artefacts and source code for reproducible research},
  year={2024},
  doi={10.1007/s41060-024-00617-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_351,
  title={Transfer learning for Bloom’s taxonomy-based question classification},
  year={2024},
  doi={10.1007/s00521-024-10241-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_352,
  title={Blockchain, artificial intelligence, and healthcare: the tripod of future—a narrative review},
  year={2024},
  doi={10.1007/s10462-024-10873-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_353,
  title={Examining the merits of feature-specific similarity functions in the news domain using human judgments},
  year={2024},
  doi={10.1007/s11257-024-09412-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_354,
  title={Cognitive-Inspired Deep Learning Models for Aspect-Based Sentiment Analysis: A Retrospective Overview and Bibliometric Analysis},
  year={2024},
  doi={10.1007/s12559-024-10331-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_355,
  title={Advancing cybersecurity: a comprehensive review of AI-driven detection techniques},
  year={2024},
  doi={10.1186/s40537-024-00957-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_356,
  title={Advancing horizons in remote sensing: a comprehensive survey of deep learning models and applications in image classification and beyond},
  year={2024},
  doi={10.1007/s00521-024-10165-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_357,
  title={Semantic web-based propaganda text detection from social media using meta-learning},
  year={2024},
  doi={10.1007/s11761-024-00422-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_358,
  title={Securing tomorrow: a comprehensive survey on the synergy of Artificial Intelligence and information security},
  year={2024},
  doi={10.1007/s43681-024-00529-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_359,
  title={Operationalizing responsible AI principles through responsible AI capabilities},
  year={2024},
  doi={10.1007/s43681-024-00524-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_360,
  title={AI-Lab: A Framework for Introducing Generative Artificial Intelligence Tools in Computer Programming Courses},
  year={2024},
  doi={10.1007/s42979-024-03074-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_361,
  title={Skill enhancement learning with knowledge distillation},
  year={2024},
  doi={10.1007/s11432-023-4016-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_362,
  title={Enhancing intrusion detection: a hybrid machine and deep learning approach},
  year={2024},
  doi={10.1186/s13677-024-00685-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_363,
  title={Temporal analysis of computational economics: a topic modeling approach},
  year={2024},
  doi={10.1007/s41060-024-00596-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_364,
  title={Transfer learning for emotion detection in conversational text: a hybrid deep learning approach with pre-trained embeddings},
  year={2024},
  doi={10.1007/s41870-024-02027-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_365,
  title={Unfairness in AI Anti-Corruption Tools: Main Drivers and Consequences},
  year={2024},
  doi={10.1007/s11023-024-09688-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_366,
  title={Learning in games: a systematic review},
  year={2024},
  doi={10.1007/s11432-023-3955-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_367,
  title={How co-authorship affects the H-index?},
  year={2024},
  doi={10.1007/s11192-024-05088-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_368,
  title={Deep reinforcement learning-based scheduling in distributed systems: a critical review},
  year={2024},
  doi={10.1007/s10115-024-02167-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_369,
  title={A survey on the contribution of ML and DL to the detection and prevention of botnet attacks},
  year={2024},
  doi={10.1007/s40860-024-00226-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_370,
  title={Linguistics-based dialogue simulations to evaluate argumentative conversational recommender systems},
  year={2024},
  doi={10.1007/s11257-024-09403-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_371,
  title={A multifaceted survey on privacy preservation of federated learning: progress, challenges, and opportunities},
  year={2024},
  doi={10.1007/s10462-024-10766-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_372,
  title={Robust and privacy-preserving collaborative training: a comprehensive survey},
  year={2024},
  doi={10.1007/s10462-024-10797-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_373,
  title={The Use of ChatGPT in Source-Based Writing Tasks},
  year={2024},
  doi={10.1007/s40593-024-00413-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_374,
  title={Engineering recommender systems for modelling languages: concept, tool and evaluation},
  year={2024},
  doi={10.1007/s10664-024-10483-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_375,
  title={A Teleological Approach to Information Systems Design},
  year={2024},
  doi={10.1007/s11023-024-09673-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_376,
  title={An overview of computer—aided medical image classification},
  year={2024},
  doi={10.1007/s11042-024-19558-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_377,
  title={Enhancing trustworthy deep learning for image classification against evasion attacks: a systematic literature review},
  year={2024},
  doi={10.1007/s10462-024-10777-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_378,
  title={An empirical study of challenges in machine learning asset management},
  year={2024},
  doi={10.1007/s10664-024-10474-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_379,
  title={Predictive analysis visualization component in simulated data streams},
  year={2024},
  doi={10.1007/s10791-024-09447-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_380,
  title={How far are we with automated machine learning? characterization and challenges of AutoML toolkits},
  year={2024},
  doi={10.1007/s10664-024-10450-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_381,
  title={Data pipeline approaches in serverless computing: a taxonomy, review, and research trends},
  year={2024},
  doi={10.1186/s40537-024-00939-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_382,
  title={Intersection of machine learning and mobile crowdsourcing: a systematic topic-driven review},
  year={2024},
  doi={10.1007/s00779-024-01820-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_383,
  title={Towards Enhanced Energy Aware Resource Optimization for Edge Devices Through Multi-cluster Communication Systems},
  year={2024},
  doi={10.1007/s10723-024-09773-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_384,
  title={Understanding user intent modeling for conversational recommender systems: a systematic literature review},
  year={2024},
  doi={10.1007/s11257-024-09398-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_385,
  title={RA-CFGPT: Chinese financial assistant with retrieval-augmented large language model},
  year={2024},
  doi={10.1007/s11704-024-31018-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_386,
  title={Mining architectural information: A systematic mapping study},
  year={2024},
  doi={10.1007/s10664-024-10480-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_387,
  title={A decadal study on identifying latent topics and research trends in open access LIS journals using topic modeling approach},
  year={2024},
  doi={10.1007/s11192-024-05058-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_388,
  title={Examining Ethical and Social Implications of Digital Mental Health Technologies Through Expert Interviews and Sociotechnical Systems Theory},
  year={2024},
  doi={10.1007/s44206-024-00110-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_389,
  title={Comparative impact of Whatsapp chatbot technology and Glaser's teaching approaches on the academic performance of education economics students in tertiary institutions in Nigeria},
  year={2024},
  doi={10.1007/s10639-024-12780-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_390,
  title={Learning Top-K Subtask Planning Tree Based on Discriminative Representation Pretraining for Decision-making},
  year={2024},
  doi={10.1007/s11633-023-1483-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_391,
  title={Examining the moderating effect of motivation on technology acceptance of generative AI for English as a foreign language learning},
  year={2024},
  doi={10.1007/s10639-024-12763-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_392,
  title={Anticipating impacts: using large-scale scenario-writing to explore diverse implications of generative AI in the news environment},
  year={2024},
  doi={10.1007/s43681-024-00497-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_393,
  title={The ethics of using artificial intelligence in scientific research: new guidance needed for a new tool},
  year={2024},
  doi={10.1007/s43681-024-00493-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_394,
  title={A scoping review on how generative artificial intelligence transforms assessment in higher education},
  year={2024},
  doi={10.1186/s41239-024-00468-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_395,
  title={The interplay between teachers’ trust in artificial intelligence and digital competence},
  year={2024},
  doi={10.1007/s10639-024-12772-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_396,
  title={Meta-analysis on effects of artificial intelligence education in K-12 South Korean classrooms},
  year={2024},
  doi={10.1007/s10639-024-12738-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_397,
  title={Advancements in skin cancer classification: a review of machine learning techniques in clinical image analysis},
  year={2024},
  doi={10.1007/s11042-024-19298-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_398,
  title={Benchmarking Micro2Micro transformation: an approach with GNN and VAE},
  year={2024},
  doi={10.1007/s10586-024-04526-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_399,
  title={A survey on imbalanced learning: latest research, applications and future directions},
  year={2024},
  doi={10.1007/s10462-024-10759-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_400,
  title={Reinforcement learning-based autonomous attacker to uncover computer network vulnerabilities},
  year={2024},
  doi={10.1007/s00521-024-09668-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_401,
  title={Assessing the current landscape of AI and sustainability literature: identifying key trends, addressing gaps and challenges},
  year={2024},
  doi={10.1186/s40537-024-00912-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_402,
  title={ChatGPT Needs SPADE (Sustainability, PrivAcy, Digital divide, and Ethics) Evaluation: A Review},
  year={2024},
  doi={10.1007/s12559-024-10285-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_403,
  title={Patterns of multi-container composition for service orchestration with Docker Compose},
  year={2024},
  doi={10.1007/s10664-024-10462-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_404,
  title={Enabling Configurable Workflows in Smart Environments with Knowledge-based Process Fragment Reuse},
  year={2024},
  doi={10.1007/s10723-024-09763-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_405,
  title={Research trends in deep learning and machine learning for cloud computing security},
  year={2024},
  doi={10.1007/s10462-024-10776-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_406,
  title={The Duo of Visual Servoing and Deep Learning-Based Methods for Situation-Aware Disaster Management: A Comprehensive Review},
  year={2024},
  doi={10.1007/s12559-024-10290-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_407,
  title={Policy advice and best practices on bias and fairness in AI},
  year={2024},
  doi={10.1007/s10676-024-09746-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_408,
  title={Beyond digital literacy: The era of AI-powered assistants and evolving user skills},
  year={2024},
  doi={10.1007/s10639-024-12694-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_409,
  title={Understanding adversarial attacks on observations in deep reinforcement learning},
  year={2024},
  doi={10.1007/s11432-021-3688-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_410,
  title={A review of nature-inspired algorithms on single-objective optimization problems from 2019 to 2023},
  year={2024},
  doi={10.1007/s10462-024-10747-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_411,
  title={Tackling AI Hyping},
  year={2024},
  doi={10.1007/s43681-024-00481-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_412,
  title={Mechanism design for public projects via three machine learning based approaches},
  year={2024},
  doi={10.1007/s10458-024-09647-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_413,
  title={Crossing the principle–practice gap in AI ethics with ethical problem-solving},
  year={2024},
  doi={10.1007/s43681-024-00469-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_414,
  title={Intrusion detection systems for IoT based on bio-inspired and machine learning techniques: a systematic review of the literature},
  year={2024},
  doi={10.1007/s10586-024-04388-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_415,
  title={Widen the debate: What is the academic community’s perception on ChatGPT?},
  year={2024},
  doi={10.1007/s10639-024-12677-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_416,
  title={Facial Expression Recognition Using Machine Learning and Deep Learning Techniques: A Systematic Review},
  year={2024},
  doi={10.1007/s42979-024-02792-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_417,
  title={Enhancing academic performance prediction with temporal graph networks for massive open online courses},
  year={2024},
  doi={10.1186/s40537-024-00918-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_418,
  title={From applied ethics and ethical principles to virtue and narrative in AI practices},
  year={2024},
  doi={10.1007/s43681-024-00472-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_419,
  title={The obscure politics of artificial intelligence: a Marxian socio-technical critique of the AI alignment problem thesis},
  year={2024},
  doi={10.1007/s43681-024-00476-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_420,
  title={Exploring contactless techniques in multimodal emotion recognition: insights into diverse applications, challenges, solutions, and prospects},
  year={2024},
  doi={10.1007/s00530-024-01302-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_421,
  title={Applying the ethics of AI: a systematic review of tools for developing and assessing AI-based systems},
  year={2024},
  doi={10.1007/s10462-024-10740-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_422,
  title={Unraveling minds in the digital era: a review on mapping mental health disorders through machine learning techniques using online social media},
  year={2024},
  doi={10.1007/s13278-024-01205-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_423,
  title={Augmenting morality through ethics education: the ACTWith model},
  year={2024},
  doi={10.1007/s00146-024-01864-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_424,
  title={Exploring Iranian english as a foreign language teachers’ acceptance of ChatGPT in english language teaching: Extending the technology acceptance model},
  year={2024},
  doi={10.1007/s10639-024-12660-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_425,
  title={WalletRadar: towards automating the detection of vulnerabilities in browser-based cryptocurrency wallets},
  year={2024},
  doi={10.1007/s10515-024-00430-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_426,
  title={On the computational complexity of ethics: moral tractability for minds and machines},
  year={2024},
  doi={10.1007/s10462-024-10732-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_427,
  title={AI statecraft heating-up: the automation of governance through Canada’s Chinook case study},
  year={2024},
  doi={10.1007/s00146-024-01903-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_428,
  title={Responsible automatically processable regulation},
  year={2024},
  doi={10.1007/s00146-024-01901-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_429,
  title={Cybernetic governance: implications of technology convergence on governance convergence},
  year={2024},
  doi={10.1007/s10676-024-09763-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_430,
  title={Improving requirements completeness: automated assistance through large language models},
  year={2024},
  doi={10.1007/s00766-024-00416-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_431,
  title={A survey on large language model based autonomous agents},
  year={2024},
  doi={10.1007/s11704-024-40231-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_432,
  title={Analysing the impact of ChatGPT in research},
  year={2024},
  doi={10.1007/s10489-024-05298-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_433,
  title={Predicting the impact of internet usage on students’ academic performance using machine learning techniques in Bangladesh perspective},
  year={2024},
  doi={10.1007/s13278-024-01234-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_434,
  title={Use case cards: a use case reporting framework inspired by the European AI Act},
  year={2024},
  doi={10.1007/s10676-024-09757-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_435,
  title={A systematic review and research challenges on phishing cyberattacks from an electroencephalography and gaze-based perspective},
  year={2024},
  doi={10.1007/s00779-024-01794-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_436,
  title={Ethical and preventive legal technology},
  year={2024},
  doi={10.1007/s43681-023-00413-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_437,
  title={A model-based reference architecture for complex assistive systems and its application},
  year={2024},
  doi={10.1007/s10270-024-01157-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_438,
  title={Enhancing Multi-agent Coordination via Dual-channel Consensus},
  year={2024},
  doi={10.1007/s11633-023-1464-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_439,
  title={Dynamic difficulty adjustment approaches in video games: a systematic literature review},
  year={2024},
  doi={10.1007/s11042-024-18768-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_440,
  title={From understanding diseases to drug design: can artificial intelligence bridge the gap?},
  year={2024},
  doi={10.1007/s10462-024-10714-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_441,
  title={Trust, artificial intelligence and software practitioners: an interdisciplinary agenda},
  year={2024},
  doi={10.1007/s00146-024-01882-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_442,
  title={Ethics in the Governance of Data and Digital Technology: An Analysis of European Data Regulations and Policies},
  year={2024},
  doi={10.1007/s44206-024-00101-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_443,
  title={Pioneering automated vulnerability detection for smart contracts in blockchain using KEVM: Guardian ADRGAN},
  year={2024},
  doi={10.1007/s10207-024-00817-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_444,
  title={Embracing the future of Artificial Intelligence in the classroom: the relevance of AI literacy, prompt engineering, and critical thinking in modern education},
  year={2024},
  doi={10.1186/s41239-024-00448-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_445,
  title={AI hype as a cyber security risk: the moral responsibility of implementing generative AI in business},
  year={2024},
  doi={10.1007/s43681-024-00443-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_446,
  title={Exploring ChatGPT and its impact on society},
  year={2024},
  doi={10.1007/s43681-024-00435-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_447,
  title={Unlabeled learning algorithms and operations: overview and future trends in defense sector},
  year={2024},
  doi={10.1007/s10462-023-10692-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_448,
  title={Ethical governance of artificial intelligence for defence: normative tradeoffs for principle to practice guidance},
  year={2024},
  doi={10.1007/s00146-024-01866-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_449,
  title={Debugging convergence problems in probabilistic programs via program representation learning with SixthSense},
  year={2024},
  doi={10.1007/s10009-024-00737-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_450,
  title={How to design an AI ethics board},
  year={2024},
  doi={10.1007/s43681-023-00409-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_451,
  title={TAI-PRM: trustworthy AI—project risk management framework towards Industry 5.0},
  year={2024},
  doi={10.1007/s43681-023-00417-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_452,
  title={Constructing a teacher portrait for the artificial intelligence age based on the micro ecological system theory: A systematic review},
  year={2024},
  doi={10.1007/s10639-024-12513-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_453,
  title={How AI hype impacts the LGBTQ + community},
  year={2024},
  doi={10.1007/s43681-024-00423-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_454,
  title={A knowledge compilation perspective on queries and transformations for belief tracking},
  year={2024},
  doi={10.1007/s10472-023-09908-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_455,
  title={Diversity and language technology: how language modeling bias causes epistemic injustice},
  year={2024},
  doi={10.1007/s10676-023-09742-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_456,
  title={The sociotechnical entanglement of AI and values},
  year={2024},
  doi={10.1007/s00146-023-01852-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_457,
  title={A survey on model-based reinforcement learning},
  year={2024},
  doi={10.1007/s11432-022-3696-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_458,
  title={A disk I/O optimized system for concurrent graph processing jobs},
  year={2024},
  doi={10.1007/s11704-023-2361-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_459,
  title={Customer satisfaction analysis with Saudi Arabia mobile banking apps: a hybrid approach using text mining and predictive learning techniques},
  year={2024},
  doi={10.1007/s00521-023-09400-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_460,
  title={The deep learning applications in IoT-based bio- and medical informatics: a systematic literature review},
  year={2024},
  doi={10.1007/s00521-023-09366-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_461,
  title={An Empirical Study on Google Research Football Multi-agent Scenarios},
  year={2024},
  doi={10.1007/s11633-023-1426-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_462,
  title={Distributed Deep Reinforcement Learning: A Survey and a Multi-player Multi-agent Learning Toolbox},
  year={2024},
  doi={10.1007/s11633-023-1454-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_463,
  title={Mapping Insights from News Articles to Tackle Low Birth Rate and Parenthood in Finland},
  year={2024},
  doi={10.1007/s42979-023-02492-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_464,
  title={Multi-modal visual tracking: Review and experimental comparison},
  year={2024},
  doi={10.1007/s41095-023-0345-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_465,
  title={What is an app store? The software engineering perspective},
  year={2024},
  doi={10.1007/s10664-023-10362-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_466,
  title={Introduction to Session-Based Recommender Systems},
  year={2024},
  doi={10.1007/978-3-031-42559-2_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_467,
  title={Bias and the Web},
  year={2024},
  doi={10.1007/978-3-031-45304-5_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_468,
  title={Introduction to Computer Network Vulnerabilities},
  year={2024},
  doi={10.1007/978-3-031-47549-8_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_469,
  title={Standardization and Security Criteria: Security Evaluation of Computer Products},
  year={2024},
  doi={10.1007/978-3-031-47549-8_16},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_470,
  title={Additional Efforts to Secure Data in Computer Networks and Beyond},
  year={2024},
  doi={10.1007/978-3-031-47549-8_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_471,
  title={Unveiling Competition Dynamics in Mobile App Markets Through User Reviews},
  year={2024},
  doi={10.1007/978-3-031-57327-9_16},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_472,
  title={In Conversation: Baker, Järvelä, & Williamson Shaffer – The Relationship Between Computational Methods and Theory in Learning Analytics},
  year={2024},
  doi={10.1007/978-3-031-60571-0_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_473,
  title={The Sensory Enrichment and Interactivity of Immersive User Experiences in the Public Sector: The Ionian Film Office Metaverse},
  year={2024},
  doi={10.1007/978-3-031-57746-8_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_474,
  title={Evolution of the Adoption of Generative AI Among Spanish Engineering Students},
  year={2024},
  doi={10.1007/978-3-031-61691-4_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_475,
  title={Is Complexity an Illusion?},
  year={2024},
  doi={10.1007/978-3-031-65572-2_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_476,
  title={A Statistical Analysis to Investigate the Factors Affecting Generative AI Use in Education and Its Impacts on Social Sustainability Using SPSS},
  year={2024},
  doi={10.1007/978-3-031-65996-6_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_477,
  title={An Investigation into the Influence of ChatGPT on Engineering Science Education: A Comparative Analysis Utilizing the 5E Pedagogical Model},
  year={2024},
  doi={10.1007/978-3-031-65691-0_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_478,
  title={CHATWISE “ChatGPT: As a High School Academic Tool for Writing, Innovation, Skills, and Education”},
  year={2024},
  doi={10.1007/978-3-031-65691-0_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_479,
  title={How to Design and Deliver Courses for Higher Education in the AI Era?},
  year={2024},
  doi={10.1007/978-3-031-65691-0_18},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_480,
  title={PCSP# Denotational Semantics with an Application in Sports Analytics},
  year={2024},
  doi={10.1007/978-3-031-67114-2_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_481,
  title={The History of AI in Thailand: Thickening Our Vision of AI by Caring for a Marginalised Actor},
  year={2024},
  doi={10.1007/978-3-031-67535-5_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_482,
  title={Ethical Governance of Emerging Digital Technologies in the Public Sector},
  year={2024},
  doi={10.1007/978-3-031-70804-6_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_483,
  title={CoastTerm: A Corpus for Multidisciplinary Term Extraction in Coastal Scientific Literature},
  year={2024},
  doi={10.1007/978-3-031-70563-2_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_484,
  title={Teaching Systematic Literature Reviews: Strategies and Best Practices},
  year={2024},
  doi={10.1007/978-3-031-71769-7_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_485,
  title={A Statistical Analysis to Investigate the Factors Affecting Generative AI Use in Education and Its Impacts on Social Sustainability Using SPSS},
  year={2024},
  doi={10.1007/978-3-031-65996-6_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_486,
  title={How to Design and Deliver Courses for Higher Education in the AI Era?},
  year={2024},
  doi={10.1007/978-3-031-65691-0_18},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_487,
  title={PCSP# Denotational Semantics with an Application in Sports Analytics},
  year={2024},
  doi={10.1007/978-3-031-67114-2_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_488,
  title={Teaching Strategies for Programming in Massive University Settings},
  year={2024},
  doi={10.1007/978-3-031-62245-8_23},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_489,
  title={LLM-Assistance for Quality Control of LLM Output},
  year={2024},
  doi={10.1007/978-3-031-71333-0_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_490,
  title={Unveiling Competition Dynamics in Mobile App Markets Through User Reviews},
  year={2024},
  doi={10.1007/978-3-031-57327-9_16},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_491,
  title={What Are Large Language Models?},
  year={2024},
  doi={10.1007/979-8-8688-0540-0_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_492,
  title={Self-Management},
  year={2024},
  doi={10.1007/979-8-8688-0995-8_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_493,
  title={A Melting Pot of Evolution and Learning},
  year={2024},
  doi={10.1007/978-981-99-8413-8_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_494,
  title={Generative AI Consulting},
  year={2024},
  doi={10.1007/979-8-8688-0318-5_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_495,
  title={Glimpses of a Digital Mind},
  year={2024},
  doi={10.1007/979-8-8688-0911-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_496,
  title={An Introduction to Generative AI},
  year={2024},
  doi={10.1007/979-8-8688-0917-0_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_497,
  title={Capturing Teachers’ Collaborative Talk Patterns in an Interdisciplinary Lesson Study: A Social Epistemic Network Signature Approach},
  year={2024},
  doi={10.1007/978-981-97-4442-8_26},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_498,
  title={Insider Threat Defense Strategies: Survey and Knowledge Integration},
  year={2024},
  doi={10.1007/978-981-97-5489-2_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_499,
  title={Introduction to Digital Twin Technologies in Transportation Infrastructure Management (TIM)},
  year={2024},
  doi={10.1007/978-981-99-5804-7_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_500,
  title={Taking on New Challenges},
  year={2024},
  doi={10.1007/978-981-97-0771-3_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_501,
  title={Are We in Control?},
  year={2024},
  doi={10.1007/978-3-031-45304-5_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_502,
  title={Computer and Network Forensics},
  year={2024},
  doi={10.1007/978-3-031-47549-8_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_503,
  title={AI and Ethics: Embedding Good Aspects of AI},
  year={2024},
  doi={10.1007/978-3-031-47594-8_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_504,
  title={Deep Generative Session-Based Recommender System},
  year={2024},
  doi={10.1007/978-3-031-42559-2_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_505,
  title={Taking on New Challenges},
  year={2024},
  doi={10.1007/978-981-97-0771-3_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_506,
  title={Struggles for the Next Step During the 1980 and 1990s},
  year={2024},
  doi={10.1007/978-981-97-0771-3_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_507,
  title={Prospects for Hybrid AI},
  year={2024},
  doi={10.1007/978-3-662-68290-6_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_508,
  title={Enabling Social Demography Research Using Semantic Technologies},
  year={2024},
  doi={10.1007/978-3-031-60635-9_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_509,
  title={Dilemmas and Path Exploration in the Development of Educational Digital Transformation},
  year={2024},
  doi={10.1007/978-3-031-60904-6_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_510,
  title={Toward Guiding Students: Exploring Effective Approaches for Utilizing AI Tools in Programming Courses},
  year={2024},
  doi={10.1007/978-3-031-55642-5_16},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_511,
  title={Neuro-Symbolic AI + Agent Systems: A First Reflection on Trends, Opportunities and Challenges},
  year={2024},
  doi={10.1007/978-3-031-56255-6_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_512,
  title={Research on the Application Trend of Scenario Theory in the Field of Intelligent Product Innovation},
  year={2024},
  doi={10.1007/978-3-031-61362-3_17},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_513,
  title={Accelerating Product Success: Designing a Digital Adoption Framework to Elevate Developer Experiences},
  year={2024},
  doi={10.1007/978-3-031-50192-0_24},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_514,
  title={Learning Optimal Policies},
  year={2024},
  doi={10.1007/978-3-031-50605-5_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_515,
  title={AI and Its Opportunities, Challenges and Risks},
  year={2024},
  doi={10.1007/978-3-031-50605-5_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_516,
  title={The Object is the Process: Computer Art Exhibitions of the 1970s in London and Edinburgh},
  year={2024},
  doi={10.1007/978-3-031-50620-8_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_517,
  title={Developments in Artificial Intelligence and Linguistics},
  year={2024},
  doi={10.1007/978-3-031-51004-5_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_518,
  title={Learning from Experience},
  year={2024},
  doi={10.1007/978-3-031-64832-8_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_519,
  title={Automated Topic Exploration in a Cultural Heritage Corpus},
  year={2024},
  doi={10.1007/978-3-031-65990-4_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_520,
  title={Introduction},
  year={2024},
  doi={10.1007/978-3-031-69366-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_521,
  title={Deep Generative Session-Based Recommender System},
  year={2024},
  doi={10.1007/978-3-031-42559-2_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_522,
  title={Are We in Control?},
  year={2024},
  doi={10.1007/978-3-031-45304-5_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_523,
  title={AI and Ethics: Embedding Good Aspects of AI},
  year={2024},
  doi={10.1007/978-3-031-47594-8_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_524,
  title={Computer and Network Forensics},
  year={2024},
  doi={10.1007/978-3-031-47549-8_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_525,
  title={Enabling Social Demography Research Using Semantic Technologies},
  year={2024},
  doi={10.1007/978-3-031-60635-9_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_526,
  title={Automated Topic Exploration in a Cultural Heritage Corpus},
  year={2024},
  doi={10.1007/978-3-031-65990-4_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_527,
  title={Toward Guiding Students: Exploring Effective Approaches for Utilizing AI Tools in Programming Courses},
  year={2024},
  doi={10.1007/978-3-031-55642-5_16},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_528,
  title={Introduction},
  year={2024},
  doi={10.1007/978-3-031-69366-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_529,
  title={Scp-bp Framework: Situational Crime Prevention for Managing Data Breaches in Business Processes},
  year={2024},
  doi={10.1007/978-3-031-70396-6_26},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_530,
  title={Research on the Application Trend of Scenario Theory in the Field of Intelligent Product Innovation},
  year={2024},
  doi={10.1007/978-3-031-61362-3_17},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_531,
  title={Dilemmas and Path Exploration in the Development of Educational Digital Transformation},
  year={2024},
  doi={10.1007/978-3-031-60904-6_21},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_532,
  title={Neuro-Symbolic AI + Agent Systems: A First Reflection on Trends, Opportunities and Challenges},
  year={2024},
  doi={10.1007/978-3-031-56255-6_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_533,
  title={Evaluating Privacy Patterns Within Collaborative Frameworks for AI Ecosystem Development},
  year={2024},
  doi={10.1007/978-3-031-71739-0_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_534,
  title={Learning from Experience},
  year={2024},
  doi={10.1007/978-3-031-64832-8_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_535,
  title={Teaching Mining Software Repositories},
  year={2024},
  doi={10.1007/978-3-031-71769-7_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_536,
  title={Data Hiding Techniques in Windows},
  year={2024},
  doi={10.1007/979-8-8688-0193-8_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_537,
  title={Technical Discipline},
  year={2024},
  doi={10.1007/979-8-8688-0995-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_538,
  title={Dawn of Tomorrow: Embracing AI’s Transformative Journey},
  year={2024},
  doi={10.1007/979-8-8688-0911-8_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_539,
  title={Software Optimization for Generative AI},
  year={2024},
  doi={10.1007/979-8-8688-0917-0_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_540,
  title={AI and Academia},
  year={2024},
  doi={10.1007/979-8-8688-0400-7_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_541,
  title={Large Language Model Based Intelligent Interaction for Digital Human},
  year={2024},
  doi={10.1007/978-981-97-5678-0_18},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_542,
  title={How to Design Scientific, Happy and Effective Educational Games: Research on Educational Game Design from the Perspective of Learning Sciences},
  year={2024},
  doi={10.1007/978-981-97-4442-8_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_543,
  title={Reconcile Using Generative AI},
  year={2024},
  doi={10.1007/979-8-8688-1061-9_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_544,
  title={Artificial Intelligence and Machine Learning in Cybersecurity},
  year={2024},
  doi={10.1007/979-8-8688-0297-3_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_545,
  title={Upgrading the Application and Routers},
  year={2024},
  doi={10.1007/979-8-8688-0391-8_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_546,
  title={Roadmap for AI Implementation in BFSI},
  year={2024},
  doi={10.1007/979-8-8688-0559-2_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_547,
  title={Unveiling the Decision-Making Process in Reinforcement Learning with Genetic Programming},
  year={2024},
  doi={10.1007/978-981-97-7181-3_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_548,
  title={Lessons Learnt, Outlook, and Conclusions},
  year={2024},
  doi={10.1007/978-3-031-54158-2_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_549,
  title={Business and Ethical Concerns in Domestic Conversational Generative AI-Empowered Multi-robot Systems},
  year={2024},
  doi={10.1007/978-3-031-53227-6_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_550,
  title={Towards a Business Case for AI Ethics},
  year={2024},
  doi={10.1007/978-3-031-53227-6_17},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_551,
  title={Language Ideology Bias in Conversational Technology},
  year={2024},
  doi={10.1007/978-3-031-54975-5_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_552,
  title={Artificial Intelligence in E-Commerce},
  year={2024},
  doi={10.1007/978-3-031-55225-0_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_553,
  title={The Role of Human-Centered AI in User Modeling, Adaptation, and Personalization—Models, Frameworks, and Paradigms},
  year={2024},
  doi={10.1007/978-3-031-55109-3_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_554,
  title={NLP Applications—Social Media},
  year={2024},
  doi={10.1007/978-3-031-55865-8_14},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_555,
  title={Applications, Challenges and Early Assessment of AI and ChatGPT in Education},
  year={2024},
  doi={10.1007/978-3-031-65996-6_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_556,
  title={Governance-Focused Classification of Security and Privacy Requirements from Obligations in Software Engineering Contracts},
  year={2024},
  doi={10.1007/978-3-031-57327-9_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_557,
  title={Digital Cultural Heritage Preservation},
  year={2024},
  doi={10.1007/978-3-031-66320-8_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_558,
  title={Computer Network Security Fundamentals},
  year={2024},
  doi={10.1007/978-3-031-47549-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_559,
  title={Cryptography},
  year={2024},
  doi={10.1007/978-3-031-47549-8_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_560,
  title={Work in a New World},
  year={2024},
  doi={10.1007/978-3-031-45304-5_34},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_561,
  title={Value-Sensitive Software Design: Ethical Deliberation in Agile Development Processes},
  year={2024},
  doi={10.1007/978-3-031-45304-5_22},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_562,
  title={Social Sustainability Approaches for Software Development: A Systematic Literature Review},
  year={2024},
  doi={10.1007/978-3-031-49266-2_33},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_563,
  title={Text Clustering},
  year={2024},
  doi={10.1007/978-3-031-51917-8_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_564,
  title={Spontaneous Theory of Mind for Artificial Intelligence},
  year={2024},
  doi={10.1007/978-3-031-60405-8_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_565,
  title={Research Design Canvas},
  year={2024},
  doi={10.1007/978-3-031-60533-8_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_566,
  title={PAKT: Perspectivized Argumentation Knowledge Graph and Tool for Deliberation Analysis},
  year={2024},
  doi={10.1007/978-3-031-63536-6_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_567,
  title={Algorithms for Learning Value-Aligned Policies Considering Admissibility Relaxation},
  year={2024},
  doi={10.1007/978-3-031-58202-8_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_568,
  title={The Use of Large Language Model in Code Review Automation: An Examination of Enforcing SOLID Principles},
  year={2024},
  doi={10.1007/978-3-031-60615-1_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_569,
  title={Exploring Human-AI Collaboration in Agile: Customised LLM Meeting Assistants},
  year={2024},
  doi={10.1007/978-3-031-61154-4_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_570,
  title={Business Perspective: The Future of Intelligent Business Process Execution},
  year={2024},
  doi={10.1007/978-3-031-61343-2_23},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_571,
  title={Bie-Modernism Cultural Computing of Literary Works of “Three Musketeers of Tie Xi” Based on the Pre-trained Dialogue Models ChatGLM3},
  year={2024},
  doi={10.1007/978-3-031-61147-6_23},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_572,
  title={Bie-modernism: From Cultural Computing to Social Computing},
  year={2024},
  doi={10.1007/978-3-031-61147-6_24},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_573,
  title={Gendered Responses to AI Governance: Insights from a Quantitative National Survey on ChatGPT Usage Among Students and Educators},
  year={2024},
  doi={10.1007/978-3-031-64315-6_20},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_574,
  title={Towards Explainable Authorship Verification: An Approach to Minimise Academic Misconduct in Higher Education},
  year={2024},
  doi={10.1007/978-3-031-64315-6_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_575,
  title={America in 1920: An Information Microhistory},
  year={2024},
  doi={10.1007/978-3-031-44134-9_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_576,
  title={Integrating Cognitive Map Learning and Active Inference for Planning in Ambiguous Environments},
  year={2024},
  doi={10.1007/978-3-031-47958-8_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_577,
  title={Harnessing the Power of General-Purpose LLMs in Hardware Trojan Design},
  year={2024},
  doi={10.1007/978-3-031-61486-6_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_578,
  title={Elevating Medical Efficiency and Personalized Care Through the Integration of Artificial Intelligence and Distributed Web Systems},
  year={2024},
  doi={10.1007/978-3-031-63031-6_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_579,
  title={An In-Depth Analysis of Security and Privacy Concerns in Smart Home IoT Devices Through Expert User Interviews},
  year={2024},
  doi={10.1007/978-3-031-62918-1_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_580,
  title={Pitfalls and Triumphs of Causal AI},
  year={2024},
  doi={10.1007/978-981-97-3187-9_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_581,
  title={The Practical Concepts of Machine Learning},
  year={2024},
  doi={10.1007/978-1-4842-9801-5_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_582,
  title={The Lawfulness of Re-identification Under Data Protection Law},
  year={2024},
  doi={10.1007/978-3-031-68024-3_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_583,
  title={A Reputation System for Scientific Contributions Based on a Token Economy},
  year={2024},
  doi={10.1007/978-3-031-72437-4_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2024_584,
  title={Attainable Game-Based-Artifacts—A Introspection of the Intersection of Fun and Function},
  year={2024},
  doi={10.1007/978-3-031-30595-5_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_585,
  title={Beyond games: a systematic review of neural Monte Carlo tree search applications},
  year={2023},
  doi={10.1007/s10489-023-05240-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_586,
  title={Model gradient: unified model and policy learning in model-based reinforcement learning},
  year={2023},
  doi={10.1007/s11704-023-3150-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_587,
  title={Structural topic model-based comparative review of human pose estimation research in the United States and China},
  year={2023},
  doi={10.1007/s11042-023-17923-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_588,
  title={Who is the human in the machine? Releasing the human–machine metaphor from its cultural roots can increase innovation and equity in AI},
  year={2023},
  doi={10.1007/s43681-023-00382-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_589,
  title={Publics’ views on ethical challenges of artificial intelligence: a scoping review},
  year={2023},
  doi={10.1007/s43681-023-00387-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_590,
  title={Communication-robust multi-agent learning by adaptable auxiliary multi-agent adversary generation},
  year={2023},
  doi={10.1007/s11704-023-2733-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_591,
  title={A survey of aspect-based sentiment analysis classification with a focus on graph neural network methods},
  year={2023},
  doi={10.1007/s11042-023-17701-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_592,
  title={Language usage analysis for EMF metamodels on GitHub},
  year={2023},
  doi={10.1007/s10664-023-10368-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_593,
  title={The impact of ChatGPT on L2 writing and expected responses: Voice from doctoral students},
  year={2023},
  doi={10.1007/s10639-023-12397-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_594,
  title={Ensuring a ‘Responsible’ AI future in India: RRI as an approach for identifying the ethical challenges from an Indian perspective},
  year={2023},
  doi={10.1007/s43681-023-00370-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_595,
  title={Modeling Digital Penetration of the Industrialized Society and its Ensuing Transfiguration},
  year={2023},
  doi={10.1007/s44206-023-00084-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_596,
  title={Uncovering Blind Spots in Education Ethics: Insights from a Systematic Literature Review on Artificial Intelligence in Education},
  year={2023},
  doi={10.1007/s40593-023-00384-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_597,
  title={Climate change characteristics and population health impact factors using deep neural network and hyperautomation mechanism},
  year={2023},
  doi={10.1007/s11227-023-05795-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_598,
  title={Fairness-aware machine learning engineering: how far are we?},
  year={2023},
  doi={10.1007/s10664-023-10402-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_599,
  title={Analyzing the impact of companies on AI research based on publications},
  year={2023},
  doi={10.1007/s11192-023-04867-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_600,
  title={Navigating in the moral landscape: analysing bias and discrimination in AI through philosophical inquiry},
  year={2023},
  doi={10.1007/s43681-023-00377-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_601,
  title={W. B. Langdon “Jaws 30”},
  year={2023},
  doi={10.1007/s10710-023-09473-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_602,
  title={AI ethics and ordoliberalism 2.0: towards a ‘Digital Bill of Rights’},
  year={2023},
  doi={10.1007/s43681-023-00367-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_603,
  title={Bringing order into the realm of Transformer-based language models for artificial intelligence and law},
  year={2023},
  doi={10.1007/s10506-023-09374-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_604,
  title={A modal approach to conscious social agents},
  year={2023},
  doi={10.1007/s10009-023-00732-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_605,
  title={Rigorous engineering of collective adaptive systems – 2nd special section},
  year={2023},
  doi={10.1007/s10009-023-00734-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_606,
  title={AI and the quest for diversity and inclusion: a systematic literature review},
  year={2023},
  doi={10.1007/s43681-023-00362-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_607,
  title={ASN: action semantics network for multiagent reinforcement learning},
  year={2023},
  doi={10.1007/s10458-023-09628-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_608,
  title={Learning discrete adaptive receptive fields for graph convolutional networks},
  year={2023},
  doi={10.1007/s11432-021-3443-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_609,
  title={Auditing of AI: Legal, Ethical and Technical Approaches},
  year={2023},
  doi={10.1007/s44206-023-00074-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_610,
  title={Multi-sensory system for UAVs detection using Bayesian inference},
  year={2023},
  doi={10.1007/s10489-023-05027-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_611,
  title={Coordinating and programming multiple ROS-based robots with X-KLAIM},
  year={2023},
  doi={10.1007/s10009-023-00727-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_612,
  title={Role of AI chatbots in education: systematic literature review},
  year={2023},
  doi={10.1186/s41239-023-00426-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_613,
  title={What do academics have to say about ChatGPT? A text mining analytics on the discussions regarding ChatGPT on research writing},
  year={2023},
  doi={10.1007/s43681-023-00354-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_614,
  title={Mapping the global evidence around the use of ChatGPT in higher education: A systematic scoping review},
  year={2023},
  doi={10.1007/s10639-023-12223-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_615,
  title={Examining deep learning’s capability to spot code smells: a systematic literature review},
  year={2023},
  doi={10.1007/s10586-023-04144-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_616,
  title={Reinvent Cloud Software Stacks for Resource Disaggregation},
  year={2023},
  doi={10.1007/s11390-023-3272-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_617,
  title={Accurate Robotic Grasp Detection with Angular Label Smoothing},
  year={2023},
  doi={10.1007/s11390-022-1458-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_618,
  title={Automated detection, categorisation and developers’ experience with the violations of honesty in mobile apps},
  year={2023},
  doi={10.1007/s10664-023-10361-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_619,
  title={Text mining of veterinary forums for epidemiological surveillance supplementation},
  year={2023},
  doi={10.1007/s13278-023-01131-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_620,
  title={Hate speech, toxicity detection in online social media: a recent survey of state of the art and opportunities},
  year={2023},
  doi={10.1007/s10207-023-00755-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_621,
  title={Investigation into the Influence of Socio-Cultural Factors on Attitudes toward Artificial Intelligence},
  year={2023},
  doi={10.1007/s10639-023-12172-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_622,
  title={Applications and Techniques of Machine Learning in Cancer Classification: A Systematic Review},
  year={2023},
  doi={10.1007/s44230-023-00041-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_623,
  title={Multilabel classification using crowdsourcing under budget constraints},
  year={2023},
  doi={10.1007/s10115-023-01973-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_624,
  title={A survey on machine and deep learning in semiconductor industry: methods, opportunities, and challenges},
  year={2023},
  doi={10.1007/s10586-023-04115-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_625,
  title={The role of ChatGPT in disrupting concepts, changing values, and challenging ethical norms: a qualitative study},
  year={2023},
  doi={10.1007/s43681-023-00338-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_626,
  title={The Power of Personalization: A Systematic Review of Personality-Adaptive Chatbots},
  year={2023},
  doi={10.1007/s42979-023-02092-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_627,
  title={On practitioners’ concerns when adopting service mesh frameworks},
  year={2023},
  doi={10.1007/s10664-023-10348-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_628,
  title={A comparison of reinforcement learning frameworks for software testing tasks},
  year={2023},
  doi={10.1007/s10664-023-10363-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_629,
  title={A survey on sentiment analysis and its applications},
  year={2023},
  doi={10.1007/s00521-023-08941-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_630,
  title={Exploring the state of the art in legal QA systems},
  year={2023},
  doi={10.1186/s40537-023-00802-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_631,
  title={Improvised progressive model based on automatic calibration of difficulty level: A practical solution of competitive-based examination},
  year={2023},
  doi={10.1007/s10639-023-12045-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_632,
  title={A systematic review of federated learning from clients’ perspective: challenges and solutions},
  year={2023},
  doi={10.1007/s10462-023-10563-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_633,
  title={Large sequence models for sequential decision-making: a survey},
  year={2023},
  doi={10.1007/s11704-023-2689-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_634,
  title={Unsupervised Dialogue State Tracking for End-to-End Task-Oriented Dialogue with a Multi-Span Prediction Network},
  year={2023},
  doi={10.1007/s11390-021-1064-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_635,
  title={Platform-independent and curriculum-oriented intelligent assistant for higher education},
  year={2023},
  doi={10.1186/s41239-023-00412-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_636,
  title={Students’ voices on generative AI: perceptions, benefits, and challenges in higher education},
  year={2023},
  doi={10.1186/s41239-023-00411-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_637,
  title={CovidO: an ontology for COVID-19 metadata},
  year={2023},
  doi={10.1007/s11227-023-05509-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_638,
  title={Deep learning for the security of software-defined networks: a review},
  year={2023},
  doi={10.1007/s10586-023-04069-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_639,
  title={Quantum NETwork: from theory to practice},
  year={2023},
  doi={10.1007/s11432-023-3773-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_640,
  title={Artificial Intelligence in K-12 Education: eliciting and reflecting on Swedish teachers' understanding of AI and its implications for teaching & learning},
  year={2023},
  doi={10.1007/s10639-023-11990-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_641,
  title={Exploring the evolution of interdisciplinary citation network by the colored network motifs: the case of Perovskite Materials},
  year={2023},
  doi={10.1007/s11192-023-04777-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_642,
  title={A review of natural language processing in contact centre automation},
  year={2023},
  doi={10.1007/s10044-023-01182-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_643,
  title={GREENER principles for environmentally sustainable computational science},
  year={2023},
  doi={10.1038/s43588-023-00461-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_644,
  title={Editorial for EAIT issue 7, 2023},
  year={2023},
  doi={10.1007/s10639-023-11979-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_645,
  title={Learning with ChatGPT 3.5 as a more knowledgeable other: an autoethnographic study},
  year={2023},
  doi={10.1186/s41239-023-00404-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_646,
  title={A systematic review of applications of natural language processing and future challenges with special emphasis in text-based emotion detection},
  year={2023},
  doi={10.1007/s10462-023-10509-0},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_647,
  title={Dual deep Q-learning network guiding a multiagent path planning approach for virtual fire emergency scenarios},
  year={2023},
  doi={10.1007/s10489-023-04601-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_648,
  title={VIS+AI: integrating visualization with artificial intelligence for efficient data analysis},
  year={2023},
  doi={10.1007/s11704-023-2691-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_649,
  title={A Review of Predictive and Contrastive Self-supervised Learning for Medical Images},
  year={2023},
  doi={10.1007/s11633-022-1406-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_650,
  title={A systematic analysis of deep learning methods and potential attacks in internet-of-things surfaces},
  year={2023},
  doi={10.1007/s00521-023-08634-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_651,
  title={Visibility, impact, and applications of bibliometric software tools through citation analysis},
  year={2023},
  doi={10.1007/s11192-023-04725-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_652,
  title={Dual-use implications of AI text generation},
  year={2023},
  doi={10.1007/s10676-023-09703-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_653,
  title={Breaking the traditional: a survey of algorithmic mechanism design applied to economic and complex environments},
  year={2023},
  doi={10.1007/s00521-023-08647-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_654,
  title={Deep learning techniques to detect cybersecurity attacks: a systematic mapping study},
  year={2023},
  doi={10.1007/s10664-023-10302-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_655,
  title={Interview, Building Trust in Medical AI Algorithms with Veridical Data Science},
  year={2023},
  doi={10.1007/s13218-023-00803-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_656,
  title={How can technology leverage university teaching & learning innovation? A longitudinal case study of diffusion of technology innovation from the knowledge creation perspective},
  year={2023},
  doi={10.1007/s10639-023-11780-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_657,
  title={AI ethics as subordinated innovation network},
  year={2023},
  doi={10.1007/s00146-023-01658-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_658,
  title={AiCEF: an AI-assisted cyber exercise content generation framework using named entity recognition},
  year={2023},
  doi={10.1007/s10207-023-00693-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_659,
  title={Human–agent interaction as augmentation of social intelligence},
  year={2023},
  doi={10.1007/s10015-023-00874-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_660,
  title={Deep learning modelling techniques: current progress, applications, advantages, and challenges},
  year={2023},
  doi={10.1007/s10462-023-10466-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_661,
  title={Technology enabled communication during COVID 19: analysis of tweets from top ten Indian IT companies using NVIVO},
  year={2023},
  doi={10.1007/s41870-023-01242-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_662,
  title={A systematic literature review of cyber-security data repositories and performance assessment metrics for semi-supervised learning},
  year={2023},
  doi={10.1007/s44248-023-00003-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_663,
  title={Offline Pre-trained Multi-agent Decision Transformer},
  year={2023},
  doi={10.1007/s11633-022-1383-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_664,
  title={Deterministic solution of algebraic equations in sentiment analysis},
  year={2023},
  doi={10.1007/s11042-023-15140-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_665,
  title={Trustworthy artificial intelligence in Alzheimer’s disease: state of the art, opportunities, and challenges},
  year={2023},
  doi={10.1007/s10462-023-10415-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_666,
  title={Federated learning for 6G-enabled secure communication systems: a comprehensive survey},
  year={2023},
  doi={10.1007/s10462-023-10417-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_667,
  title={Architecting decentralized control in large-scale self-adaptive systems},
  year={2023},
  doi={10.1007/s00607-023-01167-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_668,
  title={A Study of Using Synthetic Data for Effective Association Knowledge Learning},
  year={2023},
  doi={10.1007/s11633-022-1380-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_669,
  title={Trans-AI/DS: transformative, transdisciplinary and translational artificial intelligence and data science},
  year={2023},
  doi={10.1007/s41060-023-00384-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_670,
  title={Trans-AI/DS: transformative, transdisciplinary and translational artificial intelligence and data science},
  year={2023},
  doi={10.1007/s41060-023-00383-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_671,
  title={Going beyond the “common suspects”: to be presumed innocent in the era of algorithms, big data and artificial intelligence},
  year={2023},
  doi={10.1007/s10506-023-09347-w},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_672,
  title={Reinforcement learning of non-additive joint steganographic embedding costs with attention mechanism},
  year={2023},
  doi={10.1007/s11432-021-3453-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_673,
  title={Beware of sustainable AI! Uses and abuses of a worthy goal},
  year={2023},
  doi={10.1007/s43681-023-00259-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_674,
  title={Guest Editorial: Intelligence for systems and software engineering},
  year={2023},
  doi={10.1007/s11334-023-00526-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_675,
  title={Soft-HGRNs: soft hierarchical graph recurrent networks for multi-agent partially observable environments},
  year={2023},
  doi={10.1631/FITEE.2200073},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_676,
  title={Reporting non-consensual pornography: clarity, efficiency and distress},
  year={2023},
  doi={10.1007/s11042-022-14291-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_677,
  title={Toward the third generation artificial intelligence},
  year={2023},
  doi={10.1007/s11432-021-3449-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_678,
  title={Trustworthy tech companies: talking the talk or walking the walk?},
  year={2023},
  doi={10.1007/s43681-022-00254-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_679,
  title={A Survey on Recent Advances and Challenges in Reinforcement Learning Methods for Task-oriented Dialogue Policy Learning},
  year={2023},
  doi={10.1007/s11633-022-1347-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_680,
  title={AI in Human-computer Gaming: Techniques, Challenges and Opportunities},
  year={2023},
  doi={10.1007/s11633-022-1384-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_681,
  title={Data collection and quality challenges in deep learning: a data-centric AI perspective},
  year={2023},
  doi={10.1007/s00778-022-00775-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_682,
  title={Democratising Tectonism: High Performance Geometry for Mass-Customisation of Virtual and Physical Spaces},
  year={2023},
  doi={10.1007/978-3-031-14160-7_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_683,
  title={Interoperable Metadata Bridges to the wider Language Technology Ecosystem},
  year={2023},
  doi={10.1007/978-3-031-17258-8_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_684,
  title={Adversarial Defense Mechanisms for Supervised Learning},
  year={2023},
  doi={10.1007/978-3-030-99772-4_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_685,
  title={Social and Ethical Issues of Data Science},
  year={2023},
  doi={10.1007/978-3-031-24758-3_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_686,
  title={Investigating Developers’ Perception on Success Factors for Research Software Development},
  year={2023},
  doi={10.1007/978-3-031-50040-4_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_687,
  title={Determining an Economic Value of High Assurance for Commodity Software Security (Transcript of Discussion)},
  year={2023},
  doi={10.1007/978-3-031-43033-6_24},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_688,
  title={Specializations in Software Engineering Education},
  year={2023},
  doi={10.1007/978-3-031-48639-5_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_689,
  title={AI Literacy: A Primary Good},
  year={2023},
  doi={10.1007/978-3-031-49002-6_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_690,
  title={From Black Boxes to Conversations: Incorporating XAI in a Conversational Agent},
  year={2023},
  doi={10.1007/978-3-031-44070-0_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_691,
  title={Deep Dive Text Analytics and Natural Language Understanding},
  year={2023},
  doi={10.1007/978-3-031-28819-7_42},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_692,
  title={Decomposing Synthesized Strategies for Reactive Multi-agent Reinforcement Learning},
  year={2023},
  doi={10.1007/978-3-031-35257-7_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_693,
  title={Language Report Catalan},
  year={2023},
  doi={10.1007/978-3-031-28819-7_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_694,
  title={Computing Education in the Age of AI-Based Assistants: Challenges and Opportunities},
  year={2023},
  doi={10.1007/978-3-031-48639-5_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_695,
  title={Demystify Artificial Intelligence},
  year={2023},
  doi={10.1007/978-981-99-1865-2_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_696,
  title={Introduction to Human and Artificial Intelligence},
  year={2023},
  doi={10.1007/978-981-99-3157-6_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_697,
  title={Risks},
  year={2023},
  doi={10.1007/978-1-4842-9852-7_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_698,
  title={ChatGPT Use Cases},
  year={2023},
  doi={10.1007/978-1-4842-9994-4_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_699,
  title={Use Cases Employing a Machine Learning Network Architecture},
  year={2023},
  doi={10.1007/978-3-031-34171-7_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_700,
  title={Introduction},
  year={2023},
  doi={10.1007/978-981-99-4823-9_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_701,
  title={Distributed Computing Continuum Systems},
  year={2023},
  doi={10.1007/978-3-031-22155-2_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_702,
  title={Strategic Research, Innovation and Implementation Agenda for Digital Language Equality in Europe by 2030},
  year={2023},
  doi={10.1007/978-3-031-28819-7_45},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_703,
  title={Awash: Prospective Story Sifting Intervention for Emergent Narrative},
  year={2023},
  doi={10.1007/978-3-031-47655-6_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_704,
  title={Navigating the Landscape of AI Ethics and Responsibility},
  year={2023},
  doi={10.1007/978-3-031-49008-8_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_705,
  title={Detecting Academic Fraud at Online Tests During COVID-19 Using Machine Learning-Based Methods},
  year={2023},
  doi={10.1007/978-3-031-36833-2_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_706,
  title={The Tower of Babel in Explainable Artificial Intelligence (XAI)},
  year={2023},
  doi={10.1007/978-3-031-40837-3_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_707,
  title={An Exploration Towards Sustainable Metaverse Systems for e-Learning by Student Designers: A Meta-analysis},
  year={2023},
  doi={10.1007/978-3-031-37126-4_33},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_708,
  title={Exploring the Potential of AI&MDL for Enhancing E-Government Services: A Review Paper},
  year={2023},
  doi={10.1007/978-3-031-39841-4_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_709,
  title={Artificial Intelligence in Manufacturing Systems},
  year={2023},
  doi={10.1007/978-3-031-21828-6_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_710,
  title={Augmenting Simulation Data with Sensor Effects for Improved Domain Transfer},
  year={2023},
  doi={10.1007/978-3-031-25075-0_52},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_711,
  title={The Advanced Course on Human-Centered AI: Learning Objectives},
  year={2023},
  doi={10.1007/978-3-031-24349-3_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_712,
  title={Knowledge Encoding and Interpretation},
  year={2023},
  doi={10.1007/978-3-031-20639-9_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_713,
  title={Intelligence in Machines},
  year={2023},
  doi={10.1007/978-3-031-15951-0_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_714,
  title={Development of a Conversational Agent for Tutoring Nursing Students to Interact with Patients},
  year={2023},
  doi={10.1007/978-3-031-32883-1_15},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_715,
  title={Congestion and Load Balancing Games with General Latency Functions},
  year={2023},
  doi={10.1007/978-3-031-30261-9_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_716,
  title={Empirical Exploration of Open-Source Issues for Predicting Privacy Compliance},
  year={2023},
  doi={10.1007/978-3-031-47112-4_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_717,
  title={Several Misconceptions and Misuses of Deep Neural Networks and Deep Learning},
  year={2023},
  doi={10.1007/978-981-99-3581-9_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_718,
  title={Introduction},
  year={2023},
  doi={10.1007/978-981-99-4823-9_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_719,
  title={Overlay Security: Email and Social Media},
  year={2023},
  doi={10.1007/978-1-4842-9560-1_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_720,
  title={Robot Motion Planning},
  year={2023},
  doi={10.1007/978-3-319-65596-3_23},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_721,
  title={ChatGPT Knows Your Attacks: Synthesizing Attack Trees Using LLMs},
  year={2023},
  doi={10.1007/978-981-99-7969-1_18},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_722,
  title={Educational Data Science Approach for an End-to-End Quality Assurance Process for Building Creditworthy Online Courses},
  year={2023},
  doi={10.1007/978-981-99-0026-8_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_723,
  title={Surmounting Obstacles for Academic Resilience: A Dynamic Portal for Supporting an Alliance of Students with Disabilities},
  year={2023},
  doi={10.1007/978-3-031-35897-5_26},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_724,
  title={Policy-Based Reinforcement Learning for Assortative Matching in Human Behavior Modeling},
  year={2023},
  doi={10.1007/978-3-031-35748-0_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_725,
  title={Will ChatGPT Get You Caught? Rethinking of Plagiarism Detection},
  year={2023},
  doi={10.1007/978-3-031-34411-4_32},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_726,
  title={The Software Heritage Open Science Ecosystem},
  year={2023},
  doi={10.1007/978-3-031-36060-2_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_727,
  title={ChatGPT in Scholarly Discourse: Sentiments and an Inflection Point},
  year={2023},
  doi={10.1007/978-3-031-39652-6_17},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_728,
  title={Another Rant About Technology},
  year={2023},
  doi={10.1007/978-3-031-31642-5_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_729,
  title={Strategic Plans and Projects in Language Technology and Artificial Intelligence},
  year={2023},
  doi={10.1007/978-3-031-28819-7_44},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_730,
  title={Towards Cognitive Bots: Architectural Research Challenges},
  year={2023},
  doi={10.1007/978-3-031-33469-6_11},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_731,
  title={Fighting the Tide—GPT and an Alarming Sense of Déjà Vu},
  year={2023},
  doi={10.1007/978-3-031-33627-0_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_732,
  title={Introduction},
  year={2023},
  doi={10.1007/978-3-031-32653-0_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_733,
  title={Empowering Learner-Centered Instruction: Integrating ChatGPT Python API and Tinker Learning for Enhanced Creativity and Problem-Solving Skills},
  year={2023},
  doi={10.1007/978-3-031-40113-8_52},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_734,
  title={Introduction to Medical Imaging Informatics},
  year={2023},
  doi={10.1007/978-3-031-47772-0_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_735,
  title={Preventing Feature Interaction with Optimization Algorithms},
  year={2023},
  doi={10.1007/978-3-031-18556-4_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_736,
  title={The Ethics of Computational Social Science},
  year={2023},
  doi={10.1007/978-3-031-16624-2_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_737,
  title={Introduction to Interpretability},
  year={2023},
  doi={10.1007/978-3-031-20639-9_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_738,
  title={Game Theoretical Adversarial Deep Learning},
  year={2023},
  doi={10.1007/978-3-030-99772-4_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_739,
  title={Overview and Application-Driven Motivations of Evolutionary Multitasking},
  year={2023},
  doi={10.1007/978-981-19-5650-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_740,
  title={The Future of AI and Ethical Implications},
  year={2023},
  doi={10.1007/978-1-4842-8998-3_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_741,
  title={Data Ethics},
  year={2023},
  doi={10.1007/978-1-4842-9642-4_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_742,
  title={Introduction to AI and Its Role in Business},
  year={2023},
  doi={10.1007/978-1-4842-9669-1_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_743,
  title={Introduction to Generative AI},
  year={2023},
  doi={10.1007/978-1-4842-9367-6_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_744,
  title={Prompt Engineering},
  year={2023},
  doi={10.1007/978-1-4842-9852-7_4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_745,
  title={Cybersecurity in Digital Transformation},
  year={2023},
  doi={10.1007/978-3-031-26845-8_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2023_746,
  title={Threats and Threat Intelligence},
  year={2023},
  doi={10.1007/978-3-031-26845-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_747,
  title={Smells in system user interactive tests},
  year={2022},
  doi={10.1007/s10664-022-10251-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_748,
  title={DRL-based and Bsld-Aware Job Scheduling for Apache Spark Cluster in Hybrid Cloud Computing Environments},
  year={2022},
  doi={10.1007/s10723-022-09630-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_749,
  title={Higher education’s influence on social networks and entrepreneurship in Brazil},
  year={2022},
  doi={10.1007/s13278-022-01011-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_750,
  title={Review on sentiment analysis for text classification techniques from 2010 to 2021},
  year={2022},
  doi={10.1007/s11042-022-14112-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_751,
  title={Generative Adversarial Networks based on optimal transport: a survey},
  year={2022},
  doi={10.1007/s10462-022-10342-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_752,
  title={The Impact of Batch Deep Reinforcement Learning on Student Performance: A Simple Act of Explanation Can Go A Long Way},
  year={2022},
  doi={10.1007/s40593-022-00312-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_753,
  title={Omission and commission errors underlying AI failures},
  year={2022},
  doi={10.1007/s00146-022-01585-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_754,
  title={Causal Reasoning Meets Visual Representation Learning: A Prospective Study},
  year={2022},
  doi={10.1007/s11633-022-1362-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_755,
  title={DD-KARB: data-driven compliance to quality by rule based benchmarking},
  year={2022},
  doi={10.1186/s40537-022-00654-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_756,
  title={Discussion on a new paradigm of endogenous security towards 6G networks},
  year={2022},
  doi={10.1631/FITEE.2200060},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_757,
  title={Systematic review of content analysis algorithms based on deep neural networks},
  year={2022},
  doi={10.1007/s11042-022-14043-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_758,
  title={Toward potential hybrid features evaluation using MLP-ANN binary classification model to tackle meaningful citations},
  year={2022},
  doi={10.1007/s11192-022-04530-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_759,
  title={Empirical research of emerging trends and patterns across the flipped classroom studies using topic modeling},
  year={2022},
  doi={10.1007/s10639-022-11396-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_760,
  title={A Blockchain-Based Architecture for Trust in Collaborative Scientific Experimentation},
  year={2022},
  doi={10.1007/s10723-022-09626-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_761,
  title={Needs and artificial intelligence},
  year={2022},
  doi={10.1007/s43681-022-00206-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_762,
  title={Experiments and Analyses of Anonymization Mechanisms for Trajectory Data Publishing},
  year={2022},
  doi={10.1007/s11390-022-2409-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_763,
  title={A field-based computing approach to sensing-driven clustering in robot swarms},
  year={2022},
  doi={10.1007/s11721-022-00215-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_764,
  title={Special Issue on Application of AI in Digital Forensics},
  year={2022},
  doi={10.1007/s13218-022-00777-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_765,
  title={A modified YOLOv4 detection method for a vision-based underwater garbage cleaning robot},
  year={2022},
  doi={10.1631/FITEE.2100473},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_766,
  title={On the principles of Parsimony and Self-consistency for the emergence of intelligence},
  year={2022},
  doi={10.1631/FITEE.2200297},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_767,
  title={Thirty years of Artificial Intelligence and Law: overviews},
  year={2022},
  doi={10.1007/s10506-022-09324-9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_768,
  title={GBGallery : A benchmark and framework for game testing},
  year={2022},
  doi={10.1007/s10664-022-10158-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_769,
  title={Cellular automata based multi-bit stuck-at fault diagnosis for resistive memory},
  year={2022},
  doi={10.1631/FITEE.2100255},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_770,
  title={Reasons and consequences of changes in Russian research assessment policies},
  year={2022},
  doi={10.1007/s11192-022-04469-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_771,
  title={Monte Carlo Tree Search: a review of recent modifications and applications},
  year={2022},
  doi={10.1007/s10462-022-10228-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_772,
  title={Conformance-oriented Predictive Process Monitoring in BPaaS Based on Combination of Neural Networks},
  year={2022},
  doi={10.1007/s10723-022-09613-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_773,
  title={“Ethically contentious aspects of artificial intelligence surveillance: a social science perspective”},
  year={2022},
  doi={10.1007/s43681-022-00196-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_774,
  title={Operationalising ethics in artificial intelligence for healthcare: a framework for AI developers},
  year={2022},
  doi={10.1007/s43681-022-00195-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_775,
  title={Constructing Explainability – Interdisciplinary Framework to Actively Shape Explanations in XAI},
  year={2022},
  doi={10.1007/s13218-022-00767-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_776,
  title={Special Issue: Iteration and persuasion as key conditions of digital societies},
  year={2022},
  doi={10.1007/s00146-022-01507-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_777,
  title={Defensive deception framework against reconnaissance attacks in the cloud with deep reinforcement learning},
  year={2022},
  doi={10.1007/s11432-021-3462-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_778,
  title={From Legal Contracts to Formal Specifications: A Systematic Literature Review},
  year={2022},
  doi={10.1007/s42979-022-01228-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_779,
  title={Assembled Bias: Beyond Transparent Algorithmic Bias},
  year={2022},
  doi={10.1007/s11023-022-09605-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_780,
  title={Fairness analysis of extra-gain guilty of a non-repudiation protocol},
  year={2022},
  doi={10.1631/FITEE.2100413},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_781,
  title={Coupling algebraic topology theory, formal methods and safety requirements toward a new coverage metric for artificial intelligence models},
  year={2022},
  doi={10.1007/s00521-022-07363-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_782,
  title={How to manage a task-oriented virtual assistant software project: an experience report},
  year={2022},
  doi={10.1631/FITEE.2100467},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_783,
  title={A survey on AI for storage},
  year={2022},
  doi={10.1007/s42514-022-00101-3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_784,
  title={Reviewer recommendation method for scientific research proposals: a case for NSFC},
  year={2022},
  doi={10.1007/s11192-022-04389-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_785,
  title={Toward few-shot domain adaptation with perturbation-invariant representation and transferable prototypes},
  year={2022},
  doi={10.1007/s11704-022-2015-7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_786,
  title={How to certify machine learning based safety-critical systems? A systematic literature review},
  year={2022},
  doi={10.1007/s10515-022-00337-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_787,
  title={Dismantling AI capitalism: the commons as an alternative to the power concentration of Big Tech},
  year={2022},
  doi={10.1007/s00146-022-01437-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_788,
  title={Extracting LPL privacy policy purposes from annotated web service source code},
  year={2022},
  doi={10.1007/s10270-022-00998-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_789,
  title={GPT-3 and InstructGPT: technological dystopianism, utopianism, and “Contextual” perspectives in AI ethics and industry},
  year={2022},
  doi={10.1007/s43681-022-00148-6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_790,
  title={An AI ethics ‘David and Goliath’: value conflicts between large tech companies and their employees},
  year={2022},
  doi={10.1007/s00146-022-01430-1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_791,
  title={Return migration of German-affiliated researchers: analyzing departure and return by gender, cohort, and discipline using Scopus bibliometric data 1996–2020},
  year={2022},
  doi={10.1007/s11192-022-04351-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_792,
  title={Generic, efficient, and effective deobfuscation and semantic-aware attack detection for PowerShell scripts},
  year={2022},
  doi={10.1631/FITEE.2000436},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_793,
  title={Evaluation of the trends in jobs and skill-sets using data analytics: a case study},
  year={2022},
  doi={10.1186/s40537-022-00576-5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_794,
  title={How to cheat on your final paper: Assigning AI for student writing},
  year={2022},
  doi={10.1007/s00146-022-01397-z},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_795,
  title={The research landscape on the artificial intelligence: a bibliometric analysis of recent 20 years},
  year={2022},
  doi={10.1007/s11042-022-12208-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_796,
  title={AI-Based Modeling: Techniques, Applications and Research Issues Towards Automation, Intelligent and Smart Systems},
  year={2022},
  doi={10.1007/s42979-022-01043-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_797,
  title={Development of novel-engineering-based maker education instructional model},
  year={2022},
  doi={10.1007/s10639-021-10841-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_798,
  title={A survey of inverse reinforcement learning},
  year={2022},
  doi={10.1007/s10462-021-10108-x},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_799,
  title={Recommendations for a smart toy parental control tool},
  year={2022},
  doi={10.1007/s11227-022-04319-4},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_800,
  title={Information Resilience: the nexus of responsible and agile approaches to information use},
  year={2022},
  doi={10.1007/s00778-021-00720-2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_801,
  title={Learning how to search: generating effective test cases through adaptive fitness function selection},
  year={2022},
  doi={10.1007/s10664-021-10048-8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_802,
  title={A survey on providing customer and public administration based services using AI: chatbot},
  year={2022},
  doi={10.1007/s11042-021-11458-y},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_803,
  title={Origins and Development of Formal Methods},
  year={2022},
  doi={10.1007/978-3-030-38800-3_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_804,
  title={Multi-agent Simulation for AI Behaviour Discovery in Operations Research},
  year={2022},
  doi={10.1007/978-3-030-94548-0_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_805,
  title={How We See Now: Traversing a Data-Mosaic},
  year={2022},
  doi={10.1007/978-3-031-03803-7_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_806,
  title={Deployment and Validation of the CS-AWARE Solution at Two Pilot Sites: A Combined Agile Software Development and Design-Based Research Approach},
  year={2022},
  doi={10.1007/978-3-031-04227-0_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_807,
  title={Contextual Use of IoT Based Water Quality Control System},
  year={2022},
  doi={10.1007/978-3-031-17968-6_16},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_808,
  title={Tackling Air Pollution in Cities with Modelling and Simulation: Remote Group Model Building as an Educational Tool Supporting System Dynamics Modelling},
  year={2022},
  doi={10.1007/978-3-031-08757-8_25},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_809,
  title={An Organizational Maturity Model forData Spaces: A Data Sharing Wheel Approach},
  year={2022},
  doi={10.1007/978-3-030-98636-0_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_810,
  title={Post-hoc Explainable Reinforcement Learning Using Probabilistic Graphical Models},
  year={2022},
  doi={10.1007/978-3-030-95502-1_28},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_811,
  title={SixthSense: Debugging Convergence Problems in Probabilistic Programs via Program Representation Learning},
  year={2022},
  doi={10.1007/978-3-030-99429-7_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_812,
  title={Background of E-Commerce},
  year={2022},
  doi={10.1007/978-981-19-6438-1_1},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_813,
  title={Tabular Value-Based Reinforcement Learning},
  year={2022},
  doi={10.1007/978-981-19-0638-1_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_814,
  title={Graph Neural Networks: Graph Transformation},
  year={2022},
  doi={10.1007/978-981-16-6054-2_12},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_815,
  title={Specification-Based Testing},
  year={2022},
  doi={10.1007/978-3-030-38800-3_5},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_816,
  title={Explainable, Interpretable, Trustworthy, Responsible, Ethical, Fair, Verifiable AI... What’s Next?},
  year={2022},
  doi={10.1007/978-3-031-15740-0_3},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_817,
  title={Automatic Simplification of Scientific Texts: SimpleText Lab at CLEF-2022},
  year={2022},
  doi={10.1007/978-3-030-99739-7_46},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_818,
  title={DyNetKAT: An Algebra of Dynamic Networks},
  year={2022},
  doi={10.1007/978-3-030-99253-8_10},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_819,
  title={Static Security Compliance Checks},
  year={2022},
  doi={10.1007/978-3-658-37665-9_8},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_820,
  title={Towards a Process Reference Model for Clinical Coding},
  year={2022},
  doi={10.1007/978-3-031-14179-9_13},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_821,
  title={The Authoring Problem is a Publishing Problem},
  year={2022},
  doi={10.1007/978-3-031-05214-9_6},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_822,
  title={Understanding Machine Learning},
  year={2022},
  doi={10.1007/978-3-030-91585-8_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_823,
  title={Ethics of Face Recognition in Smart Cities Toward Trustworthy AI},
  year={2022},
  doi={10.1007/978-3-031-04424-3_2},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_824,
  title={Where Is the AI? AI Literacy for Educators},
  year={2022},
  doi={10.1007/978-3-031-11647-6_31},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_825,
  title={Multi-Agent Reinforcement Learning},
  year={2022},
  doi={10.1007/978-981-19-0638-1_7},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_826,
  title={Interactive Media in Public Spaces:},
  year={2022},
  doi={10.1007/978-981-19-1280-1_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

@article{springer2022_827,
  title={Verification and Enforcement of Security at Run-time},
  year={2022},
  doi={10.1007/978-3-658-37665-9_9},
  publisher={Springer},
  note={Crawled from Springer RSS feed}
}

