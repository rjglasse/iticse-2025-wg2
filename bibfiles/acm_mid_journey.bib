@inproceedings{10.1145/3641555.3705277,
author = {Tsang, Jedidiah and Li, Carol and Park, Su Min and Yan, Lisa},
title = {Using LLMs to Detect the Presence of Learning Outcomes in Submitted Work Within Computing Ethics Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705277},
doi = {10.1145/3641555.3705277},
abstract = {This study investigates how large language models (LLMs) can identify the presence of learning outcomes within student submitted work in a computing ethics course. To do so, we craft a codebook to spot key learning outcomes, such as the usage of critical reasoning and awareness of various social issues. We leverage the GPT-4o and GPT-3.5-turbo LLMs to apply codes onto 8,500 pieces of student submitted work. We then use Cohen's kappa to assess interrater reliability and compare human reviewers' coding to outputs from those models, finding that GPT-4o performed just as well as the agreement between human reviewers. We then use the model outputs to identify specific course readings that students engaged particularly deeply with to better inform our computing ethics instruction.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1641–1642},
numpages = {2},
keywords = {codebook, computing ethics, critical consciousness, large language models, positionality},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701872,
author = {McDanel, Bradley and Novak, Ed},
title = {Designing LLM-Resistant Programming Assignments: Insights and Strategies for CS Educators},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701872},
doi = {10.1145/3641554.3701872},
abstract = {The rapid advancement of Large Language Models (LLMs) like ChatGPT has raised concerns among computer science educators about how programming assignments should be adapted. This paper explores the capabilities of LLMs (GPT-3.5, GPT-4, and Claude Sonnet) in solving complete, multi-part CS homework assignments from the SIGCSE Nifty Assignments list. Through qualitative and quantitative analysis, we found that LLM performance varied significantly across different assignments and models, with Claude Sonnet consistently outperforming the others. The presence of starter code and test cases improved performance for advanced LLMs, while certain assignments, particularly those involving visual elements, proved challenging for all models. LLMs often disregarded assignment requirements, produced subtly incorrect code, and struggled with context-specific tasks. Based on these findings, we propose strategies for designing LLM-resistant assignments. Our work provides insights for instructors to evaluate and adapt their assignments in the age of AI, balancing the potential benefits of LLMs as learning tools with the need to ensure genuine student engagement and learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {756–762},
numpages = {7},
keywords = {ai-resistant assignments, assignment design, cs education, llm code generation, programming pedagogy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701946,
author = {Li, Nero and Broner, Shahar and Kim, Yubin and Mizuo, Katrina and Sauder, Elijah and To, Claire and Wang, Albert and Gila, Ofek and Shindler, Michael},
title = {Investigating the Capabilities of Generative AI in Solving Data Structures, Algorithms, and Computability Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701946},
doi = {10.1145/3641554.3701946},
abstract = {There is both great hope and concern about the future of Computer Science practice and education concerning the recent advent of large language models (LLMs).We present the first study to extensively evaluate the ability of such a model to solve problems in Computer Science Theory. Specifically, we tested 165 exam-level problems across 16 specific topics related to computer science theory, ranging from preliminary data structures to algorithm design paradigms to theory of computation (automata and complexity). Our results use the recent popular models (GPT-4 and GPT-4o). This is a rapidly evolving field, with model performance continuously improving. We present our results primarily as an indication of what they can already achieve-equivalently how they can already be useful-today, fully expecting them to improve even further in the near future. Our results show that what was very recently a state-of-the-art model (GPT-4) can solve 77% of free-response problems in data structures and algorithms with little to no guidance. The latest model, GPT-4o, can solve around 46% of the Theory of Computation problems we posed, with predictable categories for which problems it could not solve. When broken down by topic, the model can solve 80% of problems in 4 out of the 15 topics and at least half in 8 other topics. Other problems, namely more visual problems, either require more substantial coaching or seem to still be beyond the capabilities of the language model--for now. By understanding the strengths and limitations of these models for solving theory problems, we can open the door to future work, ranging from human educational assessment on the topic to automated tutors for learners of the subject.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {659–665},
numpages = {7},
keywords = {algorithm design techniques, chatgpt, computational thinking, computer-assisted instruction, data structures, generative ai, gpt-4, gpt-4o, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706468.3706529,
author = {Hassany, Mohammad and Brusilovsky, Peter and Savelka, Jaromir and Lekshmi Narayanan, Arun Balajiee and Akhuseyinoglu, Kamil and Agarwal, Arav and Hendrawan, Rully Agus},
title = {Generating Effective Distractors for Introductory Programming Challenges: LLMs vs Humans},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706529},
doi = {10.1145/3706468.3706529},
abstract = {As large language models (LLMs) show great promise in generating a wide spectrum of educational materials, robust yet cost-effective assessment of the quality and effectiveness of such materials becomes an important challenge. Traditional approaches, including expert-based quality assessment and student-centered evaluation, are resource-consuming, and do not scale efficiently. In this work, we explored the use of pre-existing student learning data as a promising approach to evaluate LLM-generated learning materials. Specifically, we used a dataset where students were completing the program construction challenges by picking the correct answers among human-authored distractors to evaluate the quality of LLM-generated distractors for the same challenges. The dataset included responses from 1,071 students across 22 classes taught from Fall 2017 to Spring 2023. We evaluated five prominent LLMs (OpenAI-o1, GPT-4, GPT-4o, GPT-4o-mini, and Llama-3.1-8b) across three different prompts to see which combinations result in more effective distractors, i.e., those that are plausible (often picked by students), and potentially based on common misconceptions. Our results suggest that GPT-4o was the most effective model, matching close to 50% of the functional distractors originally authored by humans. At the same time, all of the evaluated LLMs generated many novel distractors, i.e., those that did not match the pre-existing human-authored ones. Our preliminary analysis shows that those appear to be promising. Establishing their effectiveness in real-world classroom settings is left for future work.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {484–493},
numpages = {10},
keywords = {Large Language Models (LLMs), Distractor Generation and Evaluation, Student Learning Data, Introductory Programming, GPT, LLaMA},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3680533.3697064,
author = {Feng, Tony Haoran and Denny, Paul and W\"{u}nsche, Burkhard C. and Luxton-Reilly, Andrew and Whalley, Jacqueline},
title = {An Eye for an AI: Evaluating GPT-4o's Visual Perception Skills and Geometric Reasoning Skills Using Computer Graphics Questions},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697064},
doi = {10.1145/3680533.3697064},
abstract = {CG (Computer Graphics) is a popular field of CS (Computer Science), but many students find this topic difficult due to it requiring a large number of skills, such as mathematics, programming, geometric reasoning, and creativity. Over the past few years, researchers have investigated ways to harness the power of GenAI (Generative Artificial Intelligence) to improve teaching. In CS, much of the research has focused on introductory computing. A recent study evaluating the performance of an LLM (Large Language Model), GPT-4 (text-only), on CG questions, indicated poor performance and reliance on detailed descriptions of image content, which often required considerable insight from the user to return reasonable results. So far, no studies have investigated the abilities of LMMs (Large Multimodal Models), or multimodal LLMs, to solve CG questions and how these abilities can be used to improve teaching.In this study, we construct two datasets of CG questions requiring varying degrees of visual perception skills and geometric reasoning skills, and evaluate the current state-of-the-art LMM, GPT-4o, on the two datasets. We find that although GPT-4o exhibits great potential in solving questions with visual information independently, major limitations still exist to the accuracy and quality of the generated results. We propose several novel approaches for CG educators to incorporate GenAI into CG teaching despite these limitations. We hope that our guidelines further encourage learning and engagement in CG classrooms.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {5},
numpages = {8},
keywords = {Large Language Models, LLMs, Large Multimodal Models, LMMs, Visual Language Models, VLMs, Generative Artificial Intelligence, GenAI, GPT-4, GPT-4o, Visual Perception, Geometric Reasoning, Computer Graphics, Computing Education, Evaluation, Assessment},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3649217.3653594,
author = {Azaiz, Imen and Kiesler, Natalie and Strickroth, Sven},
title = {Feedback-Generation for Programming Exercises With GPT-4},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653594},
doi = {10.1145/3649217.3653594},
abstract = {Ever since Large Language Models (LLMs) and related applications have become broadly available, several studies investigated their potential for assisting educators and supporting students in higher education. LLMs such as Codex, GPT-3.5, and GPT 4 have shown promising results in the context of large programming courses, where students can benefit from feedback and hints if provided timely and at scale. This paper explores the quality of GPT-4 Turbo's generated output for prompts containing both the programming task specification and a student's submission as input. Two assignments from an introductory programming course were selected, and GPT-4 was asked to generate feedback for 55 randomly chosen, authentic student programming submissions. The output was qualitatively analyzed regarding correctness, personalization, fault localization, and other features identified in the material. Compared to prior work and analyses of GPT-3.5, GPT-4 Turbo shows notable improvements. For example, the output is more structured and consistent. GPT-4 Turbo can also accurately identify invalid casing in student programs' output. In some cases, the feedback also includes the output of the student program. At the same time, inconsistent feedback was noted such as stating that the submission is correct but an error needs to be fixed. The present work increases our understanding of LLMs' potential, limitations, and how to integrate them into e-assessment systems, pedagogical scenarios, and instructing students who are using applications based on GPT-4.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {31–37},
numpages = {7},
keywords = {GPT-4 turbo, LLMs, assessment, benchmarking, formative feedback, introductory programming, large language models, personalized feedback},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3643795.3648389,
author = {Dingle, Adam and Krulis, Martin},
title = {Tackling Students' Coding Assignments with LLMs},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648389},
doi = {10.1145/3643795.3648389},
abstract = {State-of-the-art large language models (LLMs) have demonstrated an extraordinary ability to write computer code. This ability can be quite beneficial when integrated into an IDE to assist a programmer with basic coding. On the other hand, it may be misused by computer science students for cheating on coding tests or homework assignments. At present, knowledge about the exact capabilities and limitations of state-of-the-art LLMs is still inadequate. Furthermore, their capabilities have been changing quickly with each new release. In this paper, we present a dataset of 559 programming exercises in 10 programming languages collected from a system for evaluating coding assignments at our university. We have experimented with four well-known LLMs (GPT-3.5, GPT-4, Codey, Code Llama) and asked them to solve these assignments. The evaluation results are intriguing and provide insights into the strengths and weaknesses of the models. In particular, GPT-4 (which performed the best) is currently capable of solving 55% of all our exercises and achieved an average score of 86% on exercises from the introductory programming course (using the best of five generated solutions).},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {94–101},
numpages = {8},
keywords = {LLM, large language model, coding, programming, student assignment, teaching},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3639474.3640052,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640052},
doi = {10.1145/3639474.3640052},
abstract = {Large Language Models (LLMs) have emerged as promising tools to assist students while solving programming assignments. However, object-oriented programming (OOP), with its inherent complexity involving the identification of entities, relationships, and responsibilities, is not yet mastered by these tools. Contrary to introductory programming exercises, there exists a research gap with regard to the behavior of LLMs in OOP contexts. In this study, we experimented with three prominent LLMs - GPT-3.5, GPT-4, and Bard - to solve real-world OOP exercises used in educational settings, subsequently validating their solutions using an Automatic Assessment Tool (AAT). The findings revealed that while the models frequently achieved mostly working solutions to the exercises, they often overlooked the best practices of OOP. GPT-4 stood out as the most proficient, followed by GPT-3.5, with Bard trailing last. We advocate for a renewed emphasis on code quality when employing these models and explore the potential of pairing LLMs with AATs in pedagogical settings. In conclusion, while GPT-4 showcases promise, the deployment of these models in OOP education still mandates supervision.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {162–169},
numpages = {8},
keywords = {programming assignments, teaching, object-oriented programming, object-oriented design, OOP best practices, large language models, GPT-3, GPT-4, bard},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3641555.3705250,
author = {Akhmetov, Ildar and Prpa, Mirjana},
title = {Simulating Requirement Elicitation: Development and Evaluation of a Persona-Based Tool},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705250},
doi = {10.1145/3641555.3705250},
abstract = {We present the Requirement Elicitation Tool that leverages Large Language Model (LLM) (gpt-4o-mini) to enable simulated real-world interactions of requirements gathering from three synthetic personas. We demonstrate the use case of Computer Science (CS) students in Database Management Systems leveraging the tool to build a conceptual model and Entity-Relationship (ER) diagrams. Our preliminary findings show the potential of this tool to engage students in discovery process without providing predefined solutions and set the directions for future work.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1357–1358},
numpages = {2},
keywords = {AI persona, requirement elicitation, software engineering education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649409.3691086,
author = {Velez, Xavier},
title = {Understanding Algorithmic Problem Solving using LLMs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691086},
doi = {10.1145/3649409.3691086},
abstract = {With the rapid advancement of Large Language Models (LLMs) many instructors for Computer Science courses have begun to opt to allow students to use them as an additional educational resource but often warn that the output may be unreliable. Recent research on LLMs has demonstrated their ability to interpret commands in natural language and produce code in a variety of programming languages. However, it is not clear how well LLMs fair in tackling more complex problem set ups, like those typically seen in Algorithms courses in which students are provided natural language descriptions of an ambiguous problem and use what they learn to map the problem to an algorithmic solution. In this paper, we explore use of LLMs, such as OpenAI's GPT-4o, as tools for assisting students with complex Computer Science curricula, such as algorithmic problem solving. We specifically aim to see if using prompt refinement techniques, LLMs are capable of taking a problem statement in plain English and performing the following tasks: providing both a natural language description and code solution in the Python programming language, producing an analytical argument for the solutions correctness, and finally providing runtime analysis for the produced solution. Our experiments show that GPT-4o is well suited to solving problems like LeetCode 75 that have been seen during training, and prompt-refinement helps with those that have not been seen.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {327–328},
numpages = {2},
keywords = {GPT-4o, algorithms, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3657604.3662040,
author = {Gabbay, Hagit and Cohen, Anat},
title = {Combining LLM-Generated and Test-Based Feedback in a MOOC for Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662040},
doi = {10.1145/3657604.3662040},
abstract = {In large-scale programming courses, providing learners with immediate and effective feedback is a significant challenge. This study explores the potential of Large Language Models (LLMs) to generate feedback on code assignments and to address the gaps in Automated Test-based Feedback (ATF) tools commonly employed in programming courses. We applied dedicated metrics in a Massive Open Online Course (MOOC) on programming to assess the correctness of feedback generated by two models, GPT-3.5-turbo and GPT-4, using a reliable ATF as a benchmark. The findings point to effective error detection, yet the feedback is often inaccurate, with GPT-4 outperforming GPT-3.5-turbo. We used insights gained from the prompt practices to develop Gipy, an application for submitting course assignments and obtaining LLM-generated feedback. Learners participating in a field experiment perceived the feedback provided by Gipy as moderately valuable, while at the same time recognizing its potential to complement ATF. Given the learners' critique and their awareness of the limitations of LLM-generated feedback, the studied implementation may be able to take advantage of the best of both ATF and LLMs as feedback resources. Further research is needed to assess the impact of LLM-generated feedback on learning outcomes and explore the capabilities of more advanced models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {177–187},
numpages = {11},
keywords = {MOOC for programming, automated feedback, generative AI, large language models (LLMs), programming education},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3649217.3653554,
author = {Liu, Suqing and Yu, Zezhu and Huang, Feiran and Bulbulia, Yousef and Bergen, Andreas and Liut, Michael},
title = {Can Small Language Models With Retrieval-Augmented Generation Replace Large Language Models When Learning Computer Science?},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653554},
doi = {10.1145/3649217.3653554},
abstract = {Leveraging Large Language Models (LLMs) for personalized learning and support is becoming a promising tool in computing education. AI Assistants can help students with programming, problem-solving, converse with them to clarify course content, explain error messages to help with debugging, and much more. However, using cloud-based LLMs poses risks around data security, privacy, but also control of the overarching system.To address these concerns, we created a locally-stored Small Language Model (SLM) that leverages different Retrieval-Augmented Generation (RAG) methods to support computing students' learning. We compare one SLM (neural-chat-7b-v3 - fine-tuned version of Mistral-7B-v0.1) against two popular LLMs (gpt-3.5-turbo and gpt-4-32k) to see the viability for computing educators to use in their course(s).We use conversations from a CS1 course (N = 1,260), providing students with an AI Assistant (using gpt-3.5-turbo) to help them learn content and support problem-solving while completing their Python programming assignment. In total, we had 269 students use the AI Assistant, with a total of 1,988 questions asked. Using this real conversational data, we re-ran student questions using our novel SLM (neural-chat-7b-v3 testing nine different RAG methods) and gpt-4-32k, then compared those results against the original gpt-3.5-turbo responses. Our findings indicate that using an SLM with RAG can perform similarly, if not better, than LLMs. This shows that it is possible for computing educators to use SLMs (with RAG) in their course(s) as a tool for scalable learning, supporting content understanding and problem-solving needs, while employing their own policies on data privacy and security.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {388–393},
numpages = {6},
keywords = {computing education, conversational agent, cs1, intelligence concentration, intelligent teaching assistant, intelligent tutoring system, large language models, locally deployable ai, personalized ai agent, retrieval augmented generation, small language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626252.3630789,
author = {Liu, Mengqi and M'Hiri, Faten},
title = {Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630789},
doi = {10.1145/3626252.3630789},
abstract = {As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {743–749},
numpages = {7},
keywords = {adaptive teaching, chatgpt, cs education, gpt, llm, machine learning, novice programmers, openai, programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705125,
author = {Zhang, Shan and Meshram, Pragati Shuddhodhan and Ganapathy Prasad, Priyadharshini and Israel, Maya and Bhat, Suma},
title = {An LLM-Based Framework for Simulating, Classifying, and Correcting Students' Programming Knowledge with the SOLO Taxonomy},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705125},
doi = {10.1145/3641555.3705125},
abstract = {Novice programmers often face challenges in designing computational artifacts and fixing code errors, which can lead to task abandonment and over-reliance on external support. While research has explored effective meta-cognitive strategies to scaffold novice programmers' learning, it is essential to first understand and assess students' conceptual, procedural, and strategic/conditional programming knowledge at scale. To address this issue, we propose a three-model framework that leverages Large Language Models (LLMs) to simulate, classify, and correct student responses to programming questions based on the SOLO Taxonomy. The SOLO Taxonomy provides a structured approach for categorizing student understanding into four levels: Pre-structural, Uni-structural, Multi-structural, and Relational. Our results showed that GPT-4o achieved high accuracy in generating and classifying responses for the Relational category, with moderate accuracy in the Uni-structural and Pre-structural categories, but struggled with the Multi-structural category. The model successfully corrected responses to the Relational level. Although further refinement is needed, these findings suggest that LLMs hold significant potential for supporting computer science education by assessing programming knowledge and guiding students toward deeper cognitive engagement.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1681–1682},
numpages = {2},
keywords = {computer science education, large language model, solo taxonomy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630928,
author = {Poulsen, Seth and Sarsa, Sami and Prather, James and Leinonen, Juho and Becker, Brett A. and Hellas, Arto and Denny, Paul and Reeves, Brent N.},
title = {Solving Proof Block Problems Using Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630928},
doi = {10.1145/3626252.3630928},
abstract = {Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs.In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1063–1069},
numpages = {7},
keywords = {ai, algorithms, artificial intelligence, chatgpt, code generation, generative ai, gpt-3, gpt-4, large language models, openai, proof blocks, proofs},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630960,
author = {Nguyen, Ha and Allan, Vicki},
title = {Using GPT-4 to Provide Tiered, Formative Code Feedback},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630960},
doi = {10.1145/3626252.3630960},
abstract = {Large language models (LLMs) have shown promise in generating sensible code explanation and feedback in programming exercises. In this experience report, we discuss the process of using one of these models (OpenAI's GPT-4) to generate individualized feedback for students' Java code and pseudocode. We instructed GPT-4 to generate feedback for 113 submissions to four programming problems in an Algorithms and Data Structures class. We prompted the model with example feedback (few-shot learning) and instruction to (1) give feedback on conceptual understanding, syntax, and time complexity, and (2) suggest follow-up actions based on students' code or provide guiding questions. Overall, GPT-4 provided accurate feedback and successfully built on students' ideas in most submissions. Human evaluators (computer science instructors and tutors) rated GPT-4's hints as useful in guiding students' next steps. Model performance varied with programming problems but not submission quality. We reflect on where the model performed well and fell short, and discuss the potential of integrating LLM-generated, individualized feedback into computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {958–964},
numpages = {7},
keywords = {computer science education, feedback, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649409.3691094,
author = {Feng, Ty and Liu, Sa and Ghosal, Dipak},
title = {CourseAssist: Pedagogically Appropriate AI Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691094},
doi = {10.1145/3649409.3691094},
abstract = {The growing enrollments in computer science courses and increase in class sizes necessitate scalable, automated tutoring solutions to adequately support student learning. While Large Language Models (LLMs) like GPT-4 have demonstrated potential in assisting students through question-answering, educators express concerns over student overreliance, miscomprehension of generated code, and the risk of inaccurate answers. Rather than banning these tools outright, we advocate for a constructive approach that harnesses the capabilities of AI while mitigating potential risks. This poster introduces CourseAssist, a novel LLM-based tutoring system tailored for computer science education. Unlike generic LLM systems, CourseAssist uses retrieval-augmented generation, user intent classification, and question decomposition to align AI responses with specific course materials and learning objectives, thereby ensuring pedagogical appropriateness of LLMs in educational settings. We evaluated CourseAssist against a baseline of GPT-4 using a dataset of 50 question-answer pairs from a programming languages course, focusing on the criteria of usefulness, accuracy, and pedagogical appropriateness. Evaluation results show that CourseAssist significantly outperforms the baseline, demonstrating its potential to serve as an effective learning assistant. We have also deployed CourseAssist in 6 computer science courses at a large public R1 research university reaching over 500 students. Interviews with 20 student users show that CourseAssist improves computer science instruction by increasing the accessibility of course-specific tutoring help and shortening the feedback loop on their programming assignments. Future work will include extensive pilot testing at more universities and exploring better collaborative relationships between students, educators, and AI that improve computer science learning experiences.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {310–311},
numpages = {2},
keywords = {AI tutor, computer science education, intelligent tutoring systems, large language models, pedagogical appropriateness, question answering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3641555.3705282,
author = {\v{R}echt\'{a}\v{c}kov\'{a}, Anna and Maximova, Alexandra and Pitts, Griffin},
title = {Finding Misleading Identifiers in Novice Code Using LLMs},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705282},
doi = {10.1145/3641555.3705282},
abstract = {Clear, well-chosen names for variables and functions significantly enhance code readability and maintainability. In computer science education, teaching students to select appropriate identifiers is a critical task, especially in CS1. This study explores how large language models (LLMs) could assist in teaching this skill. While prior research has explored the use of LLMs in programming education, their precision and consistency in teaching code quality, particularly identifier selection, remains largely unexplored. For this purpose, this study investigated how well different LLMs can detect and report misleading identifiers. In a dataset of 33 code samples, we manually labeled misleading identifiers. On this dataset, we then tested five different LLMs on their ability to detect these misleading identifiers, measuring the overall accuracy, precision, recall, and f-score. Results revealed that the most successful model, GPT-4o, was able to correctly detect most of the manually flagged misleading variable names. However, it also tended to flag issues with variable identifiers in cases where the human evaluators would not, and refined prompting was not able to discourage this behavior.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1595–1596},
numpages = {2},
keywords = {automated feedback, code quality, misleading identifiers, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3657604.3664660,
author = {Nguyen, Ha and Stott, Nate and Allan, Vicki},
title = {Comparing Feedback from Large Language Models and Instructors: Teaching Computer Science at Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664660},
doi = {10.1145/3657604.3664660},
abstract = {Large language models (LLMs) can provide formative feedback in programming to help students improve the code they have written. We investigate the use of LLMs (GPT-4) to provide formative code feedback in a sophomore-level computer science (CS) course on data structures and algorithms. In three quizzes on recursion, half of the students randomly received GPT-4's feedback, while the other half received feedback from the course instructor. Students resubmitted their code based on the provided feedback. We found that students in the LLM-feedback condition scored higher in resubmissions than those receiving feedback from the instructor. Students perceived the two types of feedback as equally supportive of guiding resubmissions. We discuss the implications of using LLMs to provide formative feedback at scale in CS instruction.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {335–339},
numpages = {5},
keywords = {computer science education, feedback, large language models},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641554.3701858,
author = {Tran, Minh and Gonzalez-Maldonado, David and Zhou, Elaine and Franklin, Diana},
title = {Can GPT Help? Supporting Teachers to Brainstorm Customized Instructional Scratch Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701858},
doi = {10.1145/3641554.3701858},
abstract = {While many recent studies have explored how large language models can transform computer science instruction from the instructor perspective, they are primarily at the college level. Thus, little is known about using large language models towards curriculum development and teacher supports outside of the college setting. Given the emphasis placed on culturally responsive teaching at the K-8 level and well-documented evidence of insensitive and inaccurate language model outputs from a cultural perspective, it is imperative to perform systematic and principled research before considering their use in this setting.This paper explores the potential of teachers using large language models to brainstorm instructional Scratch projects. Specifically, we use GPT-3 to mimic structured projects from an existing computer science curriculum but situate the generated projects in different contexts/themes. We qualitatively analyze 300 project ideas generated by GPT and find 81% of the generated ideas satisfy our metrics for technical alignment and theme quality. We identify two major weaknesses: code complexity of generated projects and presence of potential insensitive elements that would require human filtering. We conclude that, while not ready as a student-facing solution, teachers could use GPT to effectively brainstorm customized instructional materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1134–1140},
numpages = {7},
keywords = {curriculum customization, k-8, large language models, scratch programming, teacher supports},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3715669.3725868,
author = {Mohamed, Suad and Ismail, Najma and Amaya Hernandez, Kimberly and Parvin, Abdullah and Oliver, Michael and Parra, Esteban},
title = {Design of An Eye-Tracking Study Towards Assessing the Impact of Generative AI Use on Code Summarization},
year = {2025},
isbn = {9798400714870},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715669.3725868},
doi = {10.1145/3715669.3725868},
abstract = {As large language models (LLMs) become more integrated into software engineering and computer science education, it is crucial to understand their impact on student learning. While recent research has explored student perceptions of generative AI, little is known about how these tools influence students’ cognitive processes during programming tasks, such as code comprehension, a valuable skill in software development and maintenance. This paper presents the design of a study that aims to investigate how computer science students interact with LLMs, such as Google’s Gemini, in the context of code summarization using eye-tracking. This study will examine differences in visual attention, fixation behaviors, and performance of students engaged in code summarization with and without AI assistance across varying experience levels.},
booktitle = {Proceedings of the 2025 Symposium on Eye Tracking Research and Applications},
articleno = {80},
numpages = {8},
keywords = {Code Summarization, Eye tracking, empirical study, code comprehension, Large Language Models, AI4SE},
location = {
},
series = {ETRA '25}
}

@inproceedings{10.1145/3626252.3630854,
author = {Neyem, Andres and Sandoval Alcocer, Juan Pablo and Mendoza, Marcelo and Centellas-Claros, Leonardo and Gonzalez, Luis A. and Paredes-Robles, Carlos},
title = {Exploring the Impact of Generative AI for StandUp Report Recommendations in Software Capstone Project Development},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630854},
doi = {10.1145/3626252.3630854},
abstract = {StandUp Reports play an important role in capstone software engineering courses, facilitating progress tracking, obstacle identification, and team collaboration. However, despite their significance, students often grapple with the challenge of creating StandUp Reports that are clear, concise, and actionable. This paper investigates the impact of the use of generative AI in producing StandUp report recommendations, aiming to assist students in enhancing the quality and effectiveness of their reports. In a semester-long capstone course, 179 students participated in 16 real-world software development projects. They submitted weekly StandUp Reports with the assistance of an AI-powered Slack, which analyzed their initial reports and provided suggestions for enhancing them using both GPT-3.5 and the early access GPT-4 API. After each submitted report, students voluntarily answered a survey about usability and suggestion preference. Furthermore, we conducted a linguistic analysis of the recommendations made by the algorithms to gauge reading ease and comprehension complexity. Our findings indicate that the AI-based recommendation system helped students improve the overall quality of their StandUp Reports throughout the semester. Students expressed a high level of satisfaction with the tool and exhibited a strong willingness to continue using it in the future. The survey reveals that students perceived a slight improvement when using GPT-4 compared to GPT-3.5. Finally, a computational linguistic analysis performed on the recommendations demonstrates that both algorithms significantly improve the alignment between the generated texts and the students' educational level, thereby improving the quality of the original texts.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {951–957},
numpages = {7},
keywords = {capstone courses, chatgpt, generative ai, large language models, software engineering education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701844,
author = {Yu, Zezhu and Liu, Suqing and Denny, Paul and Bergen, Andreas and Liut, Michael},
title = {Integrating Small Language Models with Retrieval-Augmented Generation in Computing Education: Key Takeaways, Setup, and Practical Insights},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701844},
doi = {10.1145/3641554.3701844},
abstract = {Leveraging a Large Language Model (LLM) for personalized learning in computing education is promising, yet cloud-based LLMs pose risks around data security and privacy. To address these concerns, we developed and deployed a locally stored Small Language Model (SLM) utilizing Retrieval-Augmented Generation (RAG) methods to support computing students' learning. Previous work has demonstrated that SLMs can match or surpass popular LLMs (gpt-3.5-turbo and gpt-4-32k) in handling conversational data from a CS1 course. We deployed SLMs with RAG (SLM + RAG) in a large course with more than 250 active students, fielding nearly 2,000 student questions, while evaluating data privacy, scalability, and feasibility of local deployments. This paper provides a comprehensive guide for deploying SLM + RAG systems, detailing model selection, vector database choice, embedding methods, and pipeline frameworks. We share practical insights from our deployment, including scalability concerns, accuracy versus context length trade-offs, guardrails and hallucination reduction, as well as data privacy maintenance. We address the "Impossible Triangle" in RAG systems, which states that achieving high accuracy, short context length, and low time consumption simultaneously is not feasible. Furthermore, our novel RAG framework, Intelligence Concentration (IC), categorizes information into multiple layers of abstraction within Milvus collections mitigating trade-offs and enabling educational assistants to deliver more relevant and personalized responses to students quickly.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1302–1308},
numpages = {7},
keywords = {computer science education, computing education, conversational agent, intelligence concentration, intelligent tutoring system, large language models, milvus, personalized ai agent, retrieval-augmented generation, small language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3672608.3707736,
author = {Speiser, Sebastian},
title = {Assessing the Real-World Impact of Disagreement Between Human Graders and LLMs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707736},
doi = {10.1145/3672608.3707736},
abstract = {Applying artificial intelligence models to grade student answers is a popular application. Lately Large Language Models (LLMs) have shown promising results. However, the disagreement between human graders and LLMs is often considered too large for practical adoption. In this paper, we investigate the real-world impact of this disagreement on final grades. Instead of focusing on individual answers, we simulate the grading process of an entire exam. We use an unmodified LLM (OpenAI GPT-3.5 Turbo) with one-shot prompting for grading individual answers to short answer questions from computer science courses at a German university. Our main contributions are the evaluation of the real-world impact on examination grades in contrast to correctness of individual student answers, the simulation of grading strategies common in human grading practice, and the discussion of the results in the context of observed inter-rater variabilities among human graders. The findings confirm the natural expectation that the impact of the disagreement is lower for final grades than when looking at individual answers. We quantify this effect and compare it to a grading obtained by simulating a second human grader.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {48–53},
numpages = {6},
keywords = {LLMs, programming education, automated short answer grading},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3568812.3603476,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Cambronero, Jos\'{e} and Gulwani, Sumit and Kohn, Tobias and Majumdar, Rupak and Singla, Adish and Soares, Gustavo},
title = {Generative AI for Programming Education: Benchmarking ChatGPT, GPT-4, and Human Tutors},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603476},
doi = {10.1145/3568812.3603476},
abstract = {Generative AI and large language models hold great promise in enhancing computing education by powering next-generation educational technologies. State-of-the-art models like OpenAI’s ChatGPT&nbsp;[8] and GPT-4&nbsp;[9] could enhance programming education in various roles, e.g., by acting as a personalized digital tutor for a student, a digital assistant for an educator, and a digital peer for collaborative learning&nbsp;[1, 2, 7]. In our work, we seek to comprehensively evaluate and benchmark state-of-the-art large language models for various scenarios in programming education. Recent works have evaluated several large language models in the context of programming education&nbsp;[4, 6, 10, 11, 12]. However, these works are limited for several reasons: they have typically focused on evaluating a specific model for a specific education scenario (e.g., generating explanations), or have considered models that are already outdated (e.g., OpenAI’s Codex&nbsp;[3] is no longer publicly available since March 2023). Consequently, there is a lack of systematic study that benchmarks state-of-the-art models for a comprehensive set of programming education scenarios. In our work, we systematically evaluate two models, ChatGPT (based on GPT-3.5) and GPT-4, and compare their performance with human tutors for a variety of scenarios in programming education. These scenarios are designed to capture distinct roles these models could play, namely digital tutors, assistants, and peers, as discussed above. More concretely, we consider the following six scenarios: (1) program repair, i.e., fixing a student’s buggy program; (2) hint generation, i.e., providing a natural language hint to the student to help resolve current issues; (3) grading feedback, i.e., grading a student’s program w.r.t. a given rubric; (4) peer programming, i.e., completing a partially written program or generating a sketch for the solution program; (5) task creation, i.e., generating new tasks that exercise specific types of concepts or bugs; (6) contextualized explanation, i.e., explaining specific concepts or functions in the context of a given program. Our study uses a mix of quantitative and qualitative evaluation to compare the performance of these models with the performance of human tutors. We conduct our evaluation based on 5 introductory Python programming problems with a diverse set of input/output specifications. For each of these problems, we consider 5 buggy programs based on publicly accessible submissions from geeksforgeeks.org &nbsp;[5] (see Figure&nbsp;1); these buggy programs are picked to capture different types of bugs for each problem. We will provide a detailed analysis of the data and results in a longer version of this poster. Our preliminary results show that GPT-4 drastically outperforms ChatGPT (based on GPT-3.5) and comes close to human tutors’ performance for several scenarios.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {41–42},
numpages = {2},
keywords = {ChatGPT, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3626253.3635543,
author = {Glynn, Colin and Hed, Emily and Pexa, Abbigail and Pohlmann, Tyler and Rahal, Imad and Hesse, Robert},
title = {CAET: Code Analysis and Education Tutor},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635543},
doi = {10.1145/3626253.3635543},
abstract = {The introduction of OpenAI's ChatGPT in 2022 kickstarted the release of Generative Artificial Intelligence (GAI) applications to the public domain. Such chat interfaces are based on large language models (LLMs) and possess a vast array of abilities spanning conversation, the writing and debugging of code, the writing of papers, and the creation of images, music, and songs. With students now having access to a myriad of GAI tools, academia has been permanently altered.Our proposed system, named Code Analysis and Education Tutor (CAET), integrates GAI into early Computer Science education by providing students with an ethical alternative to existing GAI tools. CAET is designed to assist students with programming tasks in a manner tailored to their individual needs without jeopardizing the integrity of their learning. A point of uniqueness from existing works is CAET's ability to display or hide generated code based on its pertinence to the problem at hand. After subjecting multiple GAI models to common programming errors and queries, we settled on OpenAI's GPT-3.5 Turbo model due to its comprehensive capabilities and cost-effectiveness. Overall, CAET underscored the model's conversational dynamics and provided insights for creating a more personalized learning experience for students in an introductory computer science course.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1656–1657},
numpages = {2},
keywords = {computer science education, generative artificial intelligence, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3639474.3640058,
author = {Lehtinen, Teemu and Koutcheme, Charles and Hellas, Arto},
title = {Let's Ask AI About Their Programs: Exploring ChatGPT's Answers To Program Comprehension Questions},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640058},
doi = {10.1145/3639474.3640058},
abstract = {Recent research has explored the creation of questions from code submitted by students. These Questions about Learners' Code (QLCs) are created through program analysis, exploring execution paths, and then creating code comprehension questions from these paths and the broader code structure. Responding to the questions requires reading and tracing the code, which is known to support students' learning. At the same time, computing education researchers have witnessed the emergence of Large Language Models (LLMs) that have taken the community by storm. Researchers have demonstrated the applicability of these models especially in the introductory programming context, outlining their performance in solving introductory programming problems and their utility in creating new learning resources. In this work, we explore the capability of the state-of-the-art LLMs (GPT-3.5 and GPT-4) in answering QLCs that are generated from code that the LLMs have created. Our results show that although the state-of-the-art LLMs can create programs and trace program execution when prompted, they easily succumb to similar errors that have previously been recorded for novice programmers. These results demonstrate the fallibility of these models and perhaps dampen the expectations fueled by the recent LLM hype. At the same time, we also highlight future research possibilities such as using LLMs to mimic students as their behavior can indeed be similar for some specific tasks.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {221–232},
numpages = {12},
keywords = {QLCs, large language models, artificial intelligence, introductory programming, program comprehension},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3568813.3600139,
author = {Hellas, Arto and Leinonen, Juho and Sarsa, Sami and Koutcheme, Charles and Kujanp\"{a}\"{a}, Lilja and Sorva, Juha},
title = {Exploring the Responses of Large Language Models to Beginner Programmers’ Help Requests},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600139},
doi = {10.1145/3568813.3600139},
abstract = {Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers’ help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students’ code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {93–105},
numpages = {13},
keywords = {CS1, GPT, OpenAI Codex, automatic feedback, help seeking, introductory programming education, large language models, student questions},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3706598.3713274,
author = {Zheng, Chanjin and Yu, Zengyi and Jiang, Yilin and Zhang, Mingzi and Lu, Xunuo and Jin, Jing and Gao, Liteng},
title = {ArtMentor: AI-Assisted Evaluation of Artworks to Explore Multimodal Large Language Models Capabilities},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713274},
doi = {10.1145/3706598.3713274},
abstract = {Can Multimodal Large Language Models (MLLMs), with capabilities in perception, recognition, understanding, and reasoning, act as independent assistants in art evaluation dialogues? Current MLLM evaluation methods, reliant on subjective human scoring or costly interviews, lack comprehensive scenario coverage. This paper proposes a process-oriented Human-Computer Interaction (HCI) space design for more accurate MLLM assessment and development. This approach aids teachers in efficient art evaluation and records interactions for MLLM capability assessment. We introduce ArtMentor, a comprehensive space integrating a dataset and three systems for optimized MLLM evaluation. It includes 380 sessions from five art teachers across nine critical dimensions. The modular system features entity recognition, review generation, and suggestion generation agents, enabling iterative upgrades. Machine learning and natural language processing ensure reliable evaluations. Results confirm GPT-4o’s effectiveness in assisting teachers in art evaluation dialogues. Our contributions are available at https://artmentor.github.io/.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {18},
keywords = {AI-Assisted Artwork Evaluation, GPT-4o, Multimodal Large Language Models, Human-Computer Interaction Dataset Design, Entity Recognition, Multi-Agent for Iterative Upgrades.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3568812.3603474,
author = {Singla, Adish},
title = {Evaluating ChatGPT and GPT-4 for Visual Programming},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603474},
doi = {10.1145/3568812.3603474},
abstract = {Generative AI has the potential to drastically improve the landscape of computing education by automatically generating personalized feedback and content. In particular, this potential lies in the advanced capabilities of state-of-the-art deep generative and large language models such as OpenAI’s Codex&nbsp;[7], ChatGPT&nbsp;[11], and GPT-4&nbsp;[12]. In our work, we seek to investigate the capabilities of these models in visual programming domains popularly used for K-8 programming education, including domains like Scratch&nbsp;[17], Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5], and Karel&nbsp;[13]. Recent works have shown us sparks of advanced capabilities of such models for various education scenarios in introductory Python programming&nbsp;[2, 14, 18, 20]. In fact, a study in 2022 had ranked Codex in the top quartile w.r.t students in a large Python programming course&nbsp;[8]. However, all these works consider only text-based Python programming and leave open the question of how well these models would perform for visual programming. The main research question is: Do state-of-the-art neural generative models show advanced capabilities for visual programming on par with their capabilities on text-based Python programming?In our work, we evaluate these models for visual programming based on the following three settings designed to capture various generative and problem-solving capabilities: We conduct our evaluation based on 10 representative tasks from two visual programming domains: Hour of Code: Maze Challenge by Code.org&nbsp;[4, 5] and Intro to Programming with Karel course by CodeHS.com&nbsp;[3, 13]. As illustrative examples, Figures&nbsp;1,&nbsp;2,&nbsp;and&nbsp;3 show the output of GPT-4 in three settings for Maze18 task. We will provide the detailed analysis and prompts used in a longer version of this poster. Our preliminary results for ChatGPT (based on GPT-3.5) and GPT-4 show that these models perform poorly and produce incorrect output the majority of the time. These results highlight that state-of-the-art neural generative models like GPT-4 still struggle to combine spatial, logical, and programming skills crucial for visual programming. As the next step, it would be important to curate novel benchmarks that the research community can use to evaluate improvements in future versions of these models for visual programming.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {14–15},
numpages = {2},
keywords = {ChatGPT, block-based visual programming, generative AI, introductory programming education, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3649165.3690101,
author = {Hellas, Arto and Leinonen, Juho and Lepp\"{a}nen, Leo},
title = {Experiences from Integrating Large Language Model Chatbots into the Classroom},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690101},
doi = {10.1145/3649165.3690101},
abstract = {We provided students access to a state-of-the-art large language model (LLM) chatbot through the online materials of three university-level courses. One of the courses focused on software engineering with LLMs, while the two other courses were not directly related to LLMs. The chatbot used OpenAI GPT-4 without additional filters or system prompts.  Our results suggest that only a minority of students engage with the chatbot in the courses that do not relate to LLMs. At the same time, unsurprisingly, nearly all students in the LLM-focused course leveraged the chatbot. In all courses, the majority of the chatbot usage came from a few superusers, whereas the majority of the students did not heavily use the chatbot even though it effectively provided free access to OpenAI's GPT-4 model (which would have otherwise required a paid subscription at the time of the study). We observe that in addition to students using the chatbot for course-specific purposes, many use the chatbot for their own purposes.  Overall, our results suggest that the worst fears of educators -- all students overrelying on chatbots -- did not materialize. Finally, we discuss potential reasons for low usage, including the need for more tailored and scaffolded chatbot experiences targeted for specific types of use cases.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {46–52},
numpages = {7},
keywords = {chatbots, classroom experiences, experience report, generative ai, large language models, usage analysis},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3636555.3636846,
author = {Phung, Tung and P\u{a}durean, Victor-Alexandru and Singh, Anjali and Brooks, Christopher and Cambronero, Jos\'{e} and Gulwani, Sumit and Singla, Adish and Soares, Gustavo},
title = {Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636846},
doi = {10.1145/3636555.3636846},
abstract = {Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4HINTS-GPT3.5VAL. As a first step, our technique leverages GPT-4 as a “tutor” model to generate hints – it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a “student” model to further validate the hint quality – it performs an automatic quality validation by simulating the potential utility of providing this feedback. We show the efficacy of our technique via extensive evaluation using three real-world datasets of Python programs covering a variety of concepts ranging from basic algorithms to regular expressions and data analysis using pandas library.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {12–23},
numpages = {12},
keywords = {ChatGPT, Feedback Generation, GPT4, Generative AI, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.5555/3712729.3712987,
author = {Shin, Jinnie and Cruz-Castro, Laura and Yang, Zhenlin and Castelblanco, Gabriel and Aggarwal, Ashish and Leite, Walter L. and Carroll, Bruce F.},
title = {Understanding Optimal Interactions between Students and a Chatbot during a Programming Task},
year = {2025},
isbn = {9798331534202},
publisher = {IEEE Press},
abstract = {This study explores integrating Large Language Models (LLMs) into computer science education by examining undergraduate interactions with a GPT-4-based chatbot during a formative assignment in an introductory course. We aim to delineate optimal help-seeking behaviors and ascertain if effective problem-navigating strategies correlate with improved learning outcomes. Using descriptive statistics and Structural Topic Modeling (STM), we analyze the types of questions posed and their connection to task completion success. Findings reveal a positive association between the number of attempts and help requests, indicating more engaged students seek assistance. STM analysis shows high-ability students address abstract concepts early, while lower-ability students focus on syntax-related issues. These insights underscore the need to evaluate interaction behaviors to optimize chatbot use in education, leading to proposed guidelines to enhance chatbot utilization, promoting responsible use and maximizing educational advantages.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {3106–3117},
numpages = {12},
location = {Orlando, Florida, USA},
series = {WSC '24}
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3632620.3671103,
author = {Logacheva, Evanfiya and Hellas, Arto and Prather, James and Sarsa, Sami and Leinonen, Juho},
title = {Evaluating Contextually Personalized Programming Exercises Created with Generative AI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671103},
doi = {10.1145/3632620.3671103},
abstract = {Programming skills are typically developed through completing various hands-on exercises. Such programming problems can be contextualized to students’ interests and cultural backgrounds. Prior research in educational psychology has demonstrated that context personalization of exercises stimulates learners’ situational interests and positively affects their engagement. However, creating a varied and comprehensive set of programming exercises for students to practice on is a time-consuming and laborious task for computer science educators. Previous studies have shown that large language models can generate conceptually and contextually relevant programming exercises. Thus, they offer a possibility to automatically produce personalized programming problems to fit students’ interests and needs. This article reports on a user study conducted in an elective introductory programming course that included contextually personalized programming exercises created with GPT-4. The quality of the exercises was evaluated by both the students and the authors. Additionally, this work investigated student attitudes towards the created exercises and their engagement with the system. The results demonstrate that the quality of exercises generated with GPT-4 was generally high. What is more, the course participants found them engaging and useful. This suggests that AI-generated programming problems can be a worthwhile addition to introductory programming courses, as they provide students with a practically unlimited pool of practice material tailored to their personal interests and educational needs.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {95–113},
numpages = {19},
keywords = {automatic exercise generation, context personalization, generative AI, large language models},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3716640.3716647,
author = {Leinonen, Juho and Denny, Paul and Kiljunen, Olli and MacNeil, Stephen and Sarsa, Sami and Hellas, Arto},
title = {LLM-itation is the Sincerest Form of Data: Generating Synthetic Buggy Code Submissions for Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716647},
doi = {10.1145/3716640.3716647},
abstract = {There is a great need for data in computing education research. Data is needed to understand how students behave, to train models of student behavior to optimally support students, and to develop and validate new assessment tools and learning analytics techniques. However, relatively few computing education datasets are shared openly, often due to privacy regulations and issues in making sure the data is anonymous. Large language models (LLMs) offer a promising approach to create large-scale, privacy-preserving synthetic data, which can be used to explore various aspects of student learning, develop and test educational technologies, and support research in areas where collecting real student data may be challenging or impractical. This work explores generating synthetic buggy code submissions for introductory programming exercises using GPT-4o. We compare the distribution of test case failures between synthetic and real student data from two courses to analyze the accuracy of the synthetic data in mimicking real student data. Our findings suggest that LLMs can be used to generate synthetic incorrect submissions that are not significantly different from real student data with regard to test case failure distributions. Our research contributes to the development of reliable synthetic datasets for computing education research and teaching, potentially accelerating progress in the field while preserving student privacy.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {56–63},
numpages = {8},
keywords = {generative AI, genAI, large language models, LLMs, GPT-4o, prompt engineering, synthetic data, bugs, submissions, data generation},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3568813.3600142,
author = {Savelka, Jaromir and Agarwal, Arav and An, Marshall and Bogart, Chris and Sakr, Majd},
title = {Thrilled by Your Progress! Large Language Models (GPT-4) No Longer Struggle to Pass Assessments in Higher Education Programming Courses},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600142},
doi = {10.1145/3568813.3600142},
abstract = {This paper studies recent developments in large language models’ (LLM) abilities to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. The emergence of ChatGPT resulted in heated debates of its potential uses (e.g., exercise generation, code explanation) as well as misuses in programming classes (e.g., cheating). Recent studies show that while the technology performs surprisingly well on diverse sets of assessment instruments employed in typical programming classes the performance is usually not sufficient to pass the courses. The release of GPT-4 largely emphasized notable improvements in the capabilities related to handling assessments originally designed for human test-takers. This study is the necessary analysis in the context of this ongoing transition towards mature generative AI systems. Specifically, we report the performance of GPT-4, comparing it to the previous generations of GPT models, on three Python courses with assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Additionally, we analyze the assessments that were not handled well by GPT-4 to understand the current limitations of the model, as well as its capabilities to leverage feedback provided by an auto-grader. We found that the GPT models evolved from completely failing the typical programming class’ assessments (the original GPT-3) to confidently passing the courses with no human involvement (GPT-4). While we identified certain limitations in GPT-4’s handling of MCQs and coding exercises, the rate of improvement across the recent generations of GPT models strongly suggests their potential to handle almost any type of assessment widely used in higher education programming courses. These findings could be leveraged by educators and institutions to adapt the design of programming assessments as well as to fuel the necessary discussions into how programming classes should be updated to reflect the recent technological developments. This study provides evidence that programming instructors need to prepare for a world in which there is an easy-to-use widely accessible technology that can be utilized by learners to collect passing scores, with no effort whatsoever, on what today counts as viable programming knowledge and skills assessments.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {78–92},
numpages = {15},
keywords = {AI code generation, AlphaCode, ChatGPT, Codex, GPT, GitHub Copilot, MCQ, Multiple-choice question answering, Python course, coding exercises, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3632620.3671097,
author = {Ali, Murtaza and Rao, Prerna and Mai, Yifan and Xie, Benjamin},
title = {Using Benchmarking Infrastructure to Evaluate LLM Performance on CS Concept Inventories: Challenges, Opportunities, and Critiques},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671097},
doi = {10.1145/3632620.3671097},
abstract = {BACKGROUND AND CONTEXT. The pace of advancement of large language models (LLMs) motivates the use of existing infrastructure to automate the evaluation of LLM performance on computing education tasks. Concept inventories are well suited for evaluation because of their careful design and prior validity evidence. OBJECTIVES. Our research explores the feasibility of using an automated benchmarking framework to evaluate computer science (CS) concept inventories. We explore three primary objectives: evaluation of LLM performance on the SCS1 and BDSI concept inventories; informal expert panel review of items which had variations between LLM and expected student performance; and description of challenges with using benchmarking infrastructure as a methodological innovation. METHOD. We used the Holistic Evaluation of Language Models (HELM) framework to evaluate the SCS1 and BDSI against 10 LLMS with zero-shot and few-shot in-context learning: GPT (3.5, 4.0), Claude (1.3, 2.0, 2.1), Llama (7B, 13B, 70B), Mistral v0.1 7B, and Mixtral 8x7B. We used psychometric data from prior studies to measure knowledge levels for each LLM run. We then conducted an informal expert review to qualitatively explore how question design, CS content knowledge, and LLM design may explain differences between LLM and expected student performances. FINDINGS. Our quantitative analysis found that most LLM response patterns reflected a below average introductory computing student with the SCS1 and did not fit the psychometric 2PL model for the BDSI. Our qualitative analysis identified that LLMs performed well on code infill questions, but poorly on nested conditionals, runtime analysis, and longer questions. We also identified several methodological challenges related to item security, translation, the structure when using HELM. IMPLICATIONS. We consider the feasibility of using automated benchmarking as a methodology to support more reproducible, replicable, and rigorous investigations to understand the intersection of LLM capabilities, computing concepts, and assessment design. We also consider connections between psychometric approaches and LLM evaluations to inform the design of computing assessments that are more resilient to LLM advancements.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {452–468},
numpages = {17},
keywords = {benchmarking, computing education, concept inventories, large language models, psychometrics},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3636243.3636263,
author = {Feng, Tony Haoran and Denny, Paul and Wuensche, Burkhard and Luxton-Reilly, Andrew and Hooper, Steffan},
title = {More Than Meets the AI: Evaluating the performance of GPT-4 on Computer Graphics assessment questions},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636263},
doi = {10.1145/3636243.3636263},
abstract = {Recent studies have showcased the exceptional performance of LLMs (Large Language Models) on assessment questions across various discipline areas. This can be helpful if used to support the learning process, for example by enabling students to quickly generate and contrast alternative solution approaches. However, concerns about student over-reliance and inappropriate use of LLMs in education are common. Understanding the capabilities of LLMs is essential for instructors to make informed decisions on question choices for learning and assessment tasks. In CS (Computer Science), previous evaluations of LLMs have focused on CS1 and CS2 questions, and little is known about how well LLMs perform for assessment questions in upper-level CS courses such as CG (Computer Graphics), which covers a wide variety of concepts and question types. To address this gap, we compiled a dataset of past assessment questions used in a final-year undergraduate course about introductory CG, and evaluated the performance of GPT-4 on this dataset. We also classified assessment questions and evaluated the performance of GPT-4 for different types of questions. We found that the performance tended to be best for simple mathematical questions, and worst for questions requiring creative thinking, and those with complex descriptions and/or images. We share our benchmark dataset with the community and provide new insights into the capabilities of GPT-4 in the context of CG courses. We highlight opportunities for teaching staff to improve student learning by guiding the use of LLMs for CG questions, and inform decisions around question choices for assessment tasks.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {182–191},
numpages = {10},
keywords = {Artificial Intelligence, Assessment, Computer Graphics, Computing Education, Evaluation, GPT-4, Large Language Models},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3545947.3569630,
author = {MacNeil, Stephen and Tran, Andrew and Leinonen, Juho and Denny, Paul and Kim, Joanne and Hellas, Arto and Bernstein, Seth and Sarsa, Sami},
title = {Automatically Generating CS Learning Materials with Large Language Models},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3569630},
doi = {10.1145/3545947.3569630},
abstract = {Recent breakthroughs in Large Language Models (LLMs), such as GPT-3 and Codex, now enable software developers to generate code based on a natural language prompt. Within computer science education, researchers are exploring the potential for LLMs to generate code explanations and programming assignments using carefully crafted prompts. These advances may enable students to interact with code in new ways while helping instructors scale their learning materials. However, LLMs also introduce new implications for academic integrity, curriculum design, and software engineering careers. This workshop will demonstrate the capabilities of LLMs to help attendees evaluate whether and how LLMs might be integrated into their pedagogy and research. We will also engage attendees in brainstorming to consider how LLMs will impact our field.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1176},
numpages = {1},
keywords = {code generation, computer science education, copilot, explanations, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3641554.3701867,
author = {Yeh, Thomas Y. and Tran, Karena and Gao, Ge and Yu, Tyler and Fong, Wai On and Chen, Tzu-Yi},
title = {Bridging Novice Programmers and LLMs with Interactivity},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701867},
doi = {10.1145/3641554.3701867},
abstract = {While Large Language Models (LLMs) enable experienced programmers to increase their productivity, LLMs' impact on learning and productivity for novices is currently unclear. Recent work showed novice programmers struggle with prompting LLMs for code generation and suggested that the use of LLMs in CS education could exacerbate existing equity issues. Educators are now faced with the difficult question of whether and when to incorporate the use of LLMs into the CS curriculum without adversely impacting student learning and equity. To address these concerns, we study the effects of using an interactive LLM on code generation with novice programmers. We find that using our interactive LLM improves the accuracy of code generation over the baseline LLM. Additionally, after using the interactive LLM, novices write improved prompts even when using the baseline LLM. Based on our findings, we plan to create iGPTs, a set of customized, interactive LLMs spanning CS education learning goals as templates to facilitate LLM integration for improving student learning and retention.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1295–1301},
numpages = {7},
keywords = {cs1, generative ai, llms, novice programmers},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3635403,
author = {Li, Yi and Zhang, Riteng and Qu, Danni and Marques Samary, Ma\'{\i}ra},
title = {Mining Students' Mastery Levels from CS Placement Tests via LLMs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635403},
doi = {10.1145/3626253.3635403},
abstract = {In higher education, introductory Computer Science (CS) programs offer a range of foundational courses. These encompass not only the standard CS1 and CS2 courses but may also include more specialized options like CS0 and CS1.5. In order to appropriately assign students to the suitable introductory courses, many institutions utilize placement tests, which assess students' pre-existing knowledge and skills. While most institutions rely on accuracy alone to make these determinations, there is often additional information concealed within the completed tests. This paper delves into the potential of Large Language Models (LLMs) to uncover this hidden information, particularly in gaining insights into how students perform in different concepts. Moreover, our framework has the flexibility to accommodate variations in curricula across different institutions, providing additional analytical perspectives. Initially, we built a concept inventory (CI) using the concepts covered in an institution's CS0, CS1, and CS2 curricula. Next, an LLM, specifically GPT 3.5, was applied to associate each question in the placement test with one or more concepts in the CI. Finally, the results of the placement tests were scrutinized, allowing the calculation of mastery levels in each concept for individual students. These mastery levels enable institutions to gauge a student's prior knowledge across various concepts simply by using a CS placement test. Additionally, we presented a case study demonstrating the application of this framework to 267 existing placement test results at Boston College.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1883},
numpages = {1},
keywords = {concept inventory, introductory computer science courses, large language models, placement test},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3691573.3691600,
author = {Yao, Heng and Gomes de Siqueira, Alexandre and Johnson, Margeaux and Pileggi, Roberta and Blue, Amy and Bumbach, Michael D. and Love, Rene and Lok, Benjamin},
title = {Enhancing Empathic Communication in Healthcare Education Through Virtual Conversations: Leveraging Large Language Models for Real-Time Feedback},
year = {2024},
isbn = {9798400709791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691573.3691600},
doi = {10.1145/3691573.3691600},
abstract = {Virtual conversations are increasingly utilized in healthcare education to enhance verbal empathic communication skills through tailored feedback on trainees’ responses. These conversations, supported by modalities such as speech, animation, and gestures, are highly customizable and accessible via the internet, bypassing the need for head-mounted displays (HMDs). However, training models to accurately evaluate empathic responses and generate human-like language with actionable suggestions remains a challenge. The advent of large language models (LLMs) provides new solutions to these challenges. This paper examines the impact of GPT-4-generated feedback on the empathic expressions of health professions trainees during virtual conversations. We enrolled 72 students from nursing and dental disciplines in an Interprofessional Collaborative Care course at the University of Florida. Participants were randomly assigned to one of two groups: one received feedback and suggestions from GPT-4 during conversations, while the other did not. We collected data on the perceived accuracy and helpfulness of the feedback from the intervention group. Using the Empathic Communication Coding System (ECCS) and GPT-4 Turbo, we assessed and compared the empathy levels of participants between the two groups. A Mann-Whitney U test was used to determine differences in average empathy levels. Results showed that participants receiving GPT-4 feedback had significantly higher median empathy levels than those without feedback. Feedback’s accuracy and utility were also affirmed by the participants. This study highlights the effectiveness of integrating LLMs like GPT-4 into virtual conversations for enhancing training outcomes in healthcare education.},
booktitle = {Proceedings of the 26th Symposium on Virtual and Augmented Reality},
pages = {41–50},
numpages = {10},
keywords = {large language models, verbal empathic communication training, virtual humans},
location = {Manaus, Brazil},
series = {SVR '24}
}

@inproceedings{10.1145/3641555.3705074,
author = {Roy, Nimisha and Olufisayo, Omojokun and Horielko, Oleksandr},
title = {Empowering Future Software Engineers: Integrating AI Tools into Advanced CS Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705074},
doi = {10.1145/3641555.3705074},
abstract = {Artificial Intelligence (AI) tools have transformed software development, making it crucial to equip computer science (CS) students with the skills to leverage these technologies. This talk presents an innovative curriculum approach, integrating AI tools into an advanced CS capstone course at a stage where students possess foundational skills in software engineering. This strategic timing ensures students can critically engage with AI, recognizing biases and managing challenges like hallucinations in AI-generated outputs.Before redesigning the curriculum, independent research was conducted to understand the strengths and limitations of various AI tools, such as Lucidchart, Eraser.io for design documentation, and GitHub Copilot, GPT-4, Codeium, Claude, and Gemini for implementation tasks like code generation, code completion, UI design, error handling, and API integration. This research guided the curriculum by shaping assignment design and delivering foundational lectures on prompt engineering to ease the learning curve for students. Experiments during the capstone course included AI-enhanced assignments and projects, where students applied these tools for software design and implementation. Quantitative data-prompt refinement counts, error rates, code accuracy, and qualitative reflections revealed increased confidence in AI tools, enhanced productivity, and greater readiness for industry roles. Despite these benefits, students faced challenges with complex tasks that required iterative refinement and oversight, but they gained skills in managing biases and hallucinations in AI outputs. The curriculum's ''right-left'' approach enables a smooth transition to AI-assisted development, preparing students for the evolving tech landscape. This talk shares key findings, best practices, and insights into balancing manual skills with AI-enhanced learning.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1747},
numpages = {1},
keywords = {ai-enhanced learning, capstone courses, gen-ai tools in curriculum, iterative prompting., software engineering education, student preparedness},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3627217.3627233,
author = {Balse, Rishabh and Kumar, Viraj and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Evaluating the Quality of LLM-Generated Explanations for Logical Errors in CS1 Student Programs},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627233},
doi = {10.1145/3627217.3627233},
abstract = {When students in CS1 (Introductory Programming) write erroneous code, course staff can use automated tools to provide various types of helpful feedback. In this paper, we focus on syntactically correct student code containing logical errors. Tools that explain logical errors typically require course staff to invest greater effort than tools that detect such errors. To reduce this effort, prior work has investigated the use of Large Language Models (LLMs) such as GPT-3 to generate explanations. Unfortunately, these explanations can be incomplete or incorrect, and therefore unhelpful if presented to students directly. Nevertheless, LLM-generated explanations may be of adequate quality for Teaching Assistants (TAs) to efficiently craft helpful explanations on their basis. We evaluate the quality of explanations generated by an LLM (GPT-3.5-turbo) in two ways, for 30&nbsp;buggy student solutions across 6&nbsp;code-writing problems. First, in a study with 5&nbsp;undergraduate TAs, we compare TA perception of LLM-generated and peer-generated explanation quality. TAs were unaware which explanations were LLM-generated, but they found them to be comparable in quality to peer-generated explanations. Second, we performed a detailed manual analysis of LLM-generated explanations for all 30&nbsp;buggy solutions. We found at least one incorrect statement in 15/30 explanations (50%). However, in 28/30 cases (93%), the LLM-generated explanation correctly identified at least one logical error. Our results suggest that for large CS1 courses, TAs with adequate training to detect erroneous statements may be able to extract value from such explanations.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {49–54},
numpages = {6},
keywords = {Explanation, GPT-3.5-Turbo, Large language models (LLMs), Logical Errors, Python Programming},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3649217.3653612,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Denny, Paul},
title = {Open Source Language Models Can Provide Feedback: Evaluating LLMs' Ability to Help Students Using GPT-4-As-A-Judge},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653612},
doi = {10.1145/3649217.3653612},
abstract = {Large language models (LLMs) have shown great potential for the automatic generation of feedback in a wide range of computing contexts. However, concerns have been voiced around the privacy and ethical implications of sending student work to proprietary models. This has sparked considerable interest in the use of open source LLMs in education, but the quality of the feedback that such open models can produce remains understudied. This is a concern as providing flawed or misleading generated feedback could be detrimental to student learning. Inspired by recent work that has utilised very powerful LLMs, such as GPT-4, to evaluate the outputs produced by less powerful models, we conduct an automated analysis of the quality of the feedback produced by several open source models using a dataset from an introductory programming course. First, we investigate the viability of employing GPT-4 as an automated evaluator by comparing its evaluations with those of a human expert. We observe that GPT-4 demonstrates a bias toward positively rating feedback while exhibiting moderate agreement with human raters, showcasing its potential as a feedback evaluator. Second, we explore the quality of feedback generated by several leading open-source LLMs by using GPT-4 to evaluate the feedback. We find that some models offer competitive performance with popular proprietary LLMs, such as ChatGPT, indicating opportunities for their responsible use in educational settings.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {52–58},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, code llama, generative ai, gpt-4, large language models, llm-as-a-judge, llms, open source, programming feedback, zephyr},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635400,
author = {Hurley, Ethan and Okyere-Badoo, Joel},
title = {A Comparative Study of Few-Shot vs. Zero-Shot Prompting to Generate Quick and Useful Responses to Students' Periodic Reflections},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635400},
doi = {10.1145/3626253.3635400},
abstract = {Our study investigates the effectiveness of leveraging Large Language Models (LLMs), such as GPT-3.5, to generate responses to student reflections. Acknowledging the intensive nature of manually handling reflections, our investigation centers on crafting prompts to automate reflection response generation. Driven by fast and meaningful response generation to student reflections, we explored both Zero-Shot learning (ZSL) and Few-Shot learning (FSL) methodologies. Our research meticulously examined the facets of each approach, highlighting the significance of consistent and meaningful responses.The Few-Shot prompting approach involves creating a fundamental prompt based on reflection questions and desired responses, striving for consistency while facing challenges such as GPT-3.5 computational time and issues related to content "hallucinations." In contrast, Zero-Shot prompting utilizes the base prompt and response without the assistance of examples. The evaluation process entails a meticulous examination of the quality of GPT-3.5 responses compared to the original student reflections.In the future, our study foresees integrating our devised prompting techniques as a resource for educators to promptly grasp students' learning concerns and issues. Despite challenges, Few-Shot prompting stands out as the more reliable and relevant approach, particularly in the context of email-based formats. As Machine Learning and AI continue to advance, overcoming challenges and adjusting to fluctuations in student emotions and content remains a pivotal factor in fully harnessing the capabilities of LLMs for automating the generation of responses to student reflections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {artificial intelligence (ai), few-shot learning (fsl), large language models (llms), student reflections, zero-shot learning (zsl)},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3661167.3661273,
author = {Mezzaro, Simone and Gambi, Alessio and Fraser, Gordon},
title = {An Empirical Study on How Large Language Models Impact Software Testing Learning},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661167.3661273},
doi = {10.1145/3661167.3661273},
abstract = {Software testing is a challenging topic in software engineering education and requires creative approaches to engage learners. For example, the Code Defenders game has students compete over a Java class under test by writing effective tests and mutants. While such gamified approaches deal with problems of motivation and engagement, students may nevertheless require help to put testing concepts into practice. The recent widespread diffusion of Generative AI and Large Language Models raises the question of whether and how these disruptive technologies could address this problem, for example, by providing explanations of unclear topics and guidance for writing tests. However, such technologies might also be misused or produce inaccurate answers, which would negatively impact learning. To shed more light on this situation, we conducted the first empirical study investigating how students learn and practice new software testing concepts in the context of the Code Defenders testing game, supported by a smart assistant based on a widely known, commercial Large Language Model. Our study shows that students had unrealistic expectations about the smart assistant, “blindly” trusting any output it generated, and often trying to use it to obtain solutions for testing exercises directly. Consequently, students who resorted to the smart assistant more often were less effective and efficient than those who did not. For instance, they wrote 8.6% fewer tests, and their tests were not useful in 78.0% of the cases. We conclude that giving unrestricted and unguided access to Large Language Models might generally impair learning. Thus, we believe our study helps to raise awareness about the implications of using Generative AI and Large Language Models in Computer Science Education and provides guidance towards developing better and smarter learning tools.},
booktitle = {Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
pages = {555–564},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, Generative AI, Smart Learning Assistant},
location = {Salerno, Italy},
series = {EASE '24}
}

@inproceedings{10.1145/3657604.3664673,
author = {Fung, Sze Ching Evelyn and Wong, Man Fai and Tan, Chee Wei},
title = {Automatic Feedback Generation on K-12 Students' Data Science Education by Prompting Cloud-based Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664673},
doi = {10.1145/3657604.3664673},
abstract = {Since data science is traditionally an advanced field taught at the college or university level, introducing its concepts to K-12 students can present unique learning challenges. As educational environments increasingly adopt data science curricula for K-12 students, the need for scalable, personalized teaching tools becomes critical. While the integration of large language models (LLMs) in educational environments offers significant potential for scalability and automation, it is important to note that the generated language output may not always be highly suitable for K-12 students. In this paper, we introduce the DSRAG, a novel educational automatic feedback generation framework that leverages Retrieval-Augmented Generation (RAG) and cloud-based LLMs to provide automated and personalized feedback for K-12 students engaged in data science education. DSRAG employs Langchain question-answering and RAG systems to manage educational content and generate feedback on the top of GPT-4. We also demonstrate the framework's capability to simplify complex concepts and align its responses to be pedagogically appropriate and understandable for K-12 students.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {255–258},
numpages = {4},
keywords = {large language models, learning technologies, prompt engineering, retrieval-augmented generation},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3643991.3644926,
author = {Idialu, Oseremen Joy and Mathews, Noble Saji and Maipradit, Rungroj and Atlee, Joanne M. and Nagappan, Mei},
title = {Whodunit: Classifying Code as Human Authored or GPT-4 Generated - A case study on CodeChef problems},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644926},
doi = {10.1145/3643991.3644926},
abstract = {Artificial intelligence (AI) assistants such as GitHub Copilot and ChatGPT, built on large language models like GPT-4, are revolutionizing how programming tasks are performed, raising questions about whether code is authored by generative AI models. Such questions are of particular interest to educators, who worry that these tools enable a new form of academic dishonesty, in which students submit AI-generated code as their work. Our research explores the viability of using code stylometry and machine learning to distinguish between GPT-4 generated and human-authored code. Our dataset comprises human-authored solutions from CodeChef and AI-authored solutions generated by GPT-4. Our classifier outperforms baselines, with an F1-score and AUC-ROC score of 0.91. A variant of our classifier that excludes gameable features (e.g., empty lines, whitespace) still performs well with an F1-score and AUC-ROC score of 0.89. We also evaluated our classifier on the difficulty of the programming problem and found that there was almost no difference between easier and intermediate problems, and the classifier performed only slightly worse on harder problems. Our study shows that code stylometry is a promising approach for distinguishing between GPT-4 generated code and human-authored code.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {394–406},
numpages = {13},
keywords = {code stylometry, ChatGPT, AI code, GPT-4 generated code, authorship profiling, software engineering},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3716640.3716652,
author = {Edwards, John and Hellas, Arto and Leinonen, Juho},
title = {On the Opportunities of Large Language Models for Programming Process Data},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716652},
doi = {10.1145/3716640.3716652},
abstract = {Computing educators and researchers have long used programming process data to understand how students construct programs and address challenges. Despite its potential, fully automated feedback systems remain underexplored. The emergence of Large Language Models (LLMs) offers new opportunities for analyzing programming data and providing formative feedback. This study explores using LLMs to summarize programming processes and deliver formative feedback. A case study analyzed keystroke-level data from an introductory programming course, processed into code snapshots. Three state-of-the-art LLMs – Claude 3 Opus, GPT-4 Turbo, and LLaMa2 70B Chat – were evaluated for their feedback capabilities. Results show LLMs effectively provide tailored feedback, emphasizing incremental development, algorithmic planning, and code readability. Our findings highlight the potential of combining keystroke data with LLMs to automate formative feedback, showing that the computing education research and practice community is again one step closer to automating formative programming process feedback.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {105–113},
numpages = {9},
keywords = {programming process data, large language models, generative AI, programming process feedback, programming process summarization, keystroke data},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3613905.3647967,
author = {Kimmel, Bailey and Geisert, Austin Lee and Yaro, Lily and Gipson, Brendan and Hotchkiss, Ronald Taylor and Osae-Asante, Sidney Kwame and Vaught, Hunter and Wininger, Grant and Yamaguchi, Chase},
title = {Enhancing Programming Error Messages in Real Time with Generative AI},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647967},
doi = {10.1145/3613905.3647967},
abstract = {Generative AI is changing the way that many disciplines are taught, including computer science. Researchers have shown that generative AI tools are capable of solving programming problems, writing extensive blocks of code, and explaining complex code in simple terms. Particular promise has been shown in using generative AI to enhance programming error messages. Both students and instructors have complained for decades that these messages are often cryptic and difficult to understand. Yet recent work has shown that students make fewer repeated errors when enhanced via GPT-4. We extend this work by implementing feedback from ChatGPT for all programs submitted to our automated assessment tool, Athene, providing help for compiler, run-time, and logic errors. Our results indicate that adding generative AI to an automated assessment tool does not necessarily make it better and that design of the interface matters greatly to the usability of the feedback that GPT-4 provided.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {608},
numpages = {7},
keywords = {AI, Artificial Intelligence, Automatic Code Generation, CS1, ChatGPT, Codex, Copilot, GPT-4, GitHub, HCI, Introductory Programming, LLM, Large Language Models, Novice Programming, OpenAI},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3587102.3588814,
author = {Cipriano, Bruno Pereira and Alves, Pedro},
title = {GPT-3 vs Object Oriented Programming Assignments: An Experience Report},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588814},
doi = {10.1145/3587102.3588814},
abstract = {Recent studies show that AI-driven code generation tools, such as Large Language Models, are able to solve most of the problems usually presented in introductory programming classes. However, it is still unknown how they cope with Object Oriented Programming assignments, where the students are asked to design and implement several interrelated classes (either by composition or inheritance) that follow a set of best-practices. Since the majority of the exercises in these tools' training dataset are written in English, it is also unclear how well they function with exercises published in other languages.In this paper, we report our experience using GPT-3 to solve 6 real-world tasks used in an Object Oriented Programming course at a Portuguese University and written in Portuguese. Our observations, based on an objective evaluation of the code, performed by an open-source Automatic Assessment Tool, show that GPT-3 is able to interpret and handle direct functional requirements, however it tends not to give the best solution in terms of object oriented design. We perform a qualitative analysis of GPT-3's output, and gather a set of recommendations for computer science educators, since we expect students to use and abuse this tool in their academic work.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {61–67},
numpages = {7},
keywords = {GPT-3, large language models, object oriented programming, programming assignments, teaching},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3699538.3699588,
author = {Pereira Cipriano, Bruno and Silva, Miguel and Correia, Rodrigo and Alves, Pedro},
title = {Towards the Integration of Large Language Models and Automatic Assessment Tools: Enhancing Student Support in Programming Assignments},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699588},
doi = {10.1145/3699538.3699588},
abstract = {The rise of Large Language Models (LLMs) has sparked discussion in Computer Science Education (CSE) due to their ability to generate code from text prompts. Students may rely on these tools, neglecting core skills like computational thinking and program design. Thus, it’s crucial to responsibly integrate them into computer science courses.To address this, we integrated an open-source Automatic Assessment Tool with GPT, enabling students to receive LLM assistance on their programming assignments. This tool can be adopted and improved by educators, promoting more responsible integration of LLMs in CSE.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {52},
numpages = {2},
keywords = {large language models, automatic assessment tools, feedback},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3637528.3671583,
author = {Wang, Junjie and Yang, Dan and Hu, Binbin and Shen, Yue and Zhang, Wen and Gu, Jinjie},
title = {Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671583},
doi = {10.1145/3637528.3671583},
abstract = {In this paper, we explore a new way for user targeting, where non-expert marketers could select their target users solely given demands in natural language form. The key to this issue is how to transform natural languages into practical structured logical languages, i.e., the structured understanding of marketer demands. In practical scenarios, the demands of non-expert marketers are often abstract and diverse. Considering the impressive natural language processing ability of large language models (LLMs), we try to leverage LLMs to solve this issue. To stimulate the LLMs' reasoning ability, the chain-of-thought (CoT) prompting method is widely used, but existing methods still have some limitations in our scenario: (1) Previous methods either use simple "Let's think step by step" spells or provide fixed examples in demonstrations without considering compatibility between prompts and concrete questions, making LLMs ineffective when the marketers' demands are abstract and diverse. (2) Previous methods are often implemented in closed-source models or excessively large models, which is not suitable in industrial practical scenarios. Based on these, we propose ARALLM (i.e., Analogical Reasoning Augmented Large Language Models) consisting of two modules: Analogical Reasoning based Prompting and Reasoning-Augmented Multi-Task Model Distillation. Then, we adopt a retrieval-based method to conduct analogical reasoning with the help of the reasoning library. The experimental results show that this prompting strategy achieves better performance than the ordinary prompting method. Beyond that, we distill knowledge from super LLMs (GPT-3.5) to fine-tune smaller student LLMs in a multi-task training paradigm, enabling the models to be easily deployed in practical environments. Part of our data and code can be found at https://github.com/alipay/Analogic-Reasoning-Augmented-Large-Language-Model.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5860–5871},
numpages = {12},
keywords = {analogical reasoning, chain of thought, knowledge distillation, large language models, user targeting},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3626253.3635404,
author = {Howard-Sarin, Brij},
title = {The Future of the Error Message: Comparing Large Language Models and Novice Programmer Effectiveness in Fixing Errors},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635404},
doi = {10.1145/3626253.3635404},
abstract = {Research on enhancing error message presentation is of great interest to teachers and developers alike because improving Integrated Development Environments (IDEs) increases early student retention and efficiency at all levels with more effective developing tools. This study aims to compare GPT-4 and novice programmer accuracy in fixing errors to assess the viability of Large Language Models as an error message enhancement tool. First, a random sample of 100,000 sessions from all users of BlueJ 5, an IDE for novice programmers, was analyzed to determine the time it took programmers to resolve coding errors. Subsequently, for each of the five most common errors, GPT-4 was given 20 randomly-selected snippets of code from Blackbox mini, a curated subset of Blackbox with source code attached, and prompted to explain and fix the errors. This study replicated prior research that proposed a Zipf-Mandelbrot Distribution of error message frequency; the five most common errors comprised 45% of all error messages. In comparing GPT-4 and novices, it was found that humans fix code at higher rates, but GPT-4 provided completely correct explanations for error messages 96% of the time. This study concludes that GPT-4 functions best as a tool to explain error messages in an interactive format, rather than as a tool to produce correct code on its own. In conclusion, GPT-4 would be best utilized to enhance the classroom experience as a chat assistant to reduce time spent on syntactical errors, leading to improved productivity and better novice retention.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1881},
numpages = {1},
keywords = {BlueJ, GPT-4, IDEs, blackbox, error message enhancement, error messages, large language models, novice programmers},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3689535.3689554,
author = {Santos, Eddie Antonio and Becker, Brett A.},
title = {Not the Silver Bullet: LLM-enhanced Programming Error Messages are Ineffective in Practice},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689554},
doi = {10.1145/3689535.3689554},
abstract = {The sudden emergence of large language models (LLMs) such as ChatGPT has had a disruptive impact throughout the computing education community. LLMs have been shown to excel at producing correct code to CS1 and CS2 problems, and can even act as friendly assistants to students learning how to code. Recent work shows that LLMs demonstrate unequivocally superior results in being able to explain and resolve compiler error messages—for decades, one of the most frustrating parts of learning how to code. However, LLM-generated error message explanations have only been assessed by expert programmers in artificial conditions. This work sought to understand how novice programmers resolve programming error messages (PEMs) in a more realistic scenario. We ran a within-subjects study with n = 106 participants in which students were tasked to fix six buggy C programs. For each program, participants were randomly assigned to fix the problem using either a stock compiler error message, an expert-handwritten error message, or an error message explanation generated by GPT-4. Despite promising evidence on synthetic benchmarks, we found that GPT-4 generated error messages outperformed conventional compiler error messages in only 1 of the 6 tasks, measured by students’ time-to-fix each problem. Handwritten explanations still outperform LLM and conventional error messages, both on objective and subjective measures.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {5},
numpages = {7},
keywords = {AI, C, CS1, GPT-4, GenAI, Generative AI, LLMs, PEM, compiler error messages, computing education, debugging, feedback, large language models, novice programmers, programming error messages},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3650212.3680328,
author = {Yang, Boyang and Tian, Haoye and Pian, Weiguo and Yu, Haoran and Wang, Haitao and Klein, Jacques and Bissyand\'{e}, Tegawend\'{e} F. and Jin, Shunfu},
title = {CREF: An LLM-Based Conversational Software Repair Framework for Programming Tutors},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650212.3680328},
doi = {10.1145/3650212.3680328},
abstract = {With the proven effectiveness of Large Language Models (LLMs) in code-related tasks, researchers have explored their potential for program repair. However, existing repair benchmarks might have influenced LLM training data, potentially causing data leakage. To evaluate LLMs’ realistic repair capabilities, (i) we introduce an extensive, non-crawled benchmark TutorCode, comprising 1,239 C++ defect codes and associated information such as tutor guidance, solution description, failing test cases, and the corrected code. Our work assesses LLM’s repair performance on TutorCode, measuring repair correctness (TOP-5 and AVG-5) and patch precision (RPSR). (ii) We then provide a comprehensive investigation into which types of extra information can help LLMs improve their repair performance. Among these types, tutor guidance was the most effective information. To fully harness LLMs’ conversational capabilities and the benefits of augmented information, (iii) we introduce a novel conversational semi-automatic repair framework CREF assisting human programming tutors. It demonstrates a remarkable AVG-5 improvement of 17.2%-24.6% compared to the baseline, achieving an impressive AVG-5 of 76.6% when utilizing GPT-4. These results highlight the potential for enhancing LLMs’ repair capabilities through tutor interactions and historical conversations. The successful application of CREF in a real-world educational setting demonstrates its effectiveness in reducing tutors’ workload and improving students’ learning experience, showing promise for code review and other software engineering tasks.},
booktitle = {Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
pages = {882–894},
numpages = {13},
keywords = {Large Language Model, Open Source, Program Repair},
location = {Vienna, Austria},
series = {ISSTA 2024}
}

@article{10.5555/3715602.3715612,
author = {Crandall, Johannah L. and Crandall, Aaron S.},
title = {Large Language Model-Supported Software Testing with the CS Matrix Taxonomy},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {New breakthroughs in code synthesis from Generative Pre-Trained Transformers (GPT) and Large Language Model (LLM) algorithms are driving significant changes to software engineering education. Having algorithms able to generate components of a software project means that software developers will need stronger skills in requirements specification to guide code generation as well as stronger skills in code review, testing, and integration to incorporate AI-generated code into projects. Shifts in industry and classroom practices are already occurring with the availability of inline code generation tools like GitHub's Copilot, which makes discussion of pedagogical strategies in this area a timely topic. Of immediate concern in computer science education is the potential for LLM-generated code and code help to undermine the learning of CS students. In order to avoid such undermining in even intentional uses of LLM-enhanced learning supports, it is necessary to clarify the roles such supports need to play in the pedagogical process. The Computer Science Matrix Taxonomy provides a strong framework for organizing software testing learning outcomes as well as delineating the operational space in which LLM-based feedback tools should operate to support those learning outcomes. In this paper, the authors operationalize the CS Matrix Taxonomy for software testing learning outcomes and illustrate the integration of LLM-generated test strategy suggestions as an extension of the peer coding/testing model. The work includes examples of AI-generated code testing suggestions that students would use to help guide their own code synthesis for assignments or projects.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {49–58},
numpages = {10}
}

@inproceedings{10.1145/3636243.3636245,
author = {Macneil, Stephen and Denny, Paul and Tran, Andrew and Leinonen, Juho and Bernstein, Seth and Hellas, Arto and Sarsa, Sami and Kim, Joanne},
title = {Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636245},
doi = {10.1145/3636243.3636245},
abstract = {Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior – in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (n = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {11–18},
numpages = {8},
keywords = {bug detection, computing education, generative AI, large language models, programming errors},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3689535.3689546,
author = {Andrei, Oana and Sojtory, Zoltan},
title = {LLM-aided Pair Programming for Algorithm Tracing},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689546},
doi = {10.1145/3689535.3689546},
abstract = {The recent widespread popularity of generative AI models has inspired the development of large-language model (LLM) based tools for educational purposes. We explore the impact of LLM-based tools on pair programming for algorithm tracing with the aim of addressing challenges inherent to pair programming. We designed and developed a GPT-4 based tool, TraceCompanion, that acts as students’ pair programming partner for algorithm tracing. We describe insights gained from running a pilot study to investigate students’ interactions with the tool and their initial perceptions.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {20},
numpages = {1},
keywords = {algorithm tracing, large language models, pair programming},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3636555.3636889,
author = {Sonkar, Shashank and Chen, Xinghe and Le, Myco and Liu, Naiming and Basu Mallick, Debshila and Baraniuk, Richard},
title = {Code Soliloquies for Accurate Calculations in Large Language Models},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636889},
doi = {10.1145/3636555.3636889},
abstract = {High-quality conversational datasets are crucial for the successful development of Intelligent Tutoring Systems (ITS) that utilize a Large Language Model (LLM) backend. Synthetic student-teacher dialogues, generated using advanced GPT-4 models, are a common strategy for creating these datasets. However, subjects like physics that entail complex calculations pose a challenge. While GPT-4 presents impressive language processing capabilities, its limitations in fundamental mathematical reasoning curtail its efficacy for such subjects. To tackle this limitation, we introduce in this paper an innovative stateful prompt design. Our design orchestrates a mock conversation where both student and tutorbot roles are simulated by GPT-4. Each student response triggers an internal monologue, or ‘code soliloquy’ in the GPT-tutorbot, which assesses whether its subsequent response would necessitate calculations. If a calculation is deemed necessary, it scripts the relevant Python code and uses the Python output to construct a response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. The preliminary Subject Matter Expert evaluations reveal that our Higgs model, a fine-tuned LLaMA model, effectively uses Python for computations, which significantly enhances the accuracy and computational reliability of Higgs’ responses.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {828–835},
numpages = {8},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.1145/3737885,
author = {Brown, Neil C. C. and Weill-Tessier, Pierre and Leinonen, Juho and Denny, Paul and K\"{o}lling, Michael},
title = {Howzat? Appealing to Expert Judgement for Evaluating Human and AI Next-Step Hints for Novice Programmers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737885},
doi = {10.1145/3737885},
abstract = {Motivation: Students learning to program often reach states where they are stuck and can make no forward progress – but this may be outside the classroom where no instructor is available to help. In this situation, an automatically generated next-step hint can help them make forward progress and support their learning. It is important to know what makes a good hint or a bad hint, and how to generate good hints automatically in novice programming tools, for example using Large Language Models (LLMs).Method and participants: We recruited 44 Java educators from around the world to participate in an online study. We used a set of real student code states as hint-generation scenarios. Participants used a technique known as comparative judgement to rank a set of candidate next-step Java hints, which were generated by Large Language Models (LLMs) and by five human experienced educators. Participants ranked the hints without being told how they were generated. The hints were generated with no explicit detail given to the LLMs/humans on what the target task was. Participants then filled in a survey with follow-up questions. The ranks of the hints were analysed against a set of extracted hint characteristics using a random forest approach.Findings: We found that LLMs had considerable variation in generating high quality next-step hints for programming novices, with GPT-4 outperforming other models tested. When used with a well-designed prompt, GPT-4 outperformed human experts in generating pedagogically valuable hints. A multi-stage prompt was the most effective LLM prompt. According to a fitted random forest model, the two most important factors of a good hint were length (80–160 words being best), and reading level (US grade nine or below being best). Offering alternative approaches to solving the problem was considered bad, and we found no effect of sentiment.Conclusions: Automatic generation of these hints is immediately viable, given that LLMs outperformed humans – even when the students’ task is unknown. Hint length and reading level were more important than several pedagogical features of hints. The fact that it took a group of experts several rounds of experimentation and refinement to design a prompt that achieves this outcome suggests that students on their own are unlikely to be able to produce the same benefit. The prompting task, therefore, should be embedded in an expert-designed tool.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Educ.},
month = may,
keywords = {LLMs, AI, Java, Next-step hints, comparative judgement}
}

@inproceedings{10.1145/3587102.3588852,
author = {Balse, Rishabh and Valaboju, Bharath and Singhal, Shreya and Warriem, Jayakrishnan Madathil and Prasad, Prajish},
title = {Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588852},
doi = {10.1145/3587102.3588852},
abstract = {Recent advances in artificial intelligence have led to the development of large language models (LLMs), which are able to generate text, images, and source code based on prompts provided by humans. In this paper, we explore the capabilities of an LLM - OpenAI's GPT-3 model to provide feedback for student written code. Specifically, we examine the feasibility of GPT-3 to check, critique and suggest changes to code written by learners in an online programming exam of an undergraduate Python programming course.We collected 1211 student code submissions from 7 questions asked in a programming exam, and provided the GPT-3 model with separate prompts to check, critique and provide suggestions on these submissions. We found that there was a high variability in the accuracy of the model's feedback for student submissions. Across questions, the range for accurately checking the correctness of the code was between 57% to 79%, between 41% to 77% for accurately critiquing code, and between 32% and 93% for suggesting appropriate changes to the code. We also found instances where the model generated incorrect and inconsistent feedback. These findings suggest that models like GPT-3 currently cannot be 'directly' used to provide feedback to students for programming assessments.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {292–298},
numpages = {7},
keywords = {GPT-3, evaluation, feedback, large language models (LLM), python programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3626252.3630897,
author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
title = {Need a Programming Exercise Generated in Your Native Language? ChatGPT's Got Your Back: Automatic Generation of Non-English Programming Exercises Using OpenAI GPT-3.5},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630897},
doi = {10.1145/3626252.3630897},
abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {618–624},
numpages = {7},
keywords = {introductory programming, large language models, non-native english speakers, problem generation},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635542,
author = {Smith, David H. and Zilles, Craig},
title = {Evaluating Large Language Model Code Generation as an Autograding Mechanism for "Explain in Plain English" Questions},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635542},
doi = {10.1145/3626253.3635542},
abstract = {The ability of students to ''Explain in Plain English'' (EiPE) the purpose of code is a critical skill for students in introductory programming courses to develop. EiPE questions serve as both a mechanism for students to develop and demonstrate code comprehension skills. However, evaluating this skill has been challenging as manual grading is time consuming and not easily automated. The process of constructing a prompt for the purposes of code generation for a Large Language Model, such OpenAI's GPT-4, bears a striking resemblance to constructing EiPE responses. In this paper, we explore the potential of using test cases run on code generated by GPT-4 from students' EiPE responses as a grading mechanism for EiPE questions. We applied this proposed grading method to a corpus of EiPE responses collected from past exams, then measured agreement between the results of this grading method and human graders. Overall, we find moderate agreement between the human raters and the results of the unit tests run on the generated code. This appears to be attributable to GPT-4's code generation being more lenient than human graders on low-level descriptions of code.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1824–1825},
numpages = {2},
keywords = {autograding, eipe, gpt-4, large language models},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3717781.3717799,
author = {Tok, Bulut and Dogan, Gulustan},
title = {Advisor SeaHawk: An Academic Advisor Chatbot for MSCSIS Students at UNCW},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {This paper introduces Advisor SeaHawk, an advanced academic advisor chatbot for students at the University of North Carolina Wilmington (UNCW), specifically tailored for MSCSIS (Master of Science Computer and Information Science) students. Using OpenAI's GPT-4o model, Advisor SeaHawk provides personalized academic advising, including course recommendations, prerequisite checks, and detailed academic plans. The development process involves converting PDF academic records into structured JSON data, extracting student information using regular expressions, and integrating CSV-based course information. By leveraging natural language processing, Advisor SeaHawk interacts with students in a friendly manner, effectively simulating a human advisor. This chatbot aims to provide an accessible, efficient, and tailored advising experience for college students. We have not tested Advisor Seahawk yet on real student data.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {138–148},
numpages = {11}
}

@article{10.5555/3715602.3715614,
author = {Rhee, Junghwan and Shrestha, Aakankshya and Qian, Gang and Zuo, Fei and Fu, Jicheng and Park, Myungah and Qu, Xianshan and Mylavarapu, Goutam and Sung, Hong},
title = {An Evaluation on the Impact of Large Language Models on Computer Science Curricula},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {Since their introduction, large language model (LLM) services have been widely used in our society, including the computer science education area. While this technology provides various types of intelligent assistance to users, its capabilities and impact on computer science education regarding students' learning need further study. In this paper, we present our manual assessment of LLM services' ability to solve questions in various course assignments and projects in our computer science curriculum. Based on the result of the study, we provide our observations of the extent of LLM services' impact on different computer science disciplines. Suggestions are summarized and offered to computer science instructors on the possible strategies for dealing with LLMs in current and future computer science curriculum designs.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {70–80},
numpages = {11}
}

@article{10.5555/3715602.3715619,
author = {Hong, Alexander and Hong, Gongbing},
title = {The Effectiveness of Coding LLMs and the Challenges in Teaching CS1/2: A Case Study},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {1},
issn = {1937-4771},
abstract = {This paper presents a case study that evaluates the effectiveness of coding Large Language Models (LLMs) in introductory computer science courses at the university level. The study assesses six different AI-powered code generators. The evaluation focuses on the accuracy of these AI code generators in solving ten programming problems from a set of problems that instructors at Duke University can assign to students for weekly completion. The results demonstrate the effectiveness of coding LLMs in solving these problems.Based on the findings, the paper discusses the challenges faced by the computer science education community and potential strategies to address them. The advent of coding LLMs poses significant challenges to traditional teaching and learning methods in computer science. These challenges include the need for strategies to mitigate any negative impact of LLMs on the learning process. At the same time, these code LLMs also offer tremendous opportunities for enhancing teaching and learning.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {122–131},
numpages = {10}
}

@article{10.5555/3722479.3722506,
author = {Liao, Weidong and Guzide, Osman},
title = {Enhancing Undergraduate Computing Education with LMMs and ChatGPT-4o},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {Large Language Models (LLMs) and ChatGPT have significantly impacted programming practices and computer science education. The rapid advancements in natural language processing, recurrent neural networks, and Transformer architectures have captured the attention of students and educators alike. These tools aid students in brainstorming, coding, analyzing code, and writing reports. Although concerns about cheating and plagiarism persist, these tools also provide educators with novel ways to create and assess assignments. Despite some hesitancy among educators to integrate these AI tools into the classroom, the advert and development of Large MultiModal Models (LMMs), the enhancement of LLMs that can deal with multimedia inputs and outputs, illustrates a significant evolution in generative AI capabilities.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {62},
numpages = {1}
}

@article{10.5555/3722479.3722526,
author = {Xie, Jingnan},
title = {Improving Introductory Java Programming Education Through ChatGPT},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The realm of introductory computer science (CS) education is swiftly changing, as educators actively pursue inventive strategies to captivate and empower students. This manuscript introduces a fresh methodology for teaching CS1 or CS2 courses, concentrating specifically on the fundamental principles of Java programming. Harnessing the capabilities of ChatGPT, an AI language model, we delve into how integrating conversational AI into the classroom milieu can foster a more dynamic and tailored learning journey. By furnishing a platform for students to pose inquiries, seek elucidation, and promptly receive feedback, ChatGPT functions as a virtual mentor, complementing conventional teaching methodologies. We scrutinize the potential repercussions of this approach on student learning outcomes (SLOs) and juxtapose it with traditional classroom paradigms. Furthermore, we deliberate on the ramifications of employing AI in education and its contribution to molding the trajectory of introductory programming courses.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {140–150},
numpages = {11}
}

@inproceedings{10.1145/3706599.3720291,
author = {Jamie, Pooriya and HajiHashemi, Reyhaneh and Alipour, Sharareh},
title = {Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720291},
doi = {10.1145/3706599.3720291},
abstract = {Integrating large language models (LLMs) like ChatGPT into computer science education offers transformative potential for complex courses such as data structures and algorithms (DSA). This study examines ChatGPT as a supplementary tool for teaching assistants (TAs), guided by structured prompts and human oversight, to enhance instruction and student outcomes. A controlled experiment compared traditional TA-led instruction with a hybrid approach where TAs used ChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide feedback. Structured prompts emphasized problem decomposition, real-world context, and code examples, enabling tailored support while mitigating over-reliance on AI. Results demonstrated the hybrid approach’s efficacy, with students in the ChatGPT-assisted group scoring 16.50 points higher on average and excelling in advanced topics. However, ChatGPT’s limitations necessitated TA verification. This framework highlights the dual role of LLMs: augmenting TA efficiency while ensuring accuracy through human oversight, offering a scalable solution for human-AI collaboration in education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {567},
numpages = {7},
keywords = {LLMs, ChatGPT, Teaching Assistant, Data Structures and Algorithms Course, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3639474.3640061,
author = {Frankford, Eduard and Sauerwein, Clemens and Bassner, Patrick and Krusche, Stephan and Breu, Ruth},
title = {AI-Tutoring in Software Engineering Education},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640061},
doi = {10.1145/3639474.3640061},
abstract = {With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences.In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic responses and students' concerns about a learning progress inhibition when using the AI-Tutor were also evident. This research adds to the discourse on AI's role in education.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {309–319},
numpages = {11},
keywords = {programming education, automated programming assessment systems, artificial intelligence, ChatGPT, OpenAI, ChatBots},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3643795.3648379,
author = {Rasnayaka, Sanka and Wang, Guanlin and Shariffdeen, Ridwan and Iyer, Ganesh Neelakanta},
title = {An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648379},
doi = {10.1145/3643795.3648379},
abstract = {Large Language Models (LLMs) represent a leap in artificial intelligence, excelling in tasks using human language(s). Although the main focus of general-purpose LLMs is not code generation, they have shown promising results in the domain. However, the usefulness of LLMs in an academic software engineering project has not been fully explored yet. In this study, we explore the usefulness of LLMs for 214 students working in teams consisting of up to six members. Notably, in the academic course through which this study is conducted, students were encouraged to integrate LLMs into their development tool-chain, in contrast to most other academic courses that explicitly prohibit the use of LLMs.In this paper, we analyze the AI-generated code, prompts used for code generation, and the human intervention levels to integrate the code into the code base. We also conduct a perception study to gain insights into the perceived usefulness, influencing factors, and future outlook of LLM from a computer science student's perspective. Our findings suggest that LLMs can play a crucial role in the early stages of software development, especially in generating foundational code structures, and helping with syntax and error debugging. These insights provide us with a framework on how to effectively utilize LLMs as a tool to enhance the productivity of software engineering students, and highlight the necessity of shifting the educational focus toward preparing students for successful human-AI collaboration.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {111–118},
numpages = {8},
keywords = {LLM for code generation, software engineering},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3657604.3664665,
author = {Koutcheme, Charles and Hellas, Arto},
title = {Propagating Large Language Models Programming Feedback},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664665},
doi = {10.1145/3657604.3664665},
abstract = {Large language models (LLMs) such as GPT-4 have emerged as promising tools for providing programming feedback. However, effective deployment of LLMs in massive classes and Massive Open Online Courses (MOOCs) raises financial concerns, calling for methods to minimize the number of calls to the APIs and systems serving such powerful models. In this article, we revisit the problem of 'propagating feedback' within the contemporary landscape of LLMs. Specifically, we explore feedback propagation as a way to reduce the cost of leveraging LLMs for providing programming feedback at scale. Our study investigates the effectiveness of this approach in the context of students requiring next-step hints for Python programming problems, presenting initial results that support the viability of the approach. We discuss our findings' implications and suggest directions for future research in optimizing feedback mechanisms for large-scale educational environments.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {366–370},
numpages = {5},
keywords = {computer science education, large language models, programming feedback},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641555.3704749,
author = {Hare, Brian K. and Gladbach, Joan and Shah, S. Jawad and Xu, Dianxiang},
title = {Building AI-Powered Responsible Workforce by Integrating Large Language Models into Computer Science Curriculum},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704749},
doi = {10.1145/3641555.3704749},
abstract = {Software development is undergoing a revolutionary transformation, fueled by remarkable advancements in Large Language Models (LLMs). This wave of innovation is reshaping the entire landscape and holds the promise of streamlining the development process, leading to increased productivity and efficiency. By providing text prompts, developers can now receive entirely generated code outputs, representing a fundamental shift in how software is built. This paradigm change can accelerate development cycles and unlock new levels of creativity and ingenuity, resulting in the realization of novel applications and business outcomes. However, this paradigm shift also brings new challenges and necessitates acquiring additional skills for software developers to fully harness the capabilities of LLM-powered tools. These skills include prompt engineering for software development, structural complexity management, debugging of AI errors, and compliance with ethical guidelines and principles.The special session will introduce our NSF-sponsored 3-year project, which aims to integrate LLMs into the standard CS curriculum. To the best of our knowledge, this project is among the first department-level initiatives to renovate CS curriculum, rather than individual courses, with the new developments of LLMs. Our project focuses on (a) enhancing students' problem-solving and programming skills by leveraging LLMs as a learning tool in core programming courses, (b) improving students' software development skills by integrating LLM-powered tools into the software engineering course sequence, and (c) educating students on ethical and responsible AI practices. The special session will discuss the objectives and methods of our project, as well as the current results and lessons learned.This NSF-supported project aims to integrate LLMs into the standard CS curriculum. The revolutionized computer science education will cultivate a new generation of AI-powered responsible developers. The objectives are to enhance student programming, software development, and problem-solving skills; educate students on ethical and responsible AI practices; and develop faculty development materials and workshops. Our presentation will discuss the objectives and methods of our project, currently in year 1 of a 3-year timeline.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1709–1710},
numpages = {2},
keywords = {AI, curriculum development, large language models, undergraduate education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701917,
author = {Wang, Kevin Shukang and Lawrence, Ramon},
title = {Quantitative Evaluation of Using Large Language Models and Retrieval-Augmented Generation in Computer Science Education},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701917},
doi = {10.1145/3641554.3701917},
abstract = {Generative artificial intelligence (GenAI) is transforming Computer Science education, and every instructor is reflecting on how AI will impact their courses. Instructors must determine how students may use AI for course activities and what AI systems they will support and encourage students to use. This task is challenging with the proliferation of large language models (LLMs) and related AI systems. The contribution of this work is an experimental evaluation of the performance of multiple open-source and commercial LLMs utilizing retrieval-augmented generation in answering questions for computer science courses and a cost-benefit analysis for instructors when determining what systems to use. A key factor is the time an instructor has to maintain their supported AI systems and the most effective activities for improving their performance. The paper offers recommendations for deploying, using, and enhancing AI in educational settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1183–1189},
numpages = {7},
keywords = {artificial intelligence, human-in-the-loop, large language model, question answering, retrieval-augmented generation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3635408,
author = {Xiang, Lili},
title = {SQL Query Evaluation with Large Language Model and Abstract Syntax Trees},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635408},
doi = {10.1145/3626253.3635408},
abstract = {SQL stands as the foundational language for data analysis and manipulation, playing a pivotal role in the database learning process. Proficiency in SQL is essential for students seeking to excel in data-related fields. However, the conventional approaches to assessing SQL queries rely heavily on manual grading, and the automated assessment tools are usually producing only binary decisions for the submitted queries. Our primary research objective is to develop effective methods for evaluating the quality of the SQL queries. To meet this objective, we introduce two approaches: structure-based analysis and evaluation by an instruction tuned large language model (LLM). The first approach deconstructs queries into Abstract Syntax Trees (AST) and employs cosine similarity to assess student submissions. The second approach utilizes a pre-trained LLM: FLAN-T5, fine-tuned for predicting the quality of student submissions. These methodologies are tested on a SQL dataset, and our experimental findings evaluate against a grading rubric with categories ranging from "good" to "unacceptable". The experimental results demonstrate that we can enhance the grading efficiency by applying these approaches and illustrate the ability of utilizing LLM to classify the assessed SQL statements more accurately. In addition, this research contributes to Computer Science (CS) education by integrating these approaches into our team's automated SQL statement assessment tool, improving the learning experience and evaluation process.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1890},
numpages = {1},
keywords = {abstract syntax trees, auto-grader, cs education, large language model, sql},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649405.3659504,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Littlefield, Matt and Hellas, Arto and MacNeil, Stephen},
title = {Analyzing Students' Preferences for LLM-Generated Analogies},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659504},
doi = {10.1145/3649405.3659504},
abstract = {Introducing students to new concepts in computer science can often be challenging, as these concepts may differ significantly from their existing knowledge and conceptual understanding. To address this, we employed analogies to help students connect new concepts to familiar ideas. Specifically, we generated analogies using large language models (LLMs), namely ChatGPT, and used them to help students make the necessary connections. In this poster, we present the results of our survey, in which students were provided with two analogies relating to different computing concepts, and were asked to describe the extent to which they were accurate, interesting, and useful. This data was used to determine how effective LLM-generated analogies can be for teaching computer science concepts, as well as how responsive students are to this approach.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {812},
numpages = {1},
keywords = {analogies, computer science education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3641555.3705076,
author = {Chen, Matt},
title = {Early Adoption of Custom Generative AI Bots in Online Forums for CS Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705076},
doi = {10.1145/3641555.3705076},
abstract = {This lightning talk presents insights from a pilot program in an IT Faculty, where custom generative AI bots were integrated into online forums across 20 courses over two semesters in 2024. The AI bots were trained on specific course content and past student questions to provide tailored responses to student inquiries, with all responses reviewed by teaching staff before being released to students.This approach, distinct from the direct use of large language models (LLMs) like ChatGPT or Claude, offers targeted information aligned with course material and ensures accuracy while preventing the disclosure of assignment answers. The mechanism is designed to support large computer science courses, including first-year courses with over 1,000 students, where timely and comprehensive staff responses can be challenging.This talk will explore the benefits and drawbacks of using generative AI bots in the CS context. It will also examine the factors influencing staff acceptance and trust in chatbot responses and how AI impacts the types and quality of student questions in forums. Key lessons learned and challenges encountered during the program's implementation will also be shared.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1739},
numpages = {1},
keywords = {custom AI integration, generative AI bots},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3632621.3671429,
author = {Potriasaeva, Anna and Dzialets, Katsiaryna and Golubev, Yaroslav and Birillo, Anastasiia},
title = {Using a Low-Code Environment to Teach Programming in the Era of LLMs},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671429},
doi = {10.1145/3632621.3671429},
abstract = {LLMs change the landscape of software engineering, and the question arises: “How can we combine LLMs with traditional teaching approaches in computer science?”. In this work, we propose to teach students in a low-code environment of code generation, developing not only their coding but also decomposition and prompting skills.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {542–543},
numpages = {2},
keywords = {Generative AI, LLMs, MOOC, Programming Education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3706598.3713644,
author = {Rogers, Kantwon and Davis, Michael and Maharana, Mallesh and Etheredge, Pete and Chernova, Sonia},
title = {Playing Dumb to Get Smart: Creating and Evaluating an LLM-based Teachable Agent within University Computer Science Classes},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713644},
doi = {10.1145/3706598.3713644},
abstract = {This work presents the iterative design and evaluation of a large-language-model (LLM) based teachable agent, MatlabTutee, that facilitates learning-by-teaching (LBT) experiences within university computer science courses. We detail four different experiments, with a total of 119 students, where we refine our system, compare it to human-facilitated LBT experiences, and deploy it in two, month-long in-the-wild environments. We find that our system is able to successfully convey a learner persona similar to a human pretending to be novice while also providing comparable LBT benefits. These benefits include helping students identify areas for improvement, develop a more accurate assessment of their own abilities, and improve their overall attitudes toward computer science. We also explore how students choose to adopt our system into their study habits while situated in real university courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {126},
numpages = {22},
keywords = {Computer Science Education, LLM, Teachable Agent, Deception, Learning by Teaching, University Students, Longitudinal},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3723010.3723021,
author = {Fischer, David Vincent and Haug, Jim and Schoppel, Paul and Abke, J\"{o}rg and Becker, Matthias and Hagel, Georg},
title = {Evaluation of a Node-based Automatic Short Answer Tool “NodeGrade”},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723021},
doi = {10.1145/3723010.3723021},
abstract = {NodeGrade tries to provide a suitable solution for the problem of time-intensive short answer grading. This research focuses simultaneously on performance, functionality and user experience, which is underlined by a triangulated approach. The evaluation results show comparable performance of NodeGrade on public datasets, even outperforming GPT-4 on the SemEval 2013 Task 7. Matching of NodeGrade’s output with multiple human expert raters reveals some weaknesses regarding cases at the lower and upper boundary. In terms of user experience, the interviewed and observed students recognized both positive facets, like better learning support and helpful feedback, and negative sides, including technical limitations and lack of transparency. Overall, NodeGrade promises high potential for further practical use and testing in the field of software engineering education and automatic short answer grading.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {20–29},
numpages = {10},
keywords = {ASAG, Automatic Short Answer Grading, Short Answer Scoring, AI in Education, Software Engineering Education, Natural Language Processing, Large Language Models},
location = {
},
series = {ECSEE '25}
}

@article{10.1145/3687038,
author = {Kumar, Harsh and Musabirov, Ilya and Reza, Mohi and Shi, Jiakai and Wang, Xinyuan and Williams, Joseph Jay and Kuzminykh, Anastasia and Liut, Michael},
title = {Guiding Students in Using LLMs in Supported Learning Environments: Effects on Interaction Dynamics, Learner Performance, Confidence, and Trust},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687038},
doi = {10.1145/3687038},
abstract = {Personalized chatbot-based teaching assistants can be crucial in addressing increasing classroom sizes, especially where direct teacher presence is limited. Large language models (LLMs) offer a promising avenue, with increasing research exploring their educational utility. However, the challenge lies not only in establishing the efficacy of LLMs but also in discerning the nuances of interaction between learners and these models, which impact learners' engagement and results. We conducted a formative study in an undergraduate computer science classroom (N=145) and a controlled experiment on Prolific (N=356) to explore the impact of four pedagogically informed guidance strategies on the learners' performance, confidence and trust in LLMs. Direct LLM answers marginally improved performance, while refining student solutions fostered trust. Structured guidance reduced random queries as well as instances of students copy-pasting assignment questions to the LLM. Our work highlights the role that teachers can play in shaping LLM-supported learning environments.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {499},
numpages = {30},
keywords = {artificial intelligence in education, collaborative learning with ai, human-ai collaboration, large language models, transparency, tutoring systems}
}

@inproceedings{10.1145/3641555.3705235,
author = {Gonzalez, Elias and Chan, Joel and Weintrop, David},
title = {Quack! Configuring Large Language Models to Serve as Rubber Duck Coding Assistants},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705235},
doi = {10.1145/3641555.3705235},
abstract = {The emergence of Generative Artificial Intelligence (GenAI) tools broadly, and Large Language Models (LLMs) specifically, are equipping introductory programming instructors with a whole new class of pedagogical tools. While GenAI certainly poses threats to time-honored instructional techniques, it also provides opportunities for new forms of instructional support. In this work, we introduce our strategy for configuring an LLM to serve as a ''rubber duck debugging'' coding assistant to help novice programmers when they encounter difficulties in programming assignments. The key contribution of this work is not in the idea of using LLMs for debugging itself (which has already been demonstrated elsewhere, e.g., [3]) but to demonstrate the ease, flexibility, and pedagogical potential of the strategy. In particular, through carefully crafted prompts and easily accessible platforms, rubber duck LLMs can assist learners with specific questions while also situating those questions alongside larger computer science concepts and computational thinking practices. This work contributes an easily replicated and model-agnostic instructional strategy that productively and responsibly leverages the power of LLMs to assist novice programmers in developing foundational programming skills.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1463–1464},
numpages = {2},
keywords = {computer science education, generative ai, introductory programming, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649217.3653543,
author = {Bassner, Patrick and Frankford, Eduard and Krusche, Stephan},
title = {Iris: An AI-Driven Virtual Tutor for Computer Science Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653543},
doi = {10.1145/3649217.3653543},
abstract = {Integrating AI-driven tools in higher education is an emerging area with transformative potential. This paper introduces Iris, a chat-based virtual tutor integrated into the interactive learning platform Artemis that offers personalized, context-aware assistance in large-scale educational settings. Iris supports computer science students by guiding them through programming exercises and is designed to act as a tutor in a didactically meaningful way. Its calibrated assistance avoids revealing complete solutions, offering subtle hints or counter-questions to foster independent problem-solving skills. For each question, it issues multiple prompts in a Chain-of-Thought to GPT-3.5-Turbo. The prompts include a tutor role description and examples of meaningful answers through few-shot learning. Iris employs contextual awareness by accessing the problem statement, student code, and automated feedback to provide tailored advice. An empirical evaluation shows that students perceive Iris as effective because it understands their questions, provides relevant support, and contributes to the learning process. While students consider Iris a valuable tool for programming exercises and homework, they also feel confident solving programming tasks in computer-based exams without Iris. The findings underscore students' appreciation for Iris' immediate and personalized support, though students predominantly view it as a complement to, rather than a replacement for, human tutors. Nevertheless, Iris creates a space for students to ask questions without being judged by others.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {394–400},
numpages = {7},
keywords = {chatgpt, cs1, education technology, generative ai, interactive learning, large language models, programming exercises},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3636243.3636257,
author = {Budhiraja, Ritvik and Joshi, Ishika and Challa, Jagat Sesh and Akolekar, Harshal D. and Kumar, Dhruv},
title = {“It's not like Jarvis, but it's pretty close!” - Examining ChatGPT's Usage among Undergraduate Students in Computer Science},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636257},
doi = {10.1145/3636243.3636257},
abstract = {Large language models (LLMs) such as ChatGPT and Google Bard have garnered significant attention in the academic community. Previous research has evaluated these LLMs for various applications such as generating programming exercises and solutions. However, these evaluations have predominantly been conducted by instructors and researchers, not considering the actual usage of LLMs by students. This study adopts a student-first approach to comprehensively understand how undergraduate computer science students utilize ChatGPT, a popular LLM, released by OpenAI. We employ a combination of student surveys and interviews to obtain valuable insights into the benefits, challenges, and suggested improvements related to ChatGPT. Our findings suggest that a majority of students (over 57%) have a convincingly positive outlook towards adopting ChatGPT as an aid in coursework-related tasks. However, our research also highlights various challenges that must be resolved for long-term acceptance of ChatGPT amongst students. The findings from this investigation have broader implications and may be applicable to other LLMs and their role in computing education.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {124–133},
numpages = {10},
keywords = {ChatGPT, Computer Science Education, User Study},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3723010.3723012,
author = {Borghoff, Uwe M. and Minas, Mark and Schopp, Jannis},
title = {Generative AI in Student Software Development Projects: A User Study on Experiences and Self-Assessment},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723012},
doi = {10.1145/3723010.3723012},
abstract = {The way software is developed is changing rapidly due to the general availability of generative AI tools. As a result, the software engineering education that is part of every computer science program needs to change. Especially in software engineering courses, such AI tools need to be used and practiced in a meaningful and useful way. The programming project is one such course at our university, and the curriculum will be expanded accordingly in the future. In this paper we describe our approach and a user study among the participants of the last programming project, in which we collected experiences with the use of current AI tools, in particular highlighting their usefulness and limitations. Our study focuses on identifying which aspects of the course students used AI tools for, evaluating successful applications, and uncovering remaining challenges.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {161–170},
numpages = {10},
keywords = {software development project course, software engineering education, AI support, AI-based tutoring, experiments},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3597503.3639187,
author = {Nam, Daye and Macvean, Andrew and Hellendoorn, Vincent and Vasilescu, Bogdan and Myers, Brad},
title = {Using an LLM to Help With Code Understanding},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639187},
doi = {10.1145/3597503.3639187},
abstract = {Understanding code is challenging, especially when working in new and complex development environments. Code comments and documentation can help, but are typically scarce or hard to navigate. Large language models (LLMs) are revolutionizing the process of writing code. Can they do the same for helping understand it? In this study, we provide a first investigation of an LLM-based conversational UI built directly in the IDE that is geared towards code understanding. Our IDE plugin queries OpenAI's GPT-3.5-turbo model with four high-level requests without the user having to write explicit prompts: to explain a highlighted section of code, provide details of API calls used in the code, explain key domain-specific terms, and provide usage examples for an API. The plugin also allows for open-ended prompts, which are automatically contextualized to the LLM with the program being edited. We evaluate this system in a user study with 32 participants, which confirms that using our plugin can aid task completion more than web search. We additionally provide a thorough analysis of the ways developers use, and perceive the usefulness of, our system, among others finding that the usage and benefits differ between students and professionals. We conclude that in-IDE prompt-less interaction with LLMs is a promising future direction for tool builders.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {97},
numpages = {13},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3641555.3705064,
author = {Erez, Yael and Ayali, Lilach and Hazzan, Orit},
title = {Evolution of Students' Attitudes Towards the Use of Generative AI Tools in a CS1 Course: Implications for Instructors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705064},
doi = {10.1145/3641555.3705064},
abstract = {Recent advancements in large language model-based generative artificial intelligence (GenAI) tools have transformed computer science education, presenting both opportunities and challenges. A study investigating students' attitudes toward these tools was conducted during an Introduction to Computer Science course. The target of the study was to gauge students' evolving attitudes toward using GenAI tools in the course, before, during and after ChatGPT was gradually assimilated into homework assignments. The study refers to three phases: preliminary phase, assimilation phase, and calibration stage, which currently takes place. Findings show that, in the preliminary phase, students appreciated the efficiency of GenAI tools offered but were concerned about developing a dependency on these tools and about ''cheating''. Findings from the assimilation phase indicate that consistent, guided exposure to GenAI tools positively shifted students' views, alleviating initial concerns and promoting a positive attitude toward using GenAI tools in the course. The targets of the calibration phase are: a) to examine how to leverage independent learning by formulating clear guidelines that can build trust in the technology and help overcome concerns regarding reliability and credibility; b) to check how GenAI can help students in a Introduction to Computer Science course acquire skills such as critical thinking and code comprehension. The study offers insights for educators on the integration of GenAI tools into computer science courses to enhance learning while maintaining academic integrity.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1740},
numpages = {1},
keywords = {critical thinking, cs1, generative ai, introduction to computer science, mixed methods, program comprehension, skills, students' attitudes},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3636555.3636882,
author = {Dunder, Nora and Lundborg, Saga and Wong, Jacqueline and Viberg, Olga},
title = {Kattis vs ChatGPT: Assessment and Evaluation of Programming Tasks in the Age of Artificial Intelligence},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636882},
doi = {10.1145/3636555.3636882},
abstract = {AI-powered education technologies can support students and teachers in computer science education. However, with the recent developments in generative AI, and especially the increasingly emerging popularity of ChatGPT, the effectiveness of using large language models for solving programming tasks has been underexplored. The present study examines ChatGPT’s ability to generate code solutions at different difficulty levels for introductory programming courses. We conducted an experiment where ChatGPT was tested on 127 randomly selected programming problems provided by Kattis, an automatic software grading tool for computer science programs, often used in higher education. The results showed that ChatGPT independently could solve 19 out of 127 programming tasks generated and assessed by Kattis. Further, ChatGPT was found to be able to generate accurate code solutions for simple problems but encountered difficulties with more complex programming tasks. The results contribute to the ongoing debate on the utility of AI-powered tools in programming education.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {821–827},
numpages = {7},
keywords = {Academic Integrity, Automated Grading, ChatGPT, Programming Education},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3657604.3664663,
author = {Wang, Tianjia and Ramanujan, Ramaraja and Lu, Yi and Mao, Chenyu and Chen, Yan and Brown, Chris},
title = {DevCoach: Supporting Students in Learning the Software Development Life Cycle at Scale with Generative Agents},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664663},
doi = {10.1145/3657604.3664663},
abstract = {Supporting novice computer science students in learning the software development life cycle (SDLC) at scale is vital for ensuring the quality of future software systems. However, this presents unique challenges, including the need for effective interactive collaboration and access to diverse skill sets of members in the software development team. To address these problems, we present ''DevCoach'', an online system designed to support students learning the SDLC at scale by interacting with generative agents powered by large language models simulating members with different roles in a software development team. Our preliminary user study results reveal that DevCoach improves the experiences and outcomes for students, with regard to learning concepts in SDLC's ''Plan and Design'' and ''Develop'' phases. We aim to use our findings to enhance DevCoach to support the entire SDLC workflow by incorporating additional simulated roles and enabling students to choose their project topics. Future studies will be conducted in an online Software Engineering class at our institution, aiming to explore and inspire the development of intelligent systems that provide comprehensive SDLC learning experiences to students at scale.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {351–355},
numpages = {5},
keywords = {computer science education, generative ai, software development life cycle, software engineering},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641554.3701800,
author = {Shah, Anshul and Chernova, Anya and Tomson, Elena and Porter, Leo and Griswold, William G. and Soosai Raj, Adalbert Gerald},
title = {Students' Use of GitHub Copilot for Working with Large Code Bases},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701800},
doi = {10.1145/3641554.3701800},
abstract = {Large language models (LLMs) are already heavily used by professional software engineers. An important skill for new university graduates to possess will be the ability to use such LLMs to effectively navigate and modify a large code base. While much of the prior work related to LLMs in computing education focuses on novice programmers learning to code, less work has focused on how upper-division students use and trust these tools, especially while working with large code bases. In this study, we taught students about various GitHub Copilot features, including Copilot chat, in an upper-division software engineering course and asked students to add a feature to a large code base using Copilot. Our analysis revealed a novel interaction pattern that we call one-shot prompting, in which students ask Copilot to implement the entire feature at once and spend the next few prompts asking Copilot to debug the code or asking Copilot to regenerate its incorrect response. Finally, students reported significantly more trust in the code comprehension features than code generation features of Copilot, perhaps due to the presence of trust affordances in the Copilot chat that are absent in the code generation features. Our study takes the first steps in understanding how upper-division students use Github Copilot so that our instruction can adequately prepare students for a career in software engineering.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1050–1056},
numpages = {7},
keywords = {github copilot, large code bases, program comprehension, trust},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@book{10.1145/3708897,
author = {Giacaman, Nasser and Terragni, Valerio},
title = {Empowering Computing Students with Large Language Models by Developing an Escape Room Game},
year = {2025},
isbn = {9798400714450},
abstract = {In this project, computing students learn to integrate large language models (LLMs) into a software system. Students develop a Java application with a basic graphical user interface (GUI) using JavaFX, gain practical experience with prompt engineering, and learn about the impact of LLM parameters and conversational roles. Students are provided with a Javabased API that connects with OpenAI's GPT model. The project emphasizes teaching students to manage LLM API calls, enhance GUI responsiveness, and improve the user experience all in the context of an AI-powered application. This experience equips them with critical skills in software development and AI application. It prepares them for advanced software development by learning how to create effective LLM prompts to create intelligent and user-friendly applications. We share the experience of using this project and provide guidelines for assessing it in a second-year software engineering undergraduate course, where students' prior programming experience is limited to the prerequisite CS2 course on object-oriented programming. In the case study we present, the project involved developing a riddle-solving escape room, which we called EscAIpe Room.},
numpages = {6}
}

@article{10.5555/3665464.3665480,
author = {Manley, Eric D.},
title = {Getting Started with Large Language Models for the CS Curriculum},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {With the introduction of ChatGPT in late 2022, popular interest in language-based Artificial Intelligence has exploded. Employers are looking to hire computer scientists who can leverage large language models (LLMs) [2], and student demand for learning about them at many higher education institutions has followed. This one-hour workshop will help computer science educators respond to this demand by introducing the Python transformers library and its associated LLM ecosystem [1]. We will discuss how LLMs can be integrated into college computer science curricula from CS 1 through advanced courses in Artificial Intelligence, Machine Learning, or Natural Language Processing. Specific topics include• Using the transformers library with pre-trained models for inference tasks like sentiment analysis, text classification, summarization, translation, and question answering in only a few lines of code• Searching for and using hundreds of thousands of different pre-trained language models hosted by Hugging Face along with datasets that they can be tested on• Utilizing conversational models to build chat bots},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {116–117},
numpages = {2}
}

@inproceedings{10.1145/3641555.3705061,
author = {Liu, Rongxin and Xu, Benjamin and Perez, Christopher and Zhao, Julianna and Zhukovets, Yuliia and Malan, David J.},
title = {Assessment in CS50 with AI: Leveraging Generative Artificial Intelligence for Personalized Student Evaluation},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705061},
doi = {10.1145/3641555.3705061},
abstract = {The scalability challenges of code review and pair-programming assessments in large computer science courses, such as CS50 at Harvard University, have opened up opportunities for the application of Generative AI. Leveraging large language models (LLMs), CS50.ai offers a suite of AI-based tools that assist both students and instructors in mastering course material while overcoming the limitations posed by human resource constraints. This demo highlights how generative AI can be employed to conduct code reviews and pair-programming simulations, providing real-time feedback, code explanations, and collaborative programming insights. By integrating these AI tools into students' learning journeys, we aim to mimic the 1:1 interaction between instructor and student, improving both formative and summative assessments. We will showcase how these tools are implemented to scale personalized feedback, ensure academic integrity, and maintain pedagogical efficacy. Our presentation will also reflect on lessons learned from deploying these AI-driven tools in recent course offerings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1735},
numpages = {1},
keywords = {AI, LLMs, artificial intelligence, generative AI, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3643795.3648375,
author = {Grandel, Skyler and Schmidt, Douglas C. and Leach, Kevin},
title = {Applying Large Language Models to Enhance the Assessment of Parallel Functional Programming Assignments},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648375},
doi = {10.1145/3643795.3648375},
abstract = {Courses in computer science (CS) often assess student programming assignments manually, with the intent of providing in-depth feedback to each student regarding correctness, style, efficiency, and other quality attributes. As class sizes increase, however, it is hard to provide detailed feedback consistently, especially when multiple assessors are required to handle a larger number of assignment submissions. Large language models (LLMs), such as ChatGPT, offer a promising alternative to help automate this process in a consistent, scalable, and minimally-biased manner.This paper explores ChatGPT-4's scalablility and accuracy in assessing programming assignments based on predefined rubrics in the context of a case study we conducted in an upper-level undergraduate and graduate CS course at Vanderbilt University. In this case study, we employed a method that compared assessments generated by ChatGPT-4 against human graders to measure the accuracy, precision, and recall associated with identifying programming mistakes. Our results show that when ChatGPT-4 is used properly (e.g., with appropriate prompt engineering and feature selection) it can improve objectivity and grading efficiency, thereby acting as a complementary tool to human graders for advanced computer science graduate and undergraduate students.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {102–110},
numpages = {9},
keywords = {ChatGPT, education, generative AI, large language models, prompt engineering, automated grading},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3663433.3663456,
author = {Sinha, Ravi and Solola, Idris and Nguyen, Ha and Swanson, Hillary and Lawrence, LuEttaMae},
title = {The Role of Generative AI in Qualitative Research: GPT-4's Contributions to a Grounded Theory Analysis},
year = {2024},
isbn = {9798400717222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663433.3663456},
doi = {10.1145/3663433.3663456},
abstract = {We present reflections on our experience using a generative AI model in qualitative research, to illuminate the AI's contributions to our analytic process. Our analytic focus was a segment of classroom transcript, which captured a teacher introducing scientific theory-building practices to middle school students. We used a grounded theory approach to produce a fine-grained characterization of the teacher's talk moves during the lesson implementation. Our eventual goal is to build a more nuanced conceptualization of responsive teaching in the context of theory-building activities. We involved GPT-4 during the initial exploratory and later focused coding stages. For our analysis of GPT-4’s contributions to the analytic process, we analyzed our notes and analytic memos, along with video recordings of meetings where we discussed insights in response to GPT-4’s input. We present vignettes to illustrate pivotal moments where AI contributed to the coding process, including code generation, comparison, and refinement. The paper presents our experiences of conducting qualitative research in partnership with generative AI, underscoring the role that emerging technologies can play in the analysis of data and the development of grounded theory.},
booktitle = {Proceedings of the 2024 Symposium on Learning, Design and Technology},
pages = {17–25},
numpages = {9},
keywords = {Generative AI, Grounded theory, Qualitative methodologies, Responsive teaching},
location = {Delft, Netherlands},
series = {LDT '24}
}

@inproceedings{10.1145/3626252.3630803,
author = {Joshi, Ishika and Budhiraja, Ritvik and Dev, Harshal and Kadia, Jahnvi and Ataullah, Mohammad Osama and Mitra, Sayan and Akolekar, Harshal D. and Kumar, Dhruv},
title = {ChatGPT in the Classroom: An Analysis of Its Strengths and Weaknesses for Solving Undergraduate Computer Science Questions},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630803},
doi = {10.1145/3626252.3630803},
abstract = {This research paper aims to analyze the strengths and weaknesses associated with the utilization of ChatGPT as an educational tool in the context of undergraduate computer science education. ChatGPT's usage in tasks such as solving assignments and exams has the potential to undermine students' learning outcomes and compromise academic integrity. This study adopts a quantitative approach to demonstrate the notable unreliability of ChatGPT in providing accurate answers to a wide range of questions within the field of undergraduate computer science. While the majority of existing research has concentrated on assessing the performance of Large Language Models in handling programming assignments, our study adopts a more comprehensive approach. Specifically, we evaluate various types of questions such as true/false, multi-choice, multi-select, short answer, long answer, design-based, and coding-related questions. Our evaluation highlights the potential consequences of students excessively relying on ChatGPT for the completion of assignments and exams, including self-sabotage. We conclude with a discussion on how can students and instructors constructively use ChatGPT and related tools to enhance the quality of instruction and the overall student experience.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {625–631},
numpages = {7},
keywords = {chatgpt, computer science, education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3737313.3737340,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Noory, Naqib A. and Vautor-Laplaceliere, Daena D.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Higher Education},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {This empirical study investigated the impact of Generative AI (GenAI) tools, particularly large language models (LLMs), on college students' Python programming skills in a graduate-level data science course. Using a pretest-posttest methodology and accounting for variables like prior programming experience, the research examined how guided LLM usage affected students' self-assessed programming abilities. The findings revealed that while LLMs positively influenced students' capacity to develop complex applications, work with Python libraries, and write quality code, they had no significant impact on students' grasp of fundamental Python concepts or their general comfort with the language. These results suggest that LLMs serve as effective tools for advancing practical programming skills but cannot substitute for the foundational programming knowledge that must be developed through traditional learning.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {163–177},
numpages = {15}
}

@inproceedings{10.1145/3626253.3635592,
author = {Niousha, Rose and Hoq, Muntasir and Akram, Bita and Norouzi, Narges},
title = {Use of Large Language Models for Extracting Knowledge Components in CS1 Programming Exercises},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635592},
doi = {10.1145/3626253.3635592},
abstract = {This study utilizes large language models to extract foundational programming concepts in programming assignments in a CS1 course. We seek to answer the following research questions: RQ1. How effectively can large language models identify knowledge components in a CS1 course from programming assignments? RQ2. Can large language models be used to extract program-level knowledge components, and how can the information be used to identify students' misconceptions? Preliminary results demonstrated a high similarity between course-level knowledge components retrieved from a large language model and that of an expert-generated list.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1762–1763},
numpages = {2},
keywords = {cs1, curriculum design, knowledge component},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3593663.3593695,
author = {Dobslaw, Felix and Bergh, Peter},
title = {Experiences with Remote Examination Formats in Light of GPT-4},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593695},
doi = {10.1145/3593663.3593695},
abstract = {Sudden access to the rapidly improving large language model GPT by OpenAI forces educational institutions worldwide to revisit their exam procedures. In the pre-GPT era, we successfully applied oral and open-book home exams for two courses in the third year of our predominantly remote Software Engineering BSc program. We ask in this paper whether our current open-book exams are still viable or whether a move back to a legally compliant but less scalable oral exam is the only workable alternative. We further compare work-effort estimates between oral and open-book exams and report on differences in throughput and grade distribution over eight years to better understand the impact of examination format on the outcome. Examining GPT-4 on the most recent open-book exams showed that our current Artificial Intelligence and Reactive Programming exams are not GPT v4 proof. Three potential weaknesses of GPT are outlined. We also found that grade distributions have largely been unaffected by the examination format, opening up for a move to oral examinations only if needed. Throughput was higher for open-book exam course instances (73% vs 64%), while fail rates were too (12% vs 7%), with teacher workload increasing even for smaller classes. We also report on our experience regarding effort. Oral examinations are efficient for smaller groups but come with caveats regarding intensity and stress.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {220–225},
numpages = {6},
keywords = {Software Engineering Education, Oral Examinations, Examination Formats, ChatGPT},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3626252.3630863,
author = {Del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating Automatically Generated Contextualised Programming Exercises},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630863},
doi = {10.1145/3626252.3630863},
abstract = {Introductory programming courses often require students to solve many small programming exercises as part of their learning. Researchers have previously suggested that the context used in the problem description for these exercises is likely to impact student engagement and motivation. Furthermore, supplying programming exercises that use a broad range of contexts or even allowing students to select contexts to personalize their own exercises, may support the interests of a diverse student population. Unfortunately, it is time-consuming for instructors to create large numbers of programming exercises that provide a wide range of contextualized problems. However, recent work has shown that large language models may be able to automate the mass production of programming exercises, reducing the burden on instructors. In this research, we explore the potential of OpenAI's GPT-4 to create high-quality and novel programming exercises that implement various contexts. Finally, through prompt engineering, we compare different prompting strategies used to generate many programming exercises with various contextualized problem descriptions and then evaluate the quality of the exercises generated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {289–295},
numpages = {7},
keywords = {chatgpt, cs1, gpt-4, large language models, novice programmers, openai, programming exercises, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3710795.3710797,
author = {Tran, Nicholas},
title = {The Book Review Column},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {4},
issn = {0163-5700},
url = {https://doi.org/10.1145/3710795.3710797},
doi = {10.1145/3710795.3710797},
abstract = {Foundation Mathematics for Computer Science: A Visual Approach, 4th edition (Springer, 2023) by John Vince (Bournemouth University, UK) is a comprehensive collection of discrete and continuous mathematical topics that are covered in most undergraduate programs in computer science. The subtitle refers to the author's use of colored graphs and tables to illustrate the concepts.Online Algorithms (Cambridge University Press, 2023) by Rahul Vaze (Tata Institute of Fundamental Research, India) is an accessible but rigorous introduction to the area aimed at advanced undergraduates and beginning graduate students. The book covers the basic as well as applied online problems with a preference of elegant analysis over performance.Privacy-preserving Computing for Big Data Analytics and AI (Cambridge University Press, 2023) by Kai Chen and Qiang Yang (Hong Kong University of Science and Technology) is a systematic examination of the history, theories, techniques, applications, and future of the field.Prize-winning neuroscientist Terrence Sejnowski (University of California at San Diego) explains the technology and mathematics behind large language models such as ChatGPT and explores the debate on their so-called comprehension of language in ChatGPT and the Future of AI: The Deep Language Revolution (The MIT Press, 2024).},
journal = {SIGACT News},
month = dec,
pages = {3–20},
numpages = {18}
}

@inproceedings{10.1145/3626253.3635511,
author = {Bhalerao, Rasika},
title = {My Learnings from Allowing Large Language Models in Introductory Computer Science Classes},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635511},
doi = {10.1145/3626253.3635511},
abstract = {Many instructors want to allow their students to use large language models (LLMs) in their introductory computer science courses, but they first want to see other instructors' results from doing so before taking on the risk in their own courses. Presented here are the results from allowing students to use LLMs in the second course in a sequence of intensive introductory courses designed to prepare students with a non-computational background for entry into a masters' degree program. We allowed students to use the internet and LLMs (such as ChatGPT or Github Copilot) to help with assignments, with guidelines to avoid plagiarism and encourage learning. We then surveyed students to ask about how they used LLMs, whether they saw others cheating, how they generally used internet-based resources on assignments and exams, and their feedback on the policies. We found that students are overwhelmingly using LLMs (and the internet generally) to learn and code "better" rather than cheat. These results are intended to be a starting point to spark discussion on the adoption of new technologies in introductory computer science courses. The authors themselves will continue teaching courses with the policy that students should interact with an LLM the way they interact with a person: students are encouraged to discuss and collaborate with it, but copying code from it is considered plagiarism.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1574–1575},
numpages = {2},
keywords = {AI, assignments, plagiarism, students},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3610661.3616177,
author = {Higasa, Taichi and Tanaka, Keitaro and Feng, Qi and Morishima, Shigeo},
title = {Gaze-Driven Sentence Simplification for Language Learners: Enhancing Comprehension and Readability},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3616177},
doi = {10.1145/3610661.3616177},
abstract = {Language learners should regularly engage in reading challenging materials as part of their study routine. Nevertheless, constantly referring to dictionaries is time-consuming and distracting. This paper presents a novel gaze-driven sentence simplification system designed to enhance reading comprehension while maintaining their focus on the content. Our system incorporates machine learning models tailored to individual learners, combining eye gaze features and linguistic features to assess sentence comprehension. When the system identifies comprehension difficulties, it provides simplified versions by replacing complex vocabulary and grammar with simpler alternatives via GPT-3.5. We conducted an experiment with 19 English learners, collecting data on their eye movements while reading English text. The results demonstrated that our system is capable of accurately estimating sentence-level comprehension. Additionally, we found that GPT-3.5 simplification improved readability in terms of traditional readability metrics and individual word difficulty, paraphrasing across different linguistic levels.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {292–296},
numpages = {5},
keywords = {sentence simplification, machine learning, human-computer interaction, Eye tracking},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@article{10.1145/3722229,
author = {AlOmar, Eman Abdullah},
title = {Nurturing Code Quality: Leveraging Static Analysis and Large Language Models for Software Quality in Education},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722229},
doi = {10.1145/3722229},
abstract = {Large Language Models (LLMs), such as ChatGPT, have become widely popular for various software engineering tasks, including programming, testing, code review, and program comprehension. However, their impact on improving software quality in educational settings remains uncertain. This article explores our experience teaching the use of Programming Mistake Detector (PMD) to foster a culture of bug fixing and leverage LLM to improve software quality in the classroom. This article discusses the results of an experiment involving 155 submissions that carried out a code review activity of 1,658 rules. Our quantitative and qualitative analyses reveal that a set of PMD quality issues influences the acceptance or rejection of the issues, and design-related categories that take longer to resolve. Although students acknowledge the potential of using ChatGPT during code review, some skepticism persists. Further, constructing prompts for ChatGPT that possess clarity, complexity, and context nurtures vital learning outcomes, such as enhanced critical thinking, and among the 1,658 issues analyzed, 93% of students indicated that ChatGPT did not identify any additional issues beyond those detected by PMD. Conversations between students and ChatGPT encompass five categories, including ChatGPT’s use of affirmation phrases like “certainly” regarding bug fixing decisions, and apology phrases such as “apologize” when resolving challenges. Through this experiment, we demonstrate that code review can become an integral part of the educational computing curriculum. We envision our findings to enable educators to support students with effective code review strategies, increasing awareness of LLMs, and promoting software quality in education.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {16},
numpages = {36},
keywords = {large language models, education, bugfix, static analysis, code quality}
}

@inproceedings{10.1145/3568812.3603453,
author = {Tran, Minh},
title = {Prompt Engineering for Large Language Models to Support K-8 Computer Science Teachers in Creating Culturally Responsive Projects},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603453},
doi = {10.1145/3568812.3603453},
abstract = {The power of large language models has opened up opportunities for educational use. In computing education, recent studies have demonstrated the potential of these models to improve learning and teaching experiences in university-level programming courses. However, research into leveraging them to aid computer science instructors in curriculum development and course material design is relatively sparse, especially at the K-12 level. This work aims to fill this gap by exploring the capability of large language models in ideating and designing culturally responsive projects for elementary and middle school programming classes. Our ultimate goal is to support K-8 teachers in effectively extracting suggestions from large language models by only using natural language modifications. Furthermore, we aim to develop a comprehensive assessment framework for culturally responsive AI-generated project ideas. We also hope to provide valuable insight into teachers’ perspectives on large language models and their integration into teaching practices.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {110–112},
numpages = {3},
keywords = {culturally responsive pedagogy, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3640544.3645215,
author = {Laney, Mason and Dewan, Prasun},
title = {Human-AI Collaboration in a Student Discussion Forum},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645215},
doi = {10.1145/3640544.3645215},
abstract = {The recent public releases of AI tools such as ChatGPT have forced computer science educators to reconsider how they teach. These tools have demonstrated considerable ability to generate code and answer conceptual questions, rendering them incredibly useful for completing CS coursework. While overreliance on AI tools could hinder students’ learning, we believe they have the potential to be a helpful resource for both students and instructors alike. We propose a novel system for instructor-mediated GPT interaction in a class discussion board. By automatically generating draft responses to student forum posts, GPT can help Teaching Assistants (TAs) respond to student questions in a more timely manner, giving students an avenue to receive fast, quality feedback on their solutions without turning to ChatGPT directly. Additionally, since they are involved in the process, instructors can ensure that the information students receive is accurate, and can provide students with incremental hints that encourage them to engage critically with the material, rather than just copying an AI-generated snippet of code. We utilize Piazza—a popular educational forum where TAs help students via text exchanges—as a venue for GPT-assisted TA responses to student questions. These student questions are sent to GPT-4 alongside assignment instructions and a customizable prompt, both of which are stored in editable instructor-only Piazza posts. We demonstrate an initial implementation of this system, and provide examples of student questions that highlight its benefits.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {74–77},
numpages = {4},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3641555.3704754,
author = {Bhattacharya, Sambit and Uma, Ravanasamudram and Deb, Debzani},
title = {Integrating Data Science for Social Justice: A Tutorial on Developing Non-Traditional Pathways for Non-CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704754},
doi = {10.1145/3641555.3704754},
abstract = {In response to the growing need for socially responsible computer scientists and data scientists, our team is developing a comprehensive data science certificate program specifically tailored for non-computing majors, with a focus on data science for social justice. This program aims to broaden participation in data science and create non-traditional pathways for diverse student populations. Each course in the program is designed to be accessible to non-computing majors, equipping them with the skills to analyze and address social justice issues through data science. Process Oriented Guided Inquiry Learning (POGIL) is employed as an instructional strategy promoting active learning, and real datasets related to social justice are utilized for hands-on activities and assignments, enhancing practical learning experiences. The courses are taught in a synchronous hybrid format, across multiple universities, accommodating both live online and in-person students.This tutorial will equip educators with the tools to incorporate data science for social justice in their courses. Attendees will have access to materials developed for these courses, enabling them to integrate similar content into their own curricula. A key focus is on recent challenges and opportunities created by generative AI. The presenters will share their experiences, course materials, and strategies for introducing computer science through a social justice lens. Participants will share ideas and strategies, which will be collated and made available in a shared repository. This initiative aims to enable educators to train future generations in data science while addressing social justice issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {certificate program, data science, non-computing majors, social justice},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3636555.3636853,
author = {Singh, Anjali and Brooks, Christopher and Wang, Xu and Li, Warren and Kim, Juho and Wilson, Deepti},
title = {Bridging Learnersourcing and AI: Exploring the Dynamics of Student-AI Collaborative Feedback Generation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636853},
doi = {10.1145/3636555.3636853},
abstract = {This paper explores the space of optimizing feedback mechanisms in complex domains such as data science, by combining two prevailing approaches: Artificial Intelligence (AI) and learnersourcing. Towards addressing the challenges posed by each approach, this work compares traditional learnersourcing with an AI-supported approach. We report on the results of a randomized controlled experiment conducted with 72 Master’s level students in a data visualization course, comparing two conditions: students writing hints independently versus revising hints generated by GPT-4. The study aimed to evaluate the quality of learnersourced hints, examine the impact of student performance on hint quality, gauge learner preference for writing hints with versus without AI support, and explore the potential of the student-AI collaborative exercise in fostering critical thinking about LLMs. Based on our findings, we provide insights for designing learnersourcing activities leveraging AI support and optimizing students’ learning as they interact with LLMs.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {742–748},
numpages = {7},
keywords = {Data Visualization, Feedback Generation, GPT-4, Learnersourcing},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3626252.3630826,
author = {Hoq, Muntasir and Shi, Yang and Leinonen, Juho and Babalola, Damilola and Lynch, Collin and Price, Thomas and Akram, Bita},
title = {Detecting ChatGPT-Generated Code Submissions in a CS1 Course Using Machine Learning Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630826},
doi = {10.1145/3626252.3630826},
abstract = {The emergence of publicly accessible large language models (LLMs) such as ChatGPT poses unprecedented risks of new types of plagiarism and cheating where students use LLMs to solve exercises for them. Detecting this behavior will be a necessary component in introductory computer science (CS1) courses, and educators should be well-equipped with detection tools when the need arises. However, ChatGPT generates code non-deterministically, and thus, traditional similarity detectors might not suffice to detect AI-created code. In this work, we explore the affordances of Machine Learning (ML) models for the detection task. We used an openly available dataset of student programs for CS1 assignments and had ChatGPT generate code for the same assignments, and then evaluated the performance of both traditional machine learning models and Abstract Syntax Tree-based (AST-based) deep learning models in detecting ChatGPT code from student code submissions. Our results suggest that both traditional machine learning models and AST-based deep learning models are effective in identifying ChatGPT-generated code with accuracy above 90%. Since the deployment of such models requires ML knowledge and resources that are not always accessible to instructors, we also explore the patterns detected by deep learning models that indicate possible ChatGPT code signatures, which instructors could possibly use to detect LLM-based cheating manually. We also explore whether explicitly asking ChatGPT to impersonate a novice programmer affects the code produced. We further discuss the potential applications of our proposed models for enhancing introductory computer science instruction.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {526–532},
numpages = {7},
keywords = {artificial intelligence, chatgpt, cheat detection, cs1, introductory programming course, large language model, plagiarism detection},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701959,
author = {Wu, Ylesia and Zheng, Qirui and Lau, Sam},
title = {How Novices Use Program Visualizations to Understand Code that Manipulates Data Tables},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701959},
doi = {10.1145/3641554.3701959},
abstract = {As data science and artificial intelligence continue to impact society, more and more people are learning how to manipulate data with code. To support these learners, program visualization tools automatically generate diagrams to show how code transforms data, in contrast to tools based on large language models (LLMs) that primarily focus on textual explanations. Although program visualization tools are popular among instructors, do novices find these tools usable and useful for data science programs that often manipulate datasets with many rows? To address this, we evaluate a popular, publicly available tool that generates diagrams for Python pandas code through a randomized, in-lab usability study with 17 data science novices. Despite minimal instruction on how to use the tool, novices found that program visualizations increased their confidence in comprehending and debugging code. In addition, even though the tool sometimes produced diagrams with many visual elements, participant performance on the study tasks was not negatively impacted. These findings suggest design guidelines for program visualization tools to help manage cognitive load for data science novices. To our knowledge, this is the first empirical study that investigates how novices use program visualization tools to understand code that manipulates data tables, and suggests a future where novices can use automatically generated diagrams as a complement to LLM tools for effectively understanding unfamiliar programs in data science.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1267–1273},
numpages = {7},
keywords = {data science education, novice programmers, program visualization tools},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705201,
author = {Bejarano, Andres and Dickey, Ethan and Setsma, Rhianna},
title = {Implementing the AI-Lab Framework: Enhancing Introductory Programming Education for CS Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705201},
doi = {10.1145/3641555.3705201},
abstract = {The advent of generative AI tools presents novel opportunities and challenges in computer science education, particularly in introductory programming courses. This study explores the implementation of AI-Lab, a framework designed to guide students in the effective and ethical use of generative AI, in this case ChatGPT, in academic settings without compromising skill development. Conducted during Spring 2024, our use of the intervention targeted over 500 Computer Science and Data Science majors enrolled in their major-specific Data Structures and Algorithms courses. The AI-Lab framework enabled students to develop both conceptual questions and c++ and Python programs by interacting with ChatGPT and iteratively correcting its errors. Focus groups and post-intervention surveys revealed a generally positive experience. Students appreciated the ability to leverage AI for tasks outside their major, recognizing the value of understanding correct solutions through AI-assisted programming. Moreover, the guided use of generative AI by professors alleviated concerns regarding academic dishonesty, fostering a supportive learning environment. Despite these benefits, students expressed awareness of the potential drawbacks of over-reliance on AI, noting the risk of impeding their professional growth. Nevertheless, they acknowledged the practical utility of AI for non-major related tasks. This study highlights the importance of incorporating structured AI training in curricula to balance skill development and ethical AI usage, offering insights for broader applications in higher education.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1383–1384},
numpages = {2},
keywords = {ai lab, ai-assisted programming, ai-lab framework, ethical ai usage, generative ai in education, skill development with ai, structured ai training},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3658644.3670392,
author = {Liu, Zeyan and Yao, Zijun and Li, Fengjun and Luo, Bo},
title = {On the Detectability of ChatGPT Content: Benchmarking, Methodology, and Evaluation through the Lens of Academic Writing},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670392},
doi = {10.1145/3658644.3670392},
abstract = {With ChatGPT under the spotlight, utilizing large language models (LLMs) to assist academic writing has drawn a significant amount of debate in the community. In this paper, we aim to present a comprehensive study of the detectability of ChatGPT-generated content within the academic literature, particularly focusing on the abstracts of scientific papers, to offer holistic support for the future development of LLM applications and policies in academia. Specifically, we first present GPABench2, a benchmarking dataset of over 2.8 million comparative samples of human-written, GPT-written, GPT-completed, and GPT-polished abstracts of scientific writing in computer science, physics, and humanities and social sciences. Second, we explore the methodology for detecting ChatGPT content. We start by examining the unsatisfactory performance of existing ChatGPT detecting tools and the challenges faced by human evaluators (including more than 240 researchers or students). We then test the hand-crafted linguistic features models as a baseline and develop a deep neural framework named CheckGPT to better capture the subtle and deep semantic and linguistic patterns in ChatGPT written literature. Last, we conduct comprehensive experiments to validate the proposed CheckGPT framework in each benchmarking task over different disciplines. To evaluate the detectability of ChatGPT content, we conduct extensive experiments on the transferability, prompt engineering, and robustness of CheckGPT.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {2236–2250},
numpages = {15},
keywords = {aigc detection, large language models, responsible ai},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3706468.3706500,
author = {Duan, Zhangqi and Fernandez, Nigel and Hicks, Alexander and Lan, Andrew},
title = {Test Case-Informed Knowledge Tracing for Open-ended Coding Tasks},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706500},
doi = {10.1145/3706468.3706500},
abstract = {Open-ended coding tasks, which ask students to construct programs according to certain specifications, are common in computer science education. Student modeling can be challenging since their open-ended nature means that student code can be diverse. Traditional knowledge tracing (KT) models that only analyze response correctness may not fully capture nuances in student knowledge from student code. In this paper, we introduce Test case-Informed Knowledge Tracing for Open-ended Coding (TIKTOC), a framework to simultaneously analyze and predict both open-ended student code and whether the code passes each test case. We augment the existing CodeWorkout dataset with the test cases used for a subset of the open-ended coding questions, and propose a multi-task learning KT method to simultaneously analyze and predict 1) whether a student’s code submission passes each test case and 2) the student’s open-ended code, using a large language model as the backbone. We quantitatively show that these methods outperform existing KT methods for coding that only use the overall score a code submission receives. We also qualitatively demonstrate how test case information, combined with open-ended code, helps us gain fine-grained insights into student knowledge.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {238–248},
numpages = {11},
keywords = {Computer Science Education, Large Language Models, Open-ended Coding Questions, Test Cases},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3581754.3584111,
author = {Cao, Chen},
title = {Scaffolding CS1 Courses with a Large Language Model-Powered Intelligent Tutoring System},
year = {2023},
isbn = {9798400701078},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581754.3584111},
doi = {10.1145/3581754.3584111},
abstract = {Programming skills are rapidly becoming essential for many educational paths and career opportunities. Yet, for many international students, the traditional approach to teaching introductory programming courses can be a significant challenge due to the complexities of the language, the lack of prior programming knowledge, and the language and cultural barriers. This study explores how large language models and gamification can scaffold coding learning and increase Chinese students’ sense of belonging in introductory programming courses. In this project, a gamification intelligent tutoring system was developed to adapt to Chinese international students’ learning needs and provides scaffolding to support their success in introductory computer programming courses. My research includes three studies: a formative study, a user study of an initial prototype, and a computer simulation study with a user study in progress. Both qualitative and quantitative data were collected through surveys, observations, focus group discussions and computer simulation. The preliminary findings suggest that GPT-3-enhanced gamification has great potential in scaffolding introductory programming learning by providing adaptive and personalised feedback, increasing students’ sense of belonging, and reducing their anxiety about learning programming.},
booktitle = {Companion Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {229–232},
numpages = {4},
location = {Sydney, NSW, Australia},
series = {IUI '23 Companion}
}

@inproceedings{10.1145/3701716.3715199,
author = {Zhang, Yifan and Zhao, Xinkui and Wang, Zuxin and Zhou, Zhengyi and Cheng, Guanjie and Deng, Shuiguang and Yin, Jianwei},
title = {SortingHat: Redefining Operating Systems Education with a Tailored Digital Teaching Assistant},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715199},
doi = {10.1145/3701716.3715199},
abstract = {Operating Systems (OS) courses are among the most challenging in computer science education due to the complexity of internal structures and the diversity of running environments. Traditional teaching methods often fail to address the diverse backgrounds, learning speeds, and practical needs of students. To tackle these challenges, we present SortingHat, a personalized digital teaching assistant tailored specifically for OS education. SortingHat integrates advanced AI technologies, including a retrieval-augmented generation (RAG) framework and multi-agent reinforcement learning (MARL), to deliver adaptive, scalable, and effective educational support. SortingHat features a 3D digital human interface powered by large language models (LLMs) to provide personalized, empathetic, and context-aware guidance. It generates tailored exercises based on each student's learning history and academic performance, reinforcing weak areas and challenging advanced concepts. Additionally, the system incorporates a robust evaluation pipeline that ensures fair, consistent, and unbiased grading of student submissions while delivering personalized, actionable feedback for improvement. By combining personalized guidance, adaptive content creation, and automated assessment, SortingHat transforms OS education into an engaging, immersive, and scalable experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2951–2954},
numpages = {4},
keywords = {digital human, education, large language models, multi agent reinforcement learning, retrieval augmented generation},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3663649.3664368,
author = {Aerts, Willem and Fletcher, George and Miedema, Daphne},
title = {A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664368},
doi = {10.1145/3663649.3664368},
abstract = {SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {13–19},
numpages = {7},
keywords = {Assessment, ChatGPT, Education, LLM, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3626252.3630817,
author = {Fernandez, Amanda S. and Cornell, Kimberly A.},
title = {CS1 with a Side of AI: Teaching Software Verification for Secure Code in the Era of Generative AI},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630817},
doi = {10.1145/3626252.3630817},
abstract = {As AI-generated code promises to become an increasingly relied upon tool for software developers, there is a temptation to call for significant changes to early computer science curricula. A move from syntax-focused topics in CS1 toward abstraction and high-level application design seems motivated by the new large language models (LLMs) recently made available. In this position paper however, we advocate for an approach more informed by the AI itself - teaching early CS learners not only how to use the tools but also how to better understand them. Novice programmers leveraging AI-code-generation without proper understanding of syntax or logic can create "black box" code with significant security vulnerabilities. We outline methods for integrating basic AI knowledge and traditional software verification steps into CS1 along with LLMs, which will better prepare students for software development in professional settings.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {345–351},
numpages = {7},
keywords = {ai, artificial intelligence, code generation, copilot, cs1, gpt-4, introductory programming, large language model, llm, machine learning, novice programmers, programming, prompt engineering, secure code, software verification},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3705236,
author = {Chopra, Ryka C. and Chakraborty, Suparna},
title = {RAFIKI: Leveraging Large Language Models to Increase AP Computer Science A Enrollment among Disadvantaged High School Females},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705236},
doi = {10.1145/3641555.3705236},
abstract = {The gender gap in computing persists even after decades of investment in lowering the gap. Evidence suggests that stereotypical attitudes and bias perceptions play a critical role in limiting female participation in STEM, beginning in middle and high school. The gap is exacerbated in developing nations with limited academic counselor support. Therefore, the goal is to provide early targeted counseling. RAFIKI - "friend" in Swahili is a large language model-based web application designed to mimic an academic coach. Using user inputs, it provides customized academic counseling with curated information on STEM and computing pathways. Initial experimental evidence shows that RAFIKI use leads to a significant increase in AP Computer Science A course enrollment, considered a pathway to future computing career, particularly among female high school students.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1417–1418},
numpages = {2},
keywords = {AP CSA, ChatGPT, digital coach, female enrollment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3701625.3701687,
author = {Sampaio, Savio Sousa and Lima, M\'{a}rcia Sampaio and de Souza, Eriky Rodrigues and Meireles, Maria Alcimar and Pessoa, Marcela Savia and Conte, Tayana Uchoa},
title = {Exploring the Use of Large Language Models in Requirements Engineering Education: An Experience Report with ChatGPT 3.5},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701687},
doi = {10.1145/3701625.3701687},
abstract = {Large Language Models (LLMs) are becoming common in educational settings. This trend presents a challenge for teachers, who must focus on teaching the proper usage of LLMs. In the context of Software Engineering (SE), ChatGPT can support various software development tasks. This work reports an experience with students using ChatGPT 3.5 to support the Requirements Engineering (RE) phase. We conducted a two-phase study with 42 students. First, the students elicited requirements for systems using RE techniques. Then, the students used ChatGPT 3.5 to generate requirements for the same systems. Finally, they compared both sets of requirements based on equivalence, innovation, and relevance. On average, 65.26% of the requirements generated by ChatGPT were considered equivalents to the requirements the students had elicited. However, students reported that ChatGPT generates broad and non-specific requirements. Students also reported that ChatGPT 3.5 can foster the requirements elicitation, but it is necessary to establish well-defined prompts for generating requirements.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {624–634},
numpages = {11},
keywords = {Requirement Elicitation, ChatGPT 3.5, Software engineering education},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3641554.3701785,
author = {Ramirez Osorio, Valeria and Zavaleta Bernuy, Angela and Simion, Bogdan and Liut, Michael},
title = {Understanding the Impact of Using Generative AI Tools in a Database Course},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701785},
doi = {10.1145/3641554.3701785},
abstract = {Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) have led to changes in educational practices by creating opportunities for personalized learning and immediate support. Computer science student perceptions and behaviors towards GenAI tools have been studied, but the effects of such tools on student learning have yet to be determined conclusively. We investigate the impact of GenAI tools on computing students' performance in a database course and aim to understand why students use GenAI tools in assignments. Our mixed-methods study (N=226) asked students to self-report whether they used a GenAI tool to complete a part of an assignment and why. Our results reveal that students utilizing GenAI tools performed better on the assignment part in which LLMs were permitted but did worse in other parts of the assignment and in the course overall. Also, those who did not use GenAI tools viewed more discussion board posts and participated more than those who used ChatGPT. This suggests that using GenAI tools may not lead to better skill development or mental models, at least not if the use of such tools is unsupervised, and that engagement with official course help supports may be affected. Further, our thematic analysis of reasons for using or not using GenAI tools, helps understand why students are drawn to these tools. Shedding light into such aspects empowers instructors to be proactive in how to encourage, supervise, and handle the use or integration of GenAI into courses, fostering good learning habits.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {959–965},
numpages = {7},
keywords = {computing education, databases, generative artificial intelligence, large language models, student behavior, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3635356,
author = {AlOmar, Eman Abdullah and Mkaouer, Mohamed Wiem},
title = {How can We Leverage Static Analysis and Large Language Models to Engage Students in Software Quality Improvement},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635356},
doi = {10.1145/3626253.3635356},
abstract = {Static analysis tools are frequently used to scan the source code and detect deviations from the project coding guidelines. Yet, their adoption is challenged by their high false positive rate, which makes them not suitable for students and novice developers. However, Large Language Models (LLMs), such as ChatGPT, have gained widespread popularity and usage in various software engineering tasks, including testing, code review, and program comprehension. Such models represent an opportunity to reduce the ambiguity of static analysis tools and support their adoption. Yet, the effectiveness of using static analysis (i.e., PMD) to detect coding issues, and relying on LLMs (i.e., ChatGPT) to explain and recommend fix, has not yet been explored. In this talk, we aim to shed light on our experience in teaching the use of ChatGPT to cultivate a bugfix culture and leverage LLMs to improve software quality in educational settings. We share our findings to support educators in teaching students better code review strategies, and to increase students' awareness about LLM and promote software quality in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1930},
numpages = {1},
keywords = {computing, education, large language models, quality},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3585059.3611431,
author = {Zheng, Yong},
title = {ChatGPT for Teaching and Learning: An Experience from Data Science Education},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611431},
doi = {10.1145/3585059.3611431},
abstract = {ChatGPT, an implementation and application of large language models, has gained significant popularity since its initial release. Researchers have been exploring ways to harness the practical benefits of ChatGPT in real-world scenarios. Educational researchers have investigated its potential in various subjects, e.g., programming, mathematics, finance, clinical decision support, etc. However, there has been limited attention given to its application in data science education. This paper aims to bridge that gap by utilizing ChatGPT in a data science course, gathering perspectives from students, and presenting our experiences and feedback on using ChatGPT for teaching and learning in data science education. The findings not only distinguish data science education from other disciplines but also uncover new opportunities and challenges associated with incorporating ChatGPT into the data science curriculum.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {66–72},
numpages = {7},
keywords = {ChatGPT, data analytics, data science, large language model},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3596671.3598574,
author = {Goel, Toshali and Shaer, Orit and Delcourt, Catherine and Gu, Quan and Cooper, Angel},
title = {Preparing Future Designers for Human-AI Collaboration in Persona Creation},
year = {2023},
isbn = {9798400708077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596671.3598574},
doi = {10.1145/3596671.3598574},
abstract = {This paper presents findings from an exploratory study investigating the use of AI text-generation tools to support novice designers in persona creation. We conducted a workshop with 22 undergraduate students enrolled in an introductory human-computer interaction course, who were instructed to use GPT-3 in the creation of personas. These novice designers were able to use GPT-3 to iterate to produce satisfactory personas, particularly when providing detailed prompts. Our findings suggest that personas created with GPT-3 assistance were mostly comparable to those created manually but rated lower on some evaluation dimensions. The study also reveals merits and concerns of using GPT-3 for persona creation. Based on our findings, we propose recommendations for novice designers on how to use text-generative AIs to create personas effectively and responsibly.},
booktitle = {Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {4},
numpages = {14},
keywords = {personas, novice designers, natural-language generation, large language models, human-AI collaboration, education},
location = {Oldenburg, Germany},
series = {CHIWORK '23}
}

@inproceedings{10.1145/3626252.3630937,
author = {Grover, Shuchi},
title = {Teaching AI to K-12 Learners: Lessons, Issues, and Guidance},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630937},
doi = {10.1145/3626252.3630937},
abstract = {There is growing recognition of the need to teach artificial intelli- gence (AI) and machine learning (ML) at the school level. This push acknowledges the meteoric growth in the range and diversity of ap- plications of ML in all industries and everyday consumer products, with Large Language Models (LLMs) being only the latest and most compelling example yet. Efforts to bring AI, especially ML educa- tion to school learners are being propelled by substantial industry interest, research efforts, as well as technological developments that make sophisticated ML tools readily available to learners of all ages. These early efforts span a variety of learning goals captured by the AI4K12 "big ideas" framework and employ a plurality of pedagogies.This paper provides a sense for the current state of the field, shares lessons learned from early K-12 AI education as well as CS education efforts that can be leveraged, highlights issues that must be addressed in designing for teaching AI in K-12, and provides guidance for future K-12 AI education efforts and tackle what to many feels like "the next new thing".},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {422–428},
numpages = {7},
keywords = {artificial intelligence, k-12 ai education, k-12 cs education, machine learning},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3737313.3737334,
author = {Fernandez, Amanda S. and Patrick, David and Gomez, Mauricio and Cornell, Kimberly A.},
title = {Incorporating LLM Activities into Established CS1 Curriculum: An Experience Report},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Large Language Models (LLMs), including Gemini, CoPilot, and ChatGPT, have experienced significant growth in usage and adoption in recent years. As these models become more sophisticated, particularly in code generation capabilities, educators need to adapt their CS1 courses. In this experience report, we share observations we made while designing and teaching LLM activities for CS1 students at two academic institutions during the spring 2024 term. Drawing on recent research, our activities consist of four short 10-15 minute exercises that guide students in how to properly utilize LLMs within their CS1 coursework. These activities can be easily added to the existing CS1 course curriculum to supplement the existing course materials. Post-activity surveys indicated a positive impact on students' understanding of CS concepts and indicated enthusiasm for learning how to use LLMs safely in programming.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {79–93},
numpages = {15}
}

@inproceedings{10.1145/3641555.3705183,
author = {Brockenbrough, Allan and Feild, Henry and Salinas, Dominic},
title = {Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705183},
doi = {10.1145/3641555.3705183},
abstract = {In Agile software development methodology, a user story describes a new feature or functionality from an end user's perspective. The user story details may also incorporate acceptance testing criteria, which can be developed through negotiation with users. When creating stories from user feedback, the software engineer may maximize their usefulness by considering story attributes, including scope, independence, negotiability, and testability. This study investigates how LLMs (large language models), with guided instructions, affect undergraduate software engineering students' ability to transform user feedback into user stories. Students, working individually, were asked to analyze user feedback comments, appropriately group related items, and create user stories following the principles of INVEST, a framework for assessing user stories. We found that LLMs help students develop valuable stories with well-defined acceptance criteria. However, students tend to perform better without LLMs when creating user stories with an appropriate scope.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1401–1402},
numpages = {2},
keywords = {LLM, generative AI, large language model, user story},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3585059.3611409,
author = {Gumina, Sharon and Dalton, Travis and Gerdes, John},
title = {Teaching IT Software Fundamentals: Strategies and Techniques for Inclusion of Large Language Models: Strategies and Techniques for Inclusion of Large Language Models},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611409},
doi = {10.1145/3585059.3611409},
abstract = {This paper argues for the inclusion of tools that utilize Artificial Intelligence (AI) Large Language Models (LLMs) in information technology (IT) undergraduate courses that teach the fundamentals of software. LLM tools have become widely available and disrupt traditional methods for teaching software concepts. Learning objectives are compromised when students submit AI-generated code for a classroom assignment without comprehending or validating the code. Since LLM tools including OpenAI Codex, Copilot by GitHub, and ChatGPT are being used in industry for software development, students need to be familiar with their use without compromising student learning. Incorporating LLM tools into the curriculum prepares students for real-world software development. However, students still need to understand software fundamentals including how to write and debug code. There are many challenges associated with the inclusion of AI tools into the IT curriculum that need to be addressed and mitigated. This paper presents strategies and techniques to integrate student use of LLM tools, assist students’ interaction with the tools, and help prepare students for careers that increasingly use AI tools to design, develop, and maintain software.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {60–65},
numpages = {6},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3501709.3544280,
author = {MacNeil, Stephen and Tran, Andrew and Mogil, Dan and Bernstein, Seth and Ross, Erin and Huang, Ziheng},
title = {Generating Diverse Code Explanations using the GPT-3 Large Language Model},
year = {2022},
isbn = {9781450391955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501709.3544280},
doi = {10.1145/3501709.3544280},
abstract = {Good explanations are essential to efficiently learning introductory programming concepts [10]. To provide high-quality explanations at scale, numerous systems automate the process by tracing the execution of code [8, 12], defining terms [9], giving hints [16], and providing error-specific feedback [10, 16]. However, these approaches often require manual effort to configure and only explain a single aspect of a given code segment. Large language models (LLMs) are also changing how students interact with code [7]. For example, Github's Copilot can generate code for programmers [4], leading researchers to raise concerns about cheating [7]. Instead, our work focuses on LLMs' potential to support learning by explaining numerous aspects of a given code snippet. This poster features a systematic analysis of the diverse natural language explanations that GPT-3 can generate automatically for a given code snippet. We present a subset of three use cases from our evolving design space of AI Explanations of Code.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 2},
pages = {37–39},
numpages = {3},
keywords = {natural language processing, large language models, computer science education, code explanations},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@article{10.1145/3705734,
author = {George, Amrita and Storey, Veda Catherine and Hong, Shuguang},
title = {Unraveling the Impact of ChatGPT as a Knowledge Anchor in Business Education},
year = {2025},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3705734},
doi = {10.1145/3705734},
abstract = {The emergence of Large Language Models (LLM), such as ChatGPT, is considered a productivity revolution in many areas of business and society. For a classroom setting, especially, it would be useful to understand whether, and how, to incorporate ChatGPT, similar to any other productivity revolution technology, such as calculators or a Google search engine. Although there are concerns regarding the use of LLMs in business education, the positive or negative impact of LLM use is not well-understood. In this research, we examine the substitution and complementarity effects of using ChatGPT in business curricula on learning outcomes and well-being in a socially supportive learning environment. Specifically, we examine whether technology anchors impact students’ goal orientation, learning outcomes, and well-being by conducting an empirical study with students majoring in Information Systems. Our analysis reveals that a technology anchor (computer playfulness) can complement the effects of social support on learning outcomes, while enhancing well-being for simple tasks. Students’ well-being and learning outcomes are hindered by LLM use (specifically, the computer anxiety anchor), substituting social support for simple and difficult tasks. These findings have implications for educational institutions that are assessing how to incorporate LLMs into business curricula.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = feb,
articleno = {4},
numpages = {30},
keywords = {ChatGPT, Large language model (LLM), technology self-efficacy, computer anxiety, goal orientation, computer playfulness, social support, technology anchors, generative AI, knowledge anchor, OpenAI, technology anchors, artificial intelligence (AI), achievement theory}
}

@inproceedings{10.1145/3617650.3624946,
author = {Balse, Rishabh and Prasad, Prajish and Warriem, Jayakrishnan Madathil},
title = {Exploring the Potential of GPT-4 in Automated Mentoring for Programming Courses},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624946},
doi = {10.1145/3617650.3624946},
abstract = {This research proposes an AI-assisted mentoring system for programming education, leveraging the advanced capabilities of OpenAI's GPT-4. We aim to validate students' pseudocode or algorithmic approaches to Python programming problems within the context of a Tier-1 institution in India, where the high student-to-mentor ratio presents unique challenges. The proposed system aspires to alleviate the pressures of the current mentoring system, providing a more accessible, responsive, and effective educational support system.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {191},
numpages = {1},
keywords = {python programming education, large language models, automated programming mentoring, GPT-4},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@article{10.5555/3636517.3636522,
author = {Crandall, Aaron S. and Sprint, Gina and Fischer, Bryan},
title = {Generative Pre-Trained Transformer (GPT) Models as a Code Review Feedback Tool in Computer Science Programs},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {1},
issn = {1937-4771},
abstract = {Undergraduate computer science and software engineering students benefit significantly from in-depth reviews of their code early and often in their courses. Performing these reviews is time-consuming for teaching assistants and professors to complete, consequently impacting the timeliness and consistency of the provided feedback. When code feedback is not delivered close to the time of authorship, the utility of the review for students is diminished. Prior work with Automatic Static Analysis Tools has shown promise at using artificial intelligence to automate code reviews, with some success integrating them into classroom environments. To leverage new advances in Generative Pre-Trained Transformer (GPT) models, this work reports on an Automatic Review Tool (ART) to provide timely, automatically generated code reviews. ART was evaluated in a second-semester computer science course by integrating ART into the course's Github-based assignment submission system. A cohort of student volunteers (N = 74) read the ART reviews and provided feedback using a survey spanning two of their course assignments. The results of this pilot study show that students perceived ART was successful at detecting defects and offering style-based suggestions, and students were receptive to receiving future automated reviews of their work.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {38–47},
numpages = {10}
}

@inproceedings{10.1145/3580305.3599827,
author = {Drori, Iddo and Zhang, Sarah J. and Shuttleworth, Reece and Zhang, Sarah and Tyser, Keith and Chin, Zad and Lantigua, Pedro and Surbehera, Saisamrit and Hunter, Gregory and Austin, Derek and Tang, Leonard and Hicke, Yann and Simhon, Sage and Karnik, Sathwik and Granberry, Darnell and Udell, Madeleine},
title = {From Human Days to Machine Seconds: Automatically Answering and Generating Machine Learning Final Exams},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599827},
doi = {10.1145/3580305.3599827},
abstract = {A final exam in machine learning at a top institution such as MIT, Harvard, or Cornell typically takes faculty days to write, and students hours to solve. We demonstrate that large language models pass machine learning finals at a human level on finals available online and automatically generate new human-quality final exam questions in seconds. Previous work has developed program synthesis and few-shot learning methods to solve university-level problem set questions in mathematics and STEM courses. In this work, we develop and compare methods that solve final exams, which differ from problem sets in several ways: the questions are longer, have multiple parts, are more complicated, and span a broader set of topics. We curate a dataset and benchmark of questions from machine learning final exams available online and code for answering these questions and generating new questions. We show how to generate new questions from other questions and course notes. For reproducibility and future research on this final exam benchmark, we use automatic checkers for multiple-choice, numeric, and questions with expression answers. A student survey comparing the quality, appropriateness, and difficulty of machine-generated questions with human-written questions shows that across multiple aspects, machine-generated questions are indistinguishable from human-generated questions and are suitable for final exams. We perform ablation studies comparing zero-shot learning with few-shot learning and chain-of-thought prompting using GPT-3, OPT, Codex, and ChatGPT across machine learning topics and find that few-shot learning methods perform best. We highlight the transformative potential of language models to streamline the writing and solution of large-scale assessments, significantly reducing the workload from human days to mere machine seconds. Our results suggest that rather than banning large language models such as ChatGPT in class, instructors should teach students to harness them by asking students meta-questions about correctness, completeness, and originality of the responses generated, encouraging critical thinking in academic studies.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3947–3955},
numpages = {9},
keywords = {quantitative reasoning, program synthesis, machine learning, large language models, few-shot learning},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3571884.3604310,
author = {Mannekote, Amogh and Celepkolu, Mehmet and Wiggins, Joseph B. and Boyer, Kristy Elizabeth},
title = {Exploring Usability Issues in Instruction-Based and Schema-Based Authoring of Task-Oriented Dialogue Agents},
year = {2023},
isbn = {9798400700149},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3571884.3604310},
doi = {10.1145/3571884.3604310},
abstract = {Platforms such as Google DialogFlow and Amazon Lex have enabled easier development of conversational agents. The standard approach to training these agents involve collecting and annotating in-domain data in the form of labelled utterances. However, obtaining in-domain data for training machine learning models remains a bottleneck. Schema-based dialogue, which involves laying out a structured representation of the flow of a “typical” dialogue, and prompt-based methods, which involve writing instructions in natural language to large language models such as GPT-3, are promising ways to tackle this problem. However, usability issues when translating these methods into practice are less explored. Our study takes a first step towards addressing this gap by having 23 students who had finished a graduate-level course on spoken dialogue systems report their experiences as they defined structured schemas and composed instruction-based prompts for two task-oriented dialogue scenarios. Through inductive coding and subsequent thematic analysis of the survey data, we explored users’ authoring experiences with schema and prompt-based methods. The findings provide insights for future data collection and authoring tool design for dialogue systems.},
booktitle = {Proceedings of the 5th International Conference on Conversational User Interfaces},
articleno = {41},
numpages = {6},
keywords = {dialogue systems, schema-based dialogue, user studies;, zero-shot prompting},
location = {Eindhoven, Netherlands},
series = {CUI '23}
}

@inproceedings{10.1145/3701625.3701657,
author = {de Almeida, \'{A}gatha and Collins, Eliane and Oran, Ana Carolina},
title = {AI in Service of Software Quality: How ChatGPT and Personas Are Transforming Exploratory Testing},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701657},
doi = {10.1145/3701625.3701657},
abstract = {Context: Exploratory testing is essential in the software validation process as a way to find unexpected and critical failures in a short time, complementing documented functional test cases. However, creating scenarios to explore the software (such as test charters) can be time-consuming, and depending on the team’s experience, it may lack adequate coverage of functionalities and scenarios that target specific user profiles of the application. Objective: This article investigates how AI, through LLMs (Large Language Models), can assist in creating exploratory test charters that reflect the characteristics and needs of different user personas. Method: To achieve this, an experimental study was conducted where personas were used as input in ChatGPT 3.5 to generate exploratory test charters. The effectiveness of the approach was evaluated by Software Engineering students, who analyzed the performance and usefulness of the generated charters through a questionnaire based on the TAM model, supplemented by qualitative and quantitative analyses. Results: Data analysis indicated positive acceptance of ChatGPT 3.5 by the participants, highlighting its ease of use and perceived usefulness. Conclusion: This study contributes to the field of Software Engineering by demonstrating a practical application of artificial intelligence in the automated generation of test charters. ChatGPT 3.5 has proven to be a promising tool to support the creation of personalized exploratory test charters, contributing to software quality improvement. The integration of artificial intelligence techniques with user-centered design methods can significantly optimize the software testing process.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {179–188},
numpages = {10},
keywords = {Exploratory Testing, ChatGPT, Personas, Software Quality, Artificial Intelligence},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3641554.3701957,
author = {Basit, Nada and Floryan, Mark and Hott, John R. and Huo, Allen and Le, Jackson and Zheng, Ivan},
title = {ASCI: AI-Smart Classroom Initiative},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701957},
doi = {10.1145/3641554.3701957},
abstract = {The Artificial Intelligence Smart Classroom Initiative (ASCI) presents a re-imagined set of online course tools, designed primarily to support growing computer science classes. The system has four primary tools: an office hours queue, an automatic student grouping algorithm, a course-specific local large-language model (LLM), and administration tools for detecting students and TAs that need support. These tools interoperate to improve the quality of one another (e.g., LLM conversations support students directly in the office hours queue) and are enhanced by synchronizing data from multiple external sources such as Piazza, Gradescope, and Canvas. The system has been deployed in multiple courses over the past three semesters: initially as a FIFO queue, then supporting manual grouping and smart grouping of office hour attendees, and recently including LLM support. Preliminary results indicate that students who were grouped using the tool were more likely to return to the queue more than twice as often (on average) than those who were not. However, while grouping in office hours has the potential to decrease student wait times, teaching assistants and students tend to favor one-on-one meetings over group meetings. This might be improved in the future with updates to the software, TA training, and incorporation of other supporting tools (e.g., LLM technology). The other, newer, tools will be more thoroughly evaluated in future semesters.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {81–87},
numpages = {7},
keywords = {computer science education, cosine similarity, group formation, office hours},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701841,
author = {Aljedaani, Wajdi and Eler, Marcelo Medeiros and Parthasarathy, P D},
title = {Enhancing Accessibility in Software Engineering Projects with Large Language Models (LLMs)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701841},
doi = {10.1145/3641554.3701841},
abstract = {Digital accessibility ensures that digital products and services are usable by a diverse range of users, regardless of their physical or cognitive abilities. While numerous standards and guidelines have been established to aid developers in creating accessible content, studies reveal a persistent lack of accessibility in many web and mobile applications. This gap is often attributed to barriers such as lack of awareness, insufficient knowledge, absence of specific requirements, time constraints, and lack of executive support. In this context, we aim to address the lack of awareness and knowledge challenges by proposing a hands-on approach that leverages the capabilities of Large Language Models (LLMs) like ChatGPT to enhance students' accessibility awareness, knowledge, and practical skills. We engaged software engineering students in tasks involving website development and accessibility evaluation using checker tools, and we utilized ChatGPT 3.5 to fix identified accessibility issues. Our findings suggest that practical assignments significantly enhance learning outcomes, as interactions with LLMs allow students to develop a deeper understanding of accessibility concepts. This approach not only reinforces theoretical knowledge but also highlights the real-world impact of their work. The results indicate that combining practical assignments with AI-driven support effectively improves students' proficiency in web accessibility.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {25–31},
numpages = {7},
keywords = {chatgpt 3.5, digital accessibility, large language models, llms, project based learning, software engineering, wcag},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3716640.3716651,
author = {Qiao, Shuying and Denny, Paul and Giacaman, Nasser},
title = {Oversight in Action: Experiences with Instructor-Moderated LLM Responses in an Online Discussion Forum},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716651},
doi = {10.1145/3716640.3716651},
abstract = {The integration of large language models (LLMs) into computing education offers many potential benefits to student learning, and several novel pedagogical approaches have been reported in the literature. However LLMs also present challenges, one of the most commonly cited being that of student over-reliance. This challenge is compounded by the fact that LLMs are always available to provide instant help and solutions to students, which can undermine their ability to independently solve problems and diagnose and resolve errors. Providing instructor oversight of LLM-generated content can mitigate this problem, however it is often not practical in real-time learning contexts. Online class discussion forums, which are widely used in computing education, present an opportunity for exploring instructor oversight because they operate asynchronously. Unlike real-time interactions, the discussion forum format aligns with the expectation that responses may take time, making oversight not only feasible but also pedagogically appropriate. In this practitioner paper, we present the design, deployment, and evaluation of a ‘bot’ module that is controlled by the instructor, and integrated into an online discussion forum. The bot assists the instructor by generating draft responses to student questions, which are reviewed, modified, and approved before release. Key features include the ability to leverage course materials, access archived discussions, and publish responses anonymously to encourage open participation. We report our experiences using this tool in a 12-week second-year software engineering course on object-oriented programming. Instructor feedback confirmed the tool successfully alleviated workload but highlighted a need for improvement in handling complex, context-dependent queries. We report the features that were viewed as most beneficial, and suggest avenues for future exploration.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {95–104},
numpages = {10},
keywords = {Large language models, LLMs, discussion forums, instructor-in-the-loop, software engineering education, chatbots, computing education},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3626252.3630784,
author = {Rogers, Michael P. and Hillberg, Hannah Miller and Groves, Christopher L.},
title = {Attitudes Towards the Use (and Misuse) of ChatGPT: A Preliminary Study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630784},
doi = {10.1145/3626252.3630784},
abstract = {ChatGPT is the front end to a powerful large language model that has garnered widespread attention in many fields of study, including computer science (CS), where it promises to be transformational. As educators, we are just starting to grapple with the ramifications of this new technology, including implications for what we teach, how we teach, and how we grade. The decisions educators make moving forward depend heavily on the prevalence of students' use (and misuse) of ChatGPT in the classroom. Further, predictors of nefarious use could aid educators as well. We conducted an online survey to capture CS student awareness of, experience with, and attitudes toward ChatGPT. Through quantitative and qualitative analysis, we found that awareness of ChatGPT is generally high, and it is more frequently being used as a study tool than to complete students' work for them. Most students are aware of the potential for abuse in academic pursuits, but a notable minority of students admit to using it unscrupulously and to the potential for it to interfere with their learning. We conclude with a discussion of factors to consider as educators modify their approaches and develop guidelines for ChatGPT usage in their classrooms.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1147–1153},
numpages = {7},
keywords = {academic misconduct, artificial intelligence, chatgpt, large language models, student survey},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626252.3630842,
author = {Amoozadeh, Matin and Daniels, David and Nam, Daye and Kumar, Aayush and Chen, Stella and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Mohammad Amin},
title = {Trust in Generative AI among Students: An exploratory study},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630842},
doi = {10.1145/3626252.3630842},
abstract = {Generative Artificial Intelligence (GenAI) systems have experienced exponential growth in the last couple of years. These systems offer exciting capabilities for CS Education (CSEd), such as generating programs, that students can well utilize for their learning. Among the many dimensions that might affect the effective adoption of GenAI for CSEd, in this paper, we investigate students' trust. Trust in GenAI influences the extent to which students adopt GenAI, in turn affecting their learning. In this paper, we present results from a survey of 253 students at two large universities to understand how much they trust GenAI tools and their feedback on how GenAI impacts their performance in CS courses. Our results show that students have different levels of trust in GenAI. We also observe different levels of confidence and motivation, highlighting the need for further understanding of factors impacting trust.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {67–73},
numpages = {7},
keywords = {generative ai, novice programmers, trust},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3662039,
author = {Smith, David H. and Denny, Paul and Fowler, Max},
title = {Prompting for Comprehension: Exploring the Intersection of Explain in Plain English Questions and Prompt Writing},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662039},
doi = {10.1145/3657604.3662039},
abstract = {Learning to program requires the development of a variety of skills including the ability to read, comprehend, and communicate the purpose of code. In the age of large language models (LLMs), where code can be generated automatically, developing these skills is more important than ever for novice programmers. The ability to write precise natural language descriptions of desired behavior is essential for eliciting code from an LLM, and the code that is generated must be understood in order to evaluate its correctness and suitability. In introductory computer science courses, a common question type used to develop and assess code comprehension skill is the 'Explain in Plain English' (EiPE) question. In these questions, students are shown a segment of code and asked to provide a natural language description of that code's purpose. The adoption of EiPE questions at scale has been hindered by: 1) the difficulty of automatically grading short answer responses and 2) the ability to provide effective and transparent feedback to students. To address these shortcomings, we explore and evaluate a grading approach where a student's EiPE response is used to generate code via an LLM, and that code is evaluated against test cases to determine if the description of the code was accurate. This provides a scalable approach to creating code comprehension questions and enables feedback both through the code generated from a student's description and the results of test cases run on that code. We evaluate students' success in completing these tasks, their use of the feedback provided by the system, and their perceptions of the activity.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {39–50},
numpages = {12},
keywords = {CS1, EIPE, LLMs, code comprehension, explain in plain English, introductory programming, large language models, prompting},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3649217.3653584,
author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith IV, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
title = {CS1-LLM: Integrating LLMs into CS1 Instruction},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653584},
doi = {10.1145/3649217.3653584},
abstract = {The recent, widespread availability of Large Language Models (LLMs) like ChatGPT and GitHub Copilot may impact introductory programming courses (CS1) both in terms of what should be taught and how to teach it. Indeed, recent research has shown that LLMs are capable of solving the majority of the assignments and exams we previously used in CS1. In addition, professional software engineers are often using these tools, raising the question of whether we should be training our students in their use as well. This experience report describes a CS1 course at a large research-intensive university that fully embraces the use of LLMs from the beginning of the course. To incorporate the LLMs, the course was intentionally altered to reduce emphasis on syntax and writing code from scratch. Instead, the course now emphasizes skills needed to successfully produce software with an LLM. This includes explaining code, testing code, and decomposing large problems into small functions that are solvable by an LLM. In addition to frequent, formative assessments of these skills, students were given three large, open-ended projects in three separate domains (data science, image processing, and game design) that allowed them to showcase their creativity in topics of their choosing. In an end-of-term survey, students reported that they appreciated learning with the assistance of the LLM and that they interacted with the LLM in a variety of ways when writing code. We provide lessons learned for instructors who may wish to incorporate LLMs into their course.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {297–303},
numpages = {7},
keywords = {copilot, cs1, generative ai, introductory programming, llm},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3660650.3660668,
author = {Rajabi, Parsa},
title = {Experience Report: Adopting AI-Usage Policy in Software Engineering Education},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660668},
doi = {10.1145/3660650.3660668},
abstract = {This report examines the introduction of an AI-usage policy within a Software Engineering course, aiming to overcome the challenges of incorporating generative AI (genAI) tools in academic settings. As the debate around the impact of technologies like ChatGPT in education continues, this policy represents a proactive stance, addressing both the opportunities and risks associated with AI tool usage. With N=86 students, this course implemented a policy that promotes responsible AI use through guidelines and an "AI-usage disclosure" form for coursework submissions. This approach sought to improve AI literacy, ensure academic integrity, and mitigate potential academic misconduct cases. Despite challenges, including adherence to AI disclosures and the evolving definition of AI tools, the policy promoted a more inclusive learning environment and encouraged a deeper understanding of AI’s role and limitations in computer science education. The findings highlight the need for ongoing policy revisions to adapt to technological advancements, emphasizing the pilot as an essential step towards integrating AI responsibly in educational contexts.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {19},
numpages = {2},
keywords = {AI in Education, AI-usage Policy, Academic Integrity, ChatGPT, Software Engineering Education},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3545947.3573358,
author = {MacNeil, Stephen and Kim, Joanne and Leinonen, Juho and Denny, Paul and Bernstein, Seth and Becker, Brett A. and Wermelinger, Michel and Hellas, Arto and Tran, Andrew and Sarsa, Sami and Prather, James and Kumar, Viraj},
title = {The Implications of Large Language Models for CS Teachers and Students},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573358},
doi = {10.1145/3545947.3573358},
abstract = {The introduction of Large Language Models (LLMs) has generated a significant amount of excitement both in industry and among researchers. Recently, tools that leverage LLMs have made their way into the classroom where they help students generate code and help instructors generate learning materials. There are likely many more uses of these tools -- both beneficial to learning and possibly detrimental to learning. To help ensure that these tools are used to enhance learning, educators need to not only be familiar with these tools, but with their use and potential misuse. The goal of this BoF is to raise awareness about LLMs and to build a learning community around their use in computing education. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed discussion leaders, including undergraduate researchers, to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1255},
numpages = {1},
keywords = {artificial intelligence, code explanations, code generation, computer science education, copilot, gpt-3, large language models},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3626253.3635380,
author = {Veilleux, Nanette and Bates, Rebecca and Goldsmith, Judy and Summet, Valerie},
title = {Mentoring, AI, and the End of Affirmative Action: Connecting with SIGCSE Reads},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635380},
doi = {10.1145/3626253.3635380},
abstract = {This Birds of a Feather will begin with a high-level overview of the SIGCSE Reads 2024 books and then quickly move to discussion about mentoring students in the era of large language models and ChatGPT, including how students may value the curriculum differently, how learning outcomes may change, and how we can support students and alumni/ae as they work with rapidly changing job and learning expectations. We expect that many of the sessions at SIGCSE will address the radical shifts in learning outcomes and curricular changes due to LLMs. We will not focus on the particulars of these changes, but rather on mentoring in this time with Sister Resisters: Mentoring Black Women on Campus by Janie Victoria Ward and Tracy L. Robinson-Wood as a resource. How do we guide our students through the curriculum upheaval triggered by shifting learning outcomes? How do we help them prepare for the new instantiation of computer science?  This BOF is the primary session for SIGCSE Reads. We encourage discussion of this year's fiction works The Lifecycle of Software Objects by Ted Chiang and "Dolly" by Elizabeth Bear, as well as past Reads, throughout the conference.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1922},
numpages = {1},
keywords = {computing education, diversity in computing, mentoring, science fiction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701864,
author = {Zamfirescu-Pereira, J.D. and Qi, Laryn and Hartmann, Bj\"{o}rn and DeNero, John and Norouzi, Narges},
title = {61A Bot Report: AI Assistants in CS1 Save Students Homework Time and Reduce Demands on Staff. (Now What?)},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701864},
doi = {10.1145/3641554.3701864},
abstract = {LLM-based chatbots enable students to get immediate, interactive help on homework assignments, but even a thoughtfully-designed bot may not serve all pedagogical goals. We report here on the development and deployment of a GPT-4-based interactive homework assistant ("61A Bot'') for students in a large CS1 course; over 2000 students made over 100,000 requests of our Bot across two semesters. Our assistant offers one-shot, contextual feedback within the command-line "autograder'' students use to test their code. Our Bot wraps student code in a custom prompt that supports our pedagogical goals and avoids providing solutions directly. Analyzing student feedback, questions, and autograder data, we find reductions in homework-related question rates in our course forum, as well as reductions in homework completion time when our Bot is available. For students in the 50th -80th percentile, reductions can exceed 30 minutes per assignment, up to 50% less time than students at the same percentile rank in prior semesters. Finally, we discuss these observations, potential impacts on student learning, and other potential costs and benefits of AI assistance in CS1.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1309–1315},
numpages = {7},
keywords = {ai assistant deployment, ai assistant evaluation, automated tutors, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705195,
author = {Marwan, Samiha and Ibrahim, Mohamed and Morrison, Briana},
title = {How Good are Large Language Models at Generating Subgoal Labels?},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705195},
doi = {10.1145/3641555.3705195},
abstract = {The use of subgoal labels in introduction to programming classrooms has been shown to improve student performance, learning, retention, and reduce students' drop out rates. However, creating and adding subgoal labels to programming assignments is often hard to articulate and very time-intensive for instructors. In Computing Education Research, Large Language Models (LLMs) have been widely used to generate human-like outputs such as worked examples and source code. In this work, we explore whether ChatGPT could be used to generate high-quality and appropriate subgoal labels in two programming curricula. Our qualitative data analysis suggests that LLMs can assist instructors in creating subgoal labels in their classrooms, opening up directions to empower students' learning experience in programming classrooms.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1541–1542},
numpages = {2},
keywords = {large language models, subgoal labels, subgoals},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3700297.3700326,
author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
title = {A Study of the AIGC-Enabled BOPPPS Smart Teaching Model},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700326},
doi = {10.1145/3700297.3700326},
abstract = {Smart teaching refers to the in-depth use of modern information technology to promote the process of education, which is characterized by using digital, network, intelligent and multimedia technologies. BOPPPS teaching model is a new type of student-centered teaching model. This teaching model is widely used around the world. The traditional BOPPPS teaching model makes it difficult to implement personalized teaching in the classroom. The new development of artificial intelligence technology provides new method for smart teaching, especially the AIGC Large Language Model represented by ChatGPT. This paper introduces AIGC technology into personalized teaching, and study the application of AIGC in various aspects of BOPPPS teaching model, by taking the design of smart teaching course of video surveillance as an example. In particular, AIGC is utilized for Pre-assessment. It is proposed to use an agent as a mediator between students and the AIGC large language model to test the students individually, and to design personalized test contents for personalized feedback. Comparatively better results were obtained in the actual teaching process, which can provide a reference for other smart teaching researchers.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {166–170},
numpages = {5},
keywords = {Artificial Intelligence, BOPPPS, Large Language Model, Personalized Teaching, Smart Teaching},
location = {
},
series = {ISAIE '24}
}

@inproceedings{10.1145/3626253.3633409,
author = {Hazzan, Orit and Erez, Yael},
title = {Generative AI in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633409},
doi = {10.1145/3626253.3633409},
abstract = {Generative AI has the potential to become disruptive technology for computer science education. Therefore, computer science educators must be familiar with the threats they should deal with and with the opportunities that generative-AI opens for the computer science education community. In the workshop, we explore the integration of several generative-AI tools and applications in computer science education. Activities include lesson design, code development, test design and assessment. We address the students' and the educators' perspectives. In addition, we explore computer science practices and soft skills to be applied with these tools as well as immediate and future applications and implications for computer science education and for the society. AT the end of the workshop, the participants will be able to use these generative AI tools in their daily educational computer science activities and beyond.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1899},
numpages = {1},
keywords = {ai, assessment, computer science education, curriculum design, disruptive technology, generative ai, skills},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3616961.3616974,
author = {Rajala, Jaakko and Hukkanen, Jenni and Hartikainen, Maria and Niemel\"{a}, Pia},
title = {"\"Call me Kiran\" – ChatGPT as a Tutoring Chatbot in a Computer Science Course"},
year = {2023},
isbn = {9798400708749},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616961.3616974},
doi = {10.1145/3616961.3616974},
abstract = {Natural language processing has taken enormous steps during the last few years. The development of large language models and generative AI has elevated natural language processing to the level that it can output coherent and contextually relevant text for a given natural language prompt. ChatGPT is one incarnation of these steps, and its use in education is a rather new phenomenon. In this paper, we study students’ perception on ChatGPT during a computer science course. On the course, we integrated ChatGPT into Teams private discussion groups. In addition, all the students had freedom to employ ChatGPT and related technologies to help them in their coursework. The results show that the majority of students had at least tested AI-powered chatbots, and that students are using AI-powered chatbots for multiple tasks, e.g., debugging code, tutoring, and enhancing comprehension. The amount of positive implications of using ChatGPT takes over the negative implications, when the implications were considered from an understanding, learning and creativity perspective. Relatively many students reported reliability issues with the outputs and that the iterations with prompts might be necessary for satisfactory outputs. It is important to try to steer the usage of ChatGPT so that it complements students’ learning processes, but does not replace it.},
booktitle = {Proceedings of the 26th International Academic Mindtrek Conference},
pages = {83–94},
numpages = {12},
keywords = {tutoring, student perceptions, generative AI, education, discussion forum, chatbots, artificial intelligence, ChatGPT},
location = {Tampere, Finland},
series = {Mindtrek '23}
}

@inproceedings{10.1145/3702163.3702188,
author = {Schefer-Wenzl, Sigrid and Vogl, Christoph and Peiris, Sahani and Miladinovic, Igor},
title = {Exploring the Adoption of Generative AI Tools in Computer Science Education: A Student Survey},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702188},
doi = {10.1145/3702163.3702188},
abstract = {The integration of generative AI tools into education has the potential to revolutionize learning experiences, particularly in computer science. This paper explores the adoption and utilization of generative AI tools among computer science students at the University of Applied Sciences Campus Vienna in Austria through a comprehensive survey. The study aims to understand the extent to which AI tools like ChatGPT are integrated into students' academic routines, their perceptions of these tools, and the challenges and opportunities they present. The survey results indicate a high level of acceptance and frequent use of AI tools for tasks such as programming, exam preparation, and generating simplified explanations. However, concerns about the accuracy of AI-generated content and the potential impact on critical thinking skills were also highlighted. The findings underscore the need for clear institutional guidelines and ethical considerations in the use of AI tools in education. This paper contributes to the growing body of literature on AI in education and provides insights for educators and policymakers to enhance the responsible integration of AI technologies in computer science curricula.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {173–178},
numpages = {6},
keywords = {Artificial Intelligence, Computer Science Education, Generative AI Tools, Higher Education},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3636243.3636249,
author = {Sheese, Brad and Liffiton, Mark and Savelka, Jaromir and Denny, Paul},
title = {Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636249},
doi = {10.1145/3636243.3636249},
abstract = {Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about how students will use them in practice and what type of help they will seek. To address this, we examine students’ use of an innovative LLM-powered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course&nbsp;(n = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {49–57},
numpages = {9},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3641555.3705252,
author = {Tadimalla, Sri Yash and Maher, Mary Lou},
title = {Sociotechnical AI Education Course Design for CS Majors and Non-Majors},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705252},
doi = {10.1145/3641555.3705252},
abstract = {As generative AI increasingly integrates into society and education, the number of institutions implementing AI usage policies and offering introductory AI courses is rising. These introductory AI courses mustn't replicate the "gateway/weed-out" phenomenon observed in introductory computer science courses like CS1 and CS2. Literature in computer science education suggests that interventions such as summer camps, bridge courses, and socio-technical courses have improved the sense of belonging and retention among students from underrepresented groups, thereby broadening participation in computer science. Building on previous work to create a socio-technical curriculum for all ages and education levels, this paper presents a course for teaching introductory AI concepts that adopts a socio-technical approach, complete with weekly activities and content designed for broad access. The course has been taught as a 1-credit general education course, primarily for freshmen and first-year students from various majors, and a 3-credit course for CS majors at all levels.This paper provides a curriculum and resources to teach a socio-technical introductory AI course. This approach is important because it not only democratizes AI education across diverse student backgrounds but also equips all students with the critical socio-technical multidisciplinary perspective necessary to navigate and shape the future ethical landscape of AI technology.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1631–1632},
numpages = {2},
keywords = {AI curriculum, AI education, intro to AI, socio-technical AI literacy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630874,
author = {Shen, Yiyin and Ai, Xinyi and Soosai Raj, Adalbert Gerald and Leo John, Rogers Jeffrey and Syamkumar, Meenakshi},
title = {Implications of ChatGPT for Data Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630874},
doi = {10.1145/3626252.3630874},
abstract = {ChatGPT is a conversational AI platform that can produce code to solve problems when provided with a natural language prompt. Prior work on similar AI models has shown that they perform well on typical intro-level Computer Science problems. However, little is known about the performance of such tools on Data Science (DS) problems. In this work, we assess the performance of ChatGPT on assignments from three DS courses with varying difficulty levels. First, we apply the raw assignment prompts provided to the students and find that ChatGPT performs well on assignments with dataset(s) descriptions and progressive question prompts, which divide the programming requirements into sub-problems. Then, we perform prompt engineering on the assignments for which ChatGPT had low performance. We find that the following prompt engineering techniques significantly increased ChatGPT's performance: breaking down abstract questions into steps, breaking down steps into multiple prompts, providing descriptions of the dataset(s), including algorithmic details, adding specific instructions to entice specific actions, and removing extraneous information. Finally, we discuss how our findings suggest potential changes to curriculum design of DS courses.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1230–1236},
numpages = {7},
keywords = {data science education, large language models, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3657604.3662036,
author = {Lyu, Wenhan and Wang, Yimeng and Chung, Tingting (Rachel) and Sun, Yifan and Zhang, Yixuan},
title = {Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662036},
doi = {10.1145/3657604.3662036},
abstract = {The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate, highlighting both their potential to augment student learning and the risks associated with their misuse. An emerging body of work has looked into using LLMs in education, primarily focusing on evaluating the performance of existing models or conducting short-term human subject studies. However, very little work has examined the impacts of LLM-powered assistants on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the "CodeTutor group" as the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the "control group"). Within the CodeTutor group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability to comprehend their queries and assist in learning programming language syntax. However, they had concerns about CodeTutor's limited role in developing critical thinking skills. Over the course of the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our findings also show that students turned to CodeTutor for different tasks, including programming task completion, syntax comprehension, and debugging, particularly seeking help for programming assignments. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon these results, we discuss the implications of our findings for the need to integrate Generative AI literacy into curricula to foster critical thinking skills, and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {63–74},
numpages = {12},
keywords = {field study, large language models, tutoring},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3657604.3662042,
author = {Kumar, Harsh and Xiao, Ruiwei and Lawson, Benjamin and Musabirov, Ilya and Shi, Jiakai and Wang, Xinyuan and Luo, Huayin and Williams, Joseph Jay and Rafferty, Anna N. and Stamper, John and Liut, Michael},
title = {Supporting Self-Reflection at Scale with Large Language Models: Insights from Randomized Field Experiments in Classrooms},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662042},
doi = {10.1145/3657604.3662042},
abstract = {Self-reflection on learning experiences constitutes a fundamental cognitive process, essential for consolidating knowledge and enhancing learning efficacy. However, traditional methods to facilitate reflection often face challenges in personalization, immediacy of feedback, engagement, and scalability. Integration of Large Language Models (LLMs) into the reflection process could mitigate these limitations. In this paper, we conducted two randomized field experiments in undergraduate computer science courses to investigate the potential of LLMs to help students engage in post-lesson reflection. In the first experiment (N=145), students completed a take-home assignment with the support of an LLM assistant; half of these students were then provided access to an LLM designed to facilitate self-reflection. The results indicated that the students assigned to LLM-guided reflection reported somewhat increased self-confidence compared to peers in a no-reflection control and a non-significant trend towards higher scores on a later assessment. Thematic analysis of students' interactions with the LLM showed that the LLM often affirmed the student's understanding, expanded on the student's reflection, and prompted additional reflection; these behaviors suggest ways LLM-interaction might facilitate reflection. In the second experiment (N=112), we evaluated the impact of LLM-guided self-reflection against other scalable reflection methods, such as questionnaire-based activities and review of key lecture slides, after assignment. Our findings suggest that the students in the questionnaire and LLM-based reflection groups performed equally well and better than those who were only exposed to lecture slides, according to their scores on a proctored exam two weeks later on the same subject matter. These results underscore the utility of LLM-guided reflection and questionnaire-based activities in improving learning outcomes. Our work highlights that focusing solely on the accuracy of LLMs can overlook their potential to enhance metacognitive skills through practices such as self-reflection. We discuss the implications of our research for the learning-at-scale community, highlighting the potential of LLMs to enhance learning experiences through personalized, engaging, and scalable reflection practices.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {86–97},
numpages = {12},
keywords = {field experiments, human-ai collaboration, large language models, learning engineering, self-reflection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.5555/3737313.3737341,
author = {Morales, Christopher},
title = {The Effectiveness of ChatGPT in Coding Novel Agent Classes for a Predator-Prey Model-Inspired Iterated Prisoner's Dilemma Model},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {I present a variant of the Iterated Prisoner's Dilemma incorporating elements of a predator-prey model, and assess whether the popular large language models (LLMs) ChatGPT-4o and ChatGPT-4o Mini should be recommended for use by pre-introductory-programming simulation and modeling students to help explore novel strategies for success in the model. I find that the LLMs' output is too unreliable to recommend to students for unsupervised use. However, LLMs may still be useful tools when used under the guidance of an instructor.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {178–185},
numpages = {8}
}

@inproceedings{10.1145/3649217.3653600,
author = {Villegas Molina, Ismael and Montalvo, Audria and Zhong, Shera and Jordan, Mollie and Soosai Raj, Adalbert Gerald},
title = {Generation and Evaluation of a Culturally-Relevant CS1 Textbook for Latines using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653600},
doi = {10.1145/3649217.3653600},
abstract = {In the United States, culturally relevant computing (CRC) is one of the most popular pedagogical implementations for Latin American (Latine) students. Culturally-relevant learning resources are a valuable tool for implementing CRC. However, the traditional method of creation and maintenance of textbooks takes a significant amount of time and effort. Given the duration required for textbook production, the development of culturally-relevant learning resources may become lengthened, as it requires close attention both on the material and the incorporation of cultural referents. In order to accelerate the process, we used the advancement of large language models (LLMs) to our advantage. Through prompt engineering, we created a series of prompts to produce a textbook for an introductory computer science course (CS1) that incorporates Latine culture. This textbook was evaluated on metrics regarding sensibility, correctness, readability, linguistic approachability, appropriateness of examples, and cultural relevance. Overall, the generated textbook was mainly sensible, correct, readable, and linguistically approachable. Code examples were not always appropriate due to the usage of libraries that are not typically used in a CS1 course. The cultural relevance was apparent, but it often included surface-level cultural referents. The main incorporation of culture was through geographical locations and people's names. This suggests that the use of LLMs to generate textbooks may serve as a valuable first step for writing culturally-relevant learning resources. Though this study focuses on Latines, our results and prompts may be applicable for generating culturally-relevant CS1 textbooks for other cultures.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {325–331},
numpages = {7},
keywords = {Latina, Latine, Latino, Latinx, computer science textbook, culturally relevant resources, large language models, resource generation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3501385.3543957,
author = {Sarsa, Sami and Denny, Paul and Hellas, Arto and Leinonen, Juho},
title = {Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models},
year = {2022},
isbn = {9781450391948},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501385.3543957},
doi = {10.1145/3501385.3543957},
abstract = {This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.},
booktitle = {Proceedings of the 2022 ACM Conference on International Computing Education Research - Volume 1},
pages = {27–43},
numpages = {17},
keywords = {Robosourcing, Resource generation, Programming exercises, OpenAI Codex, Natural language generation, Large language models, GPT-3, Exercise generation, Code explanations, CS1, Automated feedback},
location = {Lugano and Virtual Event, Switzerland},
series = {ICER '22}
}

@inproceedings{10.1145/3631802.3631830,
author = {Liffiton, Mark and Sheese, Brad E and Savelka, Jaromir and Denny, Paul},
title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631830},
doi = {10.1145/3631802.3631830},
abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students’ usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {8},
numpages = {11},
keywords = {Guardrails, Intelligent programming tutors, Intelligent tutoring systems, Large language models, Natural language interfaces, Novice programmers, Programming assistance},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3641555.3705212,
author = {Baek, Jeonghun and Yamazaki, Tetsuro and Morihata, Akimasa and Mori, Junichiro and Yamakata, Yoko and Taura, Kenjiro and Chiba, Shigeru},
title = {Leveraging LLM for Detecting and Explaining LLM-generated Code in Python Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705212},
doi = {10.1145/3641555.3705212},
abstract = {As large language models (LLMs) have become more advanced, generating code to solve exercises in programming courses has become significantly easier. However, this convenience raises the concern of over-reliance on these tools, potentially hindering students from developing independent coding skills. To address this concern, we introduce an LLM-based detector that not only detects LLM-generated code but also explains the reasons for its judgments. These reasons provide insight into the characteristics of LLM-generated code, enhancing transparency in the detection process. We evaluate the detector in an introductory Python programming course, achieving over 99% accuracy. Additionally, instructors manually reviewed the reasons provided by the detector and verified that 64.7% of reasons for classifying code as LLM-generated were appropriate. These reasons can also serve as feedback, helping students improve their coding skills by understanding the characteristics of expert-level LLM-generated code.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1369–1370},
numpages = {2},
keywords = {detecting and explaining llm-generated code, large language model, llm-based detector, llm-generated code, python programming courses, reasons for judgment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3699538.3699569,
author = {Jegourel, Cyrille and Ong, Jung Yi and Kurniawan, Oka and Meng Shin, Lim and Chitluru, Kushat},
title = {Sieving Coding Assignments Over Submissions Generated by AI and Novice Programmers},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699569},
doi = {10.1145/3699538.3699569},
abstract = {In the era of AI tools like ChatGPT and GitHub Copilot, and with the numerous online resources, computer science education faces the challenge of students potentially submitting plagiarised coding assignments or assignments generated by these technologies. Distinguishing between AI-generated and human-written text is notoriously difficult. In this study, we applied two text distance algorithms, commonly used for machine translation and document comparisons, to detect similarities between various computer Python code submissions and employed hierarchical clustering to analyze them from both AI tools and human programmers. Our results indicate that the distances to the cluster representatives can effectively predict whether a code submission is generated by AI or by novice programmers, achieving an accuracy of over 90%. These findings demonstrate the significant potential of text distance algorithms in identifying the origin of coding submissions, whether generated by AI or by novice programmers.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {12},
numpages = {11},
keywords = {Computing education, code distance, AI code generation, hierarchical clustering, plagiarism, code clone detection},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3657604.3664699,
author = {Hutt, Stephen and Hieb, Grayson},
title = {Scaling Up Mastery Learning with Generative AI: Exploring How Generative AI Can Assist in the Generation and Evaluation of Mastery Quiz Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664699},
doi = {10.1145/3657604.3664699},
abstract = {Generative AI has the potential to scale a number of educational practices, previously limited by resources. One such instructional approach is mastery learning, a pedagogy emphasizing proficiency before progression that is highly resource (teacher time, materials) intensive. The rise of computer-based instruction offered partial solutions, tailoring student progression and automating some facets of the mastery learning process. This work in progress considers the application of large language models for content generation tailored to mastery learning. We present a paired framework for analyzing and evaluating the generated content relative to rubrics designed by the teacher. Recognizing the potential of large language models, we critically assess the potential of improving mastery-based instruction. We close our discussion by considering the applications and limitations of this approach.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {310–314},
numpages = {5},
keywords = {content evaluation, content generation, generative ai, large language models, mastery learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3641555.3705208,
author = {Weber, Jason Lee and Park, Hyunjun and Song, Daniel J. and Apillanes, Jared and Martinez Neda, Barbara and Wong-Ma, Jennifer and Gago-Masague, Sergio},
title = {Investigating Autograder Usage in the Post- Pandemic and LLM Era},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705208},
doi = {10.1145/3641555.3705208},
abstract = {This work investigates the impact of Large Language Models (LLMs) and the COVID-19 pandemic on student behavior with autograder systems in three programming-heavy courses. We examine whether the release of LLMs like ChatGPT and GitHub Copilot, along with post-pandemic effects, has modified student interactions with autograders. Using data from student submissions over five years, totalling over 4,500 students across over 420,000 submissions, we analyze trends in submission behaviors before and after these events. Our methodology involves tracking submission patterns, focusing on timing, frequency, and score.Contrary to expectations, our findings reveal that metrics remain relatively consistent in the post-ChatGPT and post-pandemic era. Despite yearly fluctuations, no significant shift in student behaviors is attributable to these changes. Students continue to rely on a combination of manual debugging and autograder feedback without noticeable changes in their problem-solving approach.These findings highlight the resilience of the educational practices in these courses and suggest that integrating LLMs into mid-level CS curriculum may not necessitate the significant paradigm shift previously envisioned. Future work should extend these analyses to courses with different structures to determine if these results are generalizable. If not, the specific course aspects contributing to our observed ChatGPT and pandemic resilience should be identified.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1653–1654},
numpages = {2},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3674805.3690741,
author = {De Bari, Daniele and Garaccione, Giacomo and Coppola, Riccardo and Torchiano, Marco and Ardito, Luca},
title = {Evaluating Large Language Models in Exercises of UML Class Diagram Modeling},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690741},
doi = {10.1145/3674805.3690741},
abstract = {Large Language Models (LLM) have rapidly affirmed in the latest years as a means to support or substitute human actors in a variety of tasks. LLM agents can generate valid software models, because of their inherent ability in evaluating textual requirements provided to them in the form of prompts. The goal of this work is to evaluate the capability of LLM agents to correctly generate UML class diagrams in activities of Requirements Modeling in the field of Software Engineering. Our aim is to evaluate LLMs in an educational setting, i.e., understanding how valuable are the results of LLMs when compared to results made by human actors, and how valuable can LLM be to generate sample solutions to provide to students. For that purpose, we collected 20 exercises from a diverse set of web sources and compared the models generated by a human and an LLM solver in terms of syntactic, semantic, pragmatic correctness, and distance from a provided reference solution. Our results show that the solutions generated by an LLM solver typically present a significantly higher number of errors in terms of semantic quality and textual difference against the provided reference solution, while no significant difference is found in syntactic and pragmatic quality. We can therefore conclude that, with a limited amount of errors mostly related to the textual content of the solution, UML diagrams generated by LLM agents have the same level of understandability as those generated by humans, and exhibit the same frequency in violating rules of UML Class Diagrams.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {393–399},
numpages = {7},
keywords = {Artificial Intelligence, Class Diagrams, Large Language Models, Software Modeling},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3706599.3720203,
author = {Tang, Xiaohang and Wong, Sam and Huynh, Marcus and He, Zicheng and Yang, Yalong and Chen, Yan},
title = {SPHERE: Supporting Personalized Feedback at Scale in Programming Classrooms with Structured Review of Generative AI Outputs},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720203},
doi = {10.1145/3706599.3720203},
abstract = {This paper introduces SPHERE, a system that enables instructors to effectively create and review personalized feedback for in-class coding activities. Comprehensive personalized feedback is crucial for programming learning. However, providing such feedback in large programming classrooms poses significant challenges for instructors. While Large Language Models (LLMs) offer potential assistance, how to efficiently ensure the quality of LLM-generated feedback remains an open question. SPHERE guides instructors’ attention to critical students’ issues, empowers them with guided control over LLM-generated feedback, and provides visual scaffolding to facilitate verification of feedback quality. Our between-subject study with 20 participants demonstrates SPHERE’s effectiveness in creating more high-quality feedback while not increasing the time spent on the overall review process compared to a baseline system. This work contributes a synergistic approach to scaling personalized feedback in programming education, addressing the challenges of real-time response, issue prioritization, and large-scale personalization.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {467},
numpages = {17},
keywords = {Generative AI, Large Language Model, Programming Education at Scale, Feedback, Computing Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3649217.3653608,
author = {Pankiewicz, Maciej and Baker, Ryan S.},
title = {Navigating Compiler Errors with AI Assistance - A Study of GPT Hints in an Introductory Programming Course},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653608},
doi = {10.1145/3649217.3653608},
abstract = {We examined the efficacy of AI-assisted learning in an introductory programming course at the university level by using a GPT-4 model to generate personalized hints for compiler errors within a platform for automated assessment of programming assignments. The control group had no access to GPT hints. In the experimental condition GPT hints were provided when a compiler error was detected, for the first half of the problems in each module. For the latter half of the module, hints were disabled. Students highly rated the usefulness of GPT hints. In affect surveys, the experimental group reported significantly higher levels of focus and lower levels of confrustion (confusion and frustration) than the control group. For the six most commonly occurring error types we observed mixed results in terms of performance when access to GPT hints was enabled for the experimental group. However, in the absence of GPT hints, the experimental group's performance surpassed the control group for five out of the six error types.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {94–100},
numpages = {7},
keywords = {GPT, LLM, automated assessment, large language models, programming education},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3632620.3671108,
author = {Pawagi, Mrigank and Kumar, Viraj},
title = {Probeable Problems for Beginner-level Programming-with-AI Contests},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671108},
doi = {10.1145/3632620.3671108},
abstract = {To broaden participation, competitive programming contests may include beginner-level problems that do not require knowledge of advanced Computer Science concepts (e.g., algorithms and data structures). However, since most participants have easy access to AI code-generation tools, these problems often become trivial to solve. For beginner-friendly programming contests that do not prohibit the use of AI tools, we propose Probeable Problems: code writing tasks that provide (1)&nbsp;a problem specification that deliberately omits certain details, and (2)&nbsp;a mechanism to probe for these details by asking clarifying questions and receiving immediate feedback. To evaluate our proposal, we conducted a 2-hour programming contest for undergraduate Computer Science students from multiple institutions, where each student was an active member of their institution’s ACM student chapter. The contest comprised of six Probeable Problems for which a popular code-generation tools (e.g., GitHub Copilot) were unable to generate accurate solutions due to the absence of details. Students were permitted to work individually or in groups, and were free to use AI tools. We obtained consent from 26&nbsp;groups (67&nbsp;students) to use their submissions for research. To determine whether Probeable Problems are suitable for such contests, we analyze the extent to which the code submitted by these groups identifies missing details.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {166–176},
numpages = {11},
keywords = {Ambiguity, CS1, Code specifications, Code writing},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3626252.3630828,
author = {Prasad, Prajish and Sane, Aamod},
title = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630828},
doi = {10.1145/3626252.3630828},
abstract = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1070–1076},
numpages = {7},
keywords = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3585059.3611447,
author = {Sakib, Nazmus and Anik, Fahim Islam and Li, Lei},
title = {ChatGPT in IT Education Ecosystem: Unraveling Long-Term Impacts on Job Market, Student Learning, and Ethical Practices},
year = {2023},
isbn = {9798400701306},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3585059.3611447},
doi = {10.1145/3585059.3611447},
abstract = {The use of ChatGPT in the educational ecosystem has opened up new avenues for learning but also raises questions about its multifarious long-term effects. This scientific study explores how ChatGPT, an AI chatbot, may impact the career prospects of Information Technology and Computer Science graduates in the long term, focusing on job automation and displacement. This study also investigates the enduring impact of ChatGPT on students' attitudes toward learning and developing skills in this education domain while examining ethical practices for incorporating this AI-based aid. This research provides methods to deter unethical actions related to ChatGPT and encourage ethical conduct among students for optimal performance. Moreover, it divulges the impact of ChatGPT on job opportunities, positive outlook, and the pressing necessity for ethical regulations in artificial intelligence use and deployment.},
booktitle = {Proceedings of the 24th Annual Conference on Information Technology Education},
pages = {73–78},
numpages = {6},
keywords = {Artificial Intelligence, ChatGPT, Ethical Practices in IT Education, Job Transformation, Student Attitudes},
location = {Marietta, GA, USA},
series = {SIGITE '23}
}

@inproceedings{10.1145/3716640.3716657,
author = {Arora, Utkarsh and Garg, Anupam and Gupta, Aryan and Jain, Samyak and Mehta, Ronit and Oberoi, Rupin and Prachi and Raina, Aryaman and Saini, Manav and Sharma, Sachin and Singh, Jaskaran and Tyagi, Sarthak and Kumar, Dhruv},
title = {Analyzing LLM Usage in an Advanced Computing Class in India},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716657},
doi = {10.1145/3716640.3716657},
abstract = {This study examines the use of large language models (LLMs) by undergraduate and graduate students for programming assignments in advanced computing classes. Unlike existing research, which primarily focuses on introductory classes and lacks in-depth analysis of actual student-LLM interactions, our work fills this gap. We conducted a comprehensive analysis involving 411 students from a Distributed Systems class at an Indian university, where they completed three programming assignments and shared their experiences through Google Form surveys and interviews.Our findings reveal that students leveraged LLMs for a variety of tasks, including code generation, debugging, conceptual inquiries, and test case creation. They employed a spectrum of prompting strategies, ranging from basic contextual prompts to advanced techniques like chain-of-thought prompting and iterative refinement. While students generally viewed LLMs as beneficial for enhancing productivity and learning, we noted a concerning trend of over-reliance, with many students submitting entire assignment descriptions to obtain complete solutions. Given the increasing use of LLMs in the software industry, our study highlights the need to update undergraduate curricula to include training on effective prompting strategies and to raise awareness about the benefits and potential drawbacks of LLM usage in academic settings.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {154–163},
numpages = {10},
keywords = {Large Language Models, Computing Education, User Study},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3643795.3648380,
author = {S Kumar, Smitha and Adam Lones, Michael and Maarek, Manuel and Zantout, Hind},
title = {Investigating the Proficiency of Large Language Models in Formative Feedback Generation for Student Programmers},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648380},
doi = {10.1145/3643795.3648380},
abstract = {Generative AI has considerably altered traditional workplace practice across numerous industries. Ever since the emergence of large language models (LLMs), their potential to generate formative feedback for introductory programming courses has been extensively researched. However, most of these studies have focused on Python. In this work, we examine the bug-fixing and feedback-generation abilities of Code Llama and ChatGPT for Java programming assignments using our new Java benchmark called CodeWBugs. The results indicate that ChatGPT performs reasonably well, and was able to fix 94.33% programs. By comparison, we observed high variability in the results from Code Llama. We further analyzed the impact of different types of prompts and observed that prompts that included task descriptions and test inputs yielded better results. In most cases, the LLMs precisely localized the bugs and also offered guidance on how to proceed. Nevertheless, we also noticed incorrect responses generated by the LLMs, emphasizing the need to validate responses before disseminating feedback to learners.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {88–93},
numpages = {6},
keywords = {large language models (LLM), GPT-4, feedback, java programming, program repair},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@inproceedings{10.1145/3641554.3701906,
author = {Hassan, Mohammed and Chen, Yuxuan and Denny, Paul and Zilles, Craig},
title = {On Teaching Novices Computational Thinking by Utilizing Large Language Models Within Assessments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701906},
doi = {10.1145/3641554.3701906},
abstract = {Novice programmers often struggle to develop computational thinking (CT) skills in introductory programming courses. This study investigates the use of Large Language Models (LLMs) to provide scalable, strategy-driven feedback to teach CT. Through think-aloud interviews with 17 students solving code comprehension and writing tasks, we found that LLMs effectively guided decomposition and program development tool usage. Challenges included students seeking direct answers or pasting feedback without considering suggested strategies. We discuss how instructors should integrate LLMs into assessments to support students' learning of CT.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {471–477},
numpages = {7},
keywords = {code comprehension, debuggers, execution, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626253.3635369,
author = {MacNeil, Stephen and Leinonen, Juho and Denny, Paul and Kiesler, Natalie and Hellas, Arto and Prather, James and Becker, Brett A. and Wermelinger, Michel and Reid, Karen},
title = {Discussing the Changing Landscape of Generative AI in Computing Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635369},
doi = {10.1145/3626253.3635369},
abstract = {In a previous Birds of a Feather discussion, we delved into the nascent applications of generative AI, contemplating its potential and speculating on future trajectories. Since then, the landscape has continued to evolve revealing the capabilities and limitations of these models. Despite this progress, the computing education research community still faces uncertainty around pivotal aspects such as (1) academic integrity and assessments, (2) curricular adaptations, (3) pedagogical strategies, and (4) the competencies students require to instill responsible use of these tools. The goal of this Birds of a Feather discussion is to unravel these pressing and persistent issues with computing educators and researchers, fostering a collaborative exploration of strategies to navigate the educational implications of advancing generative AI technologies. Aligned with this goal of building an inclusive learning community, our BoF is led by globally distributed leaders to facilitate multiple coordinated discussions that can lead to a broader conversation about the role of LLMs in CS education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1916},
numpages = {1},
keywords = {academic integrity, assessment, computing education, curriculum, large language models, pedagogy},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641555.3704765,
author = {Liu, Rongxin and Malan, David J. and Zhukovets, Yuliia and Lloyd, Doug},
title = {Teaching with AI (GPT)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704765},
doi = {10.1145/3641555.3704765},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. In this tutorial, we share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's latest APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, collaboratively building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1773},
numpages = {1},
keywords = {AI, AI ethics, ChatGPT, GPT, generative AI, programming, prompt, prompt engineering},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3722237.3722310,
author = {Hwang, Min-Shiang and Fatima, Kanza and Chan, Chi-Shiang and Wu, Chia-Chun},
title = {Research on Steganography Course with Large Language Model ChatGPT Assisted Learning},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722310},
doi = {10.1145/3722237.3722310},
abstract = {In this study, by integrating practice-oriented teaching methods and combining large language models to assist learning and teaching situations, it is proposed that the Steganography course is practical-oriented and integrates ChatGPT with the Steganography language model teaching and teaching established by the applicant. In addition to focusing In addition to cultivating students with Steganography concepts and practical operational abilities, we hope to cultivate students' abilities of active observation, independent research, and critical thinking so that students can meet the technology industry's professional skills and requirements for Steganography studies. This research explores the pre-test and post-test, of course, students' use of large language models to learn to have higher learning attitudes and achievements towards Steganography theory and practice.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {422–425},
numpages = {4},
keywords = {ChatGPT, Social Media Learning, Independent Thinking Ability, Learning Effectiveness, Project-based Learning, Steganography, Information Security Theory and Practice},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3641554.3701859,
author = {Gorson Benario, Jamie and Marroquin, Jenn and Chan, Monica M. and Holmes, Ernest D.V. and Mejia, Daniel},
title = {Unlocking Potential with Generative AI Instruction: Investigating Mid-level Software Development Student Perceptions, Behavior, and Adoption},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701859},
doi = {10.1145/3641554.3701859},
abstract = {Generative AI tools are rapidly evolving and impacting many domains, including programming. Computer Science (CS) instructors must address student access to these tools. While some advocate to ban the tools entirely, others suggest embracing them so that students develop the skills for utilizing the tools safely and responsibly. Studies indicate positive impacts, as well as cautions, on student outcomes when these tools are integrated into courses. We studied the impact of incorporating instruction on industry-standard generative AI tools into a mid-level software development course with students from 16 Minority Serving Institutions. 89% of student participants used generative AI tools prior to the course without any formal instruction. After formal instruction, students most frequently used generative AI tools for explaining concepts and learning new things. Students generally reported positive viewpoints on their ability to learn to program and learn problem-solving skills while using generative AI tools. Finally, we found that students: reported to understand their code when they work with generative AI tools, are critical about the outputs that generative AI tools provide, and check outputs of generative AI tools to ensure accuracy.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {395–401},
numpages = {7},
keywords = {cs education, generative ai, llms in cs education, minority serving institutions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3631802.3631816,
author = {Malaise, Yoshi and Signer, Beat},
title = {Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631816},
doi = {10.1145/3631802.3631816},
abstract = {We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {24},
numpages = {8},
keywords = {PRIMM, Programming Education, Study Lenses},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3649409.3691089,
author = {Gupta, Anisha and Monahan, Robert and Vandenberg, Jessica and Smith, Andy and Elsayed, Rasha and Fox, Kimkinyona and Minogue, James and Oliver, Kevin and Hubbard Cheuoua, Aleata and Ringstaff, Cathy and Mott, Bradford},
title = {Leveraging Large Language Models for Automated Assessment of Elementary Students' Block-Based Narrative Programs},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691089},
doi = {10.1145/3649409.3691089},
abstract = {Recent years have seen increasing awareness of the need to engage young learners in computational thinking (CT). Integrating digital storytelling, where students create short narratives, and CT offers significant potential for promoting interdisciplinary learning for students; however, it is critical to provide both teachers and students with automated support. A promising approach for enabling support is to leverage advances in Large Language Models (LLMs), which have demonstrated considerable potential for assessing both programming and natural language artifacts. In this work, we investigate the capabilities of LLMs to automatically assess student-created block-based programs developed using a narrative-centered learning environment that engages upper elementary students (ages 9 to 11) in learning CT and physical science through the creation of interactive science narratives. Using the narrative programs created by 28 students, we explore the efficacy of LLMs to assess the programs across two dimensions.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {318–319},
numpages = {2},
keywords = {k-12 education, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3641555.3705132,
author = {Blasco, I\~{n}aki and Mochetti, Karina},
title = {Assessing the Influence of ChatGPT on Student Outcomes in a Models of Computing Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705132},
doi = {10.1145/3641555.3705132},
abstract = {This study investigates the impact of ChatGPT on student performance in a Models of Computing course, foundational for the computer science major. Analysing data from 11 pre-lecture quizzes across four terms, we found a decline in average quiz scores, particularly in the latest term. The results suggest a correlation between increased reliance on ChatGPT and decreased student performance, especially on challenging questions where the AI frequently struggled. These findings highlight both the benefits and challenges of integrating AI in education. Our ongoing research aims to explore this further across multiple courses, ultimately promoting responsible AI use to enhance learning outcomes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1389–1390},
numpages = {2},
keywords = {computing education, llm, student performance},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3722479.3722507,
author = {Crocetti, Giancarlo and Bak, Seonwoo and Vautor-Laplaceliere, Daena D. and Noory, Naqib A.},
title = {Evaluating the Pedagogical Impact of Large Language Models on Programming Skills in Data Science Programs in Higher Education},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The integration of GenAI (GenAI), such as large language models (LLMs), in education has raised the question of how it will alter the students' training and learning outcomes. To better understand the phenomenon, this empirical study explores whether college students find GenAI tools helpful in advancing their skills, particularly Python programming proficiency.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {63–64},
numpages = {2}
}

@inproceedings{10.1145/3706599.3720081,
author = {Patton, Evan W and Kim, David Y and Granquist, Ashley M and Liu, Robin and Scott, Arianna and Zamanova, Jennet and Abelson, Harold},
title = {Aptly: Making Mobile Apps from Natural Language},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720081},
doi = {10.1145/3706599.3720081},
abstract = {This paper introduces Aptly, a platform designed to democratize mobile app development, particularly for young learners. Aptly integrates a Large Language Model (LLM) with App Inventor, enabling users to create apps using their natural language. User’s description is translated into a programming language that corresponds with App Inventor’s visual blocks. A preliminary study with high school students demonstrated the usability and potential of the platform. Prior programming experience influenced how users interact with Aptly. Participants identified areas for improvement and expressed a shift in perspective regarding programming accessibility and AI’s role in creative endeavors.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {73},
numpages = {6},
keywords = {Computational Action, Large Language Model, Block Programming, Mobile Application},
location = {
},
series = {CHI EA '25}
}

@article{10.5555/3737313.3737323,
author = {Barnard, Jakob and Braught, Grant and Davis, Janet and Holland-Minkley, Amanda and Schmitt, Karl and Tartaro, Andrea},
title = {Reviewing and Revising your Undergraduate CS Major: A Structured Design Process for Creating Distinctive Curricula},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Computer science (CS) programs have a variety of reasons for regularly reviewing and revising the curriculum for their undergraduate major. Some of these stem from the rapid pace of change in the discipline and corresponding changes in industry expectations for CS graduates. This has been most recently seen as departments consider how to adjust to advances in generative AI and respond to new international curricular guidelines in the form of CS2023 [1]. Programs also revise their CS major in response to contextual shifts at their institution, such as changes in the size and makeup of the student body, the resources and staffing of a program, assessment results, or new institutional priorities [6]. A shifting student body may come with changes in prior experience with computing and in the professional goals of the students. For smaller programs, staffing changes often affect the balance of expertise within subareas of CS. New institutional priorities such as enabling more study abroad experiences or embedding internship/service-learning into the curriculum can require majors to adjust to both accommodate and support these priorities.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {32–34},
numpages = {3}
}

@inproceedings{10.1145/3641555.3705066,
author = {Rahman, Farzana},
title = {Leveraging or Limiting: Strategies and Implications of ChatGPT Use by Undergraduate TAs in Large CS2 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705066},
doi = {10.1145/3641555.3705066},
abstract = {As AI tools like ChatGPT become more prevalent in educational settings, their potential to assist undergraduate teaching assistants (uTAs) in large Computer Science 2 (CS2) courses presents both opportunities and challenges. This work focuses on how ChatGPT can be strategically utilized by uTAs during office hours to enhance student support, particularly in complex topics such as data structures, algorithm development, and object-oriented programming. We explored effective strategies for uTAs to use ChatGPT in ways that promote deeper student understanding without compromising the development of independent problem-solving skills. Key strategies include leveraging ChatGPT for real-time code debugging assistance, offering alternative approaches to solving coding problems, comparing and critiquing self and AI generated documentation, and code reviewing. This work also identifies potential challenges, such as the risk of students or uTAs becoming overly dependent on AI-generated solutions and the possibility of inaccurate or incomplete responses from the AI. Hence, our findings highlight the dual role of ChatGPT as both an asset and a potential hindrance, depending on how it is utilized. To mitigate these risks, we propose a set of best practices that ensure ChatGPT enhances, rather than replaces, the uTA's role as a facilitator of learning. The findings from this research provide valuable insights into how uTAs can integrate AI tools thoughtfully into office hours to offer more effective support, ultimately improving student engagement and learning outcomes in large-scale CS2 courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1745},
numpages = {1},
keywords = {ai tools, cs2, student engagement, ta training, undergraduate teaching assistants},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3654777.3676347,
author = {Tang, Xiaohang and Wong, Sam and Pu, Kevin and Chen, Xi and Yang, Yalong and Chen, Yan},
title = {VizGroup: An AI-assisted Event-driven System for Collaborative Programming Learning Analytics},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676347},
doi = {10.1145/3654777.3676347},
abstract = {Programming instructors often conduct collaborative learning activities, like Peer Instruction, to foster a deeper understanding in students and enhance their engagement with learning. These activities, however, may not always yield productive outcomes due to the diversity of student mental models and their ineffective collaboration. In this work, we introduce VizGroup, an AI-assisted system that enables programming instructors to easily oversee students’ real-time collaborative learning behaviors during large programming courses. VizGroup leverages Large Language Models (LLMs) to recommend event specifications for instructors so that they can simultaneously track and receive alerts about key correlation patterns between various collaboration metrics and ongoing coding tasks. We evaluated VizGroup with 12 instructors in a comparison study using a dataset collected from a Peer Instruction activity that was conducted in a large programming lecture. The results showed that VizGroup helped instructors effectively overview, narrow down, and track nuances throughout students’ behaviors.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {93},
numpages = {22},
keywords = {Collaborative Learning, Programming Education},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@inproceedings{10.1145/3626253.3635432,
author = {Edwards, Katlyn and Scalisi, Corrie and DeMars-Smith, Julianne and Lee, Key},
title = {Google Colab for Teaching CS and ML},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635432},
doi = {10.1145/3626253.3635432},
abstract = {Colab is a frictionless, hosted Jupyter notebook that combines text, code, and outputs into a single document. Colab allows anybody to write and execute arbitrary python code using the latest ML accelerators (GPU/TPUs) through the browser, no setup required. It is especially well suited to machine learning, data analysis and education, and serves over 10 million active users. Colab is used extensively for teaching computer science and machine learning, giving equitable access to expensive resources and AI/ML instruction to students around the world, regardless of background. As one professor stated: ''There's an equity aspect. Not everyone has a high-end laptop. Being able to say everyone has the same computing experience and they all have access to the same resources and they can start using them right away, it allows us to find more talent randomly distributed around our student population. Colab has been the best solution so far.'' Additionally, Google Colab partners with Google DeepMind to launch innovative AI coding features and models to the public, giving users the ability to author code with natural language, a much simpler experience for writing code. We are the team who builds Colab, and would love to demo our latest features, including Google Classroom integration and AI coding using Gemini, Google's latest foundation AI model. We hope to make attendees aware of these features and have them give us feedback on their usefulness and impact on the process of teaching computer science and machine learning.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1925},
numpages = {1},
keywords = {ai, colab, jupyter},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3665464.3665476,
author = {Alrifai, Rad},
title = {Using Generative AI to Design Programming Assignments in Introduction to Computer Science},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Programming stands as an essential requisite in computer science education. Recognizing the challenges students face in learning programming effectively, the proposed assignment aims to integrate generative artificial intelligence (AI) tools to teach students introductory programming constructs. Generative AI has gained an increasing popularity in recent years. Several available Generative AI implementations can now help students learn programming essentials and debugging skills.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {103–106},
numpages = {4}
}

@inproceedings{10.1145/3699538.3699541,
author = {Korpimies, Kai and Laaksonen, Antti and Luukkainen, Matti},
title = {Unrestricted Use of LLMs in a Software Project Course: Student Perceptions on Learning and Impact on Course Performance},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699541},
doi = {10.1145/3699538.3699541},
abstract = {Large language models (LLMs) provide round-the-clock personalized programming assistance, unlike course instructors or traditional online information sources such as Stack Overflow. While LLMs can aid in code generation, concerns about over-reliance and the impact on learning persist. This study discusses students’ experiences with LLMs in a software project course where students were allowed to use LLMs freely except for unit test generation. We conducted surveys during course instances in autumn 2023 and spring 2024. The surveys assessed the extent of LLM usage, methods of application, and perceived impact on learning. Results indicate diverse usage patterns, with many students finding LLMs beneficial for efficiency and problem-solving, though over-reliance and poor-quality outputs were noted concerns. The usage patterns can be linked to course performance and time spent on the project.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {23},
numpages = {7},
keywords = {Large language models, Computer Science Education, User Study, Code generation, Software project},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3641554.3701827,
author = {Renzella, Jake and Vassar, Alexandra and Lee Solano, Lorenzo and Taylor, Andrew},
title = {Compiler-Integrated, Conversational AI for Debugging CS1 Programs},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701827},
doi = {10.1145/3641554.3701827},
abstract = {Large Language Models (LLMs) present a transformative opportunity to address longstanding challenges in computing education. This paper presents a conversational AI extension to an LLM-enhanced C/C++ compiler which generates pedagogically sound programming error explanations. Our new tool, DCC Sidekick, retains compiler integration, allowing students to see their code, error messages, and stack frames alongside a conversational AI interface. Compiler context improves error explanations, and provides a seamless development experience. We present quantitative analyses of Sidekick's usage and engagement patterns in a large CS1 course. In the first seven weeks of use, 959 students initiated 11,222 DCC Sidekick sessions, generating 17,982 error explanations. Over half of all conversations occur outside of business hours, highlighting the value of these always-available tools. Early results indicate strong adoption of conversational AI debugging tools, demonstrating scalability in supporting large CS1 courses. We share implementation details and lessons learned, offering guidance to educators considering integrating AI tools with pedagogical guardrails.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {994–1000},
numpages = {7},
keywords = {ai in education, cs1, generative ai, programming error messages},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3663384.3663393,
author = {Feldman, Molly Q and Anderson, Carolyn Jane},
title = {Non-Expert Programmers in the Generative AI Future},
year = {2024},
isbn = {9798400710179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663384.3663393},
doi = {10.1145/3663384.3663393},
abstract = {Generative AI is rapidly transforming the practice of programming. At the same time, our understanding of who writes programs, for what purposes, and how they program, has been evolving. By facilitating natural-language-to-code interactions, large language models for code have the potential to open up programming work to a broader range of workers. While existing work finds productivity benefits for expert programmers, interactions with non-experts are less well-studied. In this paper, we consider the future of programming for non-experts through a controlled study of 67 non-programmers. Our study reveals multiple barriers to effective use of large language models of code for non-experts, including several aspects of technical communication. Comparing our results to a prior study of beginning programmers illuminates the ways in which a traditional introductory programming class does and does not equip students to effectively work with generative AI. Drawing on our empirical findings, we lay out a vision for how to empower non-expert programmers to leverage generative AI for a more equitable future of programming.},
booktitle = {Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work},
articleno = {15},
numpages = {19},
keywords = {CS1, Code LLMs, Generative AI, mixed methods, non-experts},
location = {Newcastle upon Tyne, United Kingdom},
series = {CHIWORK '24}
}

@inproceedings{10.1145/3708359.3712104,
author = {Kazemitabaar, Majeed and Huang, Oliver and Suh, Sangho and Henley, Austin Z and Grossman, Tovi},
title = {Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning},
year = {2025},
isbn = {9798400713064},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708359.3712104},
doi = {10.1145/3708359.3712104},
abstract = {Novice programmers are increasingly relying on Large Language Models (LLMs) to generate code for learning programming concepts. However, this interaction can lead to superficial engagement, giving learners an illusion of learning and hindering skill development. To address this issue, we conducted a systematic design exploration to develop seven cognitive engagement techniques aimed at promoting deeper engagement with AI-generated code. In this paper, we describe our design process, the initial seven techniques and results from a between-subjects study (N=82). We then iteratively refined the top techniques and further evaluated them through a within-subjects study (N=42). We evaluate the friction each technique introduces, their effectiveness in helping learners apply concepts to isomorphic tasks without AI assistance, and their success in aligning learners’ perceived and actual coding abilities. Ultimately, our results highlight the most effective technique: guiding learners through the step-by-step problem-solving process, where they engage in an interactive dialog with the AI, prompting what needs to be done at each stage before the corresponding code is revealed.},
booktitle = {Proceedings of the 30th International Conference on Intelligent User Interfaces},
pages = {695–714},
numpages = {20},
keywords = {AI-Assisted Programming, Generative AI, Copilot, ChatGPT, Cognitive Engagement Enhancement, AI-Assisted Learning, Cognitive Forcing Functions, Task Decomposition, Learning Outcomes},
location = {
},
series = {IUI '25}
}

@inproceedings{10.1145/3723010.3723034,
author = {Mueller, Moritz and List, Corinna and Kipp, Michael},
title = {The Power of Context: An LLM-based Programming Tutor with Focused and Proactive Feedback},
year = {2025},
isbn = {9798400712821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723010.3723034},
doi = {10.1145/3723010.3723034},
abstract = {Current research aims to utilize Large Language Models (LLMs) for tutoring beginning programming students efficiently and at scale. Students often struggle to interact effectively with LLMs to obtain meaningful feedback. We introduce an LLM-based Intelligent Tutoring System (ITS) with a structured interface and prompts aligned with Hattie’s feedback model. To provide more focused feedback, we utilize the user interaction history for context. Additionally, we explore the question of proactivity.A user study with 9 participants compared history-based and current-state feedback methods using ChatGPT, showing a preference for history-based feedback in 69% of cases and with higher usefulness ratings (M = 7.57 vs. M = 4.1, p = 0.03 (statistically significant at p &lt; 0.05)). This effect became more pronounced in later learning stages. For proactivity, we collected user data from the study, where participants explicitly requested feedback, and trained a neural network (NN) to predict optimal feedback timing. While the model achieved 97% accuracy on test data, the small sample size (N = 10) and the use of oversampling limit its generalizability. Future work will refine history-based feedback with eye-tracking data and integrate NN-driven proactive behavior to further enhance the effectiveness of LLM-based ITS in programming education.},
booktitle = {Proceedings of the 6th European Conference on Software Engineering Education},
pages = {1–10},
numpages = {10},
keywords = {CS in higher education, Large Language Models, intelligent tutoring, focused feedback, proactive feedback, neural networks},
location = {
},
series = {ECSEE '25}
}

@inproceedings{10.1145/3649217.3653615,
author = {Gardella, Nicholas and Pettit, Raymond and Riggs, Sara L.},
title = {Performance, Workload, Emotion, and Self-Efficacy of Novice Programmers Using AI Code Generation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653615},
doi = {10.1145/3649217.3653615},
abstract = {Artificial Intelligence-driven Development Environments (AIDEs) offer developers revolutionary computer programming assistance. There is great potential in incorporating AIDEs into Computer Science education; however, the effects of these tools should be fully examined before doing so. Here, a within-subjects study was conducted to compare the programming performance, workload, emotion, and self-efficacy of seventeen novices coding with and without use of the GitHub Copilot AIDE under time pressure. Results showed that using the AIDE significantly increased programming efficiency and reduced effort and mental workload but did not significantly impact emotion or self-efficacy. However, participants' performance improved with more experience using the AI, and their self-efficacy followed. The results suggest that students who try AIDEs will likely be tempted to use them for time-sensitive work. There is no evidence that providing AIDEs will aid struggling students, but there is a clear need for students to practice with AI to become competent and confident using it.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {290–296},
numpages = {7},
keywords = {ai code generators, artificial intelligence-driven development environment, computer science education, cs1, generative ai, github copilot, introductory programming, novice programmers},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3706468.3706564,
author = {Ramanathan, Sriram and Lim, Lisa-Angelique and Mottaghi, Nazanin Rezazadeh and Buckingham Shum, Simon},
title = {When the Prompt becomes the Codebook: Grounded Prompt Engineering (GROPROE) and its application to Belonging Analytics},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706564},
doi = {10.1145/3706468.3706564},
abstract = {With the emergence of generative AI, the field of Learning Analytics (LA) has increasingly embraced the use of Large Language Models (LLMs) to automate qualitative analysis. Deductive analysis requires theoretical or other conceptual grounding to inform coding. However, few studies detail the process of translating the literature into a codebook, and then into an effective LLM prompt. In this paper, we introduce Grounded Prompt Engineering (GROPROE) as a systematic process to develop a literature-grounded prompt for deductive analysis. We demonstrate our GROPROE process on a dataset of 860 written reflections, coding for students’ affective engagement and sense of belonging. To evaluate the quality of the coding we demonstrate substantial human/LLM Inter-Annotator Reliability (IAR). To evaluate the consistency of LLM coding, a subset of the data was analysed 60 times using the LLM Quotient showing how this stabilized for most codes. We discuss the dynamics of human-AI interaction when following GROPROE, foregrounding how the prompt took over as the iteratively revised codebook, and how the LLM provoked codebook revision. The contributions to the LA field are threefold: (i) GROPROE as a systematic prompt-design process for deductive coding grounded in literature, (ii) a detailed worked example showing its application to Belonging Analytics, and (iii) implications for human-AI interaction in automated deductive analysis.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {713–725},
numpages = {13},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3632620.3671098,
author = {Padiyath, Aadarsh and Hou, Xinying and Pang, Amy and Viramontes Vargas, Diego and Gu, Xingjian and Nelson-Fromm, Tamara and Wu, Zihan and Guzdial, Mark and Ericson, Barbara},
title = {Insights from Social Shaping Theory: The Appropriation of Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671098},
doi = {10.1145/3632620.3671098},
abstract = {The capability of large language models (LLMs) to generate, debug, and explain code has sparked the interest of researchers and educators in undergraduate programming, with many anticipating their transformative potential in programming education. However, decisions about why and how to use LLMs in programming education may involve more than just the assessment of an LLM’s technical capabilities. Using the social shaping of technology theory as a guiding framework, our study explores how students’ social perceptions influence their own LLM usage. We then examine the correlation of self-reported LLM usage with students’ self-efficacy and midterm performances in an undergraduate programming course. Triangulating data from an anonymous end-of-course student survey (n = 158), a mid-course self-efficacy survey (n=158), student interviews (n = 10), self-reported LLM usage on homework, and midterm performances, we discovered that students’ use of LLMs was associated with their expectations for their future careers and their perceptions of peer usage. Additionally, early self-reported LLM usage in our context correlated with lower self-efficacy and lower midterm scores, while students’ perceived over-reliance on LLMs, rather than their usage itself, correlated with decreased self-efficacy later in the course.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {114–130},
numpages = {17},
keywords = {Generative AI, Large Language Models, Self-Efficacy, Social Shaping Theory, Technology Appropriation Model},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3641554.3701791,
author = {Koutcheme, Charles and Dainese, Nicola and Sarsa, Sami and Hellas, Arto and Leinonen, Juho and Ashraf, Syed and Denny, Paul},
title = {Evaluating Language Models for Generating and Judging Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701791},
doi = {10.1145/3641554.3701791},
abstract = {The emergence of large language models (LLMs) has transformed research and practice across a wide range of domains. Within the computing education research (CER) domain, LLMs have garnered significant attention, particularly in the context of learning programming. Much of the work on LLMs in CER, however, has focused on applying and evaluating proprietary models. In this article, we evaluate the efficiency of open-source LLMs in generating high-quality feedback for programming assignments and judging the quality of programming feedback, contrasting the results with proprietary models. Our evaluations on a dataset of students' submissions to introductory Python programming exercises suggest that state-of-the-art open-source LLMs are nearly on par with proprietary models in both generating and assessing programming feedback. Additionally, we demonstrate the efficiency of smaller LLMs in these tasks and highlight the wide range of LLMs accessible, even for free, to educators and practitioners.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {624–630},
numpages = {7},
keywords = {automatic evaluation, automatic feedback, generative ai, large language models, llm-as-a-judge, open source, programming feedback},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3627673.3679881,
author = {Ding, Yuyang and Hu, Hanglei and Zhou, Jie and Chen, Qin and Jiang, Bo and He, Liang},
title = {Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679881},
doi = {10.1145/3627673.3679881},
abstract = {With the introduction of large language models (LLMs), automatic math reasoning has seen tremendous success. However, current methods primarily focus on providing solutions or using techniques like Chain-of-Thought to enhance problem-solving accuracy. In this paper, we focus on improving the capability of mathematics teaching via a Socratic teaching-based LLM (SocraticLLM), which guides learners toward profound thinking with clarity and self-discovery via conversation. We collect and release a high-quality mathematical teaching dataset, named SocraticMATH, which provides Socratic-style conversations of problems with extra knowledge. Also, we propose a knowledge-enhanced LLM as a strong baseline to generate reliable responses with review, guidance/heuristic, rectification, and summarization. Experimental results show the great advantages of SocraticLLM by comparing it with several strong generative models. The codes and datasets are available on https://github.com/ECNU-ICALK/SocraticMath.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3730–3735},
numpages = {6},
keywords = {LLMs, conversation, mathematics, socratic teaching},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3701551.3703577,
author = {Tian, Yijun and Han, Yikun and Chen, Xiusi and Wang, Wei and Chawla, Nitesh V.},
title = {Beyond Answers: Transferring Reasoning Capabilities to Smaller LLMs Using Multi-Teacher Knowledge Distillation},
year = {2025},
isbn = {9798400713293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701551.3703577},
doi = {10.1145/3701551.3703577},
abstract = {Transferring the reasoning capability from stronger large language models (LLMs) to smaller ones has been quite appealing, as smaller LLMs are more flexible to deploy with less expense. Among the existing solutions, knowledge distillation stands out due to its outstanding efficiency and generalization. However, existing methods suffer from several drawbacks, including limited knowledge diversity and the lack of rich contextual information. To solve the problems and facilitate the learning of compact language models, we propose TinyLLM, a new knowledge distillation paradigm to learn a small student LLM from multiple large teacher LLMs. In particular, we encourage the student LLM to not only generate the correct answers but also understand the rationales behind these answers. Given that different LLMs possess diverse reasoning skills, we guide the student model to assimilate knowledge from various teacher LLMs. We further introduce an in-context example generator and a teacher-forcing Chain-of-Thought strategy to ensure that the rationales are accurate and grounded in contextually appropriate scenarios. Extensive experiments on six datasets across two reasoning tasks demonstrate the superiority of our method. Results show that TinyLLM can outperform large teacher LLMs significantly, despite a considerably smaller model size. The source code is available at: https://github.com/YikunHan42/TinyLLM.},
booktitle = {Proceedings of the Eighteenth ACM International Conference on Web Search and Data Mining},
pages = {251–260},
numpages = {10},
keywords = {knowledge distillation, knowledge reasoning, large language models},
location = {Hannover, Germany},
series = {WSDM '25}
}

@inproceedings{10.1145/3626252.3630799,
author = {Al-Hossami, Erfan and Bunescu, Razvan and Smith, Justin and Teehan, Ryan},
title = {Can Language Models Employ the Socratic Method? Experiments with Code Debugging},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630799},
doi = {10.1145/3626252.3630799},
abstract = {When employing the Socratic method of teaching, instructors guide students toward solving a problem on their own rather than providing the solution directly. While this strategy can substantially improve learning outcomes, it is usually time-consuming and cognitively demanding. Automated Socratic conversational agents can augment human instruction and provide the necessary scale, however their development is hampered by the lack of suitable data for training and evaluation. In this paper, we introduce a manually created dataset of multi-turn Socratic advice that is aimed at helping a novice programmer fix buggy solutions to simple computational problems. The dataset is then used for benchmarking the Socratic debugging abilities of a number of language models, ranging from fine-tuning the instruction-based text-to-text transformer Flan-T5 to zero-shot and chain of thought prompting of the much larger GPT-4. The code and datasets are made freely available for research at the link below.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {53–59},
numpages = {7},
keywords = {benchmark dataset, debugging, language models, socratic dialogue},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3633418,
author = {Gunawardena, Ananda and Chaturvedi, Naina},
title = {AI Enhanced Learning: Powering Curated Videos with Generative Intelligence},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633418},
doi = {10.1145/3626253.3633418},
abstract = {Instructional videos are becoming increasingly popular among computer science students. Over 78% of students frequently visit YouTube to find videos as supplement to their textbook or classroom instruction[1]. Recent surveys show that on average, 73% of students prefer having their instructors curate a supplemental video library to aid in their learning. Now, the emergence of generative AI is revolutionizing supplemental video instruction, enabling instructors to generate slides, recording scripts, and produce high-quality videos with deep search and embedded interactive activities.Generative AI also takes the student video learning to a new level by providing AI-generated video summaries, on-demand questions, and exploration of topics in greater depth. Integrating AI into standard videos greatly expands the possibilities of video-based learning. This workshop demonstrates how educators can enhance their existing video playlists by incorporating AI to increase student engagement and establish safety measures for AI use in education. By using dynamic dashboards, scheduled content, and gamified questions, instructors can maintain student focus.Drawing on insights from computer science courses taught at Princeton and Rutgers Universities, we will highlight the transformative potential of AI-enhanced videos in promoting active learning, particularly in large classes. We will discuss engagement strategies and real-time data visualizations applicable to any video platform. We will utilize the cubits.ai[2] platform, a Princeton University initiative that enhances the impact of computer science courses. The platform is free, and participants are encouraged to bring their own video playlists to curate them into AI-enabled collections by enhancing the student experience through integrated generative AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1898},
numpages = {1},
keywords = {ai generated content, contextualized generative ai, cost-effective videos, customized videos, data-driven insights, instructional videos, video summarization},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3587102.3588815,
author = {Daun, Marian and Brings, Jennifer},
title = {How ChatGPT Will Change Software Engineering Education},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588815},
doi = {10.1145/3587102.3588815},
abstract = {This position paper discusses the potential for using generative AIs like ChatGPT in software engineering education. Currently, discussions center around potential threats emerging from student's use of ChatGPT. For instance, generative AI will limit the usefulness of graded homework dramatically. However, there exist potential opportunities as well. For example, ChatGPT's ability to understand and generate human language allows providing personalized feedback to students, and can thus accompany current software engineering education approaches. This paper highlights the potential for enhancing software engineering education. The availability of generative AI will improve the individualization of education approaches. In addition, we discuss the need to adapt software engineering curricula to the changed profiles of software engineers. Moreover, we point out why it is important to provide guidance for using generative AI and, thus, integrate it in courses rather than accepting the unsupervised use by students, which can negatively impact the students' learning.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, generative AI, software engineering education},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3632621.3671424,
author = {Mozgovoy, Maxim and Suero Montero, Calkin},
title = {Exploring Students Solutions to Concurrent and Parallel Programming Exercises – Impact of Generative AI},
year = {2024},
isbn = {9798400704765},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632621.3671424},
doi = {10.1145/3632621.3671424},
abstract = {Background. Concurrent and parallel programming is difficult to teach and learn as the understanding of complex and abstract concepts such as nondeterminism, semaphore, and rare conditions, among others, is required [1, 2, 9], having as a core issue the synchronisation of processes to achieve a common goal [4]. It is well-acknowledged that concurrent and parallel programming skills are fundamental since, nowadays, computing is increasingly handled in a parallel manner [7].Problem and Motivation. Therefore, identifying students’ pitfalls and successes when solving practical concurrent and parallel programming exercises could shed light on the best approaches and strategies that they use [3]. In addition, the advent of large language models, and generative AI applications such as ChatGPT, has prompted intensive research on their use in several areas including programming teaching and learning [8]. Yet, the studies in the literature have focused on issues related to learning to program by novice students in introductory courses (e.g., CS1, CS2) [6]. Less work, however, has been presented on the impact of generative AI tools in advanced programming practices such as concurrent and parallel programming.Methodology. To investigate whether generative AI has had an impact on the submitted concurrent and parallel programming exercises solutions at the University of Aizu, Japan, we performed a comparison analysis of the students’ submissions over 2020–2023. The analysis included five different exercises covering the basis of concurrency through various tasks and scenarios where the implementation of parallel processes is needed as solution. For instance, exercises 2.3 and 2.4 required to create parallel processes and perform independent computations; exercises 3.2 and 3.3, required synchronisation of the parallel processes; and in exercise 3.5 a code template was given for modification. We analysed the submissions of 72 undergraduate 3rd year students (avg. 18 students/year) and labelled the solutions using the following nomenclature: OK, indicating a good solution; OKFeat, a good solution but with unusual features; AdvLib, use of unnecessary advanced library or functionality; BadTool, use of an inappropriate tool when the task definition explicitly required a different tool; CodeErr, general coding error; SyncErr, concurrent programming specific error; N/A, solution not submitted or incomplete.Results and Analysis. Results show a substantial increase in the incidence of use of advance libraries (AdvLib) and the wrong tools (BadTool) among students in 2023 for three out of the five analysed exercises. At the same time the concurrency programming-specific errors (SyncErr) also see a reduction in all the exercises. (Figure 1). This coincides with the availability of generative AI tools such as ChatGPT [5], which warrants further investigations to understand how students, teachers and instructors could harness the affordances of large language models in their concurrent programming learning, teaching, and practice.Contribution and Impact. This paper presents an initial step towards investigating the impact of generative AI on advanced programming topics. This research will continue to uncover strategies for the lecturers and instructors to identify the affordances and use of generative AI and to design exercises that harness these affordances to support students learning of difficult programming concepts.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 2},
pages = {533–534},
numpages = {2},
keywords = {Evaluation of students’ exercises, Large language models in advanced programming},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3626253.3635600,
author = {Chen, Xi and Liang, Jingsai},
title = {Pair Programming with ChatGPT},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635600},
doi = {10.1145/3626253.3635600},
abstract = {This poster explores the potential of ChatGPT to replace the traditional approach of pair programming in introductory computer science courses. Traditionally, two students collaborate as a driver and a navigator, periodically switching roles. Now, a student can pair up with ChatGPT, which offers an innovative approach to pair programming. This exploratory activity, which emphasizes collaboration and communication, provides step-by-step instructions for effectively interacting with ChatGPT during pair programming.This poster reflects on the advantages and limitations of using ChatGPT in pair programming. The main advantages of using ChatGPT include rapid responses, syntax error-free code generation, and flexibility in handling incomplete pseudocode. The primary limitations include the coding generation style, redundancy in responses, and challenges in understanding the code. Despite the advantages, it may still be valuable to have students work with human partners in certain situations, particularly for learning purposes.This poster proposes that ChatGPT is an invaluable tool for enhancing productivity and emphasizes the importance of becoming proficient in its use during students' college years. It also provides insights into the effective utilization of ChatGPT in pair programming and its preparation for future careers in programming and related fields.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1600–1601},
numpages = {2},
keywords = {chatgpt, pair programming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3689187.3709607,
author = {Clear, Tony and Cajander, \r{A}sa and Clear, Alison and McDermott, Roger and Daniels, Mats and Divitini, Monica and Forshaw, Matthew and Humble, Niklas and Kasinidou, Maria and Kleanthous, Styliani and Kultur, Can and Parvini, Ghazaleh and Polash, Mohammad and Zhu, Tingting},
title = {AI Integration in the IT Professional Workplace: A Scoping Review and Interview Study with Implications for Education and Professional Competencies},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709607},
doi = {10.1145/3689187.3709607},
abstract = {As Artificial Intelligence (AI) continues transforming workplaces globally, particularly within the Information Technology (IT) industry, understanding its impact on IT professionals and computing curricula is crucial. This research builds on joint work from two countries, addressing concerns about AI's increasing influence in IT sector workplaces and its implications for tertiary education. The study focuses on AI technologies such as generative AI (GenAI) and large language models (LLMs). It examines how they are perceived and adopted and their effects on workplace dynamics, task allocation, and human-system interaction.IT professionals, noted as early adopters of AI, offer valuable insights into the interplay between AI and work engagement, highlighting the significant competencies required for digital workplaces. This study employs a dual-method approach, combining a systematic and multi-vocal literature review and qualitative research methods. These included a thematic analysis of a set of 47 interviews conducted between March and May of 2024 with IT professionals in two countries (New Zealand and Sweden). The research aimed to understand the implications for computing students, education curricula, and the assessment of emerging professional competencies.The literature review found insufficient evidence addressing comprehensive AI practice methodologies, highlighting the need to both develop and regulate professional competencies for effective AI integration. Key interview findings revealed diverse levels of GenAI adoption, ranging from individual experimentation to institutional integration. Participants generally expressed positive attitudes toward the technology and were actively pursuing self-learning despite some concerns. The themes emerging from the interviews included AI's role in augmenting human tasks, privacy and security concerns, productivity enhancements, legal and ethical challenges, and the evolving need for new competencies in the workplace.The study underscores the critical role of competency frameworks in guiding professional development and ensuring preparedness for an AI-driven environment. Additionally, it highlights the need for educational institutions to adapt curricula to address these emerging demands effectively},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {34–67},
numpages = {34},
keywords = {artificial intelligence, computing competencies, computing curricula, generative ai, it profession, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649165.3690100,
author = {MacNeil, Stephen and Rogalska, Magdalena and Leinonen, Juho and Denny, Paul and Hellas, Arto and Crosland, Xandria},
title = {Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690100},
doi = {10.1145/3649165.3690100},
abstract = {Large language models (LLMs) present an exciting opportunity for generating synthetic classroom data. Such data could include code containing a typical distribution of errors, simulated student behavior to address the cold start problem when developing education tools, and synthetic user data when access to authentic data is restricted due to privacy reasons. In this research paper, we conduct a comparative study examining the distribution of bugs generated by LLMs in contrast to those produced by computing students. Leveraging data from two previous large-scale analyses of student-generated bugs, we investigate whether LLMs can be coaxed to exhibit bug patterns that are similar to authentic student bugs when prompted to inject errors into code. The results suggest that unguided, LLMs do not generate plausible error distributions, and many of the generated errors are unlikely to be generated by real students. However, with guidance including descriptions of common errors and typical frequencies, LLMs can be shepherded to generate realistic distributions of errors in synthetic code.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {137–143},
numpages = {7},
keywords = {buggy code, generative ai, gpt-4, llms, synthetic data},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3589335.3641306,
author = {Mao, Haitao and Zhao, Jianan and He, Xiaoxin and Chen, Zhikai and Huang, Qian and Zhu, Zhaocheng and Tang, Jian and Bronstein, Micheal and Bresson, Xavier and Hooi, Bryan and Zhang, Haiyang and Tang, Xianfeng and Chen, Luo and Tang, Jiliang},
title = {The 1st International Workshop on Graph Foundation Models (GFM)},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641306},
doi = {10.1145/3589335.3641306},
abstract = {Foundation models such as GPT-4 for natural language processing (NLP), Flamingo for computer vision (CV), have set new benchmarks in AI by delivering state-of-the-art results across various tasks with minimal task-specific data. Despite their success, the application of these models to the graph domain is challenging due to the relational nature of graph-structured data. To address this gap, we propose the Graph Foundation Model (GFM) Workshop, the first workshop for GFMs, dedicated to exploring the adaptation and development of foundation models specifically designed for graph data. The GFM workshop focuses on two critical questions: (1) How can the underlying capabilities of existing foundation models be effectively applied to graph data? (2) What foundational principles should guide the creation of models tailored to the graph domain? Through a curated set of panel sections, keynote talks, and paper presentations, our workshop intends to catalyze innovative approaches and theoretical frameworks for Graph Foundation Models (GFMs). We target a broad audience, encompassing researchers, practitioners, and students, and aim to lay the groundwork for the next wave of breakthroughs in integrating graph data with foundation models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1789–1792},
numpages = {4},
keywords = {data mining, foundation model, graph machine learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3641555.3705178,
author = {Eikmeier, Nicole and Perlmutter, Leah},
title = {Experiences Teaching A Course On Algorithms, Ethics, and Society},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705178},
doi = {10.1145/3641555.3705178},
abstract = {It is essential for CS students to graduate with competence about ethics and societal impacts of technology. We designed and taught a new reading discussion course, at Grinnell College, Algorithms, Ethics, and Society, for advanced undergraduate students who have completed CS1 and CS2. Course topics included Identity in Computing, Tech Ethics, Algorithms Informing Policies, Large Language Models, Networks and Social Media, Health Applications, and Robotics. We encountered some challenges with the discussion format, which we addressed by upholding class norms, employing discussion techniques learned from humanities and social science colleagues, and being open to learn from our mistakes.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1449–1450},
numpages = {2},
keywords = {computer science education, computing and society, technology ethics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3729857.3729874,
author = {Bandi, Ajay and Blackford, Benjamin and Fellah, Aziz and Linville, Diana and Meyer, Trevor C. and Voss, Robert J.},
title = {Prompting Collaboration: Development of an Multidisciplinary Applied AI Minor Program},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {6},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has rapidly transformed industries and research, becoming a driving force for technological innovation and development [1]. As AI continues to grow and change, it is reshaping the way we approach problem-solving, decision-making, and creative processes across various sectors. Northwest Missouri State University is developing a new multidisciplinary AI minor open to all undergraduate students on campus. The program is tailored for students from any discipline who want to explore how AI can be utilized and integrated into their fields such as computer science, humanities, business, sciences, healthcare, agriculture, and education, among others. The curriculum integrates topics such as foundational AI concepts, prompt engineering and writing processes, ethical considerations in AI, AI in the workplace, and a capstone project. This program also promotes interdisciplinary collaboration and emphasizes the ethical use of AI.By the end of the program, students will be able to use AI to enhance efficiency and accuracy in tasks, develop and evaluate effective prompts, apply generative AI tools across various input formats, and assess the ethical considerations of AI in real-world applications. The panel members are experts from diverse fields, including management, humanities, technical writing, and computer science. The panel discusses the development of the AI minor curriculum and explores opportunities to extend the AI curriculum by offering AI certificates for undergraduate and graduate online professional students. By attending this panel, the audience will gain valuable insights into developing comprehensive AI programs, fostering cross-disciplinary innovation, and preparing students to use AI ethically and effectively across diverse fields.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {129–132},
numpages = {4}
}

@inproceedings{10.1145/3678610.3678631,
author = {Robledo-Rella, V\'{\i}ctor and Toh, Bee-Yen},
title = {Artificial Intelligence in Physics Courses to Support Active Learning},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678610.3678631},
doi = {10.1145/3678610.3678631},
abstract = {The integration of generative artificial intelligence (AI), particularly Large Language Models (LLMs) like OpenAI's ChatGPT and Microsoft's Copilot, is transforming educational methodologies, including undergraduate physics courses for engineering students. Despite their potential, these LLMs typically rely on statistical learning methods and often exhibit algebraic inaccuracies in solving standard university-level physics problems. This study explores the use of LLMs in physics courses for N = 91 freshman engineering students over two academic terms (Spring and Fall 2023). Students engaged in AI-assisted activities to solve physics problems and were asked to identify and correct the errors made by the chatbot. The outcomes were compared with those from traditional teaching methods without AI involvement, and no significant difference in student learning gains was found. To assess the impact of AI tools in education, a more detailed approach using pre-test and post-test instruments&nbsp;with control and experimental groups is necessary. Survey results revealed, however, that AI-assisted sessions enhanced student engagement, problem-solving skills, and understanding of physics concepts. Students also indicated a strong preference for AI-assisted activities, citing increased motivation and a firm belief in the educational benefits of using these tools. Our findings suggest that well-designed AI interventions can effectively complement traditional instructional methods, especially when the LLMs are integrated with symbolic computational tools like WolframAlpha to improve their accuracy.},
booktitle = {Proceedings of the 2024 10th International Conference on E-Society, e-Learning and e-Technologies (ICSLT)},
pages = {68–75},
numpages = {8},
keywords = {ChatGPT, Copilot, Educational Innovation, Generative AI, Higher Education, Interactive Learning, Physics Education Research},
location = {
},
series = {ICSLT '24}
}

@inproceedings{10.1145/3545945.3569770,
author = {Leinonen, Juho and Hellas, Arto and Sarsa, Sami and Reeves, Brent and Denny, Paul and Prather, James and Becker, Brett A.},
title = {Using Large Language Models to Enhance Programming Error Messages},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569770},
doi = {10.1145/3545945.3569770},
abstract = {A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {563–569},
numpages = {7},
keywords = {ai, codex, compiler error messages, large language models, programming error messages, syntax error messages},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3641555.3705187,
author = {O'Neill, Abby and Smith, Samantha and Durai, Aneesh and DeNero, John and Zamfirescu-Pereira, J.D. and Norouzi, Narges},
title = {From Code to Concepts: Textbook-Driven Knowledge Tracing with LLMs in CS1},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705187},
doi = {10.1145/3641555.3705187},
abstract = {Gauging a student's understanding of course concepts, at an arbitrary point during a course, can be challenging. Standardized exams offer only a snapshot of performance rather than a deep understanding of progress. However, with Large Language Models (LLMs) now deployed at scale in CS1 courses, we can track multiple attempts from each student for every homework problem. This data provides insights into how students learn and deploy concepts over time, presenting a unique opportunity to rethink how we track changes in individual student knowledge. Traditional Knowledge Tracing (KT) methods often lack explainability and are computationally expensive. In contrast, our framework leverages an LLM to identify student progress on labeled, problem-level concepts from a student homework code submission. Our initial results show that the student's knowledge state can be dynamically updated. This knowledge state can then be used to provide more targeted, effective feedback and create tailored study materials.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1565–1566},
numpages = {2},
keywords = {artificial intelligence/machine learning, cs1/cs2, instructional technologies, programming, tools and tool use},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649217.3653570,
author = {Frazier, Matthew and Damevski, Kostadin and Pollock, Lori},
title = {Customizing ChatGPT to Help Computer Science Principles Students Learn Through Conversation},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653570},
doi = {10.1145/3649217.3653570},
abstract = {This paper explores leveraging conversational agents, specifically ChatGPT, to enhance the introduction of computing, focused on the Advanced Placement Computer Science Principles (CSP) course in secondary schools. Despite the potential benefits for diverse student audiences, little research has investigated their effectiveness and engagement in this context. We examine the customization of ChatGPT for secondary school CSP students, assessing its impact on exploratory searches for learning CSP concepts. Results from 20 high school students in grades 10-12 (ages 15-18) in a CSP course indicate that students preferred a customized ChatGPT, with its terminology more suitable to secondary school level, examples more understandable, and better connections to personal experiences compared to standard ChatGPT.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {633–639},
numpages = {7},
keywords = {chatgpt, computer science principles, conversational agent, exploratory search},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649409.3691093,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui},
title = {Code Metrics, Rules of Thumb for Introductory CS},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691093},
doi = {10.1145/3649409.3691093},
abstract = {In response to the recent surge in easily accessible generative AI, Harvey Mudd College has integrated AI-assisted coding into the introductory Computer Science course. In this context, a question arises: How do we measure the quality of students' code when AI-generated code is present?Allowing generative AI to write coding assignments comes with the expectation of improved efficiency and accuracy. While generative AI is a useful tool, it merely supplements fundamental computing skills. This technological step towards being fully syntax-free allows for emphasis on the already important skill of developing problem-solving and critical thinking skills in more abstract contexts. In past years, metrics were designed to measure quantitative aspects of code, but these metrics alone are insufficient when evaluating how code written with the assistance of AI will perform in broader applications. When students submit code written with the assistance of generative AI, they are still expected to meet standards given by past metrics, such as Correctness and Complexity. To establish foundational computing skills, students will also be held to new standards and evaluated by new metrics such as Individuality and Ambition.While the model does give objective measures of the metrics, due to the fast-evolving nature of programming, predefined rules-of-thumb for these metrics are not provided. As users of our system, we recognize that evaluating the measurements will require our judgment, which will evolve over time. This work offers the foundation for that evolution.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {314–315},
numpages = {2},
keywords = {computing as a general education requirement, computing as a shared literacy, generative AI, undergraduate-universal computing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3649165.3690099,
author = {Pang, Amy and Padiyath, Aadarsh and Viramontes Vargas, Diego and Ericson, Barbara Jane},
title = {Examining the Relationship between Socioeconomic Status and Beliefs about Large Language Models in an Undergraduate Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690099},
doi = {10.1145/3649165.3690099},
abstract = {Research on students' use of large language models (LLMs) in academic settings has increased recently, focusing on usage patterns, tasks, and instructor policies. However, there is limited research on the relationships between students' socioeconomic backgrounds, perceptions, and usage of these resources. As socioeconomic factors may shape students' approach to learning, it is important to understand their impact on students' perceptions and attitudes towards emerging technologies like LLMs. Thus, we analyzed a quantitative and internally consistent student survey (N=144) and qualitative interview (N=2) responses of students taking an undergraduate-level programming course at a public university for correlations between socioeconomic background, attitudes towards LLMs, and LLM usage. Regression analysis found a significant positive association between socioeconomic status (SES) and belief that LLM use will lead to career success. Qualitative interviews suggested low-SES students perceived LLMs as helpful tools for debugging and learning concepts, but not as a significant factor in long-term career success. Rather, programming knowledge itself was still paramount for career success. Our findings contribute to our understanding of the complex influences social and cultural factors have on students' perceptions and attitudes towards LLMs.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {172–178},
numpages = {7},
keywords = {large language models, socioeconomic status, student attitudes},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.5555/3665464.3665467,
author = {Hsin, Wen-Jung},
title = {The Effect of ChatGPT: Student Perspective and Performance Achievement},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {ChatGPT, introduced in November 2022, has rapidly used in various educational systems, prompting the U.S. Department of Education to explore the role of Artificial Intelligence (AI) in teaching and learning. This paper focuses on the impact of AI, particularly ChatGPT, in Computer Science education from the student's perspective and student's performance achievement. Specifically, a study in a Computer Networking course encouraged students to use ChatGPT for learning-related questions, followed by a post-exam survey to evaluate its impact on their learning. Both student feedback and performance achievement indicate that ChatGPT has made a positive impact in their learning in the Computer Networking course.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {20–29},
numpages = {10}
}

@inproceedings{10.1145/3672608.3707732,
author = {Raimondi, Bianca and Giallorenzo, Saverio and Gabbrielli, Maurizio},
title = {Affordably Fine-tuned LLMs Provide Better Answers to Course-specific MCQs},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707732},
doi = {10.1145/3672608.3707732},
abstract = {In education, the capability of generating human-like text of Large Language Models (LLMs) inspired work on how they can increase the efficiency of learning and teaching. We study the affordability of these models for educators and students by investigating how LLMs answer multiple-choice questions (MCQs) with respect to hardware constraints and refinement techniques. We explore this space by using generic pre-trained LLMs (the 7B, 13B, and 70B variants of LLaMA-2) to answer 162 undergraduate-level MCQs from a course on Programming Languages (PL)—the MCQ dataset is a contribution of this work, which we make publicly available. Specifically, we dissect how different factors, such as using readily-available material—(parts of) the course's textbook—for fine-tuning and quantisation (to decrease resource usage) can change the accuracy of the responses. The main takeaway is that smaller textbook-based fine-tuned models outperform generic larger ones (whose pre-training requires conspicuous resources), making the usage of LLMs for answering MCQs resource- and material-wise affordable.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {32–39},
numpages = {8},
keywords = {education, large language models, multiple-choice questions, fine-tuning, quantisation},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3641554.3701972,
author = {Ahmed, Umair Z. and Sahai, Shubham and Leong, Ben and Karkare, Amey},
title = {Feasibility Study of Augmenting Teaching Assistants with AI for CS1 Programming Feedback},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701972},
doi = {10.1145/3641554.3701972},
abstract = {With the increasing adoption of Large Language Models (LLMs), there are proposals to replace human Teaching Assistants (TAs) with LLM-based AI agents for providing feedback to students. In this paper, we explore a new hybrid model where human TAs receive AI-generated feedback for CS1 programming exercises, which they can then review and modify as needed. We conducted a large-scale randomized intervention with 185 CS1 undergraduate students, comparing the efficacy of this hybrid approach against manual feedback and direct AI-generated feedback.Our initial hypothesis predicted that AI-augmented feedback would improve TA efficiency and increase the accuracy of guidance to students. However, our findings revealed mixed results. Although students perceived improvements in feedback quality, the hybrid model did not consistently translate to better student performance. We also observed complacency among some TAs who over-relied on LLM generated feedback and failed to identify and correct inaccuracies. These results suggest that augmenting human tutors with AI may not always result in improved teaching outcomes, and further research is needed to ensure it is truly effective.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {11–17},
numpages = {7},
keywords = {cs1, gpt, hint, llm, programming, randomized trial, ta},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649217.3653533,
author = {Bernstein, Seth and Denny, Paul and Leinonen, Juho and Kan, Lauren and Hellas, Arto and Littlefield, Matt and Sarsa, Sami and Macneil, Stephen},
title = {"Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students Using Large Language Models},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653533},
doi = {10.1145/3649217.3653533},
abstract = {Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies produced with student-prescribed topics, in contrast to the otherwise generic analogies, highlighting the value of student creativity when working with LLMs. Not only did students enjoy the activity and report an improved understanding of recursion, but they described more easily remembering analogies that were personally and culturally relevant.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {122–128},
numpages = {7},
keywords = {analogies, computing education, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@article{10.5555/3737313.3737332,
author = {Chamberlain, Devin and Levine, David B. and Pitcairn, Abigail and Snow, Nicholas and Sweeney, Benjamin},
title = {Large Language Models and Introductory Lab Exercises: Susceptibility, Resistance, and Potential},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {8},
issn = {1937-4771},
abstract = {Three student personas were created, each representing a way in which current students interact with AI tools such as ChatGPT when completing introductory computer science assignments. Four undergraduate students assumed the role of each of the personas in turn and two semesters worth of current assignments were completed in each persona. The results and experiences were then analyzed to determine aspects of the assignments that made it more (or less) difficult to complete them using the AI tools, with an eye towards whether small changes in phrasing or requirements might result in significant changes in this metric.Three of the main takeaways were that LLMs are more difficult for students to use when assignments 1) consist of many small steps, 2) make use of external code libraries, or 3) involve spatial reasoning.Finally, the student/persona experiences helped to generate a list of opportunities for instructors to proactively include the use of AI tools in current assignments without sacrificing any of the current learning objectives.The initial phase involved labs from one institution and used only one AI tool, but follow-up work involving the use of other tools and labs from other institutions validated those core conclusions. A student survey (as well as other published literature) also validated the choice of personas.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {49–63},
numpages = {15}
}

@inproceedings{10.1145/3649217.3653587,
author = {Denny, Paul and Smith, David H. and Fowler, Max and Prather, James and Becker, Brett A. and Leinonen, Juho},
title = {Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653587},
doi = {10.1145/3649217.3653587},
abstract = {Reading, understanding and explaining code have traditionally been important skills for novices learning programming. As large language models (LLMs) become prevalent, these foundational skills are more important than ever given the increasing need to understand and evaluate model-generated code. Brand new skills are also needed, such as the ability to formulate clear prompts that can elicit intended code from an LLM. Thus, there is great interest in integrating pedagogical approaches for the development of both traditional coding competencies and the novel skills required to interact with LLMs. One effective way to develop and assess code comprehension ability is with "Explain in plain English'' (EiPE) questions, where students succinctly explain the purpose of a fragment of code. However, grading EiPE questions has always been difficult given the subjective nature of evaluating written explanations and this has stifled their uptake. In this paper, we explore a natural synergy between EiPE questions and code-generating LLMs to overcome this limitation. We propose using an LLM to generate code based on students' responses to EiPE questions -- not only enabling EiPE responses to be assessed automatically, but helping students develop essential code comprehension and prompt crafting skills in parallel. We investigate this idea in an introductory programming course and report student success in creating effective prompts for solving EiPE questions. We also examine student perceptions of this activity and how it influences their views on the use of LLMs for aiding and assessing learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {283–289},
numpages = {7},
keywords = {code comprehension, cs1, eipe, explain in plan english, introductory programming, large language models, llms, prompting},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3636243.3636247,
author = {Hou, Irene and Man, Owen and Mettille, Sophia and Gutierrez, Sebastian and Angelikas, Kenneth and MacNeil, Stephen},
title = {More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636247},
doi = {10.1145/3636243.3636247},
abstract = {Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {29–38},
numpages = {10},
keywords = {Bard, ChatGPT, GPT-4V, Generative AI, LLMs, Parsons Problems, computing education, visual programming problems},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3706599.3720240,
author = {Shochcho, Muhtasim Ibteda and Rahman, Mohammad Ashfaq Ur and Rohan, Shadman and Islam, Ashraful and Heickal, Hasnain and Rahman, AKM Mahbubur and Amin, M. Ashraful and Ali, Amin Ahsan},
title = {Improving User Engagement and Learning Outcomes in LLM-Based Python Tutor: A Study of PACE},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720240},
doi = {10.1145/3706599.3720240},
abstract = {Large Language Models (LLMs) are increasingly being adopted for educational applications, but sometimes, limited internet access and budget constraints restrict their accessibility. Small Language Models (SLMs) have emerged as viable alternatives, capable of providing effective tutoring in resource-constrained contexts. This paper introduces PACE (Python AI Companion for Enhanced Engagement), a system leveraging SLMs to deliver step-by-step guidance and adaptive feedback for teaching Python. An evaluation with varying levels of learners showed PACE’s effectiveness, achieving a System Usability Scale (SUS) score of 77.28. While participants were generally satisfied with its clarity and personalized feedback, they identified some areas for improvement, such as loss of context during lengthy conversations. This study examines (1) the PACE system’s effectiveness in programming education according to learners, (2) learners’ trust in PACE versus traditional resources, and (3) design recommendations to enhance engagement and learning outcomes. PACE contributes to advancing cost-effective, scalable programming education.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {337},
numpages = {12},
keywords = {LLM, SLM, PACE, Python, Tutor, Learning, Tutoring, Education},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3702212.3702214,
author = {Clift, Lee and Petrovska, Olga},
title = {Learning without Limits: Analysing the Usage of Generative AI in a Summative Assessment},
year = {2025},
isbn = {9798400711725},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702212.3702214},
doi = {10.1145/3702212.3702214},
abstract = {This paper explores how Generative AI (GenAI) can be introduced within summative assessment components in software engineering education. We present an example of an assessment which allows learners to use GenAI in a freeform, constructionist manner, as part of a large, software development project. This work is inspired by previously executed AI-focused assessments and surveys, which explicitly indicate that learners on an Applied Software Engineering Degree Apprenticeship Programme want to formally learn how to use GenAI tools when programming and their employers want to see these skills from graduates. The learning outcome of the assignment was for learners to explore a typical developmental pipeline as a solo developer, moving from design to development to finished product. Learners were marked exclusively on their end product and understanding of application components, not the written code itself, resulting in an assessment where the end product and project were prioritised over foundational code (which was adequately assessed in other components). The results show that all learners used GenAI to some extent during their project, and in all cases, they found it beneficial for large programming tasks. Learners were generally able to produce a larger, more comprehensive and more ambitious project, compared to previous years. It is proposed that removing the barrier to GenAI - and demystifying it - can encourage a constructionist approach to its use, and normalise it as a potential tool for programming.},
booktitle = {Proceedings of the 9th Conference on Computing Education Practice},
pages = {5–8},
numpages = {4},
keywords = {GenAI, software engineering, education, apprenticeship},
location = {
},
series = {CEP '25}
}

@inproceedings{10.1145/3641555.3705281,
author = {Li, Carol and Park, Su Min and Tsang, Jedidiah and Yan, Lisa},
title = {What Gets Them Talking? Identifying Catalysts for Student Engagement Within a Computing Ethics Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705281},
doi = {10.1145/3641555.3705281},
abstract = {The expansion of undergraduate CS programs brings different forms of student identity, sociotechnical perspectives, and intersectionality into the classroom. These background factors affect student understanding of the world, and, consequently, their work in computing ethic classes. Instructors of computing ethics courses therefore must facilitate topics that are not only pertinent to modern technologies but that are also interesting for students from a range of backgrounds. In this work, we introduce a low-overhead, natural language processing tool that can assist instructors in extracting student talking points from over 600 discussion forum posts in a large-scale undergraduate computing ethics course. When compared to large language model approaches, this n-gram-based scripting tool is more effective in selecting popular quotes and summarizing course discussion. This tool is simple in implementation and can be easily adapted by instructors to prepare for classroom discussion.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1521–1522},
numpages = {2},
keywords = {computing ethics, llm-based tool, n-gram-based tool, open pedagogy, student engagement},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3586182.3615817,
author = {Du, Ruofei and Li, Na and Jin, Jing and Carney, Michelle and Yuan, Xiuxiu and Wright, Kristen and Sherwood, Mark and Mayes, Jason and Chen, Lin and Jiang, Jun and Zhou, Jingtao and Zhou, Zhongyi and Yu, Ping and Kowdle, Adarsh and Iyengar, Ram and Olwal, Alex},
title = {Experiencing Visual Blocks for ML: Visual Prototyping of AI Pipelines},
year = {2023},
isbn = {9798400700965},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586182.3615817},
doi = {10.1145/3586182.3615817},
abstract = {We demonstrate Visual Blocks for ML, a visual programming platform that facilitates rapid prototyping of ML-based multimedia applications. As the public version of Rapsai&nbsp;[3], we further integrated large language models and custom APIs into the platform. In this demonstration, we will showcase how to build interactive AI pipelines in a few drag-and-drops, how to perform interactive data augmentation, and how to integrate pipelines into Colabs. In addition, we demonstrate a wide range of community-contributed pipelines in Visual Blocks for ML, covering various aspects including interactive graphics, chains of large language models, computer vision, and multi-modal applications. Finally, we encourage students, designers, and ML practitioners to contribute ML pipelines through https://github.com/google/visualblocks/tree/main/pipelines to inspire creative use cases. Visual Blocks for ML is available at http://visualblocks.withgoogle.com.},
booktitle = {Adjunct Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
articleno = {76},
numpages = {3},
keywords = {data augmentation, deep learning, deep neural networks, large language models, multi-modal models, node-graph editor, visual analytics, visual programming, visual prototyping},
location = {San Francisco, CA, USA},
series = {UIST '23 Adjunct}
}

@inproceedings{10.1145/3701625.3701681,
author = {Menolli, Andr\'{e} and Strik, Bruno and Rodrigues, Luiz},
title = {Teaching Refactoring to Improve Code Quality with ChatGPT: An Experience Report in Undergraduate Lessons},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701681},
doi = {10.1145/3701625.3701681},
abstract = {Refactoring presents a complex computational challenge, and its learning is intricate, requiring a solid foundation in computational thinking, programming and object-oriented concepts. Moreover, making students realize the importance and benefits of refactoring is also challenging. To address this complexity, we introduce a refactoring teaching method based on Generative Artificial Intelligence (GAI), incorporating single-loop and double-loop learning principles, focusing on fostering deeper and critical learning. We used ChatGPT, a GAI-based tool, and conducted an eight-week mixed-methods study involving 23 computer science undergraduate students. The study involved applying four distinct projects extracted from GitHub, where participants were tasked with identifying code smells and performing the necessary refactoring to improve code quality. The primary focus was on identifying both the positive and negative aspects of the method, as well as delineating the computational thinking characteristics developed during the process. The results indicate that the use of ChatGPT facilitated the learning of refactoring, contributing to the development of numerous computational thinking skills, especially problem formulation, decomposition, and abstraction. Thus, this paper contributes a GAI-based teaching method along with evidence on how it helps students develop refactoring skills.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {563–574},
numpages = {12},
keywords = {Generative Artificial Intelligence, ChatGPT, Refactory, Higher Education, Teaching, Computational Thinking},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3649409.3691076,
author = {Wiese, Eliane S. and Finnie-Ansley, James and Duran, Rodrigo and Cunningham, Kathryn and Demirtas, Mehmet Arif},
title = {Challenges and Solutions for Teaching Decomposition and Planning Skills in CS1},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691076},
doi = {10.1145/3649409.3691076},
abstract = {The task of decomposing a problem into sub-problems to build a solution, also formalized as planning in prior work, is a key skill for programming expertise. Improving the decomposition and planning skills of novices is shown to be a challenging goal for educators. Moreover, decomposing complex projects into smaller subtasks is an increasingly relevant skill with rapid developments in tools like large language models (LLMs). While there are many aspects of planning, one skill consistently observed in studies with experts is the ability to identify subtasks that can be solved via common code patterns. To support students in acquiring these skills, many researchers have explored explicit instruction about a set of common patterns in programs (i.e. programming plans). However, recent work implies that students may need additional support to fully benefit from such interventions. This panel aims to bring computing education researchers together to discuss the main challenges around teaching decomposition and planning using common patterns, the crucial factors for designing instruction for teaching these concepts, and the impact evolving technology like LLMs can have on these developments.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {291–292},
numpages = {2},
keywords = {cs1, decomposition, large language models, programming plans},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3641554.3701910,
author = {Gonzalez-Maldonado, David and Liu, Jonathan and Franklin, Diana},
title = {Evaluating GPT for use in K-12 Block Based CS Instruction Using a Transpiler and Prompt Engineering},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701910},
doi = {10.1145/3641554.3701910},
abstract = {Though the increased availability of Large Language Models (LLMs) presents significant potential for change in the way students learn to program, the text-based nature of the available tools currently preclude block-based languages from much of that innovation. In an attempt to remedy this, we identify the strengths and weaknesses of using a transpiler to leverage the existing learning in commercially available LLMs and Scratch, a visual block-based programming language.Using only prompt engineering, we evaluate an LLM's performance on two common classroom tasks in a Scratch curriculum. We evaluate the LLM's ability to: 1) Create project solutions that compile and satisfy project requirements and 2) Analyze student projects' completion of project requirements using natural language. In both cases, we find results indicating that prompt-engineering alone is insufficient to reliably produce high-quality results. For projects of medium complexity, the LLM-generated solutions consistently failed to follow correct syntax or, in the few instances with correct syntax, produce correct solutions. When used for auto-grading, we found a correlation between scores assigned by the official Scratch Encore autograder and those generated by the LLM, nevertheless the discrepancies between the 'real' scores and the scores assigned by the LLM remained too great for the tool to be reliable in a classroom setting.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {388–394},
numpages = {7},
keywords = {block based programming, generative ai, k-12, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641554.3701953,
author = {Deb, Debzani and Taylor, Greg and Betz, Scott and Maddux, Bao Anh T. and Ebert, C. Edward and Richardson, Flourice W. and Couto, Jeanine Lino S. and Jarrett, Michael S. and Madjd-Sadjadi, Zagros},
title = {Enhancing University Curricula with Integrated AI Ethics Education: A Comprehensive Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701953},
doi = {10.1145/3641554.3701953},
abstract = {As AI technologies become more prevalent, it is crucial for students to develop responsible, ethical, and proactive AI engagement skills. Recent educational initiatives have focused on enhancing CS and engineering students' AI ethics education but have largely overlooked integrating these concepts across other disciplines. This paper presents and assesses a pioneering initiative that integrates AI ethics into university curricula through a collaborative framework between CS and domain educators. We introduced 1-3 week AI ethics modules in seven diverse courses from Art to Chemistry, incorporating case studies and hands-on activities using chat- or image-based Large Language Models (LLMs). Student surveys indicated significant gains in confidence regarding AI ethics discussions, application of principles, and reasoning skills. Our approach advocates for utilizing structured frameworks and faculty collaboration in embedding AI ethics into university curricula, enhancing students' practical skills and ethical understanding across diverse professional settings.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {248–254},
numpages = {7},
keywords = {ai ethics, computing education, ethics education, inclusive computing curricula and pedagogy, non-majors},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3613904.3642229,
author = {Chen, Liuqing and Xiao, Shuhong and Chen, Yunnong and Song, Yaxuan and Wu, Ruoyu and Sun, Lingyun},
title = {ChatScratch: An AI-Augmented System Toward Autonomous Visual Programming Learning for Children Aged 6-12},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642229},
doi = {10.1145/3613904.3642229},
abstract = {As Computational Thinking (CT) continues to permeate younger age groups in K-12 education, established CT platforms such as Scratch face challenges in catering to these younger learners, particularly those in the elementary school (ages 6-12). Through formative investigation with Scratch experts, we uncover three key obstacles to children’s autonomous Scratch learning: artist’s block in project planning, bounded creativity in asset creation, and inadequate coding guidance during implementation. To address these barriers, we introduce ChatScratch, an AI-augmented system to facilitate autonomous programming learning for young children. ChatScratch employs structured interactive storyboards and visual cues to overcome artist’s block, integrates digital drawing and advanced image generation technologies to elevate creativity, and leverages Scratch-specialized Large Language Models (LLMs) for professional coding guidance. Our study shows that, compared to Scratch, ChatScratch efficiently fosters autonomous programming learning, and contributes to the creation of high-quality, personally meaningful Scratch projects for children.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {19},
keywords = {Children Aged 6-12, Computational Thinking, Large Language Model, Scratch},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3742939.3742941,
author = {Vardanega, T.},
title = {It Is Time to Care for Ada!},
year = {2025},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {44},
number = {2},
issn = {1094-3641},
url = {https://doi.org/10.1145/3742939.3742941},
doi = {10.1145/3742939.3742941},
abstract = {1 A rather strange introductionI confess, I am a voracious book reader, and being (luckily) versed in quite a few tongues, I enjoy reading books frequently (but not always) without needing translation. In fact, I find languages fascinating, for all they say about people's culture, history, and traits.As a student in Computer Science in the late 1980s, I was imbued with Noam Chomsky's linguistic ''generative grammar'' theory. That theory sees specific languages as second-order derivatives of a single universal grammar, innate in the human mind. That theory, with its hierarchy of formal grammars, has laid the foundation for the theory and practice of language compilers. The principal tenet of Chomsky's theory is that grammar precedes language.},
journal = {Ada Lett.},
month = jun,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3626253.3633407,
author = {Westerlund, Jill and Czajka, Sandra and Kuemmel, Andrew},
title = {Innovative Strategies for genAI in CS Courses},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633407},
doi = {10.1145/3626253.3633407},
abstract = {Students are using generative artificial intelligence (genAI), organizations are embracing AI and machine learning, tools are emerging almost daily, and addressing these evolving technologies can be overwhelming. Rather than choosing to ignore genAI, instructors of computer science (CS) can find ways to teach with and guide students in the use of genAI in their courses. Teaching about genAI can be incorporated with instruction about effective and appropriate uses of the ever-growing tools.This special session brings together three experienced CS educators who integrate genAI in their work with high school students, college students, and in-service teachers. The session environment allows for participant involvement in three model activities that showcase genAI tools with learner-focused practices. Participants will be provided supporting teaching resources for each guided activity and encouraged to discuss with peers and presenters.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1875–1876},
numpages = {2},
keywords = {ai, assessment, genai, instruction},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3540250.3569444,
author = {Gulwani, Sumit},
title = {AI-assisted programming: applications, user experiences, and neuro-symbolic techniques (keynote)},
year = {2022},
isbn = {9781450394130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3540250.3569444},
doi = {10.1145/3540250.3569444},
abstract = {AI can enhance programming experiences for a diverse set of programmers: from professional developers and data scientists (proficient programmers) who need help in software engineering and data wrangling, all the way to spreadsheet users (low-code programmers) who need help in authoring formulas, and students (novice programmers) who seek hints when stuck with their programming homework. To communicate their need to AI, users can express their intent explicitly—as input-output examples or natural-language specification—or implicitly—where they encounter a bug (and expect AI to suggest a fix), or simply allow AI to observe their last few lines of code or edits (to have it suggest the next steps).  

The task of synthesizing an intended program snippet from the user’s intent is both a search and a ranking problem. Search is required to discover candidate programs that correspond to the (often ambiguous) intent, and ranking is required to pick the best program from multiple plausible alternatives. This creates a fertile playground for combining symbolic-reasoning techniques, which model the semantics of programming operators, and machine-learning techniques, which can model human preferences in programming. Recent advances in large language models like Codex offer further promise to advance such neuro-symbolic techniques.  

Finally, a few critical requirements in AI-assisted programming are usability, precision, and trust; and they create opportunities for innovative user experiences and interactivity paradigms. In this talk, I will explain these concepts using some existing successes, including the Flash Fill feature in Excel, Data Connectors in PowerQuery, and IntelliCode/CoPilot in Visual Studio. I will also describe several new opportunities in AI-assisted programming, which can drive the next set of foundational neuro-symbolic advances.},
booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1},
numpages = {1},
keywords = {Symbolic Reasoning, Program Synthesis, Machine Learning, Interactive Programming},
location = {Singapore, Singapore},
series = {ESEC/FSE 2022}
}

@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3626253.3633433,
author = {Liu, Rongxin and Zenke, Carter and Lloyd, Doug and Malan, David J.},
title = {Teaching with AI (GPT)},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633433},
doi = {10.1145/3626253.3633433},
abstract = {Teaching computer science at scale can be challenging. From our experience in CS50, Harvard University's introductory course, we've seen firsthand the impactful role that generative artificial intelligence can play in education. Recognizing its potential and stakes, we integrated OpenAI's GPT into our own teaching methodology. The goal was to emulate a 1:1 teacher-to-student ratio, incorporating "pedagogical guardrails" to maintain instructional integrity. The result was a personalized, AI-powered bot in the form of a friendly rubber duck aimed at delivering instructional responses and troubleshooting without giving outright solutions. We plan to share our journey and offer insights into responsibly harnessing AI in educational settings. Participants will gain hands-on experience working with GPT through OpenAI's APIs, understanding and crafting prompts, answering questions using embedding-based search, and finally, building their own AI chatbot. Ultimately, we'll not only share lessons learned from our own approach but also equip educators hands-on with the knowledge and tools with which they, too, can implement these technologies in their unique teaching environments.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1902},
numpages = {1},
keywords = {ai, artificial intelligence, chatgpt, ethics, generative ai, gpt, programming, prompt, prompt engineering},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3631802.3631806,
author = {Kazemitabaar, Majeed and Hou, Xinying and Henley, Austin and Ericson, Barbara Jane and Weintrop, David and Grossman, Tovi},
title = {How Novices Use LLM-based Code Generators to Solve CS1 Coding Tasks in a Self-Paced Learning Environment},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631806},
doi = {10.1145/3631802.3631806},
abstract = {As Large Language Models (LLMs) gain in popularity, it is important to understand how novice programmers use them and the effect they have on learning to code. We present the results of a thematic analysis on a data set from 33 learners, aged 10-17, as they independently learned Python by working on 45 code-authoring tasks with access to an AI Code Generator based on OpenAI Codex. We explore several important questions related to how learners used LLM-based AI code generators, and provide an analysis of the properties of the written prompts and the resulting AI generated code. Specifically, we explore (A) the context in which learners use Codex, (B) what learners are asking from Codex in terms of syntax and logic, (C) properties of prompts written by learners in terms of relation to task description, language, clarity, and prompt crafting patterns, (D) properties of the AI-generated code in terms of correctness, complexity, and accuracy, and (E) how learners utilize AI-generated code in terms of placement, verification, and manual modifications. Furthermore, our analysis reveals four distinct coding approaches when writing code with an AI code generator: AI Single Prompt, where learners prompted Codex once to generate the entire solution to a task; AI Step-by-Step, where learners divided the problem into parts and used Codex to generate each part; Hybrid, where learners wrote some of the code themselves and used Codex to generate others; and Manual coding, where learners wrote the code themselves. Our findings reveal consistently positive trends between learners’ utilization of the Hybrid coding approach and their post-test evaluation scores, while showing consistent negative trends between the AI Single Prompt and the post-test evaluation scores. Furthermore, we offer insights into novice learners’ use of AI code generators in a self-paced learning environment, highlighting signs of over-reliance, self-regulation, and opportunities for enhancing AI-assisted learning tools.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {3},
numpages = {12},
keywords = {ChatGPT, Copilot, Introductory Programming, Large Language Models, OpenAI Codex, Self-paced Learning, Self-regulation},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3545947.3573353,
author = {Brusilovsky, Peter and Ericson, Barbara J. and Horstmann, Cay S. and Servin, Christian and Vahid, Frank and Zilles, Craig},
title = {Significant Trends in CS Educational Material: Current and Future},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3573353},
doi = {10.1145/3545947.3573353},
abstract = {To recognize the current and future trends and challenges in computer science education educational materials for the next decade, the authors of this work provide a conversation to voice the computer science community's experience and expertise on these trends. One of the biggest challenges for introductory computing courses in the next few years will be leveraging the new capabilities of Artificial Intelligent systems such as Open AI CodeX and GPT3 that can generate code from a textual description, explain code, and translate code between programming languages. These tools could drastically change how introductory programming is taught by allowing students to focus more on understanding code, modifying code, and testing code than on writing code. Learning content is increasingly shifting from paper textbooks to online learning systems, which include not just traditional text and figures, but increasingly use interactive items to provide students with better explanations and illustrations, extensive practice, and frequent immediate formative feedback, typically at a lower cognitive load than classical programming assignment. We will discuss challenges and opportunities for interoperability with publishing and learning management platforms. Another example is how guided-based instruments, such as peer team learning, open educational resources, or workbooks, are adaptive and hybrid according to students' needs.Feedback and point of view from the CS community will be considered as part of the curricular practices "Future of CS educational materials" document, featured in the new version of the CS2023: ACM/IEEE-CS/AAAI Computer Science Curricula.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1253},
numpages = {1},
keywords = {adaptive, animation, assessment, automation, computer science, educational materials, feedback, homework, learning, sharing, textbook, videos},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3641554.3701883,
author = {Haji Amin Shirazi, Shirin and Pang, Ashley and Knight, Allan and Salloum, Mariam and Vahid, Frank},
title = {Midterm Exam Outliers Efficiently Highlight Potential Cheaters on Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701883},
doi = {10.1145/3641554.3701883},
abstract = {The ubiquitous use of online tools, contractors and homework sites, has made plagiarism a concerning topic in computer science education. With the introduction of ChatGPT, it poses a threat now more than ever. Many cheating detection tools, such as similarity checkers and style anomaly checkers, help instructors decide whether a student has plagiarized. However, these are not scalable to large classes. Similarity tools can produce high rates of suspected cheating and thus ineffectively use an instructor's time in weeding out the actual cheating cases, especially in the early weeks of CS courses where programs can be small and student solutions can be very similar. We developed a new approach using outlier detection to filter inconsistent performers based on their lab scores throughout the course and their midterm exam scores. Instructors can then manually analyze a manageable amount of students even with large class sizes. We performed our experiment on two large course offerings of CS1 (a total of 177 students) using our algorithm and compared it to a manual analysis performed by an experienced CS1 instructor. The detection approach identified 11 students in the first offering (Winter 2019) and 12 students in the second offering (Spring 2023). With an average precision of 83%, our tool produces a list of concerning students with high precision. This significantly helps teachers efficiently allocate their time and pursue cheating early in the term in order to address and prevent further issues.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {437–442},
numpages = {6},
keywords = {academic integrity, cs1, plagiarism, programming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@inproceedings{10.1145/3649217.3653575,
author = {Smith, C. Estelle and Shiekh, Kylee and Cooreman, Hayden and Rahman, Sharfi and Zhu, Yifei and Siam, Md Kamrul and Ivanitskiy, Michael and Ahmed, Ahmed M. and Hallinan, Michael and Grisak, Alexander and Fierro, Gabe},
title = {Early Adoption of Generative Artificial Intelligence in Computing Education: Emergent Student Use Cases and Perspectives in 2023},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653575},
doi = {10.1145/3649217.3653575},
abstract = {Because of the rapid development and increasing public availability of Generative Artificial Intelligence (GenAI) models and tools, educational institutions and educators must immediately reckon with the impact of students using GenAI. There is limited prior research on computing students' use and perceptions of GenAI. In anticipation of future advances and evolutions of GenAI, we capture a snapshot of student attitudes towards and uses of yet emerging GenAI, in a period of time before university policies had reacted to these technologies. We surveyed all computer science majors in a small engineering-focused R1 university in order to: (1) capture a baseline assessment of how GenAI has been immediately adopted by aspiring computer scientists; (2) describe computing students' GenAI-related needs and concerns for their education and careers; and (3) discuss GenAI influences on CS pedagogy, curriculum, culture, and policy. We present an exploratory qualitative analysis of this data and discuss the impact of our findings on the emerging conversation around GenAI and education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {3–9},
numpages = {7},
keywords = {ai literacy, code generator, education, generative artificial intelligence, image generator, interactive tutoring, large language model, policy, student experience, survey},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3626253.3635609,
author = {Mitra, Chancharik and Miroyan, Mihran and Jain, Rishi and Kumud, Vedant and Ranade, Gireeja and Norouzi, Narges},
title = {Elevating Learning Experiences: Leveraging Large Language Models as Student-Facing Assistants in Discussion Forums},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635609},
doi = {10.1145/3626253.3635609},
abstract = {Recent advancements in instruction-tuned large language models offer new potential for enhancing students' experiences in large-scale classes. Deploying LLMs as student-facing assistants, however, presents challenges. Key issues include integrating class-specific content into responses and applying effective pedagogical techniques. This study addresses these challenges through retrieval and prompting techniques, focusing on mitigating hallucinations in LLM-generated responses, a crucial concern in education. Furthermore, practical deployment brings further challenges related to student data privacy and computational constraints. This research strives to enhance the quality and relevance of LLM responses while addressing practical deployment issues, with an emphasis on creating a versatile system for diverse domains and teaching styles.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1752–1753},
numpages = {2},
keywords = {discussion forum, educational tools, natural language processing},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636243.3636259,
author = {Roest, Lianne and Keuning, Hieke and Jeuring, Johan},
title = {Next-Step Hint Generation for Introductory Programming Using Large Language Models},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636259},
doi = {10.1145/3636243.3636259},
abstract = {Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student’s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {Generative AI, Large Language Models, Next-step hints, automated feedback, learning programming},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3649217.3653624,
author = {Grande, Virginia and Kiesler, Natalie and Francisco R., Mar\'{\i}a Andre\'{\i}na},
title = {Student Perspectives on Using a Large Language Model (LLM) for an Assignment on Professional Ethics},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653624},
doi = {10.1145/3649217.3653624},
abstract = {The advent of Large Language Models (LLMs) started a serious discussion among educators on how LLMs would affect, e.g., curricula, assessments, and students' competencies. Generative AI and LLMs also raised ethical questions and concerns for computing educators and professionals.This experience report presents an assignment within a course on professional competencies, including some related to ethics, that computing master's students need in their careers. For the assignment, student groups discussed the ethical process by Lennerfors et al. by analyzing a case: a fictional researcher considers whether to attend the real CHI 2024 conference in Hawaii. The tasks were (1) to participate in in-class discussions on the case, (2) to use an LLM of their choice as a discussion partner for said case, and (3) to document both discussions, reflecting on their use of the LLM.Students reported positive experiences with the LLM as a way to increase their knowledge and understanding, although some identified limitations. The LLM provided a wider set of options for action in the studied case, including unfeasible ones. The LLM would not select a course of action, so students had to choose themselves, which they saw as coherent.From the educators' perspective, there is a need for more instruction for students using LLMs: some students did not perceive the tools as such but rather as an authoritative knowledge base. Therefore, this work has implications for educators considering the use of LLMs as discussion partners or tools to practice critical thinking, especially in computing ethics education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {478–484},
numpages = {7},
keywords = {chatgpt, ethics, experience report, large language models, llms, student perspective},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3649217.3653568,
author = {del Carpio Gutierrez, Andre and Denny, Paul and Luxton-Reilly, Andrew},
title = {Automating Personalized Parsons Problems with Customized Contexts and Concepts},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653568},
doi = {10.1145/3649217.3653568},
abstract = {Parsons problems provide useful scaffolding for introductory programming students learning to write code. However, generating large numbers of high-quality Parsons problems that appeal to the diverse range of interests in a typical introductory course is a significant challenge for educators. Large language models (LLMs) may offer a solution, by allowing students to produce on-demand Parsons problems for topics covering the breadth of the introductory programming curriculum, and targeting thematic contexts that align with their personal interests. In this paper, we introduce PuzzleMakerPy, an educational tool that uses an LLM to generate unlimited contextualized drag-and-drop programming exercises in the form of Parsons Problems, which introductory programmers can use as a supplemental learning resource. We evaluated PuzzleMakerPy by deploying it in a large introductory programming course, and found that the ability to personalize the contextual framing used in problem descriptions was highly engaging for students, and being able to customize the programming topics was reported as being useful for their learning.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {688–694},
numpages = {7},
keywords = {cs education tools, cs1, large language models, parsons problems, personalized learning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3511861.3511863,
author = {Finnie-Ansley, James and Denny, Paul and Becker, Brett A. and Luxton-Reilly, Andrew and Prather, James},
title = {The Robots Are Coming: Exploring the Implications of OpenAI Codex on Introductory Programming},
year = {2022},
isbn = {9781450396431},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511861.3511863},
doi = {10.1145/3511861.3511863},
abstract = {Recent advances in artificial intelligence have been driven by an exponential growth in digitised data. Natural language processing, in particular, has been transformed by machine learning models such as OpenAI’s GPT-3 which generates human-like text so realistic that its developers have warned of the dangers of its misuse. In recent months OpenAI released Codex, a new deep learning model trained on Python code from more than 50 million GitHub repositories. Provided with a natural language description of a programming problem as input, Codex generates solution code as output. It can also explain (in English) input code, translate code between programming languages, and more. In this work, we explore how Codex performs on typical introductory programming problems. We report its performance on real questions taken from introductory programming exams and compare it to results from students who took these same exams under normal conditions, demonstrating that Codex outscores most students. We then explore how Codex handles subtle variations in problem wording using several published variants of the well-known “Rainfall Problem” along with one unpublished variant we have used in our teaching. We find the model passes many test cases for all variants. We also explore how much variation there is in the Codex generated solutions, observing that an identical input prompt frequently leads to very different solutions in terms of algorithmic approach and code length. Finally, we discuss the implications that such technology will have for computing education as it continues to evolve, including both challenges and opportunities.},
booktitle = {Proceedings of the 24th Australasian Computing Education Conference},
pages = {10–19},
numpages = {10},
keywords = {novice programming, neural networks, machine learning, introductory programming, deep learning, copilot, code writing, code generation, artificial intelligence, academic integrity, OpenAI, GitHub, GPT-3, Codex, CS1, AI},
location = {Virtual Event, Australia},
series = {ACE '22}
}

@inproceedings{10.1145/3686852.3687073,
author = {Servin, Christian and Karichev, Nadia V. and Pagel, Myshie},
title = {Unfolding Programming: How to Use AI Tools in Introductory Computing Courses},
year = {2024},
isbn = {9798400711060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686852.3687073},
doi = {10.1145/3686852.3687073},
abstract = {Artificial Intelligence (AI) generative tools, commonly referred to as AI-based tools, have become integral in various computing domains, including education. The widespread adoption of these tools has raised concerns among educators, spanning from issues related to plagiarism and comprehension gaps to potential threats to student identity. Consequently, educators are grappling with how to adapt their courses and incorporate AI technologies into their curriculum and pedagogical approaches. In addition to navigating challenges associated with AI regulations, educators face the compounded difficulty of addressing post-pandemic issues, such as students displaying diminished effort and professionalism in the classroom. The convergence of these two challenges creates a complex scenario that intertwines technical and professional considerations. Within the Computer Science Fundamentals course, commonly referred to as CS 1, the learning process revolves around comprehending programming through a sequential understanding of steps, as each concept builds upon the preceding one. This investigation centers on the CS 1 curriculum within an American two-year program, commonly known as a community college. The objective is to address a problem by leveraging an AI tool within team settings. The study assesses both problem-solving capabilities and the effectiveness of teamwork, providing recommendations to guide students in the proper utilization of AI tools. The emphasis is on fostering contextual relevance and collaborative work within the generative learning process.},
booktitle = {Proceedings of the 25th Annual Conference on Information Technology Education},
pages = {49–55},
numpages = {7},
keywords = {ai-tools, community colleges, prompt programming, two-year},
location = {El Paso, TX, USA},
series = {SIGITE '24}
}

@inproceedings{10.1145/3641554.3701810,
author = {Borela, Rodrigo and Liding, Zhixian and McDaniel, Melinda},
title = {Enhancing CS1 Education through Experiential Learning with Robotics Projects},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701810},
doi = {10.1145/3641554.3701810},
abstract = {To address the challenges of generative AI in CS1 education, especially its misuse by students to bypass coding exercises, which undermines their engagement with foundational learning, CS1 curricula are evolving to emphasize higher-level problem-solving and systems thinking. In response, a novel experiential learning initiative grounded in High-Impact Practices was introduced to a CS1 course over the course of 2 semesters, involving 132 students. This initiative utilized robotics lab assignments to enhance computational thinking across various levels of granularity, from individual functional components to overall system behaviors, bridging conceptual understanding with real-world applications. The approach emphasized project-based learning, extended engagement time, and reflective practices to deepen students' understanding of core computing concepts and scaffold knowledge integration. The curriculum featured both individual and team-based lab assignments to build foundational skills followed by collaborative problem-solving. The initiative's impact was assessed against a control group of 427 students who completed traditional web development lab assignments. Evaluation methods included thematic analyses of student reflections, instructor opinion surveys, and statistical analysis of exam performances across the semester. Results revealed a substantial positive effect on self-efficacy and learning outcomes. Students in the experiential learning group reported increased confidence in applying their computing skills to real-world scenarios, heightened engagement, and greater improvements in technical proficiency. Notably, their exam scores demonstrated a statistically significant improvement compared to the control group. These findings highlight the effectiveness of integrating practical, interactive elements into computer science education to meet the demands of a rapidly evolving technological landscape.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {144–150},
numpages = {7},
keywords = {artificial intelligence, collaborative learning, cs1, experiential learning, robotics},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3623762.3633499,
author = {Prather, James and Denny, Paul and Leinonen, Juho and Becker, Brett A. and Albluwi, Ibrahim and Craig, Michelle and Keuning, Hieke and Kiesler, Natalie and Kohn, Tobias and Luxton-Reilly, Andrew and MacNeil, Stephen and Petersen, Andrew and Pettit, Raymond and Reeves, Brent N. and Savelka, Jaromir},
title = {The Robots Are Here: Navigating the Generative AI Revolution in Computing Education},
year = {2023},
isbn = {9798400704055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623762.3633499},
doi = {10.1145/3623762.3633499},
abstract = {Recent advancements in artificial intelligence (AI) and specifically generative AI (GenAI) are threatening to fundamentally reshape computing and society. Largely driven by large language models (LLMs), many tools are now able to interpret and generate both natural language instructions and source code. These capabilities have sparked urgent questions in the computing education community around how educators should adapt their pedagogy to address the challenges and to leverage the opportunities presented by this new technology. In this working group report, we undertake a comprehensive exploration of generative AI in the context of computing education and make five significant contributions. First, we provide a detailed review of the literature on LLMs in computing education and synthesise findings from 71 primary articles, nearly 80% of which have been published in the first 8 months of 2023. Second, we report the findings of a survey of computing students and instructors from across 20 countries, capturing prevailing attitudes towards GenAI/LLMs and their use in computing education contexts. Third, to understand how pedagogy is already changing, we offer insights collected from in-depth interviews with 22 computing educators from five continents. Fourth, we use the ACM Code of Ethics to frame a discussion of ethical issues raised by the use of large language models in computing education, and we provide concrete advice for policy makers, educators, and students. Finally, we benchmark the performance of several current GenAI models/tools on various computing education datasets, and highlight the extent to which the capabilities of current models are rapidly improving.There is little doubt that LLMs and other forms of GenAI will have a profound impact on computing education over the coming years. However, just as the technology will continue to improve, so will our collective knowledge about how to leverage these new models and tools in educational settings. We expect many important conversations around this topic will emerge as the community explores how to provide more effective, inclusive, and personalised learning experiences. Our aim is that this report will serve as a focal point for both researchers and practitioners who are exploring, adapting, using, and evaluating GenAI and LLM-based tools in computing classrooms.},
booktitle = {Proceedings of the 2023 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {108–159},
numpages = {52},
keywords = {ai, artificial intelligence, chatgpt, code generation, codex, computer programming, copilot, cs1, curriculum, generative ai, github, gpt, gpt-3, gpt-4, large language models, llm, llms, novice programming, openai, pedagogical practices, programming},
location = {Turku, Finland},
series = {ITiCSE-WGR '23}
}

@inproceedings{10.1145/3649409.3691074,
author = {Zarb, Mark and Brown, John N.A. and Goodfellow, Martin and Liaskos, Konstantinos and Young, Tiffany},
title = {Ethical Implications of Gen-AI and LLMs in Computing Education},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691074},
doi = {10.1145/3649409.3691074},
abstract = {The panel convenes five educators to discuss the ethical implications of utilising Generative AI (Gen-AI) and Large Language Models (LLMs) in computing education. Their expertise spans various domains, including organising national workshops on the implications of generative AI tools, conducting surveys on their use within curricula, implementing institutional policies related to technology use, and engaging with students directly in the classroom. They reflect on the evolution of Gen-AI and LLMs from challenging-to-use technologies to indispensable tools for users of all levels. Furthermore, they examine the ethical dilemmas arising from the widespread adoption of these technologies in educational contexts, particularly regarding issues of originality, integrity, and responsible use. In addition, they explore practical strategies for integrating ethics education into computing curriculum design and classroom practices. This includes discussions on the role of educators in guiding students towards ethical technology usage, addressing uncertainties surrounding Gen-AI tools, and fostering a culture of responsible innovation within educational institutions. Through their collective insights and experiences, the panel aims to provide recommendations for navigating the ethical complexities inherent in the integration of Gen-AI technologies into computing education curricula.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {293–294},
numpages = {2},
keywords = {ChatGPT, curriculum design, ethics, generative AI, large language models, responsibility},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3613905.3637148,
author = {Abolnejadian, Mohammad and Alipour, Sharareh and Taeb, Kamyar},
title = {Leveraging ChatGPT for Adaptive Learning through Personalized Prompt-based Instruction: A CS1 Education Case Study},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3637148},
doi = {10.1145/3613905.3637148},
abstract = {In this research paper, we discuss our attempt to teach high school students introductory programming with Python using a custom learning platform that leverages ChatGPT to generate personalized learning materials based on each student’s educational background. The platform features topics and subtopics, each supported by prompts for Explanation, Example, Exercise, and Exercise Solution, with a context-setting prompt tailored to individual students’ backgrounds while respecting their privacy. The case study brought up compelling insights. Students exhibited heightened engagement, and the lecturers transitioned from being traditional instructors teaching content to becoming mentors who guide students on what to do next, clarifying misunderstandings and addressing potential questions. Furthermore, students gained hands-on programming experience during the learning process, eliminating the traditional post-class experimentation phase. This innovative approach not only enhances traditional CS1 education but also suggests a broader application of Large Language Models (LLMs) for personalized learning across diverse fields, providing tailored instruction and fostering engagement.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {521},
numpages = {8},
keywords = {CS1, ChatGPT, Course Design, Introductory Programming, LLM, Learning Platform, Prompt Engineering},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3613904.3642349,
author = {Jin, Hyoungwook and Lee, Seonghee and Shin, Hyungyu and Kim, Juho},
title = {Teach AI How to Code: Using Large Language Models as Teachable Agents for Programming Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642349},
doi = {10.1145/3613904.3642349},
abstract = {This work investigates large language models (LLMs) as teachable agents for learning by teaching (LBT). LBT with teachable agents helps learners identify knowledge gaps and discover new knowledge. However, teachable agents require expensive programming of subject-specific knowledge. While LLMs as teachable agents can reduce the cost, LLMs’ expansive knowledge as tutees discourages learners from teaching. We propose a prompting pipeline that restrains LLMs’ knowledge and makes them initiate “why” and “how” questions for effective knowledge-building. We combined these techniques into TeachYou, an LBT environment for algorithm learning, and AlgoBo, an LLM-based tutee chatbot that can simulate misconceptions and unawareness prescribed in its knowledge state. Our technical evaluation confirmed that our prompting pipeline can effectively configure AlgoBo’s problem-solving performance. Through a between-subject study with 40 algorithm novices, we also observed that AlgoBo’s questions led to knowledge-dense conversations (effect size=0.71). Lastly, we discuss design implications, cost-efficiency, and personalization of LLM-based teachable agents.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {652},
numpages = {28},
keywords = {AI and Education, Generative AI, Human-AI interaction, LLM agents},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3674399.3674426,
author = {Dong, Dong and Liang, Yue},
title = {Grading Programming Assignments by Summarization},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674426},
doi = {10.1145/3674399.3674426},
abstract = {Grading programming assignments manually is a big burden for instructors who teach programming languages for university students due to complexity and subjectivity. The black test approach adopted by online judge systems can only outputs either an answer is correct or incorrect. This study proposes a Large Language Model (LLM) approach to automatically grade answers from students for programming assignments. A LLM mode formed by coder-decoder architecture is utilized to generate summarization from source code, then the summarization is compared to the textual assignment description by semantic similarity. Finally, the output is converted to five-score rating. CodeBERT and a Transformer model serve as coder and decoder respectively. The semantic similarity is computed by MiniLM-L6. The validation test shows that the accuracy of the suggested approach reaches 0.92.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {53–58},
numpages = {6},
keywords = {CodeBERT, automatic grading, programming assignment assessment, source code summarization},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3675094.3678991,
author = {Li, Yunjia and Liu, Haiming and Wald, Mike},
title = {DeepVision: Heads-up Computing and AI in Education},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3678991},
doi = {10.1145/3675094.3678991},
abstract = {Heads-up computing together with AI can enhance in-class learning experiences. In this position paper, we propose the development of a multimodal AI system called DeepVision that integrates Automatic Speech Recognition (ASR), Large Language Models (LLM), Large Vision Models (LVM), Information Retrieval (IR) and Inclusive User Experience Design (IUX) to convert real-time lectures into multiple knowledge representations. These will be visualized on heads-up communication devices such as Augmented Reality (AR) and Mixed Reality (MR) devices. The initiative is a collaboration between Habitat Learn Limited (HLL) and the University of Southampton, leveraging HLL's existing software and extensive data repository to address the challenges of traditional and digital learning environments, especially for students with disabilities or language differences.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {627–630},
numpages = {4},
keywords = {ai, ar, heads-up computing, inclusive user experience design, large language model, multimodal information access and retrieval},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3613905.3650937,
author = {Xiao, Ruiwei and Hou, Xinying and Stamper, John},
title = {Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650937},
doi = {10.1145/3613905.3650937},
abstract = {Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students’ problem-solving and learning, we conducted a think-aloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing help responses from content, format, and granularity levels to accurately identify and meet students’ learning needs.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {142},
numpages = {10},
keywords = {GPT, Help-seeking, Introductory Programming, Large Language Model, Programming Hint},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3626253.3633436,
author = {Leinonen, Juho and MacNeil, Stephen and Denny, Paul and Hellas, Arto},
title = {Using Large Language Models for Teaching Computing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3633436},
doi = {10.1145/3626253.3633436},
abstract = {In the past year, large language models (LLMs) have taken the world by storm, demonstrating their potential as a transformative force in many domains including computing education. Computing education researchers have found that LLMs can solve most assessments in introductory programming courses, including both traditional code writing tasks and other popular tasks such as Parsons problems. As more and more students start to make use of LLMs, the question instructors might ask themselves is "what can I do?". We propose that one promising way forward is to integrate LLMs into teaching practice, providing all students with an equal opportunity to learn how to interact productively with LLMs as well as encounter and understand their limitations. In this workshop, we first present state-of-the-art research results on how to utilize LLMs in computing education practice, after which participants will take part in hands-on activities using LLMs. We end the workshop by brainstorming ideas with participants around adapting their classrooms to most effectively integrate LLMs while avoiding some common pitfalls.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1901},
numpages = {1},
keywords = {generative ai, large language models, teaching practice},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626203.3670588,
author = {Stevens, Cody and Anderson, Sean and Carlson, Adam},
title = {Integrating High Performance Computing into Higher Education and the Pedagogy of Cluster Computing},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626203.3670588},
doi = {10.1145/3626203.3670588},
abstract = {Despite the exponential growth in demand for advanced computational skills driven by big data, machine learning, and artificial intelligence, higher education institutions still face a significant shortage of dedicated course offerings pertaining to High Performance Computing (HPC). This educational deficiency not only hampers the preparedness of undergraduate students for cutting-edge postgraduate programs but also impairs their readiness to enter a dynamic workforce increasingly reliant on sophisticated computational capabilities. Integrating comprehensive HPC courses at the undergraduate level is critical for equipping students with expertise to effectively utilize modern computing technologies, and also for bridging the growing gap between academic preparation and industry demands. At Wake Forest University (WFU), we, members of the HPC Team, are actively working to address the educational gap in HPC by integrating the WFU HPC Facility[4] into higher-level elective courses across various disciplines. Recognizing the foundational importance of these skills, we have developed an introductory course specifically designed to equip students with the knowledge to excel in advanced courses, in graduate and research programs, and to meet the demands of the modern workforce. By integrating the WFU HPC Facility into our curriculum, the University is committed to pioneering a comprehensive educational pathway that empowers students to leverage the full potential of computing technologies in their future careers. WFU is an R-2 liberal arts institution with around 9,000 students[6] that actively supports undergraduate research through a multitude of departments and programs. Undergraduate research is so paramount to the University mission, that WFU has a dedicated center, the Undergraduate Research and Creative Activities (URECA) Center, just for this purpose. Many students engage in research projects that leverage the resources of the WFU HPC Facility. The facility’s main asset, the Distributed Environment for Academic Computing (DEAC) Cluster, contains approximately 4000 CPU cores and 20TB of RAM, and is a true interdisciplinary tool; in 2023 it was utilized by 15 departments and 500 active users to submit over 1.5 million computational tasks on a vast array of research topics. The interdisciplinary nature of the DEAC Cluster played an instrumental role in developing an introductory course in HPC that caters to students from a diverse number of majors. Having supported a wide range of researchers, we designed the course to bridge concepts and applications from Computer Science, Engineering, Data Science, and the Natural Sciences to their respective academic domains. By enabling students from multiple disciplines to access foundational HPC skills, we foster a versatile educational environment where collaborative and interdisciplinary learning thrives. One way that we ensure our introductory course is accessible to all students is that we do not require any prerequisite classes to enroll in the course. Students are also not expected to have any prior experience in programming. We have chosen Python as the primary programming language for the course, as it is one of the most versatile and widely-used languages in the fields of data science and machine learning, and can easily interface with parallel frameworks such as MPI and OpenMP. Students gain hands-on experience by developing asynchronous workflows, which are then executed on the DEAC Cluster. This practical focus not only demystifies complex computational concepts but also empowers students to apply their learning in real-world scenarios. HPC serves as a cornerstone for two distinct user groups, each integral to its advancement and application. The first encompasses those who enable and optimize HPC systems, including Computer Scientists, Computer Engineers, Systems Administrators, and Cyberinfrastructure Professionals, who enhance computational efficiency and build the underlying hardware infrastructure. The second group comprises scientists and researchers across diverse fields such as Statistics, Chemistry, Biology, Physics, Engineering, and more, who leverage HPC as a powerful tool for simulating complex phenomena, analyzing large datasets, and researching novel problems in their respective domains. While current course offerings at other institutions seem to prioritize the first group and educate students on how to build and enable an HPC cluster, we have chosen to prioritize curriculum for the second group as the skills they gain through our course’s curriculum will help them as they continue their academic career in higher level electives and independent research projects with faculty advisors. We choose to offer our course during the Spring semester in order to prepare students who may want to pursue research during the summer session. The first half of the course serves as foundational cluster training, familiarizing students with essential skills to work within an HPC environment. In this segment, students delve into the Linux command line interface (CLI) using Bashcrawl[3] and explore the intricacies of the Linux filesystem and environment modules. A significant focus is placed on understanding and utilizing job schedulers, such as the Slurm resource manager[2]. Another unique feature of this segment is the guided tour of the Wake Forest datacenter. This tour provides students with a tangible understanding of how the theoretical concepts discussed in class are implemented in a real-world HPC cluster. To further provide a reference to the resources requested for their jobs through Slurm, the tour concludes with students disassembling retired compute nodes to learn about the different components that comprise modern servers. The midterm assessment challenges students to submit multiple jobs, analyzing the effects of varying input sizes and the use of multiple CPU processors on calculation speed. Upon completion of this initial phase, students are fully equipped to engage in research activities under an advisor and effectively utilize an HPC cluster outside the confines of the classroom. Many apply for summer grants through the aforementioned URECA program with a faculty advisor. In the latter half of the course, the curriculum shifts towards more advanced topics, focusing on parallel computing frameworks and technologies. Students are introduced to MPI and OpenMP, which are essential for developing parallel applications that can run efficiently on today’s multi-processor systems. Additionally, the course delves into high-speed interconnects, crucial for optimizing communication between different parts of an HPC cluster. One of our final topics covers GPU computing, with a particular emphasis on using NVIDIA GPUs and the CUDA programming platform, enabling students to harness the power of graphical processing for computational tasks. As an example from our Spring 2024 semester, students built a “chatbot” using Meta’s Llama 2 model[5] on both CPU and GPU using LLaMA C++[1], and compared its performance to ChatGPT while interacting freely with it. Our course is designed to complement other specialized courses found in Computer Science or in Computer Engineering programs, such as Parallel Algorithms, Computer Vision, or Deep Learning. It aims to introduce these critical computational concepts and provide a solid foundation that prepares students for these more advanced electives. By the end of the course, students are not only familiar with the basic principles of HPC but are also primed to tackle more specialized studies and research in their future academic and professional pursuits. It is not uncommon that a course may require students to use a specific programming language or software. While there are tools such as Google Colab and zyBooks that provide a browser-based interface to computing resources, those tools can be very limited in what resources they can provide. A faculty member might then want students to install software locally on their laptop, but this can be challenging when students bring their own device to the classroom as they may be running different operating systems or may have different hardware platforms. This can cause the software to behave differently or it may not even be available on that given platform. Courses with significant computational demands are better served utilizing a unified computing environment, and an HPC facility is ideally equipped to provide a consistent learning environment where each student has access to the same software and computing resources. A primary challenge in integrating HPC resources into coursework is instructing students on the use of schedulers for asynchronous workloads. Our introductory HPC course effectively bridges this gap by providing the necessary training and context, enabling students to engage with advanced topics more efficiently, without the steep initial learning curve typically associated with these environments. Our HPC facility has proven instrumental in enhancing educational experiences across a variety of disciplines, demonstrating significant benefits in classes such as Statistics, Natural Language Processing, Parallel Algorithms, Computer Vision, Physics Laboratory, Cancer Biology, Environmental Physics, Computational Modeling, and more. Moreover, students in fields like Finance and Business and Enterprise Management have also successfully leveraged our HPC resources, and have performed analysis on client data that was protected under a nondisclosure agreement which prevented students from storing the data locally on their laptop or with commercial cloud providers. This integration not only facilitates sophisticated computational tasks, but also allows students and faculty to easily share and store large datasets that the students may need to access without having to consume space on their local device. One of our primary goals is to promote diversity and interdisciplinary collaboration within this course, and this semester attracted a notably diverse group of students, with majors ranging from Biology and Statistics to Applied Mathematics, Economics, and Computer Science. Although the course is currently catalogued under the Computer Science department, we recognize that associating it with any single discipline could potentially limit its appeal and accessibility. The diverse enrollment underscores the interdisciplinary relevance of HPC skills across various fields of study. We are leveraging the current success and broad interest in the course as a foundation to establish a new academic program dedicated to High Performance Computing. This new program will serve as a hub for integrating computational skills across different disciplines, fostering a broader understanding and application of HPC in various scientific and economic sectors. The HPC team’s commitment to High Performance Computing education extends beyond traditional academic structures. While we are not developing a new major, minor, certificate track, or concentration in HPC, our objective is to make HPC education accessible and applicable across various disciplines without the constraints of a single departmental bias. This approach allows students from any field to engage with HPC skills as an integral part of their academic and professional development. To achieve this, we are actively collaborating with multiple academic departments to ensure that our HPC course offerings are recognized as fulfilling degree requirements across a range of programs. One way we collaborate with these departments is by altering activities and projects to use different languages and software, such as R and MATLAB, for the Statistics and Engineering departments, while still maintaining the same learning goals we achieve with Python. This strategy not only enhances the versatility of our course but also promotes a more comprehensive integration of the university’s HPC facilities into the curriculum. By doing so, we allow faculty in different departments to integrate our projects into their courses and utilize our HPC facility, even if it is for only one or two projects throughout the semester. Our efforts are focused on fostering a collaborative academic environment where the HPC facility is not just an isolated resource used for research but a central part of our educational infrastructure. By working across disciplines, we hope to catalyze a deeper engagement with HPC technologies throughout the university, enhancing both teaching and research capacities across departments. In conclusion, the escalating demand for big data, machine learning, and artificial intelligence is not only transforming industries but also reshaping educational requirements. As these fields expand, the need for substantial computational resources becomes increasingly critical. The HPC facility at Wake Forest University is exceptionally well-equipped to meet these demands, by providing a unified computing environment that supports an array of academic endeavors. Our initiative to develop introductory HPC courses is a strategic response to this need, preparing students to proficiently utilize HPC resources in higher-level electives and beyond. These courses are pivotal in bridging the gap between conventional academic programs and the rigorous computational needs of modern disciplines. Looking forward, the necessity for such educational offerings will only intensify as the reliance on advanced computational technologies grows. By anticipating and responding to these educational demands, Wake Forest University’s HPC academic program not only enhances student readiness for future challenges but also positions the university at the forefront of academic innovation in the computational sciences.},
booktitle = {Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
articleno = {106},
numpages = {3},
location = {Providence, RI, USA},
series = {PEARC '24}
}

@inproceedings{10.1145/3613904.3642024,
author = {Rajashekar, Niroop Channa and Shin, Yeo Eun and Pu, Yuan and Chung, Sunny and You, Kisung and Giuffre, Mauro and Chan, Colleen E and Saarinen, Theo and Hsiao, Allen and Sekhon, Jasjeet and Wong, Ambrose H and Evans, Leigh V and Kizilcec, Rene F. and Laine, Loren and Mccall, Terika and Shung, Dennis},
title = {Human-Algorithmic Interaction Using a Large Language Model-Augmented Artificial Intelligence Clinical Decision Support System},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642024},
doi = {10.1145/3613904.3642024},
abstract = {Integration of artificial intelligence (AI) into clinical decision support systems (CDSS) poses a socio-technological challenge that is impacted by usability, trust, and human-computer interaction (HCI). AI-CDSS interventions have shown limited benefit in clinical outcomes, which may be due to insufficient understanding of how health-care providers interact with AI systems. Large language models (LLMs) have the potential to enhance AI-CDSS, but haven’t been studied in either simulated or real-world clinical scenarios. We present findings from a randomized controlled trial deploying AI-CDSS for the management of upper gastrointestinal bleeding (UGIB) with and without an LLM interface within realistic clinical simulations for physician and medical student participants. We find evidence that LLM augmentation improves ease-of-use, that LLM-generated responses with citations improve trust, and HCI varies based on clinical expertise. Qualitative themes from interviews suggest the perception of LLM-augmented AI-CDSS as a team-member used to confirm initial clinical intuitions and help evaluate borderline decisions.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {442},
numpages = {20},
keywords = {Artificial Intelligence, Clinical Decision Support Systems, Electronic Health Record, Health-Clinical, Machine Learning, Medical: Nursing Homes/Hospitals, Qualitative Methods, Quantitative Methods, Workflows},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3691620.3695062,
author = {Liu, Fang and Liu, Zhenwei and Zhao, Qianhui and Jiang, Jing and Zhang, Li and Sun, Zian and Li, Ge and Li, Zhongqi and Ma, Yuchi},
title = {FastFixer: An Efficient and Effective Approach for Repairing Programming Assignments},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695062},
doi = {10.1145/3691620.3695062},
abstract = {Providing personalized and timely feedback for student's programming assignments is useful for programming education. Automated program repair (APR) techniques have been used to fix the bugs in programming assignments, where the Large Language Models (LLMs) based approaches have shown promising results. Given the growing complexity of identifying and fixing bugs in advanced programming assignments, current fine-tuning strategies for APR are inadequate in guiding the LLM to identify bugs and make accurate edits during the generative repair process. Furthermore, the autoregressive decoding approach employed by the LLM could potentially impede the efficiency of the repair, thereby hindering the ability to provide timely feedback. To tackle these challenges, we propose FastFixer, an efficient and effective approach for programming assignment repair. To assist the LLM in accurately identifying and repairing bugs, we first propose a novel repair-oriented fine-tuning strategy, aiming to enhance the LLM's attention towards learning how to generate the necessary patch and its associated context. Furthermore, to speed up the patch generation, we propose an inference acceleration approach that is specifically tailored for the program repair task. The evaluation results demonstrate that FastFixer obtains an overall improvement of 20.46% in assignment fixing when compared to the state-of-the-art baseline. Considering the repair efficiency, FastFixer achieves a remarkable inference speedup of 16.67\texttimes{} compared to the autoregressive decoding algorithm.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {669–680},
numpages = {12},
keywords = {automated program repair, large language models, programming education, inference acceleration},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3641554.3701974,
author = {P?durean, Victor-Alexandru and Denny, Paul and Singla, Adish},
title = {BugSpotter: Automated Generation of Code Debugging Exercises},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701974},
doi = {10.1145/3641554.3701974},
abstract = {Debugging is an essential skill when learning to program, yet its instruction and emphasis often vary widely across introductory courses. In the era of code-generating large language models (LLMs), the ability for students to reason about code and identify errors is increasingly important. However, students frequently resort to trial-and-error methods to resolve bugs without fully understanding the underlying issues. Developing the ability to identify and hypothesize the cause of bugs is crucial but can be time-consuming to teach effectively through traditional means. This paper introduces BugSpotter, an innovative tool that leverages an LLM to generate buggy code from a problem description and verify the synthesized bugs via a test suite. Students interact with BugSpotter by designing failing test cases, where the buggy code's output differs from the expected result as defined by the problem specification. This not only provides opportunities for students to enhance their debugging skills, but also to practice reading and understanding problem specifications. We deployed BugSpotter in a large classroom setting and compared the debugging exercises it generated to exercises hand-crafted by an instructor for the same problems. We found that the LLM-generated exercises produced by BugSpotter varied in difficulty and were well-matched to the problem specifications. Importantly, the LLM-generated exercises were comparable to those manually created by instructors with respect to student performance, suggesting that BugSpotter could be an effective and efficient aid for learning debugging.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {896–902},
numpages = {7},
keywords = {bugspotter, debugging, exercise generation, generative ai, llms, programming education, test cases},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3627673.3679664,
author = {Guo, Yuxiang and Shen, Shuanghong and Liu, Qi and Huang, Zhenya and Zhu, Linbo and Su, Yu and Chen, Enhong},
title = {Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679664},
doi = {10.1145/3627673.3679664},
abstract = {Knowledge Tracing (KT) is a crucial research task for dynamically monitoring students' knowledge states, particularly in online education systems. Recently, knowledge tracing has gained significant attention and in-depth research. Most existing methods rely on students' response data for question understanding and modeling, which helps better updating students' knowledge states. Meanwhile, question ID is utilized to indicate and represent questions. However, this presents a challenge when transitioning to new, cold-start questions that few students has answered before. Also, prior work has overlooked the semantic modeling of questions, which could better assist in modeling the transfer of students' knowledge states. In this paper, we explore leveraging the power of Large Language Models (LLMs) to help understand questions for knowledge tracing, which benefits mitigating cold-start and sparse problems and modeling the transfer of students' knowledge states in a sophisticated manner. Specifically, we first design an attribute estimation module to estimate the attribute of the questions (e.g., difficulty, ability requirements, expected response time) by prompting Large Language Models. Subsequently, we have developed a question embedding module that incorporates graph attention network to effectively utilizing these attributes. Extensive experiments on various datasets demonstrate that our model outperforms existing state-of-the-art models and effectively addresses the problems of cold-start and sparsity. In addition, due to the estimation of multiple attributes of the questions, our model exhibits superior interpretability.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {727–736},
numpages = {10},
keywords = {knowledge tracing, large language model, question attributes},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3634814.3634816,
author = {Cowan, Brendan and Watanobe, Yutaka and Shirafuji, Atsushi},
title = {Enhancing Programming Learning with LLMs: Prompt Engineering and Flipped Interaction},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634816},
doi = {10.1145/3634814.3634816},
abstract = {Due to their robustness, large language models (LLMs) are being utilized in many fields of study, including programming and education. Notably, they can be used by programmers by interfacing with their IDEs to assist with development, and in education by giving students meaningful and immediate feedback. In this paper, we propose and explore the groundwork of a framework designed to combine these two applications of LLMs. The framework acts as a facilitator between the LLM and the student by reading the student’s prompts before filtering and modifying them and sending them to the LLM. The intent is that this will improve the responses from the LLM, thereby improving the student’s learning experience. We discuss the framework in detail and analyze the value of individual responses returned from the LLM as a result of our framework. We conclude that the framework causes the LLM to give helpful responses in comparison to how it would respond without the framework.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {10–16},
numpages = {7},
keywords = {ChatGPT, educational technology, large language models, programming education, prompt engineering},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

@inproceedings{10.1145/3641555.3705180,
author = {Brilliantova, Angelina and Butler, Zack and Bez\'{a}kov\'{a}, Ivona},
title = {Exploring ChatGPT as a Qualitative Research Assistant},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705180},
doi = {10.1145/3641555.3705180},
abstract = {In many CS educational research studies, students are surveyed to understand their reactions to a particular pedagogical approach or tool. These surveys, as well as other types of evaluations, often invite students to provide open-ended feedback about their experiences. However, analyzing these comments can prove to be a challenge, especially to CS educators who may not have strong expertise in qualitative research methods. In addition, in a large study, evaluating all of the provided comments can consume a significant amount of researcher time. In this work, we undertook two separate conversations with ChatGPT in which we prompted it to perform qualitative analysis of a set of comments collected in an earlier study. This allowed us to begin to judge how effectively a modern large language model can serve as an assistant in qualitative analysis. We found that with the prompts we used, ChatGPT can reliably build a set of reasonable labels (codes) for a set of comments, but the application of its labels to specific comments may or may not be effective and human researchers still need to use care and their own understanding in interpreting its output.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1397–1398},
numpages = {2},
keywords = {chatgpt, grounded theory, large-language models, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630909,
author = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
title = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630909},
doi = {10.1145/3626252.3630909},
abstract = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {296–302},
numpages = {7},
keywords = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701945,
author = {Liu, Rongxin and Zhao, Julianna and Xu, Benjamin and Perez, Christopher and Zhukovets, Yuliia and Malan, David J.},
title = {Improving AI in CS50: Leveraging Human Feedback for Better Learning},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701945},
doi = {10.1145/3641554.3701945},
abstract = {In 2023, we developed and deployed AI-based tools in CS50 at Harvard University to provide students with 24/7 interactive assistance, approximating a 1:1 teacher-to-student ratio. These tools offer code explanations, style suggestions, and responses to course-related inquiries, emulating human educators to foster critical thinking. However, maintaining alignment with instructional goals is challenging, especially with frequent updates to the underlying large language models (LLMs). We thus propose a continuous improvement process for LLM-based systems using a collaborative human-in-the-loop approach. We introduce a systematic evaluation framework for assessing and refining the performance of AI-based tutors, combining human-graded and model-graded evaluations. Using few-shot prompting and fine-tuning, we aim to ensure our AI tools adopt pedagogically sound teaching styles. Fine-tuning with a small, high-quality dataset has shown significant improvements in aligning with teaching goals, as confirmed through multi-turn conversation evaluations. Additionally, our framework includes a model-evaluation backend that teaching assistants periodically review, ensuring the AI system remains effective and aligned with instructional objectives. This paper offers insights into our methods and the impact of these AI tools on CS50 and contributes to the discourse on AI in education, showcasing scalable, personalized learning enhancements.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {715–721},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3640457.3688181,
author = {Jamet, Henri and Manderlier, Maxime and Shrestha, Yash Raj and Vlachos, Michalis},
title = {Evaluation and simplification of text difficulty using LLMs in the context of recommending texts in French to facilitate language learning},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688181},
doi = {10.1145/3640457.3688181},
abstract = {Learning a new language can be challenging. To help learners, we built a recommendation system that suggests texts and videos based on the learners’ skill level of the language and topic interests. Our system analyzes content to determine its difficulty and topic, and, if needed, can simplify complex texts while maintaining semantics. Our work explores the holistic use of Large Language Models (LLMs) for the various sub-tasks involved for accurate recommendations: difficulty estimation and simplification, graph recommender engine, topic estimation. We present a comprehensive evaluation comparing zero-shot and fine-tuned LLMs, demonstrating significant improvements in French content difficulty prediction (18-56%), topic prediction accuracy (27%), and recommendation relevance (up to 18% NDCG increase).},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {987–992},
numpages = {6},
keywords = {digital education, extensive reading, large language models, machine learning},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3587102.3588785,
author = {Leinonen, Juho and Denny, Paul and MacNeil, Stephen and Sarsa, Sami and Bernstein, Seth and Kim, Joanne and Tran, Andrew and Hellas, Arto},
title = {Comparing Code Explanations Created by Students and Large Language Models},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588785},
doi = {10.1145/3587102.3588785},
abstract = {Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n ≈ 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {124–130},
numpages = {7},
keywords = {CS1, ChatGPT, GPT-3, GPT-4, code comprehension, code explanations, foundation models, large language models, natural language generation, resource generation},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3636243.3636252,
author = {Jury, Breanna and Lorusso, Angela and Leinonen, Juho and Denny, Paul and Luxton-Reilly, Andrew},
title = {Evaluating LLM-generated Worked Examples in an Introductory Programming Course},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636252},
doi = {10.1145/3636243.3636252},
abstract = {Worked examples, which illustrate the process for solving a problem step-by-step, are a well-established pedagogical technique that has been widely studied in computing classrooms. However, creating high-quality worked examples is very time-intensive for educators, and thus learners tend not to have access to a broad range of such examples. The recent emergence of powerful large language models (LLMs), which appear capable of generating high-quality human-like content, may offer a solution. Separate strands of recent work have shown that LLMs can accurately generate code suitable for a novice audience, and that they can generate high-quality explanations of code. Therefore, LLMs may be well suited to creating a broad range of worked examples, overcoming the bottleneck of manual effort that is currently required. In this work, we present a novel tool, ‘WorkedGen’, which uses an LLM to generate interactive worked examples. We evaluate this tool with both an expert assessment of the content, and a user study involving students in a first-year Python programming course (n = ~400). We find that prompt chaining and one-shot learning are useful strategies for optimising the output of an LLM when producing worked examples. Our expert analysis suggests that LLMs generate clear explanations, and our classroom deployment revealed that students find the LLM-generated worked examples useful for their learning. We propose several avenues for future work, including investigating WorkedGen’s value in a range of programming languages, and with more complex questions suitable for more advanced courses.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {77–86},
numpages = {10},
keywords = {CS1, GPT-3.5, LLM, chat-GPT, computing education, large language models, worked examples},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@article{10.1145/3633287,
author = {Richards, Mike and Waugh, Kevin and Slaymaker, Mark and Petre, Marian and Woodthorpe, John and Gooch, Daniel},
title = {Bob or Bot: Exploring ChatGPT's Answers to University Computer Science Assessment},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3633287},
doi = {10.1145/3633287},
abstract = {Cheating has been a long-standing issue in university assessments. However, the release of ChatGPT and other free-to-use generative AI tools has provided a new and distinct method for cheating. Students can run many assessment questions through the tool and generate a superficially compelling answer, which may or may not be accurate.&nbsp;We ran a dual-anonymous “quality assurance” marking exercise across four end-of-module assessments across a distance university computer science (CS) curriculum. Each marker received five ChatGPT-generated scripts alongside 10 student scripts. A total of 90 scripts were marked; every ChatGPT-generated script for the undergraduate modules received at least a passing grade (&gt;40%), with all of the introductory module CS1 scripts receiving a distinction (&gt;85%). None of the ChatGPT-taught postgraduate scripts received a passing grade (&gt;50%). We also present the results of interviewing the markers and of running our sample scripts through a GPT-2 detector and the TurnItIn AI detector, which both identified every ChatGPT-generated script but differed in the number of false positives. As such, we contribute a baseline understanding of how the public release of generative AI is likely to significantly impact quality assurance processes. Our analysis demonstrates that in most cases, across a range of question formats, topics, and study levels, ChatGPT is at least capable of producing adequate answers for undergraduate assessment.},
journal = {ACM Trans. Comput. Educ.},
month = jan,
articleno = {5},
numpages = {32},
keywords = {ChatGPT, generative AI, cheating, quality assurance, university assessment’}
}

@inproceedings{10.1145/3716640.3716658,
author = {Feng, Tony Haoran and Luxton-Reilly, Andrew and W\"{u}nsche, Burkhard C and Denny, Paul},
title = {From Automation to Cognition: Redefining the Roles of Educators and Generative AI in Computing Education},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716658},
doi = {10.1145/3716640.3716658},
abstract = {Generative Artificial Intelligence (GenAI) offers numerous opportunities to revolutionise teaching and learning in Computing Education (CE). However, educators have expressed concerns that students may over-rely on GenAI and use these tools to generate solutions without engaging in the learning process. While substantial research has explored GenAI use in CE, and many Computer Science (CS) educators have expressed their opinions and suggestions on the subject, there remains little consensus on implementing curricula and assessment changes.In this paper, we describe our experiences with using GenAI in CS-focused educational settings and the changes we have implemented accordingly in our teaching in recent years since the popularisation of GenAI. From our experiences, we propose two primary actions for the CE community: 1) redesign take-home assignments to incorporate GenAI use and assess students on their process of using GenAI to solve a task rather than simply on the final product; 2) redefine the role of educators to emphasise metacognitive aspects of learning, such as critical thinking and self-evaluation. This paper presents and discusses these stances and outlines several practical methods to implement these strategies in CS classrooms. Then, we advocate for more research addressing the concrete impacts of GenAI on CE, especially those evaluating the validity and effectiveness of new teaching practices.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {164–171},
numpages = {8},
keywords = {Generative Artificial Intelligence, GenAI, Strategy, Assignments, Metacognition, Assessments},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3576882.3617921,
author = {Prasad, Siddhartha and Greenman, Ben and Nelson, Tim and Krishnamurthi, Shriram},
title = {Generating Programs Trivially: Student Use of Large Language Models},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617921},
doi = {10.1145/3576882.3617921},
abstract = {Educators have been concerned about the capability of large language models to automatically generate programs in response to textual prompts. However, little is known about whether and how students actually use these tools.In the context of an upper-level formal methods course, we gave students access to large language models. They were told they could use the models freely. We built a Visual Studio Code extension to simplify access to these models. We also paid for an account so students could use the models for free without worrying about cost.In this experience report we analyze the outcomes. We see how students actually do and do not use the models. We codify the different uses they make. Most of all, we notice that students actually do not use them very much at all, and provide insight into the many reasons why not. We believe such experiments can help rebalance some of the public narrative about such tools.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {126–132},
numpages = {7},
keywords = {formal methods, large language models, properties, testing},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3568812.3603482,
author = {Tran, Andrew and Li, Linxuan and Rama, Egi and Angelikas, Kenneth and Macneil, Stephen},
title = {Using Large Language Models to Automatically Identify Programming Concepts in Code Snippets},
year = {2023},
isbn = {9781450399753},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568812.3603482},
doi = {10.1145/3568812.3603482},
abstract = {Curating course material that aligns with students’ learning goals is a challenging and time-consuming task that instructors undergo when preparing their curricula. For instance, it is a challenge to find multiple-choice questions or example codes that demonstrate recursion in an unlabeled question bank or repository. Recently, Large Language Models (LLMs) have demonstrated the capability to generate high-quality learning materials at scale. In this poster, we use LLMs to identify programming concepts found within code snippets, allowing instructors to quickly curate their course materials. We compare programming concepts generated by LLMs with concepts generated by experts to see the extent to which they agree. The agreement was calculated using Cohen’s Kappa.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 2},
pages = {22–23},
numpages = {2},
keywords = {computer science education, explanations, large language models},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@inproceedings{10.1145/3644116.3644294,
author = {Zhu, Jinyang and Gong, Qingyue and Zhou, Chunfang and Luan, Huidan},
title = {ZhongJing: A Locally Deployed Large Language Model for Traditional Chinese Medicine and Corresponding Evaluation Methodology: A Large Language Model for data fine-tuning in the field of Traditional Chinese Medicine, and a new evaluation method called TCMEval are proposed},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644294},
doi = {10.1145/3644116.3644294},
abstract = {The success of ChatGPT has showcased the potential applications of Large Language Models (LLMs) in the field of Traditional Chinese Medicine (TCM), encompassing areas such as medical diagnosis, adjunctive therapy, and TCM talent cultivation. However, the current challenges, including hardware constraints, insufficient model domain knowledge, and difficulties in domain-specific evaluation, have constrained the fusion of LLMs with TCM. In an attempt to address these issues, this paper introduces ZhongJing, a domain-specific LLM fine-tuned within the domain of TCM, capable of generating responses at a rate of 8 tokens per second, smoothly operating on local personal computers. To assess the model's domain expertise, this paper introduces the TCMEval evaluation method, designed concerning medical students' exams. Experimental results demonstrate that ZhongJing achieves a 6.49 TCMEval Score improvement over Chinese-LLaMA2 in the field of TCM, indicating the model's ability to generate more specialized responses compared to baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1036–1042},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3657604.3662032,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {CodeTailor: LLM-Powered Personalized Parsons Puzzles for Engaging Support While Learning Programming},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662032},
doi = {10.1145/3657604.3662032},
abstract = {Learning to program can be challenging, and providing high-quality and timely support at scale is hard. Generative AI and its products, like ChatGPT, can create a solution for most intro-level programming problems. However, students might use these tools to just generate code for them, resulting in reduced engagement and limited learning. In this paper, we present CodeTailor, a system that leverages a large language model (LLM) to provide personalized help to students while still encouraging cognitive engagement. CodeTailor provides a personalized Parsons puzzle to support struggling students. In a Parsons puzzle, students place mixed-up code blocks in the correct order to solve a problem. A technical evaluation with previous incorrect student code snippets demonstrated that CodeTailor could deliver high-quality (correct, personalized, and concise) Parsons puzzles based on their incorrect code. We conducted a within-subjects study with 18 novice programmers. Participants perceived CodeTailor as more engaging than just receiving an LLM-generated solution (the baseline condition). In addition, participants applied more supported elements from the scaffolded practice to the posttest when using CodeTailor than baseline. Overall, most participants preferred using CodeTailor versus just receiving the LLM-generated code for learning. Qualitative observations and interviews also provided evidence for the benefits of CodeTailor, including thinking more about solution construction, fostering continuity in learning, promoting reflection, and boosting confidence. We suggest future design ideas to facilitate active learning opportunities with generative AI techniques.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {51–62},
numpages = {12},
keywords = {active learning, generative ai, gpt, introductory programming, large language models, parsons problems, personalization},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3724504.3724605,
author = {Qi, Shanshan and Qiu, Hongye},
title = {Developing and Implementing Teacher-Created AI Tools for Cultural Expression: A Mixed-Methods Study of EFL Students' Learning of Traditional Chinese Culture},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724605},
doi = {10.1145/3724504.3724605},
abstract = {This study focused on the design and application of AI tools developed by teachers to enable EFL students to express themselves in English within the context of traditional Chinese culture. This study uses a sequential explanatory mixed-methods design to illustrate how educators with little programming knowledge can develop customized learning tools through low-code platforms with large language model integration. The study consists of three phases: developing IA Improved Learning tools, implementing AI Improved tools in EFL classrooms, and evaluating their efficiency. Rich quantitative data collected from 33 undergraduate students, as well as qualitative data from semi-structured interviews, also demonstrate a profound improvement in both the ability of students to express cultural understanding as well as critical engagement in a post-course environment. These findings show how AI tools developed by teachers can fill the gap between technical possibility and pedagogical necessity and how these efforts can support culturally sustaining language learning. This study advances scholarship concerning integrating AIs into language education while offering practice and practical insights for educators interested in creating bespoke domain-specific AI learners.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {608–616},
numpages = {9},
keywords = {English as Foreign Language (EFL), Low-code development, Mixed-methods research, Teacher-created AI tools, Technology-enhanced language learning},
location = {
},
series = {ICIEAI '24}
}

@inproceedings{10.1145/3699538.3699556,
author = {Birillo, Anastasiia and Artser, Elizaveta and Potriasaeva, Anna and Vlasov, Ilya and Dzialets, Katsiaryna and Golubev, Yaroslav and Gerasimov, Igor and Keuning, Hieke and Bryksin, Timofey},
title = {One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699556},
doi = {10.1145/3699538.3699556},
abstract = {Students often struggle with solving programming problems when learning to code, especially when they have to do it online, with one of the most common disadvantages of working online being the lack of personalized help. This help can be provided as next-step hint generation, i.e., showing a student what specific small step they need to do next to get to the correct solution. There are many ways to generate such hints, with large language models (LLMs) being among the most actively studied right now. While LLMs constitute a promising technology for providing personalized help, combining them with other techniques, such as static analysis, can significantly improve the output quality. In this work, we utilize this idea and propose a novel system to provide both textual and code hints for programming tasks. The pipeline of the proposed approach uses a chain-of-thought prompting technique and consists of three distinct steps: (1) generating subgoals — a list of actions to proceed with the task from the current student’s solution, (2) generating the code to achieve the next subgoal, and (3) generating the text to describe this needed action. During the second step, we apply static analysis to the generated code to control its size and quality. The tool is implemented as a modification to the open-source JetBrains Academy plugin, supporting students in their in-IDE courses. To evaluate our approach, we propose a list of criteria for all steps in our pipeline and conduct two rounds of expert validation. Finally, we evaluate the next-step hints in a classroom with 14 students from two universities. Our results show that both forms of the hints — textual and code — were helpful for the students, and the proposed system helped them to proceed with the coding tasks.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {9},
numpages = {12},
keywords = {Programming Education, in-IDE learning, LLMs, Generative AI, Next-Step Hints},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3632620.3671092,
author = {Yang, Stephanie and Zhao, Hanzhang and Xu, Yudian and Brennan, Karen and Schneider, Bertrand},
title = {Debugging with an AI Tutor: Investigating Novice Help-seeking Behaviors and Perceived Learning},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671092},
doi = {10.1145/3632620.3671092},
abstract = {Debugging is a crucial skill for programmers, yet it can be challenging for novices to learn. The introduction of large language models (LLMs) has opened up new possibilities for providing personalized debugging support to students. However, concerns have been raised about potential student over-reliance on LLM-based tools. This mixed-methods study investigates how a pedagogically-designed LLM-based chatbot supports students’ debugging efforts in an introductory programming course. We conducted interviews and debugging think-aloud tasks with 20 students at three points throughout the semester. We specifically focused on characterizing when students initiate help from the chatbot during debugging, how they engage with the chatbot’s responses, and how they describe their learning experiences with the chatbot. By analyzing data from the debugging tasks, we identified varying help-seeking behaviors and levels of engagement with the chatbot’s responses, depending on students’ familiarity with the suggested strategies. Interviews revealed that students appreciated the content and experiential knowledge provided by the chatbot, but did not view it as a primary source for learning debugging strategies. Additionally, students self-identified certain chatbot usage behaviors as negative, “non-ideal” engagement and others as positive, “learning-oriented” usage. Based on our findings, we discuss pedagogical implications and future directions for designing pedagogical chatbots to support debugging.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {84–94},
numpages = {11},
keywords = {AI tutoring, LLMs, debugging, help-seeking, large language models, programming education},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3626253.3635427,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635427},
doi = {10.1145/3626253.3635427},
abstract = {CS50.ai is an AI-based educational tool developed and integrated into CS50 at Harvard University using large language models (LLMs), supporting both in-person and online learners. CS50.ai encapsulates a variety of AI-based tools designed to enhance students' learning by approximating a 1:1 teacher-to-student ratio. We showcase: "Explain Highlighted Code," a Visual Studio (VS) Code extension that provides just-in-time explanations of code snippets; style50, a VS Code extension that offers formatting suggestions and explanations thereof; and our "CS50 Duck," an AI-based chatbot for course-related questions, implemented both as a VS Code extension and as a standalone web application. We also demonstrate the integration of our tools into Ed, the course's discussion forum. This demo will illustrate the functionality and effectiveness of these tools as well as the pedagogical "guardrails" that we put in place to ensure secure and fair usage of these tools, while sharing insights from our own experience therewith this past summer and fall.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1927},
numpages = {1},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3478432.3499265,
author = {Koornneef, Stacey A. and Bradbury, Jeremy S. and Miljanovic, Michael A.},
title = {Run, Llama, Run: A Collaborative Physical and Online Coding Game for Children},
year = {2022},
isbn = {9781450390712},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3478432.3499265},
doi = {10.1145/3478432.3499265},
abstract = {Computational thinking and computer science are now being introduced in K-5 classrooms and this has led to a demand for more engaging and interactive tools designed for a younger audience. Educational games and block-based programming are two approaches that have been shown to be effective at engaging children to learn computer science. While existing tools have value, they also have limitations with respect to their support for collaborative learning and with respect to equitable access. Run, Llama, Run, is a collaborative educational game designed to be played by K-5 students both with and without access to a tablet or computer. The game includes physical programming blocks where a group of students work together to find a solution for a given scenario. A digital interface is available to execute and animate student solutions and a non-digital alternative allows students to act out their solutions. This demo of Run, Llama, Run provides a chance for participants to play both versions of the game and observe the potential impact this game could have for students.},
booktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2},
pages = {1177},
numpages = {1},
keywords = {k-5 computer science education, educational game, collaborative learning},
location = {Providence, RI, USA},
series = {SIGCSE 2022}
}

@inproceedings{10.1145/3626253.3635604,
author = {Weber, Jason Lee and Martinez Neda, Barbara and Carbajal Juarez, Kitana and Wong-Ma, Jennifer and Gago-Masague, Sergio and Ziv, Hadar},
title = {Measuring CS Student Attitudes Toward Large Language Models},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635604},
doi = {10.1145/3626253.3635604},
abstract = {With the mainstream adoption of Large Language Models (LLMs), members of both academia and the media have raised concerns around their impact on student learning and pedagogy. Many students and educators wonder about the pedagogical fit of this emerging technology. We aim to measure the adoption of and attitudes toward LLMs among the CS student population at an R1 University to determine how students are using these new tools. To this end, we conducted a large survey study targeting two populations participating in computing courses at the university: intro-sequence students (ISS) and experienced students (ES).In our preliminary results from Spring 2023, we've found several significant differences among the views of over 700 respondents across the two groups. Most students reported LLMs' unparalleled potential for quick information access, yet many harbor concerns about the reliability of the LLM responses, and the impact on academic integrity. Additionally, while ES have rapidly integrated LLMs into their learning, ISS remain cautious of the tools, highlighting a stark contrast in adoption rates between the groups.LLMs are clearly going to reshape pedagogical approaches and student engagement. Our study hopes to provide insight on the nuanced student attitudes toward LLMs. For example, the notable reservations expressed by ISS illustrate an imperative for careful, informed, and ethical integration to ensure these tools enhance rather than compromise the educational experience. In the future, we plan to continue tracking student attitudes in order to gain further understanding of the changing perceptions of LLMs and their impact.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1846–1847},
numpages = {2},
keywords = {academic integrity, ai tools, chatgpt, faculty perception, generative ai, large language models (llms), student perception},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3649850,
author = {Zhang, Jialu and Cambronero, Jos\'{e} Pablo and Gulwani, Sumit and Le, Vu and Piskac, Ruzica and Soares, Gustavo and Verbruggen, Gust},
title = {PyDex: Repairing Bugs in Introductory Python Assignments using LLMs},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {OOPSLA1},
url = {https://doi.org/10.1145/3649850},
doi = {10.1145/3649850},
abstract = {Students often make mistakes in their introductory programming assignments as part of their learning process. Unfortunately, providing custom repairs for these mistakes can require a substantial amount of time and effort from class instructors. Automated program repair (APR) techniques can be used to synthesize such fixes. Prior work has explored the use of symbolic and neural techniques for APR in the education domain. Both types of approaches require either substantial engineering efforts or large amounts of data and training. We propose to use a large language model trained on code, such as Codex (a version of GPT), to build an APR system -- PyDex -- for introductory Python programming assignments. Our system can fix both syntactic and semantic mistakes by combining multi-modal prompts, iterative querying, test-case-based selection of few-shots, and program chunking. We evaluate PyDex on 286 real student programs and compare to three baselines, including one that combines a state-of-the-art Python syntax repair engine, BIFI, and a state-of-the-art Python semantic repair engine for student assignments, Refactory. We find that PyDex can fix more programs and produce smaller patches on average.},
journal = {Proc. ACM Program. Lang.},
month = apr,
articleno = {133},
numpages = {25},
keywords = {AI for programming education, automated program repair, large language models}
}

@inproceedings{10.1145/3627217.3627238,
author = {Singhal, Shreya and Kumar, Viraj},
title = {Creating Thorough Tests for AI-Generated Code is Hard},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627238},
doi = {10.1145/3627217.3627238},
abstract = {Before implementing a function, programmers are encouraged to write a suite of test cases that specify its intended behaviour on several inputs. A suite of tests is thorough if any buggy implementation fails at least one of these tests. We posit that as the proportion of code generated by Large Language Models (LLMs) grows, so must the ability of students to create test suites that are thorough enough to detect subtle bugs in such code. Our paper makes two contributions. First, we demonstrate how difficult it can be to create thorough tests for LLM-generated code by evaluating 27&nbsp;test suites from a public dataset (EvalPlus). Second, by identifying deficiencies in these test suites, we propose strategies for improving the ability of students to develop thorough test suites for LLM-generated code.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {108–111},
numpages = {4},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3613904.3642706,
author = {Nguyen, Sydney and Babe, Hannah McLean and Zi, Yangtian and Guha, Arjun and Anderson, Carolyn Jane and Feldman, Molly Q},
title = {How Beginning Programmers and Code LLMs (Mis)read Each Other},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642706},
doi = {10.1145/3613904.3642706},
abstract = {Generative AI models, specifically large language models (LLMs), have made strides towards the long-standing goal of text-to-code generation. This progress has invited numerous studies of user interaction. However, less is known about the struggles and strategies of non-experts, for whom each step of the text-to-code problem presents challenges: describing their intent in natural language, evaluating the correctness of generated code, and editing prompts when the generated code is incorrect. This paper presents a large-scale controlled study of how 120 beginning coders across three academic institutions approach writing and editing prompts. A novel experimental design allows us to target specific steps in the text-to-code process and reveals that beginners struggle with writing and editing prompts, even for problems at their skill level and when correctness is automatically determined. Our mixed-methods evaluation provides insight into student processes and perceptions with key implications for non-expert Code LLM use within and outside of education.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {651},
numpages = {26},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3627217.3627235,
author = {Venkatesh, Varshini and Venkatesh, Vaishnavi and Kumar, Viraj},
title = {Evaluating Copilot on CS1 Code Writing Problems with Suppressed Specifications},
year = {2023},
isbn = {9798400708404},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627217.3627235},
doi = {10.1145/3627217.3627235},
abstract = {Code writing problems in introductory programming (CS1) courses typically ask students to write simple functions or programs based on detailed natural-language specifications. These details can be leveraged by large language models (LLMs), accessible to students via tools such as GitHub Copilot, to generate solutions that are often correct. CS1 instructors who are unwilling or unable to prohibit such usage must consider variants of traditional code writing problems that align with their learning objectives but are more difficult for LLMs to solve. Since LLMs are sensitive to the level of details in their prompts, it is natural to consider variants where details are progressively trimmed from the specifications of traditional code writing problems, and consequent ambiguities are clarified via examples. We consider an extreme variant, where all natural language is suppressed except for meaningful names of functions and their arguments. We evaluate the performance of Copilot on suppressed specification versions of 153 such problems drawn from the CodeCheck repository. If Copilot initially fails to generate a correct solution, we augment each suppressed specification with as few clarifying examples as possible to obtain a correct solution. Copilot solves 134 problems (87%) with just 0.7 examples on average, requiring no examples in 78 instances. Thus, modifying traditional code-writing problems by merely trimming specification details is unlikely to thwart sophisticated LLMs such as GitHub Copilot.},
booktitle = {Proceedings of the 16th Annual ACM India Compute Conference},
pages = {104–107},
numpages = {4},
keywords = {CS1, code writing, large language models},
location = {Hyderabad, India},
series = {COMPUTE '23}
}

@inproceedings{10.1145/3610969.3611132,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron},
title = {Generative AI in Software Development Education: Insights from a Degree Apprenticeship Programme},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3611132},
doi = {10.1145/3610969.3611132},
abstract = {We describe insights gained from incorporating ChatGPT into assignments for our Software Engineering Degree Apprenticeship programme, including attitudes expressed by the learners and their employers regarding our approach.},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {19},
numpages = {1},
keywords = {Software Engineering, Generative AI, Education, Apprenticeships},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@inproceedings{10.1145/3633083.3633099,
author = {Stone, Irene},
title = {Exploring the Research Gap: Generative AI and Learning of Python Programming among Post-Primary Students},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633099},
doi = {10.1145/3633083.3633099},
abstract = {The introduction of Leaving Certificate Computer Science (LCCS) in Ireland in 2018 signifies a notable advancement in post-primary education. Moreover, developments in generative Artificial Intelligence (GAI) in education, are gaining prominence, yet we do not understand its value or how best to implement it in post-primary educational settings. Despite a growing international body of research in this area, my scoping review highlights that many aspects of these topics have yet to be explored, particularly in the context of post-primary students in Ireland. My study will begin to bridge this gap by exploring how a purposeful sample of LCCS post-primary students in Ireland engage with GAI tools, such as ChatGPT, during their initial experiences learning Python programming. These findings, when approached through the lens of Human-Centred Artificial Intelligence (HCAI), can help enhance pedagogical strategies and lead to improved learning experiences for students.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {51},
numpages = {1},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3639474.3640065,
author = {Tao, Yida and Chen, Wenyan and Ye, Qingyang and Zhao, Yao},
title = {Beyond Functional Correctness: An Exploratory Study on the Time Efficiency of Programming Assignments},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640065},
doi = {10.1145/3639474.3640065},
abstract = {Practical programming assignments are critical parts of programming courses in Computer Science education. Students are expected to translate programming concepts learned from lectures into executable implementations that solve the tasks outlined in the assignments. These implementations are primarily assessed based on their functional correctness, ensuring that students' code produces the expected output when provided with specific inputs.However, functional correctness is not the only metric that evaluates the quality of programs. Runtime efficiency is a metric that is less frequently evaluated in programming courses, yet it holds significant importance in the context of professional software development. To investigate this gap and its potential ramifications, we conducted a large-scale empirical study on the time efficiency of 250 programming assignments that are evaluated solely on functional correctness. The results demonstrate that students' programming assignments exhibit significant variance in terms of execution time. We further identified 27 recurring inefficient code patterns from these assignments, and observed that most of the inefficient patterns can be optimized by automated tools such as PMD, IntelliJ IDEA and ChatGPT. Our findings provide actionable guidelines for educators to enhance the organization and integration of code performance topics throughout the programming course curriculum.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {320–330},
numpages = {11},
keywords = {programming assignment, code performance, tool support},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@article{10.1145/3585060.3585063,
author = {Lopez, Patty},
title = {Reflections on the Design of Systems that Impact Computers and Society},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {51},
number = {3},
issn = {0095-2737},
url = {https://doi.org/10.1145/3585060.3585063},
doi = {10.1145/3585060.3585063},
abstract = {Having spent the past year post-retirement working with my alma mater, New Mexico State University's (NMSU) Computer Science department to broaden computing, increase student engagement, and to improve graduation completion, as well as reflecting on the state of computing in society at large, I thought I'd share some observations. In March of this year, I had the opportunity to participate in the SIGCSE 2022 Technical Symposium. I was struck by Dr. Shaundra Daily's plenary keynote, entitled "Diversifying Computing: Real Change Must Come from Within", and her use of the phrase "navigating systems that were not designed for me" as she described her exploration of STEM as a first-generation college student, as both a dance and an engineering student, and as a graduate student preparing for motherhood lacking flexibility during her pregnancy, no maternity leave, no livable stipend, and a lack of affordable childcare, as well as the coping strategies she needed to develop to deal with academic culture. In my work with NMSU this past spring, co-teaching a problem solving course, my work this fall advising CS students, and my board roles serving on the National Academy of Science, Engineering, and Medicine's Roundtable for Systemic Change in Undergraduate STEM Education co-chairing the "Culture of STEM" workgroup, on the Computing Alliance of Hispanic Serving Institution's (CAHSI) Advisory Board, and on the Computing Research Association for Widening Participation (CRA-WP), co-editing the "Expanding the Pipeline" column, it's clear that system design adversely impacts society in terms of determining not only who gets to participate in the design of computer hardware and software, but also who gets to advance in social and economic mobility. Academic institutions are complex systems in need of an overhaul, by the University of California's academic workers strike for better pay and benefits. The design and commercialization of AI without fully understanding the implications of bias and ethics is inherently a system design problem. The application to everything from AI generated art and images (and how to spot deep fakes), the ability of large language models (LLMs) to create volumes of text generated articles that appear legitimate with the capacity to spread hate and misinformation globally are but just a few examples of the potentially horrific impact to society, because humans cannot work at the pace and scale to validate and/or authenticate them, with few if any meaningful domestic and international laws or policies in place to safeguard us.},
journal = {SIGCAS Comput. Soc.},
month = feb,
pages = {9},
numpages = {1},
keywords = {system design, ethics, diversity, bias}
}

@inproceedings{10.1145/3641555.3705025,
author = {Diaz, Marc and Karp, Dustin and Tuli, Prayuj and Kapoor, Amanpreet},
title = {Edugator: An AI-enabled Tool for Creating and Delivering Interactive Computing Content},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705025},
doi = {10.1145/3641555.3705025},
abstract = {Edugator is a browser-based, AI-enabled tool designed to help instructors of introductory computing courses create and deliver interactive educational content. It streamlines the content authoring process by incorporating generative AI models into both the creation and delivery stages. Instructors can create bespoke interactive computing lessons and programming problems by providing a prompt and a few clicks. They can also author templates and test cases in programming languages such as C++, Java, C, and Python. Additionally, instructors can validate programming problems by running them against an auto-generated solution, allowing them to refine the problems before releasing it to students, preventing misinformation or ambiguity. Students can complete lessons and solve programming problems in a browser-based text editor receiving immediate feedback. They can also interact with a large language model-powered AI chatbot that scaffolds a student on how to approach the problem without giving out solutions. Edugator is built using modern web frameworks and the goal of the tool is to accelerate the adoption of automated assessment tools by minimizing the challenges instructors face with such tools. It also supports Learning Tools Interoperability (LTI), allowing seamless integration with learning management systems (LMS). The demo will provide an overview of Edugator's features, including authoring programming problems and lessons using AI or remixing existing problems obtained from test banks, LTI integration, and AI-chatbot. More information about the tool can be found at https://edugator.app/ and https://github.com/edugatorlabs/resources},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {ai tutor, automated assessment tool, generative ai, introductory programming, learning by doing},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630764,
author = {Wang, Sierra and Mitchell, John and Piech, Chris},
title = {A Large Scale RCT on Effective Error Messages in CS1},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630764},
doi = {10.1145/3626252.3630764},
abstract = {In this paper, we evaluate the most effective error message types through a large-scale randomized controlled trial conducted in an open-access, online introductory computer science course with 8,762 students from 146 countries. We assess existing error message enhancement strategies, as well as two novel approaches of our own: (1) generating error messages using OpenAI's GPT in real time and (2) constructing error messages that incorporate the course discussion forum. By examining students' direct responses to error messages, and their behavior throughout the course, we quantitatively evaluate the immediate and longer term efficacy of different error message types. We find that students using GPT generated error messages repeat an error 23.1% less often in the subsequent attempt, and resolve an error in 34.8% fewer additional attempts, compared to students using standard error messages. We also perform an analysis across various demographics to understand any disparities in the impact of different error message types. Our results find no significant difference in the effectiveness of GPT generated error messages for students from varying socioeconomic and demographic backgrounds. Our findings underscore GPT generated error messages as the most helpful error message type, especially as a universally effective intervention across demographics.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1395–1401},
numpages = {7},
keywords = {cs1, error messages, gpt, llm, randomized control trial},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701934,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Becker, Brett A.},
title = {Exploring Student Reactions to LLM-Generated Feedback on Explain in Plain English Problems},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701934},
doi = {10.1145/3641554.3701934},
abstract = {Code reading and comprehension skills are essential for novices learning programming, and explain-in-plain-English tasks (EiPE) are a well-established approach for assessing these skills. However, manual grading of EiPE tasks is time-consuming and this has limited their use in practice. To address this, we explore an approach where students explain code samples to a large language model (LLM) which generates code based on their explanations. This generated code is then evaluated using test suites, and shown to students along with the test results. We are interested in understanding how automated formative feedback from an LLM guides students' subsequent prompts towards solving EiPE tasks. We analyzed 177 unique attempts on four EiPE exercises from 21 students, looking at what kinds of mistakes they made and how they fixed them. We found that when students made mistakes, they identified and corrected them using either a combination of the LLM-generated code and test case results, or they switched from describing the purpose of the code to describing the sample code line-by-line until the LLM-generated code exactly matched the obfuscated sample code. Our findings suggest both optimism and caution with the use of LLMs for unmonitored formative feedback. We identified false positive and negative cases, helpful variable naming, and clues of direct code recitation by students. For most students, this approach represents an efficient way to demonstrate and assess their code comprehension skills. However, we also found evidence of misconceptions being reinforced, suggesting the need for further work to identify and guide students more effectively.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {575–581},
numpages = {7},
keywords = {eipe, explain in plain english, formative feedback, large language models, llm, misconceptions, qualitative analysis},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inbook{10.1145/3724504.3724622,
author = {Liang, Bohan},
title = {Artificial Intelligence in Language Education: CiteSpace-based Visualisation and Analysis},
year = {2025},
isbn = {9798400711732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3724504.3724622},
abstract = {Over the past five years, the rapid development of generative artificial intelligence (AI) has led to a significant increase in research on AI in language education. This article uses CiteSpace software to conduct a visual analysis of research related to AI in language education from the SCI and SSCI databases over the past five years. The research results indicate that from 2020 to 2024, the number of papers related to AI in language education has been increasing steadily with the improvement of AI technologies. What's more, China, the United States, South Korea, England, and Saudi Arabia are the leading countries in terms of publication volume. Institutions such as the Chinese University of Hong Kong, Education University of Hong Kong, and Indiana University System (including Indiana University Bloomington), etc. have a significant number of publications, and collaborative publications among institutions are the mainstream. Moreover, the keyword co-occurrence graph shows that students’ English learning, large language models, natural language processing technology and deep learning are the foci of scholars' research. Keyword clustering graph and top terms in each cluster indicate that research in this field primarily focuses on English learning, particularly on speech and writing skills, and the psychological factors, learning effect, and learning strategies in the process of AI-assisted language education have also attracted the attention of scholars. Lastly, computational modeling technologies and mobile-assisted language learning are also topics that scholars have discussed extensively. The application of AI in non-English languages education, emotional factors of students and mobile-assisted language education driven by large language models may become hotspots in the future.},
booktitle = {Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence},
pages = {721–725},
numpages = {5}
}

@inproceedings{10.1145/3639474.3640076,
author = {Xue, Yuankai and Chen, Hanlin and Bai, Gina R. and Tairas, Robert and Huang, Yu},
title = {Does ChatGPT Help With Introductory Programming?An Experiment of Students Using ChatGPT in CS1},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640076},
doi = {10.1145/3639474.3640076},
abstract = {Generative AI, notably ChatGPT, has garnered attention in computer science education. This paper presents a controlled experiment that explores ChatGPT's role in CS1 in a classroom setting. Specifically, we aim to investigate the impact of ChatGPT on student learning outcomes and their behaviors when working on programming assignments. Participants were tasked with creating a UML diagram and subsequently implementing its design through programming, followed by a closed-book post-evaluation and a post-survey. All the participants were required to screen-record the whole process. In total, 56 participants were recruited, with 48 successful screen recordings. Participants in the Experimental Group can access ChatGPT 3.5 and other online resources, such as Google and Stack Overflow when creating the UML diagram and programming; however, participants in the Control Group can access all online resources except for ChatGPT (i.e., the only design variable is the access to ChatGPT). Finally, we measured and analyzed participants' learning outcomes through their UML diagram, programming, and post-evaluation scores. We also analyzed the time participants took to complete the tasks and their interactions with ChatGPT and other resources from the screen recordings. After finishing the tasks, student participants also provided their perceptions of using ChatGPT in CS1 through a post-survey.With rigorous quantitative and qualitative analysis, we found that (1) using ChatGPT does not present a significant impact on students' learning performance in the CS1 assignment-style tasks; (2) once using ChatGPT, students' tendency to explore other traditional educational resources is largely reduced (though available) and they tend to rely solely on ChatGPT, and this reliance on ChatGPT did not guarantee enhanced learning performance; (3) the majority of students hold neutral views on ChatGPT's role in CS1 programming but most of them raised concerns about its potential ethical issues and inconsistent performance across different tasks. We hope this study can help educators and students better understand the impact of ChatGPT in CS1 and inspire future work to provide proper guidelines for using ChatGPT in introductory programming classes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {331–341},
numpages = {11},
keywords = {CS education, CS1, generative AI, ChatGPT, OOP},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3613904.3642379,
author = {Hedderich, Michael A. and Bazarova, Natalie N. and Zou, Wenting and Shim, Ryun and Ma, Xinda and Yang, Qian},
title = {A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642379},
doi = {10.1145/3613904.3642379},
abstract = {Cyberbullying harms teenagers’ mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers’ distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students’ and the chatbot’s behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a safe environment. We discuss the design opportunities LLM-Chains offer for empowering teachers and the research opportunities this work opens up.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {668},
numpages = {17},
keywords = {chatbot, cyberbullying, education, large language models, teachers},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3696410.3714620,
author = {Liu, Zheng and Li, Chaofan and Xiao, Shitao and Li, Chaozhuo and Zhang, Chen Jason and Liao, Hao and Lian, Defu and Shao, Yingxia},
title = {Fitting Into Any Shape: A Flexible LLM-Based Re-Ranker With Configurable Depth and Width},
year = {2025},
isbn = {9798400712746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696410.3714620},
doi = {10.1145/3696410.3714620},
abstract = {Large language models (LLMs) provide powerful foundations to perform fine-grained text re-ranking. However, they are often prohibitive in reality due to constraints on computation bandwidth. In this work, we propose a flexible architecture called Matroyshka Re-Ranker, which is designed to facilitate runtime customization of model layers and sequence lengths at each layer based on users' configurations. Consequently, the LLM-based re-rankers can be made applicable across various real-world situations. The increased flexibility may come at the cost of precision loss. To address this problem, we introduce a suite of techniques to optimize the performance. First, we propose cascaded self-distillation, where each sub-architecture learns to preserve a precise re-ranking performance from its super components, whose predictions can be exploited as smooth and informative teacher signals. Second, we design a factorized compensation mechanism, where two collaborative LoRA modules, vertical and horizontal, are jointly employed to compensate for the precision loss resulted from arbitrary combinations of layer and sequence compression. We perform comprehensive experiments using passage and document retrieval datasets from MSMARCO, along with all public datasets from BEIR. In our experiments, Matryoshka Re-Ranker substantially outperforms existing methods, while effectively preserving its superior performance across various compression forms and application scenarios. We have publicly released our method at this https://github.com/FlagOpen/FlagEmbedding repo.},
booktitle = {Proceedings of the ACM on Web Conference 2025},
pages = {3942–3951},
numpages = {10},
keywords = {flexibility, lightweighting, llm-based re-rankers, text retrieval},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3613905.3650868,
author = {Cai, Zhenyao and Park, Seehee and Nixon, Nia and Doroudi, Shayan},
title = {Advancing Knowledge Together: Integrating Large Language Model-based Conversational AI in Small Group Collaborative Learning},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650868},
doi = {10.1145/3613905.3650868},
abstract = {In today’s educational landscape, students learn collaboratively, where students benefit from both peer interactions and facilitator guidance. Prior research in Human-Computer Interaction (HCI) and Computer-Supported Collaborative Learning (CSCL) has explored chatbots and AI techniques to aid such collaboration. However, these methods often depend on predefined dialogues (which limits adaptability), are not based on collaborative learning theories, and do not fully recognize the learning context. In this paper, we introduce an Large Language Model (LLM)-powered conversational AI, designed to enhance small group learning through its advanced language understanding and generation capabilities. We detail the iterative design process, final design, and implementation. Our preliminary evaluation indicates that the bot performs as designed but points to considerations in the timing of interventions and bot’s role in discussions. The evaluation also reveals that learners perceive the bot’s tone and behavior as important for engagement. We discuss design implications for chatbot integration in collaborative learning and future research directions.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {37},
numpages = {9},
keywords = {AI facilitator, Collaborative Learning, Human-AI Collaboration},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3587102.3588805,
author = {Reeves, Brent and Sarsa, Sami and Prather, James and Denny, Paul and Becker, Brett A. and Hellas, Arto and Kimmel, Bailey and Powell, Garrett and Leinonen, Juho},
title = {Evaluating the Performance of Code Generation Models for Solving Parsons Problems With Small Prompt Variations},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588805},
doi = {10.1145/3587102.3588805},
abstract = {The recent emergence of code generation tools powered by large language models has attracted wide attention. Models such as OpenAI Codex can take natural language problem descriptions as input and generate highly accurate source code solutions, with potentially significant implications for computing education. Given the many complexities that students face when learning to write code, they may quickly become reliant on such tools without properly understanding the underlying concepts. One popular approach for scaffolding the code writing process is to use Parsons problems, which present solution lines of code in a scrambled order. These remove the complexities of low-level syntax, and allow students to focus on algorithmic and design-level problem solving. It is unclear how well code generation models can be applied to solve Parsons problems, given the mechanics of these models and prior evidence that they underperform when problems include specific restrictions. In this paper, we explore the performance of the Codex model for solving Parsons problems over various prompt variations. Using a corpus of Parsons problems we sourced from the computing education literature, we find that Codex successfully reorders the problem blocks about half of the time, a much lower rate of success when compared to prior work on more free-form programming tasks. Regarding prompts, we find that small variations in prompting have a noticeable effect on model performance, although the effect is not as pronounced as between different problems.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {299–305},
numpages = {7},
keywords = {CS1, GPT-3, GitHub, ML, academic integrity, ai, artificial intelligence, chatgpt, code generation, code writing, codex, computer programming, copilot, deep learning, generative ai, introductory programming, large language models, machine learning, natural language processing, neural networks, novice programming, openAI},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3722237.3722245,
author = {Fan, Sun and Peng, Lu and Wu, Shaofeng and Yu, Xingmu},
title = {ChatGPT Empowers Higher Education: —Research Topics Hotspots and Quantitative Visual Analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722245},
doi = {10.1145/3722237.3722245},
abstract = {In order to deeply explore the current research hotspots and development trends of ChatGPT generative artificial intelligence in empowering higher education applications, this study conducted a detailed analysis of 178 articles related to ChatGPT+higher education in the knowledge Resource Database. By using software tools such as Power BI, SPSS, and Excel, this study conducted a visual analysis of core authors, research funding, research topics, author institutions, discipline areas, and related indicators in the literature. The aim of the study is to analyze the current status of ChatGPT research in higher education applications and to explore the hot issues surrounding ChatGPT empowerment in higher education.The study points out that current research in higher education in the era of artificial intelligence mainly focuses on introducing ChatGPT, the characteristics and connotations of large language models, and discussing the opportunities, challenges, coping strategies, and digital transformation research they bring. However, there is still a lack of in-depth exploration of the application of ChatGPT and other technologies in education, especially in areas such as personalized learning and precision teaching, the integration of virtual and actual teaching spaces, intelligent teaching facilities and resources, human-computer collaborative teaching methods, and interdisciplinary innovative research methods.We should actively respond to the opportunities and challenges brought by intelligent tools such as ChatGPT to higher education, and comprehensively and deeply explore how to integrate ChatGPT into key areas of digital education, including teaching design, teaching resource development, teaching organization and implementation, teaching evaluation and reflection, learning and personal knowledge management, innovation team building, and enhancing the digital literacy and professional capabilities of teachers and students. In addition, the impact of the application of ChatGPT and other technologies in education on educational equity, and how to ensure that all students can benefit from it through reasonable design and use, should also be of concern. The goal of this study is to further promote and drive the digital transformation of higher education by building a brand new higher education ecosystem based on ChatGPT.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {38–45},
numpages = {8},
keywords = {ChatGPT, Digital transformation, Empowers, higher education, hot topics, human-machine collaborative intelligence, trends, visualization},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3633053.3633057,
author = {Petrovska, Olga and Clift, Lee and Moller, Faron and Pearsall, Rebecca},
title = {Incorporating Generative AI into Software Development Education},
year = {2024},
isbn = {9798400709326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633053.3633057},
doi = {10.1145/3633053.3633057},
abstract = {This paper explores how Generative AI can be incorporated into software development education. We present examples of formative and summative assessments, which explore various aspects of ChatGPT, including its coding capabilities, its ability to construct arguments as well as ethical issues of using ChatGPT and similar tools in education and the workplace. Our work is inspired by the insights from surveys that show that the learners on our Degree Apprenticeship Programme have a great interest in learning about and exploiting emerging AI technology. Similarly, our industrial partners have a clear interest for their employees to be formally prepared to use GenAI in their software engineering roles. In this vein, it is proposed that embedding the use of GenAI tools in a careful and creative way - by developing assessments which encourage learners to critically evaluate AI output - can be beneficial in helping learners understand the subject material being taught without the risk of the AI tools “doing the homework”.},
booktitle = {Proceedings of the 8th Conference on Computing Education Practice},
pages = {37–40},
numpages = {4},
keywords = {apprenticeship, assessment, education, generative AI, software engineering},
location = {Durham, United Kingdom},
series = {CEP '24}
}

@inproceedings{10.1145/3711403.3711428,
author = {Guo, Peirong and Zhang, Qi and Tian, Chunwei and Xue, Wanli and Feng, Xiaocheng},
title = {Digital Human Techniques for Education Reform},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711428},
doi = {10.1145/3711403.3711428},
abstract = {The rapid evolution of artificial intelligence, big data, and generative AI models has ushered in significant transformations across various sectors, including education. Digital Human Technique, an innovative technology grounded in advanced computer science and artificial intelligence, is reshaping educational paradigms by enabling virtual humans to simulate human behavior, express emotions, and interact with users. This paper explores the application of Digital Human Technique in education reform, focusing on creating immersive, intelligent classroom experiences that foster meaningful interactions between teachers and students. We define Digital Human Technique and delve into its key technical components such as character modeling and rendering, natural language processing, computer vision, and augmented reality technologies. Our methodology involves analyzing the role of educational digital humans created through these technologies, assessing their impact on educational processes, and examining various application scenarios in educational reform. Results indicate that Digital Human Technique significantly enhances the learning experience by enabling personalized teaching, increasing engagement, and fostering emotional connections. Educational digital humans serve as virtual teachers, interactive learning aids, and facilitators of emotional interaction, effectively addressing the challenges of traditional educational methods. They also promote a deeper understanding of complex concepts through simulated environments and interactive digital content.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {173–178},
numpages = {6},
keywords = {Digital Human Techniques, Education Reform},
location = {
},
series = {ICETM '24}
}

@proceedings{10.1145/3664647,
title = {MM '24: Proceedings of the 32nd ACM International Conference on Multimedia},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to welcome you to Melbourne, Australia for ACM Multimedia 2024, the 32nd ACM International Conference on Multimedia. ACM Multimedia is the premier international conference series in the area of multimedia within the field of computer science. Since 1993, ACM Multimedia has been bringing together worldwide researchers and practitioners from academia and industry to present their innovative research and to discuss recent advancements in multimedia.For the first time since the end of the COVID-19 pandemic, this year's conference returns to the Asia-Pacific region and resumes as a full-fledged, inperson event. With no travel restrictions or significant visa challenges, we are excited to once again experience the warmth of face-to-face gatherings, where we can reconnect with colleagues and friends.The enthusiasm and support from the community have been incredible. ACM Multimedia 2024 received over 4,300 main conference submissions, accepting more than 1,100 papers (please refer to the TPC Chairs' message for details). In addition, 10 Grand Challenges were selected from 22 submissions, 18 workshops from 30 submissions, and 8 tutorials from 13 proposals. We've prepared an exciting five-day program: workshops, grand challenges, and tutorials will be held on the 1st and 5th days, with the main conference occupying the middle three days. All accepted papers will be accessible online prior to the conference, and we are working to ensure proceedings are available through the ACM Digital Library around the conference period.This year's conference features three distinguished academic keynote speeches, several prestigious SIGMM award talks, a panel discussion on Generative AI in Multimedia, a refreshed Brave New Idea (BNI) session, and our inaugural industry program.The opening keynote will be delivered by Prof. Pascale Fung from HKUST, a Fellow of AAAI, ACL, and IEEE. Her talk will explore the pressing topic of Agents in the Large Language Model (LLM) Era. Prof. Judy Kay from the University of Sydney, a renowned expert in HCI, user modeling, and ubiquitous computing, will give the second keynote on how to empower individuals to harness and control their multimodal data. The final academic keynote will be presented by Prof. Jiebo Luo from the University of Rochester, a Fellow of ACM, AAAI, IEEE, SPIE, and IAPR, as well as a member of Academia Europaea and the US National Academy of Inventors. He will discuss leveraging LLMs as social multimedia analysis engines.This year, we continue using OpenReview to ensure an open and transparent review process. Thanks to the exceptional efforts of the technical program committee, every paper received at least three reviews before the review announcement. The BNI track has also revamped its review process to align with the main conference, promoting visionary papers. Additionally, we are excited to introduce the industry program to ACM Multimedia for the first time, featuring industry keynote speeches, expert talks, and demonstrations (please refer to the industry chairs' message for further details).We are also committed to making the conference inclusive and accessible. To support students with financial constraints, we have awarded travel grants to at least 25 students from the ACM Multimedia 2024 budget, with an additional 20+ students receiving SIGMM travel grants. Over 20 local students have also been recruited as volunteers, benefiting from complimentary registration. Furthermore, we have arranged childcare facilities to accommodate attendees with young children. A welcome reception will take place on the 2nd day of the conference, followed by a gala dinner on the 3rd day, featuring exciting cultural performances.We hope you find this year's program engaging and thought-provoking and that it offers valuable opportunities to exchange ideas with fellow researchers and practitioners from around the globe. We also encourage you to take time to explore the beautiful city of Melbourne and its surrounding regions.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3657604.3664671,
author = {Wang, Yuchen and Guo, Shangxin and Ling, Lin and Tan, Chee Wei},
title = {Nemobot: Crafting Strategic Gaming LLM Agents for K-12 AI Education},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664671},
doi = {10.1145/3657604.3664671},
abstract = {Artificial intelligence (AI) permeates modern society and is poised for further integration across various domains. However, there exists a notable deficiency in equipping K-12 students with foundational AI understanding. This paper introduces a novel learning framework that leverages large language models (LLMs) and strategic gaming to teach K-12 students about the inner workings of AI. The framework consists of a chatbot programming and testing IDE that enables K-12 students to construct AI from scratch, engage in strategic gameplay to generate instant training data, and improve the AI heuristics with a data-driven learning mechanism. With a tiered curriculum catering to diverse proficiency levels and fostering synchronous collaboration, this framework efficiently adapts learning experiences to suit various groups of students, thereby facilitating learning at scale. Preliminary experiments validate the feasibility and vast potential of this approach, promising to revolutionize AI education in K-12 education.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {393–397},
numpages = {5},
keywords = {ai-assisted programming, chatbot programming, collaborative learning, gamification approach, generative ai, k-12 education, large language models(llms)},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3702163.3702185,
author = {Arones, Maritza and Chauca, Carmen and Phun-Pat, Yn\'{e}s and Curro-Urbano, Olga and De La Cruz-Arones, Maritza},
title = {Heutagogical Learning and the Use of ChatGPT in the pre-professional practice of university students},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702185},
doi = {10.1145/3702163.3702185},
abstract = {The objective of the study was to establish the relationship between heutagogical learning and the use of chatGPT in the pre-professional practice of university students of the professional career of Educational Sciences in Mathematics and Computer Science at the National University “San Luis Gonzaga”. The Self-Learning Strategies Questionnaire (CETA) was used for university students, which considers six dimensions: Extension Strategies, Collaboration Strategies, Conceptualization Strategies, Planning Strategies, Exam Preparation Strategies and Participation Strategies. The sample was made up of students enrolled in the IX and X semester of the aforementioned professional career. Through univariate correlation analysis and applying Spearman's Rho test (0.587&gt;0.344, p&lt;0.05), a significant correlation between the variables is confirmed, highlighting the importance of the self-directed approach in the training of educators supported in the use from chatGPT. Additionally, specific strategies, such as outreach, collaboration, conceptualization, planning, test preparation, and participation, were found to be related to preprofessional practice success. Consequently, it is recommended to actively promote heutagogical learning and the application of these strategies in the training of educators.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {155–160},
numpages = {6},
keywords = {chatGPT, heutagogical learning, learning strategy and pre-professional practice},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3641554.3701960,
author = {Sanchez, Edwin Antonio and Zheng, Muwei and Bishop, Matt and Zou, Xukai},
title = {Case Study 2: Mapping between an E-Voting Curriculum and the DHS/NSA CAE Knowledge Units},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701960},
doi = {10.1145/3641554.3701960},
abstract = {To become a DHS/NSA Center of Academic Excellence in Cyber Defense (CAE-CD), academic institutions must satisfy several specific Knowledge Units (KUs). How they achieve this is up to the institutions. In this case study, we follow the methodology of an earlier work to demonstrate how key parts of an electronic voting (E-voting)-oriented cybersecurity curriculum, proposed by Hostler et al. [4] in 2021, maps into the DHS/NSA KUs supporting the CAE-CD designation, from two aspects: E-voting principle based topics, i.e., from theory and a plug-and-play e-voting system's composing components, i.e., from practice. We grouped CAE-CD KUs into those required as prerequisites, closely related, related/supported, and not covered by the E-voting curriculum. Teachers can then choose which KUs they will use and teach using only the parts of the E-voting-oriented curriculum they deem relevant, and in a depth they find appropriate to their educational objectives, while meeting the requirements of the selected KUs. We conclude with a discussion of how LLMs (Large Language Models) and quantum computing might be added to the E-voting-oriented curriculum.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1022–1028},
numpages = {7},
keywords = {cae-cd, cybersecurity curriculum, cybersecurity education, electronic voting system},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649217.3653582,
author = {Smith, David H. and Zilles, Craig},
title = {Code Generation Based Grading: Evaluating an Auto-grading Mechanism for "Explain-in-Plain-English" Questions},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653582},
doi = {10.1145/3649217.3653582},
abstract = {Comprehending and conveying the purpose of code is often cited as being a key learning objective within introductory programming courses. To address this objective, "Explain in Plain English'' questions, where students are shown a segment of code and asked to provide an abstract description of the code's purpose, have been adopted. However, given EiPE questions require a natural language response, they often require manual grading which is time-consuming for course staff and delays feedback for students. With the advent of large language models (LLMs) capable of generating code, responses to EiPE questions can be used to generate code segments, the correctness of which can then be easily verified using test cases. We refer to this approach as "Code Generation Based Grading'' (CGBG) and in this paper we explore its agreement with human graders using EiPE responses from past exams in an introductory programming course taught in Python. Overall, we find that all CGBG approaches achieve moderate agreement with human graders with the primary area of disagreement being its leniency with respect to low-level and line-by-line descriptions of code.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {171–177},
numpages = {7},
keywords = {auto-grading, eipe, gpt-4, large language models},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.5555/3721488.3721591,
author = {Ito, Shunichiro and Kochigami, Kanae and Kanda, Takayuki},
title = {A Robot Dynamically Asking Questions in University Classes},
year = {2025},
publisher = {IEEE Press},
abstract = {We developed a robot that dynamically asks questions after listening to a lecture in university group classes to enhance students' learning. Based on interview results with ten professors, we designed our robot to let professors choose when a robot asks questions, ask various kinds of questions by letting professors choose question types, and ask questions dynamically without sharing them with professors in advance. The prepared question types include such as clarification questions, which are fact-based questions about a lecture, and thought-provoking questions, which activate students' critical thinking. We expanded them into eight sub-categories of questions that the most common types that are likely to emerge in classrooms. Leveraging large language models (LLMs), based on lecture transcripts, we developed a robot system that generates questions in the eight sub-categories and yields 0.93 classification accuracy toward human coding results. We also conducted a case study with our developed robot in four university lectures. In these lectures that involved our robot, the professors often asked reasoning questions and criticism questions, and the students showed engagement with the robot-professor dialogues. Interviews with 20 students revealed that the robot's questions contributed to the classes by helping the students reflect on the lectures and gain new perspectives. The professors also recognized some benefits of the robot, perceiving its presence as a question facilitator, a mood maker, a communication tool as well as a motivator to prepare more diligently for their own lectures.},
booktitle = {Proceedings of the 2025 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {839–848},
numpages = {10},
keywords = {education, group class, large language models, question, social robotics},
location = {Melbourne, Australia},
series = {HRI '25}
}

@inproceedings{10.1145/3649217.3653557,
author = {Farinetti, Laura and Canale, Lorenzo},
title = {Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653557},
doi = {10.1145/3649217.3653557},
abstract = {Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking.This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion.The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {401–407},
numpages = {7},
keywords = {chatbot development, creativity and critical thinking, database education, information retrieval, langchain framework, large language models, natural language interfaces},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3660650.3660657,
author = {Roberts, Jordan and Mohamed, Abdallah},
title = {Generative AI in CS Education: Literature Review through a SWOT Lens},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660657},
doi = {10.1145/3660650.3660657},
abstract = {The rapid growth of generative artificial intelligence (AI) models introduced challenges for educators, students and administrators across the academic sphere related to how to manage and regulate these tools. While some oppose their use, many researchers have begun to approach the topic of educational AI use from a different perspective. Despite being in its early stages; this field of research has produced notable insights into the capabilities and limitations of models like ChatGPT. This paper utilizes a SWOT analysis framework to analyze and consolidate existing literature, with a specific focus on Computer Science education. Through the analysis of this literature, we have created a set of use cases and guidelines to aid in the future development of strategies and tools within this field. Our findings indicate that while some concerns are valid, such as AI's ability to generate plagiarized work, we identified several promising avenues and opportunities for careful integration of this technology into education.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {10},
numpages = {6},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3649409.3691092,
author = {de Miranda, Fabio and Ferrao, Rafael Corsi and Soler, Diego Pavan and Vieira Graglia, Marcelo Augusto},
title = {LLM-based Individual Contribution Summarization in Software Projects},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691092},
doi = {10.1145/3649409.3691092},
abstract = {This work in progress is about preliminary results in using a Large Language Model (LLM) to summarize individual student contributions in open-ended software projects. Projects for industry clients are good real-world learning opportunities. Though, if the scope is open and defined based on external clients' needs, each group's project will look unique, what makes a challenge for grading and regular feedback. Distributed code version control systems such as Git and resources such as Git classroom help, but it is still burdensome to have professors and TAs looking at the repositories with a frequency that enables useful, timely feedback for the students. We prototyped a method of summarizing each student's contributions to a project's Git repository using an LLM, indicating how to preprocess and break down repository data in order to get better responses from the system. Each student's contributions were extracted using Pydriller. This technique was tested during a 3-week full-time software development sprint in a class of 28 students. Preliminary results indicate a general agreement of students and faculty with the synthesized summaries and an increase in students' awareness of individual responsibilities within the teams and an improvement in engagement among less active members.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {307–308},
numpages = {2},
keywords = {project assessment, software engineering education, teamwork},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.5555/3665464.3665469,
author = {Manley, Eric D. and Urness, Timothy and Migunov, Andrei and Reza, Md. Alimoor},
title = {Examining Student Use of AI in CS1 and CS2},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {The launch of ChatGPT in November 2022 marked a seismic disruption to many disciplines and industries, including higher education. For the first time, students everywhere have widely available access to a Large Language Model (LLM) capable of generating content - including solutions to programming assignments in CS1 and CS2 - that can pass as the work of a high-achieving student while making traditional plagiarism-detection obsolete. This has spurred various responses in higher education, including a shift to more in-class and unplugged assessments. At the same time, LLMs are transforming the way that many people work, including professional software developers, and students similarly might be able to use them to enhance their learning. In this paper, we report on our experiences with a permissive policy towards the use of ChatGPT and other artificial intelligence (AI) tools for assisting students with their programming assignments in CS1 and CS2 courses in the Spring 2023 semester. Students were allowed to use these tools however they wished as long as they submitted a form which included a transcript of their chat and a reflection on what they learned, if anything, through the interaction. We found that students largely approached the AI in positive ways and that they seemed to genuinely learn from the experience. We also document some things that did not go well and that remain challenges to using AI in programming courses, along with our recommendations on how these might be dealt with in the future.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {41–51},
numpages = {11}
}

@inproceedings{10.1145/3626253.3635483,
author = {Lee Solano, Lorenzo and Renzella, Jake and Vassar, Alexandra},
title = {DCC Sidekick: Helping Novices Solve Programming Errors Through a Conversational Explanation Interface},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635483},
doi = {10.1145/3626253.3635483},
abstract = {Students in introductory computing courses often lack the experience required to effectively identify and resolve errors in their code. For such students, Programming Error Messages (PEMs) are often the first indication of an error, and could provide valuable debugging guidance. However, in many cases, such as with standard C compiler implementations, PEMs are largely unsuitable for novices. Confusing, misleading, and filled with terse language and jargon, these messages instead act as an additional source of difficulty.In this paper, we present DCC Sidekick, which integrates the Debugging C Compiler (DCC) with a Large Language Model (LLM) in a web-based dashboard to produce contextual, accurate guidance conducive to student learning. This dashboard is directly accessible from the output of the compiler, and provides a bird's-eye-view of the program source, compiler output, and a conversational AI interface to help unravel cryptic error messages. We aim to deploy DCC Sidekick to a C-based CS1 cohort at a large higher education institution to investigate how novice students utilise the conversational explanation interface during debugging activities. In this work, we present our experience designing and building DCC Sidekick.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1714–1715},
numpages = {2},
keywords = {ai in education, compiler error messages, cs1, error message enhancement, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.1145/3736580,
author = {Wu, Tong and Zhu, Jinhua and Zhou, Wengang and Li, Houqiang},
title = {RESIST: Rationale-Enhanced and Reward Model-Based End-to-End Social Influence Dialogue System},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3736580},
doi = {10.1145/3736580},
abstract = {Developing proactive social influence dialogue systems presents a significant challenge, particularly in non-cooperative scenarios where the system's goals may conflict with those of the user. Traditional methods often focus on training models to plan dialogue strategies, but since human strategies are often sub-optimal, relying solely on manually collected data can be problematic. While large language models (LLMs) facilitate the generation of high-quality synthetic dialogues, their effectiveness in strategic dialogue under zero-shot or few-shot conditions is inconsistent. To address these issues, we propose a training framework applicable to multiple social influence dialogue tasks, named Rationale-Enhanced and Reward Model-Based End-to-End Social Influence Dialogue System (RESIST). To streamline the dialogue system development, we first use existing datasets to prompt a teacher LLM for generating “chain-of-thought” rationales, which are then used to enrich the data and enable supervised fine-tuning (SFT) of the model. Next, we train a reward model by ranking the fine-tuned model's outputs, thereby deriving task-specific preferences without manually constructing scalar rewards. Finally, we apply reinforcement learning to further refine the system, optimizing dialogue strategies and responses according to specific tasks and conversational contexts. Experimental results on three social influence tasks demonstrate the effectiveness and adaptability of our training approach. In terms of task goal completion, RESIST outperforms baseline models and even exceeds the performance of ChatGPT-driven prompt-based policy planning methods in both efficiency and effectiveness. Additionally, we introduce strategic proactivity as a novel evaluation metric, enabling us to analyze how RESIST training influences the proactive traits of dialogue agents, with a particular focus on the personality tendencies of smaller-scale language models during task execution. Experimental findings indicate that RESIST enhances the strategic proactivity of language models, aligning them more closely with task requirements. The source code will be made publicly available upon publication.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = may,
keywords = {Proactive dialogue system, Social influence, Large language model, Reinforcement learning}
}

@inproceedings{10.1145/3600100.3626262,
author = {Berger, Markus and Ploennigs, Joern},
title = {ArchiGuesser – Teaching Architecture Styles using Generative AI},
year = {2023},
isbn = {9798400702303},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600100.3626262},
doi = {10.1145/3600100.3626262},
abstract = {Generative AIs are opening new possibilities to create content from text, speech, and images based on simple input prompts. Users use this to improve their productivity when summarizing knowledge, templating communication, and inspiring their creativity. But, can it also be used to teach, e.g. about our architectural history? With this demo we are exploring this question. We created an educational game that combines various AI technologies from large language models and image generation to computer vision, in order to serve a single purpose: Teach users about architecture in an entertaining way. We wanted to enable students to explore and learn the diversity of our architectural history in a playful and exploratory way and at the same time experience and understand what current AI technologies can achieve.},
booktitle = {Proceedings of the 10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {284–285},
numpages = {2},
location = {Istanbul, Turkey},
series = {BuildSys '23}
}

@inproceedings{10.1145/3613944.3613946,
author = {Qureshi, Basit},
title = {ChatGPT in Computer Science Curriculum Assessment: An analysis of Its Successes and Shortcomings},
year = {2023},
isbn = {9798400700415},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613944.3613946},
doi = {10.1145/3613944.3613946},
abstract = {The application of Artificial intelligence for teaching and learning in the academic sphere is a trending subject of interest in computing education. ChatGPT, as an AI-based tool, provides various advantages, such as heightened student involvement, cooperation, accessibility, and availability. This paper addresses the prospects and obstacles associated with utilizing ChatGPT as a tool for learning and assessment in undergraduate Computer Science curriculum in particular to teaching and learning fundamental programming courses. Students having completed the course work for a Data Structures and Algorithms (a sophomore-level course) participated in this study. Two groups of students were given programming challenges to solve within a short period of time. The control group (group A) had access to textbooks and notes of programming courses, however, no Internet access was provided. Group B students were given access to ChatGPT and were encouraged to use it to help solve the programming challenges. The challenge was conducted in a computer lab environment using Programming Contest Control (PC2) environment which is widely used in ACM International Collegiate Programming Contest (ICPC). Each team of students addresses the problem by writing executable code that satisfies a certain number of test cases. Student teams were scored based on their performance in terms of the number of successfully passed test cases. Results show that students using ChatGPT had an advantage in terms of earned scores, however, there were inconsistencies and inaccuracies in the submitted code consequently affecting the overall performance. After a thorough analysis, the paper’s findings indicate that incorporating AI in higher education brings about various opportunities and challenges. Nonetheless, universities can efficiently manage these apprehensions by adopting a proactive and ethical stance toward the implementation of such tools.},
booktitle = {Proceedings of the 2023 9th International Conference on E-Society, e-Learning and e-Technologies},
pages = {7–13},
numpages = {7},
keywords = {Academic assessment, ChatGPT, Data Structures and Algorithms, programming concepts},
location = {Portsmouth, United Kingdom},
series = {ICSLT '23}
}

@inproceedings{10.1145/3707292.3707389,
author = {Li, Yanjun and Yang, Ruiting and Guo, Donghao and Song, Yu},
title = {Research on the Construction of Digital Knowledge Graphs Based on Resources of National First-Class Undergraduate Programs},
year = {2025},
isbn = {9798400707308},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3707292.3707389},
doi = {10.1145/3707292.3707389},
abstract = {[Purpose/Significance]: The digitalization of education is an essential path to advancing higher education. The construction of knowledge graphs is a key approach to achieving the digitalization and intelligence of education. [Method/Process]: This paper leverages the rich video resources of existing national first-class undergraduate programs and, based on the teaching orientations of different universities, independently designs customized ontologies and extraction principles. These are then integrated into the LLM knowledge graph builder to ensure the hierarchical structure of the overall course framework. The course video content is transformed into text form, and large language models (LLMS) and word segmentation tools are used for core content extraction, text cleaning, and lexical analysis. The structured text is then converted into SPO (Subject-Predicate-Object) triplets database. [Results/Conclusions]: Finally, the database is imported into the LLM knowledge graph builder, which is pre-configured with extraction rules. It will automatically generate the knowledge graph. After the text is imported into the LLM knowledge graph builder, it will be manually checked to ensure it better meets the actual needs of the students. [Innovation/Limitations]: The research team plans to apply the knowledge graph to train a specialized knowledge-based Q&amp;A assistant. This will support students' understanding and self-assessment of knowledge points in an online learning community. Student feedback will be used to improve and enrich the knowledge graph. Compared to existing methods, this approach better aligns with the constantly evolving digital teaching resources available online, offering more comprehensive and higher-level automation.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Intelligent Information Processing},
pages = {353–359},
numpages = {7},
keywords = {Knowledge graph, course resources, intelligent Q&amp;A, ontology construction, personalized learning},
location = {
},
series = {AIIIP '24}
}

@inproceedings{10.1145/3701625.3701684,
author = {Oran, Ana Carolina and Montenegro, Let\'{\i}cia Braga and Schuster, Hellmut Alencar and Duarte, Jos\'{e} Carlos and Silva, Williamson and Lima, Rayfran Rocha},
title = {Integrating ChatGPT in Project Management Education: Benefits and Challenges in the Academic Environment},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701625.3701684},
doi = {10.1145/3701625.3701684},
abstract = {CONTEXT: Teaching project management is complex, and students often do not feel engaged or motivated. Professors can use many initiatives to improve the teaching and learning process. Tools like ChatGPT, when integrated into education, have generated considerable interest due to their potential to enrich students’ learning experiences. GOAL: This paper analyzes the impacts of using ChatGPT as a complementary tool in teaching Project Management in the Software Engineering course, highlighting its benefits and challenges. METHOD: We performed an exploratory study to identify the effects of using ChatGPT in teaching project management, evaluating learning, productivity, teamwork, student perceptions, and future expectations. RESULTS: The results indicate that ChatGPT contributed to improving content comprehension, developing critical skills, accelerating production, improving collaboration and communication, and increasing student engagement. However, challenges related to misuse and dependence on the tool were also identified. CONCLUSION: The integration of ChatGPT in teaching project management has shown promise, promoting a richer and more collaborative learning experience. The insights obtained provide directions for future implementations and research on the use of AI in project management education.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Software Quality},
pages = {596–604},
numpages = {9},
keywords = {Project management education, Software project management, ChatGPT, AI-assisted learning, Software engineering},
location = {
},
series = {SBQS '24}
}

@inproceedings{10.1145/3545945.3569785,
author = {MacNeil, Stephen and Tran, Andrew and Hellas, Arto and Kim, Joanne and Sarsa, Sami and Denny, Paul and Bernstein, Seth and Leinonen, Juho},
title = {Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569785},
doi = {10.1145/3545945.3569785},
abstract = {Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations -- a line-by-line explanation, a list of important concepts, and a high-level summary of the code -- were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {931–937},
numpages = {7},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3702163.3702432,
author = {Zhang, Mengchen and Feng, Xiang},
title = {Automated Annotation of Academic Emotion Intensity in Online Learning Comment Texts: A BWS Method Based on LLMs},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702432},
doi = {10.1145/3702163.3702432},
abstract = {Academic emotions significantly impact learning processes and student performance, with a recent trend towards automated measurement for their types and intensity. However, manual annotation methods for large-scale training data required by modeling face issues of time consumption and high cost. The Best Worst Scaling (BWS) methodology enhances the reliability of intensity annotation, while Large Language Models (LLMs) offer advantages in understanding academic emotions across diverse contexts. Combining the BWS and LLMs in academic emotion intensity annotation, this study aims to address the challenge of data annotation in measuring academic emotion intensity in online learning. We choose three widely recognized LLMs to complete the BWS annotation tasks separately, then calculate the consistency and conduct statistical analysis. Results indicate that the consistency of the three LLMS in identifying emotion intensity in nine academic emotions was above 0.750, with a total of 0.865 in 4569 comment texts. The perception of emotion intensity by the LLMs closely resembles that of human cognition and responds to the context of online learning, enabling them to effectively substitute for humans in performing large-scale annotation tasks.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {317–323},
numpages = {7},
keywords = {Academic Emotion Intensity, Automated Annotation, Best Worst Scaling (BWS), Online Learning},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3626252.3630822,
author = {Taylor, Andrew and Vassar, Alexandra and Renzella, Jake and Pearce, Hammond},
title = {dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630822},
doi = {10.1145/3626252.3630822},
abstract = {In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1314–1320},
numpages = {7},
keywords = {ai in cs1, ai in education, compiler error messages, cs1, debugging, error message enhancement, generative ai, large language models, programming error messages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3593342.3593360,
author = {Rajabi, Parsa and Taghipour, Parnian and Cukierman, Diana and Doleck, Tenzin},
title = {Exploring ChatGPT’s impact on post-secondary education: A qualitative study},
year = {2023},
isbn = {9798400707896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593342.3593360},
doi = {10.1145/3593342.3593360},
abstract = {As Chat Generative Pre-trained Transformer (ChatGPT) gains traction, its impact on post-secondary education is increasingly being debated. This qualitative study explores the perception of students and faculty members at a research university in Canada regarding ChatGPT’s use in a post-secondary setting, focusing on how it could be incorporated and what ways instructors can respond to this technology. We present the summary of a discussion that took place in a two-hour focus group session with 40 participants from the computer science and engineering departments, and highlight issues surrounding plagiarism, assessment methods, and the appropriate use of ChatGPT. Findings suggest that students are likely to use ChatGPT, but there is a need for specific guidelines, more classroom assessments, and mandatory reporting of ChatGPT use. The study contributes to the emergent research on ChatGPT in higher education and emphasizes the importance of proactively addressing challenges and opportunities associated with ChatGPT adoption and use.},
booktitle = {Proceedings of the 25th Western Canadian Conference on Computing Education},
articleno = {9},
numpages = {6},
keywords = {post-secondary, higher education, education, conversational AI, assessment, ChatGPT, Artificial Intelligence in education},
location = {Vancouver, BC, Canada},
series = {WCCCE '23}
}

@inproceedings{10.1145/3636555.3636922,
author = {Samadi, Mohammad Amin and Jaquay, Spencer and Lin, Yiwen and Tajik, Elham and Park, Seehee and Nixon, Nia},
title = {Minds and Machines Unite: Deciphering Social and Cognitive Dynamics in Collaborative Problem Solving with AI},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636922},
doi = {10.1145/3636555.3636922},
abstract = {We investigated the feasibility of automating the modeling of collaborative problem-solving skills encompassing both social and cognitive aspects. Leveraging a diverse array of cutting-edge techniques, including machine learning, deep learning, and large language models, we embarked on the classification of qualitatively coded interactions within groups. These groups were composed of four undergraduate students, each randomly assigned to tackle a decision-making challenge. Our dataset comprises contributions from 514 participants distributed across 129 groups. Employing a suite of prominent machine learning methods such as Random Forest, Support Vector Machines, Naive Bayes, Recurrent and Convolutional Neural Networks, BERT, and GPT-2 language models, we undertook the intricate task of classifying peer interactions. Notably, we introduced a novel task-based train-test split methodology, allowing us to assess classification performance independently of task-related context. This research carries significant implications for the learning analytics field by demonstrating the potential for automated modeling of collaborative problem-solving skills, offering new avenues for understanding and enhancing group learning dynamics.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {885–891},
numpages = {7},
keywords = {Artificial Intelligence, CPS, Learning Analytics, Machine Learning, NLP},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3641554.3701913,
author = {Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh and Tamilselvam, Srikanth},
title = {Design and Evaluation of an AI-Assisted Grading Tool for Introductory Programming Assignments: An Experience Report},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701913},
doi = {10.1145/3641554.3701913},
abstract = {In a typical introductory programming course, grading student-submitted programs involves an autograder which compiles and runs the programs and tests their functionality with predefined test cases, with no attention to the source code. However, in an educational setting, grading based on inspection of the source code is required for two main reasons (1) awarding partial marks to 'partially correct' code that may be failing the testcase check (2) awarding marks (or penalties) based on source code quality or specific criteria that the instructor may have laid out in the problem statement (e.g. 'implement sorting using bubble-sort'). However, grading based on studying the source code can be highly time consuming when the course has a large enrollment. In this paper we present the design and evaluation of an AI Assistant for source code grading, which we have named TA Buddy. TA Buddy is powered by Code Llama, a large language model especially trained for code related tasks, which we fine-tuned using a graded programs dataset. Given a problem statement, student code submissions and a grading rubric, TA Buddy can be asked to generate suggested grades, i.e. ratings for the various rubric criteria, for each submission. The human teaching assistant (TA) can then accept or overrule these grades. We evaluated the TA Buddy-assisted manual grading against 'pure' manual grading and found that the time taken to grade reduced by 24% while maintaining grade agreement in the two cases at 90%.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {805–811},
numpages = {7},
keywords = {ai-assisted grading, cs education, grading, llms, programming assignments, rubric, source code evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649217.3653595,
author = {Cucuiat, Veronica and Waite, Jane},
title = {Feedback Literacy: Holistic Analysis of Secondary Educators' Views of LLM Explanations of Program Error Messages},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653595},
doi = {10.1145/3649217.3653595},
abstract = {The implications of using large language model (LLM) tools for learning to program at secondary school level are largely unknown, and yet there is pressure for teachers to engage with these. To start addressing this gap, we investigated: RQ1: What are secondary educators' views on the potential classroom use of LLM program error message explanations? RQ2: In what ways can a feedback literacy perspective support the analysis of educators' views of potential classroom use of LLM program error message explanations? The responses of eight expert secondary school educators were gathered during a semi-structured, activity-based interview and qualitatively analysed. Fifteen themes were derived from their commentary, of which ten corresponded to enhanced program error message (PEM) guidelines. Yet, all themes correlated to feedback literacy theory, providing a more holistic view. The analysis revealed that educators preferred LLM explanations to guide and develop understanding rather than tell, that students should be supported to make judgements and action LLM-generated feedback. Combining PEM guideline and feedback literacy findings, we suggest augmented IDEs should be designed with educators and students in mind, and teacher professional development (PD) is needed. Research is needed to compare our findings with a wider range of educators and investigate what feedback literacy means for resource design, PD, and classroom practice in secondary and undergraduate contexts.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {192–198},
numpages = {7},
keywords = {AI, IDE, K-12 education, ML, feedback literacy},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3597503.3639201,
author = {Choudhuri, Rudrajit and Liu, Dylan and Steinmacher, Igor and Gerosa, Marco and Sarma, Anita},
title = {How Far Are We? The Triumphs and Trials of Generative AI in Learning Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639201},
doi = {10.1145/3597503.3639201},
abstract = {Conversational Generative AI (convo-genAI) is revolutionizing Software Engineering (SE) as engineers and academics embrace this technology in their work. However, there is a gap in understanding the current potential and pitfalls of this technology, specifically in supporting students in SE tasks. In this work, we evaluate through a between-subjects study (N=22) the effectiveness of ChatGPT, a convo-genAI platform, in assisting students in SE tasks. Our study did not find statistical differences in participants' productivity or self-efficacy when using ChatGPT as compared to traditional resources, but we found significantly increased frustration levels. Our study also revealed 5 distinct faults arising from violations of Human-AI interaction guidelines, which led to 7 different (negative) consequences on participants.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {184},
numpages = {13},
keywords = {empirical study, software engineering, generative AI, ChatGPT},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3587103.3594155,
author = {Wermelinger, Michel},
title = {Checking Conformance to a Subset of the Python Language},
year = {2023},
isbn = {9798400701399},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587103.3594155},
doi = {10.1145/3587103.3594155},
abstract = {Introductory courses usually only teach a small subset of a programming language and its library, in order to focus on the general concepts rather than overwhelm students with the syntactic, semantic and API minutiae of a particular language.This paper presents courseware that checks if a program only uses the subset of the Python language and library defined by the instructor. This allows to automatically check that programming examples, exercises and assessments only use the taught constructs. It also helps detect student code with advanced constructs, possibly copied from Q&amp;A sites or generated by large language models.The tool is easy to install, configure and use. It also checks Python code in Jupyter notebooks, a popular format for interactive textbooks and assessment handouts.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 2},
pages = {573–574},
numpages = {2},
keywords = {academic integrity, code checking, introductory programming, novice programming, programming exercises},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3583780.3615047,
author = {Hoq, Muntasir and Chilla, Sushanth Reddy and Ahmadi Ranjbar, Melika and Brusilovsky, Peter and Akram, Bita},
title = {SANN: Programming Code Representation Using Attention Neural Network with Optimized Subtree Extraction},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3615047},
doi = {10.1145/3583780.3615047},
abstract = {Automated analysis of programming data using code representation methods offers valuable services for programmers, from code completion to clone detection to bug detection. Recent studies show the effectiveness of Abstract Syntax Trees (AST), pre-trained Transformer-based models, and graph-based embeddings in programming code representation. However, pre-trained large language models lack interpretability, while other embedding-based approaches struggle with extracting important information from large ASTs. This study proposes a novel Subtree-based Attention Neural Network (SANN) to address these gaps by integrating different components: an optimized sequential subtree extraction process using Genetic algorithm optimization, a two-way embedding approach, and an attention network. We investigate the effectiveness of SANN by applying it to two different tasks: program correctness prediction and algorithm detection on two educational datasets containing both small and large-scale code snippets written in Java and C, respectively. The experimental results show SANN's competitive performance against baseline models from the literature, including code2vec, ASTNN, TBCNN, CodeBERT, GPT-2, and MVG, regarding accurate predictive power. Finally, a case study is presented to show the interpretability of our model prediction and its application for an important human-centered computing application, student modeling. Our results indicate the effectiveness of the SANN model in capturing important syntactic and semantic information from students' code, allowing the construction of accurate student models, which serve as the foundation for generating adaptive instructional support such as individualized hints and feedback.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {783–792},
numpages = {10},
keywords = {static analysis, program correctness prediction, program analysis, code representation, algorithm detection},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3649217.3653574,
author = {Denny, Paul and MacNeil, Stephen and Savelka, Jaromir and Porter, Leo and Luxton-Reilly, Andrew},
title = {Desirable Characteristics for AI Teaching Assistants in Programming Education},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653574},
doi = {10.1145/3649217.3653574},
abstract = {Providing timely and personalized feedback to large numbers of students is a long-standing challenge in programming courses. Relying on human teaching assistants (TAs) has been extensively studied, revealing a number of potential shortcomings. These include inequitable access for students with low confidence when needing support, as well as situations where TAs provide direct solutions without helping students to develop their own problem-solving skills. With the advent of powerful large language models (LLMs), digital teaching assistants configured for programming contexts have emerged as an appealing and scalable way to provide instant, equitable, round-the-clock support. Although digital TAs can provide a variety of help for programming tasks, from high-level problem solving advice to direct solution generation, the effectiveness of such tools depends on their ability to promote meaningful learning experiences. If students find the guardrails implemented in digital TAs too constraining, or if other expectations are not met, they may seek assistance in ways that do not help them learn. Thus, it is essential to identify the features that students believe make digital teaching assistants valuable. We deployed an LLM-powered digital assistant in an introductory programming course and collected student feedback (n=813) on the characteristics of the tool they perceived to be most important. Our results highlight that students value such tools for their ability to provide instant, engaging support, particularly during peak times such as before assessment deadlines. They also expressed a strong preference for features that enable them to retain autonomy in their learning journey, such as scaffolding that helps to guide them through problem-solving steps rather than simply being shown direct solutions.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {408–414},
numpages = {7},
keywords = {ai tutors, automated tutors, digital tas, feedback, llms},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3716640.3716656,
author = {Vadaparty, Annapurna and Geng, Francis and Smith, David H and Benario, Jamie Gorson and Zingaro, Daniel and Porter, Leo},
title = {Achievement Goals in CS1-LLM},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716656},
doi = {10.1145/3716640.3716656},
abstract = {Introduction: The emergence and widespread adoption of generative AI (GenAI) chatbots such as ChatGPT, and programming assistants such as GitHub Copilot, have radically redefined the landscape of programming education. This calls for replication of studies and reexamination of findings from pre-GenAI CS contexts to understand the impact on students. Objectives: Achievement Goals are well studied in computing education and can be predictive of student interest and exam performance. The objective in this study is to compare findings from prior achievement goal studies in CS1 courses with new CS1 courses that emphasize the use of human-GenAI collaborative coding. Methods: In a CS1 course that integrates GenAI, we use linear regression to explore the relationship between achievement goals and prior experience on student interest, exam performance, and perceptions of GenAI. Results: As with prior findings in traditional CS1 classes, Mastery goals are correlated with interest in computing. Contradicting prior CS1 findings, normative goals are correlated with exam scores. Normative and mastery goals correlate with students’ perceptions of learning with GenAI. Mastery goals weakly correlate with reading and testing code output from GenAI.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {144–153},
numpages = {10},
keywords = {CS1, CS1-LLM, Copilot, Achievement Goals, Large Language Models},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3641555.3705175,
author = {Bouamor, Houda and Gongora-Svartzman, Gabriela and Heimann, Larry and Huang, Shihong},
title = {Evaluating GenAI's Effectiveness for Students with Varied Programming Backgrounds in a Software Development Course},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705175},
doi = {10.1145/3641555.3705175},
abstract = {Using Generative AI (GenAI) tools in education presents both opportunities and challenges to the traditional teaching methods and students' learning experience and outcomes, particularly in technical and programming courses. This experience report evaluates the impact of GenAI tools, specifically ChatGPT and GitHub CoPilot, in leveling the playing field for Information Systems students with varying technical backgrounds in an application design and development course. By integrating these tools into course labs and projects, this study aimed to determine whether they improve the success rates of less technically prepared and struggling students. Data were collected from five sessions of a semester-long course across two campuses, involving 162 students with five parallel sessions across two continents. The analysis of student performance metrics and surveys revealed that GenAI tools significantly helped students complete programming tasks. However, those who were less technically prepared and relied heavily on AI assistance struggled with more complex, transformative tasks, such as closed-book exams. These findings suggest that while GenAI tools can help close gaps in temporary programming skills, they are less effective - and may even exacerbate disparities - in fostering long-term deeper learning and developing transformative knowledge and critical thinking.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1395–1396},
numpages = {2},
keywords = {generative AI, impact of Genai tools in education, information systems education (IS), leveling playfield, programming background, student performance evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3626252.3630773,
author = {Woodrow, Juliette and Malik, Ali and Piech, Chris},
title = {AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630773},
doi = {10.1145/3626252.3630773},
abstract = {Teaching students how to write code that is elegant, reusable, and comprehensible is a fundamental part of CS1 education. However, providing this "style feedback" in a timely manner has proven difficult to scale. In this paper, we present our experience deploying a novel, real-time style feedback tool in Code in Place, a large-scale online CS1 course. Our tool is based on the latest breakthroughs in large-language models (LLMs) and was carefully designed to be safe and helpful for students. We used our Real-Time Style Feedback tool (RTSF) in a class with over 8,000 diverse students from across the globe and ran a randomized control trial to understand its benefits. We show that students who received style feedback in real-time were five times more likely to view and engage with their feedback compared to students who received delayed feedback. Moreover, those who viewed feedback were more likely to make significant style-related edits to their code, with over 79% of these edits directly incorporating their feedback. We also discuss the practicality and dangers of LLM-based tools for feedback, investigating the quality of the feedback generated, LLM limitations, and techniques for consistency, standardization, and safeguarding against demographic bias, all of which are crucial for a tool utilized by students.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1442–1448},
numpages = {7},
keywords = {cs1, deployed at scale, gpt, llms, real time, style feedback},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3636555.3636912,
author = {Snyder, Caitlin and Hutchins, Nicole M and Cohn, Clayton and Fonteles, Joyce Horn and Biswas, Gautam},
title = {Analyzing Students Collaborative Problem-Solving Behaviors in Synergistic STEM+C Learning},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636912},
doi = {10.1145/3636555.3636912},
abstract = {This study introduces a methodology to investigate students’ collaborative behaviors as they work in pairs to build computational models of scientific processes. We expand the Self-Regulated Learning (SRL) framework—specifically, Planning, Enacting, and Reflection—proposed in the literature, applying it to examine students’ collaborative problem-solving (CPS) behaviors in a computational modeling task. We analyze these behaviors by employing a Markov Chain (MC) modeling approach that scrutinizes students’ model construction and model debugging behaviors during CPS. This involves interpreting their actions in the system collected through computer logs and analyzing their conversations using a Large Language Model (LLM) as they progress through their modeling task in segments. Our analytical framework assesses the behaviors of high- and low-performing students by evaluating their proficiency in completing the specified computational model for a kinematics problem. We employ a mixed-methods approach, combining Markov Chain analysis of student problem-solving transitions with qualitative interpretations of their conversation segments. The results highlight distinct differences in behaviors between high- and low-performing groups, suggesting potential for developing adaptive scaffolds in future work to enhance support for students in collaborative problem-solving.},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {540–550},
numpages = {11},
keywords = {SRL, STEM, collaboration, learning analytics},
location = {Kyoto, Japan},
series = {LAK '24}
}

@inproceedings{10.1145/3704289.3704301,
author = {Chang, Chi In and Choi, Wan Chong and Choi, Iek Chong},
title = {A Systematic Literature Review of the Opportunities and Advantages for AIGC (OpenAI ChatGPT, Copilot, Codex) in Programming Course},
year = {2025},
isbn = {9798400716980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3704289.3704301},
doi = {10.1145/3704289.3704301},
abstract = {This systematic literature review explored the opportunities and advantages of integrating Artificial Intelligence Generated Content (AIGC) tools like OpenAI's ChatGPT, Copilot, and Codex in programming education. From an initial pool of 1,173 papers, 24 were rigorously selected for detailed analysis. The findings highlighted the dominant use of ChatGPT, particularly versions 3/3.5 and 4, underscoring its effectiveness and accessibility. Python emerged as the most frequently studied language, followed by Java, C, R, and Scala. A notable research gap was identified in block-based programming languages and online/blended learning environments. Key opportunities and advantages identified included enhanced code review, where AIGC tools offer efficient and comprehensive assessments; personalized learning, with ChatGPT providing individualized feedback and improving student comprehension; and increased student engagement and motivation through interactive features. Additionally, AIGC tools significantly improved problem-solving and debugging support, effectively identifying and correcting coding errors. They also supported diverse learning styles by offering varied examples and solutions, facilitated innovative teaching strategies that improved educational outcomes, and reduced teacher workload by automating routine tasks. These insights demonstrated the transformative potential of AIGC tools in revolutionizing programming education.},
booktitle = {Proceedings of the 2024 7th International Conference on Big Data and Education},
pages = {29–35},
numpages = {7},
keywords = {Advantages of AIGC, Artificial intelligence generated content, ChatGPT, Codex, Copilot, Opportunities of AIGC, Programming Course, Systematic literature review},
location = {
},
series = {ICBDE '24}
}

@inproceedings{10.1145/3639701.3656308,
author = {Alonso del Barrio, David and Tiel, Max and Gatica-Perez, Daniel},
title = {Human Interest or Conflict? Leveraging LLMs for Automated Framing Analysis in TV Shows},
year = {2024},
isbn = {9798400705038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639701.3656308},
doi = {10.1145/3639701.3656308},
abstract = {In the current media landscape, understanding the framing of information is crucial for critical consumption and informed decision making. Framing analysis is a valuable tool for identifying the underlying perspectives used to present information, and has been applied to a variety of media formats, including television programs. However, manual analysis of framing can be time-consuming and labor-intensive. This is where large language models (LLMs) can play a key role. In this paper, we propose a novel approach to use prompt-engineering to identify the framing of spoken content in television programs. Our findings indicate that prompt-engineering LLMs can be used as a support tool to identify frames, with agreement rates between human and machine reaching up to 43%. As LLMs are still under development, we believe that our approach has the potential to be refined and further improved. The potential of this technology for interactive media applications is vast, including the development of support tools for journalists, educational resources for students of journalism learning about framing and related concepts, and interactive media experiences for audiences.},
booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences},
pages = {157–167},
numpages = {11},
keywords = {LLMs, TV, framing analysis, media, prompt-engineering},
location = {Stockholm, Sweden},
series = {IMX '24}
}

@inproceedings{10.1145/3613905.3650792,
author = {Higasa, Taichi and Tanaka, Keitaro and Feng, Qi and Morishima, Shigeo},
title = {Keep Eyes on the Sentence: An Interactive Sentence Simplification System for English Learners Based on Eye Tracking and Large Language Models},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650792},
doi = {10.1145/3613905.3650792},
abstract = {Language learners should read challenging texts regularly. However, using dictionaries or search engines to look up difficult expressions can be time-consuming and distracting. To address this, we have developed a system combining eye tracking with Large Language Models (LLMs) to simplify sentences automatically, allowing learners to focus on the content. The system incorporates user-tailored models that estimate users’ comprehension of sentences using gaze data and sentence information. The system also features user-triggered simplification, resulting from iterative design improvements. We conducted a user study with 17 English learners where they read English text using either our system or a baseline involving online dictionaries and search engines. Our system significantly improved both reading speed and comprehension, especially for complex sentences. The gaze-based simplification improved concentration on the content, allowing for an interruption-free reading experience. It could assist in daily reading practice, particularly for extensive reading focused on large volumes of text at a rapid pace.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {211},
numpages = {7},
keywords = {Eye tracking, human-computer interaction, machine learning, sentence simplification},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3616855.3635690,
author = {Xie, Yukang and Wang, Chengyu and Yan, Junbing and Zhou, Jiyong and Deng, Feiqi and Huang, Jun},
title = {Making Small Language Models Better Multi-task Learners with Mixture-of-Task-Adapters},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635690},
doi = {10.1145/3616855.3635690},
abstract = {Recently, Large Language Models (LLMs) have achieved amazing zero-shot learning performance over a variety of Natural Language Processing (NLP) tasks, especially for text generative tasks. Yet, the large size of LLMs often leads to the high computational cost of model training and online deployment. In our work, we present ALTER, a system that effectively builds the multi-tAsk Learners with mixTure-of-task-adaptERs upon small language models (with &lt;1B parameters) to address multiple NLP tasks simultaneously, capturing the commonalities and differences between tasks, in order to support domain-specific applications. Specifically, in ALTER, we propose the Mixture-of-Task-Adapters (MTA) module as an extension to the transformer architecture for the underlying model to capture the intra-task and inter-task knowledge. A two-stage training method is further proposed to optimize the collaboration between adapters at a small computational cost. Experimental results over a mixture of NLP tasks show that our proposed MTA architecture and the two-stage training method achieve good performance. Based on ALTER, we have also produced MTA-equipped language models for various domains.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1094–1097},
numpages = {4},
keywords = {language model, multi-task learning, text generation},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3610661.3617514,
author = {A, Rajagopal and V, Nirmala and Jebadurai, Immanuel Johnraja and Vedamanickam, Arun Muthuraj and Kumar, Prajakta Uthaya},
title = {Design of Generative Multimodal AI Agents to Enable Persons with Learning Disability},
year = {2023},
isbn = {9798400703218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610661.3617514},
doi = {10.1145/3610661.3617514},
abstract = {The recent advances in Multimodal AI &amp; Generative AI open doors to the possibilities of solving key challenges for Persons with Learning Disability. To assist individuals facing difficulty in visual or auditory perception, this paper designs &amp; develops a multimodal AI agent using recent advances in the field. We aim to solve the challenge of enabling persons with Visual or Auditory Processing Disorders to learn &amp; communicate. We do this by exploring a design that allows the transformation of information across visual and language modalities. This design can be realized with the recent advances in Generative Multimodal AI. Based on each individual's needs, the AI agent dynamically adapts the Human Computer interaction model. For instance, for a child with Visual Processing Disorder (VPD), given the child's hindered ability to make sense of information taken in through the eyes, the Multimodal AI agent transforms any visual information into auditory user interaction. In another instance, for a person with Central Auditory Processing Disorder (CAPD), given the hindrance in the individual's ability to analyze information taken in through the ears, the AI dynamically translates any speech modality into visual cues. Thus the AI agent adapts dynamically to the strengths and abilities of the individual. To enable students with VPD to learn, the design allows the student to ask questions about an image. This design is realized as a Visual Question Answering task in Vision Language Transformer models. We explore interactive multimodal conversations with Few shot Learning and In-Context Instruction Tuning of Multimodal Large Language Models to address difficulty in visual reasoning. To enable persons with CAPD to learn, the design translates audio lectures into visual cues. This visual cue consists of a combination of words using speech recognition and Large Language Models based re-phrasing to simpler words, cross-modal retrieval of images to address auditory memory challenges, and AI-generated images. To identify the strengths of each child, we also explore Multimodal embedding based Multimodal latent space arithmetic to link AI across senses. To effectively integrate the proposed design into the mainstream, we explore a universal design based inclusive approach to extend the use case to create AI assistants for assisting children with different learning styles such as visual learners or auditory learners. To enable future research on the proposed design, we explore an architecture to compose a pipeline of AI models, and to connect with external systems via plugin connectors. We implement lab scale prototypes of this design and present a demo on the project webpage at https://sites.google.com/view/multimodallearningdisability.},
booktitle = {Companion Publication of the 25th International Conference on Multimodal Interaction},
pages = {259–271},
numpages = {13},
keywords = {Visual Processing Disorder, Vision Language Models, Person with Disability, Multimodal latent space, Multimodal Large Language Transformers, Multimodal In-context Tuning, Multimodal Few shot Learning, Multimodal AI, Learning disability, Human Computer Interaction, Generative AI, Central Auditory Processing Disorder, Assistive Technology},
location = {Paris, France},
series = {ICMI '23 Companion}
}

@inproceedings{10.1145/3637528.3671965,
author = {Chen, Lin and Xu, Fengli and Li, Nian and Han, Zhenyu and Wang, Meng and Li, Yong and Hui, Pan},
title = {Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671965},
doi = {10.1145/3637528.3671965},
abstract = {Heterogeneous information networks (HIN) have gained increasing popularity in recent years for capturing complex relations between diverse types of nodes. Meta-structures are proposed as a useful tool to identify the important patterns in HINs, but hand-crafted meta-structures pose significant challenges for scaling up, drawing wide research attention towards developing automatic search algorithms. Previous efforts primarily focused on searching for meta-structures with good empirical performance, overlooking the importance of human comprehensibility and generalizability. To address this challenge, we draw inspiration from the emergent reasoning abilities of large language models (LLMs). We propose ReStruct, a meta-structure search framework that integrates LLM reasoning into the evolutionary procedure. ReStruct uses a grammar translator to encode the meta-structures into natural language sentences, and leverages the reasoning power of LLMs to evaluate their semantic feasibility. Besides, ReStruct also employs performance-oriented evolutionary operations. These two competing forces allow ReStruct to jointly optimize the semantic explainability and empirical performance of meta-structures. Furthermore, ReStruct contains a differential LLM explainer to generate and refine natural language explanations for the discovered meta-structures by reasoning through the search history. Experiments on eight representative HIN datasets demonstrate that ReStruct achieves state-of-the-art performance in both recommendation and node classification tasks. Moreover, a survey study involving 73 graduate students shows that the discovered meta-structures and generated explanations by ReStruct are substantially more comprehensible. Our code and questionnaire are available at https://github.com/LinChen-65/ReStruct.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {307–318},
numpages = {12},
keywords = {graph neural networks, heterogeneous information networks, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3660650.3660673,
author = {Rajabi, Parsa and Kerslake, Chris},
title = {Can You Spot the AI? Incorporating GenAI into Technical Writing Assignments},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660673},
doi = {10.1145/3660650.3660673},
abstract = {In an effort to foster critical reflection on the usage of generative AI (genAI) during computer science writing assignments, this three-part assignment challenges students to predict whether their peers can detect which essays are generated using AI. Implemented as part of a third-year professional responsibility and technical writing course for N=200 students during Spring 2024, students individually generated two short persuasive essays, one using genAI and the other without. They then combined the two essays into a single document and submitted it for peer-review. Additionally, they formulated a guess on whether their peers would be able to detect which essay was generated as well as a rationale for their guess. Following the peer-review process, students reflected on their own experience trying to detect which essays were generated as well as the outcome of their guess about their peers abilities as well. Feedback indicates its effectiveness in engaging students in their understanding of the potentials and limitations of genAI. Recommended prerequisites include a clear course AI-usage policy and a brief overview of genAI prompt engineering.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {23},
numpages = {2},
keywords = {AI Literacy, AI in Education, AI-usage Policy, ChatGPT, Generative AI, Technical Writing},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3657604.3664664,
author = {Moreau-Pernet, Baptiste and Tian, Yu and Sawaya, Sandra and Foltz, Peter and Cao, Jie and Milne, Brent and Christie, Thomas},
title = {Classifying Tutor Discursive Moves at Scale in Mathematics Classrooms with Large Language Models},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664664},
doi = {10.1145/3657604.3664664},
abstract = {In mathematics tutoring, using appropriate instructional discursive strategies, called "talk moves'', is critical to support student learning. Training tutors in the appropriate use of talk moves is a key component of tutor development programs. However, tutor development at scale is a challenge. Recent research has shown that automatic talk moves classification of tutorial discourse can facilitate large-scale delivery of personalized talk moves feedback. In this paper, we build on this work and share our current progress using large language models to classify talk moves in transcripts of tutoring sessions. We report classification results from fine-tuned models, prompt optimization, and supervised embedding vectors classification. The fine-tuned strategy performed best, yielding better performance (.87 macro and .93 weighted f1 score in predicting expert labels) than the current state-of-the-art RoBERTa model. We discuss trade-offs across methods and models.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {361–365},
numpages = {5},
keywords = {discourse analysis, llm classification, math tutor training},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626253.3635524,
author = {Bevilacqua, Joey and Chiodini, Luca and Moreno Santos, Igor and Hauswirth, Matthias},
title = {Using Notional Machines to Automatically Assess Students' Comprehension of Their Own Code},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635524},
doi = {10.1145/3626253.3635524},
abstract = {Code comprehension has been shown to be challenging and important for a positive learning outcome. Students don't always understand the code they write. This has been exacerbated by the advent of large language models that automatically generate code that may or may not be correct. Now students don't just have to understand their own code, but they have to be able to critically analyze automatically generated code as well. To help students with code comprehension, instructors often use notional machines. Notional machines are used not only by instructors to explain code, but also in activities or exam questions given to students. Traditionally, these questions involve code that was not written by students. However, asking questions to students about their own code (Questions on Learners' Code, QLCs) has been shown to strengthen their code comprehension. This poster presents an approach to combine notional machines and QLCs to automatically generate personalized questions about learners' code based on notional machines. Our aim is to understand whether notional machine-based QLCs are effective. We conducted a pilot study with 67 students to test our approach, and we plan to conduct a comprehensive empirical evaluation to study its effectiveness.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1572–1573},
numpages = {2},
keywords = {assessment, code comprehension, expressions, notional machines, programmming},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3605507.3610629,
author = {Gehringer, Edward F. and Wang, Jianxun George and Jilla, Sharan Kumar},
title = {Dual-Submission Homework in Parallel Computer Architecture: An Exploratory Study in the Age of LLMs},
year = {2024},
isbn = {9798400702532},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605507.3610629},
doi = {10.1145/3605507.3610629},
abstract = {The traditional model of assigning textbook problems for homework is endangered by the ability of students to find answers to almost any published problem on the web. An alternative is a dual-submission approach, where students submit their work, then receive the solutions, and submit a second metacognitive reflection, explaining any errors they made. Students’ scores can depend on the quality of their second submissions alone or the combined quality of their first and second submissions. We tried this approach in a class on parallel computer architecture. We report students’ personal experience based on their questionnaires responses. In addition, we quantitatively compare students’ performance on test questions related to dual-submission homework against their performance on other questions and previous semesters’ student performance on similar questions. Students overwhelmingly preferred this approach and thought they learned more from it, but evidence about whether it improved their learning was inconclusive. We also analyze the continued viability of this approach in the era of large language models.},
booktitle = {Proceedings of the Workshop on Computer Architecture Education},
pages = {41–47},
numpages = {7},
location = {Orlando, FL, USA},
series = {WCAE '23}
}

@inproceedings{10.1145/3511808.3557079,
author = {Biderman, Stella and Raff, Edward},
title = {Fooling MOSS Detection with Pretrained Language Models},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557079},
doi = {10.1145/3511808.3557079},
abstract = {As artificial intelligence (AI) technologies become increasingly powerful and prominent in society, their misuse is a growing concern. In educational settings, AI technologies could be used by students to cheat on assignments and exams. In this paper we explore whether transformers can be used to solve introductory level programming assignments while bypassing commonly used AI tools to detect similarities between pieces of software. We find that a student using GPT-J [60] can complete introductory level programming assignments without triggering suspicion from MOSS [2], a widely used software similarity and plagiarism detection tool. This holds despite the fact that GPT-J was not trained on the problems in question and is not provided with any examples to work from. We further find that the code written by GPT-J is diverse in structure, lacking any particular tells that future plagiarism detection techniques may use to try to identify algorithmically generated code. We conclude with a discussion of the ethical and educational implications of large language models and directions for future research.},
booktitle = {Proceedings of the 31st ACM International Conference on Information &amp; Knowledge Management},
pages = {2933–2943},
numpages = {11},
keywords = {open source software, multimodal transformers, language models, education technology},
location = {Atlanta, GA, USA},
series = {CIKM '22}
}

@inproceedings{10.1145/3622780.3623648,
author = {Kuramitsu, Kimio and Obara, Yui and Sato, Miyu and Obara, Momoka},
title = {KOGI: A Seamless Integration of ChatGPT into Jupyter Environments for Programming Education},
year = {2023},
isbn = {9798400703904},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622780.3623648},
doi = {10.1145/3622780.3623648},
abstract = {The impact of ChatGPT has brought both anxiety and anticipation to schools and universities. Exploring a positive method to improve programming skills with ChatGPT is a new and pressing challenge.  
In pursuit of this goal, we have developed KOGI, a learning support system that integrates ChatGPT into the Jupyter environment. This paper demonstrates how KOGI enables students to receive timely advice from ChatGPT in response to errors and other questions they encounter.  

We immediately introduced KOGI in our two introductory courses: Algorithms and Data Science. The introduction of KOGI resulted in a significant decrease in the number of unresolved student errors. In addition, we report on student trends observed in the classroom regarding the type and frequency of help requested. Although our findings are preliminary, they are informative for programming instructors interested in using ChatGPT.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on SPLASH-E},
pages = {50–59},
numpages = {10},
keywords = {programming education, classroom experience, LLM, ChatGPT},
location = {Cascais, Portugal},
series = {SPLASH-E 2023}
}

@article{10.1145/3628162,
author = {Shoufan, Abdulhadi},
title = {Can Students without Prior Knowledge Use ChatGPT to Answer Test Questions? An Empirical Study},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
url = {https://doi.org/10.1145/3628162},
doi = {10.1145/3628162},
abstract = {With the immense interest in ChatGPT worldwide, education has seen a mix of both excitement and skepticism. To properly evaluate its impact on education, it is crucial to understand how far it can help students without prior knowledge answer assessment questions. This study aims to address this question as well as the impact of the question type. We conducted multiple experiments with computer engineering students (experiment group: n=41 to 56), who were asked to use ChatGPT to answer previous test questions before learning about the related topics. Their scores were then compared with the scores of previous-term students who answered the same questions in a quiz or exam setting (control group: n=24 to 61). The results showed a wide range of effect sizes, from -2.55 to 1.23, depending on the question type and content. The experiment group performed best answering code analysis and conceptual questions but struggled with code completion and questions that involved images. However, the performance in code generation tasks was inconsistent. Overall, the ChatGPT group’s answers lagged slightly behind the control group’s answers with an effect size of -0.16. We conclude that ChatGPT, at least in the field of this study, is not yet ready to rely on by students who do not have sufficient background to evaluate generated answers. We suggest that educators try using ChatGPT and educate students on effective questioning techniques and how to assess the generated responses. This study provides insights into the capabilities and limitations of ChatGPT in education and informs future research and development.},
journal = {ACM Trans. Comput. Educ.},
month = dec,
articleno = {45},
numpages = {29},
keywords = {large language models, ChatGPT}
}

@inproceedings{10.1145/3617650.3624950,
author = {Bouvier, Dennis J. and Lovellette, Ellie and Santos, Eddie Antonio and Becker, Brett A. and Crick, Tom and Dasigi, Venu G. and Forden, Jack and Glebova, Olga and Joshi, Swaroop and Kurkovsky, Stan and Russell, Se\'{a}n},
title = {Teaching Students To Use Programming Error Messages},
year = {2023},
isbn = {9798400703744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3617650.3624950},
doi = {10.1145/3617650.3624950},
abstract = {Research shows many students struggle to use programming error and warning messages effectively. Instead of using these messages as aids to debug and fix their code, some students have negative emotional reactions to seeing 'angry red text'. Not utilizing programming error and warning messages effectively, or at all, increases the difficulty of learning to program.As compiler messages can vary by programming language and/or development environment, lessons on reading them are not typically included in mainstream educational materials. We believe this gap can be filled and that students can learn to use error messages to their advantage. Further, we believe that teaching students how to read and use error messages can have a significant impact on the learning experience for novice programmers.The goal of this working group is to develop educational materials to teach students to use programming error messages, and evaluate the use of these materials. An additional goal is to investigate the role that large language models may play in the interpretation of error messages in the educational environment. We will produce guidelines for developing educational materials and strategies informed by feedback obtained from the community and our experimentation.},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 2},
pages = {207–208},
numpages = {2},
keywords = {warning messages, runtime errors, programming error messages, novice programmers, error messages, computing education, computer error messages},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@article{10.1145/3722228,
author = {Bodon, Herminio and Kumar, Vishesh and Worsley, Marcelo},
title = {Design Principles for Authentically Embedding Computer Science in Sports},
year = {2025},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
url = {https://doi.org/10.1145/3722228},
doi = {10.1145/3722228},
abstract = {Objectives. Athletics and sports represent a focal part of adolescence for millions of youth around the world. However, opportunities to engage in computer science (CS) learning experiences are less prevalent, particularly among Hispanic and low-income communities. Recently, researchers have explored ways to bridge these, seemingly, disparate disciplines. Much of this prior research centers on the proliferation of sports technologies that support individualistic learning experiences. Additionally, many of these experiences are developed by researchers with limited design contributions from sports practitioners. To extend prior work, this project centers youth athletic identities and the associated cultural contexts of sports to explore ways that computing technologies can enhance and develop youth athletic identities and sports performance. Moreover, this work surfaces ways that athletics can be a generative and fulfilling space to learn about CS.Participants. In summer 2021, we collaborated with basketball coaches to design and implement a computing-enhanced learning experience with a basketball team of Hispanic participants in Puerto Rico. Eleven basketball athletes from a high school in southern Puerto Rico participated in the study. The participants have strong sports identities, as demonstrated by their lifelong engagement with team sports. Conversely, only one 1 of the 11 participants had experienced sports technologies, and none of them had previously participated in computing learning experiences.Study Method. In collaboration with local basketball coaches, we co-designed a learning experience that centers sports identities and practices and adds computing as a way to extend existing sports identities and local sports activities. We present and evaluate this learning experience using a design-based research approach. Participants’ feedback was collected in the form of surveys, designs, and journal entries, and additional data on their experiences were collected via videos and researchers’ field notes. Using a mixed-methods approach, we highlight existing participants’ identities and perceptions as well as their experiences with our design. We complement quantitative analysis of survey responses with case studies.Findings. We find that our design can provide shifts in youth student-athletes’ perceptions of computing. Additionally, hands-on experiences with computing tools enable participants to start practicing CS sensemaking via learning how different computing tools can support their sports performance individually and as a team. Furthermore, we find that the material, ideational, and relational resources made available through camp:bit supported each participant differently, while collectively providing a space for all of them to have meaningful and fulfilling experiences. Finally, we find that this design can foster and support sports team cohesion.Conclusions. We provide in-depth descriptions of our design, the youth’s engagement with it, and how these learning experiences can be further applied in sports spaces. These examples highlight a unique conception of practice-linked computational identities—where learners’ computational identities are grounded in a specific culturally relevant practice, enabling a more culturally sustaining computing learning experience. Finally, our analysis suggests five design principles for designing and conducting computing-supported learning experiences in sports environments. The principles are as follows: (1) Sports Experience: Authentically Support Existing Identities. (2) Team Dynamics: Team Athletes Are Part of a Whole. (3) Individual Pursuits: Supporting Individual Paths. (4) Direct Interactions: Conversations with Materials and Ideas. (5) Interdisciplinary Facilitation Team: Complementary Skills. These design principles can be used by researchers, practitioners, and local stakeholders to implement sport-centric CS learning experiences to extend and enhance the way student-athletes from marginalized communities practice sports, as well as to activate interest and engagement in CS.},
journal = {ACM Trans. Comput. Educ.},
month = may,
articleno = {13},
numpages = {42},
keywords = {Sports, Wearable, Identity, Computing, Computer Science Education, Design-Based Research, Participation, Data Science, AI}
}

@inproceedings{10.1145/3701716.3715222,
author = {Zhao, Gang and Zhang, Ximing and Lu, Chenji and Zhao, Hui and Wu, Tianshu and Wang, Pengjie and Xu, Jian and Zheng, Bo},
title = {Explainable LLM-driven Multi-dimensional Distillation for E-Commerce Relevance Learning},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715222},
doi = {10.1145/3701716.3715222},
abstract = {Effective query-item relevance modeling is pivotal for enhancing user experience and safeguarding user satisfaction in e-commerce search systems. Recently, benefiting from the vast inherent knowledge, Large Language Model (LLM) approach demonstrates strong performance and long-tail generalization ability compared with previous neural-based specialized relevance learning methods. Though promising, current LLM-based method encounters the following inadequacies in practice: Firstly, the relevance modeling process is a black box, making it difficult to clearly understand why LLM can provide the significant improvement or to analyze its relevance judgment errors. This opacity also hinders the reuse of the LLM's rich intrinsic knowledge. Secondly, the massive parameters and computational demands make it challenging to be deployed online. To improve the interpretability of LLM and boost the performance of online relevance models, we propose an Explainable LLM-driven Multi-dimensional Distillation framework for e-commerce relevance learning, which comprises two core components: (1) An Explainable LLM for relevance modeling (ELLM-rele), which decomposes the relevance learning into intermediate steps and models relevance learning as a Chain-of-Thought (CoT) reasoning, thereby enhancing both interpretability and performance of LLM. (2) A Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the knowledge of ELLM-rele to current interaction-based and representation-based student models from both the relevance score distribution and CoT reasoning aspects. Through distilling the probabilistic and CoT reasoning knowledge, MKD improves both the semantic interaction and long-tail generalization abilities of student models. Extensive offline evaluations and online experiments conducted on Taobao search ad scene demonstrate that our proposed ELLM-MD framework significantly enhances e-commerce relevance learning performance and consumer experience.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {631–640},
numpages = {10},
keywords = {e-commerce, knowledge distillation, large language model, semantic matching},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3613372.3614189,
author = {Albonico, Michel and Varela, Paulo J\'{u}nior},
title = {A Report on the Use of ChatGPT in Software Engineering and Systems Analysis Courses},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3614189},
doi = {10.1145/3613372.3614189},
abstract = {ChatGPT is a natural language model that works as a virtual chat assistant. It has the potential to be used for fostering classroom discussions and addressing student needs when the professor is not accessible. Although it is still early to assess the impact of ChatGPT and similar technologies, there is a considerable discussion on social media and blogs regarding the aspirations and opportunities of utilizing ChatGPT in the software industry and education. The main perception is that ChatGPT can serve as a support tool but should not completely replace interpersonal interaction, as face-to-face dialogue remains crucial for the development of interpersonal skills and a deeper understanding of concepts. This article reports a recent classroom experience in the subjects of Software Engineering and Systems Analysis, while also analyzing ChatGPT’s responses to student inquiries.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {303–311},
numpages = {9},
keywords = {ChatGPT, Software Engineering, Student Support, System Analysis},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3722237.3722266,
author = {Yang, Ye and Wen, Xiong and Maidin, Siti Sarah},
title = {Generative AI Tools in Higher Education Emerging Research: A Bibliometric analysis of co-citation and co-word analysis},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722266},
doi = {10.1145/3722237.3722266},
abstract = {Artificial Intelligence (AI) is positively grasped as promising to disrupt the higher education system but it also poses a number of challenges. Although so many studies attempt to explore the matching of the possibility of this growing technology with the higher education system, ample research needs to be conducted to solve the challenges facing the renovation of higher education. With this in mind, our aim of bibliometric studies is to conduct a deep investigation into the increasingly developing scenario of Generative AI tools in higher education. We extracted data from the Web of Science database that is up-to-date till July 2024, comprising 934 relevant articles. Co-citation and co-word analyses revealed three main research clusters: advanced computationable methods, AI application in higher education, and user technology and adoption. The findings illustrated rapid diffusion of generative AI technologies with prominent emphasis on large-language models in pedagogical practices. Other critical themes center around developing AI-facilitated learning interventions, ethical challenges, and usage impact on learning outcomes. The results show that the field is inherently interdisciplinary, using ideas from educational technology, cognitive science, and AI. In addition, a rising trend is noted for the focus on academic honesty and users' involvement with AI devices. The results indicate the important implications of this study for teachers and policymakers alongside contributions to teaching and research that offer a guide to sustainable improvement across education. Future research would benefit from longitudinal studies drawing on an interdisciplinary approach to realize the long-term implications and address complex issues surrounding the integration of AI within universities.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {166–174},
numpages = {9},
keywords = {Generative AI, artificial intelligence, bibliometric, educational technology, higher education},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3644815.3644948,
author = {Rasool, Zafaryab and Barnett, Scott and Willie, David and Kurniawan, Stefanus and Balugo, Sherwin and Thudumu, Srikanth and Abdelrazek, Mohamed},
title = {LLMs for Test Input Generation for Semantic Applications},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644948},
doi = {10.1145/3644815.3644948},
abstract = {Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {160–165},
numpages = {6},
keywords = {large language model, query evaluation, question answering, semantic cache, test input generation},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3675249.3675307,
author = {Yao, Huan and Bao, Wanying and Wu, Hequn},
title = {BabyGAN for Facial Contour Reversion: AI Course Applications Using U-Net Architecture},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675307},
doi = {10.1145/3675249.3675307},
abstract = {BabyGAN is a generative adversarial network model based on the U-net architecture and residual networks, designed for the transformation of adult facial contours into baby facial contours. This model is primarily used in the artificial intelligence practical courses of vocational colleges, focusing on information technology education. A key feature of BabyGAN is its ability to help students deeply understand the logical structure of generative adversarial networks while also fostering their enthusiasm. Compared to other GAN models used in teaching, BabyGAN has the advantage of allowing students to easily construct training sets, enabling immediate use of class-specific datasets in the classroom. The working principle of BabyGAN involves integrating a special keypoint constraint loss function in the generator to produce high-quality baby facial contours, thereby transforming adult facial contours into corresponding high-quality infant facial contours. BabyGAN plays a significant role in the future work scenarios of students. Incorporating the BabyGAN course into AI curricula effectively blends information technology education with students' future career prospects. The application of GANs to meet user needs is a current research hotspot. Introducing students to BabyGAN in a fun and educational setting also aligns with market demands, equipping students with practical skills and the ability to apply these skills in future work contexts.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {324–329},
numpages = {6},
location = {Sanming, China},
series = {ICCMT '24}
}

@inproceedings{10.1145/3674829.3675060,
author = {Graves, Eric and Aswar, Shreyas and Desai, Rujuta and Nampelli, Srilekha and Chakraborty, Sunandan and Hall, Ted},
title = {AAVE Corpus Generation and Low-Resource Dialect Machine Translation},
year = {2024},
isbn = {9798400710483},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674829.3675060},
doi = {10.1145/3674829.3675060},
abstract = {African American Vernacular English (AAVE) is a dialect of the English language spoken in the United States by members of the Black community. The stark differences between AAVE and Standard American English (SAE), as well as a historically negative stigma towards its use, have contributed to an academic performance gap between Black students and their non-Black counterparts. This research works to generate educational resources similar to what is available in English Second Language (ESL) classrooms. Exposure to these resources has been shown to both improve the negative stigma towards the use of AAVE as well as facilitate code-switching between AAVE and SAE. The resources to be generated in this research are a parallel corpora for AAVE and SAE using both professionally translated text and AI-generated text, and a Neural Machine Translation (NMT) model to translate SAE into AAVE using novel network architectures used language to language translation including LSTM, Bi-LSTM, Attention, and Transformer network components. The parallel corpora will be quantitatively reviewed and validated before using tested dialect translation model methods. Methodology will additionally be focused on low-resource machine translation due to the lack of large corpora containing AAVE. Both professional translators and large language model, ChatGPT, will be used to create parallel corpora containing AAVE and SAE. This short paper details the preliminary results of the assessment of these generated corpora as well as the accuracy of dialect machine translation models trained on them.},
booktitle = {Proceedings of the 7th ACM SIGCAS/SIGCHI Conference on Computing and Sustainable Societies},
pages = {50–59},
numpages = {10},
keywords = {AAVE, Bi-LSTM, ChatGPT, Dialect translation, LSTM, SAE, attention, low-resource languages, machine translation},
location = {New Delhi, India},
series = {COMPASS '24}
}

@inproceedings{10.5555/3523760.3523920,
author = {Pittman, Daniel E. and Haring, Kerstin S. and Kim, Pilyoung and Dossett, Benjamin and Ehman, Gillian and Gutierrez-Gutierrez, Elizabeth and Patil, Sneha and Sanchez, Ashley},
title = {A Novel Online Robot Design Research Platform to Determine Robot Mind Perception},
year = {2022},
publisher = {IEEE Press},
abstract = {A common issue in Human-Robot Interaction is a gap in understanding how robot designs are perceived by the user. A common issue encountered by practitioners of Machine Learning (ML) is a lack of salient data to use in training. The "Build-A-Bot" project is developing a novel research platform implemented as a web-accessible 3D game that affords data collection of many user-provided robot designs. The designs are used to train ML models to better evaluate robot designs, predict how a design will be perceived using Convolutional Neural Networks (CNNs), and create new robot designs using Generative Adversarial Networks (GANs). This paper outlines the current and future work accomplished by an interdisciplinary undergraduate student team at the University of Denver across Computer Science, Music, Psychology, and other related STEM fields that have created Build-A-Bot.},
booktitle = {Proceedings of the 2022 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {986–990},
numpages = {5},
keywords = {machine learning, fnirs, robot design},
location = {Sapporo, Hokkaido, Japan},
series = {HRI '22}
}

@inproceedings{10.1145/3576123.3576134,
author = {Finnie-Ansley, James and Denny, Paul and Luxton-Reilly, Andrew and Santos, Eddie Antonio and Prather, James and Becker, Brett A.},
title = {My AI Wants to Know if This Will Be on the Exam: Testing OpenAI’s Codex on CS2 Programming Exercises},
year = {2023},
isbn = {9781450399418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576123.3576134},
doi = {10.1145/3576123.3576134},
abstract = {The introduction of OpenAI Codex sparked a surge of interest in the impact of generative AI models on computing education practices. Codex is also the underlying model for GitHub Copilot, a plugin which makes AI-generated code accessible to students through auto-completion in popular code editors. Research in this area, particularly on the educational implications, is nascent and has focused almost exclusively on introductory programming (or CS1) questions. Very recent work has shown that Codex performs considerably better on typical CS1 exam questions than most students. It is not clear, however, what Codex’s limits are with regard to more complex programming assignments and exams. In this paper, we present results detailing how Codex performs on more advanced CS2 (data structures and algorithms) exam questions taken from past exams. We compare these results to those of students who took the same exams under normal conditions, demonstrating that Codex outscores most students. We consider the implications of such tools for the future of undergraduate computing education.},
booktitle = {Proceedings of the 25th Australasian Computing Education Conference},
pages = {97–104},
numpages = {8},
keywords = {AI, AlphaCode, CS1, CS2, Codex, DeepMind, GPT-3, GitHub, OpenAI, academic integrity, algorithms, artificial intelligence, code generation, copilot, data structures, deep learning, introductory programming, machine learning, neural networks, novice programming},
location = {Melbourne, VIC, Australia},
series = {ACE '23}
}

@inproceedings{10.1145/3711403.3711410,
author = {Wen, Jiacun and Lin, Yi and Si, Nian},
title = {Behavioral Analysis of Classroom Interactions Supported by Generative Artificial Intelligence},
year = {2025},
isbn = {9798400717468},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711403.3711410},
doi = {10.1145/3711403.3711410},
abstract = {Generative artificial intelligence, represented by Chatgpt, has been developing rapidly because of its superiority in form and process, covering almost all industries. In order to comply with the development of technology, some classroom teaching also incorporates it to build a generative artificial intelligence classroom. The classroom interaction behavior has an important reference value to help teachers reconstruct the teaching design and reform the teaching mode. The purpose of this paper is to derive significant behavioral sequence characteristics by coding and recording the actual video of generative artificial intelligence classrooms and analyzing the classroom interaction behaviors using lag sequence analysis. The study shows that the teacher-student interaction in the generative artificial intelligence classroom is more active, and the students' active participation in the classroom is very high, which will further promote the generative artificial intelligence classroom and realize the deep integration of the new technology and the classroom.},
booktitle = {Proceedings of the 2024 7th International Conference on Educational Technology Management},
pages = {49–54},
numpages = {6},
keywords = {Classroom interactive behavior, Generative artificial intelligence, lagged series analysis},
location = {
},
series = {ICETM '24}
}

@inproceedings{10.1145/3657604.3664701,
author = {Popescu, Diana M. and Joyner, David A.},
title = {ChatGPT's Performance on Problem Sets in an At-Scale Introductory Computer Science Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664701},
doi = {10.1145/3657604.3664701},
abstract = {This work in progress paper examines the impact of LLMs such as ChatGPT in a college-level introductory computing course offered simultaneously as a massive open online course (MOOC) on the edX platform, focusing on its strengths and limitations in solving coding assignments. The study reveals ChatGPT's proficiency in some areas while highlighting challenges in pseudo-code interpretation, handling multiple correct answers, and addressing complex problem statements. In order to discourage over-reliance on AI assistance from students while preserving scalability, the paper proposes strategies to enhance the difficulty of coding assignments by adding more creative elements in their structure. This research provides insights into the dynamics of AI in education and emphasizes the need for a balanced approach between technological assistance and genuine student participation.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {486–490},
numpages = {5},
keywords = {applied computing, artificial intelligence, e-learning},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@article{10.5555/3636988.3636996,
author = {Carter, Karla},
title = {"I, ChatBot": Co-Teaching Cybersecurity Courses With Generative AI},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {This tutorial is for computing science faculty who are intrigued by the notion that generative AI, such as OpenAI's ChatGPT or Google's Bard, can enhance the way we teach and students learn cybersecurity. Rather than questioning if faculty and students should use generative AI in the classroom, you're asking how faculty and students can use generative AI appropriately and responsibly in the classroom. Our students deserve to understand the tools shaping their future; generative AI is not going away and we need to prepare our students for a future where not knowing how to write generative AI prompts isn't an option.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {27–28},
numpages = {2}
}

@inproceedings{10.1145/3545945.3569830,
author = {Wermelinger, Michel},
title = {Using GitHub Copilot to Solve Simple Programming Problems},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569830},
doi = {10.1145/3545945.3569830},
abstract = {The teaching and assessment of introductory programming involves writing code that solves a problem described by text. Previous research found that OpenAI's Codex, a natural language machine learning model trained on billions of lines of code, performs well on many programming problems, often generating correct and readable Python code. GitHub's version of Codex, Copilot, is freely available to students. This raises pedagogic and academic integrity concerns. Educators need to know what Copilot is capable of, in order to adapt their teaching to AI-powered programming assistants. Previous research evaluated the most performant Codex model quantitatively, e.g. how many problems have at least one correct suggestion that passes all tests. Here I evaluate Copilot instead, to see if and how it differs from Codex, and look qualitatively at the generated suggestions, to understand the limitations of Copilot. I also report on the experience of using Copilot for other activities asked of students in programming courses: explaining code, generating tests and fixing bugs. The paper concludes with a discussion of the implications of the observed capabilities for the teaching of programming.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {academic integrity, code explanation, code generation, introductory programming, novice programming, openai codex, programming exercises, programming patterns, test generation},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3660043.3660172,
author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
title = {Research on the Application of AI in Personalized Education},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660172},
doi = {10.1145/3660043.3660172},
abstract = {Smart education uses advanced information technology, combined with educational theories and teaching methods, to achieve automatic, intelligent, and efficient teaching process. Personalized education represents the core content and goal of smart education because traditional classroom or remote teaching can't accurately grasp every student's individual knowledge and understanding of the content being taught. The development of artificial intelligence technology has provided technical support for smart education, particularly for personalized education. Natural language processing models such as chatGPT and knowledge graph technology have made personalized education increasingly practicable. This article describes the technological framework of smart education, its potential applications, and emphasizes the use of AI technology in personalized education. The article covers topic areas, including learning situation analysis, implementing personalized instruction, personalized teaching management.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {723–727},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3641554.3701806,
author = {Kannam, Suhas and Yang, Yuri and Dharm, Aarya and Lin, Kevin},
title = {Code Interviews: Design and Evaluation of a More Authentic Assessment for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701806},
doi = {10.1145/3641554.3701806},
abstract = {Generative artificial intelligence poses new challenges around assessment, increasingly driving introductory programming educators to employ invigilated exams. But exams do not afford more authentic programming experiences that involve planning, implementing, and debugging programs with computer interaction. In this experience report, we describe code interviews: a more authentic assessment method for take-home programming assignments. Through action research, we experimented with the number and type of questions as well as whether interviews were conducted individually or with groups of students. To scale the program, we converted most of our weekly teaching assistant (TA) sections to conduct code interviews on 5 major weekly take-home programming assignments. By triangulating data from 5 sources, we identified 4 themes. Code interviews (1) pushed students to discuss their work, motivating more nuanced but sometimes repetitive insights; (2) enabled peer learning, reducing stress in some ways but increasing stress in other ways; (3) scaled with TA-led sections, replacing familiar practice with an unfamiliar assessment; (4) focused on student contributions, limiting opportunities for TAs to give guidance and feedback. We reflect on the design of code interviews for student experience, academic integrity, and teacher workload.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {554–560},
numpages = {7},
keywords = {authentic assessment, introductory programming, oral exams},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3699538.3699567,
author = {Amoozadeh, Matin and Nam, Daye and Prol, Daniel and Alfageeh, Ali and Prather, James and Hilton, Michael and Srinivasa Ragavan, Sruti and Alipour, Amin},
title = {Student-AI Interaction: A Case Study of CS1 students},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699567},
doi = {10.1145/3699538.3699567},
abstract = {Generative artificial intelligence tools (Generative AI), such as ChatGPT, allow users to interact with them in intuitive ways (e.g., conversational) and receive (mostly) good-quality answers. In education, such systems can support students’ learning objectives by providing accessible explanations and examples even when students pose vague queries. But, they also encourage undesired help-seeking behaviors, such as by providing solutions to the students’ homework. Therefore, it is important to better understand how students approach such tools and the potential issues such approaches might present for the learners.In this paper, we present a case study for understanding student-AI collaboration to solve programming tasks in the CS1 introductory programming course. To this end, we recruited a gender-balanced majority non-white set of 15 CS1 students at the University of Houston, a large public university in the US. We observed them solving programming tasks. We used a mixed-method approach to study their interactions as they tackled Python programming tasks, focusing on when and why they used ChatGPT for problem-solving. We analyze and classify the questions submitted by the 15 participants to ChatGPT. Additionally, we analyzed user interaction patterns, their reactions to ChatGPT’s responses, and the potential impacts of Generative AI on their perception of self-efficacy.Our results suggest that, in about a third of the cases, the student attempted to complete the task by submitting the full description of the tasks to ChatGPT without making any effort on their own. We also observed that few students verified their solutions. We discuss the potential implications of these results.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {13},
numpages = {13},
keywords = {Generative Artificial Intelligence, Human-AI Interaction, Self-regulation, CS1, User study, Novice programmers},
location = {
},
series = {Koli Calling '24}
}

@article{10.5555/3636988.3636989,
author = {Conrad, Susan and Dimitoglou, George and Flinn, Michael B. and Morgan, Jacob and Gupta, Pranshu and Mengistu, Zelalem},
title = {Current Challenges in Computing Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {Discussion about topics related to current issues in computing science education focusing on three themes: "That AI thing...", "Post-Pandemic Strategies," and "Partnerships."The first theme attempts to address the benefits, challenges, and practical applications of integrating Generative AI technologies, such as ChatGPT, Bard, and CoPilot, into educational settings. Exploration of academic honesty and intellectual property and strategies for how these AI tools can be utilized in classrooms, labs, student projects, assignments, academic programs, and even preparing students for future job opportunities.The second theme revolves around post-pandemic approaches and initiatives to explore aimed at re-engaging students in both classroom activities and extracurricular pursuits. Exploration of strategies to enhance undergraduate and graduate student participation in internships, research opportunities, and the unique challenges and characteristics of job hunting in the current educational and economic landscape.The third theme highlights the significance of forging partnerships between educational institutions and industry stakeholders. Exploring campus ideas and efforts to establish and strengthen relationships with industry partners. Discussion on collaborative projects, research initiatives, mentorship programs, and ways to bridge the gap between academia and industry to benefit both students and the workforce.The final theme is open-ended, encouraging attendees to contemplate additional questions that may initiate reflection on emerging trends, pedagogical challenges, technological advancements, and any other critical issues that computing science educators should address to stay effective and responsive in their roles.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {16–17},
numpages = {2}
}

@inproceedings{10.1145/3640544.3645234,
author = {George, Samuel D and Dewan, Prasun},
title = {NotebookGPT – Facilitating and Monitoring Explicit Lightweight Student GPT Help Requests During Programming Exercises},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645234},
doi = {10.1145/3640544.3645234},
abstract = {The success of GPT with coding tasks has made it important to consider the impact of GPT and similar models on teaching programming. Students’ use of GPT to solve programming problems can hinder their learning. However, they might also get significant benefits such as quality feedback on programming style, explanations of how a given piece of code works, help with debugging code, and the ability to see valuable alternatives to their code solutions. We propose a new design for interacting with GPT called Mediated GPT with the goals of (a) providing students with access to GPT but allowing instructors to programmatically modify responses to prevent hindrances to student learning and combat common GPT response concerns, (b) helping students generate and learn to create effective prompts to GPT, and (c) tracking how students use GPT to get help on programming exercises. We demonstrate a first-pass implementation of this design called NotebookGPT.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {62–65},
numpages = {4},
keywords = {ChatGPT, Computer programming, GPT, Intelligent tutoring systems, Learning at scale},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3639474.3640059,
author = {Fwa, Hua Leong},
title = {Experience Report: Identifying common misconceptions and errors of novice programmers with ChatGPT},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640059},
doi = {10.1145/3639474.3640059},
abstract = {Identifying the misconceptions of novice programmers is pertinent for informing instructors of the challenges faced by their students in learning computer programming. In the current literature, custom tools, test scripts were developed and, in most cases, manual effort to go through the individual codes were required to identify and categorize the errors latent within the students' code submissions. This entails investment of substantial effort and time from the instructors. In this study, we thus propose the use of ChatGPT in identifying and categorizing the errors. Using prompts that were seeded only with the student's code and the model code solution for questions from two lab tests, we were able to leverage on ChatGPT's natural language processing and knowledge representation capabilities to automatically collate frequencies of occurrence of the errors by error types. We then clustered the generated error descriptions for further insights into the misconceptions of the students. The results showed that although ChatGPT was not able to identify the errors perfectly, the achieved accuracy of 93.3% is sufficiently high for instructors to have an aggregated picture of the common errors of their students. To conclude, we have proposed a method for instructors to automatically collate the errors latent within the students' code submissions using ChatGPT. Notably, with the novel use of generated error descriptions, the instructors were able to have a more granular view of the misconceptions of their students, without the onerous effort of manually going through the students' codes.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {233–241},
numpages = {9},
keywords = {LLM, ChatGPT, misconception, programming, errors, cluster, prompts},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3545945.3569823,
author = {Denny, Paul and Kumar, Viraj and Giacaman, Nasser},
title = {Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569823},
doi = {10.1145/3545945.3569823},
abstract = {GitHub Copilot is an artificial intelligence tool for automatically generating source code from natural language problem descriptions. Since June 2022, Copilot has officially been available for free to all students as a plug-in to development environments like Visual Studio Code. Prior work exploring OpenAI Codex, the underlying model that powers Copilot, has shown it performs well on typical CS1 problems thus raising concerns about its potential impact on how introductory programming courses are taught. However, little is known about the types of problems for which Copilot does not perform well, or about the natural language interactions that a student might have with Copilot when resolving errors. We explore these questions by evaluating the performance of Copilot on a publicly available dataset of 166 programming problems. We find that it successfully solves around half of these problems on its very first attempt, and that it solves 60% of the remaining problems using only natural language changes to the problem description. We argue that this type of prompt engineering, which we believe will become a standard interaction between human and Copilot when it initially fails, is a potentially useful learning activity that promotes computational thinking skills, and is likely to change the nature of code writing skill development.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1136–1142},
numpages = {7},
keywords = {artificial intelligence, cs1, foundation models, github copilot, introductory programming, large language models, openai},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3568813.3600138,
author = {Lau, Sam and Guo, Philip},
title = {From "Ban It Till We Understand It" to "Resistance is Futile": How University Programming Instructors Plan to Adapt as More Students Use AI Code Generation and Explanation Tools such as ChatGPT and GitHub Copilot},
year = {2023},
isbn = {9781450399760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568813.3600138},
doi = {10.1145/3568813.3600138},
abstract = {Over the past year (2022–2023), recently-released AI tools such as ChatGPT and GitHub Copilot have gained significant attention from computing educators. Both researchers and practitioners have discovered that these tools can generate correct solutions to a variety of introductory programming assignments and accurately explain the contents of code. Given their current capabilities and likely advances in the coming years, how do university instructors plan to adapt their courses to ensure that students still learn well? To gather a diverse sample of perspectives, we interviewed 20 introductory programming instructors (9 women + 11 men) across 9 countries (Australia, Botswana, Canada, Chile, China, Rwanda, Spain, Switzerland, United States) spanning all 6 populated continents. To our knowledge, this is the first empirical study to gather instructor perspectives about how they plan to adapt to these AI coding tools that more students will likely have access to in the future. We found that, in the short-term, many planned to take immediate measures to discourage AI-assisted cheating. Then opinions diverged about how to work with AI coding tools longer-term, with one side wanting to ban them and continue teaching programming fundamentals, and the other side wanting to integrate them into courses to prepare students for future jobs. Our study findings capture a rare snapshot in time in early 2023 as computing instructors are just starting to form opinions about this fast-growing phenomenon but have not yet converged to any consensus about best practices. Using these findings as inspiration, we synthesized a diverse set of open research questions regarding how to develop, deploy, and evaluate AI coding tools for computing education.},
booktitle = {Proceedings of the 2023 ACM Conference on International Computing Education Research - Volume 1},
pages = {106–121},
numpages = {16},
keywords = {AI coding tools, ChatGPT, Copilot, LLM, instructor perspectives},
location = {Chicago, IL, USA},
series = {ICER '23}
}

@article{10.5555/3715638.3715656,
author = {Roll, James},
title = {AI as a Learning Tool for Introductory Programming},
year = {2024},
issue_date = {September 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {4},
issn = {1937-4771},
abstract = {The goal of this assignment is to introduce introductory programming students to using generative AI tools like Claude and ChatGPT to help them in learning introductory programming. Students are shown how they can use AI tools to help explain basic programming concepts, decode cryptic error messages, explain why a program isn't working, and find syntax errors in and suggest fixes. Students are also encouraged to avoid using AI Tools to fully write programs at this point in their education, and introduced to the limitations generative AI tools for programming. This version of the assignment was written for an introductory Java programming course, but could easily be adapted to other programming languages.},
journal = {J. Comput. Sci. Coll.},
month = sep,
pages = {45},
numpages = {1}
}

@inproceedings{10.1145/3677619.3678092,
author = {Bahr, Tobias and Manzocco, Mario and Schuster, Dennis},
title = {Differentiated Tasks by ChatGPT for Secondary Computer Science Education: Useful or not?},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678092},
doi = {10.1145/3677619.3678092},
abstract = {In recent years, there has been a growing interest in exploring the capabilities of AI chatbots, such as ChatGPT. Studies have investigated diverse applications, including the response of AI chatbots to undergraduate exam questions and the generation of student exercises for programming. However, the question remains if AI chatbots provide adequate results for K-12 CS in different application scenarios. AI chatbots are increasingly integrated into K-12 education by both students and teachers. In this context, a tool using didactical parameters was created to differentiate tasks with ChatGPT-4 in an ongoing project. Preliminary findings from this work in progress reveal that teachers see a benefit using the tool. Future directions for using the tool are discussed.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {34},
numpages = {2},
keywords = {AI chatbots, ChatGPT, Computer Science Education, Expert rating, K-12},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@inproceedings{10.1145/3641555.3705037,
author = {Piech, Chris and Sahami, Mehran and Alonso, Yasmine and Liu, Katie and Arifov, Javokhir and Sreenivas, Anjali and Webber, Dan and Zheng, Tina and Nguyen, Ngoc and Mlauzi, Iddah and Woodrow, Juliette},
title = {Infinite Story},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705037},
doi = {10.1145/3641555.3705037},
abstract = {In Infinite Story, students build a choose-your-own-adventure game that integrates generative AI to create a dynamic, interactive "infinite story" experience. The game is powered by nested dictionary (JSON) objects that store pre-existing scenes. Each scene is a nested dictionary, containing user choices, descriptions, and more. Students are challenged to navigate and manipulate these deeply nested data structures, which helps them appreciate the utility and complexity of dictionary objects. When a user ventures into an undefined scene, the program makes an API call to ChatGPT to generate the next scene, allowing the adventure to continue seamlessly. To the best of our knowledge it is one of the first assignments in intro CS that uses ChatGPT. What makes this assignment truly nifty is how it teaches students to leverage generative AI in a creative, meaningful way. By blending generative storytelling with technical skills, students get to see the power of AI in extending their projects beyond predefined boundaries, creating an open-ended, exciting experience. Many students expanded on this assignment for their final projects, creating sophisticated programs like AI-driven Chess and Go games. Using the techniques from this assignment, they leveraged the course's OpenAI integration to build functional AI agents that enhanced gameplay. These projects showcased the flexibility of the assignment, inspiring students to think critically about the creative and practical applications of AI in real-world contexts.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1750},
numpages = {1},
keywords = {API, CS1, JSON, dictionaries, generative AI, nested structures, python, storytelling},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@article{10.5555/3715622.3715630,
author = {Lindoo, Ed and Lotfy, Mohamed},
title = {Generative AI and its Impact on the CS Classroom and Programmers},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {As the integration of generative artificial intelligence (AI) in educational settings becomes more widespread, students, teachers, and educational institutions face the challenge of utilizing these technologies in a responsible manner. The responsible use of generative AI can help CS and IT students develop critical thinking, enhance their learning experience, facilitate the learning process, can assist in understanding code concepts, programming skills, and/or enhancing the programming knowledge. The aim of this investigation is on how students might utilize, and potentially abuse, generative AI. In this paper we provide examples of how generative AI can be used to generate code modules. We discuss the use of generative AI in programming classes as well as its impact on the future of programming and programmers.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {35–50},
numpages = {16}
}

@article{10.1145/3572780,
author = {Zhang, Zhijie and Li, Wenzhong and Ding, Wangxiang and Zhang, Linming and Lu, Qingning and Hu, Peng and Gui, Tong and Lu, Sanglu},
title = {STAD-GAN: Unsupervised Anomaly Detection on Multivariate Time Series with Self-training Generative Adversarial Networks},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3572780},
doi = {10.1145/3572780},
abstract = {Anomaly detection on multivariate time series (MTS) is an important research topic in data mining, which has a wide range of applications in information technology, financial management, manufacturing system, and so on. However, the state-of-the-art unsupervised deep learning models for MTS anomaly detection are vulnerable to noise and have poor performance on the training data containing anomalies. In this article, we propose a novel Self-Training based Anomaly Detection with Generative Adversarial Network (GAN) model called STAD-GAN to address the practical challenge. The STAD-GAN model consists of a generator-discriminator structure for adversarial learning and a neural network classifier for anomaly classification. The generator is learned to capture the normal data distribution, and the discriminator is learned to amplify the reconstruction error of abnormal data for better recognition. The proposed model is optimized with a self-training teacher-student framework, where a teacher model generates reliable high-quality pseudo-labels to train a student model iteratively with a refined dataset so that the performance of the anomaly classifier can be gradually improved. Extensive experiments based on six open MTS datasets show that STAD-GAN is robust to noise and achieves significant performance improvement compared to the state-of-the-art.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {71},
numpages = {18},
keywords = {unsupervised learning, self-training, generative adversarial network, anomaly detection, Multivariate time series}
}

@inproceedings{10.1145/3626252.3630958,
author = {Cambaz, Doga and Zhang, Xiaoling},
title = {Use of AI-driven Code Generation Models in Teaching and Learning Programming: a Systematic Literature Review},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630958},
doi = {10.1145/3626252.3630958},
abstract = {The recent emergence of LLM-based code generation models can potentially transform programming education. To pinpoint the current state of research on using LLM-based code generators to support the teaching and learning of programming, we conducted a systematic literature review of 21 papers published since 2018. The review focuses on (1) the teaching and learning practices in programming education that utilized LLM-based code generation models, (2) characteristics and (3) performance indicators of the models, and (4) aspects to consider when utilizing the models in programming education, including the risks and challenges. We found that the most commonly reported uses of LLM-based code generation models for teachers are generating assignments and evaluating student work, while for students, the models function as virtual tutors. We identified that the models exhibit accuracy limitations; generated content often contains minor errors that are manageable by instructors but pose risks for novice learners. Moreover, risks such as academic misconduct and over-reliance on the models are critical when considering integrating these models into education. Overall, LLM-based code generation models can be an assistive tool for both learners and instructors if the risks are mitigated.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {172–178},
numpages = {7},
keywords = {artificial intelligence in education, code generation models, large language models, programming education, systematic review},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3637036.3637054,
author = {Chundur, Suguna and Hall, Kristi},
title = {Towards an AI-Aware Pedagogy in IT Education},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {4},
issn = {1937-4771},
abstract = {With the recent sudden explosion in the development of AI-based tools there is uncertainty among educators on its impact in teaching and learning as well as concerns about integrity of student work. Simultaneously, AI tools present a unique opportunity to personalize education and encourage self-driven learning. Hence, there is an urgent need to understand the impact of AI-based tools on teaching and learning and to find a way forward in building a framework that directly addresses the challenges raised by generative AI in three main areas: strategies for AI-aware teaching, reliability of AI-generated knowledge and design of assessments. With a view towards acquiring a clearer picture of the new AI-aware teaching landscape, we have attempted to incorporate AI-tools in the classroom. We have experimented with using various AI-tools in designing assignments that co-opt AI for teaching and learning, whether it is a written essay on an IT topic, a programming assignment in Java or troubleshooting a systems administration issue, topics that cover the breath of our Information Technology program. The assessments provide clear instructions to students on acceptable and unacceptable ways of using specific AI-tools in completing the work. There is a feedback question in each assessment that seeks students' perception of AI-tools used, its strengths and weaknesses in learning. We plan to continue the experiment for an entire academic year using this methodology in various IT courses. In this work-in-progress presentation, we will discuss the results of the assessments administered so far and provide an overview of the resulting draft AI-aware framework of teaching and learning in the IT discipline.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {106},
numpages = {1}
}

@inproceedings{10.1145/3675812.3675877,
author = {Huang, Lei and Liu, Xiyu and Xie, Chunqiu and Zhu, Wenjuan},
title = {Investigating Factors Influencing University Students' Use of intelligent Audio Reading Platform for Reading and Learning},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675877},
doi = {10.1145/3675812.3675877},
abstract = {In recent years, with the rapid development of information technology and advances in smart technologies, the modes of reading have become more diversified. It is now possible not only to read books with one's eyes but also to "listen" to them, offering the better reading experience. University students need to constantly absorb information and knowledge from the outside world, which means that they need an efficient and easy way to read and learn, and the use of intelligent audio reading platform can fulfill this need. Therefore, in order to propose strategies to promote university students' use of intelligent audio reading platforms for reading and learning, this study employs a questionnaire survey to investigate the factors influencing university students' behavioral intention to use audio reading platform for reading and learning. A sample of 236 university students was analyzed using the Partial Least Squares Structural Equation Modelling technique (PLS-SEM). Results showed that perceived usefulness, perceived ease of use, and social influence have a significant positive influence on the behavioral intention of university students to use audio reading platform for reading and learning, while perceived cost and perceived enjoyment have no significant influence on the behavioral intention. Based on these results, this study proposes strategies for university teachers, intelligent audio reading platform developers and operators to promote university students’ use of intelligent audio reading platform for reading and learning. For university teachers, they can promote the adoption of audio reading by guiding students to use audio reading platforms for learning. For developers of an intelligent audio reading platform, based on generative AI, they can enhance reading and learning experience for university students by optimizing personalized recommendation functions and offering diverse reading preferences, such as pronunciation styles and speeds. For operators of intelligent audio reading platforms, they can ensure high-quality content, stable network connections, and reasonable pricing strategies to enhance university students’ reading and learning experience.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {131–137},
numpages = {7},
keywords = {Intelligent audio reading platform, influencing factors, university students},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3649165.3690125,
author = {Kerslake, Chris and Denny, Paul and Smith, David H. and Prather, James and Leinonen, Juho and Luxton-Reilly, Andrew and MacNeil, Stephen},
title = {Integrating Natural Language Prompting Tasks in Introductory Programming Courses},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690125},
doi = {10.1145/3649165.3690125},
abstract = {Introductory programming courses often emphasize mastering syntax and basic constructs before progressing to more complex and interesting programs. This bottom-up approach can be frustrating for novices, shifting the focus away from problem solving and potentially making computing less appealing to a broad range of students. The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module. The first requires students to solve computational problems by writing natural language prompts, emphasizing problem-solving over syntax. The second involves students crafting prompts to generate code equivalent to provided fragments, to foster an understanding of the relationship between prompts and code. Most of the students in the course had reported finding programming difficult to learn, often citing frustrations with syntax and debugging. We found that self-reported difficulty with learning programming had a strong inverse relationship with performance on traditional programming assessments such as tests and projects, as expected. However, performance on the natural language tasks was less strongly related to self-reported difficulty, suggesting they may target different skills. Learning how to communicate with AI coding models is becoming an important skill, and natural language prompting tasks may appeal to a broad range of students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {88–94},
numpages = {7},
keywords = {cs1, eipe, explain in plain english, introductory programming, llm, natural language prompting, prompt engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3631802.3631848,
author = {Deriba, Fitsum Gizachew and Sanusi, Ismaila Temitayo and Sunday, Amos Oyelere},
title = {Enhancing Computer Programming Education using ChatGPT- A Mini Review},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631848},
doi = {10.1145/3631802.3631848},
abstract = {This paper aims to provide insights into how ChatGPT enhances computer programming education by synthesizing existing studies using rapid review. We analysed 13 articles published in 2023, where studies focused on different aspects of basic programming education. The results indicate that 21% of these studies demonstrate that ChatGPT served as a tool for code explanation and handling complex topics. However, 36% show that ChatGPT had difficulty answering non-text-based and code-related questions, revealing reliability and accuracy issues with these tools. Another 36% of the studies showed that blindly over-reliance on ChatGPT affected critical thinking, student creativity, and problem-solving skills in programming education. 46% of the studies indicated the need to provide clear guidelines and employ plagiarism-detection tools to instruct students effectively. We suggest that educators should adopt diverse approaches to integrating ChatGPT as an educational tool while highlighting ethical considerations and model limitations.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {45},
numpages = {2},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@inproceedings{10.1145/3613904.3642773,
author = {Kazemitabaar, Majeed and Ye, Runlong and Wang, Xiaoning and Henley, Austin Zachary and Denny, Paul and Craig, Michelle and Grossman, Tovi},
title = {CodeAid: Evaluating a Classroom Deployment of an LLM-based Programming Assistant that Balances Student and Educator Needs},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642773},
doi = {10.1145/3613904.3642773},
abstract = {Timely, personalized feedback is essential for students learning programming. LLM-powered tools like ChatGPT offer instant support, but reveal direct answers with code, which may hinder deep conceptual engagement. We developed CodeAid, an LLM-powered programming assistant delivering helpful, technically correct responses, without revealing code solutions. CodeAid answers conceptual questions, generates pseudo-code with line-by-line explanations, and annotates student’s incorrect code with fix suggestions. We deployed CodeAid in a programming class of 700 students for a 12-week semester. A thematic analysis of 8,000 usages of CodeAid was performed, further enriched by weekly surveys, and 22 student interviews. We then interviewed eight programming educators to gain further insights. Our findings reveal four design considerations for future educational AI assistants: D1) exploiting AI’s unique benefits; D2) simplifying query formulation while promoting cognitive engagement; D3) avoiding direct responses while encouraging motivated learning; and D4) maintaining transparency and control for students to asses and steer AI responses.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {650},
numpages = {20},
keywords = {AI assistants, AI tutoring, class deployment, design guidelines, educational technology, generative AI, intelligent tutoring systems, large language models, programming education},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3689535.3689537,
author = {Stone, Irene},
title = {Investigating the Use of ChatGPT to Support the Learning of Python Programming Among Upper Secondary School Students: A Design-Based Research Study},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689537},
doi = {10.1145/3689535.3689537},
abstract = {This study investigates how ChatGPT can be used to support the learning of Python programming among upper second-level students in an Irish classroom. It addresses critical gaps in the literature, such as the lack of research at secondary level, the need for human-centered studies conducted over time, and the absence of guidelines for integrating ChatGPT into introductory programming education. Employing a design-based research methodology, this study aims to understand student engagement with ChatGPT and investigates how to support their use of prompts when learning to program. The research involves students as co-creators alongside their teacher, who is also the researcher, in developing a pedagogical framework that integrates ChatGPT into Python programming education.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {11},
numpages = {1},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, design-based research, generative AI, human-centered, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3702386.3702392,
author = {Maurat, John Ivan Curbano and Isip, Elsie Villareal and Lumabas, Aileen Gail Regala},
title = {A Comparative Study of Gender Differences in the Utilization and Effectiveness of AI-Assisted Learning Tools in Programming Among University Students},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702392},
doi = {10.1145/3702386.3702392},
abstract = {This comparative study examines gender differences in the use and efficacy of AI-assisted learning tools for programming among university students. A survey-based methodology was used to collect data from a varied sample of students across different academic years, ensuring representation from diverse demographic groups. The study sought to investigate the frequency of AI tool use and students' assessments of their efficacy in learning programming fundamentals. Notably, the findings reveal that students overwhelmingly prefer ChatGPT as the primary AI tool for learning programming concepts, with 312 mentions, making it the most popular and presumably the most useful tool among respondents. Following ChatGPT, Blackbox AI was the second most mentioned, with 74 students highlighting its utility. Gemini, Co-pilot, Assistguru, and Amazon Code Whisperer followed in popularity, with varying levels of student engagement and perceived usefulness. The study also found a substantial positive association (r = 0.296, p &lt; 0.05) between AI tool usage frequency and perceived effectiveness in programming education, indicating the potential benefits of increased interaction with AI tools. Gender disparities in tool preferences were identified, with male students showing a preference for specific instruments over their female counterparts. Despite these differences, there was little variation in the overall perceived efficacy of AI technology between genders. Furthermore, first-year students exhibited the highest frequency of AI tool usage, particularly on a weekly basis, emphasizing the importance of early exposure on usage patterns throughout students' academic careers. These findings underscore the necessity of considering gender preferences and demographics when developing and implementing AI-powered educational systems. The study recommends individualized approaches to enhance inclusivity and effectiveness in programming education, aiming to inform future advancements in educational technology and pedagogy.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {30–34},
numpages = {5},
keywords = {Educational Technology, Gender Differences, Learning Outcomes, Programming, User Preferences},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3702163.3702448,
author = {Domingues, Ines and Rasteiro, Deolinda Maria Lopes Dias},
title = {A Paradigm Shift in Teaching Machine Learning to Sustainable City Management Master Students},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702448},
doi = {10.1145/3702163.3702448},
abstract = {Teaching machine learning (ML) to students with diverse backgrounds, such as those in the Master in Sustainable City Management program, presents unique challenges. Traditional programming-based approaches can be daunting for students unfamiliar with coding. Initially, software tools like RapidMiner, Weka, and Orange Data Mining were employed to simplify the learning process. However, this method often fell short in conveying deep ML concepts, which often resulted in a superficial understanding. With the advent of user-friendly coding aids like ChatGPT, a transition to Python-based instruction was implemented. Additionally, the incorporation of active learning strategies has further enhanced student engagement and understanding. This shift has shown to improve comprehension and practical skills, evidenced by higher median and maximum grades on the evaluation tool, a final project. A multiple linear regression analysis suggested that performance in “Big Data” significantly predicts grades on the Artificial Intelligence module, and the teaching approach has a marginally significant impact. Subjective analysis by the professor, also proved a better grasp of the concepts by the students.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {413–417},
numpages = {5},
keywords = {Machine Learning Education, Python Programming, Sustainable City Management, Active Learning, Code Assistance Tools},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3669754.3669806,
author = {Batac, Carlo Antonio and Baroja, Marc Jethro and Caballero, Don John Daniel and Coloma, Louis Gabriel and Tan, Lind Matthew and Ebardo, Ryan},
title = {Do Human Beliefs and Traits Influence the Adoption of ChatGPT among Programming Students?},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669806},
doi = {10.1145/3669754.3669806},
abstract = {Abstract: Increased use of generative artificial intelligence or AI in various academic activities such as programming is a significant milestone in technology diffusion in learning. To bring AI closer to how programmers think, behave, and interact, it is imperative for research to establish a clear connection between various human factors that lead to its adoption. Using a model based on the Theory of Reasoned Action, we positioned human traits of academic stress, risk propensity, neuroticism, and computer self-efficacy as factors that positively influence attitudes toward the use of AI in programming among university students. We further posited that attitude and social norms lead to the behavioral intention to use AI in programming. We used PLS-SEM to analyze responses from 131 programming students who use ChatGPT to accomplish learning tasks. We found that both academic stress and computer self-efficacy influence attitudes toward using AI in programming. While attitude positively influences the behavioral intention to use ChatGPT, we found that risk propensity and neuroticism do not affect attitude, and social norms do not influence behavioral intention. We discuss the implications of our investigation to the industry and the academe.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {339–344},
numpages = {6},
keywords = {ChatGPT, PLS-SEM, education, generative AI, programming},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@article{10.5555/3717781.3717788,
author = {Works, Karen E.},
title = {Three Phase - Adversarial Search - Tile Games},
year = {2024},
issue_date = {November 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {5},
issn = {1937-4771},
abstract = {With the advent of chatGPT and Copilot I find that students are not delving deep enough into the implementation of search approaches. To combat this, I decided to implement a three-phase adversarial search project. After lectures on adversarial search approaches and implementation examples, students are given code to a user versus user basic tile game. They are informed of the three phases of the assignment with the goal of encouraging students to understand that they are expected to be able to read and understand an adversarial search logic. In the first phase, all students use the user versus user basic tile game to implement a computer versus user basic tile game app that utilizes an adversarial search. In the second phase, students create and implement their own computer versus user basic tile game app by changing the rules on how the tile game is won and what a valid move is. In the third phase, students are given a timed 10 minute quiz where they are given code for a tile game and the rules for how the game is won and valid moves. The students must identify if the adversarial search is properly implemented and if not then what logic is not correct.},
journal = {J. Comput. Sci. Coll.},
month = nov,
pages = {29–32},
numpages = {4}
}

@inproceedings{10.1145/3544548.3580919,
author = {Kazemitabaar, Majeed and Chow, Justin and Ma, Carl Ka To and Ericson, Barbara J. and Weintrop, David and Grossman, Tovi},
title = {Studying the effect of AI Code Generators on Supporting Novice Learners in Introductory Programming},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580919},
doi = {10.1145/3544548.3580919},
abstract = {AI code generators like OpenAI Codex have the potential to assist novice programmers by generating code from natural language descriptions, however, over-reliance might negatively impact learning and retention. To explore the implications that AI code generators have on introductory programming, we conducted a controlled experiment with 69 novices (ages 10-17). Learners worked on 45 Python code-authoring tasks, for which half of the learners had access to Codex, each followed by a code-modification task. Our results show that using Codex significantly increased code-authoring performance (1.15x increased completion rate and 1.8x higher scores) while not decreasing performance on manual code-modification tasks. Additionally, learners with access to Codex during the training phase performed slightly better on the evaluation post-tests conducted one week later, although this difference did not reach statistical significance. Of interest, learners with higher Scratch pre-test scores performed significantly better on retention post-tests, if they had prior access to Codex.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {455},
numpages = {23},
keywords = {AI Coding Assistants, AI-Assisted Pair-Programming, ChatGPT, Copilot, GPT-3, Introductory Programming, K-12 Computer Science Education, Large Language Models, OpenAI Codex},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3658549.3658566,
author = {Ho, Chia-Ling and Liu, Xin-Ying and Qiu, Yu-Wei and Yang, Shih-Yang},
title = {Research on Innovative Applications and Impacts of Using Generative AI for User Interface Design in Programming Courses},
year = {2024},
isbn = {9798400709180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658549.3658566},
doi = {10.1145/3658549.3658566},
abstract = {Generative Artificial Intelligence (GAI) has become a hot topic nowadays, as its powerful content generation models enable users to instantly create everything from digital media products to coding examples through simple text queries, providing more possibilities in the field of education. This study aims to investigate the impact of Generative AI intervention in teaching App Inventor programming courses, analyzing the differences between UI materials designed by traditional teachers based on their professional knowledge and experience, and UI materials created by Generative AI in classroom teaching. The study also evaluates the impact of Generative AI on students' learning outcomes and motivation through satisfaction and Technology Acceptance Model (TAM) questionnaires. The results indicate that UI materials produced through Generative AI effectively enhance students' satisfaction with the course and their acceptance of new technologies. Compared to traditional teaching methods, Generative AI significantly saves teachers' time and effort in designing materials while simultaneously improving teaching efficiency and quality.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology, Data Science, and Optimization},
pages = {68–72},
numpages = {5},
keywords = {Generative artificial intelligence, Intelligent assistant, Learning effectiveness, Programming course, User interface design},
location = {Taipei, Taiwan},
series = {I-DO '24}
}

@inproceedings{10.1145/3691620.3695470,
author = {Cao, Jialun and Chen, Zhiyong and Wu, Jiarong and Cheung, Shing-Chi and Xu, Chang},
title = {JavaBench: A Benchmark of Object-Oriented Code Generation for Evaluating Large Language Models},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695470},
doi = {10.1145/3691620.3695470},
abstract = {Code generation benchmarks such as HumanEval are widely adopted to evaluate LLMs' capabilities. However, after consolidating the latest 24 benchmarks, we noticed three significant imbalances. First, imbalanced programming language. 95.8% of benchmarks involve Python, while only 5 benchmarks involve Java, resulting in an insufficient understanding of LLMs' capability to generate Java code. Second, imbalanced code granularity. Function-/statement-level benchmarks account for over 83.3% of benchmarks. Only a mere handful extends to class-/project-levels, and all are limited to Python. Third, lacking advanced features. Existing benchmarks primarily assess basic coding skills (e.g., variables, operators, and control structures), while overlooking advanced Object-Oriented Programming (OOP) features (i.e., encapsulation, inheritance, and polymorphism). Considering the prevalence of these advanced features in real-world Java project development, constructing benchmarks to test LLMs on handling OOP features is necessary.To fill these gaps, we propose JavaBench, a project-level Java benchmark that exercises OOP features. It comprises four Java projects with 389 methods in 106 Java classes. The test coverage is up to 92%, and JavaBench is attested by 282 undergraduate students, reaching a 90.93/100 average score (i.e., pass rate against the test suite), ensuring the quality of documentation, code skeleton, and tests. To better evaluate LLM's capability against JavaBench, we introduce a systematic evaluation design covering three context settings and five synthesis strategies at two granularities using three hierarchical metrics. Our extensive experiment yields several interesting findings. First, we noticed that regarding project-level Java programming, LLMs are far behind undergraduate students (no project can be correctly completed by any studied LLMs, and at most 48.24% Pass@5 in a more relaxed evaluation). Second, using method signature as prompt context may strike an ideal balance for project-level code generation. JavaBench is publicly available at https://github.com/java-bench/JavaBench. We also release a leaderboard and invite model developers to participate and test their models against JavaBench at https://java-bench.github.io/leaderboard.html.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {870–882},
numpages = {13},
keywords = {large language model, program synthesis, object-oriented programming},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3626253.3635522,
author = {Ruiz, Pati and Rangel, Alessandra and Coenraad, Merijke},
title = {Using Generative AI to Support PK-12 Teaching and Learning: Developing Sample Lessons and More},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635522},
doi = {10.1145/3626253.3635522},
abstract = {North Salem Central School District (North Salem) has worked with researchers as part of a larger Research Practice Partnership (RPP) to design and implement an inclusive PK-12 computing pathway in their district. This poster describes how teachers used Generative AI (GenAI) tools in three areas: (1) the development of sample computational thinking (CT) lesson plans; (2) initial brainstorming; and (3) professional learning.As North Salem reflected on their use of GenAI tools, they named two AI tools specifically: OpenAI's ChatGPT-4 and Bing's Image Creator. Teachers also describe ethical dilemmas that they faced when integrating GenAI tools as well as other concerns that will be described below. This work builds on the growing literature on the use of Generative AI tools to support the day-to-day work of teachers.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1800–1801},
numpages = {2},
keywords = {K-12 computer science education, ducational equity, formative assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3675812.3675843,
author = {Zhang, Wenting and Zhang, Qiaorong and Cai, Mingming and Wang, Dongqing and Zheng, Yafeng},
title = {Navigating the Application Challenges of ChatGPT in Education: Promoting Responsible Use and Minimizing Mental Risks},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675843},
doi = {10.1145/3675812.3675843},
abstract = {With the wide application of artificial intelligence, especially generative AI like ChatGPT, the era of significant transformation in education has quietly arrived. This article first explores the current applications of ChatGPT in logical learning, language learning, as well as personalized and effective teaching. It then deeply analyzes the challenges brought by the application of ChatGPT in education from three aspects: digital ethics, psychological risks for teachers and students, and educational governance. Based on its potential risks and challenges, effective measures and suggestions are proposed, including improving information literacy education, fully utilizing human-computer collaboration, and establishing clear regulations for the use of ChatGPT. These measures aim to ensure that ChatGPT can maximize its application value in the field of education while minimizing the mental risks.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {23–28},
numpages = {6},
keywords = {Application Challenges, ChatGPT, Mental Risks},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3706598.3713748,
author = {Ma, Shuai and Wang, Junling and Zhang, Yuanhao and Ma, Xiaojuan and Wang, April Yi},
title = {DBox: Scaffolding Algorithmic Programming Learning through Learner-LLM Co-Decomposition},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713748},
doi = {10.1145/3706598.3713748},
abstract = {Decomposition is a fundamental skill in algorithmic programming, requiring learners to break down complex problems into smaller, manageable parts. However, current self-study methods, such as browsing reference solutions or using LLM assistants, often provide excessive or generic assistance that misaligns with learners’ decomposition strategies, hindering independent problem-solving and critical thinking. To address this, we introduce Decomposition Box (DBox), an interactive LLM-based system that scaffolds and adapts to learners’ personalized construction of a step tree through a “learner-LLM co-decomposition” approach, providing tailored support at an appropriate level. A within-subjects study (N=24) found that compared to the baseline, DBox significantly improved learning gains, cognitive engagement, and critical thinking. Learners also reported a stronger sense of achievement and found the assistance appropriate and helpful for learning. Additionally, we examined DBox’s impact on cognitive load, identified usage patterns, and analyzed learners’ strategies for managing system errors. We conclude with design implications for future AI-powered tools to better support algorithmic programming education.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {585},
numpages = {20},
keywords = {Programming Learning, Self-Paced Learning, Large Language Models, AI for Coding, Human-AI Collaboration},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3649217.3653626,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley and Salloum, Mariam},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653626},
doi = {10.1145/3649217.3653626},
abstract = {Student cheating on at-home programming assignments is a well- known problem. A key contributor is externally-obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally-obtained solutions often use coding styles that depart from a class' style, which we call "style anomalies," such as using untaught or advanced constructs like pointers or ternary operators, or having different indenting or brace usage from the class style. We developed a tool to auto-count style anomalies. For six labs across four terms in 2021-2022, and 50 sampled students per lab, we found 18% of submissions on average had unusually-high style anomaly counts. Importantly, 8% of submissions on average had a high style anomaly count but were not flagged by a similarity checker, meaning 8% of submissions are suspicious but might have been missed if using similarity checking alone. We repeated a similar analysis for Spring 2023 when generative AI (ChatGPT) was gaining popularity, and the numbers rose to 26% and 18%, respectively. Detailed investigations by instructors led to a majority (but not all) high style anomaly submissions being deemed cheating. Even for high-similarity submissions, counting style anomalies can help instructors focus investigations on the most-likely cheating cases, and can strengthen cases sent to student conduct offices. With the rise of externally-obtained solutions from websites, contractors, and generative AI, counting style anomalies may become an increasingly important complement to similarity checking; in fact, it is now the primary cheat-detection tool in our CS1 at a large state university, with similarity secondary.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {381–387},
numpages = {7},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3587102.3588794,
author = {Ouh, Eng Lieh and Gan, Benjamin Kok Siew and Jin Shim, Kyong and Wlodkowski, Swavek},
title = {ChatGPT, Can You Generate Solutions for my Coding Exercises? An Evaluation on its Effectiveness in an undergraduate Java Programming Course.},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588794},
doi = {10.1145/3587102.3588794},
abstract = {In this study, we assess the efficacy of employing the ChatGPT language model to generate solutions for coding exercises within an undergraduate Java programming course. ChatGPT, a large-scale, deep learning-driven natural language processing model, is capable of producing programming code based on textual input. Our evaluation involves analyzing ChatGPT-generated solutions for 80 diverse programming exercises and comparing them to the correct solutions. Our findings indicate that ChatGPT accurately generates Java programming solutions, which are characterized by high readability and well-structured organization. Additionally, the model can produce alternative, memory-efficient solutions. However, as a natural language processing model, ChatGPT struggles with coding exercises containing non-textual descriptions or class files, leading to invalid solutions. In conclusion, ChatGPT holds potential as a valuable tool for students seeking to overcome programming challenges and explore alternative approaches to solving coding problems. By understanding its limitations, educators can design coding exercises that minimize the potential for misuse as a cheating aid while maintaining their validity as assessment tools.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {54–60},
numpages = {7},
keywords = {Java, computer science education, object-oriented, programming},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@proceedings{10.1145/3657604,
title = {L@S '24: Proceedings of the Eleventh ACM Conference on Learning @ Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the Proceedings of the Eleventh Annual ACM Conference on Learning at Scale, L@S 2024, held July 18-20, 2024 at Georgia Tech in Atlanta, Georgia, USA.The Learning at Scale conference was created by the Association for Computing Machinery (ACM), inspired by the emergence of Massive Open Online Courses (MOOCs) and the accompanying shift in thinking about education. During the last few years, new opportunities for scaling up learning have emerged, like hybrid learning environments combining online and face-to-face, and informal learning enabled by all sorts of platforms (e.g., gamified language learning, citizen science communities, and collaborative programming communities). In the recent two years, the unprecedented development of generative AI has brought profound opportunities to scale the teaching and learning experiences, with the goal of enhancing learning for the increasingly diverse group of learners in both formal and informal contexts. L@S has evolved along with these emergent massive learning scenarios and opportunities and is today one of the most prominent venues for discussion of the highest quality of research on how learning and teaching can be transformed at scale, in diverse learning environments.The theme of L@S 2024 is Scaling Learning in the Age of AI. Rapid advances in AI have created new opportunities but also challenges for the Learning@Scale community. The advances in generative AI show potential to enhance pedagogical practices and the efficacy of learning at scale. This has led to an unprecedented level of interest in employing generative AI for scaling tutoring and feedback. The prevalence of such tools calls for new practices and understanding on how AI-based methods should be designed and developed to enhance the experiences and outcomes of teachers and learners.Learning@Scale 2024 solicits empirical and theoretical papers on, but not limited to, the following topics (in no particular order): 1) Instruction at scale: studies that examine how teachers and educators scale their instructions, what aspects of instruction could be scaled effectively, and which of these instructional strategies are the most effective for learning. 2) Interventions at scale: studies that examine the effects of interventions on student learning and performance when implemented at scale. We welcome studies that use both qualitative and quantitative methods. 3) The use of generative AI to scale learning: studies that investigate stakeholders' experiences with generative AI, students' and teachers' interactions with generative AI, and the potentials and limitations of using generative AI in education. 4) Systems and tools to support learning at scale: research that designs and develops systems and tools to support learning at scale. For example, this involves scaling learning through web-based systems, MOOCs, visualization, intelligent tutoring systems, gamification, immersive techniques (AR/VR/MR), mobile technologies, tangible interfaces, and various other technologies. 5) The evaluation of existing learning at scale systems and online learning environments using but not limited to the above-mentioned technologies. 6) Methods and algorithms that model learner behavior: research that contributes methods, algorithms, and pipelines that process large student data to enhance learning at scale. 7) Scaling learning in informal contexts: studies that explore how people take advantage of online environments to pursue their interests informally. 8) Review and synthesis of existing literature related to learning at scale. 9) Empirical studies and interventions that address equity, trust, algorithmic transparency and explainability, fairness and bias when using AI in education. 10) Research that addresses accessibility in learning at scale contexts. 11) Design and deployment of learning at scale systems for learners from underrepresented groups.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3641555.3705227,
author = {Hou, Xinying and Wu, Zihan and Wang, Xu and Ericson, Barbara J.},
title = {Personalized Parsons Puzzles as Scaffolding Enhance Practice Engagement Over Just Showing LLM-Powered Solutions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705227},
doi = {10.1145/3641555.3705227},
abstract = {As generative AI products could generate code and assist students with programming learning seamlessly, integrating AI into programming education contexts has driven much attention. However, one emerging concern is that students might get answers without learning from the LLM-generated content. In this work, we deployed the LLM-powered personalized Parsons puzzles as scaffolding to write-code practice in a Python learning classroom (PC condition) and conducted an 80-minute randomized between-subjects study. Both conditions received the same practice problems. The only difference was that when requesting help, the control condition showed students a complete solution (CC condition), simulating the most traditional LLM output. Results indicated that students who received personalized Parsons puzzles as scaffolding engaged in practicing significantly longer than those who received complete solutions when struggling.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1483–1484},
numpages = {2},
keywords = {GPT, LLM, active learning, generative AI, parsons problems},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3649165.3690111,
author = {Poitras, Eric and Crane, Brent and Siegel, Angela},
title = {Generative AI in Introductory Programming Instruction: Examining the Assistance Dilemma with LLM-Based Code Generators},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690111},
doi = {10.1145/3649165.3690111},
abstract = {Problem decomposition is an important skill in programming, allowing learners to break down complex tasks into manageable subgoals. However, translating these subgoals into executable code poses a significant challenge for novice programmers. In this study conducted in an introductory programming course, learners received instruction in stepwise refinement and integration of AI-generated code within their assignments. Throughout the course, learners were permitted to rely on AI code generators, following opportunities to receive feedback on their ability to read and write code without AI assistance.  Our findings show that learners frequently relied on AI-generated code when working on assignments outside the classroom, but that the frequency of reliance varied from one assignment to another. The reliance on AI-generated code was not correlated with the learners' year in their degree, nor whether they were enrolled in a CS degree or not. Instead, it was associated with their prior knowledge, as learners who were less proficient in reading and writing code were more likely to seek AI assistance.  AI tools were primarily used to translate subgoals into code, fix errors, and explain algorithmic concepts. Few learners encountered difficulties in understanding or integrating AI generated code into their solutions. Overall, learner performance in meeting assignment requirements was relatively high, regardless of their prior knowledge or reliance on AI code generators. We conclude that leveraging the capabilities of generative AI can effectively bridge the gap between problem-solving and implementation, enabling learners to engage in skills that might otherwise be beyond their reach.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {186–192},
numpages = {7},
keywords = {ai coding assistants, ai-assisted pair programming, chatgpt, generative ai, gpt-3.5, introductory programming, large language models},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3641554.3701942,
author = {Liu, Zifeng and Jiao, Xinyue and Xing, Wanli and Zhu, Wangda},
title = {Detecting AI-Generated Pseudocode in High School Online Programming Courses Using an Explainable Approach},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701942},
doi = {10.1145/3641554.3701942},
abstract = {Despite extensive research on code plagiarism detection in higher education and for programming languages like Java and Python, limited work has focused on K-12 settings, particularly for pseudocode. This study aims to address this gap by building explainable machine learning models for pseudocode plagiarism detection in online programming education. To achieve this, we construct a comprehensive dataset comprising 7,838 pseudocode submissions from 2,578 high school students enrolled in an online programming foundations course, along with 6,300 pseudocode samples generated by three versions of generative pre-trained transformer (GPT) models. Utilizing this dataset, we develop an explainable model to detect AI-generated pseudocode across various assessments. The model not only identifies AI-generated content but also provides insights into its predictions at both the student and problem levels, thus enhancing our understanding of AI-generated pseudocode in K-12 education. Furthermore, we analyzed SHAP values and key features of the model to pinpoint student submissions that closely resemble AI-generated pseudocode. This research offers implications for developing robust educational technologies and methodologies to uphold academic integrity in online programming courses.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {701–707},
numpages = {7},
keywords = {ai-generated content, explainable ai, gpt model, online programming education, plagiarism detection, pseudocode},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3689535.3689538,
author = {Sentance, Sue and Watson, Steven and Addo, Salomey Afua and Shi, Shengpeng and Waite, Jane and Yu, Bo},
title = {Developing Computing Teacher Guidance on GenAI},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689538},
doi = {10.1145/3689535.3689538},
abstract = {Generative AI (GenAI) is becoming widely available for use in schools by teachers and students. While many educators appreciate the potential benefits of GenAI for enhancing learning, there are also significant concerns about authorship, authenticity, plagiarism, ethics, biases, and the broader implications of their use in education. For computing teachers in schools, these issues can be even more acute. In this project, we established a working group of practising computing teachers to bring together a range of views and experiences. Initial results of the project led to a booklet for computing teachers on how to use GenAI, illustrating the effectiveness of teacher-researcher partnerships in developing resources for school use. This project will be followed by further work on computing teachers’ actual experience of GenAI in practice.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {12},
numpages = {1},
keywords = {AI education, K-12 education, generative AI, teachers},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3706468.3706474,
author = {Yin, Stella Xin and Liu, Zhengyuan and Goh, Dion Hoe-Lian and Quek, Choon Lang and Chen, Nancy F.},
title = {Scaling Up Collaborative Dialogue Analysis: An AI-driven Approach to Understanding Dialogue Patterns in Computational Thinking Education},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706474},
doi = {10.1145/3706468.3706474},
abstract = {Pair programming is a collaborative activity that enhances students’ computational thinking (CT) skills. Analyzing students’ interactions during pair programming provides valuable insights into effective learning. However, interpreting classroom dialogues is a challenging and complex task. Due to the simultaneous interaction between interlocutors and other ambient noise in collaborative learning contexts, previous work heavily relied on manual transcription and coding, which is labor-intensive and time-consuming. Recent advancements in speech and language processing offer promising opportunities to automate and scale up dialogue analysis. Besides, previous work mainly focused on task-related interactions, with little attention to social interactions. To address these gaps, we conducted a four-week CT course with 26 fifth-grade primary school students. We recorded their discussions, transcribed them with speech processing models, and developed a coding scheme and applied LLMs for annotation. Our AI-driven pipeline effectively analyzed classroom recordings with high accuracy and efficiency. After identifying the dialogue patterns, we investigated the relationships between these patterns and CT performance. Four clusters of dialogue patterns have been identified: Inquiry, Constructive Collaboration, Disengagement, and Disputation. We observed that Inquiry and Constructive Collaboration patterns were positively related to students’ CT skills, while Disengagement and Disputation patterns were associated with lower CT performance. This study contributes to the understanding of how dialogue patterns relate to CT performance and provides implications for both research and educational practice in CT learning.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {47–57},
numpages = {11},
keywords = {Collaborative learning, Computational thinking, Dialogue analysis, Large language models, Pair programming, Speech and language processing},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3702386.3702399,
author = {Huang, Hui-Wen and Chang, Jessica (Chieh-Yu)},
title = {Human-AI Interactions in Teacher Education: Examining Social Presence and Friendship},
year = {2025},
isbn = {9798400710131},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702386.3702399},
doi = {10.1145/3702386.3702399},
abstract = {This study examines the potential of AI chatbots, such as ChatGPT, to establish meaningful human-AI friendships with college students enrolled in teacher education programs. Fifty-nine junior-level elementary education majors participated in a three-week intervention study. Using the framework of social presence theory, this research explores whether generative AI technologies can replicate key qualities of friendship, such as empathy, social support, and trust. The findings reveal that while AI chatbots provide practical benefits and reliable assistance, they fall short in fostering the deep emotional and empathetic connections that are fundamental to human relationships. Notably, some participants expressed trust in AI chatbots, citing their ability to keep users' secrets private. The results suggest that enhancing social presence may improve emotional engagement and trust in human-AI interactions. This study contributes to the understanding of AI's role in offering social and emotional support, particularly in explaining student teachers' behaviors with AI technologies within educational settings.},
booktitle = {Proceedings of the 2024 International Conference on Artificial Intelligence and Teacher Education},
pages = {64–69},
numpages = {6},
keywords = {Generative AI, emotional support, human-AI Interaction, social presence theory, virtual friends},
location = {
},
series = {ICAITE '24}
}

@inproceedings{10.1145/3675812.3675874,
author = {Liu, Liyuan and Mendoza, Ruben A. and Martin, Thomas R. and Miori, Virginia M.},
title = {Generative AI-Powered Educational Alignment: A Framework for Matching Syllabus Course Topics with Web Description},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675874},
doi = {10.1145/3675812.3675874},
abstract = {The application of generative artificial intelligence (GAI) in the educational sector is increasingly gaining attention from researchers. This study explores the congruence between online course descriptions and actual course syllabi to improve course preparation and consistency for instructors. Alignment between course catalog descriptions and actual course content as detailed in the syllabus can lead to learning improvements, student satisfaction, and academic alignment in a program. Our research introduces a novel framework utilizing GAI to systematically evaluates and identifies mismatches and suggests content to close the gap between online course descriptions and syllabus content. We used OpenAI’s ChatGPT to extract key topics from course syllabi and assessed the congruence between results and course description content with embedding methods such as BERT, GPT-2, RoBERTa, and DistilBERT, coupled with cosine similarity metrics. Our framework also integrates an outlier detection algorithm to identify courses with significant misalignments and use GAI applications to refine and enhance course catalog descriptions. This approach helps higher education institutions update course offerings with cutting-edge technology and contributes to curriculum development, helping improve student learning efficiency and course design.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {340–346},
numpages = {7},
keywords = {AI in education, ChatGPT, Curriculum alignment, Curriculum development, Generative AI, Syllabus analysis},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@inproceedings{10.1145/3626252.3630875,
author = {Ishizue, Ryosuke and Sakamoto, Kazunori and Washizaki, Hironori and Fukazawa, Yoshiaki},
title = {Improved Program Repair Methods using Refactoring with GPT Models},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630875},
doi = {10.1145/3626252.3630875},
abstract = {Teachers often utilize automatic program repair methods to provide feedback on submitted student code using model answer code. A state-of-the-art tool is Refactory, which achieves a high repair success rate and small patch size (less code repair) by refactoring code to expand the variety of correct code samples that can be referenced. However, Refactory has two major limitations. First, it cannot fix code with syntax errors. Second, it has difficulty fixing code when there are few correct submissions. Herein we propose a new method that combines Refactory and OpenAI's GPT models to address these issues and conduct a performance measurement experiment. The experiment uses a dataset consisting of 5 programming assignment problems and almost 1,800 real-life incorrect Python program submissions from 361 students for an introductory programming course at a large public university. The proposed method improves the repair success rate by 1-21% when the set of correct code samples is sufficient and the patch size is smaller than Refactory alone in 16-45% of the cases. When there was no set of correct code samples at all (only the model answer code was used as a reference for repair), method improves the repair success rate by 1-43% and the patch size is smaller than Refactory alone in 42-68% of the cases.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {569–575},
numpages = {7},
keywords = {generative ai, program repair, programming assignment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635398,
author = {Mousa, Raneem Emad and Veilleux, Nanette},
title = {Is ChatGPT the Academic Catalyst We've all been Waiting For?},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635398},
doi = {10.1145/3626253.3635398},
abstract = {The excitement around ChatGPT 3.5 underscores its potential to transform various fields in education, including STEM. However, we must approach these claims cautiously. While AI can enhance STEM education, there are ethical concerns and potential inaccuracies linked to unsupervised automated responses. To comprehensively evaluate ChatGPT's influence on STEM, we conducted a controlled experiment that involved answering a question set in mathematics and CS in a time-limited session. To avoid bias, we recruited four groups of math and CS students with similar abilities -each group comprised five students. Two groups utilized ChatGPT, while the other two did not. Students who used ChatGPT were tasked with explaining how and where they employed the tool. Conversely, students who did not use ChatGPT were asked to showcase their problem-solving process. We analyzed the responses from these four groups, alongside the analysis of ChatGPT conversations for those who employed ChatGPT. Performance, confidence level, and completion time of each participant were recorded. Experts in mathematics and CS were then consulted to review participant responses. These experts were subsequently interviewed to gain deeper insights and draw conclusive findings. Our findings show that students who didn't use ChatGPT in Mathematics scored better than those who did, Specifically, ChatGPT provided the correct working process but yielded a wrong final answer due to arithmetic mistakes. Similarly, in programming, ChatGPT led to less elegant code. Our findings provide valuable insights into the benefits and challenges of AI integration in these fields, helping educators and students to adapt to AI advancements.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1885},
numpages = {1},
keywords = {ai, chatgpt, education, stem},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3649217.3653558,
author = {Pang, Ashley and Vahid, Frank},
title = {ChatGPT and Cheat Detection in CS1 Using a Program Autograding System},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653558},
doi = {10.1145/3649217.3653558},
abstract = {We experimented with ChatGPT's ability to write programs in a CS1 class, and the ability of a popular tool to auto-detect ChatGPT-written programs. We found ChatGPT was proficient at generating correct programs from a mere copy-paste of the English programming assignment specifications. However, running ChatGPT for 10 programming assignments and acting as 20 different students, and using zyBook's APEX beta tool for academic integrity, we found: (1) ChatGPT-generated programs tend to use a programming style departing from the style taught in the textbook or by the instructor, and these "style anomalies" were automatically detected. (2) Although ChatGPT may for the same assignment generate a few different program solutions for different students, ChatGPT often generates highly-similar programs for different students, so if enough students in a class (e.g., 5 or more) use ChatGPT, their programs will likely be flagged by a similarity checker. (3) If students are required to do all programming in the autograder's IDE, then a student using ChatGPT ends up showing very little time relative to classmates, which is automatically flagged. (4) Manually, we observed that if a student consistently uses ChatGPT to submit programs, the programming style may vary across programs, something normal students don't do; automation of style inconsistency detection was recently added to APEX. In short, while there will no doubt be an arms race between AI-generated programs and automatic detection of AI-generated programs, currently students using ChatGPT for multiple CS1 programs can be detected by automated tools such as zyBooks' APEX.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {367–373},
numpages = {7},
keywords = {CS1, ChatGPT, academic integrity, cheat detection, large language models, plagiarism, similarity checking, style anomalies},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3636243.3636248,
author = {Hou, Irene and Mettille, Sophia and Man, Owen and Li, Zhuo and Zastudil, Cynthia and MacNeil, Stephen},
title = {The Effects of Generative AI on Computing Students’ Help-Seeking Preferences},
year = {2024},
isbn = {9798400716195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636243.3636248},
doi = {10.1145/3636243.3636248},
abstract = {Help-seeking is a critical way that students learn new concepts, acquire new skills, and get unstuck when problem-solving in their computing courses. The recent proliferation of generative AI tools, such as ChatGPT, offers students a new source of help that is always available on-demand. However, it is unclear how this new resource compares to existing help-seeking resources along dimensions of perceived quality, latency, and trustworthiness. In this paper, we investigate the help-seeking preferences and experiences of computing students now that generative AI tools are available to them. We collected survey data (n=47) and conducted interviews (n=8) with computing students. Our results suggest that although these models are being rapidly adopted, they have not yet fully eclipsed traditional help resources. The help-seeking resources that students rely on continue to vary depending on the task and other factors. Finally, we observed preliminary evidence about how help-seeking with generative AI is a skill that needs to be developed, with disproportionate benefits for those who are better able to harness the capabilities of LLMs. We discuss potential implications for integrating generative AI into computing classrooms and the future of help-seeking in the era of generative AI.},
booktitle = {Proceedings of the 26th Australasian Computing Education Conference},
pages = {39–48},
numpages = {10},
keywords = {ChatGPT, Generative AI, computing education, help-seeking},
location = {Sydney, NSW, Australia},
series = {ACE '24}
}

@inproceedings{10.1145/3633083.3633220,
author = {Shaka, Martha and Carraro, Diego and Brown, Kenneth N.},
title = {Personalised Programming Education with Knowledge Tracing},
year = {2023},
isbn = {9798400716461},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633083.3633220},
doi = {10.1145/3633083.3633220},
abstract = {In traditional programming education, addressing diverse student needs and providing effective and scalable learning experiences is challenging. Conventional methods struggle to adapt to varying learning styles and offer personalised feedback. AI-based Programming Tools (AIPTs) have shown promise in automating feedback, simplifying programming concepts, and guiding students. Their widespread adoption is hindered by limitations related to accuracy, explanation, and personalisation. Conversely, AIPTs tailored for expert programmers, such as ChatGPT and Copilot, have gained popularity for their productivity-enhancing capabilities, but they still fall short in terms of personalisation, neglecting individual students’ unique knowledge and skills. Our research aims to leverage AI to create AIPTs that offer personalised feedback through adaptive learning, accommodating diverse student backgrounds and proficiency levels. In particular, we explore using Knowledge Tracing (KT) to anticipate specific syntax errors in programming assignments, addressing the challenges novices face in acquiring syntactical knowledge. The findings suggest the KT’s potential to transform programming education by enabling timely interventions for students dealing with specific errors or misconceptions, automating personalised feedback, and informing tailored instructional strategies.},
booktitle = {Proceedings of the 2023 Conference on Human Centered Artificial Intelligence: Education and Practice},
pages = {47},
numpages = {1},
keywords = {Automated Feedback, Knowledge Tracing, Personalisation, Programming Assignments, Syntax Errors},
location = {Dublin, Ireland},
series = {HCAIep '23}
}

@inproceedings{10.1145/3663649.3664375,
author = {Yang, Jun and Gilad, Amir and Hu, Yihao and Meng, Hanze and Miao, Zhengjie and Roy, Sudeepa and Stephens-Martinez, Kristin},
title = {What Teaching Databases Taught Us about Researching Databases: Extended Talk Abstract},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664375},
doi = {10.1145/3663649.3664375},
abstract = {Declarative querying is a cornerstone of the success and longevity of database systems, yet it is challenging for novice learners accustomed to different coding paradigms. The transition is further hampered by a lack of query debugging tools compared to the plethora available for programming languages. The paper samples several systems that we build at Duke University to help students learn and debug database queries. These systems have not only helped scale up teaching and improve learning, but also inspired interesting research on databases. Furthermore, with the rise of generative AI, we argue that there is a heightened need for skills in scrutinizing and debugging AI-generated queries, and we outline several ongoing and future work directions aimed at addressing this challenge.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {1–6},
numpages = {6},
keywords = {Database Education, Query Debugging, Query Verification, Relational Algebra, SQL},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@inproceedings{10.1145/3641555.3705266,
author = {Hou, Irene and Nguyen, Hannah Vy and Man, Owen and MacNeil, Stephen},
title = {The Evolving Usage of GenAI by Computing Students},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705266},
doi = {10.1145/3641555.3705266},
abstract = {Help-seeking is a critical aspect of learning and problem-solving for computing students. Recent research has shown that many students are aware of generative AI (GenAI) tools; however, there are gaps in the extent and effectiveness of how students use them. With over two years of widespread GenAI usage, it is crucial to understand whether students' help-seeking behaviors with these tools have evolved and how. This paper presents findings from a repeated cross-sectional survey conducted among computing students across North American universities ( n=95 ). Our results indicate shifts in GenAI usage patterns. In 2023, 34.1% of students ( n=47 ) reported never using ChatGPT for help, ranking it fourth after online searches, peer support, and class forums. By 2024, this figure dropped sharply to 6.3% ( n=48 ), with ChatGPT nearly matching online search as the most commonly used help resource. Despite this growing prevalence, there has been a decline in students' hourly and daily usage of GenAI tools, which may be attributed to a common tendency to underestimate usage frequency. These findings offer new insights into the evolving role of GenAI in computing education, highlighting its increasing acceptance and solidifying its position as a key help resource.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1481–1482},
numpages = {2},
keywords = {chatgpt, computing education, generative ai, help-seeking},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3670013.3670058,
author = {Torrato, Janette B. and Pillar, Genevieve A. and Robledo, Dave Arthur R. and Aguja, Socorro E. and Prudente, Maricar S.},
title = {Knowledge, Attitudes, and Practices on ChatGPT:Perspectives from Students and Teachers of De La Salle Santiago Zobel School},
year = {2024},
isbn = {9798400717062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670013.3670058},
doi = {10.1145/3670013.3670058},
abstract = {Abstract. Chat Generative Pre-trained Transformer (ChatGPT) is an artificial intelligence (AI) system that is gaining popularity among students and teachers. However, in the basic education level, the use of ChatGPT is still an ongoing discussion, particularly on how to regulate its use. This study endeavors to describe the perspectives of teachers and students about ChatGPT in terms of their knowledge, attitudes, and practices to better appreciate its role in advancing teaching and learning. This descriptive survey involved a total of (N=187) respondents, including students from Grade 6 (n=70), Grade 10 (n=38), and Grade 12 (n=18) and teachers (n=61). The newly developed 39-item Knowledge, Attitudes, Practices on ChatGPT Questionnaire (KAP-CQ39) with a Cronbach α = 0.91 was used as the primary instrument in understanding and leveraging the academic potential of this AI system. Open-ended questions on the advantages and disadvantages of using ChatGPT are also included in the questionnaire. KAP-CQ39 was administered online using Google Forms. Data culled from the survey was analyzed using an online open-source program referred to as Jeffreys's Amazing Statistics Program (JASP). Results revealed no significant difference in perspectives between teachers (mean=11.88) and students (mean=11.46) knowledge on ChatGPT F (2,169) =2.66, p=0.104. Similarly, attitudes towards the educational use of ChatGPT showed that both teachers and students hold positive attitudes. Demographic factors contributing to the differences in teachers’ perspectives on the educational use of ChatGPT were sex, years of teaching experience, and specialization. For the students, the demographic factors did not contribute to the differences in their perspectives. Generally, in terms of practices, responses provided valuable insights into how ChatGPT can be better designed and implemented for teaching and learning. Thus, policy implications were drawn relative to the efficient use of ChatGPT.},
booktitle = {Proceedings of the 2024 15th International Conference on E-Education, E-Business, E-Management and E-Learning},
pages = {107–116},
numpages = {10},
location = {Fukuoka-shi, Japan},
series = {IC4E '24}
}

@article{10.1145/3701198,
author = {Wang, Tianjia and Wu, Tong and Liu, Huayi and Brown, Chris and Chen, Yan},
title = {Generative Co-Learners: Enhancing Cognitive and Social Presence of Students in Asynchronous Learning with Generative AI},
year = {2025},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
url = {https://doi.org/10.1145/3701198},
doi = {10.1145/3701198},
abstract = {Cognitive presence and social presence are crucial for a comprehensive learning experience. Despite the flexibility of asynchronous learning environments to accommodate individual schedules, the inherent constraints of asynchronous environments make augmenting cognitive and social presence particularly challenging. Students often face challenges such as a lack of timely feedback and support, an absence of non-verbal cues in communication, and a sense of isolation. To address this challenge, this paper introduces Generative Co-Learners, a system designed to leverage generative AI-powered agents, simulating co-learners supporting multimodal interactions, to improve cognitive and social presence in asynchronous learning environments. We conducted a study involving 12 student participants who used our system to engage with online programming tutorials to assess the system's effectiveness. The results show that by implementing features to support textual and visual communication and simulate an interactive learning environment with generative agents, our system enhances the cognitive and social presence in the asynchronous learning environment. These results suggest the potential to use generative AI to support student learning and transform asynchronous learning into a more inclusive, engaging, and efficacious educational approach.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jan,
articleno = {GROUP19},
numpages = {24},
keywords = {asynchronous learning, cognitive presence, generative AI, multimodal generative agent, social presence}
}

@inproceedings{10.1145/3641555.3705166,
author = {Demirta\c{s}, Mehmet Arif and Zheng, Claire and Cunningham, Kathryn},
title = {Detecting Programming Plans in Open-ended Code Submissions},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705166},
doi = {10.1145/3641555.3705166},
abstract = {Open-ended code-writing exercises are commonly used in large-scale introductory programming courses, as they can be autograded against test cases. However, code writing requires many skills at once, from planning out a solution to applying the intricacies of syntax. As autograding only evaluates code correctness, feedback addressing each of these skills separately cannot be provided. In this work, we explore methods to detect which high-level patterns (i.e. programming plans) have been used in a submission, so learners can receive feedback on planning skills even when their code is not completely correct. Our preliminary results show that LLMs with few-shot prompting can detect the use of programming plans in 95% of correct and 86% of partially correct submissions. Incorporating LLMs into grading of open-ended programming exercises can enable more fine-grained feedback to students, even in cases where their code does not compile due to other errors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1435–1436},
numpages = {2},
keywords = {autograding, large language models, programming plans},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3689187.3709614,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Gorson Benario, Jamie and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {Beyond the Hype: A Comprehensive Review of Current Trends in Generative AI Research, Teaching Practices, and Tools},
year = {2025},
isbn = {9798400712081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689187.3709614},
doi = {10.1145/3689187.3709614},
abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
booktitle = {2024 Working Group Reports on Innovation and Technology in Computer Science Education},
pages = {300–338},
numpages = {39},
keywords = {artificial intelligence, computing education, genai, generative ai, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3716640.3716649,
author = {Prather, James and Reeves, Brent N and Denny, Paul and Leinonen, Juho and MacNeil, Stephen and Luxton-Reilly, Andrew and Orvalho, Jo\~{a}o and Alipour, Amin and Alfageeh, Ali and Amarouche, Thezyrie and Kimmel, Bailey and Wright, Jared and Blake, Musa and Barbre, Gweneth},
title = {Breaking the Programming Language Barrier: Multilingual Prompting to Empower Non-Native English Learners},
year = {2025},
isbn = {9798400714252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716640.3716649},
doi = {10.1145/3716640.3716649},
abstract = {Non-native English speakers (NNES) face multiple barriers to learning programming. These barriers can be obvious, such as the fact that programming language syntax and instruction are often in English, or more subtle, such as being afraid to ask for help in a classroom full of native English speakers. However, these barriers are frustrating because many NNES students know more about programming than they can articulate in English. Advances in generative AI (GenAI) have the potential to break down these barriers because state of the art models can support interactions in multiple languages. Moreover, recent work has shown that GenAI can be highly accurate at code generation and explanation. In this paper, we provide the first exploration of NNES students prompting in their native languages (Arabic, Chinese, and Portuguese) to generate code to solve programming problems. Our results show that students are able to successfully use their native language to solve programming problems, but not without some difficulty specifying programming terminology and concepts. We discuss the challenges they faced, the implications for practice in the short term, and how this might transform computing education globally in the long term.},
booktitle = {Proceedings of the 27th Australasian Computing Education Conference},
pages = {74–84},
numpages = {11},
keywords = {AI; Artificial Intelligence; Automatic Code Generation; Codex; Copilot; CS1; GenAI; GitHub; GPT; GPT-4; ChatGPT; HCI; Introductory Programming; Large Language Models; LLM; Non-Native English Speakers; Novice Programming; OpenAI; Prompt Problems},
location = {
},
series = {ACE '25}
}

@inproceedings{10.1145/3699538.3699546,
author = {Keuning, Hieke and Alpizar-Chacon, Isaac and Lykourentzou, Ioanna and Beehler, Lauren and K\"{o}ppe, Christian and de Jong, Imke and Sosnovsky, Sergey},
title = {Students' Perceptions and Use of Generative AI Tools for Programming Across Different Computing Courses},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699546},
doi = {10.1145/3699538.3699546},
abstract = {Investigation of students’ perceptions and opinions on the use of generative artificial intelligence (GenAI) in education is a topic gaining much interest. Studies addressing this are typically conducted with large heterogeneous groups, at one moment in time. However, how students perceive and use GenAI tools can potentially depend on many factors, including their background knowledge, familiarity with the tools, and the learning goals and policies of the courses they are taking. In this study we explore how students following computing courses use GenAI for programming-related tasks across different programs and courses: Bachelor and Master, in courses in which learning programming is the learning goal, courses that require programming as a means to achieve another goal, and in courses in which programming is optional, but can be useful. We are also interested in changes over time, since GenAI capabilities are changing at a fast pace, and users are adopting GenAI increasingly. We conducted three consecutive surveys (fall ‘23, winter ‘23, and spring ‘24) among students of all computing programs of a large European research university. We asked questions on the use in education, ethics, and job prospects, and we included specific questions on the (dis)allowed use of GenAI tools in the courses they were taking at the time. We received 264 responses, which we quantitatively and qualitatively analyzed, to find out how students have employed GenAI tools across 59 different computing courses, and whether the opinion of an average student about these tools evolves over time. Our study contributes to the emerging discussion of how to differentiate GenAI use across different courses, and how to align its use with the learning goals of a computing course.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {14},
numpages = {12},
keywords = {Generative AI, Large Language Models, Computing Education, Programming Courses},
location = {
},
series = {Koli Calling '24}
}

@article{10.1145/3617367,
author = {Prather, James and Reeves, Brent N. and Denny, Paul and Becker, Brett A. and Leinonen, Juho and Luxton-Reilly, Andrew and Powell, Garrett and Finnie-Ansley, James and Santos, Eddie Antonio},
title = {“It’s Weird That it Knows What I Want”: Usability and Interactions with Copilot for Novice Programmers},
year = {2023},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {1},
issn = {1073-0516},
url = {https://doi.org/10.1145/3617367},
doi = {10.1145/3617367},
abstract = {Recent developments in deep learning have resulted in code-generation models that produce source code from natural language and code-based prompts with high accuracy. This is likely to have profound effects in the classroom, where novices learning to code can now use free tools to automatically suggest solutions to programming exercises and assignments. However, little is currently known about how novices interact with these tools in practice. We present the first study that observes students at the introductory level using one such code auto-generating tool, Github Copilot, on a typical introductory programming (CS1) assignment. Through observations and interviews we explore student perceptions of the benefits and pitfalls of this technology for learning, present new observed interaction patterns, and discuss cognitive and metacognitive difficulties faced by students. We consider design implications of these findings, specifically in terms of how tools like Copilot can better support and scaffold the novice programming experience.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = nov,
articleno = {4},
numpages = {31},
keywords = {OpenAI, novice programming, LLM, large language models, introductory programming, HCI, GPT-3, GitHub, CS1, Copilot, Codex, automatic code generation, Artificial Intelligence, AI}
}

@article{10.5555/3665609.3665633,
author = {Liu, Sa and Grey, Brian and Watkins, Ryan and Chu, Chad and Grim, Phillip and McManus, Thomas},
title = {Assessing Risks, Challenges and Opportunities of Generative AI in Computer Programming Education --- Lightning Talk},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {8},
issn = {1937-4771},
abstract = {Artificial Intelligence (AI) has the potential to transform the education sector by enhancing teaching and learning experiences. According to Sal Khan, founder of Khan Academy, AI is about to start "the biggest positive transformation that education has ever seen"1 by making high-quality personalized tutoring available (tuition free) to everyone on the planet. Given AI's, and more specifically Generative AI's (GAI), rapidly developing capabilities (e.g., to provide tailored feedback, ask questions of students, give examples and non-examples, and offer general learning support), incorporating GAI into programming education has the potential to enhance student engagement and learning outcomes. At the same time, they identified challenges in using GAI, such as its inability to answer some questions and its tendency to provide incorrect or incomplete responses. Students also report an increase in anxiety surrounding GAI and its potential effects on future professional opportunities. Outside of the classroom there is likewise an increasing prevalence of GAI in computational professions, making it crucial to equip students with the necessary knowledge and skills to effectively, responsibly, and ethically utilize GAI. Rather than avoiding the use of GAI in the classroom, in this study we aim to investigate the pros and cons of leveraging GAI's capabilities to offer personalized guidance and assistance to students as they learn programming. By doing this research, we are learning to create more interactive and engaging learning experiences that better equip students with the skills and knowledge needed to succeed in the field of programming. This project, which is currently being conducted, was designed to address this research question: To what extent does the incorporation of GAI impact students' engagement, motivation, and achievement, particularly with the material in Intro to Programming courses and their chosen STEM field of study? It is utilizing case studies that focus on the integration of GAI into computer programming education. The team has 1) developed a series of GAI-supported teaching modules specifically designed to improve problem-solving skills in programming tasks among undergraduate students; and 2) is in the process of analyzing student feedback on GAI integration in computer programming education. This project offers an important exploration into the intersection of GAI and programming education, with the expectation that results will provide useful guidance for programming instructors who are adapting their instructional strategies for the emerging role of GAI in programming. The team will briefly present the status of the research and early insights from the project, and then engage with the audience on how lessons learned from this work can pragmatically shape programming courses in their institutions. Quick tips, takeaways, and prompting strategies will be shared throughout this interactive lighting talk.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {210–211},
numpages = {2}
}

@inproceedings{10.1145/3649217.3653621,
author = {Margulieux, Lauren E. and Prather, James and Reeves, Brent N. and Becker, Brett A. and Cetin Uzun, Gozde and Loksa, Dastyni and Leinonen, Juho and Denny, Paul},
title = {Self-Regulation, Self-Efficacy, and Fear of Failure Interactions with How Novices Use LLMs to Solve Programming Problems},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653621},
doi = {10.1145/3649217.3653621},
abstract = {We explored how undergraduate introductory programming students naturalistically used generative AI to solve programming problems. We focused on the relationship between their use of AI to their self-regulation strategies, self-efficacy, and fear of failure in programming. In this repeated-measures, mixed-methods research, we examined students' patterns of using generative AI with qualitative student reflections and their self-regulation, self-efficacy, and fear of failure with quantitative instruments at multiple times throughout the semester. We also explored the relationships among these variables to learner characteristics, perceived usefulness of AI, and performance. Overall, our results suggest that student factors affect their baseline use of AI. In particular, students with higher self-efficacy, lower fear of failure, or higher prior grades tended to use AI less or later in the problem-solving process and rated it as less useful than others. Interestingly, we found no relationship between students' self-regulation strategies and their use of AI. Students who used AI less or later in problem-solving also had higher grades in the course, but this is most likely due to prior characteristics as our data do not suggest that this is a causal relationship.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {276–282},
numpages = {7},
keywords = {CS1, LLMs, artificial intelligence, copilot, fear of failure, generative ai, introductory programming, large language models, metacognition, self-efficacy, self-regulated learning, self-regulation},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3723178.3723268,
author = {Sadat Shanto, Shakib and Ahmed, Zishan and Jony, Akinul Islam},
title = {Generative AI for Programming Education: Can ChatGPT Facilitate the Acquisition of Fundamental Programming Skills for Novices?},
year = {2025},
isbn = {9798400713828},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3723178.3723268},
doi = {10.1145/3723178.3723268},
abstract = {Modern Generative AI (GAI) systems like ChatGPT have sparked much interest in their potential to revolutionize programming education, especially for beginners. However, the existing empirical data regarding the effectiveness of technologies like ChatGPT as autonomous programming tutors is presently limited. The present study investigates the capacity of ChatGPT to facilitate the acquisition of fundamental programming skills for novice programmers without human assistance. This study puts forth a conceptual framework (APEC - Adaptive Programming Education via ChatGPT) that integrates both bottom-up and top-down approaches, incorporating ChatGPT as the principal instructor for the study of programming. An empirical study was undertaken to assess the usefulness of ChatGPT as a tool for teaching novice programmers a new programming language. This empirical study was conducted on 20 undergraduate students. To provide an expert assessment of the quality of the responses, a survey was conducted with three programming experts proficient in Python. The survey findings indicate that ChatGPT is proficient in explaining core principles such as variables, data types, and control statements through conversational exchanges, adopting an intelligent and logical methodology. Nevertheless, certain constraints arise when dealing with increasingly complex topics.},
booktitle = {Proceedings of the 3rd International Conference on Computing Advancements},
pages = {685–692},
numpages = {8},
keywords = {Generative AI, ChatGPT, Programming Education, Educational Technology, Higher Education},
location = {
},
series = {ICCA '24}
}

@inproceedings{10.1145/3626253.3635519,
author = {Denzler, Benjamin and Vahid, Frank and Pang, Ashley},
title = {Style Anomalies Can Suggest Cheating in CS1 Programs},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635519},
doi = {10.1145/3626253.3635519},
abstract = {Student cheating on at-home programming assignments is a well-known problem. A key contributor is externally obtained solutions from websites, contractors, and recently generative AI. In our experience, such externally obtained solutions often use coding styles that depart from a class's style, which we call "style anomalies". Examples of style anomalies include using untaught or advanced constructs like pointers or ternary operators or having different indenting or brace usage from the class style. We developed a tool to automatically count style anomalies in student code submissions. We used this tool to find suspected cheating in student submissions for lab assignments across five terms of CS1. This poster presents our findings: Some student submissions were suspected of cheating due to high style anomaly counts and were not flagged as suspicious by a code similarity checker. With the rise of externally obtained solutions from websites, contractors, and generative AI, style anomalies may become an important complement to similarity checking for detecting cheating.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1624–1625},
numpages = {2},
keywords = {cheating, cs1, plagiarism, program autograders, program style},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3640544.3645231,
author = {George, Samuel D and Huang, Tao and Robinson, Chandler and Schell, Gabriel and Shan, Wei and Zhao, Ziqian and Zhou, Zeqi and Dewan, Prasun},
title = {Assistant Dashboard Plus – Enhancing an Existing Instructor Dashboard with Difficulty Detection and GPT-based Code Clustering},
year = {2024},
isbn = {9798400705090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640544.3645231},
doi = {10.1145/3640544.3645231},
abstract = {As interest in programming as a major grows, instructors must accommodate more students in their programming courses. One particularly challenging aspect of this growth is providing quality assistance to students during in-class and out-of-class programming exercises. Prior work proposes using instructor dashboards to help instructors combat these challenges. Further, the introduction of ChatGPT represents an exciting avenue to assist instructors with programming exercises but needs a delivery method for this assistance. We propose a revision of a current instructor dashboard Assistant Dashboard Plus that extends an existing dashboard with two new features: (a) identifying students in difficulty so that instructors can effectively assist them, and (b) providing instructors with pedagogically relevant groupings of students’ exercise solutions with similar implementations so that instructors can provide overlapping code style feedback to students within the same group. For difficulty detection, it uses a state-of-the-art algorithm for which a visualization has not been created. For code clustering, it uses GPT. We present a first-pass implementation of this dashboard.},
booktitle = {Companion Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {54–57},
numpages = {4},
keywords = {ChatGPT, Computer programming, Dashboards, GPT, Learning at scale},
location = {Greenville, SC, USA},
series = {IUI '24 Companion}
}

@inproceedings{10.1145/3678726.3678745,
author = {Wu, Chih-Hung and Liou, Guang-Mei},
title = {ARCS Model for Exploring the Enhancement of Learning Motivation and Engagement through AIGC Technology in Computer Graphics Courses},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678745},
doi = {10.1145/3678726.3678745},
abstract = {The purpose of this study is to apply the Keller ARCS Motivation Model theory to the "Computer Graphics" course. In the learning process of computer graphics courses, generating images using generative AI and then modifying them is employed to arouse students' interest and enhance their learning engagement. The aim of this research is to analyze the interest generated by the course through experimental results of curriculum design. Most students show a high level of interest in the integration of generative AI into the course, while a very small minority express dislike for generating images in this manner. The findings confirm that integrating generative AI into computer graphics courses can increase student interest in learning.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {51–59},
numpages = {9},
keywords = {AIGC, ARCS, Learning Interest},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3626252.3630938,
author = {Liu, Rongxin and Zenke, Carter and Liu, Charlie and Holmes, Andrew and Thornton, Patrick and Malan, David J.},
title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630938},
doi = {10.1145/3626252.3630938},
abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {750–756},
numpages = {7},
keywords = {ai, artificial intelligence, generative ai, large language models, llms},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3631700.3665227,
author = {Fenu, Gianni and Galici, Roberta and Marras, Mirko and Reforgiato, Diego},
title = {Exploring Student Interactions with AI in Programming Training},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665227},
doi = {10.1145/3631700.3665227},
abstract = {In recent years, the integration of artificial intelligence (AI) in education has collected significant attention due to its potential to revolutionize learning experiences and support student skill development. This study delves into the dynamics of student interactions with AI support within the domain of C programming education, with a specific focus on the utilization of ChatGPT, a conversational AI model, during training sessions. Through manual clustering analysis, this research unveils distinct patterns of student engagement, elucidating diverse problem-solving approaches and varying levels of interaction with ChatGPT. Our findings underscore the importance of acknowledging individual differences in learning strategies and preferences, highlighting the necessity for personalized educational interventions tailored to meet the diverse needs of learners. However, despite the strides made in AI-supported learning, gaps persist in the existing literature, particularly concerning our understanding of how students approach prompts and exercises when utilizing AI-driven educational tools. This research aims to address this gap by shedding light on the nuanced dynamics of student-AI interactions during training of C programming, offering insights into effective pedagogical strategies and instructional design principles for integrating AI technologies into educational settings. This study makes a significant contribution to the continuous endeavors of educators and AI developers by furthering the discussion on AI-facilitated learning. It aims to enhance student engagement, learning outcomes, and overall educational experiences through the integration of technology into learning environments.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {555–560},
numpages = {6},
keywords = {AI Assistance, ChatGPT, Large Language Models, Learning Strategies, Learning Support Systems, Programming Education},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@article{10.1145/3711023,
author = {Neshaei, Seyed Parsa and Tolzin, Antonia and Berkle, Yvonne and Leuchter, Miriam and Leimeister, Jan Marco and Janson, Andreas and Wambsganss, Thiemo},
title = {Leveraging Learner Errors in Digital Argumentation Learning: How ALure Helps Students Learn from their Mistakes and Write Better Arguments},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3711023},
doi = {10.1145/3711023},
abstract = {Providing argumentation feedback is considered helpful for students preparing to work in collaborative environments, helping them with writing higher-quality argumentative texts. Domain-independent natural language processing (NLP) methods, such as generative models, can utilize learner errors and fallacies in argumentation learning to help students write better argumentative texts. To test this, we collect design requirements, and then design and implement two different versions of our system called ALure to improve the students' argumentation skills. We test how ALure helps students learn argumentation in a university lecture with 305 students and compare the learning gains of the two versions of ALure with a control group using video tutoring. We find and discuss the differences of learning gains in argument structure and fallacies in both groups after using ALure, as well as the control group. Our results shed light on the applicability of computer-supported systems using recent advances in NLP to help students in learning argumentation as a necessary skill for collaborative working settings.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW125},
numpages = {32},
keywords = {argumentation learning, learning from errors, natural language processing, writing assistants}
}

@inproceedings{10.1145/3675812.3675871,
author = {Zhong, Xuanyan and Xin, Haiyang and Li, Wenfeng and Zhan, Zehui and Cheng, May-hung},
title = {The Design and application of RAG-based conversational agents for collaborative problem solving},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675812.3675871},
doi = {10.1145/3675812.3675871},
abstract = {Dialogue is the basis of collaborative problem solving, and the development of generative artificial intelligence has made dialogue no longer limited to human-to-human, and human-computer dialogue has gradually become an important way for people to solve problems. At the same time, with the change of the subject of collaborative problem solving, the cultivation of collaborative problem-solving skill urgently needs to explore a new path. In this regard, more and more studies have begun to apply conversational agents in collaborative problem-solving activities, digging deeper into the effects of time on students in conversational agents. However, there is no clear answer to the question of how conversational agents can be better integrated into a collaborative environment for all to assist people in the collaborative problem-solving process and improve performance. In this study, we constructed a conceptual model of human-computer collaboration in order to improve students' learning performance. Based on this model, we integrated Retrieval-Augmented Generative and GPT to construct a conversational agent, and the results of the study showed that the Retrieval-Augmented Generative Agent for Collaborative Problem Solving constructed in this study can effectively promote students' collaborative problem-solving performance.},
booktitle = {Proceedings of the 2024 9th International Conference on Distance Education and Learning},
pages = {62–68},
numpages = {7},
keywords = {Collaborative problem solving, Conversational agent, GPT},
location = {Guangzhou, China},
series = {ICDEL '24}
}

@article{10.5555/3665464.3665471,
author = {Mouli, Chandra and Kotteti, Madhav and Lal, Ratan and Chetti, Prasad},
title = {Coding Integrity Unveiled: Exploring the Pros and Cons of Detecting Plagiarism in Programming Assignments Using Copyleaks},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {Before the advent of generative Artificial Intelligence (AI) tools, for example, ChatGPT, students traditionally approached assignment development authentically by employing libraries and by referring to textbooks. However, with the widespread reliance on powerful AI tools for assignment completion, the process has become more convenient. Unfortunately, this ease of use has led to a potential detriment in students' genuine understanding of subjects, as well as a decline in their problem-solving and innovative thinking skills. Moreover, AI tools like ChatGPT will evolve as technology advances such that the need to detect AI-generated content is even more crucial in educational setting to reinforce the value of original work [5]. This paper aims to address this issue by focusing on the detection of plagiarism in student assignments through the utilization of the Copyleaks1 tool, specifically designed to identify AI-generated code. The accuracy of the tool is systematically evaluated by submitting various pairs of codes, each with similar functionality, wherein one is generated by AI and the other by humans.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {61–69},
numpages = {9}
}

@inproceedings{10.1145/3490100.3516473,
author = {Suh, Sangho and An, Pengcheng},
title = {Leveraging Generative Conversational AI to Develop a Creative Learning Environment for Computational Thinking},
year = {2022},
isbn = {9781450391450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490100.3516473},
doi = {10.1145/3490100.3516473},
abstract = {We explore how generative conversational AI can assist students’ learning, creative, and sensemaking process in a visual programming environment where users can create comics from code. The process of visualizing code in terms of comics involves mapping programming language (code) to natural language (story) and then to visual language (of comics). While this process requires users to brainstorm code examples, metaphors, and story ideas, the recent development in generative models introduces an exciting opportunity for learners to harness their creative superpower and researchers to advance our understanding of how generative conversational AI can augment our intelligence in creative learning contexts. We provide an overview of our system and discuss interaction scenarios to demonstrate ways we can partner with generative conversational AI in the context of learning computer programming.},
booktitle = {Companion Proceedings of the 27th International Conference on Intelligent User Interfaces},
pages = {73–76},
numpages = {4},
keywords = {coding strip, comics, generative conversational AI, visual programming environment},
location = {Helsinki, Finland},
series = {IUI '22 Companion}
}

@inproceedings{10.1145/3706468.3706494,
author = {Jansen, Thorben and Horbach, Andrea and Meyer, Jennifer},
title = {Feedback from Generative AI: Correlates of Student Engagement in Text Revision from 655 Classes from Primary and Secondary School},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706494},
doi = {10.1145/3706468.3706494},
abstract = {Writing is fundamental in knowledge-based societies, and engaging students in text revision through feedback is critical for developing students’ writing skills. Automated feedback offers a promising solution to teachers’ time constraints creating feedback. However, prior research indicates that 20 to 71 percent of students receiving feedback do not engage in any text revision. Despite these concerning figures, students’ non-engagement has not received widespread attention, likely due to fragmented evidence from a few grade levels and writing tasks disconnected from regular teaching. Further, whether the issue persists when generative AI generates the feedback is unclear. The present study investigates what percentage of students behaviorally engage with feedback from generative AI in authentic classroom learning contexts. We analyzed data from an educational technology company, including 655 teacher-generated writing tasks involving 14,236 students across grades 1-12. Our findings show that around half of the students did not revise a single character in the text after receiving feedback. The percentage was similar across grade levels, task types, or feedback characteristics. We discuss the importance of including the percentage of engaged students as an additional metric in feedback research to achieve the goal that no student is left behind.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {831–836},
numpages = {6},
keywords = {student engagement, automated feedback, writing, generative AI},
location = {
},
series = {LAK '25}
}

@inproceedings{10.1145/3632620.3671116,
author = {Prather, James and Reeves, Brent N and Leinonen, Juho and MacNeil, Stephen and Randrianasolo, Arisoa S and Becker, Brett A. and Kimmel, Bailey and Wright, Jared and Briggs, Ben},
title = {The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671116},
doi = {10.1145/3632620.3671116},
abstract = {Novice programmers often struggle through programming problem solving due to a lack of metacognitive awareness and strategies. Previous research has shown that novices can encounter multiple metacognitive difficulties while programming, such as forming incorrect conceptual models of the problem or having a false sense of progress after testing their solution. Novices are typically unaware of how these difficulties are hindering their progress. Meanwhile, many novices are now programming with generative AI (GenAI), which can provide complete solutions to most introductory programming problems, code suggestions, hints for next steps when stuck, and explain cryptic error messages. Its impact on novice metacognition has only started to be explored. Here we replicate a previous study that examined novice programming problem solving behavior and extend it by incorporating GenAI tools. Through 21 lab sessions consisting of participant observation, interview, and eye tracking, we explore how novices are coding with GenAI tools. Although 20 of 21 students completed the assigned programming problem, our findings show an unfortunate divide in the use of GenAI tools between students who did and did not struggle. Some students who did not struggle were able to use GenAI to accelerate, creating code they already intended to make, and were able to ignore unhelpful or incorrect inline code suggestions. But for students who struggled, our findings indicate that previously known metacognitive difficulties persist, and that GenAI unfortunately can compound them and even introduce new metacognitive difficulties. Furthermore, struggling students often expressed cognitive dissonance about their problem solving ability, thought they performed better than they did, and finished with an illusion of competence. Based on our observations from both groups, we propose ways to scaffold the novice GenAI experience and make suggestions for future work.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {469–486},
numpages = {18},
keywords = {CS1, ChatGPT, Copilot, generative AI, large language models, metacognition},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3587102.3588792,
author = {Savelka, Jaromir and Agarwal, Arav and Bogart, Christopher and Song, Yifan and Sakr, Majd},
title = {Can Generative Pre-trained Transformers (GPT) Pass Assessments in Higher Education Programming Courses?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588792},
doi = {10.1145/3587102.3588792},
abstract = {We evaluated the capability of generative pre-trained transformers (GPT), to pass assessments in introductory and intermediate Python programming courses at the postsecondary level. Discussions of potential uses (e.g., exercise generation, code explanation) and misuses (e.g., cheating) of this emerging technology in programming education have intensified, but to date there has not been a rigorous analysis of the models' capabilities in the realistic context of a full-fledged programming course with diverse set of assessment instruments. We evaluated GPT on three Python courses that employ assessments ranging from simple multiple-choice questions (no code involved) to complex programming projects with code bases distributed into multiple files (599 exercises overall). Further, we studied if and how successfully GPT models leverage feedback provided by an auto-grader. We found that the current models are not capable of passing the full spectrum of assessments typically involved in a Python programming course (&lt;70% on even entry-level modules). Yet, it is clear that a straightforward application of these easily accessible models could enable a learner to obtain a non-trivial portion of the overall available score (&gt;55%) in introductory and intermediate courses alike. While the models exhibit remarkable capabilities, including correcting solutions based on auto-grader's feedback, some limitations exist (e.g., poor handling of exercises requiring complex chains of reasoning steps). These findings can be leveraged by instructors wishing to adapt their assessments so that GPT becomes a valuable assistant for a learner as opposed to an end-to-end solution.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {117–123},
numpages = {7},
keywords = {AI code generation, GPT, GitHub copilot, alphacode, codex, generative pre-trained transformers, introductory and intermediate programming, programming knowledge assessment, python course},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@inproceedings{10.1145/3636555.3636910,
author = {Hou, Chenyu and Zhu, Gaoxia and Zheng, Juan and Zhang, Lishan and Huang, Xiaoshan and Zhong, Tianlong and Li, Shan and Du, Hanxiang and Ker, Chin Lee},
title = {Prompt-based and Fine-tuned GPT Models for Context-Dependent and -Independent Deductive Coding in Social Annotation},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636555.3636910},
doi = {10.1145/3636555.3636910},
abstract = {GPT has demonstrated impressive capabilities in executing various natural language processing (NLP) and reasoning tasks, showcasing its potential for deductive coding in social annotations. This research explored the effectiveness of prompt engineering and fine-tuning approaches of GPT for deductive coding of context-dependent and context-independent dimensions. Coding context-dependent dimensions (i.e., Theorizing, Integration, Reflection) requires a contextualized understanding that connects the target comment with reading materials and previous comments, whereas coding context-independent dimensions (i.e., Appraisal, Questioning, Social, Curiosity, Surprise) relies more on the comment itself. Utilizing strategies such as prompt decomposition, multi-prompt learning, and a codebook-centered approach, we found that prompt engineering can achieve fair to substantial agreement with expert-labeled data across various coding dimensions. These results affirm GPT's potential for effective application in real-world coding tasks. Compared to context-independent coding, context-dependent dimensions had lower agreement with expert-labeled data. To enhance accuracy, GPT models were fine-tuned using 102 pieces of expert-labeled data, with an additional 102 cases used for validation. The fine-tuned models demonstrated substantial agreement with ground truth in context-independent dimensions and elevated the inter-rater reliability of context-dependent categories to moderate levels. This approach represents a promising path for significantly reducing human labor and time, especially with large unstructured datasets, without sacrificing the accuracy and reliability of deductive coding tasks in social annotation. The study marks a step toward optimizing and streamlining coding processes in social annotation. Our findings suggest the promise of using GPT to analyze qualitative data and provide detailed, immediate feedback for students to elicit deepening inquiries.&nbsp;},
booktitle = {Proceedings of the 14th Learning Analytics and Knowledge Conference},
pages = {518–528},
numpages = {11},
keywords = {Context-Dependent, Fine-tuning, GPT, Prompt Engineering, Social Annotation, deductive coding},
location = {Kyoto, Japan},
series = {LAK '24}
}

@article{10.5555/3729849.3729853,
author = {Garcia, Yuan and Ngo, Jenny and Lin, Florence Rui and Dodds, Zachary},
title = {Adaptable Metrics to Inform Introductory CS},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {9},
issn = {1937-4771},
abstract = {Metrics have long been used to assess and guide successful software projects. Traditionally these metrics have measured software's professional rather than its educational suitability. This work proposes six adaptable, reproducible pedagogical metrics. With these metrics, we track an Introductory CS course's capstone projects, 2018--2024. The results suggest both year-over-year evolution and a more sudden, LLM-correlated impact on students' relationship with their early computing work. We have begun adapting our curriculum to these signals, and we foresee future refinements and broader applications to metrics-based reproducible curricular assessment.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {34–42},
numpages = {9}
}

@inproceedings{10.1145/3657604.3662046,
author = {Chen, Binglin and Lewis, Colleen M. and West, Matthew and Zilles, Craig},
title = {Plagiarism in the Age of Generative AI: Cheating Method Change and Learning Loss in an Intro to CS Course},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662046},
doi = {10.1145/3657604.3662046},
abstract = {Background: ChatGPT became widespread in early 2023 and enabled the broader public to use powerful generative AI, creating a new means for students to complete course assessments.  Purpose: In this paper, we explored the degree to which generative AI impacted the frequency and nature of cheating in a large introductory programming course. We also estimate the learning impact of students choosing to submit plagiarized work rather than their own work.  Methods: We identified a collection of markers that we believe are indicative of plagiarism in this course. We compare the estimated prevalence of cheating in the semesters before and during which ChatGPT became widely available. We use linear regression to estimate the impact of students' patterns of cheating on their final exam performance. Findings: The patterns associated with these plagiarism markers suggest that the quantity of plagiarism increased with the advent of generative AI, and we see evidence of a shift from online plagiarism hubs (e.g., Chegg, CourseHero) to ChatGPT. In addition, we observe statistically significant learning losses proportional to the amount of presumed plagiarism, but there is no statistical difference on the proportionality between semesters.  Implications: Our findings suggest that unproctored exams become increasingly insecure and care needs to be taken to ensure the validity of summative assessments. More importantly, our results suggest that generative AI can be detrimental to students' learning. It seems necessary for educators to reduce the benefit of students using generative AI for counterproductive purposes.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {75–85},
numpages = {11},
keywords = {cheating, cs 1, generative ai, llm, plagiarism detection},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3626252.3630951,
author = {Vahid, Frank and Pang, Ashley and Denzler, Benjamin},
title = {Towards Comprehensive Metrics for Programming Cheat Detection},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630951},
doi = {10.1145/3626252.3630951},
abstract = {Automated assistance for detecting cheating on programs has long been investigated by CS educators, especially with the rise of "homework help" websites over the past decade, and recently with AI tools like ChatGPT. The main detection approach has long been flagging similar submission pairs. Modern cheating, like hiring contractors or using ChatGPT, may not yield such similarity. And, cases based on similarity alone may be weak. Thus, over the past several years, building on logs from an online program auto-grader (zyBooks), we developed additional "cheating concern metrics": points rate, style anomalies, style inconsistencies, IP address anomalies, code replacements, and initial copying. Most are defined not only for one programming assignment but also across a set of assignments. The metrics can help catch more kinds of cheating, provide more compelling evidence of cheating, reduce false cheating accusations based on similarity alone, and help instructors focus their limited cheat-detection time on the most egregious cases. We describe the techniques, and our experiences (via our own Python scripts and a commercial tool) for several terms, showing benefits of having more metrics than just similarity. Of 30 cheating cases over 3 terms and 300 students, most were based on metrics beyond similarity, all students admitted, none later contested, and time per student was only 1-2 hours (far less than previously). Our goal is to prevent cheating in the first place, by reducing opportunity via strong detection tools, as part of a multi-faceted approach to having students truly learn and stay out of trouble.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1361–1367},
numpages = {7},
keywords = {ai, cheating, cs1, homework, plagiarism, programming assignments},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3727648.3727765,
author = {Zhang, Kaijie and Wu, Minhui and Chen, Kaihao},
title = {Scaling Down LLaMA 3: Advanced Compression Techniques and Knowledge Distillation for Resource-Efficient Language Models},
year = {2025},
isbn = {9798400712647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727648.3727765},
doi = {10.1145/3727648.3727765},
abstract = {With the widespread application of large-scale language models (LLMs) in natural language processing, traditional Transformer-based models (such as LLaMA 3) face challenges in resource-constrained environments due to their huge parameter size and computational complexity. To improve efficiency, model compression has become an important research direction. This paper proposes an innovative knowledge distillation strategy to distill the LlamaDecoderLayer of LLaMA 3 into a smaller student model TinyDecoder to reduce the computational and storage overhead of the model. TinyDecoder significantly reduces the model size and computational complexity while maintaining good performance by simplifying parameters such as the hidden layer size and the number of attention heads in LlamaDecoderLayer. Experimental results show that the distilled model significantly reduces storage requirements and computational load while still achieving decent performance. The parameter size of the distilled model is about 4.3% of the original model, the throughput speedup ratio is 1.49x - 10.93x, and the perplexity only increases from 3.25 to 7.94. Although the text generation performance of the distilled model has declined, the inference speed and memory usage are significantly improved compared to the original model, which is particularly suitable for resource-constrained environments. Through distillation, the student model effectively learns the core knowledge of the teacher model and performs well on tasks of simple to medium complexity.},
booktitle = {Proceedings of the 4th International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {721–725},
numpages = {5},
keywords = {Knowledge Distillation, LLama 3 Optimization, Large Language Models, Model Compression},
location = {
},
series = {CAICE '25}
}

@inproceedings{10.1145/3675417.3675537,
author = {Li, Tianxin},
title = {Theoretical Construction of AIGC College Student User Information Demand Model},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675537},
doi = {10.1145/3675417.3675537},
abstract = {This paper takes ChatGPT as an example, employing a grounded theory research method while strictly adhering to the norms of research methods. The research team conducted a back-to-back three-level coding analysis of the original data obtained from interviews. This process involved identifying initial concepts, subcategories, and main categories, to deeply analyze the specific content and dimensions of AIGC college student user information demands. Based on the accuracy and comprehensiveness of the coding results, the paper constructs an AIGC college student user information demand model.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {716–721},
numpages = {6},
keywords = {AIGC, ChatGPT, User Requirements Research},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3615335.3623035,
author = {York, Eric},
title = {Evaluating ChatGPT: Generative AI in UX Design and Web Development Pedagogy},
year = {2023},
isbn = {9798400703362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615335.3623035},
doi = {10.1145/3615335.3623035},
abstract = {The advent of widely-accessible generative AI tools and their rapid adoption across industry and education is necessitating large-scale revisions to user experience design and web development pedagogies and curricula, a process that will take some time. This report describes a series of initial experiments using generative AI tools as a student or junior designer or web developer might, sometimes na\"{\i}vely and sometimes in more sophisticated ways, to complete beginner-level and advanced projects. The report evaluates how ChatGPT performs across three categories of prompts (brainstorming, design, and coding) and assesses the quality of the outputs in order to inform the research design of a larger, ongoing interdisciplinary study in its initial phases and to document the results for instructors or senior members of design and development teams to aid them in assessing the fitness of generative AI for user experience design and web development production.},
booktitle = {Proceedings of the 41st ACM International Conference on Design of Communication},
pages = {197–201},
numpages = {5},
keywords = {Artificial Intelligence, Pedagogy, User experience (UX) design, Web development},
location = {Orlando, FL, USA},
series = {SIGDOC '23}
}

@inproceedings{10.1145/3641555.3705038,
author = {Dzhumaliev, Mirbek and Musaev, Aibek and Pu, Calton},
title = {Leveraging Generative AI for Personalized Learning Experiences},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705038},
doi = {10.1145/3641555.3705038},
abstract = {This demo presents KimBilet.com, an educational platform that utilizes generative AI to create personalized educational content on demand. Catering to high-school and college students, instructors, job seekers, and lifelong learners, the system generates customized courses based on user prompts, covering any topic of interest. Each course may include a sequence of AI-created lessons and quizzes, providing detailed feedback for every quiz option to enhance understanding. The platform supports intuitive navigation through keyboard shortcuts and allows users to jump between course items seamlessly. It also maintains a history of completed quizzes to help users track their learning progress. Future enhancements include topic suggestions based on past interests, support for coding exercises, and multilingual support. This demo will showcase how KimBilet.com leverages AI to offer adaptive learning experiences, engage attendees through interactive exploration, and discuss its potential applications in educational settings. Participants will gain insights into integrating AI-driven tools into teaching and learning processes to address diverse educational needs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1732},
numpages = {1},
keywords = {AI in education, e-learning tools, educational technology, generative AI, personalized learning},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3641555.3705031,
author = {Diaz, Nicolas and Roy, Saunak and Beltran, Jonathan},
title = {Exploring Undergraduate AI Perceptions: Knowledge, Enthusiasm, and Concerns},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705031},
doi = {10.1145/3641555.3705031},
abstract = {As Artificial Intelligence (AI) develops and grows its presence in society, college students are increasingly interacting with AI and utilizing tools like ChatGPT as part of their education. Particularly in STEM fields, educators themselves are incorporating AI by encouraging its use as an assistive tool for coursework or designing courses that teach about its inner workings. Understanding students' perceptions and knowledge of AI can help educators know whether students will embrace learning in AI-heavy environments, as well as which student concerns they should acknowledge. Our study uses both quantitative and qualitative data from undergraduate CMNS (College of Computer, Mathematical, and Natural Sciences) students at the University of Maryland, College Park to explore students' perceived knowledge, enthusiasm, and concerns over AI. Our data was collected via a survey administered via email to undergraduates and subsequent focus group interviews with these students about their relationship with AI. Survey findings indicated that students were confident in their knowledge of AI and related competencies, as well as enthusiastic about learning and using AI. Students also highly believed in the need for standards and testing for AI systems to curtail risks. There was a positive correlation between perceived knowledge and enthusiasm of AI, but no correlation between knowledge and concerns. In interviews, students' main uses of AI were summarizing information, creating practice problems, and writing assistance. Popular concerns included academic dishonesty, overreliance on AI tools, and fabricated information in outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1753},
numpages = {1},
keywords = {artificial intelligence, generative AI, higher education, learning environments, student perceptions},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713832,
author = {Jain, Yoshee and Demirtas, Mehmet Arif and Cunningham, Kathryn Irene},
title = {PLAID: Supporting Computing Instructors to Identify Domain-Specific Programming Plans at Scale},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713832},
doi = {10.1145/3706598.3713832},
abstract = {Pedagogical approaches focusing on stereotypical code solutions, known as programming plans, can increase problem-solving ability and motivate diverse learners. However, plan-focused pedagogies are rarely used beyond introductory programming. Our formative study (N=10 educators) showed that identifying plans is a tedious process. To advance plan-focused pedagogies in application-focused domains, we created an LLM-powered pipeline that automates the effortful parts of educators’ plan identification process by providing use-case-driven program examples and candidate plans. In design workshops (N=7 educators), we identified design goals to maximize instructors’ efficiency in plan identification by optimizing interaction with this LLM-generated content. Our resulting tool, PLAID, enables instructors to access a corpus of relevant programs to inspire plan identification, compare code snippets to assist plan refinement, and facilitates them in structuring code snippets into plans. We evaluated PLAID in a within-subjects user study (N=12 educators) and found that PLAID led to lower cognitive demand and increased productivity compared to the state-of-the-art. Educators found PLAID beneficial for generating instructional material. Thus, our findings suggest that human-in-the-loop approaches hold promise for supporting plan-focused pedagogies at scale.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {52},
numpages = {21},
keywords = {programming plan, programming pattern, pattern identification, instructor support},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641554.3701853,
author = {Filcik, Daniel and Sobiesk, Edward and Matthews, Suzanne J.},
title = {Fostering Creativity: Student-Generative AI Teaming in an Open-Ended CS0 Assignment},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701853},
doi = {10.1145/3641554.3701853},
abstract = {The increasing ubiquity of web-based generative artificial intelligence technologies necessitates that all students experience teaming with such technologies -- exploring their strengths and limitations and learning how to create synergy with them. To aid in this effort, we designed an open-ended generative AI project for the freshmen taking our general-education introduction to computing course. Students were required to team with generative AI to create something beyond what they alone (or the AI alone) could accomplish. Upon completion, students submitted a short written critical analysis documenting their experiences and presented a three-minute demonstration of their project in class. Despite limited course coverage of AI and generative AI prior to this project, we were impressed by the creativity and sophistication of the submitted final products as well as the breadth of generative AI tools explored. Student reflections on the experience illustrated numerous insights into the strengths and limitations of the tools they employed. Our results underscore that students can learn about the benefits and limitations of generative AI in as little as a single assignment and that covering such topics need not require extensive amounts of course time and resources.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {339–345},
numpages = {7},
keywords = {computing education, cs0, final project, freshmen, generative artificial intelligence, human-ai teaming},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3660650.3660656,
author = {Bird, William},
title = {Faceless Adversary, Feckless Colleague: The Many Sides of ChatGPT},
year = {2024},
isbn = {9798400709975},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660650.3660656},
doi = {10.1145/3660650.3660656},
abstract = {Although CS educators have studied the potential of generative AI for years, the release of ChatGPT in late 2022 sparked a wave of uncertainty and anxiety. With students arriving at university already experienced with using ChatGPT for work across the academic spectrum, educators were under pressure to somehow address the presence of this new resource in their classroom. This article describes both the “climate of fear” surrounding ChatGPT’s impacts on education and an attempt by the authors to induct ChatGPT as a colleague instead of an adversary. While creating a video series where we used ChatGPT to generate practice exercises for CS1 and CS2, we found it to be patient, charismatic and friendly, but also sometimes obstinate, misinformed, stubborn and confused; in other words, it was surprisingly human.},
booktitle = {Proceedings of the 26th Western Canadian Conference on Computing Education},
articleno = {14},
numpages = {6},
keywords = {CS education, generative AI, teaching tools},
location = {Kelowna, BC, Canada},
series = {WCCCE '24}
}

@inproceedings{10.1145/3641555.3705278,
author = {Jayaraman, Sharanya and Kolarkar, Ameya},
title = {Using Peer Tutoring to Bolster Retention Rates and Student Performance in CS1 Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705278},
doi = {10.1145/3641555.3705278},
abstract = {Active Learning approaches have found success in CS1 and CS2 courses, consolidating instructional time on the practical, problem-solving aspects of programming. With the increasing availability of generative Artificial Intelligence Assistants, there is a renewed push to focus on higher-order skills beyond syntax and solving programming problems by matching sample outputs.This poster examines the impact of conceptual explanation-based exercises in introductory programming courses through the implementation of a scaffolded semi-flipped classroom. This method is currently in its third semester as a part of an ongoing, iterative, semi-experimental approach to support student resilience in entrance-level courses. This approach aimed to enhance student engagement, retention, and performance by integrating weekly practice sessions and "group-tutoring" sessions facilitated by peer learning assistants. In these sessions, students were encouraged to articulate their problem-solving strategies and the reasoning behind their solutions, fostering a deeper understanding of programming language paradigms and problem-solving techniques.The findings indicate that this method significantly increased classroom engagement, as students became more active participants in their learning journey. Retention rates improved as students became more confident in understanding and applying programming concepts. Overall, student performance saw a notable rise, with students demonstrating a better grasp of programming paradigms and problem-solving approaches beyond rote memorization and matching sample outputs.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1495–1496},
numpages = {2},
keywords = {active learning, cs1/cs2, peer-based learning, self-assessment},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713574,
author = {Ahmadpour, Naseem and Pillai, Ajit G. and Zhang, Wendy Qi and Loke, Lian and Sachathep, Thida and Zhou, Zhaohua and Gough, Phillip},
title = {Ethics Reflexivity Canvas: Resourcing Ethical Sensitivity for HCI Educators},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713574},
doi = {10.1145/3706598.3713574},
abstract = {Integrating ethics education in human-computer interaction (HCI) programs is critical to training responsible industry practitioners. Yet, there is a lack of practical educator-focused resources, which facilitate reflection on personal approaches to ethics education. We conducted a series of nine generative participatory workshops with 15 educators to explore, design and seek feedback on the Ethics Reflexivity Canvas as a pedagogical resource. The canvas makes the educator and learner positionality explicit to develop ethical sensitivity, sensitise and situate a pedagogical plan, and iterate and adapt over time. However, our findings suggest that educators experience tensions, depending on their pedagogical approach. We contribute insight on how resources can align with education work in HCI, help educators reflect on a plurality of approaches to ethics, use accessible language to stimulate curiosity towards ethics, and provide scaffolding to operationalize collaborative and personal exploration.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {399},
numpages = {17},
keywords = {ethics, ethical sensitivity, education work, educator, reflection, reflexivity, canvas},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3641237.3691673,
author = {Trim, Michelle and Butler, Erin and Suttcliffe, Christina},
title = {Seeing How the Sausage is Made: Data Storytelling as Means and Method in a Computer Science Writing Course},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691673},
doi = {10.1145/3641237.3691673},
abstract = {As data corpus-driven tools and technologies increasingly push users to passively search for an answer, rather than search to understand, we believe that technical and computing disciplinary writing courses have a duty to teach the process of responsible data storytelling. While students can grasp that generative AI makes mistakes, hallucinates, and perpetuates bias, they can need help understanding the antecedent causes of those difficulties. All algorithmically driven decision-making or recommending software have in common a large data set that has been labeled, either by users or by the system itself. The origins of that data and the reasonable applications/deductions and conclusions possible for any given dataset have everything to do with why some tools help and some tools perpetuate harms. By starting at the very beginning and asking students to make sense of data, students can more easily see how purpose and audience impact analysis of any given collection of data. Once those opportunities for rhetorical choice making are known, students become ready to understand the connection between data and complex A.I. systems and some of the ways that bias and other kinds of harm can result if designers are not careful. Combining instruction in a technical coding environment with basic data literacy lessons such as ‘the seven data stories,’ [14] we developed and delivered a three-week writing unit designed around responsible data exploration and storytelling. In this experience report, we provide the assignment we used, and the scaffolded activities we employed to bring students through the process, remarking on what worked well and what we want to improve. We provide attendees with a link to an R-based notebook with a walk-through lesson on data exploration commands, and the rubric used to assess students’ texts, notebooks with code and commentary and results, all existing in a referential context. We provide the survey results of students’ perception of learning from this activity. Early findings demonstrate that students internalized lessons about the non-objective nature of data analysis and of specific responsible data storytelling practices required by anyone seeking to ethically represent answers within and limitations of any dataset.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {217–222},
numpages = {6},
keywords = {Data Visualization, Data storytelling, Pedagogy, Technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3532512.3539664,
author = {Lewis, Clayton},
title = {Automatic Programming and Education},
year = {2022},
isbn = {9781450396561},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3532512.3539664},
doi = {10.1145/3532512.3539664},
abstract = {Automatic programming, as supported by recent language-model based AI systems, potentially allows a new approach to making computation a useful tool for learning, a goal of the Boxer project. This paper shows that the Codex system can be used to support some of the explorations in mathematics for which Boxer has been used. Virtually no knowledge of programming is required. Reflecting on the lessons from this exploration may sharpen the goals we bring to educational computing. What knowledge about computing, as distinct from the ability to creatively use computing, should learners gain?},
booktitle = {Companion Proceedings of the 6th International Conference on the Art, Science, and Engineering of Programming},
pages = {70–80},
numpages = {11},
keywords = {Boxer, automatic programming, computational literacy, education},
location = {Porto, Portugal},
series = {Programming '22}
}

@inproceedings{10.1145/3649165.3699863,
author = {Bailey, Cynthia},
title = {Artificial Intelligence Policy: What Computing Educators and Students Should Know},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3699863},
doi = {10.1145/3649165.3699863},
abstract = {Catalyzed by the release of ChatGPT by OpenAI in November 2022, policymakers worldwide have launched a surge of activity surrounding artificial intelligence (AI). The legal and policy frameworks emerging from this concentrated period of attention may shape AI governance for decades to come. This keynote will examine the implications of these global AI policy debates for computing educators and their students.  Drawing on the speaker's dual experience as a computing educator and AI policy adviser within the United States Senate, this presentation will explore the developing threads of AI policy that educators should integrate into their curricula to prepare students for an evolving socio-technical landscape.  The talk will present an overview of significant AI policy developments, including the European Union's AI Act, the over 120 AI-related bills currently pending in the United States Congress, and the United Arab Emirates' launch of a state-of-the-art open-source AI model. These examples will be contextualized within the history of how the current active regulatory stance diverges from prior approaches to technologies like the internet and social media, and consider the potential implications of this shift.  Equally important to understanding how AI policy is evolving is understanding why. Many legislative efforts are driven by concerns about AI's potential to exacerbate societal harms, such as election misinformation, cybersecurity threats, nonconsensual sexual imagery, weapons development, data privacy violations, intellectual property appropriation, labor market disruptions, and algorithmic biases. Coupled with these concerns is a widespread skepticism toward the tech industry's capacity for responsible self-governance. This context underscores the need for computing educators to engage students on issues of policy, ethics, and justice throughout the curriculum, to cultivate future professionals who can earn public trust and who appreciate the role of governments in establishing balance between innovation and safety guardrails.  Finally, the talk will offer reflections on the experience of serving as a technical adviser to policymakers, and advocate for computing educators to consider public service engagement on AI policy as a compelling career trajectory for themselves and their students.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {1–2},
numpages = {2},
keywords = {ai, artificial intelligence, ethics, government, policy, social impact},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3706468.3706559,
author = {Li, Tongguang and Nath, Debarshi and Cheng, Yixin and Fan, Yizhou and Li, Xinyu and Rakovi\'{c}, Mladen and Khosravi, Hassan and Swiecki, Zachari and Tsai, Yi-Shan and Ga\v{s}evi\'{c}, Dragan},
title = {Turning Real-Time Analytics into Adaptive Scaffolds for Self-Regulated Learning Using Generative Artificial Intelligence},
year = {2025},
isbn = {9798400707018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706468.3706559},
doi = {10.1145/3706468.3706559},
abstract = {In computer-based learning environments (CBLEs), adopting effective self-regulated learning (SRL) strategies requires sophisticated coordination of multiple SRL processes. While various studies have proposed adaptive SRL scaffolds (i.e. real-time advice on adopting effective SRL processes) and embedded them in CBLEs to facilitate learners’ effective use of SRL strategies, two key research gaps remain. First, there is a lack of research on SRL scaffolds that are based on continuous assessment of both learners’ SRL processes and learning conditions (e.g., awareness of learning resources) to provide adaptive support. Second, current analytics-based scaffolding mechanisms lack the scalability needed to effectively address multiple learning conditions. Integration of analytics of SRL with generative artificial intelligence (GenAI) can provide scalable scaffolding for real-time SRL processes and evolving conditions. Yet, empirical studies implementing and evaluating effects of this integration remain scarce. To address these limitations, we conducted a randomized control trial, assigning participants to three groups (control, process only, and process with condition groups) to investigate the effects of using GenAI to turn insights from real-time analytics about students’ SRL processes and conditions into adaptive scaffolds. The results demonstrate that integrating real-time analytics with GenAI in adaptive SRL scaffolds – addressing both SRL processes and dynamic conditions – promotes more metacognitive learning patterns compared to the control and process-only groups. In addition, the learners showed varying levels of compliance with analytics-based GenAI scaffolds, and this was also reflected in how the learners coordinated their SRL processes, particularly in the performance phase of SRL. This study contributes to the literature by designing, implementing, and evaluating the impact of adaptive scaffolds on learners’ SRL processes using real-time analytics with GenAI.},
booktitle = {Proceedings of the 15th International Learning Analytics and Knowledge Conference},
pages = {667–679},
numpages = {13},
keywords = {self-regulated learning, scaffolding compliance, GenAI, scaffolding, learning analytics},
location = {
},
series = {LAK '25}
}

@article{10.5555/3729849.3729850,
author = {Kerney, William},
title = {Treachery and Deceit: Detecting and Dissuading AI Cheating},
year = {2025},
issue_date = {April 2025},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {9},
issn = {1937-4771},
abstract = {Last semester, 75% of the author's data structures students were caught cheating at least once, with Generative AI technologies being the most common means by which they cheated. While it may be tempting to move back to in-person pen-and-paper evaluations to ensure students have retained material, the author has found is possible to detect and discourage the use of cheating via various tricky methods. Finally, the author looks at attempts by students to conceal their use of AI in cheating, and how successful off the shelf AI detection tools are at finding the use of AI in coding assignments before and after being rewritten by hand.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {10–17},
numpages = {8}
}

@inproceedings{10.1145/3638067.3638100,
author = {Freire, Andr\'{e} Pimenta and Cardoso, Paula Christina Figueira and Salgado, Andr\'{e} de Lima},
title = {May We Consult ChatGPT in Our Human-Computer Interaction Written Exam? An Experience Report After a Professor Answered Yes},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638100},
doi = {10.1145/3638067.3638100},
abstract = {Using ChatGPT in education presents challenges for evaluating students. It requires distinguishing between original ideas and those generated by the model, assessing critical thinking skills, and gauging subject mastery accurately, which can impact fair assessment practices. The Human-Computer Interaction course described in this experience report has enabled consultation with textbooks, slides and other materials for over five years. This experience report describes reflections regarding using ChatGPT as a source of consultation in a written HCI exam in 2023. The paper describes experiences with analysis of the types of questions ChatGPT was able to solve immediately without mediation and the types of questions that could benefit from ChatGPT’s assistance without compromising the assessment of higher-level learning outcomes that professors want to analyse in teaching HCI. The paper uses Bloom’s taxonomy to analyse different questions and abilities to be evaluated and how they can be solved solely by using ChatGPT. The paper discusses questions that need mediation, previous lived experience in class and understanding of the knowledge acquired in class that cannot be answered directly by copying and pasting questions into ChatGPT. The discussions can raise reflections on the learning outcomes that can be assessed in HCI written exams and how professors should reflect upon their experiences and expectations for exams in the age of growing generative artificial intelligence resources.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {6},
numpages = {11},
keywords = {ChatGPT, HCI education, evaluation, open-book exams},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3632620.3671112,
author = {Skripchuk, James and Bacher, John and Price, Thomas},
title = {An Investigation of the Drivers of Novice Programmers' Intentions to Use Web Search and GenAI},
year = {2024},
isbn = {9798400704758},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632620.3671112},
doi = {10.1145/3632620.3671112},
abstract = {External help resources are frequently used by novice programmers solving classwork in undergraduate computing courses. Traditionally, these tools consisted of web resources such as tutorial websites and Q&amp;A forums. With the rise of Generative AI (GenAI), there has been increasing concern and research about how external resources should be used in the classroom. However, little work has directly contrasted student beliefs and perceptions of web resources with GenAI, has grounded these beliefs in prior psychological theory, and has investigated how demographic factors and student backgrounds influence these beliefs and intentions. We administered a vignette-style survey across two courses required for a CS major at an R1 University, a freshman (n = 152) and senior capstone course (n = 44). Students responded to likert questions aiming to measure behavioral factors related to these tools, such as intention to use, perceived attitudes, peer perceptions, and their own perceived tool competency. We primarily investigate the results of an introductory course, finding that novices have a wide range of opinions on both resources, but overall find them slightly useful and have a tendency to prefer web-search. We compare this with seniors, who have more positive perceptions of these tools, and discuss possible reasons and implications for this difference. We constructed two path models to investigate which factors strongly influence novices’ intention to use resources and find the primary factor to be their general attitudes in how these tools will result in a positive or negative outcome (e.g. perceived benefits, justifiability). We also measure the effects of student background on intention to use these resources. Finally, we discuss implications and suggestions on how instructors can use this information to approach, address, and influence resource usage in their classrooms.},
booktitle = {Proceedings of the 2024 ACM Conference on International Computing Education Research - Volume 1},
pages = {487–501},
numpages = {15},
keywords = {CS Education, GenAI, Help-seeking, student perspectives, web-search},
location = {Melbourne, VIC, Australia},
series = {ICER '24}
}

@inproceedings{10.1145/3702163.3702451,
author = {Han, Mengying and Jiang, Rui and Hong, Jon-Chao and Li, Yushun},
title = {Educational Digital Divide: Investigating Teachers'Digital Teaching Competence in Digital Transformation of Education},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702451},
doi = {10.1145/3702163.3702451},
abstract = {Digital teaching has become one of the key approaches in the wave of digital transformation, considering teachers are the key role in digital teaching to achieve educational equity. What is the competence of teachers to cope with digital teaching has rarely been studied, especially with regard to the gender, regional and area differences. To address this gap, this study paid attention to the differences in digital teaching competence of teachers in different gender, regions and areas. A large-scale survey was conducted and 3,732 valid responses were collected (24.2% from rural schools, 31.4% from town schools, and 44.5% from urban schools) among four major regions. The results show that the overall digital teaching competence of teachers is at an intermediate level, with the emergence of the characteristic of “transforming teaching into learning”, but the competence of student-centered learning design, implementation and evaluation needs to be strengthened. What's more, there are significant differences in digital teaching competence among teachers of different genders, regions, and fields, highlighting the digital divide in education among different groups of teachers. Thus, this study provides valuable evidence that can be used to develop flexible, appropriate, and beneficial teacher professional development programs to prepare teachers for the adoption of generative AI in future education.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {429–434},
numpages = {6},
keywords = {Digital Teaching Assessment, Digital Teaching Competencies, Digital Teaching Design, Digital Teaching Implementation},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3626252.3630832,
author = {Sakzad, Amin and Paul, David and Sheard, Judithe and Brankovic, Ljiljana and Skerritt, Matthew P. and Li, Nan and Minagar, Sepehr and Simon and Billingsley, William},
title = {Diverging assessments: What, Why, and Experiences},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630832},
doi = {10.1145/3626252.3630832},
abstract = {In this experience paper, we introduce the concept of 'diverging assessments', process-based assessments designed so that they become unique for each student while all students see a common skeleton. We present experiences with diverging assessments in the contexts of computer networks, operating systems, ethical hacking, and software development. All the given examples allow the use of generative-AI-based tools, are authentic, and are designed to generate learning opportunities that foster students' meta-cognition. Finally, we reflect upon these experiences in five different courses across four universities, showing how diverging assessments enhance students' learning while respecting academic integrity.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {1161–1167},
numpages = {7},
keywords = {assessment-as-learning, authentic assessment, diverging assessment},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3626253.3635618,
author = {Garcia, Leiny and Ojeda-Ramirez, Santiago and Warschauer, Mark},
title = {Restorying with AI Art among Latinx Elementary Students},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635618},
doi = {10.1145/3626253.3635618},
abstract = {The Latinx community is underrepresented in tech-oriented fields, which aligns with the lack of culturally relevant learning experiences in CS for Latinx youth, hindering their ability to conceptualize technology as a tool for transformation and vehicle for cultural expression. This study takes on a restorying approach at the elementary level, where 9 fourth-grade students engaged in focus group discussions over three days to generate prompts for a generative AI art. Through the lens of restorying, the prompts had students conceptualize a future with a focus on their Mexican-American heritage, local community, and technology. The study revealed that students associated their heritage with symbolic representations such as food and music, and characterized the community as a commercialized space while also emphasizing locations conducive to family-oriented activities. As a result, technology in community spaces was associated with consumerism. However, when envisioning a futuristic, transformed community, they made deeper connections between the role of technology in the community, making intricate connections between community improvements and technology-based solutions. This underscores the need for computing education to dedicate time for young learners to reflect on the role technology has on their current culture and community to make deeper connections.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1648–1649},
numpages = {2},
keywords = {ai literacy, elementary school, heritage, latinx, restorying},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3641554.3701823,
author = {Ali, Areej and Collier, Aayushi Hingle and Dewan, Umama and McDonald, Nora and Johri, Aditya},
title = {Analysis of Generative AI Policies in Computing Course Syllabi},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701823},
doi = {10.1145/3641554.3701823},
abstract = {Since the release of ChatGPT in 2022, Generative AI (GenAI) is increasingly being used in higher education computing classrooms across the United States. While scholars have looked at overall institutional guidance for the use of GenAI and reports have documented the response from schools in the form of broad guidance to instructors, we do not know what policies and practices instructors are actually adopting and how they are being communicated to students through course syllabi. To study instructors' policy guidance, we collected 98 computing course syllabi from 54 R1 institutions in the U.S. and studied the GenAI policies they adopted and the surrounding discourse. Our analysis shows that 1) most instructions related to GenAI use were as part of the academic integrity policy for the course and 2) most syllabi prohibited or restricted GenAI use, often warning students about the broader implications of using GenAI, e.g. lack of veracity, privacy risks, and hindering learning. Beyond this, there was wide variation in how instructors approached GenAI including a focus on how to cite GenAI use, conceptualizing GenAI as an assistant, often in an anthropomorphic manner, and mentioning specific GenAI tools for use. We discuss the implications of our findings and conclude with current best practices for instructors.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {18–24},
numpages = {7},
keywords = {course syllabi, generative ai, policy},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3691720.3691768,
author = {Shan, Qiang},
title = {Design and application of a web front-end development course training platform based on generative artificial intelligence and low code development},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691768},
doi = {10.1145/3691720.3691768},
abstract = {With the rapid development of artificial intelligence technology, generative artificial intelligence has shown strong application potential in various fields, and low code development has become a popular choice for quickly building application systems due to its efficient and easy-to-use characteristics. With the continuous updates and iterations of web front-end development technology, how to improve learners' practical abilities and development efficiency has become an important issue in the field of vocational education. Therefore, we have designed an innovative web front-end development course training platform that combines the automation generation ability of generative artificial intelligence and the fast construction advantage of low code development. In platform design, we fully utilize the automated generation capability of generative artificial intelligence to achieve intelligent generation and layout optimization of front-end page elements. At the same time, with the help of the visual programming interface and component-based development methods of low code development platforms, the front-end development process is simplified, the technical threshold is lowered, and students can focus more on the implementation of business logic and creative expression.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {287–291},
numpages = {5},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3649217.3653607,
author = {Rivera, Elijah and Steinmaurer, Alexander and Fisler, Kathi and Krishnamurthi, Shriram},
title = {Iterative Student Program Planning using Transformer-Driven Feedback},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653607},
doi = {10.1145/3649217.3653607},
abstract = {Problem planning is a fundamental programming skill, and aids students in decomposing tasks into manageable subtasks. While feedback on plans is beneficial for beginners, providing this in a scalable and timely way is an enormous challenge in large courses.Recent advances in LLMs raise the prospect of helping here. We utilize LLMs to generate code based on students' plans, and evaluate the code against expert-defined test suites. Students receive feedback on their plans and can refine them.In this report, we share our experience with the design and implementation of this workflow. This tool was used by 544 students in a CS1 course at an Austrian university. We developed a codebook to evaluate their plans and manually applied it to a sample. We show that LLMs can play a valuable role here. However, we also highlight numerous cautionary aspects of using LLMs in this context, many of which will not be addressed merely by having more powerful models (and indeed may be exacerbated by it).},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {45–51},
numpages = {7},
keywords = {automated feedback, llms, program planning},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3699538.3699591,
author = {Keuning, Hieke and Luxton-Reilly, Andrew and Ott, Claudia and Petersen, Andrew and Kiesler, Natalie},
title = {Goodbye Hello World - Research Questions for a Future CS1 Curriculum},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699591},
doi = {10.1145/3699538.3699591},
abstract = {Generative AI (GenAI) is currently capable of generating correct code for introductory level programming problems, and its performance is improving. We believe that this capability can be leveraged to improve student motivation, broaden students’ understanding of software development, and engage them in more authentic learning. We defined a set of assumptions about GenAI’s future capabilities (e.g., the ability to generate small pieces of code and to compose these pieces of code via user prompts) and engaged in a backcasting exercise to identify what else is needed to develop a CS1 course that places GenAI in a central role. Undertaking this thought experiment immediately revealed that aspects of the software development process usually reserved for later in the curriculum, such as requirements elicitation and design, could be introduced earlier in the process. With GenAI tools bearing the load of generating correct code snippets, students could focus on higher-level software design and construction skills and practice them in an authentic environment. Our thought experiment identified a set of questions that need to be addressed for such a course to actually exist, including questions about student preparation, and the ability of students to decompose problems effectively and to resolve problems that arise when integrating pieces of code. We also identified questions related to the design of a GenAI centered course, such as the impact on student motivation of using GenAI instead of engaging directly with code, the extent to which social learning theories apply to interactions with GenAI, and how existing pedagogies can integrate GenAI tools.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {27},
numpages = {2},
keywords = {Computing education, CS1, Generative AI, Mastery Learning, LLMs},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3649405.3659534,
author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Virginia and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and Smith, David H. and Strickroth, Sven and Zingaro, Daniel},
title = {How Instructors Incorporate Generative AI into Teaching Computing},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659534},
doi = {10.1145/3649405.3659534},
abstract = {Generative AI (GenAI) has seen great advancements in the past two years and the conversation around adoption is increasing. Widely available GenAI tools are disrupting classroom practices as they can write and explain code with minimal student prompting. While most acknowledge that there is no way to stop students from using such tools, a consensus has yet to form on how students should use them if they choose to do so. At the same time, researchers have begun to introduce new pedagogical tools that integrate GenAI into computing curricula. These new tools offer students personalized help or attempt to teach prompting skills without undercutting code comprehension. This working group aims to detail the current landscape of education-focused GenAI tools and teaching approaches, present gaps where new tools or approaches could appear, identify good practice-examples, and provide a guide for instructors to utilize GenAI as they continue to adapt to this new era.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {771–772},
numpages = {2},
keywords = {artificial intelligence, generative AI, large language models, pedagogical practices, teaching computing},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3703619.3706049,
author = {Casas, Llogari and Mitchell, Kenny},
title = {Structured Teaching Prompt Articulation for Generative-AI Role Embodiment with Augmented Mirror Video Displays},
year = {2025},
isbn = {9798400713484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703619.3706049},
doi = {10.1145/3703619.3706049},
abstract = {We present a classroom enhanced with augmented reality video display in which students adopt snapshots of their corresponding virtual personas according to their teacher’s live articulated spoken educational theme, linearly, such as historical figures, famous scientists, cultural icons, and laterally according to archetypal categories such as world dance styles. We define a structure of generative AI prompt guidance to assist teachers with focused specified visual role embodiment stylization. By leveraging role-based immersive embodiment, our proposed approach enriches pedagogical practices that prioritize experiential learning.},
booktitle = {Proceedings of the 19th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {15},
numpages = {7},
keywords = {Artificial Intelligence, Generative AI, Human-Computer Interaction, Virtual Reality},
location = {Nanjing, Guangdong Province, China},
series = {VRCAI '24}
}

@article{10.5555/3715622.3715635,
author = {Al-Nsour, Rawan},
title = {AI Tools in Matlab Course Education: Instructor Point of View},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {2},
issn = {1937-4771},
abstract = {This work aims to investigate the influence of AI tools, specifically ChatGPT, on assignment submissions for an undergraduate programming course. The study evaluates the variance between MATLAB code submissions supported by ChatGPT and those based solely on traditional classroom resources such as instructor notes, textbooks, and class exercises. By analyzing these differences, the research seeks to highlight the advantages of using AI as an assistant tool, including enhanced efficiency and personalized feedback. However, it also examines the drawbacks, such as potential over-reliance on AI and its impact on achieving students' learning goals. Additionally, the study provides recommendations on how to manage and integrate this new technology effectively to ensure that it complements rather than detracts from the educational experience. Through this comprehensive evaluation, the paper seeks to offer insights into balancing AI assistance with traditional teaching methods to optimize learning outcomes in programming education.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {95–104},
numpages = {10}
}

@inproceedings{10.1145/3701716.3715244,
author = {Wang, Tianfu and Zhan, Yi and Lian, Jianxun and Hu, Zhengyu and Yuan, Nicholas Jing and Zhang, Qi and Xie, Xing and Xiong, Hui},
title = {LLM-powered Multi-agent Framework for Goal-oriented Learning in Intelligent Tutoring System},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3715244},
doi = {10.1145/3701716.3715244},
abstract = {Intelligent Tutoring Systems (ITSs) have revolutionized education by offering personalized learning experiences. However, as goal-oriented learning, which emphasizes efficiently achieving specific objectives, becomes increasingly important in professional contexts, existing ITSs often struggle to deliver this type of targeted learning experience. In this paper, we propose GenMentor, an LLM-powered multi-agent framework designed to deliver goal-oriented, personalized learning within ITS. GenMentor begins by accurately mapping learners' goals to required skills using a fine-tuned LLM trained on a custom goal-to-skill dataset. After identifying the skill gap, it schedules an efficient learning path using an evolving optimization approach, driven by a comprehensive and dynamic profile of learners' multifaceted status. Additionally, GenMentor tailors learning content with an exploration-drafting-integration mechanism to align with individual learner needs. Extensive automated and human evaluations demonstrate GenMentor's effectiveness in learning guidance and content quality. Furthermore, we have deployed it in practice and also implemented it as an application. Practical human study with professional learners further highlights its effectiveness in goal alignment and resource targeting, leading to enhanced personalization. Supplementary resources are available at ttps://github.com/GeminiLight/gen-mentor.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {510–519},
numpages = {10},
keywords = {intelligent tutoring system, large language model, multi-agent},
location = {Sydney NSW, Australia},
series = {WWW '25}
}

@inproceedings{10.1145/3649165.3690113,
author = {Kasinidou, Maria and Kleanthous, Styliani and Otterbacher, Jahna},
title = {"We have to learn to work with such systems": Students' Perceptions of ChatGPT After a Short Educational Intervention on NLP},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690113},
doi = {10.1145/3649165.3690113},
abstract = {Natural Language Processing (NLP) is a critical area of AI that is increasingly integrated into everyday life. The public regularly engages with systems such as Siri, Alexa, and more recently, ChatGPT, yet few understand how these systems work. In this paper, we examine how students perceive NLP technologies after completing a unit on NLP within an AI course designed for non-CS majors. We further present our students' perspectives on the banning of ChatGPT in Italy, where the course was delivered. The NLP unit featured a lecture, an interactive session, and a practical assignment wherein students developed a smart assistant responsive to textual commands. Students, after creating their smart assistants, highlighted challenges such as inadequate training datasets and natural language ambiguity. Opinions on ChatGPT's ban varied, with privacy concerns prevailing. However, a consensus emerged in favor of educational efforts to raise awareness about technology limitations, advocating understanding over outright bans in anticipation of their inevitable integration into daily life.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {74–80},
numpages = {7},
keywords = {artificial intelligence, chatgpt, large language models, natural language processing},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3624720,
author = {Denny, Paul and Prather, James and Becker, Brett A. and Finnie-Ansley, James and Hellas, Arto and Leinonen, Juho and Luxton-Reilly, Andrew and Reeves, Brent N. and Santos, Eddie Antonio and Sarsa, Sami},
title = {Computing Education in the Era of Generative AI},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3624720},
doi = {10.1145/3624720},
abstract = {Challenges and opportunities faced by computing educators and students adapting to LLMs capable of generating accurate source code from natural-language problem descriptions.},
journal = {Commun. ACM},
month = jan,
pages = {56–67},
numpages = {12}
}

@inproceedings{10.1145/3573051.3596191,
author = {Smolansky, Adele and Cram, Andrew and Raduescu, Corina and Zeivots, Sandris and Huber, Elaine and Kizilcec, Rene F.},
title = {Educator and Student Perspectives on the Impact of Generative AI on Assessments in Higher Education},
year = {2023},
isbn = {9798400700255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573051.3596191},
doi = {10.1145/3573051.3596191},
abstract = {The sudden popularity and availability of generative AI tools, such as ChatGPT that can write compelling essays on any topic, code in various programming languages, and ace standardized tests across domains, raises questions about the sustainability of traditional assessment practices. To seize this opportunity for innovation in assessment practice, we conducted a survey to understand both the educators' and students' perspectives on the issue. We measure and compare attitudes of both stakeholders across various assessment scenarios, building on an established framework for examining the quality of online assessments along six dimensions. Responses from 389 students and 36 educators across two universities indicate moderate usage of generative AI, consensus for which types of assessments are most impacted, and concerns about academic integrity. Educators prefer adapted assessments that assume AI will be used and encourage critical thinking, but students' reaction is mixed, in part due to concerns about a loss of creativity. The findings show the importance of engaging educators and students in assessment reform efforts to focus on the process of learning over its outputs, higher-order thinking, and authentic applications.},
booktitle = {Proceedings of the Tenth ACM Conference on Learning @ Scale},
pages = {378–382},
numpages = {5},
keywords = {ChatGPT, assessment, educators, generative AI, students, survey},
location = {Copenhagen, Denmark},
series = {L@S '23}
}

@inproceedings{10.1145/3716554.3716575,
author = {Andreatos, Antonios},
title = {Using ChatGPT for developing and simulating a circuit in VHDL},
year = {2025},
isbn = {9798400713170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3716554.3716575},
doi = {10.1145/3716554.3716575},
abstract = {This article describes the experience of using ChatGPT for developing and simulating an 8253/ 8254 counter/timer in VHDL without prior knowledge of the language. An 8253/ 8254 chip contains three counters/timers, each of which can work in six different modes of operation. The design is hierarchical and was developed in steps; initially a single counter was developed and simulated; next, a higher-level module containing three such timers was developed and a particular configuration was simulated. ChatGPT suggested the proper tools for the user’s platform, the VHDL code, the testbenches, the procedure (commands) and the troubleshooting. Manual interventions were necessary for fine-tuning. The quality and accuracy of the code generated by ChatGPT were found to be proportional to the user’s specifications, which implies that the specifications must be accurate. In order to get a satisfactory result, several trials (initial specifications, simulation, review, revised specifications) were needed. What made this experiment interesting was that the author did not have prior VHDL language know-how. The experience was interesting and leaded to the following findings: ChatGPT can produce code but it is not guaranteed that it won’t have syntactical or logical errors; the quality of the generated code is directly dependent on the clarity of the specifications, otherwise the user wastes a lot of time correcting errors and re-defining specifications; ChatGPT is a valuable self-learning tool for both students and teachers providing personalized and interactive learning.},
booktitle = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {143–147},
numpages = {5},
keywords = {8253/8254 counter/timer, VHDL, ChatGPT, simulation, specifications, learning by example, pair programming},
location = {
},
series = {PCI '24}
}

@inproceedings{10.1145/3672608.3707909,
author = {Zambach, Sine},
title = {AI-Enhanced Learning: Comparing Outcomes in Introductory and Advanced Programming Courses},
year = {2025},
isbn = {9798400706295},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672608.3707909},
doi = {10.1145/3672608.3707909},
abstract = {Generative AI chatbots have recently transformed education, necessitating new teaching methods for this paradigm. This study compares the impact of generative AI on introductory and advanced programming courses in fall 2023. Advanced students showed better outcomes, while the performance of introductory students remained unchanged or declined. This highlights the need for tailored AI integration strategies based on students' skill levels.},
booktitle = {Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing},
pages = {104–105},
numpages = {2},
keywords = {teaching, higher education, chatbots, generative AI},
location = {Catania International Airport, Catania, Italy},
series = {SAC '25}
}

@inproceedings{10.1145/3675417.3675461,
author = {Liu, Shitou and Liang, Zhenjie and Zhang, Ling},
title = {Analyzing Key Influencing Factors of University Teachers45 Use of Generative Artificial Intelligence in a Small-Sample Data Environment},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675461},
doi = {10.1145/3675417.3675461},
abstract = {This study focuses on exploring the key factors influencing the use of generative artificial intelligence (AI) by university teachers in the context of digital education, particularly in the backdrop of human-computer interaction. Considering the challenges posed by small-sample data, we employed various machine learning models such as linear regression, random forest regression, and support vector regression (SVR), and optimized model parameters through grid search and cross-validation techniques. The optimized models exhibited significantly improved performance, with the linear regression model showing a mean squared error (MSE) of 0.1239 and an R² score of 0.6362, indicating its good predictive accuracy and generalization ability on the small-sample dataset. The study results emphasize performance expectations, perceived value, and community influence as primary influencing factors for university teachers' use of generative AI, especially in the context of human-computer interaction. This is crucial for understanding and promoting the acceptance and use of educational technology. This research provides valuable insights for education policymakers and technology developers and offers important methodological guidance for machine learning applications dealing with small-sample data.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {271–279},
numpages = {9},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3641555.3704762,
author = {Birillo, Anastasiia and Keuning, Hieke and Migut, Gosia and Dzialets, Katsiaryna and Golubev, Yaroslav},
title = {Creating in-IDE Programming Courses},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704762},
doi = {10.1145/3641555.3704762},
abstract = {The in-IDE learning format represents a novel way of teaching programming to students entirely within an industry-grade IDE, allowing them to learn both the language and the necessary tooling at the same time. In this tutorial, we will teach the audience everything they need to know to create in-IDE courses and analyze how the students are working in them. In the first part of the tutorial, the audience will get to know the JetBrains Academy plugin that allows creating courses for IntelliJ-based IDEs such as IntelliJ IDEA and PyCharm. The participants will develop their own simple courses with theory, programming tasks, and quizzes, as well as employ some LLM-based features like automatic test generation. In the second part, we will learn how to use another plugin to collect code snapshots and the usage of IDE features of students when they are solving the tasks. Finally, the participants will solve tasks in their own course while using the data gathering plugin, and we will show them how to process and analyze the collected data. As the outcome of the tutorial, the audience will know how to create in-IDE courses, track the students' performance and analyze it, and will already have their own simple course and a dataset that can be expanded or used for further research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1767},
numpages = {1},
keywords = {In-IDE learning, JetBrains academy, LLMs, MOOCs, activity tracking, course creation, generative AI, programming education, programming exercises},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3670653.3677507,
author = {Kubullek, Ann-Kathrin and Kuma\c{c}, Nadire and Dogang\"{u}n, Ayseg\"{u}l},
title = {Understanding the Adoption of ChatGPT in Higher Education: A Comparative Study with Insights from STEM and Business Students},
year = {2024},
isbn = {9798400709982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670653.3677507},
doi = {10.1145/3670653.3677507},
abstract = {Since ChatGPT’s introduction, generative artificial intelligence (AI) has significantly influenced the media, technological innovation, and educational discourse. Its increasing importance, especially in academia, necessitates a detailed examination of the impact of AI on higher education, particularly on how it changes teaching and learning processes. This study therefore looks at the factors affecting students’ attitudes towards AI technologies in the university setting, with a particular focus on the differences between business and STEM programmes. Using a mixed methods approach, the study combines surveys and interviews to collect data on students’ perceptions, attitudes and experiences with generative AI technology in academia. The data collected is analysed both quantitatively and qualitatively to reveal significant trends and insights into the adoption and use of generative AI tools in the university environment. The main objective of the study is to shed light on the determinants that determine the varying degrees of AI adoption in different academic disciplines. The findings have the potential to inform the implementation of educational technology and assist in the development of strategies for the effective integration of generative AI tools to meet the different needs and preferences of students in a range of academic contexts.},
booktitle = {Proceedings of Mensch Und Computer 2024},
pages = {684–689},
numpages = {6},
keywords = {ChatGPT, STEM degree programs, academic disciplines, acceptance of AI, business degree programs, generative AI adoption, higher education, students},
location = {Karlsruhe, Germany},
series = {MuC '24}
}

@inproceedings{10.1145/3660853.3660863,
author = {McGowan, Aidan and Anderson, Neil and Smith, Christopher},
title = {The use of ChatGPT to generate Summative Feedback in Programming Assessments that is Consistent, Prompt, without Bias and Scalable},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660863},
doi = {10.1145/3660853.3660863},
abstract = {ABSTRACTThis paper explores the automated integration of ChatGPT into the feedback process for a large-scale and complex university programming assignment. It aims to explore the feasibility of using ChatGPT to facilitate prompt, efficient, and valued feedback to students. The study presents case studies illustrating the use of the ChatGPT API in generating feedback through an automated tool (AutoFeed) developed by the researchers. The findings report on the advantages as well as the limitations of employing Prompt Engineering for this purpose.},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {39–43},
numpages = {5},
keywords = {ChatGPT, Gen Ai, Programming,university,lab,feedback},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

@inproceedings{10.1145/3626253.3635606,
author = {Hou, Xinying and Ericson, Barbara J. and Wang, Xu},
title = {Integrating Personalized Parsons Problems with Multi-Level Textual Explanations to Scaffold Code Writing},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635606},
doi = {10.1145/3626253.3635606},
abstract = {Novice programmers need to write basic code as part of the learning process, but they often face difficulties. To assist struggling students, we recently implemented personalized Parsons problems, which are code puzzles where students arrange blocks of code to solve them, as pop-up scaffolding. Students found them to be more engaging and preferred them for learning, instead of simply receiving the correct answer, such as the response they might get from generative AI tools like ChatGPT. However, a drawback of using Parsons problems as scaffolding is that students may be able to put the code blocks in the correct order without fully understanding the rationale of the correct solution. As a result, the learning benefits of scaffolding are compromised. Can we improve the understanding of personalized Parsons scaffolding by providing textual code explanations? In this poster, we propose a design that incorporates multiple levels of textual explanations for the Parsons problems. This design will be used for future technical evaluations and classroom experiments. These experiments will explore the effectiveness of adding textual explanations to Parsons problems to improve instructional benefits.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1686–1687},
numpages = {2},
keywords = {code explanations, code writing, hint, introductory programming, large language models, parsons problems, scaffolding},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@article{10.5555/3636988.3637001,
author = {Tu, Junyi},
title = {How to Integrate ChatGPT into the CS1/CS2 Sequence},
year = {2023},
issue_date = {October 2023},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {3},
issn = {1937-4771},
abstract = {ChatGPT is one of most revolutionary technologies and fiercely debated on the benefit and disaster of its effect on human society. How to guide students to use this new technology is an inevitably topic as CS educators. This nifty idea includes ways to integrate ChatGPT into the CS1/CS2 sequence, how to guide students to use ChatGPT in a constructive way, instead of cheating on their homework.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {34},
numpages = {1}
}

@inproceedings{10.1145/3641555.3704769,
author = {Sussman, Alan and Prasad, Sushil and Bunde, David P. and Spacco, Jaime and Gannod, Gerald and Crockett, April Renee and Vaidyanathan, Ramachandran},
title = {Modernizing the CS Introductory Sequence with Parallel and Distributed Computing (and some AI)},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3704769},
doi = {10.1145/3641555.3704769},
abstract = {Parallel and distributed computing (PDC) has become pervasive in all aspects of computing, so it is essential that students include parallelism and distribution in the computational thinking that they apply to problem solving, from the beginning of their computing education. With all computing devices that students use having multiple cores as well as a GPU in many cases, many students' favorite applications use multiple cores and/or distributed processors. However, we are still teaching them to solve problems using only sequential thinking. Why?This hands-on tutorial will demonstrate how easy it is to open students' eyes to exploiting concurrency in problem solving. You will participate in plugged and unplugged activities that will help students to recognize examples of PDC concepts and concurrency in the world around them. We introduce plugged and unplugged curriculum modules that have been successfully integrated in existing computing classes at multiple institutions. We will also discuss recent efforts at integrating AI methods, including LLMs, into introductory classes.A laptop capable of running a C/C++ compiler, a Java virtual environment, and a Python interpreter is needed to fully participate in activities. However, attendees may learn the core concepts without a laptop. The activities and curriculum modules have been used successfully to teach PDC concepts in early computing courses and will be available after the workshop. Participants will receive a stipend of 400 to defray their cost of registration and one-night hotel stay. The CDER center will also have a booth in the exhibition hall for additional support.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1775},
numpages = {1},
keywords = {acm/ieee-cs/aaai computer science curricula, ai, computing education, cs1/ cs2, early computing class, hpc education, undergraduate instruction, pdc education},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3587102.3588773,
author = {Denny, Paul and Becker, Brett A. and Leinonen, Juho and Prather, James},
title = {Chat Overflow: Artificially Intelligent Models for Computing Education - renAIssance or apocAIypse?},
year = {2023},
isbn = {9798400701382},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587102.3588773},
doi = {10.1145/3587102.3588773},
abstract = {Recent breakthroughs in deep learning have led to the emergence of generative AI models that exhibit extraordinary performance at producing human-like outputs. Using only simple input prompts, it is possible to generate novel text, images, video, music, and source code, as well as tackle tasks such as answering questions and translating and summarising text.However, the potential for these models to impact computing education practice is only just beginning to be explored. For example, novices learning to code can now use free tools that automatically suggest solutions to programming exercises and assignments; yet these tools were not designed with novices in mind and little to nothing is known about how they will impact learning. Furthermore, much attention has focused on the immediate challenges these models present, such as academic integrity concerns. It seems that even in the AI-era a pending apocalypse sells better than a promising renaissance.Generative AI will likely play an increasing role in people's lives in the reasonably foreseeable future. Model performance seems set to continue accelerating while novel uses and new possibilities multiply. Given this, we should devote just as much effort to identifying and exploiting new opportunities as we do to identifying and mitigating challenges.In this talk, we begin by discussing several concrete and research-backed opportunities for computing educators. Many of these have already shown great promise in positively impacting current practice. We then discuss more short- to medium-term possibilities in areas such as student recruitment, and curricular changes. Finally - against our better judgement - we speculate over the longer-term, including rethinking the very fundamentals of the practice of teaching introductory and advanced computing courses. In these discussions we suggest potential research questions and directions. Although making remotely accurate predictions in such a fast-changing landscape is foolhardy, we believe that now is the time to explore and embrace opportunities to help make positive change in as many computing classrooms as possible.},
booktitle = {Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1},
pages = {3–4},
numpages = {2},
keywords = {ai, artificial intelligence, chatgpt, computer programming, computer science education, computing education, copilot, deep learning, generative ai, large language models, llm, machine learning},
location = {Turku, Finland},
series = {ITiCSE 2023}
}

@article{10.1145/3735652,
author = {Guo, Teng and Zhan, Bojun and Huang, Shuyan and Chen, Jiahao and Zhao, Xiangyu and Hou, Mingliang and Liu, Zitao},
title = {Improving Knowledge Tracing through Multi-Source Scaling with Decoder-Only Transformers},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3735652},
doi = {10.1145/3735652},
abstract = {Knowledge tracing (KT) is a problem of modeling students’ knowledge states to predict their future performance by observing their historical learning interactions. The collection of educational data presents significant challenges, as students’ limited learning engagement restricts the generation of large-scale interaction data, while stringent privacy regulations further limit the availability of student learning sequences from online platforms. Hence, it is crucial to enhance the capabilities of deep learning based KT (DLKT) models by constructing large-scale datasets through the integration of student interaction data across multiple subjects and sources. The success of ChatGPT demonstrates that the decoder-only Transformer architecture is highly effective in capturing complex information from large-scale sequential data. Against this background, we propose a novel decoder-only Transformer architecture based model, named Unified DLKT (UniKT), to learn coherent and unified representations across a wide range of data sources. Specifically, we combine student learning sequences from six educational scenarios and utilize a multi-source encoding to learn unified representations of interactions from mixed data. UniKT is a stack of Transformer decoder layers for handling long-term dependencies among students’ historical interactions and future performance. We evaluate UniKT on six publicly available real-world educational datasets, and experimental results demonstrate that our method outperforms the majority of existing DLKT models in terms of AUC and accuracy. Furthermore, the empirical analysis shows the strong transferability and adaptability of UniKT in learning from multiple sources. To encourage reproducible research, we make our data and code publicly available at .},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
keywords = {knowledge tracing, cognitive behavior, attention mechanism, temporal learning environments}
}

@inproceedings{10.1145/3649405.3659517,
author = {Glassey, Richard and Baltatzis, Alexander},
title = {Active Repos: Integrating Generative AI Workflows into GitHub},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649405.3659517},
doi = {10.1145/3649405.3659517},
abstract = {The aim of this work is to describe a simple and cost effective way to integrate generative AI into GitHub to support course specific scenarios. We are motivated by helping teachers realise their creative AI use cases in spite of technical barriers and also to ensure that students have a blessed and fair way to access AI services without needing to sign-up, prompt or pay. First we will describe a scenario that we have implemented for our own CS1 course, then we will describe the technical requirements for implementation. We finish off with our early thoughts on where these types of scenarios might be heading in terms of supporting computing education.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
pages = {777–778},
numpages = {2},
keywords = {CS1, GitHub actions, automation, generative AI},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3689535.3689543,
author = {Addo, Salomey Afua and Sentance, Sue},
title = {Exploring Computing Teachers' Readiness to Teach AI in Secondary Schools},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689543},
doi = {10.1145/3689535.3689543},
abstract = {Artificial intelligence (AI) is significantly impacting how we live, and the increased capabilities of generative AI applications have positioned AI firmly in the public domain. There is a growing interest in what AI might look like as a subject within the K-12 curriculum, whilst research on teachers’ readiness for teaching AI is as yet limited. This paper describes a qualitative study investigating teachers’ readiness to teach AI in secondary education. The interview study involved eight computing teachers with varying teaching experiences. We used reflexive thematic analysis for themes development. Findings suggest several indicators of teachers’ readiness, including attitudes, prior AI experience, professional development, and access to quality resources. This paper contributes to ongoing debates about how to best support teachers to be ready to teach AI effectively at the school level.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {17},
numpages = {1},
keywords = {K-12 education, artificial intelligence, computing education, teacher readiness},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3641555.3705051,
author = {Nagakalyani, Goda and Chaudhary, Saurav and Apte, Varsha and Ramakrishnan, Ganesh},
title = {TA Buddy: AI-Assisted Grading Tool for Introductory Programming Assignments},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705051},
doi = {10.1145/3641555.3705051},
abstract = {In introductory programming courses, autograders typically evaluate student programs by running testcases without inspecting the source code. However, educational grading often requires manual code inspection for two key reasons: (1) to award partial marks for code that may fail test cases but is partially correct, and (2) to assign marks based on code quality or specific criteria set by the instructor, such as requiring a particular algorithm, e.g., bubble sort. Rubric-based subjective grading is beneficial for these reasons, but manual grading for large course enrollments is time consuming. This demo introduces TA Buddy, an AI assistant integrated with IIT Bombay's BodhiTree Evalpro platform, which is designed to streamline grading in introductory programming courses. It is powered by a pre-trained code LLM, which was fine-tuned with a dataset created here at IITB Bombay. Its key benefits include speeding up the grading process with AI-generated suggestions for ratings of the criteria of a grading rubric. Furthermore, it provides feedback with justifications for assigned grades, making it useful for large courses where manual grading is time-consuming. Note that TA-Buddy only suggests grades to TAs, TAs are still required to review the grades and accept or reject them. In that sense, TA-Buddy offers an AI-Assisted grading option to TAs. This hybrid approach reduces grading time by up to 45% while maintaining an average match of 90% (on a sample of six problems) with un-assisted manual grades.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1736},
numpages = {1},
keywords = {ai-assisted grading, cs education, llms, programming assignments, rubric, source code evaluation},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3678726.3678733,
author = {Takeuchi, Miki and Ito, Akinori and Nose, Takashi},
title = {Selection of key sentences from lecture video transcription and its application to feedback to the learner},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678733},
doi = {10.1145/3678726.3678733},
abstract = {The COVID-19 pandemic accelerated the shift to online university lectures. Real-time online lectures offer live interaction, while on-demand video lectures such as MOOCs allow flexibility; however, on-demand video lectures face low student concentration and engagement challenges. Thus, our project aims to develop an interactive agent for on-demand videos, improving student motivation. As a building block of such a system, we develop a method to estimate key sentences from lecture speech. We compared two text summarization methods, the BERTSUM and GPT-based summarization, to select the key sentences. As a result, a combination of GPT-based summarization and BERT-based text selection gave the best results. Moreover, we developed a system that indicates the estimated key sentences to the learners and conducted a subjective evaluation of the system.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {218–223},
numpages = {6},
keywords = {MOOC, Online learning, text summarization},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3706599.3719742,
author = {Li, Jinqiao and Neshaei, Seyed Parsa and M\"{u}ller, Livia and Rietsche, Roman and Davis, Richard Lee and Wambsganss, Thiemo},
title = {SpatiaLearn: Exploring XR Learning Environments for Reflective Writing},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719742},
doi = {10.1145/3706599.3719742},
abstract = {Reflective writing promotes deeper learning by enhancing metacognitive awareness and critical thinking, but learners often struggle with structuring their reflections and maintaining focus. Generative AI and advances in spatial computing offer promising solutions. Extended reality (XR) environments create immersive, distraction-free settings, while conversational agents use dialog-based scaffolding guides to structure learners’ thoughts. However, research on combining dialog-based scaffolding with XR for reflective writing remains limited. To address this, we introduce SpatiaLearn, an adaptive XR tool that enhances reflective writing through conversational guidance in both traditional and immersive environments. A within-subjects study (N = 19) compared participants’ performance in traditional laptop and XR environments. Qualitative analysis shows the spatial interface enhances engagement but raises challenges like unfamiliar interactions and health concerns, requiring task adaptation for XR. This study advances the design of immersive tools for reflective writing, highlighting both the opportunities and challenges of spatial interfaces.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {491},
numpages = {11},
keywords = {Extended Reality (XR), Spatial Computing, Adaptive Education, Conversational Tutoring},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3702163.3702179,
author = {Mohd A'seri, Muhamad Safwan and Mahmud, Malissa Maria and Yaacob, Yazilimiwati and Ahmad, Rozaini and Nagasundram, Usha and Mustamam, Nur Izzati},
title = {Beyond the Textbook: A Study of ChatGPT Patterns of Use Perceptions and Experiences Among Students in Higher Education},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702179},
doi = {10.1145/3702163.3702179},
abstract = {This study investigates the utilization pattern, perception, and experience of Higher Education Institutes (HEIs) students towards the ChatGPT application in an academic context. It employs a quantitative approach utilizing a questionnaire as the research instrument. The study sample was selected using a simple random sampling method from Sunway University and Sunway College in Kuala Lumpur, Malaysia. The survey participants, enrolled in General Studies Subjects (MPU) during their short semester between September and December 2023, were selected using a simple random sampling method. Out of 150 students who received the survey via Google Forms, 119 provided complete responses suitable for analysis. The research primarily focused on calculating mean scores to assess three key dimensions: its use patterns of ChatGPT, perceptions and experiences among students towards its adoption in educational contexts. A descriptive analysis was conducted to determine student frequency and percentage values for ChatGPT usage. At the same time, mean scores were utilized to evaluate higher education institutes (HEIs) students' perceptions and experiences with the application in an academic context. This descriptive analysis revealed a spectrum of responses that ranged from low to very high levels across these dimensions. The findings of this study offer extensive insight into the current incorporation and perception of ChatGPT within Higher Education Institutions (HEIs), showcasing the diverse range of engagement and acceptance levels among students.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {110–116},
numpages = {7},
keywords = {ChatGPT, Experiences, Higher education institutions, Perceptions, Use patterns},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3699538.3699580,
author = {Kiesler, Natalie and Scholz, Ingo and Albrecht, Jens and Stappert, Friedhelm and Wienkop, Uwe},
title = {Novice Learners of Programming and Generative AI - Prior Knowledge Matters},
year = {2024},
isbn = {9798400710384},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3699538.3699580},
doi = {10.1145/3699538.3699580},
abstract = {With the broad availability of Generative AI (GenAI), introductory programming education is starting to change. At Nuremberg Tech, we observed the doubling of failure rates to approximately 50% in the first semester course “Procedural Programming” across students of all study programs. Due to these exam results in winter 2023/24, we conducted a pilot study to gather students’ use of GenAI tools, their exam results, and prior programming education and experience. The results imply significant differences of students’ use of GenAI tools depending on their prior programming education. We will therefore extend the investigation in winter term 2024/25.},
booktitle = {Proceedings of the 24th Koli Calling International Conference on Computing Education Research},
articleno = {51},
numpages = {2},
keywords = {GenAI, student success, programming education, introductory programming, use pattern},
location = {
},
series = {Koli Calling '24}
}

@inproceedings{10.1145/3689535.3689553,
author = {Stone, Irene},
title = {Exploring Human-Centered Approaches in Generative AI and Introductory Programming Research: A Scoping Review},
year = {2024},
isbn = {9798400711770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689535.3689553},
doi = {10.1145/3689535.3689553},
abstract = {Recent advancements in generative artificial intelligence are poised to reshape introductory programming education, challenging conventional teaching methodologies. This paper presents a scoping review that explores the current understanding of integrating generative artificial intelligence tools in the learning of introductory programming. Through an analysis of 28 selected studies, this review provides a snapshot of the landscape in mid-2024, presenting benefits, concerns, and recommendations surrounding the use of generative artificial intelligence within programming education. It finds insufficient guidance on how to implement recommended pedagogical strategies, limited consideration of student perceptions and experiences, and a predominance of short study time frames. Additionally, there is a significant research gap in second-level education, particularly in the United Kingdom and Ireland. The paper discusses how these gaps signal a need for more human-centered approaches in the current research. The paper concludes with recommendations for future research, aiming to inspire further inquiry and advance the understanding of generative artificial intelligence’s role in programming education from a human-centered perspective.},
booktitle = {Proceedings of the 2024 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {4},
numpages = {7},
keywords = {AI, CS1, ChatGPT, LLMs, artificial intelligence, code generation, generative AI, human-centered, learner perspectives, novice programming, pedagogical practices, programming, python, student-centered},
location = {Manchester, United Kingdom},
series = {UKICER '24}
}

@inproceedings{10.1145/3649217.3653596,
author = {Apiola, Mikko and Vartiainen, Henriikka and Tedre, Matti},
title = {First Year CS Students Exploring And Identifying Biases and Social Injustices in Text-to-Image Generative AI},
year = {2024},
isbn = {9798400706004},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649217.3653596},
doi = {10.1145/3649217.3653596},
abstract = {Generative AI is a recent breakthrough in AI. While it has become a hot topic in computing education research (CER), much of the recent research has focused on e.g. issues of plagiarism or academic integrity. One problem spot with Generative AI is its susceptibility to various kinds of algorithmic bias. In this study, we collected data from an introductory computing course, where students experimented with text-to-image generative models and reflected on their generated image sets, in terms of biases, related harms, and possible fixes. Data were collected in Fall 2023 (pilot data in Fall 2022). Data included reports from 163 students. The results show (1) a variety of bias types observed by students related to gender, ethnicity, age, as well as a variety of bias types not observed by students, (2) two major types of attributions for the source of bias: bias caused by biases in the society and bias caused by data or algorithms, and (3) a number of potential harms associated with the biases, as well as attributions of those harms in specific contexts and use cases.},
booktitle = {Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 1},
pages = {485–491},
numpages = {7},
keywords = {bias, critical computing education, generative ai, social injustice},
location = {Milan, Italy},
series = {ITiCSE 2024}
}

@inproceedings{10.1145/3527927.3532801,
author = {Jonsson, Martin and Tholander, Jakob},
title = {Cracking the code: Co-coding with AI in creative programming education},
year = {2022},
isbn = {9781450393270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527927.3532801},
doi = {10.1145/3527927.3532801},
abstract = {This paper presents a study of a group of university students using generative machine learning to translate from natural language to computer code. The study explores how the use of the AI tool can be understood in terms of co-creation, focusing on the one hand on how the tool may serve as a resource for understanding and learning, and on the other hand how the tool affects the creative processes. Findings show how the participants search for a ’correct’ syntax in their instructions to the machine learning tool, and how the inconsistent and erroneous behavior can work as a way to generate clues and inspiration for generating creative expressions. The notion of friction is used to describe how systems like this can serve to both lower thresholds for programming, and also interfere with the creative processes, encouraging reflection and exploration of alternative solutions.},
booktitle = {Proceedings of the 14th Conference on Creativity and Cognition},
pages = {5–14},
numpages = {10},
keywords = {programming, post-human design, generative machine learning, co-creation, GPT-3},
location = {Venice, Italy},
series = {C&amp;C '22}
}

@article{10.1145/3637208,
author = {Edwards, Chris},
title = {Teaching Transformed},
year = {2024},
issue_date = {February 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {67},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/3637208},
doi = {10.1145/3637208},
abstract = {The apparent ability of LLMs to write functioning source code has caused celebration over the potential for massive increases in programmer productivity and consternation among teachers.},
journal = {Commun. ACM},
month = jan,
pages = {12–13},
numpages = {2}
}

@inproceedings{10.1145/3610977.3634950,
author = {Williams, Randi and Ali, Safinah and Alcantara, Ra\'{u}l and Burghleh, Tasneem and Alghowinem, Sharifa and Breazeal, Cynthia},
title = {Doodlebot: An Educational Robot for Creativity and AI Literacy},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634950},
doi = {10.1145/3610977.3634950},
abstract = {Today, Artificial Intelligence (AI) is prevalent in everyday life, with emerging technologies like AI companions, autonomous vehicles, and AI art tools poised to significantly transform the future. The development of AI curricula that shows people how AI works and what they can do with it is a powerful way to prepare everyone, and especially young learners, for an increasingly AI-driven world. Educators often employ robotic toolkits in the classroom to boost engagement and learning. However, these platforms are generally unsuitable for young learners and learners without programming expertise. Moreover, these platforms often serve as either programmable artifacts or pedagogical agents, rarely capitalizing on the opportunity to support students in both capacities. We designed Doodlebot, a mobile social robot for hands-on AI education to address these gaps. Doodlebot is an effective tool for exploring AI with grade school (K-12) students, promoting their understanding of AI concepts such as perception, representation, reasoning and generation. We begin by elaborating Doodlebot's design, highlighting its reliability, user-friendliness, and versatility. Then, we demonstrate Doodlebot's versatility through example curricula about AI character design, autonomous robotics, and generative AI accessible to young learners. Finally, we share the results of a preliminary user study with elementary school youth where we found that the physical Doodlebot platform was as effective and user-friendly as the virtual version. This work offers insights into designing interactive educational robots that can inform future AI curricula and tools.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {772–780},
numpages = {9},
keywords = {collaboration, creativity, education, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3649165.3690094,
author = {Ma, Iris and Krone-Martins, Alberto and Videira Lopes, Cristina},
title = {Integrating AI Tutors in a Programming Course},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649165.3690094},
doi = {10.1145/3649165.3690094},
abstract = {RAGMan is an LLM-powered tutoring system that can support a variety of course-specific and homework-specific AI tutors. RAGMan leverages Retrieval Augmented Generation (RAG), as well as strict instructions, to ensure the alignment of the AI tutors' responses. By using RAGMan's AI tutors, students receive assistance with their specific homework assignments without directly obtaining solutions, while also having the ability to ask general programming-related questions.  RAGMan was deployed as an optional resource in an introductory programming course with an enrollment of 455 students. It was configured as a set of five homework-specific AI tutors. This paper describes the interactions the students had with the AI tutors, the students' feedback, and a comparative grade analysis. Overall, about half of the students engaged with the AI tutors, and the vast majority of the interactions were legitimate homework questions. When students posed questions within the intended scope, the AI tutors delivered accurate responses 98% of the time. Among the students who used AI tutors, 78% reported that the tutors helped their learning. Beyond AI tutors' ability to provide valuable suggestions, students reported appreciating them for fostering a safe learning environment free from judgment.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
pages = {130–136},
numpages = {7},
keywords = {education, large language models, llms, software engineering},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@inproceedings{10.1145/3702163.3702165,
author = {Gong, Rushi and Jiang, Rui and Guo, Chuanlei and Hu, Wanqing and Li, Yanyan},
title = {Roles emerging during the knowledge construction process in collaborative learning: Does a generative AI-support chatbot matter?},
year = {2025},
isbn = {9798400717819},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702163.3702165},
doi = {10.1145/3702163.3702165},
abstract = {Students’ emerging roles in computer supported collaborative learning (CSCL) are crucial in revealing what learning characteristics and states students present during their collaborative knowledge construction. Previous researchers have unveiled the fact that pedagogical scaffoldings such as AI chatbots play a pivotal role in students’ role emerging, but with the prevalence of generative AI (GAI), there is also an urgent need to investigate whether GAI chatbots influence students’ emerging roles during the knowledge construction process in collaborative learning. Therefore, this study conducted a quasi-experiment, using an integration of cluster analysis, chi-square test, case analysis, and content analysis to investigate whether and how a GAI chatbot affected students’ emerging roles in their online collaborative knowledge construction. Results demonstrated statistical significance that the GAI chatbot and the traditional static scripts did not have a distinct difference in students’ emerging roles. However, qualitative data showed that the GAI chatbot had an impact on the allocation of roles and that there were perceptual differences in how students with the same roles experienced the writing process and collaborative atmosphere under different support conditions. The study will provide insights into how GAI chatbots can be adapted for future development and application in a collaborative learning context with consideration of students’ roles.},
booktitle = {Proceedings of the 2024 16th International Conference on Education Technology and Computers},
pages = {8–16},
numpages = {9},
keywords = {Computer Supported Collaborative Learning, Generative AI Chatbot, Knowledge Construction, Students’ Roles},
location = {
},
series = {ICETC '24}
}

@inproceedings{10.1145/3626253.3635595,
author = {Hamerski, Patti C.},
title = {Generative AI as a Resource for Creativity in Computational Physics},
year = {2024},
isbn = {9798400704246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626253.3635595},
doi = {10.1145/3626253.3635595},
abstract = {Generative artificial intelligence (gen-AI) has become ubiquitous in daily life, including classroom environments where students are using it to assist them on their coursework. Given the widespread use of this tool and the lack of knowledge over how it can support learning, there is a need for educators to have a framework for using it in the classroom and teaching their students usage strategies that are beneficial for learning. One pathway forward is through creativity, a process crucial for learning and also connected to the act of using gen-AI. This poster demonstrates the results of a study designed to provide an in-depth view on how creativity intersects with gen-AI usage in a computational physics course. In the course, students learn about computing tools during group-based, open-ended computational physics activities. Students are often tasked with using gen-AI to explore and help make decisions. The findings demonstrate a connection between using gen-AI and engaging in creative processes, and the implications point to strategies for supporting student usage of gen-AI.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1666–1667},
numpages = {2},
keywords = {computational science, creativity, curriculum design, generative ai},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3576882.3617916,
author = {Agarwal, Nimisha and Kumar, Viraj and Raman, Arun and Karkare, Amey},
title = {A Bug's New Life: Creating Refute Questions from Filtered CS1 Student Code Snapshots},
year = {2023},
isbn = {9798400700484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576882.3617916},
doi = {10.1145/3576882.3617916},
abstract = {In an introductory programming (CS1) context, a Refute question asks students for a counter-example which proves that a given code fragment is an incorrect solution for a given task. Such a question can be used as an assessment item to (formatively) develop or (summatively) demonstrate a student's abilities to comprehend the task and the code well enough to recognize a mismatch. These abilities assume greater significance with the emergence of generative AI technologies capable of writing code that is plausible (at least to novice programmers) but not always correct.Instructors must address three concerns while designing an effective Refute question, each influenced by their specific teaching-learning context: (1) Is the task comprehensible? (2) Is the incorrect code a plausible solution for the task? (3) Is the complexity of finding a counter-example acceptable? While the first concern can often be addressed by reusing tasks from previous code writing questions, addressing the latter concerns may require substantial instructor effort. We therefore investigate whether concerns (2) and (3) can be addressed by buggy student solutions for the corresponding code writing question from a previous course offering. For 6 code writing questions (from a Fall 2015 C programming course), our automated evaluation system logged 13,847 snapshots of executable student code, of which 10,574 were buggy (i.e., they failed at least one instructor-supplied test case). Code selected randomly from this pool rarely addresses these concerns, and manual selection is infeasible. Our paper makes three contributions. First, we propose an automated mechanism to filter this pool to a more manageable number of snapshots from which appropriate code can be selected manually. Second, we evaluate our semi-automated mechanism with respect to concerns (2) and (3) by surveying a diverse set of 56 experienced participants (instructors, tutors, and teaching assistants). Third, we use this mechanism to seed a public repository of Refute questions and provide a template to create additional questions using a public resource (CodeCheck).},
booktitle = {Proceedings of the ACM Conference on Global Computing Education Vol 1},
pages = {7–14},
numpages = {8},
keywords = {CS1, assessment, refute questions},
location = {Hyderabad, India},
series = {CompEd 2023}
}

@inproceedings{10.1145/3626252.3630761,
author = {Mason, Raina and Simon and Becker, Brett A. and Crick, Tom and Davenport, James H.},
title = {A Global Survey of Introductory Programming Courses},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630761},
doi = {10.1145/3626252.3630761},
abstract = {We present results of an in-depth survey of nearly 100 introductory programming (CS1) instructors in 18 countries spanning six continents. Although CS1 is well studied, relatively few broadly-scoped studies have been conducted, and none prior have exceeded regional scale. In addition, CS1 is a notoriously fickle and often changing course, and many might find it beneficial to know what other instructors are doing across the globe; perhaps more so as we continue to understand the impact of the COVID-19 pandemic on computing education and as the effects of Generative AI take hold. Expanding upon several surveys conducted in Australasia, the UK, and Ireland, this survey facilitates a direct comparison of global trends in CS1. The survey goes beyond environmental factors such as languages used, and examines why CS1 instructors teach what they do, in the ways they do. In total the survey spans 84 institutions and 91 courses in which a total of over 40,000 students are enrolled.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {799–805},
numpages = {7},
keywords = {covid-19, cs 1, cs-1, cs1, global, instructors, introductory programming, novice programmers, programming languages, survey, teaching languages},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3677045.3685439,
author = {R\"{o}nnberg, Niklas and B\"{o}r\"{u}tecene, Ahmet},
title = {Use of Generative AI for Fictional Field Studies in Design Courses},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677045.3685439},
doi = {10.1145/3677045.3685439},
abstract = {In this paper, we present how we used generative AI (GenAI) as a pedagogical tool for students taking a course in tangible interaction design. In this course, the students design different physical-digital objects (PDOs) to learn designing, sketching and prototyping with code and hardware. However, due to the short course duration these PDOs are not evaluated or explored with any kind of field or user study. Therefore we gave the students the exercise of doing user interviews with GenAI to explore their design ideas further. With this paper, we contribute a description and the outcomes of this approach, and highlight the pedagogical implications for student learning.},
booktitle = {Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
articleno = {23},
numpages = {5},
keywords = {Design, Education, Field study, Generative AI, User interview},
location = {Uppsala, Sweden},
series = {NordiCHI '24 Adjunct}
}

@inproceedings{10.1145/3643834.3661581,
author = {Chen, Qiaoyi and Liu, Siyu and Huang, Kaihui and Wang, Xingbo and Ma, Xiaojuan and Zhu, Junkai and Peng, Zhenhui},
title = {RetAssist: Facilitating Vocabulary Learners with Generative Images in Story Retelling Practices},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661581},
doi = {10.1145/3643834.3661581},
abstract = {Reading and repeatedly retelling a short story is a common and effective approach to learning the meanings and usages of target words. However, learners often struggle with comprehending, recalling, and retelling the story contexts of these target words. Inspired by the Cognitive Theory of Multimedia Learning, we propose a computational workflow to generate relevant images paired with stories. Based on the workflow, we work with learners and teachers to iteratively design an interactive vocabulary learning system named RetAssist. It can generate sentence-level images of a story to facilitate the understanding and recall of the target words in the story retelling practices. Our within-subjects study (N=24) shows that compared to a baseline system without generative images, RetAssist significantly improves learners’ fluency in expressing with target words. Participants also feel that RetAssist eases their learning workload and is more useful. We discuss insights into leveraging text-to-image generative models to support learning tasks.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2019–2036},
numpages = {18},
keywords = {Vocabulary learning, image generation, story retelling},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3640771.3640783,
author = {Chen, Shuo and Zhang, Juan},
title = {CLIP-M-Cap: CLIP Mean Teacher for Image Captioning},
year = {2024},
isbn = {9798400708954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640771.3640783},
doi = {10.1145/3640771.3640783},
abstract = {Abstract. Image description plays a pivotal role in the realm of computer vision language tasks, as its core mission revolves around predicting relevant textual information given an input image. In this research paper, we introduce an innovative model (Clip-M-cap) to tackle this challenge. Drawing inspiration from the Mean Teacher approach, we present a fresh network architecture that comprises two branches. One of these branches acts as a reference for the other, providing essential support during training. In the image feature extraction phase of our model, we harness CLIP to extract distinctive image features. In the subsequent caption generation stage, we enlist the assistance of GPT-2 to enhance the accuracy of caption generation. During the training phase, we meticulously train our model on two distinct datasets, MS-COCO and Flickr30k. Subsequently, we rigorously evaluate the performance of our trained model across three domains: MS-COCO, Flickr30k, and Cross-Domain, consistently achieving outstanding results in all three scenarios.},
booktitle = {Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence},
pages = {50–55},
numpages = {6},
keywords = {CLIP, Flickr30K, Image captioning, MS-COCO, Mean teacher},
location = {Shanghai, China},
series = {ISCAI '23}
}

@inproceedings{10.1145/3641555.3705241,
author = {Jindal, Vasu},
title = {SAFARI-P: Swahili-Focused Adaptive Framework for Accelerated Reinforcement in Intelligent Python Education},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705241},
doi = {10.1145/3641555.3705241},
abstract = {This paper introduces SAFARI-P (Swahili-Focused Adaptive Framework for Accelerated Reinforcement in Intelligent Python Education), an innovative system that integrates Generative Adversarial Networks (GANs) and a Multi-Dimensional Learning Confidence (MDLC) system for Python programming education in Swahili. The framework comprises three key components: (1) an Adversarial Code Generation System (ACGS) for creating culturally relevant code snippets, (2) an MDLC Assessment Module that uses a tripartite confidence matrix system to evaluate concept understanding, problem-solving patterns, and code quality, and (3) a Cultural Context Integration Engine for incorporating local elements. By simultaneously tracking technical proficiency and cultural understanding through confidence matrices, SAFARI-P provides personalized learning paths that ensure students build strong foundational knowledge while maintaining cultural relevance. In a 16-week study conducted across Kenya, Tanzania, and Uganda, this mathematically rigorous approach to confidence tracking led to significant improvements: a 27% increase in Python proficiency (p &lt; 0.001) and a 32.6% improvement in problem-solving efficiency (p &lt; 0.001).},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1499–1500},
numpages = {2},
keywords = {adaptive learning, ai in education, cultural computing, culturally relevant computing, generative adversarial networks},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3605468.3609775,
author = {Philbin, Carrie Anne},
title = {Impact of Generative AI on K-12 Students’ Perceptions of Computing: A Research Proposal},
year = {2023},
isbn = {9798400708510},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605468.3609775},
doi = {10.1145/3605468.3609775},
abstract = {The rapid progress of generative artificial intelligence (AI) is fundamentally reshaping traditional perspectives on knowledge and skills, with profound implications for computing education. This necessitates a thorough examination of the relevance and timeliness of computing as a subject, especially for K-12 students who are making critical decisions about their future qualifications. This abstract proposes an empirical research study that aims to explore the effects of integrating generative AI in the creation of digital artefacts on K-12 students’ perceptions of the value of computing, as well as their understanding of ownership and achievement. Constructive discussions regarding the outlined approach are encouraged.},
booktitle = {Proceedings of the 18th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {28},
numpages = {2},
keywords = {Artificial Intelligence education, Creative computing, Generative AI, K-12 education, Student perceptions},
location = {Cambridge, United Kingdom},
series = {WiPSCE '23}
}

@inproceedings{10.1145/3613905.3647966,
author = {Lim, Jullia},
title = {The Potential of Learning With AI-Generated Pedagogical Agents in Instructional Videos},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3647966},
doi = {10.1145/3613905.3647966},
abstract = {With the recent advancement in technology, generative artificial intelligence (GenAI) can produce hyper-realistic multimedia content, such as audio, text, images, and videos. Although this technology has raised great concerns about its misuse and harmful applications, it holds great potential to revolutionize traditional ways of teaching and learning. The use of GenAI in education has increased markedly, however, pedagogical research on this rapidly emerging technology is yet to be studied extensively. There is an urgent need to investigate the unexamined potential of this technology. Therefore, this ongoing research will explore the potential of AI-generated pedagogical agents (PA), or avatars, in instructional videos to facilitate learning. The effects of the type of PA (AI-generated, real-life human), and voice (AI-generated, human voice) on an individual's learning outcomes, cognitive load, motivation, and attention will be studied. Findings from a pilot study provide some preliminary evidence that PA appearance influences learners’ retention and cognitive load, but not attention. The type of PA influenced learners' perception of the agent's ability to facilitate learning, its human-like qualities, and its engagement level. However, it did not affect its credibility. This ongoing work will contribute to the growing understanding of the impact of AI in education, provide evidence of the efficacy of AI-generated PAs in instructional videos for learning, and narrow the gap between human-computer interaction research and education.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {615},
numpages = {6},
keywords = {avatars, multimedia learning, pedagogical agents, videos},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3627673.3679930,
author = {Young, Oliver and Fan, Yixing and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Cheng, Xueqi},
title = {GaQR: An Efficient Generation-augmented Question Rewriter},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679930},
doi = {10.1145/3627673.3679930},
abstract = {Query understanding is an essential part in search systems to improve the recall. Unlike prior works focusing on word expansions, in this paper, we leverage the comprehension ability of LLM to generate detailed queries from a global semantic perspective. To this end, we introduce an efficient GaQR to reformulate a question into several queries using Chain of Thought (CoT) and make it more efficient through knowledge distillation. Specifically, we first prompt a teacher model to generate indicative queries by considering answer generation one step ahead. Then, we filter out low-quality queries by validating the effectiveness of all generated queries in retrieving useful passages. Finally, we distill a student rewriter based on the verified results to improve efficiency. Our experimental results demonstrate that the rewriter improves the retrieval performance by 3% to 15% on the Miracl and NFCorpus datasets and shows good generalisation ability across different retrieval methods. Moreover, the efficiency of the rewriter after knowledge distillation is improved by as much as 5 times. Code is available at https://github.com/youngbeauty250/GaQR.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4228–4232},
numpages = {5},
keywords = {generation-augmented retrieval, knowledge distillation, question rewriting},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3677619.3678114,
author = {Marx, Erik and Witt, Clemens and Leonhardt, Thiemo},
title = {Identifying Secondary School Students' Misconceptions about Machine Learning: An Interview Study},
year = {2024},
isbn = {9798400710056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677619.3678114},
doi = {10.1145/3677619.3678114},
abstract = {Since students are familiar with machine learning (ML)-based applications in their everyday lives, they already construct mental models of how these systems work. This can result in misconceptions that influence the learning of correct ML concepts. Therefore, this study investigates the misconceptions students hold about the functionality of ML-based applications. To this end, we conducted semi-structured interviews with five students, focusing on their understanding of facial recognition and ChatGPT. The interviews were analyzed using an inductively developed code system and qualitative content analysis. This process identified six key misconceptions held by students: “Programmed Behavior,” “Exactness,” “Data Storage,” “Continuous Learning,” “User-trained Model,” and “Autonomous Data Acquisition”. These misconceptions include the notion that AI learns continuously during application, or that training data is saved and reused later. This paper presents the identified misconceptions and discusses their implication for the design and evaluation of effective learning activities in the context of ML.},
booktitle = {Proceedings of the 19th WiPSCE Conference on Primary and Secondary Computing Education Research},
articleno = {6},
numpages = {10},
keywords = {artificial intelligence, interview study, machine learning, mental models, misconceptions, qualitative research, students conceptions},
location = {Munich, Germany},
series = {WiPSCE '24}
}

@inproceedings{10.1145/3610969.3610973,
author = {Addo, Salomey Afua},
title = {Are You Ready to Teach AI in Schools? Teachers' Perspectives of Teaching AI in K-12 Settings},
year = {2023},
isbn = {9798400708763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610969.3610973},
doi = {10.1145/3610969.3610973},
abstract = {Artificial intelligence (AI) has continually made headlines, even more so with the mass interest in generative AI. The implications of AI on society raises the need for its inclusion in the K-12 computing curriculum. However, little research has been conducted to understand teachers’ preparedness to teach AI concepts in K-12. This exploratory study seeks to understand teachers’ motivation and preparedness to teach AI in schools through the lens of Self Efficacy Theory (SET) and Self Determination Theory (SDT).},
booktitle = {Proceedings of the 2023 Conference on United Kingdom &amp; Ireland Computing Education Research},
articleno = {32},
numpages = {1},
keywords = {motivation, K-12 computing education, Artificial intelligence},
location = {Swansea, Wales Uk},
series = {UKICER '23}
}

@proceedings{10.1145/3689491,
title = {SPLASH Companion '24: Companion Proceedings of the 2024 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity},
year = {2024},
isbn = {9798400712142},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is my great pleasure to welcome you to the 39th ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, being held in the vibrant city of Pasadena, California, from October 20th to October 25th, 2024. Nestled in beautiful southern California, Pasadena offers a unique blend of innovation, culture, and charm, providing the perfect backdrop for this year’s SPLASH conference.SPLASH 2024 continues to be a premier forum for discussing all aspects of software development. This year’s program is as diverse and dynamic as ever, featuring the OOPSLA conference, Onward! Papers and Onward! Essays, SPLASH-E, and our popular student-focused events including the Doctoral Symposium, Student Research Competition, and Programming Language Mentoring Workshop. We are also excited to host a revival of REBASE, a day of talks and discussion to connect industry and academia. Additionally, attendees will have the opportunity to engage with an exciting collection of co-hosted conferences, the Static Analysis Symposium (SAS), International Conference on Generative Programming: Concepts &amp; Experiences (GPCE), and Software Language Engineering (SLE). SPLASH 2024 is also proud to host ten exciting workshops: HATRA, IWACO, JENSFEST, LIVE, NSAD, PAINT, ProLaLa, UNSOUND, VIVEKFEST, and VMIL.},
location = {Pasadena, CA, USA}
}

@inproceedings{10.1145/3545947.3576354,
author = {Blouin, Sophie and Solomon, Bridget and Crane, Brent and Dempsey, David and Siegel, Angela and Poitras, Eric},
title = {The Role of Sketching in Facilitating Problem Solving in Introductory Programming},
year = {2023},
isbn = {9781450394338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545947.3576354},
doi = {10.1145/3545947.3576354},
abstract = {This study examined the effectiveness of sketching flow diagrams in facilitating CS1 students' problem solving and performance on code writing tasks. Five students received training in design strategies and sketched flow diagrams prior to implementing their solution by writing code. Procedures in solving a sequence of four problems depicted in sketches and captured in keystroke log data were coded and scored for each student. The study results showed that specific and generative depictions of procedures predict the correctness of edits made to solutions.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1411},
numpages = {1},
keywords = {introductory programming, sketching, strategic programming knowledge},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@inproceedings{10.1145/3649409.3691073,
author = {Barendsen, Erik and Lonati, Violetta and Quille, Keith and Altin, Rukiye and Divitini, Monica and Hooshangi, Sara and Karnalim, Oscar and Kiesler, Natalie and Melton, Madison and Suero Montero, Calkin and Morpurgo, Anna},
title = {AI in and for K-12 Informatics Education. Life after Generative AI.},
year = {2024},
isbn = {9798400706042},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649409.3691073},
doi = {10.1145/3649409.3691073},
abstract = {The use and adoption of Generative AI (GenAI) has revolutionised various sectors, including computing education. However, this narrow focus comes at a cost to the wider AI in and for educational research. This working group aims to explore current trends and explore multiple sources of information to identify areas of AI research in K-12 informatics education that are being underserved but needed in the post-GenAI AI era. Our research focuses on three areas: curriculum, teacher-professional learning and policy. The denouement of this aims to identify trends and shortfalls for AI in and for K-12 informatics education. We will systematically review the current literature to identify themes and emerging trends in AI education at K-12. This will be done under two facets, curricula and teacher-professional learning. In addition, we will conduct interviews and surveys with educators and AI experts. Next, we will examine the current policy (such as the European AI Act, and European Commission guidelines on the use of AI and data in education and training as well as international counterparts). Policies are often developed by both educators and experts in the domain, thus providing a source of topics or areas that may be added to our findings. Finally, by synthesising insights from educators, AI experts, and policymakers, as well as the literature and policy, our working group seeks to highlight possible future trends and shortfalls.},
booktitle = {Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 2},
pages = {279–280},
numpages = {2},
keywords = {AI, GenAI, K-12, curricula, generative AI, informatics},
location = {Virtual Event, NC, USA},
series = {SIGCSE Virtual 2024}
}

@article{10.1145/3592367.3617935,
author = {Hines, Jasara},
title = {Review of "Writing in the Clouds: Inventing and Composing in Internetworked Writing Spaces by John Logie," Logie, J. (2021). Writing in the clouds: Inventing and composing in internetworked writing spaces. Parlor Press.},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {11},
number = {3},
url = {https://doi.org/10.1145/3592367.3617935},
doi = {10.1145/3592367.3617935},
abstract = {In the wake of the controversy surrounding the new AI chatbot application, ChatGPT, I wonder how Logie would seek to include this new technology in his work. I ponder this because, throughout the book, Logie presents compelling evidence for why the concepts of invention, composition, and internetworked writing should be embraced and not feared. While some denounce the application and take to social media to disparage the possible negative impact on students, creativity, and composition, ChatGPT, I believe Logie would argue, would be a powerful tool we can implement to become "composers." He believes that through cloud computing services we are now more apt to collaborate, use, remix, and create rhetorical modes that extend far beyond the formulaic argument, therefore we are composers. So, Logie applies the idea of a composer as someone who is a "prosumer" (Toffler). This composer is media literate and transforms traditional rhetorical canons into multimodal compositions such as memes, Google Docs, and digital collages. However, his overarching argument is that internetworked writing tools have democratized writing through that same offering of innovative outlets. His book is arranged in a way that walks the reader through this argument.},
journal = {Commun. Des. Q. Rev},
month = dec,
pages = {80–81},
numpages = {2}
}

@inproceedings{10.1145/3536169.3537785,
author = {Sosa, Ricardo and Gibbons, Andrew and O'Riordan, Emma and Iorangi, Keu and Crowe, Andy and Gibson, Leanne and Harris, Sam and Badenhorst, Daniel},
title = {Food for Advanced Computational Thinking: Critical and Creative Approaches to Technology at Te Kura Taurua Manurewa},
year = {2022},
isbn = {9781450393881},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3536169.3537785},
doi = {10.1145/3536169.3537785},
abstract = {This paper focuses on a participatory activity that is part of an ongoing partnership formed six years ago between teachers and academics to study creative technology approaches to youth participation. By focusing on a food-based activity in an after-school maker space, we reflect on the pedagogical and methodological innovations, and the ethical and aesthetic qualities of food-based activities for participatory design. The session brought together students and teachers to form a generative dialogue around computation and automation while preparing and sharing food. The results suggest opportunities to rethink current curricular, pedagogical, and education policy strategies. Recommendations for organizers to prepare generative activities where food is used as a design material close the paper.},
booktitle = {Proceedings of the Participatory Design Conference 2022 - Volume 1},
pages = {109–119},
numpages = {11},
location = {Newcastle upon Tyne, United Kingdom},
series = {PDC '22}
}

@inproceedings{10.1145/3593663.3593692,
author = {Jell, Lea and List, Corinna and Kipp, Michael},
title = {Towards Automated Interactive Tutoring - Focussing on Misconceptions and Adaptive Level-Specific Feedback},
year = {2023},
isbn = {9781450399562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593663.3593692},
doi = {10.1145/3593663.3593692},
abstract = {Programming is an essential cross-disciplinary skill, yet teaching it effectively in large classes can be challenging due to the need for close feedback loops. Identifying and addressing common misconceptions is particularly important during the initial stages of learning to program. While automated interactive tutoring systems have the potential to offer personalized tutoring at scale, current systems tend to emphasize errors and predefined solutions rather than focusing on common misconceptions. In this study, we introduce a novel platform centered on addressing misconceptions in programming education. We describe methods for detecting misconceptions using Abstract Syntax Trees (AST) and providing tailored, level-specific feedback to emulate human-like tutoring. As an empirical basis for this project, we gathered data from various introductory programming courses. Additionally, we advocate for the establishment of a repository of common misconceptions, offering examples derived from both the literature and our own data. Investigating misconceptions can ultimately enhance the teaching strategies of both human educators and AI agents, such as GPT, in guiding learners effectively.},
booktitle = {Proceedings of the 5th European Conference on Software Engineering Education},
pages = {226–235},
numpages = {10},
keywords = {programming misconceptions, intelligent tutoring, CS in higher education},
location = {Seeon/Bavaria, Germany},
series = {ECSEE '23}
}

@inproceedings{10.1145/3641555.3705242,
author = {Caraco, Serena and Fabros, Melissa and Lojo, Nelson and Fox, Armando},
title = {Scaffolding Collaborative Software Design with Serious Games},
year = {2025},
isbn = {9798400705328},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641555.3705242},
doi = {10.1145/3641555.3705242},
abstract = {An application's architecture is frequently refactored after deployment to accommodate its users' evolving needs. However, we currently lack a repeatable, consistent method to teach high-level collaborative design skills. Drawing on the serious play framework, we advance an existing analog exercise for scaffolding collaborative design using a new system: the LLM-managed application overview. From an instructor prompt, the system generates an overview detailing an entire application using CRC cards -- common industry design aids that forego any code or implementation detail. Students individually edit the cards to redesign the application's architecture, while the system simulates the effects of these edits by updating emulated code metrics and estimating redesign cost. Returning to their teams, students discuss the cost and complexity of their designs before selecting and refining a single solution. By the activity's end, the students will have practiced all the design skills necessary for a months-long cycle of development, without the students or the instructor manually managing any implementation details.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 2},
pages = {1405–1406},
numpages = {2},
keywords = {collaborative design, collaborative learning, serious play, teaching software design},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{10.1145/3706598.3713677,
author = {Jiang, Chutian and Fan, Yinan and Xie, Junan and Kuang, Emily and Feng, Baichuan and Zhang, Kaihao and Fan, Mingming},
title = {Designing LLM-Powered Multimodal Instructions to Support Rich Hands-on Skills Remote Learning: A Case Study with Massage Instructors and Learners},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713677},
doi = {10.1145/3706598.3713677},
abstract = {Although remote learning is widely used for delivering and capturing knowledge, it has limitations in teaching hands-on skills that require nuanced instructions and demonstrations of precise actions, such as massage. Furthermore, scheduling conflicts between instructors and learners often limit the availability of real-time feedback, reducing learning efficiency. To address these challenges, we developed a synthesis tool utilizing an LLM-powered Virtual Teaching Assistant (VTA). This tool integrates multimodal instructions that convey precise data, such as stroke patterns and pressure control, while providing real-time feedback for learners and summarizing their performance for instructors. Our case study with instructors and learners demonstrated the effectiveness of these multimodal instructions and the VTA in enhancing massage teaching and learning. We then discuss the tools’ use in other hands-on skills instruction and cognitive process differences in various courses.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {15},
numpages = {17},
keywords = {Remote Massage Learning; Multimodal Teaching and Learning; Hands-on Training.},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3690624.3709337,
author = {Wang, Qi (Cheems) and Lv, Yiqin and Mao, Yixiu and Qu, Yun and Xu, Yi and Ji, Xiangyang},
title = {Robust Fast Adaptation from Adversarially Explicit Task Distribution Generation},
year = {2025},
isbn = {9798400712456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690624.3709337},
doi = {10.1145/3690624.3709337},
abstract = {Meta-learning is a practical learning paradigm to transfer skills across tasks from a few examples. Nevertheless, the existence of task distribution shifts tends to weaken meta-learners' generalization capability, particularly when the training task distribution is naively hand-crafted or based on simple priors that fail to cover critical scenarios sufficiently. Here, we consider explicitly generative modeling task distributions placed over task identifiers and propose robustifying fast adaptation from adversarial training. Our approach, which can be interpreted as a model of a Stackelberg game, not only uncovers the task structure during problem-solving from an explicit generative model but also theoretically increases the adaptation robustness in worst cases. This work has practical implications, particularly in dealing with task distribution shifts in meta-learning, and contributes to theoretical insights in the field. Our method demonstrates its robustness in the presence of task subpopulation shifts and improved performance over SOTA baselines in extensive experiments. The code is available at the project site https://sites.google.com/view/ar-metalearn.},
booktitle = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
pages = {1481–1491},
numpages = {11},
keywords = {qi (cheems) wang, xiangyang ji, yi xu, yiqin lv, yixiu mao, yun qu},
location = {Toronto ON, Canada},
series = {KDD '25}
}

@inproceedings{10.1145/3656650.3656663,
author = {Gennari, Rosella and Krik, Soufiane},
title = {Responsible Design of Socio-Technical Solutions with Social Design Students: a Case Study},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656650.3656663},
doi = {10.1145/3656650.3656663},
abstract = {Recent research work on digital-well being considers it a matter of personal growth and education. Research in social digital well-being, in particular, invites young generations to consider the role of digital technologies for social well-being. It explored how to engage young generations in building socio-technical prototypes and reflecting on the impact of technology on people. This article fits into this broad line of research. It reports on a case study with social design students with no computing background. It invited them to consider the use of computing technologies in their social-design projects, and to reflect critically on their work. The design was structured with an ad hoc toolkit with various building materials, including cards for reflecting, and physical-computing devices for rapidly prototyping design ideas. The purpose of the toolkit is, on the one hand, to structure and constrain the generative design process and, on the other hand, to allow a certain degree of expressiveness and freedom to participants. The article reports the results of the case study and concludes with a discussion of how to engage non-computing experts in such a process, balancing freedom and guidance.},
booktitle = {Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
articleno = {50},
numpages = {9},
keywords = {Responsible design, building interaction, end user, interaction design tools, prototyping, social interaction, well being},
location = {Arenzano, Genoa, Italy},
series = {AVI '24}
}

@article{10.5555/3665464.3665466,
author = {Juhnke, Kevin},
title = {Perspectives on Technology's Impact on Financial Services and the Future Workforce},
year = {2024},
issue_date = {April 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {39},
number = {6},
issn = {1937-4771},
abstract = {A variety of experiences over a 30+ year career in the computing field at Principal Financial provides for a life-long journey with many fascinating insights. Mr. Juhnke will focus his thoughts on:• Business and market challenges in Financial Services and their impact on an organization's Technology Strategies• The impact key maturing and emerging technologies have on the Financial Services industry including...- Cloud Advancements- Generative AI- Blockchain- "Citizen" DevelopmentHe will conclude his thoughts with perspectives on areas where educators can help position students to be more marketable and impactful in financial services tech jobs after graduation.},
journal = {J. Comput. Sci. Coll.},
month = apr,
pages = {18–19},
numpages = {2}
}

@article{10.1145/3710953,
author = {Chen, Si and Cheng, Haocong and Su, Suzy and Patterson, Stephanie and Kushalnagar, Raja and Huang, Yun and Wang, Qi},
title = {Customizing Generated Signs and Voices of AI Avatars: Deaf-Centric Mixed-Reality Design for Deaf-Hearing Communication},
year = {2025},
issue_date = {May 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {2},
url = {https://doi.org/10.1145/3710953},
doi = {10.1145/3710953},
abstract = {This study investigates innovative interaction designs for communication and collaborative learning between learners of mixed hearing and signing abilities, leveraging advancements in mixed reality technologies like Apple Vision Pro and generative AI for animated avatars. Adopting a participatory design approach, we engaged 15 d/Deaf and hard of hearing (DHH) students to brainstorm ideas for an AI avatar with interpreting ability (sign language to English and English to sign language) that would facilitate their face-to-face communication with hearing peers. Participants envisioned the AI avatars to address some issues with human interpreters, such as lack of availability, and provide affordable options to expensive personalized interpreting services. Our findings indicate a range of preferences for integrating the AI avatars with actual human figures of both DHH and hearing communication partners. The participants highlighted the importance of having control over customizing the AI avatar, such as AI-generated signs, voices, facial expressions, and their synchronization for enhanced emotional display in communication. Based on our findings, we propose a suite of design recommendations that balance respecting sign language norms with adherence to hearing social norms. Our study offers insights into improving the authenticity of generative AI in scenarios involving specific and sometimes unfamiliar social norms.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {CSCW055},
numpages = {31},
keywords = {american sign language, facial expressions, interpreter, multi-modality, voice generation}
}

@inproceedings{10.1145/3722237.3722260,
author = {Wu, Yanan and Zeng, Xiaoping and Lin, Qibei},
title = {Generative AI Integrated Educational Model for User-Centered Design},
year = {2025},
isbn = {9798400712692},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3722237.3722260},
doi = {10.1145/3722237.3722260},
abstract = {The advent of artificial intelligence (AI) has profoundly transformed the educational landscape. Many educators are exploring how AI tools can enhance learning instructional programs. However, there is less focus on how its application within design education—particularly when teaching user-centered design. This study developed an educational model utilizing AI for user-centered design curriculum. Based on design thinking theory, this model integrates ChatGPT and Midjourney into the divergent and convergent design phases to facilitate the workflow. The empirical research showed that educational model can foster students’ creativity and problem-solving skills. The findings highlight the efficacy of AI integration in curricula design and instructional practices.},
booktitle = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Education},
pages = {129–135},
numpages = {7},
keywords = {Generative AI, design education, design thinking, instructional design, user-centered design},
location = {
},
series = {ICAIE '24}
}

@inproceedings{10.1145/3680533.3697066,
author = {Luo, Hanzhong and Gao, Fengsen and Fang, Ke and Liu, Dejian and Lin, Ziyun and Chan, Wai Kin (Victor)},
title = {Study with Confucius: An AI-Based Immersive Educational Game with Multiple Educational Modes},
year = {2024},
isbn = {9798400711367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680533.3697066},
doi = {10.1145/3680533.3697066},
abstract = {Current history education faces challenges in cultivating student immersion and knowledge retention. This study introduces an innovative educational game, "Study with Confucius", which blends traditional Chinese cultural education with AI technology. The game's objective is to enhance student engagement and learning outcomes by simulating historical figures and reconstructing historical backgrounds. Utilizing ChatGPT technology, the game assigns distinct educational abilities to different Agents, resulting in three unique educational modes. Players interact with these Agents, learning classical knowledge and gaining insights into the associated wisdom and moral culture. User study findings demonstrate that the game improves student immersion and their understanding and memorization of knowledge. This game offers adolescents a novel learning approach, where they can engage with and inherit traditional culture through interactive and enjoyable means.},
booktitle = {SIGGRAPH Asia 2024 Educator's Forum},
articleno = {9},
numpages = {6},
keywords = {History education, agent, educational game, immersion},
location = {
},
series = {SA '24}
}

@inproceedings{10.1145/3613904.3642677,
author = {Trajkova, Milka and Long, Duri and Deshpande, Manoj and Knowlton, Andrea and Magerko, Brian},
title = {Exploring Collaborative Movement Improvisation Towards the Design of LuminAI—a Co-Creative AI Dance Partner},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642677},
doi = {10.1145/3613904.3642677},
abstract = {Co-creation in embodied contexts is central to the human experience but is often lacking in our interactions with computers. We seek to develop a better understanding of embodied human co-creativity to inform the human-centered design of machines that can co-create with us. In this paper, we ask: What characterizes dancers’ experiences of embodied dyadic interaction in movement improvisation? To answer this, we ran focus groups with 24 university dance students and conducted a thematic analysis of their responses. We synthesize our findings in an Interconnected Model of Improvisational Dance Inputs, where movement choices are shaped by the interplay between in-the-moment influences between the self, partner, and the environment, a set of generative strategies, and heuristics for a successful collaboration. We present a set of design recommendations for LuminAI, a co-creative AI dance partner. Our contributions can inform the design of AI in embodied co-creative domains.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {890},
numpages = {22},
keywords = {AI agents, co-creative agents, co-creativity, computational creativity, dance improvisation, movement improvisation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.5555/3711988.3711989,
author = {Tham, Jason},
title = {Teaching UX: Amid the Hype of Generative AI},
year = {2025},
issue_date = {November 2024},
publisher = {Usability Professionals' Association},
address = {Bloomingdale, IL},
volume = {20},
number = {1},
issn = {1931-3357},
abstract = {I am a faculty member in a technical communication program at a comprehensive research university. Recently, I have been inundated with questions, concerns, and critiques about the rise of augmentation technologies in writing and design processes, particularly generative artificial intelligence (AI) tools that support chat-based text generation and text-to-image production. I'm sure many UX researchers and designers face similar issues in their work. It remains unclear how generative AI should fit into existing workflow or design processes. Common questions include these:• How does AI work? What can it do? Is it free?• Is it cheating if I use AI to produce content?• Who is responsible for the quality of AI-generated content?• To what extent can I outsource my routine work to AI? In other words, what's an acceptable threshold for using AI before it is considered too much?Specific to UX is the value (cost and labor versus gains and effects) of generative AI in the research and design of user-centered products. Students in my UX courses are increasingly worried about the presence of AI and, consequently, the relevance of their developing skill sets in UX. Educators are growing wary about the presence of AI in the context of teaching and learning; many form partially informed decisions on academic policies for AI usage.},
journal = {J. User Exper.},
month = feb,
pages = {1–8},
numpages = {8}
}

@inproceedings{10.1145/3580305.3599373,
author = {Zhao, Wentao and Wu, Qitian and Yang, Chenxiao and Yan, Junchi},
title = {GraphGLOW: Universal and Generalizable Structure Learning for Graph Neural Networks},
year = {2023},
isbn = {9798400701030},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3580305.3599373},
doi = {10.1145/3580305.3599373},
abstract = {Graph structure learning is a well-established problem that aims at optimizing graph structures adaptive to specific graph datasets to help message passing neural networks (i.e., GNNs) to yield effective and robust node embeddings. However, the common limitation of existing models lies in the underlying closed-world assumption: the testing graph is the same as the training graph. This premise requires independently training the structure learning model from scratch for each graph dataset, which leads to prohibitive computation costs and potential risks for serious over-fitting. To mitigate these issues, this paper explores a new direction that moves forward to learn a universal structure learning model that can generalize across graph datasets in an open world. We first introduce the mathematical definition of this novel problem setting, and describe the model formulation from a probabilistic data-generative aspect. Then we devise a general framework that coordinates a single graph-shared structure learner and multiple graph-specific GNNs to capture the generalizable patterns of optimal message-passing topology across datasets. The well-trained structure learner can directly produce adaptive structures for unseen target graphs without any fine-tuning. Across diverse datasets and various challenging cross-graph generalization protocols, our experiments show that even without training on target graphs, the proposed model i) significantly outperforms expressive GNNs trained on input (non-optimized) topology, and ii) surprisingly performs on par with state-of-the-art models that independently optimizes adaptive structures for specific target graphs, with notably orders-of-magnitude acceleration for training on the target graph.},
booktitle = {Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3525–3536},
numpages = {12},
keywords = {out-of-distribution generalization, network representation learning, graph structure learning, graph neural networks},
location = {Long Beach, CA, USA},
series = {KDD '23}
}

@inproceedings{10.1145/3610540.3627006,
author = {Garvey, Gregory Patrick},
title = {A University Curriculum Course for Undergraduates: Artificial Intelligence and Art},
year = {2023},
isbn = {9798400703119},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610540.3627006},
doi = {10.1145/3610540.3627006},
abstract = {This paper describes a new course entitled “AI &amp; Art” offered at Quinnipiac University in the spring of 2023. An updated version of this course is scheduled for Spring 2024. In this course, students use text-to-image AI generators to create artwork, write prompts using ChatGPT, and write short essays on critical issues and topics (creativity, deep fakes, copyright etc.) implicated by the rise of AI image-generation software. This course fosters essential learning outcomes such as critical thinking, creativity, and hands-on experience with AI technology preparing students for 21st-century careers.},
booktitle = {SIGGRAPH Asia 2023 Educator's Forum},
articleno = {1},
numpages = {2},
keywords = {text-to-image generation, ChatGPT, Artificial Intelligence, AI Detection, AI},
location = {Sydney, NSW, Australia},
series = {SA '23}
}

@inproceedings{10.1145/3544548.3581408,
author = {Jeong, Yunwoo and Cho, Hyungjun and Kim, Taewan and Nam, Tek-Jin},
title = {AutomataStage: an AR-mediated Creativity Support Tool for Hands-on Multidisciplinary Learning},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581408},
doi = {10.1145/3544548.3581408},
abstract = {The creativity support tools can enhance the hands-on multidisciplinary learning experience by drawing interest in the process of creating the outcome. We present AutomataStage, an AR-mediated creativity support tool for hands-on multidisciplinary learning. AutomataStage utilizes a video see-through interface to support the creation of Interactive Automata. The combination of building blocks and low-cost materials increases the expressiveness. The generative design method and one-to-one guide support the idea development process. It also provides a hardware see-through feature with which inside parts and circuits can be seen and an operational see-through feature that shows the operation in real-time. The visual programming method with a state transition diagram supports the iterative process during the creation process. A user study shows that AutomataStage enabled the students to create diverse Interactive Automata within 40-minute sessions. By creating Interactive Automata, the participants could learn the basic concepts of components. See-through features allowed active exploration with interest while integrating the components. We discuss the implications of hands-on tools with interactive and kinetic content beyond multidisciplinary learning.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {732},
numpages = {16},
keywords = {Interactive Automata, Multidisciplinary learning, STEAM, creativity support tool, hands-on learning, learning tool, video see-through system},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3587399.3587462,
author = {Piccolo, Lara and Buzzo, Daniel and Knobel, Martin and Gunasekera, Prasanna and Papathoma, Tina},
title = {Interaction Design as Project-Based Learning: Perspectives for Unsolved Challenges},
year = {2023},
isbn = {9798400707377},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587399.3587462},
doi = {10.1145/3587399.3587462},
abstract = {Project-based learning (PBL) is an educational approach that actively involves students in tackling real-world complex problems in an interdisciplinary way, emphasising critical thinking, collaboration and problem-solving skills. In this paper, we share our empirical experience of teaching three different modules of an Interaction Design program: Screen Design, Generative Design and Experience and Behaviour Design within the context of Project-Based Learning. We report on what we consider successful cases, as well as significant barriers encountered by the students. We then discuss some of the unsolved challenges, providing our perspectives for teaching interaction design with PBL.},
booktitle = {Proceedings of the 5th Annual Symposium on HCI Education},
pages = {59–67},
numpages = {9},
keywords = {HCI Education, Interaction design, Project-based learning},
location = {Hamburg, Germany},
series = {EduCHI '23}
}

@article{10.5555/3722479.3722530,
author = {Kollapally, Navya Martin and Geller, James and Morreale, Patricia and Kwak, Daehan},
title = {An Ontology for Social Determinants of Education (SDoEd) Based on Human-AI Collaborative Approach},
year = {2024},
issue_date = {October 2024},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {40},
number = {3},
issn = {1937-4771},
abstract = {The use of computational ontologies is well-established in the field of Medical Informatics. The topic of Social Determinants of Health (SDoH) has also received extensive attention. Work at the intersection of ontologies and SDoH has been published. However, a standardized framework for Social Determinants of Education (SDoEd) is lacking. In this paper, we are closing the gap by introducing an SDoEd ontology for creating a precise conceptualization of the interplay between life circumstances of students and their possible educational achievements. The ontology was developed utilizing suggestions from ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The first version of developed ontology was evaluated by human experts in the field of education and validated using standard ontology evaluation software. This version of the SDoEd ontology contains 231 domain concepts, 10 object properties, and 24 data properties.},
journal = {J. Comput. Sci. Coll.},
month = oct,
pages = {191–203},
numpages = {13}
}

@inproceedings{10.1145/3583780.3614821,
author = {Chen, Jiangui and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten and Chen, Wei and Fan, Yixing and Cheng, Xueqi},
title = {Continual Learning for Generative Retrieval over Dynamic Corpora},
year = {2023},
isbn = {9798400701245},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583780.3614821},
doi = {10.1145/3583780.3614821},
abstract = {Generative retrieval (GR) directly predicts the identifiers of relevant documents (i.e., docids) based on a parametric model. It has achieved solid performance on many ad-hoc retrieval tasks. So far, these tasks have assumed a static document collection. In many practical scenarios, however, document collections are dynamic, where new documents are continuously added to the corpus. The ability to incrementally index new documents while preserving the ability to answer queries with both previously and newly indexed relevant documents is vital to applying GR models. In this paper, we address this practical continual learning problem for GR. We put forward a novel Continual-LEarner for generatiVE Retrieval (CLEVER) model and make two major contributions to continual learning for GR: (i) To encode new documents into docids with low computational cost, we present Incremental Product Quantization, which updates a partial quantization codebook according to two adaptive thresholds; and (ii) To memorize new documents for querying without forgetting previous knowledge, we propose a memory-augmented learning mechanism, to form meaningful connections between old and new documents. Empirical results demonstrate the effectiveness and efficiency of the proposed model.},
booktitle = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
pages = {306–315},
numpages = {10},
keywords = {product quantization, generative retrieval, document increment},
location = {Birmingham, United Kingdom},
series = {CIKM '23}
}

@inproceedings{10.1145/3539597.3570404,
author = {Tan, Qiaoyu and Liu, Ninghao and Huang, Xiao and Choi, Soo-Hyun and Li, Li and Chen, Rui and Hu, Xia},
title = {S2GAE: Self-Supervised Graph Autoencoders are Generalizable Learners with Graph Masking},
year = {2023},
isbn = {9781450394079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3539597.3570404},
doi = {10.1145/3539597.3570404},
abstract = {Self-supervised learning (SSL) has been demonstrated to be effective in pre-training models that can be generalized to various downstream tasks. Graph Autoencoder (GAE), an increasingly popular SSL approach on graphs, has been widely explored to learn node representations without ground-truth labels. However, recent studies show that existing GAE methods could only perform well on link prediction tasks, while their performance on classification tasks is rather limited. This limitation casts doubt on the generalizability and adoption of GAE. In this paper, for the first time, we show that GAE can generalize well to both link prediction and classification scenarios, including node-level and graph-level tasks, by redesigning its critical building blocks from the graph masking perspective. Our proposal is called Self-Supervised Graph Autoencoder--S2GAE, which unleashes the power of GAEs with minimal yet nontrivial efforts. Specifically, instead of reconstructing the whole input structure, we randomly mask a portion of edges and learn to reconstruct these missing edges with an effective masking strategy and an expressive decoder network. Moreover, we theoretically prove that S2GAE could be regarded as an edge-level contrastive learning framework, providing insights into why it generalizes well. Empirically, we conduct extensive experiments on 21 benchmark datasets across link prediction and node &amp; graph classification tasks. The results validate the superiority of S2GAE against state-of-the-art generative and contrastive methods. This study demonstrates the potential of GAE as a universal representation learner on graphs. Our code is publicly available at https://github.com/qiaoyu-tan/S2GAE.},
booktitle = {Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
pages = {787–795},
numpages = {9},
keywords = {masked autoencoders, masked graph autoencoder, self-supervised learning},
location = {Singapore, Singapore},
series = {WSDM '23}
}

@inproceedings{10.1145/3675094.3677575,
author = {Watanabe, Ko and Tanaka, Seiya and Vargo, Andrew and Kise, Koichi and Dengel, Andreas},
title = {Comparing Web Browsing Behaviors with High and Low Information Literacy: A Case Study for Fact Check Against GPT Generated Fake News},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3677575},
doi = {10.1145/3675094.3677575},
abstract = {Generative AI has introduced significant concerns about how people interact with information in society, particularly regarding the potential harm caused by fake news. To address this issue, it is critical to understand how people perceive fake news and how their information literacy can be improved. Our research tackles two key questions: "Can we estimate the level of information literacy from participants' web browsing behavior?", and "What characteristics can be observed when comparing participants with high and low information literacy?". We recruited 20 university students to read and evaluate the veracity of generated news. During this process, participants used web searches to verify the news, with their browsing logs collected using the open-source browser extension TrackThink Camera. The study achieved a 73.8% accuracy in estimating participants' ability to detect fake news based on their web browsing behavior. Notably, we observed that web search time ratio is higher, the number of searches are more, and the average scrolling speed is faster for high information literacy participants.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {9–13},
numpages = {5},
keywords = {fake news, information literacy, machine learning, web browsing},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3543507.3583388,
author = {He, Bing and Ahamad, Mustaque and Kumar, Srijan},
title = {Reinforcement Learning-based Counter-Misinformation Response Generation: A Case Study of COVID-19 Vaccine Misinformation},
year = {2023},
isbn = {9781450394161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543507.3583388},
doi = {10.1145/3543507.3583388},
abstract = {The spread of online misinformation threatens public health, democracy, and the broader society. While professional fact-checkers form the first line of defense by fact-checking popular false claims, they do not engage directly in conversations with misinformation spreaders. On the other hand, non-expert ordinary users act as eyes-on-the-ground who proactively counter misinformation – recent research has shown that 96% counter-misinformation responses are made by ordinary users. However, research also found that 2/3 times, these responses are rude and lack evidence. This work seeks to create a counter-misinformation response generation model to empower users to effectively correct misinformation. This objective is challenging due to the absence of datasets containing ground-truth of ideal counter-misinformation responses, and the lack of models that can generate responses backed by communication theories. In this work, we create two novel datasets of misinformation and counter-misinformation response pairs from in-the-wild social media and crowdsourcing from college-educated students. We annotate the collected data to distinguish poor from ideal responses that are factual, polite, and refute misinformation. We propose MisinfoCorrect, a reinforcement learning-based framework that learns to generate counter-misinformation responses for an input misinformation post. The model rewards the generator to increase the politeness, factuality, and refutation attitude while retaining text fluency and relevancy. Quantitative and qualitative evaluation shows that our model outperforms several baselines by generating high-quality counter-responses. This work illustrates the promise of generative text models for social good – here, to help create a safe and reliable information ecosystem. The code and data is accessible on https://github.com/claws-lab/MisinfoCorrect.},
booktitle = {Proceedings of the ACM Web Conference 2023},
pages = {2698–2709},
numpages = {12},
keywords = {misinformation, reinforcement learning, text generation},
location = {Austin, TX, USA},
series = {WWW '23}
}

@article{10.1613/jair.1.13550,
author = {Javed, Rana Tallal and Nasir, Osama and Borit, Melania and Vanh\'{e}e, Lo\"{\i}s and Zea, Elias and Gupta, Shivam and Vinuesa, Ricardo and Qadir, Junaid},
title = {Get out of the BAG! Silos in AI Ethics Education: Unsupervised Topic Modeling Analysis of Global AI Curricula},
year = {2022},
issue_date = {May 2022},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {73},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.13550},
doi = {10.1613/jair.1.13550},
abstract = {The domain of Artificial Intelligence (AI) ethics is not new, with discussions going back at least 40 years. Teaching the principles and requirements of ethical AI to students is considered an essential part of this domain, with an increasing number of technical AI courses taught at several higher-education institutions around the globe including content related to ethics. By using Latent Dirichlet Allocation (LDA), a generative probabilistic topic model, this study uncovers topics in teaching ethics in AI courses and their trends related to where the courses are taught, by whom, and at what level of cognitive complexity and specificity according to Bloom’s taxonomy. In this exploratory study based on unsupervised machine learning, we analyzed a total of 166 courses: 116 from North American universities, 11 from Asia, 36 from Europe, and 10 from other regions. Based on this analysis, we were able to synthesize a model of teaching approaches, which we call BAG (Build, Assess, and Govern), that combines specific cognitive levels, course content topics, and disciplines affiliated with the department(s) in charge of the course. We critically assess the implications of this teaching paradigm and provide suggestions about how to move away from these practices. We challenge teaching practitioners and program coordinators to reflect on their usual procedures so that they may expand their methodology beyond the confines of stereotypical thought and traditional biases regarding what disciplines should teach and how.
This article appears in the AI &amp; Society track.},
journal = {J. Artif. Int. Res.},
month = may,
numpages = {33},
keywords = {discourse modelling, data mining, scientific discovery, philosophical foundations}
}

@inproceedings{10.1145/3503161.3547855,
author = {Huang, Rongjie and Zhao, Zhou and Liu, Huadai and Liu, Jinglin and Cui, Chenye and Ren, Yi},
title = {ProDiff: Progressive Fast Diffusion Model for High-Quality Text-to-Speech},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3547855},
doi = {10.1145/3503161.3547855},
abstract = {Denoising diffusion probabilistic models (DDPMs) have recently achieved leading performances in many generative tasks. However, the inherited iterative sampling process costs hinder their applications to text-to-speech deployment. Through the preliminary study on diffusion model parameterization, we find that previous gradient-based TTS models require hundreds or thousands of iterations to guarantee high sample quality, which poses a challenge for accelerating sampling. In this work, we propose ProDiff, on progressive fast diffusion model for high-quality text-to-speech. Unlike previous work estimating the gradient for data density, ProDiff parameterizes the denoising model by directly predicting clean data to avoid distinct quality degradation in accelerating sampling. To tackle the model convergence challenge with decreased diffusion iterations, ProDiff reduces the data variance in the target site via knowledge distillation. Specifically, the denoising model uses the generated mel-spectrogram from an N-step DDIM teacher as the training target and distills the behavior into a new model with N/2 steps. As such, it allows the TTS model to make sharp predictions and further reduces the sampling time by orders of magnitude. Our evaluation demonstrates that ProDiff needs only 2 iterations to synthesize high-fidelity mel-spectrograms, while it maintains sample quality and diversity competitive with state-of-the-art models using hundreds of steps. ProDiff enables a sampling speed of 24x faster than real-time on a single NVIDIA 2080Ti GPU, making diffusion models practically applicable to text-to-speech synthesis deployment for the first time. Our extensive ablation studies demonstrate that each design in ProDiff is effective, and we further show that ProDiff can be easily extended to the multi-speaker setting.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {2595–2605},
numpages = {11},
keywords = {text-to-speech, speech synthesis, diffusion probabilistic model},
location = {Lisboa, Portugal},
series = {MM '22}
}

